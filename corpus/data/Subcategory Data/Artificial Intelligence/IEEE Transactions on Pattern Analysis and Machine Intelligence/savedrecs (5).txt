PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Zhou, F; De la Torre, F				Zhou, Feng; De la Torre, Fernando			Generalized Canonical Time Warping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-modal sequence alignment; canonical correlation analysis; dynamic time warping	LINEAR-TIME; RECOGNITION; ALIGNMENT; CCA	Temporal alignment of human motion has been of recent interest due to its applications in animation, tele-rehabilitation and activity recognition. This paper presents generalized canonical time warping (GCTW), an extension of dynamic time warping (DTW) and canonical correlation analysis (CCA) for temporally aligning multi-modal sequences from multiple subjects performing similar activities. GCTW extends previous work on DTW and CCA in several ways: (1) it combines CCA with DTW to align multi-modal data (e.g., video and motion capture data); (2) it extends DTW by using a linear combination of monotonic functions to represent the warping path, providing a more flexible temporal warp. Unlike exact DTW, which has quadratic complexity, we propose a linear time algorithm to minimize GCTW. (3) GCTW allows simultaneous alignment of multiple sequences. Experimental results on aligning multi-modal data, facial expressions, motion capture data and video illustrate the benefits of GCTW. The code is available at http://humansensing.cs.cmu. edu/ctw.	[Zhou, Feng; De la Torre, Fernando] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Zhou, F; De la Torre, F (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	zhfe99@gmail.com; ftorre@cs.cmu.edu			National Science Foundation [EEEC-0540865, RI-1116583, CPS-0931999]	National Science Foundation(National Science Foundation (NSF))	This work was partially supported by the National Science Foundation under Grant No. EEEC-0540865, RI-1116583 and CPS-0931999. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. F. Zhou is the corresponding author.	Aach J, 2001, BIOINFORMATICS, V17, P495, DOI 10.1093/bioinformatics/17.6.495; Anderson T. W., 2003, INTRO MULTIVARIATE S; Barbic J, 2004, PROC GRAPH INTERF, P185; Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35; Bertsekas D. P., 1995, DYNAMIC PROGRAMMING, V1; Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865; Bruderlin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P97, DOI 10.1145/218380.218421; Caspi Y, 2002, INT J COMPUT VISION, V48, P39, DOI 10.1023/A:1014803327923; Chu S, 2002, SIAM PROC S, P195; Chu WS, 2012, LECT NOTES COMPUT SC, V7575, P373, DOI 10.1007/978-3-642-33765-9_27; De la Torre F., 2009, RITR0822 CARN MELL U; De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184; Dryden I.L., 1998, STAT SHAPE ANAL; Fischer B., 2007, BMC BIOINFORMATICS, V8, P1; Gong D, 2011, IEEE I CONF COMP VIS, P571, DOI 10.1109/ICCV.2011.6126290; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Gorelick L, 2006, IEEE T PATTERN ANAL, V28, P1991, DOI 10.1109/TPAMI.2006.253; Gusfield D, 1997, ALGORITHMS STRINGS T; Ham J., 2005, P ANN C UNC ART INT, P120; Hasan Mohammed A., 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1128, DOI 10.1109/IJCNN.2009.5178958; Heloir A, 2006, COMPUT ANIMAT VIRT W, V17, P347, DOI 10.1002/cav.138; Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315; Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68; Keogh E.J., 2001, P 2001 SIAM INT C DA, P1, DOI [10.1137/1.9781611972719.1, DOI 10.1137/1.9781611972719.1]; Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167; Listgarten J., 2005, P 18 ANN C NEUR INF, P817; Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156; Nicolaou MA, 2014, IEEE T PATTERN ANAL, V36, P1299, DOI 10.1109/TPAMI.2014.16; Pan W., 2009, P 26 ANN INT C MACH, P785; Rabiner L., 1993, FUNDAMENTALS SPEECH; Rakthanmanon Thanawin, 2012, KDD, V2012, P262, DOI 10.1145/2339530.2339576; Ramsay J.O., 2005, FUNCTIONAL DATA ANAL; Ramsay JO, 1998, J ROY STAT SOC B, V60, P365, DOI 10.1111/1467-9868.00130; Rao C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P939; Robertson T, 1988, ORDER RESTRICTED STA; Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Shapiro A, 2006, PROC GRAPH INTERF, P33; Shariat S, 2011, IEEE I CONF COMP VIS, P2572, DOI 10.1109/ICCV.2011.6126545; Tormene P, 2009, ARTIF INTELL MED, V45, P11, DOI 10.1016/j.artmed.2008.11.007; Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143; Wang C, 2008, P 25 INT C MACH LEAR, P1120, DOI DOI 10.1145/1390156.1390297; Winters JM, 2003, IEEE ENG MED BIOL, V22, P56, DOI 10.1109/MEMB.2003.1213627; WRIGHT IW, 1980, ANN STAT, V8, P1023, DOI 10.1214/aos/1176345140; Zhou F., 2009, P NEUR INF PROC SYST, P2286; Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137; Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812	50	57	62	2	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					279	294		10.1109/TPAMI.2015.2414429	http://dx.doi.org/10.1109/TPAMI.2015.2414429			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761734	Green Submitted			2022-12-18	WOS:000369989600007
J	Bartoli, A; Gerard, Y; Chadebecq, F; Collins, T; Pizarro, D				Bartoli, Adrien; Gerard, Yan; Chadebecq, Francois; Collins, Toby; Pizarro, Daniel			Shape-from-Template	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							SURFACE DETECTION	We study a problem that we call Shape-from-Template, which is the problem of reconstructing the shape of a deformable surface from a single image and a 3D template. Current methods in the literature address the case of isometric deformations, and relax the isometry constraint to the convex inextensibility constraint, solved using the so-called maximum depth heuristic. We call these methods zeroth-order since they use image point locations (the zeroth-order differential structure) to solve the shape inference problem from a perspective image. We propose a novel class of methods that we call first-order. The key idea is to use both image point locations and their first-order differential structure. The latter can be easily extracted from a warp between the template and the input image. We give a unified problem formulation as a system of PDEs for isometric and conformal surfaces that we solve analytically. This has important consequences. First, it gives the first analytical algorithms to solve this type of reconstruction problems. Second, it gives the first algorithms to solve for the exact constraints. Third, it allows us to study the well-posedness of this type of reconstruction: we establish that isometric surfaces can be reconstructed unambiguously and that conformal surfaces can be reconstructed up to a few discrete ambiguities and a global scale. In the latter case, the candidate solution surfaces are obtained analytically. Experimental results on simulated and real data show that our isometric methods generally perform as well as or outperform state of the art approaches in terms of reconstruction accuracy, while our conformal methods largely outperform all isometric methods for extensible deformations.	[Bartoli, Adrien; Gerard, Yan; Chadebecq, Francois; Collins, Toby; Pizarro, Daniel] Clermont Univ, ISIT ALCoV, Aubiere, France		Bartoli, A (corresponding author), Clermont Univ, ISIT ALCoV, Aubiere, France.	adrien.bartoli@gmail.com; yan.gerard@udamail.fr; f.chadebecq@gmail.com; Toby.Collins@gmail.com; Dani.Pizarro@gmail.com	Collins, Toby/Q-8967-2019	Collins, Toby/0000-0002-9441-8306; Pizarro, Daniel/0000-0003-0622-4884	EU's FP7 through the ERC research grant [307483 FLEXABLE]	EU's FP7 through the ERC research grant	The authors would like to thank the authors of [27] for the implementation of their reconstruction method and the authors of [37] for their dataset. This research has received funding from the EU's FP7 through the ERC research grant 307483 FLEXABLE. Adrien Bartoli is the corresponding author.	Bartoli A, 2012, PROC CVPR IEEE, P2026, DOI 10.1109/CVPR.2012.6247906; Bartoli A, 2013, IEEE I CONF COMP VIS, P961, DOI 10.1109/ICCV.2013.123; Bartoli A, 2013, PROC CVPR IEEE, P1514, DOI 10.1109/CVPR.2013.199; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Brunet F., 2010, ACCV, V6494, P52; Chhatkuli A, 2014, PROC CVPR IEEE, P708, DOI 10.1109/CVPR.2014.96; Del Bue A, 2008, P IEEE C COMP VIS PA, P1; DUCHON J, 1976, REV FR AUTOMAT INFOR, V10, P5; Ecker A, 2008, LECT NOTES COMPUT SC, V5302, P127, DOI 10.1007/978-3-540-88682-2_11; Gay-Bellile V, 2010, IEEE T PATTERN ANAL, V32, P87, DOI 10.1109/TPAMI.2008.265; Gumerov NA, 2006, INT J COMPUT VISION, V66, P261, DOI 10.1007/s11263-005-3678-x; Hartley R., 2003, MULTIPLE VIEW GEOMET; IKEUCHI K, 1984, ARTIF INTELL, V22, P49, DOI 10.1016/0004-3702(84)90025-0; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malti A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1650, DOI 10.1109/ICCVW.2011.6130447; Malti A., 2011, P C MED IM UND AN, P1; Moreno-Noguer F., 2010, P EUR C COMP VIS, P361; Moreno-Noguer F, 2009, PROC CVPR IEEE, P1842, DOI 10.1109/CVPRW.2009.5206758; Ohta T.I., 1981, P INT JOINT C ART IN, P746; Perriollat M, 2013, COMPUT ANIMAT VIRT W, V24, P457, DOI 10.1002/cav.1478; Perriollat M, 2011, INT J COMPUT VISION, V95, P124, DOI 10.1007/s11263-010-0352-8; Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9; Pizarro D, 2012, INT J COMPUT VISION, V97, P54, DOI 10.1007/s11263-011-0452-0; Russell C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3009, DOI 10.1109/CVPR.2011.5995383; Salzmann M., 2007, COMP VIS 2007 ICCV 2, P1; Salzmann M, 2008, LECT NOTES COMPUT SC, V5305, P581, DOI 10.1007/978-3-540-88693-8_43; Salzmann M, 2007, IEEE I CONF COMP VIS, P1578; Salzmann M, 2007, IEEE T PATTERN ANAL, V29, P1481, DOI 10.1109/TPAMI.2007.1080; Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158; Salzmann M, 2009, PROC CVPR IEEE, P1054, DOI 10.1109/CVPRW.2009.5206759; Shaji A, 2010, PROC CVPR IEEE, P1221, DOI 10.1109/CVPR.2010.5539827; Sheffer A, 2005, ACM T GRAPHIC, V24, P311, DOI 10.1145/1061347.1061354; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Varol A, 2012, PROC CVPR IEEE, P2248, DOI 10.1109/CVPR.2012.6247934; Vicente S, 2012, LECT NOTES COMPUT SC, V7574, P426, DOI 10.1007/978-3-642-33712-3_31	38	57	58	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					2099	2118		10.1109/TPAMI.2015.2392759	http://dx.doi.org/10.1109/TPAMI.2015.2392759			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26353187				2022-12-18	WOS:000360813400012
J	Gao, SB; Yang, KF; Li, CY; Li, YJ				Gao, Shao-Bing; Yang, Kai-Fu; Li, Chao-Yi; Li, Yong-Jie			Color Constancy Using Double-Opponency	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color constancy; double opponency; human visual system; pooling mechanism	ILLUMINATION CHROMATICITY; NEURAL-NETWORK; RETINEX THEORY; VISUAL-CORTEX; MODEL; IMAGE; CATEGORIZATION; STATISTICS; ALGORITHM; VISION	The double-opponent (DO) color-sensitive cells in the primary visual cortex (V1) of the human visual system (HVS) have long been recognized as the physiological basis of color constancy. In this work we propose a new color constancy model by imitating the functional properties of the HVS from the single-opponent (SO) cells in the retina to the DO cells in V1 and the possible neurons in the higher visual cortexes. The idea behind the proposed double-opponency based color constancy (DOCC) model originates from the substantial observation that the color distribution of the responses of DO cells to the color-biased images coincides well with the vector denoting the light source color. Then the illuminant color is easily estimated by pooling the responses of DO cells in separate channels in LMS space with the pooling mechanism of sum or max. Extensive evaluations on three commonly used datasets, including the test with the dataset dependent optimal parameters, as well as the intra-and inter-dataset cross validation, show that our physiologically inspired DOCC model can produce quite competitive results in comparison to the state-of-the-art approaches, but with a relative simple implementation and without requiring fine-tuning of the method for each different dataset.	[Gao, Shao-Bing; Yang, Kai-Fu; Li, Chao-Yi; Li, Yong-Jie] Univ Elect Sci & Technol China, Sch Life Sci & Technol, Chengdu 610054, Peoples R China; [Li, Chao-Yi] Chinese Acad Sci, Shanghai Inst Biol Scien, Ctr Life Sci, Shanghai 200031, Peoples R China	University of Electronic Science & Technology of China; Chinese Academy of Sciences; Shanghai Institutes for Biological Sciences, CAS	Li, YJ (corresponding author), Univ Elect Sci & Technol China, Sch Life Sci & Technol, Chengdu 610054, Peoples R China.	gao_shaobing@163.com; yang_kf@163.com; cyli@sibs.ac.cn; liyj@uestc.edu.cn			Major State Basic Research Program [2013CB329401]; Natural Science Foundations of China [61375115, 91420105, 91120013]; Doctoral Support Program of UESTC; 111 Project [B12027]	Major State Basic Research Program(National Basic Research Program of China); Natural Science Foundations of China(National Natural Science Foundation of China (NSFC)); Doctoral Support Program of UESTC; 111 Project(Ministry of Education, China - 111 Project)	The authors would like to thank all the anonymous reviewers for their thoughtful comments. This work was supported by the Major State Basic Research Program under Grant 2013CB329401, the Natural Science Foundations of China under Grant 61375115, 91420105, 91120013, and the Doctoral Support Program of UESTC. The work was also supported by the 111 Project (B12027). Yong-Jie Li is the corresponding author of the article.	Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049; Bianco S, 2010, PATTERN RECOGN, V43, P695, DOI 10.1016/j.patcog.2009.08.007; Bianco S, 2008, IEEE T IMAGE PROCESS, V17, P2381, DOI 10.1109/TIP.2008.2006661; Bianco S, 2014, IEEE T PATTERN ANAL, V36, P1505, DOI 10.1109/TPAMI.2013.2297710; BRAINARD DH, 1986, J OPT SOC AM A, V3, P1651, DOI 10.1364/JOSAA.3.001651; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Carandini M, 2012, NAT REV NEUROSCI, V13, P51, DOI 10.1038/nrn3136; Cardei V. C., 1999, COL IM C, V1, P311; Cardei VC, 2002, J OPT SOC AM A, V19, P2374, DOI 10.1364/JOSAA.19.002374; Chakrabarti A, 2012, IEEE T PATTERN ANAL, V34, P1509, DOI 10.1109/TPAMI.2011.252; Conway BR, 2007, NEURON, V56, P560, DOI 10.1016/j.neuron.2007.10.008; Conway BR, 2010, J NEUROSCI, V30, P14955, DOI 10.1523/JNEUROSCI.4348-10.2010; Conway BR, 2009, NEUROSCIENTIST, V15, P274, DOI 10.1177/1073858408331369; COURTNEY SM, 1995, IEEE T NEURAL NETWOR, V6, P972, DOI 10.1109/72.392259; Drew MS, 2012, LECT NOTES COMPUT SC, V7584, P411, DOI 10.1007/978-3-642-33868-7_41; DUFORT PA, 1991, BIOL CYBERN, V65, P293, DOI 10.1007/BF00206226; EBNER M., 2007, COLOR CONSTANCY, V6; Ebner M, 2006, PATTERN RECOGN LETT, V27, P1220, DOI 10.1016/j.patrec.2005.07.020; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; Finlayson GD, 1996, IEEE T PATTERN ANAL, V18, P1034, DOI 10.1109/34.541413; Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37; Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885; Finlayson GD, 2013, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2013.239; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Foster DH, 2011, VISION RES, V51, P674, DOI 10.1016/j.visres.2010.09.006; Funt B, 2004, J ELECTRON IMAGING, V13, P48, DOI 10.1117/1.1636761; Funt B, 2010, COLOR IMAG CONF, P256; Gao SB, 2013, IEEE I CONF COMP VIS, P929, DOI 10.1109/ICCV.2013.119; Gegenfurtner KR, 2003, NAT REV NEUROSCI, V4, P563, DOI 10.1038/nrn1138; Gehler PV, 2008, PROC CVPR IEEE, P3291; Gijsenij A., COLOR CONSTANCY RES; Gijsenij A, 2012, IEEE T PATTERN ANAL, V34, P918, DOI 10.1109/TPAMI.2011.197; Gijsenij A, 2012, IEEE T IMAGE PROCESS, V21, P697, DOI 10.1109/TIP.2011.2165219; Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224; Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93; Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3; Golz J, 2002, NATURE, V415, P637, DOI 10.1038/415637a; Hansen T, 2006, NAT NEUROSCI, V9, P1367, DOI 10.1038/nn1794; Hordley SD, 2006, J OPT SOC AM A, V23, P1008, DOI 10.1364/JOSAA.23.001008; Hordley SD, 2006, COLOR RES APPL, V31, P303, DOI 10.1002/col.20226; Huang CH, 2007, IEEE T CIRCUITS-I, V54, P35, DOI 10.1109/TCSI.2006.887975; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356; Johnson EN, 2001, NAT NEUROSCI, V4, P409, DOI 10.1038/86061; Joze HRV, 2014, IEEE T PATTERN ANAL, V36, P860, DOI 10.1109/TPAMI.2013.169; Kiper DC, 1997, VISUAL NEUROSCI, V14, P1061, DOI 10.1017/S0952523800011779; Land E, 1977, RETINEX THEORY COLOR; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; LAND EH, 1983, P NATL ACAD SCI USA, V80, P5163, DOI 10.1073/pnas.80.16.5163; LAND EH, 1986, VISION RES, V26, P7, DOI 10.1016/0042-6989(86)90067-2; Lau H. Y., 2008, THESIS HONG KONG U S; LEE HC, 1986, J OPT SOC AM A, V3, P1694, DOI 10.1364/JOSAA.3.001694; LIVINGSTONE MS, 1984, J NEUROSCI, V4, P309; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MOORE A, 1991, IEEE T NEURAL NETWOR, V2, P237, DOI 10.1109/72.80334; Provenzi E, 2005, J OPT SOC AM A, V22, P2613, DOI 10.1364/JOSAA.22.002613; Rahtu E, 2009, LECT NOTES COMPUT SC, V5716, P873, DOI 10.1007/978-3-642-04146-4_93; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629; Roe AW, 2012, NEURON, V74, P12, DOI 10.1016/j.neuron.2012.03.011; Rosenberg Charles R., 2003, ADV NEURAL INFORM PR, P1595; Schaefer G, 2005, PROC CVPR IEEE, P148; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Shapley R, 2011, VISION RES, V51, P701, DOI 10.1016/j.visres.2011.02.012; Shi L., REPROCESSED VERSION; Solomon SG, 2007, NAT REV NEUROSCI, V8, P276, DOI 10.1038/nrn2094; Spitzer H, 2002, PATTERN RECOGN, V35, P1645, DOI 10.1016/S0031-3203(01)00160-1; Stoughton CM, 2008, CURR BIOL, V18, pR698, DOI 10.1016/j.cub.2008.06.018; Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321; Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808; van de Weijer J, 2007, IEEE I CONF COMP VIS, P2197; Vazquez-Corral J, 2012, IEEE T IMAGE PROCESS, V21, P1997, DOI 10.1109/TIP.2011.2171353; Xiao YP, 2003, NATURE, V421, P535, DOI 10.1038/nature01372; Xiong WH, 2006, J IMAGING SCI TECHN, V50, P341, DOI 10.2352/J.ImagingSci.Technol.(2006)50:4(341); Yang KF, 2013, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2013.362; ZEKI S, 1983, NEUROSCIENCE, V9, P741, DOI 10.1016/0306-4522(83)90265-8	77	57	61	2	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					1973	1985		10.1109/TPAMI.2015.2396053	http://dx.doi.org/10.1109/TPAMI.2015.2396053			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26353182				2022-12-18	WOS:000360813400003
J	Tai, YW; Chen, XG; Kim, S; Kim, SJ; Li, F; Yang, J; Yu, JY; Matsushita, Y; Brown, MS				Tai, Yu-Wing; Chen, Xiaogang; Kim, Sunyeong; Kim, Seon Joo; Li, Feng; Yang, Jie; Yu, Jingyi; Matsushita, Yasuyuki; Brown, Michael S.			Nonlinear Camera Response Functions and Image Deblurring: Theoretical Analysis and Practice	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonlinear camera response functions (CRFs); motion deblurring; CRF estimation	CALIBRATION	This paper investigates the role that nonlinear camera response functions (CRFs) have on image deblurring. We present a comprehensive study to analyze the effects of CRFs on motion deblurring. In particular, we show how nonlinear CRFs can cause a spatially invariant blur to behave as a spatially varying blur. We prove that such nonlinearity can cause large errors around edges when directly applying deconvolution to a motion blurred image without CRF correction. These errors are inevitable even with a known point spread function (PSF) and with state-of-the-art regularization-based deconvolution algorithms. In addition, we show how CRFs can adversely affect PSF estimation algorithms in the case of blind deconvolution. To help counter these effects, we introduce two methods to estimate the CRF directly from one or more blurred images when the PSF is known or unknown. Our experimental results on synthetic and real images validate our analysis and demonstrate the robustness and accuracy of our approaches.	[Tai, Yu-Wing; Kim, Sunyeong] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea; [Chen, Xiaogang; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China; [Kim, Seon Joo] Yonsei Univ, Dept Comp Sci, Engn Coll, Seoul 120749, South Korea; [Li, Feng] Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA; [Yu, Jingyi] Univ Delaware, Dept CIS, Coll Engn, Newark, DE 19716 USA; [Matsushita, Yasuyuki] Microsoft Res Asia T2 13173, Beijing 100080, Peoples R China; [Brown, Michael S.] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore	Korea Advanced Institute of Science & Technology (KAIST); Shanghai Jiao Tong University; Yonsei University; University of Delaware; National University of Singapore	Tai, YW (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, 291 Daehak Ro, Taejon 305701, South Korea.	yuwing@kaist.ac.kr; cxg@stju.edu.cn; harharr@gmail.com; seonjookim@yonsei.ac.kr; fli@merl.com; jieyang@stju.edu.cn; yu@cis.udel.edu; yasumat@microsoft.com; brown@comp.nus.edu.sg	Tai, Yu Wing/C-2047-2011	Tai, Yu Wing/0000-0002-3148-0380; Matsushita, Yasuyui/0000-0002-1935-4752	National Research Foundation of Korea [2012-0003359]; Microsoft Research Asia under the KAIST-Microsoft Research Collaboration Center, Natural Science Foundation (China) [61273258, 61105001]; Committee of Science and Technology, Shanghai [11530700200]; US National Science Foundation [IIS-CAREER-0845268, IIS-RI-1016395]; US Air Force Office of Science Research under the YIP Award; Singapore A*STAR PSF grant [1121202020]; Div Of Information & Intelligent Systems [1016395] Funding Source: National Science Foundation	National Research Foundation of Korea(National Research Foundation of Korea); Microsoft Research Asia under the KAIST-Microsoft Research Collaboration Center, Natural Science Foundation (China); Committee of Science and Technology, Shanghai; US National Science Foundation(National Science Foundation (NSF)); US Air Force Office of Science Research under the YIP Award; Singapore A*STAR PSF grant; Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was funded in part by the National Research Foundation of Korea (2012-0003359), Microsoft Research Asia under the KAIST-Microsoft Research Collaboration Center, Natural Science Foundation (China) (Nos. 61273258, 61105001), the Committee of Science and Technology, Shanghai (No. 11530700200), US National Science Foundation under grants IIS-CAREER-0845268 and IIS-RI-1016395, the US Air Force Office of Science Research under the YIP Award, and the Singapore A*STAR PSF grant (Proj No. 1121202020).	Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1; Bian L, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011); CAI J, 2009, P IEEE C COMP VIS PA; Chakrabarti A., 2009, P BRIT MACH VIS C; Chang YC, 1996, IEEE T IMAGE PROCESS, V5, P1414, DOI 10.1109/83.536890; Chen J., 2008, P IEEE C COMP VIS PA; Chen X., 2011, P IEEE C COMP VIS PA; CHEN X, 2012, P 12 EUR C COMP VIS; CHO S, 2007, P 11 IEEE INT C COMP; Cho S., 2011, P IEEE INT C COMP VI; CHO S, 2009, P ACM SIGGR ASIA; Cho T. S., 2011, P IEEE C COMP VIS PA; Debevec P. E., 1997, P ACM SIGGRAPH; Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; GROSSBERG M, 2003, P IEEE C COMP VIS PA; Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88; JIA J, 2007, P IEEE C COMP VIS PA; Joshi N., 2010, ACM T GRAPHICS, V29; Joshi N., 2008, P IEEE C COMP VIS PA; KIM S, 2012, P IEEE C COMP VIS PA; Kim S. J., 2008, P IEEE C COMP VIS PA; Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732; Kim SJ, 2012, IEEE T PATTERN ANAL, V34, P2289, DOI 10.1109/TPAMI.2012.58; Krishnan D., 2011, P IEEE C COMP VIS PA; KRISHNAN D, 2009, P C NEUR INF PROC SY; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Lee J., 2011, P IEEE C COMP VIS PA; LEVIN A, 2006, P C NEUR INF PROC SY; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Lin H.T., 2011, P IEEE INT C COMP VI; LIN S, 2005, P IEEE C COMP VIS PA; LIN S, 2004, P IEEE C COMP VIS PA; LU PY, 2009, P IEEE C COMP VIS PA; Lucy L. B., 1974, ASTRON J, V79, p754 ; MATSUSHITA Y, 2007, P IEEE C COMP VIS PA; MITSUNAGA T, 1999, P IEEE C COMP VIS PA; Ng TT., 2007, P IEEE COMP SOC C CO, DOI [10.1109/CVPR.2007.383000, DOI 10.1109/CVPR.2007.383000]; Rav-Acha A, 2005, PATTERN RECOGN LETT, V26, P311, DOI 10.1016/j.patrec.2004.10.017; Richardson W. H., 1972, J OPTICAL SOC AM, V62; Shan Q., 2008, ACM T GRAPHICS, V27; TAI W, 2008, P IEEE C COMP VIS PA; Tai Y.-W., 2010, P IEEE C COMP VIS PA; Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222; Tai YW, 2010, IEEE T PATTERN ANAL, V32, P1012, DOI 10.1109/TPAMI.2009.97; TAI YW, 2012, P IEEE C COMP VIS PA; Whyte O., 2010, P IEEE C COMP VIS PA; WILBURN B, 2008, P IEEE C COMP VIS PA; Xu L., 2010, P 11 EUR C COMP VIS; Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452	51	57	62	1	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2498	2512		10.1109/TPAMI.2013.40	http://dx.doi.org/10.1109/TPAMI.2013.40			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969392	Green Published			2022-12-18	WOS:000323175200014
J	Liu, MZ; Vemuri, BC; Amari, SI; Nielsen, F				Liu, Meizhu; Vemuri, Baba C.; Amari, Shun-Ichi; Nielsen, Frank			Shape Retrieval Using Hierarchical Total Bregman Soft Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Total Bregman divergence; t-center; lifted exponential families; hard clustering; soft clustering; Gaussian mixture model; 3D shape retrieval	RECOGNITION; DIVERGENCE; DISTANCE; MODELS; ALGORITHM	In this paper, we consider the family of total Bregman divergences (tBDs) as an efficient and robust "distance" measure to quantify the dissimilarity between shapes. We use the tBD-based l(1)-norm center as the representative of a set of shapes, and call it the t-center. First, we briefly present and analyze the properties of the tBDs and t-centers following our previous work in [1]. Then, we prove that for any tBD, there exists a distribution which belongs to the lifted exponential family (lEF) of statistical distributions. Further, we show that finding the maximum a posteriori (MAP) estimate of the parameters of the lifted exponential family distribution is equivalent to minimizing the tBD to find the t-centers. This leads to a new clustering technique, namely, the total Bregman soft clustering algorithm. We evaluate the tBD, t-center, and the soft clustering algorithm on shape retrieval applications. Our shape retrieval framework is composed of three steps: 1) extraction of the shape boundary points, 2) affine alignment of the shapes and use of a Gaussian mixture model (GMM) [2], [3], [4] to represent the aligned boundaries, and 3) comparison of the GMMs using tBD to find the best matches given a query shape. To further speed up the shape retrieval algorithm, we perform hierarchical clustering of the shapes using our total Bregman soft clustering algorithm. This enables us to compare the query with a small subset of shapes which are chosen to be the cluster t-centers. We evaluate our method on various public domain 2D and 3D databases, and demonstrate comparable or better results than state-of-the-art retrieval techniques.	[Liu, Meizhu; Vemuri, Baba C.] Univ Florida, Dept CISE, Gainesville, FL 32611 USA; [Amari, Shun-Ichi] RIKEN, Brain Sci Inst, Math Neurosci Lab, Wako, Saitama 3510198, Japan; [Nielsen, Frank] Ecole Polytech, F-91128 Palaiseau, France; [Nielsen, Frank] Sony Comp Sci Labs, Shinagawa Ku, Tokyo 1410022, Japan	State University System of Florida; University of Florida; RIKEN; Institut Polytechnique de Paris	Liu, MZ (corresponding author), Univ Florida, Dept CISE, E324,CSE Bldg,POB 11612, Gainesville, FL 32611 USA.	mliu@cise.ufl.edu; vemuri@cise.ufl.edu; amari@brain.riken.jp; nielsen@lix.polytechnique.fr	Amari, Shun-ichi/A-5901-2016	Nielsen, Frank/0000-0001-5728-0726	US National Institutes of Health [NS066340]; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R01EB007082] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE [R01NS066340] Funding Source: NIH RePORTER	US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS))	This work was partly supported by US National Institutes of Health grant NS066340 to Baba C. Vemuri.	Akgul CB, 2009, IEEE T PATTERN ANAL, V31, P1117, DOI 10.1109/TPAMI.2009.25; Amari SI, 2007, NEURAL COMPUT, V19, P2780, DOI 10.1162/neco.2007.19.10.2780; AMARI SI, 2001, METHODS INFORM GEOME; Bai X., 2010, P 11 EUR C COMP VIS, P861; Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Barndorff-Nielsen O., 1978, INFORM EXPONENTIAL F; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BIEDERMAN I, 1988, COGNITIVE PSYCHOL, V20, P38, DOI 10.1016/0010-0285(88)90024-2; Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377; Collins M., 2001, MACH LEARN, V48, P253; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Damski JC, 1996, COMPUT AIDED DESIGN, V28, P169, DOI 10.1016/0010-4485(95)00024-0; de Groen P. P. N., 1996, NIEUW ARCH WISK, V14, P237; Ding L., 2008, P 1 ACM INT C MULT I, P216; Felzenszwalb P.F., 2007, P 2007 IEEE C COMP V, P1, DOI [DOI 10.1109/CVPR.2007.383018, 10.1109/CVPR.2007.383018]; Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2; FERRUCCI V, 1991, COMPUT AIDED DESIGN, V23, P40, DOI 10.1016/0010-4485(91)90080-G; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P114, DOI 10.1109/34.67642; Frigyik BA, 2008, IEEE T INFORM THEORY, V54, P5130, DOI 10.1109/TIT.2008.929943; Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062; Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286; Ho J, 2007, IEEE WORKSH APPL COM, P25; Jian B, 2005, IEEE I CONF COMP VIS, P1246; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Joshi Shantanu H, 2007, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2007, P1; Kontschieder Peter, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P655; Lancaster JL, 1998, HUM BRAIN MAPP, V6, P358, DOI 10.1002/(SICI)1097-0193(1998)6:5/6<358::AID-HBM5>3.0.CO;2-L; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; LEYTON M, 1988, ARTIF INTELL, V34, P213, DOI 10.1016/0004-3702(88)90039-2; Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058; Ling HB, 2010, LECT NOTES COMPUT SC, V6313, P411; Ling HB, 2005, PROC CVPR IEEE, P719; Liu MZ, 2010, PROC CVPR IEEE, P3463, DOI 10.1109/CVPR.2010.5539979; Longbin Chen, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563078; Macrini D, 2008, P IEEE C COMP VIS PA, P1; Maji Subhransu, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587630; McNeill G., 2006, 2012 IEEE C COMP VIS, P885, DOI DOI 10.1109/CVPR.2006.133; MOKHTARIAN F, 1997, IMAGE DATABASES MULT, P51, DOI DOI 10.1142/9789812797988_; Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220; Munsell BC, 2012, INT J COMPUT VISION, V97, P210, DOI 10.1007/s11263-011-0477-4; Nielsen F., 2009, ARXIVORG09114863; Nielsen F, 2008, INFORM PROCESS LETT, V105, P93, DOI 10.1016/j.ipl.2007.08.007; Nielsen F, 2011, IEEE T INFORM THEORY, V57, P5455, DOI 10.1109/TIT.2011.2159046; Nielsen F, 2009, IEEE INT CON MULTI, P878, DOI 10.1109/ICME.2009.5202635; Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026; Peter A.M., 2008, IEEE C COMP VIS PATT, P1; PIETRA SD, 2001, CMUCS01109 SCH COMP; Pobil A.P.D., 1995, SPATIAL REPRESENTATI, P169; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504; Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772; Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8; Soderkvist O, 2001, COMPUTER VISION CLAS; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Temlyakov A, 2010, PROC CVPR IEEE, P2289, DOI 10.1109/CVPR.2010.5539912; Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195; Vemuri BC, 2011, IEEE T MED IMAGING, V30, P475, DOI 10.1109/TMI.2010.2086464; Vranic D., 2005, TOOS 3D MODEL RETRIE; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Weinland D., 2008, CVPR 2008, P1, DOI DOI 10.1109/CVPR.2008.4587731; Xu CJ, 2009, IEEE T PATTERN ANAL, V31, P180, DOI 10.1109/TPAMI.2008.199; Yang X., 2011, P IEEE C COMP VIS PA, P2873; Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844; Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685; Zhang J, 2004, NEURAL COMPUT, V16, P159, DOI 10.1162/08997660460734047	70	57	64	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2407	2419		10.1109/TPAMI.2012.44	http://dx.doi.org/10.1109/TPAMI.2012.44			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22331859	Green Accepted			2022-12-18	WOS:000309913700010
J	Hughes, C; Denny, P; Glavin, M; Jones, E				Hughes, Ciaran; Denny, Patrick; Glavin, Martin; Jones, Edward			Equidistant Fish-Eye Calibration and Rectification by Vanishing Point Extraction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fish-eye; calibration; perspective	CAMERA; LINES	In this paper, we describe a method to photogrammetrically estimate the intrinsic and extrinsic parameters of fish-eye cameras using the properties of equidistance perspective, particularly vanishing point estimation, with the aim of providing a rectified image for scene viewing applications. The estimated intrinsic parameters are the optical center and the fish-eye lensing parameter, and the extrinsic parameters are the rotations about the world axes relative to the checkerboard calibration diagram.	[Hughes, Ciaran; Denny, Patrick] Valeo Vis Syst, Vis Technol & Expertise Grp, Tuam, Galway, Ireland; [Glavin, Martin; Jones, Edward] Natl Univ Ireland, Coll Engn & Informat, Galway, Ireland	Valeo SA; Ollscoil na Gaillimhe-University of Galway	Hughes, C (corresponding author), Valeo Vis Syst, Vis Technol & Expertise Grp, Tuam, Galway, Ireland.	ciaran.hughes@valeo.com; patrick.denny@valeo.com; martin.glavin@nuigalway.ie; edward.jones@nuigalway.ie	Eising, Ciarán/GON-7585-2022; Glavin, Martin/GRX-8748-2022	Eising, Ciarán/0000-0001-8383-2635; Denny, Patrick/0000-0001-7494-8513; Glavin, Martin/0000-0003-1477-4835; Jones, Edward/0000-0003-1521-4442	Enterprise Ireland and Valeo Vision Systems (formerly Connaught Electronics Ltd.)	Enterprise Ireland and Valeo Vision Systems (formerly Connaught Electronics Ltd.)	This research was cofunded by Enterprise Ireland and Valeo Vision Systems (formerly Connaught Electronics Ltd.) under the Enterprise Ireland Innovation Partnerships Scheme.	Asari KV, 2004, J SYST ARCHITECT, V50, P743, DOI 10.1016/j.sysarc.2004.05.001; Avinash N, 2008, J MATH IMAGING VIS, V30, P221, DOI 10.1007/s10851-007-0052-3; Barreto JP, 2006, COMPUT VIS IMAGE UND, V101, P151, DOI 10.1016/j.cviu.2005.07.002; Barreto JP, 2005, IEEE I CONF COMP VIS, P625; Brauer-Burchardt C, 2001, IEEE IMAGE PROC, P225, DOI 10.1109/ICIP.2001.958994; CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; De Veylder L, 2001, PLANT CELL, V13, P1653, DOI 10.2307/3871392; Gallagher AC, 2005, P 2 CAN C COMP ROB V; Hartley R, 2007, IEEE T PATTERN ANAL, V29, P1309, DOI 10.1109/TPAMI.2007.1147; Hughes C, 2010, IMAGE VISION COMPUT, V28, P538, DOI 10.1016/j.imavis.2009.09.001; JAHNE BB, 2002, DIGITAL IMAGE PROCES, pCH12; MIYAMOTO K, 1964, J OPT SOC AM, V54, P1060, DOI 10.1364/JOSA.54.001060; Schaffalitzky F, 2000, IMAGE VISION COMPUT, V18, P647, DOI 10.1016/S0262-8856(99)00069-4; Shah S, 1996, PATTERN RECOGN, V29, P1775, DOI 10.1016/0031-3203(96)00038-6; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; STRAND R, 2005, P BRIT MACH VIS C SE; Wang GH, 2008, PATTERN RECOGN LETT, V29, P977, DOI 10.1016/j.patrec.2008.01.017; WANG LL, 1991, IEEE T PATTERN ANAL, V13, P370, DOI 10.1109/34.88572; Wang ZS, 2007, APPL MATH COMPUT, V185, P894, DOI 10.1016/j.amc.2006.05.210; Wu YH, 2008, INT J COMPUT VISION, V79, P209, DOI 10.1007/s11263-007-0114-4; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2	21	57	61	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2010	32	12					2289	2296		10.1109/TPAMI.2010.159	http://dx.doi.org/10.1109/TPAMI.2010.159			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	672BT	20733225				2022-12-18	WOS:000283558700013
J	Douxchamps, D; Chihara, K				Douxchamps, Damien; Chihara, Kunihiro			High-Accuracy and Robust Localization of Large Control Markers for Geometric Camera Calibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Camera calibration; imaging geometry; image measurement; high resolution; noise; ray tracing; subpixel		Accurate measurement of the position of features in an image is subject to a fundamental compromise: The features must be both small, to limit the effect of nonlinear distortions, and large, to limit the effect of noise and discretization. This constrains both the accuracy and the robustness of image measurements, which play an important role in geometric camera calibration as well as in all subsequent measurements based on that calibration. In this paper, we present a new geometric camera calibration technique that exploits the complete camera model during the localization of control markers, thereby abolishing the marker size compromise. Large markers allow a dense pattern to be used instead of a simple disc, resulting in a significant increase in accuracy and robustness. When highly planar markers are used, geometric camera calibration based on synthetic images leads to true errors of 0.002 pixels, even in the presence of artifacts such as noise, illumination gradients, compression, blurring, and limited dynamic range. The camera parameters are also accurately recovered, even for complex camera models.	[Douxchamps, Damien; Chihara, Kunihiro] Nara Inst Sci & Technol, Image Proc Lab, Ikoma, Nara 6300192, Japan	Nara Institute of Science & Technology	Douxchamps, D (corresponding author), Nara Inst Sci & Technol, Image Proc Lab, Takayama Cho, Ikoma, Nara 6300192, Japan.	d.douxchamps@ieee.org; chihara@is.naist.jp						DEMERTZI DK, 1995, J CHEM SOC DA, V1, P123; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Galassi M., 2006, GNU SCI LIB REFERENC, V2nd; Haralick R.M., 1993, COMPUTER ROBOT VISIO, V2; Hartley R., 2003, MULTIPLE VIEW GEOMET; Heikkila J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788; Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468; Heikkila J, 1998, INT C PATT RECOG, P734, DOI 10.1109/ICPR.1998.711250; Hirakawa K, 2005, IEEE T IMAGE PROCESS, V14, P360, DOI 10.1109/TIP.2004.838691; Jain R., 1995, MACHINE VISION; Klette R., 1998, COMPUTER VISION; LAVEST JM, 2000, P EUR C COMP VIS, V2, P654; LAVEST JM, 1998, P EUR C COMP VIS, V1, P158; LAVEST JM, 2000, P REC FORM INT ART F, V3, P81; McGlone C., 2004, MANUAL PHOTOGRAMMETR; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; Redert A, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P522, DOI 10.1109/TDPVT.2002.1024110; Reinfeld NV, 1958, MATH PROGRAMMING; Robert L, 1996, COMPUT VIS IMAGE UND, V63, P314, DOI 10.1006/cviu.1996.0021; Salvi J, 2002, PATTERN RECOGN, V35, P1617, DOI 10.1016/S0031-3203(01)00126-1; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P965, DOI 10.1109/34.159901; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zollner H, 2004, P 28 WORKSH AUSTR AS, P234	25	57	61	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					376	383		10.1109/TPAMI.2008.214	http://dx.doi.org/10.1109/TPAMI.2008.214			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110502				2022-12-18	WOS:000261846800015
J	Toh, KA; Eng, HL				Toh, Kar-Ann; Eng, How-Lung			Between classification-error approximation and weighted least-squares learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern classification; classification error rate; discriminant functions; polynomials and machine learning	ALGORITHM	This paper presents a deterministic solution to an approximated classification-error-based objective function. In the formulation, we propose a quadratic approximation as the function for achieving smooth error counting. The solution is subsequently found to be related to the weighted least-squares, whereby a robust tuning process can be incorporated. The tuning traverses between the least-squares estimate and the approximated total-error-rate estimate to cater to various situations of unbalanced attribute distributions. By adopting a linear parametric classifier model, the proposed classification-error-based learning formulation is empirically shown to be superior to that using the original least-squares-error cost function. Finally, it will be seen that the performance of the proposed formulation is comparable to other classification-error-based and state-of-the-art classifiers without sacrificing the computational simplicity.	[Toh, Kar-Ann] Yonsei Univ, Biometr Engn Res Ctr, Sch Elect & Elect Engn, Seoul 120749, South Korea; [Eng, How-Lung] Inst Infocomm Res, Singapore 119613, Singapore	Yonsei University; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)	Toh, KA (corresponding author), Yonsei Univ, Biometr Engn Res Ctr, Sch Elect & Elect Engn, 134 Shinchon Dong, Seoul 120749, South Korea.	katoh@yonsei.ac.kr; hleng@i2r.a-star.edu.sg						Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Draper N.R., 1998, APPL REGRESSION ANAL, V326; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771; Gordon G. J., 2002, ADV NEURAL INFORM PR, P577; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Jones E, 2001, IEEE T PATTERN ANAL, V23, P890, DOI 10.1109/34.946991; Kim NS, 2004, IEEE SIGNAL PROC LET, V11, P40, DOI 10.1109/LSP.2003.819345; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; McCullagh P., 1989, GEN LINEAR MODELS, V2nd; Newman D.J., UCI REPOSITORY MACHI; OSUNA EE, 1997, 1602 AI CBCL DEP BRA; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Rimer M, 2006, MACH LEARN, V63, P183, DOI 10.1007/s10994-006-6266-6; Scholkopf B., 2001, LEARNING KERNELS SUP; Schurmann J, 1996, PATTERN CLASSIFICATI; Toh KA, 2004, IEEE T PATTERN ANAL, V26, P740, DOI 10.1109/TPAMI.2004.3; Toh KA, 2006, C IND ELECT APPL, P815; Toh KA, 2006, MACH LEARN, V65, P273, DOI 10.1007/s10994-006-9455-4; Vapnik V.N, 1998, STAT LEARNING THEORY	26	57	57	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					658	669		10.1109/TPAMI.2007.70730	http://dx.doi.org/10.1109/TPAMI.2007.70730			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276971				2022-12-18	WOS:000253135600009
J	Bhowmick, P; Bhattacharya, BB				Bhowmick, Partha; Bhattacharya, Bhargab B.			Fast polygonal approximation of digital curves using relaxed straightness properties	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						digital geometry; digital straight line; polygonal approximation; shape analysis	PIECEWISE LINEAR-APPROXIMATION; ALGORITHM; SEGMENTATION; CURVATURE; POINTS; NUMBER	Several existing digital straight line segment (DSS) recognition algorithms can be used to determine the digital straightness of a given one-pixel-thick digital curve. Because of the inherent geometric constraints of digital straightness, these algorithms often produce a large number of segments to cover a given digital curve representing a real-life object/image. Thus, a curve segment, which is not exactly digitally straight but appears to be visually straight, is fragmented into multiple DSS when these algorithms are run. In this paper, a new concept of approximate straightness is introduced by relaxing certain conditions of DSS, and an algorithm is described to extract those segments from a digital curve. The number of such segments required to cover the curve is found to be significantly fewer than that of the exact DSS cover. As a result, the data set required for representing a curve also reduces to a large extent. The extracted set of segments can further be combined to determine a compact polygonal approximation of a digital curve based on certain approximation criteria and a specified error tolerance. The proposed algorithm involves only primitive integer operations and, thus, runs very fast compared to those based on exact DSS. The overall time complexity becomes linear in the number of points present in the representative set. Experimental results on several digital curves demonstrate the speed, elegance, and efficacy of the proposed method.	Bengal Engn & Sci Univ, Comp Sci & Technol Dept, Sibpur, Howrah, India; Indian Stat Inst, Adv Comp & Microelect Unit, Kolkata, India	Indian Institute of Engineering Science Technology Shibpur (IIEST); Indian Statistical Institute; Indian Statistical Institute Kolkata	Bhowmick, P (corresponding author), Bengal Engn & Sci Univ, Comp Sci & Technol Dept, Sibpur, Howrah, India.	partha@cs.becs.ac.in; bhargab@isical.ac.in	Bhattacharya, Bhargab/AAE-6130-2020					AKEN JV, 1985, ACM T GRAPHIC, V4, P147; ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; BEZDEK JC, 1985, IEEE T SYST MAN CYB, V15, P637, DOI 10.1109/TSMC.1985.6313440; Bhowmick P, 2005, LECT NOTES COMPUT SC, V3776, P407; BISWAS A, 2005, P 14 SCAND C IM AN, P930; BRESENHAM J, 1963, P ACM NATL C; Chen TC, 2001, REAL-TIME IMAGING, V7, P473, DOI 10.1006/rtim.2001.0233; Climer S, 2003, PATTERN RECOGN LETT, V24, P2291, DOI 10.1016/S0167-8655(03)00055-2; Cormen TH, 2000, INTRO ALGORITHMS; CREUTZBURG E, 1982, P 2 INT C ART INT IN, P42; DAVIS LS, 1976, IEEE T SYST MAN CYB, V6, P127, DOI 10.1109/TSMC.1976.5409183; DEBLEDRENNESSON I, 1995, INT J PATTERN RECOGN, V9, P635, DOI 10.1142/S0218001495000249; DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753; FISCHLER MA, 1994, IEEE T PATTERN ANAL, V16, P113, DOI 10.1109/34.273737; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; Freeman H., 1961, P NAT EL C; Gonzalez R.C, 2002, DIGITAL IMAGE PROCES; Guru DS, 2004, PATTERN RECOGN LETT, V25, P1, DOI 10.1016/j.patrec.2003.08.007; HELD A, 1994, IEEE T SYST MAN CYB, V24, P942, DOI 10.1109/21.293514; Hu JM, 1997, PATTERN RECOGN, V30, P701, DOI 10.1016/S0031-3203(96)00105-7; IMAI H, 1986, COMPUT VISION GRAPH, V36, P31, DOI 10.1016/S0734-189X(86)80027-5; Klette R, 2004, DISCRETE APPL MATH, V139, P197, DOI 10.1016/j.dam.2002.12.001; Klette R., 2004, DIGITAL GEOMETRY GEO; KOPLOWITZ J, 1990, IEEE T INFORM THEORY, V36, P192, DOI 10.1109/18.50392; Kovalevsky V. A., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P31, DOI 10.1109/ICPR.1990.119324; MIEGHEM JAV, 1995, J VIS COMMUN IMAGE R, V6, P59; MIGNOSI F, 1991, THEOR COMPUT SCI, V82, P71, DOI 10.1016/0304-3975(91)90172-X; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; Pavlidis T., 1977, STRUCTURAL PATTERN R; PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7; POVAZAN I, 1998, P SPRING C COMP GRAP, P205; Rocha J, 1998, IEEE T PATTERN ANAL, V20, P391, DOI 10.1109/34.677264; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; Rosenfeld A., 1982, DIGITAL PICTURE PROC; ROSENFELD A, 2001, ELECT NOTES THEORETI, V46; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253; SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W; Schroder K., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P811, DOI 10.1109/ICIP.1999.823009; Schuster GM, 1998, IEEE T IMAGE PROCESS, V7, P13, DOI 10.1109/83.650847; SMEULDERS AWM, 1991, CONT MATH, V119, P169; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; VENTURA JA, 1992, PATTERN RECOGN, V25, P1129, DOI 10.1016/0031-3203(92)90016-C; VOSS K, 1991, COMPUT ARTIF INTELL, V10, P75; WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7; WU LD, 1984, IEEE T PATTERN ANAL, V6, P41, DOI 10.1109/TPAMI.1984.4767473; WUESCHER DM, 1991, IEEE T PATTERN ANAL, V13, P41, DOI 10.1109/34.67629; Xie YG, 2001, IEEE IMAGE PROC, P181, DOI 10.1109/ICIP.2001.958983; Yin PY, 1998, PATTERN RECOGN LETT, V19, P1017, DOI 10.1016/S0167-8655(98)00082-8; Yin PY, 2004, J VIS COMMUN IMAGE R, V15, P241, DOI 10.1016/j.jvcir.2003.12.001; Yin PY, 2003, PATTERN RECOGN, V36, P1783, DOI 10.1016/S0031-3203(02)00321-7	53	57	59	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1590	1602		10.1109/TPAMI.2007.1082	http://dx.doi.org/10.1109/TPAMI.2007.1082			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627046				2022-12-18	WOS:000247965600008
J	Yang, S				Yang, S			Symbol recognition via statistical integration of pixel-level constraint histograms: A new descriptor	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						symbol recognition; graphics recognition; descriptor; feature extraction; feature representation	RETRIEVAL	A new descriptor for symbol recognition is proposed. 1) A histogram is constructed for every pixel to figure out the distribution of the constraints among the other pixels. 2) All the histograms are statistically integrated to form a feature vector with fixed dimension. The robustness and invariance were experimentally confirmed.	Fudan Univ, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China	Fudan University	Yang, S (corresponding author), Fudan Univ, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China.	suyang@fudan.edu.cn						Ah-Soon C, 2001, PATTERN RECOGN LETT, V22, P231, DOI 10.1016/S0167-8655(00)00091-X; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Chang MT, 2001, PATTERN RECOGN, V34, P953, DOI 10.1016/S0031-3203(00)00053-4; Chaudhuri BB, 2000, PATTERN ANAL APPL, V3, P120, DOI 10.1007/s100440070017; Chen KZ, 2003, PATTERN RECOGN, V36, P123, DOI 10.1016/S0031-3203(02)00067-5; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; HUANG XF, 1993, IEEE T PATTERN ANAL, V15, P838, DOI 10.1109/34.236243; Huet B, 1999, IEEE T PATTERN ANAL, V21, P1363, DOI 10.1109/34.817414; Llados J, 2001, IEEE T PATTERN ANAL, V23, P1137, DOI 10.1109/34.954603; LUO Y, 2003, P INT C DOC AN REC; OKAZAKI A, 1988, IEEE T PATTERN ANAL, V10, P331, DOI 10.1109/34.3898; Rossant F, 2002, PATTERN RECOGN LETT, V23, P1129, DOI 10.1016/S0167-8655(02)00036-3; Samet H, 1996, IEEE T PATTERN ANAL, V18, P783, DOI 10.1109/34.531799; Schurmann J, 1996, PATTERN CLASSIFICATI; Valveny E, 2004, LECT NOTES COMPUT SC, V3088, P368; Valveny E, 2003, PATTERN RECOGN LETT, V24, P2857, DOI 10.1016/S0167-8655(03)00144-2; Yuen PC, 1998, INT J PATTERN RECOGN, V12, P209, DOI 10.1142/S0218001498000142; 2003, EL P 5 IAPR INT WORK	18	57	64	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2005	27	2					278	281		10.1109/TPAMI.2005.38	http://dx.doi.org/10.1109/TPAMI.2005.38			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	879AR	15688565				2022-12-18	WOS:000225689300011
J	Szeliski, R; Scharstein, D				Szeliski, R; Scharstein, D			Sampling the disparity space image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo algorithms; matching cost; subpixel sampling; disparity space image; aliasing	ALGORITHMS	A central issue in stereo algorithm design is the choice of matching cost Many algorithms simply use squared or absolute intensity differences based on integer disparity steps. In this paper, we address potential problems with such approaches. We begin with a careful analysis of the properties of the continuous disparity space image (DSI) and propose several new matching cost variants based on symmetrically matching interpolated image signals. Using stereo images with ground truth, we empirically evaluate the performance of the different cost variants and show that proper sampling can yield improved matching performance.	Microsoft Corp, Res, Redmond, WA 98052 USA; Middlebury Coll, Middlebury, VT 05753 USA	Microsoft	Szeliski, R (corresponding author), Microsoft Corp, Res, 1 Microsoft Way, Redmond, WA 98052 USA.	szeliski@microsoft.com; schar@middlebury.edu						ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; KUTULAKOS K, 2000, P EUR C COMP VIS, V1, P67; Loop C., 1999, 1999 IEEE COMP SOC C, V1, DOI [10.1109/CVPR.1999.786928, DOI 10.1109/CVPR.1999.786928]; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; Schaaf P, 2002, PROG MATER SCI, V47, P1, DOI 10.1016/S0079-6425(00)00003-7; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; Shimizu M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P90, DOI 10.1109/ICCV.2001.937503; SZELISKI R, 1986, IEE PROC-E, V133, P341, DOI 10.1049/ip-e.1986.0041; Szeliski R, 2002, LECT NOTES COMPUT SC, V2351, P525; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9; Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555; Yang Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P274, DOI 10.1109/CVPR.1993.340969	20	57	60	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					419	425		10.1109/TPAMI.2004.1262341	http://dx.doi.org/10.1109/TPAMI.2004.1262341			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376889				2022-12-18	WOS:000188949400013
J	Li, Y; Shum, HY; Tang, CK; Szeliski, R				Li, Y; Shum, HY; Tang, CK; Szeliski, R			Stereo reconstruction from multiperspective panoramas	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiperspective panorama; epipolar geometry; stereo; correspondence; tensor voting; plane sweep stereo; multibaseline stereo	SPACE	A new approach to computing a panoramic (360 degrees) depth map is presented in this paper. Our approach uses a large collection of images taken by a camera whose motion has been constrained to planar concentric circles. We resample regular perspective images to produce a set of multiperspective panoramas and then compute depth maps directly from these resampled panoramas. Our panoramas sample uniformly in three dimensions: rotation angle, inverse radial distance, and vertical elevation. The use of multiperspective panoramas eliminates the limited overlap present in the original input images and, thus, problems as in conventional multibaseline stereo can be avoided. Our approach differs from stereo matching of single-perspective panoramic images taken from different locations, where the epipolar constraints are sine curves. For our multiperspective panoramas, the epipolar geometry, to the first order approximation, consists of horizontal lines. Therefore, any traditional stereo algorithm can be applied to multiperspective panoramas with little modification. In this paper, we describe two reconstruction algorithms. The first is a cylinder sweep algorithm that uses a small number of resampled multiperspective panoramas to obtain dense 3D reconstruction. The second algorithm, in contrast, uses a large number of multiperspective panoramas and takes advantage of the approximate horizontal epipolar geometry inherent in multiperspective panoramas. It comprises a novel and efficient 1 D multibaseline matching technique, followed by tensor voting to extract the depth surface. Experiments show that our algorithms are capable of producing comparable high quality depth maps which can be used for applications such as view interpolation.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; Beijing Sigma Ctr, Microsoft Res Asia, Beijing 100080, Peoples R China; Microsoft Res, Redmond, WA 98052 USA	Hong Kong University of Science & Technology; Microsoft; Microsoft Research Asia; Microsoft	Li, Y (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Hong Kong, Hong Kong, Peoples R China.	liyin@ust.hk; hshum@microsoft.com; cktang@cs.ust.hk; szeliski@microsoft.com						Baker S, 1998, PROC CVPR IEEE, P434, DOI 10.1109/CVPR.1998.698642; Benosman R, 2001, MG COMP SCI, P161; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792; JELINEK D, 2002, P 7 EUR C COMP VIS M, V2, P463; Kanade T, 1996, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1996.517074; Kang SB, 1997, INT J COMPUT VISION, V25, P167, DOI 10.1023/A:1007971901577; Kang SB, 2001, PROC CVPR IEEE, P103; KOCH R, 1998, P 5 EUR C COMP VIS, V1, P55; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kutulakos K. N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P307, DOI 10.1109/ICCV.1999.791235; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Li Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P119, DOI 10.1109/ICCV.2001.937507; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; Medioni G., 2000, COMPUTATIONAL FRAMEW; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; Pajdla T, 2002, INT J COMPUT VISION, V47, P161, DOI 10.1023/A:1014593824520; Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; Rademacher P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P199, DOI 10.1145/280814.280871; Schaaf P, 2002, PROG MATER SCI, V47, P1, DOI 10.1016/S0079-6425(00)00003-7; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; SEITZ S, 1999, INT J COMPUTER VISIO, V25; Seitz SM, 2002, INT J COMPUT VISION, V48, P21, DOI 10.1023/A:1014851111084; Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573; SHUM HY, 1999, P 7 INT C COMP VIS, P22; SHUM HY, 1999, P INT C COMP VIS, P14; Szeliski R, 2002, LECT NOTES COMPUT SC, V2351, P525; Wood D. N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P243, DOI 10.1145/258734.258859	34	57	65	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2004	26	1					45	62		10.1109/TPAMI.2004.1261078	http://dx.doi.org/10.1109/TPAMI.2004.1261078			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	752LF	15382685	Green Submitted			2022-12-18	WOS:000187161400004
J	Namboodiri, AM; Jain, AK				Namboodiri, AM; Jain, AK			Online handwritten script recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document understanding; handwritten script identification; online document; evidence accumulation; feature design		Automatic identification of handwritten script facilitates many important applications such as automatic transcription of multilingual documents and search for documents on the Web containing a particular script. The increase in usage of handheld devices which accept handwritten input has created a growing demand for algorithms that can efficiently analyze and retrieve handwritten data. This paper proposes a method to classify words and lines in an online handwritten document into one of the six major scripts: Arabic, Cyrillic, Devnagari, Han, Hebrew, or Roman. The classification is based on 11 different spatial and temporal features extracted from the strokes of the words. The proposed system attains an overall classification accuracy of 87.1 percent at the word level with 5-fold cross validation on a data set containing 13,379 words. The classification accuracy improves to 95 percent as the number of words in the test sample is increased to five, and to 95.5 percent for complete text lines consisting of an average of seven words.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Namboodiri, AM (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	anoop@cse.msu.edu; jain@cse.msu.edu						Coulmas Florian., 1999, BLACKWELL ENCY WRITI; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Figueiredo MAT, 2000, INT C PATT RECOG, P87, DOI 10.1109/ICPR.2000.906023; Hochberg J., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P378, DOI 10.1109/ICDAR.1995.599017; Hochberg J., 1999, International Journal on Document Analysis and Recognition, V2, P45, DOI 10.1007/s100320050036; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X; Jensen Hans, 1970, SIGN SYMBOL SCRIPT A; Lee J.J., 1996, INT WORKSHOP FRONTIE, P393; NAKANISHI A, 1999, WRITINGS SYSTEM WORL; PAL U, 1999, P 5 INT C DOC AN REC; PEAKE GS, 1998, P 3 AS C COMP VIS JA, P96; RATZLAFF E, 2000, P 7 INT WORKSH FRONT; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; SUEN CY, 1998, P INT C ADV PATT REC, P297; TAN CL, 1999, P INT S INT MULT DIS	16	57	57	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2004	26	1					124	130		10.1109/TPAMI.2004.1261096	http://dx.doi.org/10.1109/TPAMI.2004.1261096			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	752LF	15382692				2022-12-18	WOS:000187161400011
J	Ben-Shahar, O; Zucker, SW				Ben-Shahar, O; Zucker, SW			The perceptual organization of texture flow: A contextual inference approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture flow; perceptual organization; social conformity of a line; good continuation; texture segmentation; line discontinuities; point singularities; shading flow; local parallelism; orientation diffusion; tangential curvature; normal curvature; relaxation labeling	ANISOTROPIC DIFFUSION; VISUAL-CORTEX; COMPUTATION; GRADIENT; IMAGES; DISCRIMINATION; SEGMENTATION; CURVATURE; PATTERNS; FIELDS	Locally parallel dense patterns-sometimes called texture flows-define a perceptually coherent structure of particular significance to perceptual organization. We argue that with applications ranging from image segmentation and edge classification to shading analysis and shape interpretation, texture flows deserve attention equal to edge segment grouping and curve completion. This paper develops the notion of texture flow from a geometrical point of view to argue that local measurements of such structures must incorporate two curvatures. We show how basic theoretical considerations lead to a unique model for the local behavior of the flow and to a notion of texture flow "good continuation." This, in turn, translates to a specification of consistency constraints between nearby flow measurements which we use for the computation of globally (piecewise) coherent structure through the contextual framework of relaxation labeling. We demonstrate the results on synthetic and natural images.	Yale Univ, Dept Comp Sci, New Haven, CT 06520 USA; Yale Univ, Dept Elect Engn, New Haven, CT 06520 USA	Yale University; Yale University	Ben-Shahar, O (corresponding author), Yale Univ, Dept Comp Sci, POB 208285, New Haven, CT 06520 USA.	ben-shahar@cs.yale.edu; steven.zucker@yale.edu	Ben-Shahar, Ohad/F-8918-2015	Ben-Shahar, Ohad/0000-0001-5346-152X				[Anonymous], 1985, PERCEPTUAL ORG VISUA; Axler S., 1992, HARMONIC FUNCTION TH; BENSHAHAR O, UNPUB ORIENTATION DI; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180; BRETON P, 1996, P C COMP VIS PATT RE; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CHAN T, 1999, 9920 CAMTGR U CAL; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Forsyth A., 1912, LECT DIFFERENTIAL GE; GLASS L, 1969, NATURE, V223, P578, DOI 10.1038/223578a0; Granlund G.H., 1995, SIGNAL PROCESSING CO; Graustein WC, 1940, T AM MATH SOC, V47, P173, DOI 10.2307/1990055; HAMEL G, 1923, DMV, V32, P6; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HORNUNG CP, 1976, BACKGROUND PATTERNS; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; HUGGINS P, 2001, P 4 INT WORKSH VIS F; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; IVERSON LA, 1995, IEEE T PATTERN ANAL, V17, P982, DOI 10.1109/34.464562; Kanizsa Gaetano, 1979, ORG VISION ESSAYS GE; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; Keeble DRT, 1997, VISION RES, V37, P2993, DOI 10.1016/S0042-6989(96)00235-0; KIMIA BK, 1999, P IEEE CS WORKSH PER; KIMMEL R, 2000, 200002 CIS TECHN ISR; KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5; KOENDERINK JJ, 1976, J OPT SOC AM, V66, P717, DOI 10.1364/JOSA.66.000717; LANDY MS, 1991, VISION RES, V31, P679, DOI 10.1016/0042-6989(91)90009-T; LEE TS, 1995, VISION RES, V35, P2643, DOI 10.1016/0042-6989(95)00032-U; Marr D., 1982, VISION; Miller DA, 1999, NEURAL COMPUT, V11, P21, DOI 10.1162/089976699300016782; MOHAMMED JL, 1983, IEEE T PATTERN ANAL, V5, P330, DOI 10.1109/TPAMI.1983.4767394; Murray J., 1993, MATH BIOL, V2nd, DOI DOI 10.1007/978-3-662-08539-4; Nitsche Johannes C. C., 1989, LECT MINIMAL SURFACE, V1; NOTHDURFT HC, 1985, VISION RES, V25, P1957, DOI 10.1016/0042-6989(85)90020-3; NOTHDURFT HC, 1991, VISION RES, V31, P1073, DOI 10.1016/0042-6989(91)90211-M; ONeill B., 1966, ELEMENTARY DIFFERENT; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195; RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908; RAO AR, 1991, CVGIP-GRAPH MODEL IM, V53, P157, DOI 10.1016/1049-9652(91)90059-S; Regan D, 1996, VISION RES, V36, P3695, DOI 10.1016/0042-6989(96)00083-1; Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429; Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407; Sigman M, 2001, P NATL ACAD SCI USA, V98, P1935, DOI 10.1073/pnas.031571498; Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181; SOCHEN N, 2001, IN PRESS J MATH IMAG; Stevens K, 1983, P INT JOINT C ART IN, P1057; STEVENS KA, 1978, BIOL CYBERN, V29, P19, DOI 10.1007/BF00365232; Tang B, 2000, INT J COMPUT VISION, V36, P149, DOI 10.1023/A:1008152115986; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; TODD JT, 1990, J EXP PSYCHOL HUMAN, V16, P665; Verbeek PW, 1998, INT C PATT RECOG, P528, DOI 10.1109/ICPR.1998.711197; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; Watanabe T, 1996, PERCEPTION, V25, P293, DOI 10.1068/p250293; Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3; WERTHEIMER M, 1955, SOURCE BOOK GESTALT, P71; Wertheimer M., 1955, SOURCE BOOK GESTALT, P1; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; ZUCKER SW, 1983, HUMAN MACHINE VISION, P545	63	57	58	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					401	417		10.1109/TPAMI.2003.1190568	http://dx.doi.org/10.1109/TPAMI.2003.1190568			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV					2022-12-18	WOS:000181758100003
J	Hu, ZY; Wu, FC				Hu, ZY; Wu, FC			A note on the number of solutions of the noncoplanar P4P problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						the noncoplanar P4P problem; rigid transformation; upper bound	DETERMINING CAMERA PARAMETERS; PERSPECTIVE PROJECTION	In the literature, the PnP problem is indistinguishably defined as either to determine the distances of the control points from the camera's optical center or to determine the transformation matrices from the object-centered frame to the camera-centered frame. In this paper, we show that these two definitions are generally not equivalent. In particular, we prove that, if the four control points are not coplanar, the upper bound of the P4P problem under the distance-based definition is 5 and also attainable, whereas the upper bound of the P4P problem under the transformation-based definition is only 4. Finally, we study the conditions under which at least two, three, four, and five different positive solutions exist in the distance based noncoplanar P4P problem.	Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China; Anhui Univ, Artificial Intelligence Lab, Hefei 230039, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Anhui University	Hu, ZY (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, POB 2728, Beijing 100080, Peoples R China.	huzy@nlpr.ia.ac.cn; wfch@nlpr.ia.ac.cn						ABIDI MA, 1995, IEEE T PATTERN ANAL, V17, P534, DOI 10.1109/34.391388; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Georgis N, 1998, IEEE T PATTERN ANAL, V20, P366, DOI 10.1109/34.677262; Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759; HARALICK RM, 1989, PATTERN RECOGN, V22, P225, DOI 10.1016/0031-3203(89)90071-X; HARTELY RI, 2000, MULTIUPLE VIEW GEOME; HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2; Liu ML, 1999, PATTERN RECOGN LETT, V20, P69, DOI 10.1016/S0167-8655(98)00128-7; PENNA MA, 1991, PATTERN RECOGN, V24, P533, DOI 10.1016/0031-3203(91)90019-2; Quan L, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P778, DOI 10.1109/ICCV.1998.710806; Smith A., 1965, PHOTOGRAMM REC, V5, P113; Su Cheng, 1998, Chinese Journal of Computers, V21, P1084; THOMPSON EH, 1966, PHOTOGRAMM REC, V10, P201; WOLFE WJ, 1991, IEEE T PATTERN ANAL, V13, P66, DOI 10.1109/34.67632	15	57	78	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2002	24	4					550	555		10.1109/34.993561	http://dx.doi.org/10.1109/34.993561			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	534FM					2022-12-18	WOS:000174574100010
J	Yang, ZR; Zwolinski, M				Yang, ZR; Zwolinski, M			Mutual information theory for adaptive mixture models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						adaptive mixtures; entropy; mutual information; pattern recognition; statistical dependence; uncertainty	FINITE MIXTURE	Many pattern recognition systems need to estimate an underlying probability density function (pdf). Mixture models are commonly used for this purpose in which an underlying pdf is estimated by a finite mixing of distributions. The basic computational element of a density mixture model is a component with a nonlinear mapping function, which takes part in mixing. Selecting an optimal set of components for mixture models is important to ensure an efficient and accurate estimate of an underlying pdf. Previous work has commonly estimated an underlying pdf based on the information contained in patterns. In this paper, mutual information theory is employed to measure whether two components are statistically dependent. If a component has small mutual information, it is statistically independent of the other components. Hence, that component makes a significant contribution to the system pdf and should not be removed. However, if a particular component has large mutual information, it is unlikely to be statistically independent of the other components and may be removed without significant damage to the estimated pdf. Continuing to remove components with large and positive mutual information will give a density mixture model with an optimal structure, which is very close to the true pdf.	Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England; Univ Southampton, Dept Elect & Comp Sci, Southampton SO17 1BJ, Hants, England	University of Exeter; University of Southampton	Yang, ZR (corresponding author), Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England.	Z.R.Yang@exeter.ac.uk; mz@ecs.soton.ac.uk	Zwolinski, Mark/A-8745-2013	Zwolinski, Mark/0000-0002-2230-625X				BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; BICHSEL M, 1989, NEURAL NETWORKS, V2, P133, DOI 10.1016/0893-6080(89)90030-0; Bishop, 1995, NEURAL NETWORKS PATT; Bridle J. S., 1990, PROC 2 INT C NEURAL, P211, DOI [10.5555/2969830, DOI 10.5555/2969830]; Cao R, 1996, SCAND J STAT, V23, P405; Chen JH, 1996, CAN J STAT, V24, P167, DOI 10.2307/3315623; DacunhaCastelle D, 1997, BERNOULLI, V3, P279, DOI 10.2307/3318593; FRASER AM, 1986, PHYS REV A, V33, P1134, DOI 10.1103/PhysRevA.33.1134; FUKUDA K, 1989, TRENDS PHARM SCI S, V11, P4; HENNA J, 1985, ANN I STAT MATH, V37, P235, DOI 10.1007/BF02481094; HENNA J, 1988, J JPN STAT SOC, V18, P51; HJORT NL, 1995, ANN STAT, V23, P882, DOI 10.1214/aos/1176324627; LI WT, 1990, J STAT PHYS, V60, P823, DOI 10.1007/BF01025996; Linsker R, 1989, NEURAL COMPUT, V1, P402, DOI 10.1162/neco.1989.1.3.402; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PRIEBE CE, 1993, PATTERN RECOGN, V26, P771, DOI 10.1016/0031-3203(93)90130-O; PRIEBE CE, 1994, J AM STAT ASSOC, V89, P796; PRIEBE CE, 1991, PATTERN RECOGN, V24, P1197, DOI 10.1016/0031-3203(91)90145-U; Roeder K, 1997, J AM STAT ASSOC, V92, P894, DOI 10.2307/2965553; RUDZKIS R, 1995, ACTA APPL MATH, V38, P37, DOI 10.1007/BF00992613; SCHIOLER H, 1992, NEURAL NETWORKS, V5, P903, DOI 10.1016/S0893-6080(05)80086-3; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Specht D F, 1988, P IEEE INT C NEURAL, V1, P525, DOI DOI 10.1109/ICNN.1988.23820; SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Xu L, 1996, NEURAL COMPUT, V8, P129, DOI 10.1162/neco.1996.8.1.129; Yang ZR, 1998, NEURAL NETWORKS, V11, P739, DOI 10.1016/S0893-6080(98)00024-0; YOUNG TY, 1970, IEEE T INFORM THEORY, V16, P258, DOI 10.1109/TIT.1970.1054454	29	57	59	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2001	23	4					396	403						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	421MJ					2022-12-18	WOS:000168067900005
J	Soatto, S; Perona, P				Soatto, S; Perona, P			Reducing "structure from motion": A general framework for dynamic vision Part 1: Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						visual motion estimation; epipolar geometry; motion decoupling; compensation; fixation; parallax; output stabilization; model reduction	SEQUENCE; SHAPE	The literature on recursive estimation of structure and motion from monocular image sequences comprises a large number of apparently unrelated models and estimation techniques. We propose a framework that allows us to derive and compare all models by following the idea of dynamical system reduction. The "natural" dynamic model, derived from the rigidity constraint and the projection model, is first reduced by explicitly decoupling structure (depth) from motion. Then, implicit decoupling techniques are explored, which consist of imposing that some function of the unknown parameters is held constant. By appropriately choosing such a function, not only can we account for models seen so far in the literature, but we can also derive novel ones.	Washington Univ, Dept Elect Engn, St Louis, MO 63130 USA; CALTECH, Dept Elect Engn & Computat & Neural Syst, Pasadena, CA 91125 USA	Washington University (WUSTL); California Institute of Technology	Soatto, S (corresponding author), Washington Univ, Dept Elect Engn, Campus Box 1127,1 Brookings Dr, St Louis, MO 63130 USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ANANDAN P, 1994, P IM UND WORKSH; [Anonymous], 1991, EXTERIOR DIFFERENTIA; AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN J, 1995, REPRESENTATION SCENE; Boothby W., 1986, INTRO DIFFERENTIABLE; BROIDA TJ, 1991, IEEE T PATTERN ANAL, V13, P497, DOI 10.1109/34.87338; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; CUI N, 1990, IEEE T AEROSPACE ELE; Dickmanns E. D., 1988, MACHINE VISION APPL; Faugeras Olivier, 1993, 3 DIMENSIONAL VISION, P2; FERMULLER C, 1992, BIOL CYBERN, V67, P259, DOI 10.1007/BF00204399; GENNERY E, 1982, PROJ AAAI 2 NAT C AR; Guillemin V., 2010, DIFFERENTIAL TOPOLOG, V370; HEEGER D, 1992, INT J COMPUTER VISIO, V7; HEEL J, 1990, 1190 AI MIT AI LAB; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; Isidori A., 1989, NONLINEAR CONTROL SY; JACOBS D, 1997, P IEEE CVPR; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; JEPSON AD, 1992, SPATIAL VISION HUMAN; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LUONG Q, 1997, UNPUB; MATTHIES L, 1989, INT J COMPUTER VISIO; Maybank S., 1992, THEORY RECONSTRUCTIO; MCLAUGHLAN P, 1994, P 3 ECCV; Murray R. M., 1994, MATH INTRO ROBOTIC M; OLIENSIS J, 1996, P IEEE CVPR; OLIENSIS J, 1992, P DARPA IM UND WORKS; POELMAN C, 1994, LNCS, V810; RAVIV D, 1994, IEEE T SYSTEMS MAN C, V24; SAWHNEY HS, 1994, P INT C PATT REC; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; Soatto S, 1998, IEEE T PATTERN ANAL, V20, P943, DOI 10.1109/34.713361; SOATTO S, 1997, AUTOMATICA, V33; SOATTO S, 1996, IEEE T AUTOMATIC CON, V41; SOATTO S, 1997, INT J COMPUTER VISIO, V22; SPETSAKIS M, 1991, INT J COMPUTER VISIO, V6; SZELISKI R, 1994, J VISUAL COMMUNICATI; TAALEBINEZHAAD MA, 1992, IEEE T PATTERN ANAL, V14, P847, DOI 10.1109/34.149584; THOMAS I, 1994, 9426 IRCS U PENNS; TIAN T, 1996, P IEEE C COMP VIS PA; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; WENG JY, 1991, IEEE T SIGNAL PROCES, V39, P2691, DOI 10.1109/78.107418; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074	47	57	58	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1998	20	9					933	942		10.1109/34.713360	http://dx.doi.org/10.1109/34.713360			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	117AX		Green Accepted			2022-12-18	WOS:000075758500003
J	Wang, JTL; Shapiro, BA; Shasha, D; Zhang, KZ; Currey, KM				Wang, JTL; Shapiro, BA; Shasha, D; Zhang, KZ; Currey, KM			An algorithm for finding the largest approximately common substructures of two trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computational biology; dynamic programming; pattern matching; pattern recognition; trees	RNA SECONDARY STRUCTURES; DISTANCE	Ordered, labeled trees are trees in which each node has a label and the left-to-right order of its children (if it has any) is fixed. Such trees have many applications in vision, pattern recognition, molecular biology and natural language processing. We consider a substructure of an ordered labeled tree T to be a connected subgraph of T. Given two ordered labeled trees T-1 and T-2 and an integer d, the largest approximately common substructure problem is to find a substructure U-1 of T-2 and a substructure U-2 of T-2 such that U-1 is within edit distance d of U-2 and where there does not exist any other substructure V-1 of T-1 and V-2 of T-2 such that V-1 and V-2 satisfy the distance constraint and the sum of the sizes of V-1 and V-2 is greater than the sum of the sizes of U-1 and U-2 We present a dynamic programming algorithm to solve this problem, which runs as fast as the fastest known algorithm for computing the edit distance of two trees when the distance allowed in the common substructures is a constant independent of the input trees. To demonstrate the utility of our algorithm, we discuss its application to discovering motifs in multiple RNA secondary structures (which are ordered labeled trees).	New Jersey Inst Technol, Dept Comp & Informat Sci, Newark, NJ 07102 USA; NCI, Image Proc Sect, Lab Expt & Computat Biol, Div Basic Sci,NIH, Frederick, MD 21702 USA; NYU, Courant Inst Math Sci, New York, NY 10012 USA; Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; Univ Maryland, Med Ctr, Dept Pediat, Baltimore, MD 21201 USA	New Jersey Institute of Technology; National Institutes of Health (NIH) - USA; NIH National Cancer Institute (NCI); New York University; Western University (University of Western Ontario); University System of Maryland; University of Maryland Baltimore	Wang, JTL (corresponding author), New Jersey Inst Technol, Dept Comp & Informat Sci, Univ Hts, Newark, NJ 07102 USA.							BURKS C, 1991, NUCLEIC ACIDS RES, V19, P2221, DOI 10.1093/nar/19.suppl.2221; CHENG YC, 1985, IEEE T PATTERN ANAL, V7, P299, DOI 10.1109/TPAMI.1985.4767658; Currey KM, 1997, COMPUT APPL BIOSCI, V13, P1; JIANG T, 1994, LECT NOTES COMPUTER, V807, P75; Kaizhong Zhang, 1996, International Journal of Foundations of Computer Science, V7, P43, DOI 10.1142/S0129054196000051; LE SY, 1989, COMPUT APPL BIOSCI, V5, P205; LIU S, 1996, 9574 IEICE COMP; Liu SM, 1997, IEICE T FUND ELECTR, VE80A, P643; LIU SM, 1996, MEM GRAD SCH SCI T A, V14, P107; LU SY, 1984, IEEE T PATTERN ANAL, V6, P249, DOI 10.1109/TPAMI.1984.4767511; MOAYER B, 1986, IEEE T PATTERN ANAL, V8, P376, DOI 10.1109/TPAMI.1986.4767798; OHMORI K, 1988, WORKSH SYNT STRUCT P; SAMET H, 1982, IEEE T PATTERN ANAL, V4, P298, DOI 10.1109/TPAMI.1982.4767246; SHAPIRO BA, 1990, COMPUT APPL BIOSCI, V6, P309; SHAPIRO BA, 1988, COMPUT APPL BIOSCI, V4, P387; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; SHASHA D, 1994, IEEE T SYST MAN CYB, V24, P668, DOI 10.1109/21.286387; TAI KC, 1979, J ACM, V26, P422, DOI 10.1145/322139.322143; TANAKA E, 1994, IEEE T PATTERN ANAL, V16, P1233, DOI 10.1109/34.387483; Tanaka E., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P221, DOI 10.1142/S0218001488000157; TANAKA E, 1984, IECE T D, V67, P722; TANAKA E, 1982, IECE T D, V65, P511; TANAKA E, 1993, IEICE T D, V76, P635; TU ZG, 1995, J VIROL, V69, P4607, DOI 10.1128/JVI.69.8.4607-4618.1995; WANG JTL, 1996, P 2 INT C KNOWL DISC, P70; WONG AKC, 1990, IEEE T SYST MAN CYB, V20, P628, DOI 10.1109/21.57275; ZHANG KZ, 1989, SIAM J COMPUT, V18, P1245, DOI 10.1137/0218082; ZHANG KZ, 1994, J ALGORITHM, V16, P33, DOI 10.1006/jagm.1994.1003	28	57	61	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1998	20	8					889	895		10.1109/34.709622	http://dx.doi.org/10.1109/34.709622			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	110GT					2022-12-18	WOS:000075372700014
J	Ha, TM				Ha, TM			The optimum class-selective rejection rule	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						decision rule; pattern classification; Bayes rule; error-reject tradeoff; class-selective rejection; preselection; preclassification; human-machine interface	MACHINE	Class-selective rejection is an extension of simple rejection. That is, when an input pattern cannot be reliably assigned to one of the N classes in an N-class problem, it is assigned to a subset of classes that are most likely to issue the pattern, instead of simply being rejected. By selecting more classes, the risk of making an error can be reduced, at the price of subsequently having a larger remaining number of classes. The optimality of class-selective rejection is therefore defined as the best tradeoff between error rate and average number of selected classes. Formally, the tradeoff study is embedded in the framework of decision theory. The average expected loss is expressed as a linear combination of error rate and average number of classes. The minimization of the average expected loss, therefore, provides the best tradeoff. The complexity of the resulting optimum rule is reduced, via a discrete convex minimization, to be linear in the number of classes. Upper-bounds on error rate and average number of classes are derived. An example is provided to illustrate various aspects of the optimum decision rule. Finally, the implications of the new decision rule are discussed.			Ha, TM (corresponding author), UNIV BERN,INST COMP SCI & APPL MATH,NEUBRUECKSTR 10,CH-3012 BERN,SWITZERLAND.							BAIRD HS, 1995, WORLD SCI, P343; Berger J.O., 1985, STAT DECISION THEORY, P74; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; CHOW CK, 1994, P 3 ANN S DOC AN INF, P1; Chow CK., 1957, IRE T ELECT COMPUTER, VEC-6, P247, DOI DOI 10.1109/TEC.1957.5222035; CHOW W, 1995, PATTERN RECOGN, V28, P1941; DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G; Duda R.O., 1973, J ROYAL STAT SOC SER; FUKUNAGA K, 1990, INTRO STATISTICAL PA; Gibbons J.D., 1977, SELECTING ORDERING P; GUPTA SS, 1965, TECHNOMETRICS, V7, P225, DOI 10.2307/1266672; HA TM, 1995, OPT ENG, V34, P2277, DOI 10.1117/12.200605; HA TM, 1996, P 13 INT C PATT REC, V2, P75; Lau C., 1992, NEURAL NETWORKS THEO; MOHIUDDIN KM, 1994, PATTERN RECOGN, V4, P437; Rabiner L., 1993, FUNDAMENTALS SPEECH; RAIFFA H, 1961, APPLIED STATISTICAL; Ripley BD., 1996; Schurmann J, 1996, PATTERN CLASSIFICATI; WILKINSON RA, 1992, 4912 NISTIR US BUR C	22	57	61	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1997	19	6					608	615		10.1109/34.601248	http://dx.doi.org/10.1109/34.601248			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XG302					2022-12-18	WOS:A1997XG30200005
J	ABUHAIBA, ISI; MAHMOUD, SA; GREEN, RJ				ABUHAIBA, ISI; MAHMOUD, SA; GREEN, RJ			RECOGNITION OF HANDWRITTEN CURSIVE ARABIC CHARACTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ARABIC CURSIVE CHARACTERS; CHARACTER GRAPH MODEL; CLUSTERING; FUZZY NUMBERS; OFF-LINE CHARACTER RECOGNITION; SKELETONIZATION; TREE STRUCTURE	THINNING ALGORITHMS; LINE; PATTERNS	An automatic off-line character recognition system for handwritten cursive Arabic characters is presented. A robust noise-independent algorithm is developed that yields skeletons that reflect the structural relationships of the character components. The character skeleton is converted to a tree structure suitable for recognition. A set of fuzzy constrained character graph models (FCCGM's), which tolerate large variability in writing, is designed. These models are graphs, with fuzzily labeled arcs used as prototypes for the characters. A set of rules is applied in sequence to match a character tree to an FCCGM. Arabic handwritings of four writers were used in the learning and testing stages. The system proved to be powerful in tolerance to variable writing, speed, and recognition rate.	KING SAUD UNIV,DEPT COMP ENGN,RIYADH,SAUDI ARABIA; UNIV BRADFORD,DEPT ELECT ENGN,BRADFORD BD7 1DP,W YORKSHIRE,ENGLAND	King Saud University; University of Bradford			Mahmoud, Sabri Abdullah/G-9027-2011; Mahmoud, Sabri A/B-6001-2015	Mahmoud, Sabri Abdullah/0000-0002-5432-3206; Mahmoud, Sabri A/0000-0002-5432-3206				ABUHAIBA ISI, IN PRES ARABIAN J SC; ALEMAMI S, 1990, IEEE T PATTERN ANAL, V12, P704, DOI 10.1109/34.56214; ALMUALLIM H, 1987, IEEE T PATTERN ANAL, V9, P715, DOI 10.1109/TPAMI.1987.4767970; BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114; CHENG FH, 1989, IEEE T PATTERN ANAL, V11, P429, DOI 10.1109/34.19042; CUN YL, 1989, IEEE COMMUN MAG, V20, P41; DAVIES ER, 1981, PATTERN RECOGN, V14, P53, DOI 10.1016/0031-3203(81)90045-5; DEUTSCH ES, 1972, COMMUN ACM, V15, P827, DOI 10.1145/361573.361583; HUNG SHY, 1983, PATTERN RECOGN, V16, P297, DOI 10.1016/0031-3203(83)90035-3; KANDEL A, 1986, FUZZY MATH TECHNIQUE, P38; KICKERT WJM, 1976, IEEE T SYST MAN CYB, V6, P148, DOI 10.1109/TSMC.1976.5409187; LEUNG CH, 1987, IEEE T SYST MAN CYB, V17, P993, DOI 10.1109/TSMC.1987.6499310; MAHMOUD SA, 1991, PATTERN RECOGN, V24, P453, DOI 10.1016/0031-3203(91)90058-D; MONTNARI U, 1970, COMMUN ACM, V13, P41, DOI 10.1145/361953.361967; NACCACHE NJ, 1984, IEEE T SYST MAN CYB, V14, P409, DOI 10.1109/TSMC.1984.6313233; NOUH A, 1980, J ENG SCI, V6, P185; PARHAMI B, 1981, PATTERN RECOGN, V14, P395, DOI 10.1016/0031-3203(81)90084-4; Pavlidis T., 1982, ALGORITHMS GRAPHICS, P195; PELEG S, 1981, IEEE T PATTERN ANAL, V3, P208, DOI 10.1109/TPAMI.1981.4767082; RAJAVELU A, 1989, NEURAL NETWORKS, V2, P387, DOI 10.1016/0893-6080(89)90023-3; RAMSIS R, 1988, IBM KSC027 KUW SCI C; SHAPIRO B, 1981, COMPUT VISION GRAPH, V15, P136, DOI 10.1016/0146-664X(81)90075-7; SIY P, 1974, IEEE T SYST MAN CYB, VSMC4, P570; STEFANELLI R, 1971, J ACM, V18, P255, DOI 10.1145/321637.321646; TAMURA H, 4TH P INT JT C PATT, P715; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; UDUPA KJ, 1975, PATTERN RECOGN, V7, P225, DOI 10.1016/0031-3203(75)90007-2; WOLBERG G, 1986, MAY P IEEE COMP VIS, P168	28	57	57	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					664	672		10.1109/34.295912	http://dx.doi.org/10.1109/34.295912			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200013
J	LOWE, D; WEBB, AR				LOWE, D; WEBB, AR			OPTIMIZED FEATURE-EXTRACTION AND THE BAYES DECISION IN FEEDFORWARD CLASSIFIER NETWORKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ADAPTIVE LAYERED NETWORKS; BAYES MINIMUM RISK; DISCRIMINANT ANALYSIS; LEARNING; LEAST-SQUARES OPTIMIZATION; PATTERN CLASSIFICATION; PRIOR PROBABILITIES		In this paper we address the problem of multiclass pattern classification using adaptive layered networks. We consider a special class of networks, i.e., feed-forward networks with a linear final layer, that perform generalized linear discriminant analysis. This class is sufficiently generic to encompass the behavior of arbitrary feed-forward nonlinear networks since there is no restriction on the number of nonlinear hidden layers. Additionally, the use of a final layer of linear output nodes allows a formal analysis to be made to predict the optimum network performance. Training the network consists of a least-square approach which combines a generalized inverse computation to solve for the final layer weights, together with a nonlinear optimization scheme to solve for parameters of the nonlinearities. Such an approach performs feature extraction and classification simultaneously, in which the feature extraction is (optimally) matched to the classification scheme. We derive a general analytic form for the feature extraction criterion and interpret it for specific forms of target coding and error weighting. An important aspect of the approach is to exhibit how a priori information regarding nonuniform class membership, uneven distribution between train and test sets and misclassification costs may be exploited in a regularized manner in the training phase of networks.			LOWE, D (corresponding author), ROYAL SIGNALS & RADAR ESTAB,ST ANDREWS RD,MALVERN WR14 3PS,WORCS,ENGLAND.							Asohand H., 1990, P IJCNN 90 SAN DIEG, pIII; BOUNDS DG, 1988, P IEEE INT C NEURAL, V2, P481; BOURLARD H, 1988, NEURAL NETWORKS, V2, P53; BROOMHEAD DS, 1988, COMPLEX SYSTEMS, V2, P269; Devijver P. A., 1973, 1st International Joint Conference on Pattern Recognition, P139; Devijver PA, 1982, PATTERN RECOGNITION; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GALLINARI P, 1988, 1988 P ICNN C, P391; Golub G., 1965, SIAM J NUMER ANAL, V2, P205, DOI DOI 10.1137/0702016; GOLUB GH, 1980, SIAM J NUMER ANAL, V17, P883, DOI 10.1137/0717073; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; Hand D. J, 1981, WILEY SERIES PROBABI; Jain A.K., 1982, HDB STAT, P835, DOI 10.1016/S0169-7161(82)02042-2; Lowe D, 1990, NETWORK-COMP NEURAL, V1, P299, DOI 10.1088/0954-898X/1/3/002; MEISEL WS, 1968, NFORM SCI, V1, P23; MIRCHANDANI G, 1989, IEEE T CIRCUITS SYST, V36, P661, DOI 10.1109/31.31313; Nilsson N., 1965, LEARNING MACHINES; Olshen R., 1984, CLASSIFICATION REGRE; PEELING SM, 1986, PROC INS AC, V8, P307; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; Rumelhart D. E., 1988, PARALLEL DISTRIBUTED; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264667; WEBB AR, 1990, NEURAL NETWORKS, V3, P367, DOI 10.1016/0893-6080(90)90019-H; WEBB AR, 1988, RSRE4193 MEM; WEBB AR, 1988, RSRE4157 MEM; WEE WG, 1968, IEEE T COMPUT, VC 17, P1157, DOI 10.1109/TC.1968.226881; YAU SS, 1972, FRONTIERS PATTERN RE; Young T. Y., 1974, CLASSIFICATION ESTIM	29	57	59	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1991	13	4					355	364		10.1109/34.88570	http://dx.doi.org/10.1109/34.88570			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL566					2022-12-18	WOS:A1991FL56600005
J	SCHONFELD, D; GOUTSIAS, J				SCHONFELD, D; GOUTSIAS, J			OPTIMAL MORPHOLOGICAL PATTERN RESTORATION FROM NOISY BINARY IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE SMOOTHING; MINIMAX ESTIMATION; MORPHOLOGICAL IMAGE ANALYSIS; MORPHOLOGICAL MODELING; NONLINEAR FILTERING; SHAPE ANALYSIS	MATHEMATICAL MORPHOLOGY; REPRESENTATION; FILTERS	A theoretical analysis of morphological filters for the "optimal" restoration of noisy binary images is presented. The problem is formulated in a general form and an "optimal" solution is obtained by using fundamental tools from mathematical morphology and decision theory. We consider the set-difference distance function as a measure of comparison between images, and, by using this function, we introduce the mean difference function as a quantitative measure of the degree of geometrical and topological distortion introduced by morphological filtering. We prove that the class of alternating sequential filters is a set of parametric, smoothing morphological filters that "best" preserve the crucial structure of input images in the least mean difference sense. A theory is also presented that demonstrates some important properties of the class of alternating filters and the class of alternating sequential filters and provides a theoretical justification for their use in morphological image analysis applications. A minimax estimation procedure is also proposed that allows us to obtain the "optimal" alternating sequential filter. This filter "optimally" eliminates the rough characteristics of the degradation noise while it "optimally" preserves the crucial geometrical and topological features of the noise-free pattern under consideration.	JOHNS HOPKINS UNIV,DEPT ELECT & COMP ENGN,IMAGE ANAL & COMMUN LAB,BALTIMORE,MD 21218	Johns Hopkins University	SCHONFELD, D (corresponding author), UNIV ILLINOIS,DEPT ELECT ENGN & COMP SCI,CHICAGO,IL 61801, USA.		Goutsias, John/A-3274-2010					Blahut R. E., 1987, PRINCIPLES PRACTICE; DESTIVAL I, 1986, ACTA ASTRONAUT, V13, P371, DOI 10.1016/0094-5765(86)90092-5; FRIEDEN BR, 1983, PROBABILITY STATISTI; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; JUSTUSSON BJ, 1981, 2 DIMENSIONAL DIGITA, V2; Lehmann E., 1983, THEORY POINT ESTIMAT; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1170, DOI 10.1109/TASSP.1987.1165254; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1153, DOI 10.1109/TASSP.1987.1165259; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P586, DOI 10.1109/34.24793; MATHERON G., 1975, RANDOM SETS INTEGRAL; Oppenheim A.V., 1989, DISCRETE TIME SIGNAL; PRETEUX F, 1985, EUR J RADIOL, V5, P313; SAFA F, 1989, SIGNAL PROCESS, V16, P319, DOI 10.1016/0165-1684(89)90029-7; SCHONFELD D, 1989, P SOC PHOTO-OPT INS, V1199, P158, DOI 10.1117/12.970028; SERRA J, 1986, COMPUT VISION GRAPH, V35, P283, DOI 10.1016/0734-189X(86)90002-2; Serra J, 1982, IMAGE ANAL MATH MORP; SERRA J, 1989, LECTURE NOTES MORPHO; Serra J, 1988, IMAGE ANAL MATH MORP; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; Stoyan D., 1987, STOCHASTIC GEOMETRY; ZHOU Z, 1988, P INT C ACOUST SPEEC, V2, P948	22	57	59	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1991	13	1					14	29		10.1109/34.67627	http://dx.doi.org/10.1109/34.67627			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EX773					2022-12-18	WOS:A1991EX77300002
J	RODRIGUEZ, JJ; AGGARWAL, JK				RODRIGUEZ, JJ; AGGARWAL, JK			MATCHING AERIAL IMAGES TO 3-D TERRAIN MAPS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV TEXAS,COMP & VIS RES CTR,AUSTIN,TX 78712	University of Texas System; University of Texas Austin								ANDREAS RD, 1978, P IEEE NAT AEROSPACE, V3, P1263; BAIRD CA, 1984, P IEEE POSITION LOCA, P294; BENNETT PJ, 1988, P IEEE NAT AEROSPACE, V1, P209; CURTIS SR, 1985, IEEE T ACOUST SPEECH, V33, P643, DOI 10.1109/TASSP.1985.1164589; DAWSON JF, 1986, P IEEE NAT AEROSPACE, V1, P60; ELASSAL AA, 1985, 895B US GEOL SURV CI; ERNST MD, 1989, WORKING NOTES AAAI S, P15; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; FREEMAN H, 1978, PATTERN RECOGN, V10, P220; Goldgof D. B., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P899, DOI 10.1109/CVPR.1988.196339; GOTTSCHALK PG, 1987, IEEE T ROBOTIC AUTOM, P1582; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1981, IMAGES SURFACES; HERBELFIN RL, 1984, P IEEE NAT AEROSPACE, V2, P1301; HORN BKP, 1978, COMMUN ACM, V21, P914, DOI 10.1145/359642.359647; KAUFFMAN D, 1987, P INT GEOSC REM SENS, V1, P349; KNOLL TF, 1986, IEEE T ROBOTIC AUTOM, V2, P3, DOI 10.1109/JRA.1986.1087031; LOGAN BF, 1977, AT&T TECH J, V56, P487, DOI 10.1002/j.1538-7305.1977.tb00522.x; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MCKEE JW, 1977, IEEE T COMPUT, V26, P790, DOI 10.1109/TC.1977.1674917; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; PSENCIK RA, 1986, P IEEE NAT AEROSPACE, V2, P618; Rodriguez J. J., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P153, DOI 10.1109/CVPR.1988.196229; ROTEM D, 1986, IEEE T ACOUST SPEECH, V34, P1269, DOI 10.1109/TASSP.1986.1164922; SHAHRARAY B, 1985, IEEE T PATTERN ANAL, V7, P674, DOI 10.1109/TPAMI.1985.4767723; Shupe N. K., 1986, Proceedings of the IEEE/AIAA 7th Digital Avionics Systems Conference (Cat. No.86CH2359-8), P275; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; WARUSZEWSKI HL, 1984, P IEEE NAT AEROSPACE, V1, P70	29	57	69	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1138	1149		10.1109/34.62603	http://dx.doi.org/10.1109/34.62603			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500					2022-12-18	WOS:A1990EN50000002
J	AHUJA, N; VEENSTRA, J				AHUJA, N; VEENSTRA, J			GENERATING OCTREES FROM OBJECT SILHOUETTES IN ORTHOGRAPHIC VIEWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801; AT&T BELL LABS,COMMUN & INFORMAT SYST,NAPERVILLE,IL 60566	University of Illinois System; University of Illinois Urbana-Champaign; AT&T								AHUJA N, 1984, COMPUT VISION GRAPH, V26, P207, DOI 10.1016/0734-189X(84)90183-X; AHUJA N, 1986, UILUENG862215 U ILL; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CHIEN CH, 1986, COMPUT VISION GRAPH, V36, P100, DOI 10.1016/S0734-189X(86)80031-7; HONG TH, 1985, IEEE T PATTERN ANAL, V7, P721, DOI 10.1109/TPAMI.1985.4767730; HWANG YK, 1988, UILUENG882251 U ILL; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; MEAGHER D, 1982, JUN P IEEE COMP SOC, P473; Osse W. M., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P821; Shneier M., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P199; SRIVASTAVA S, 1987, NOV P IEEE WORKSH CO, P363; VEENSTRA J, IN PRESS ACM T GRAPH; WENG J, 1987, COMPUT VISION GR AUG, P167	14	57	60	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1989	11	2					137	149		10.1109/34.16710	http://dx.doi.org/10.1109/34.16710			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R9989					2022-12-18	WOS:A1989R998900003
J	CYGANSKI, D; ORR, JA				CYGANSKI, D; ORR, JA			APPLICATIONS OF TENSOR THEORY TO OBJECT RECOGNITION AND ORIENTATION DETERMINATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CYGANSKI, D (corresponding author), WORCESTER POLYTECH INST,DEPT ELECT ENGN,WORCESTER,MA 01609, USA.							ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; AGGARWAL JK, 1981, P IEEE, V69, P562, DOI 10.1109/PROC.1981.12025; CASASENT D, 1977, P IEEE, V65, P77, DOI 10.1109/PROC.1977.10432; Cyganski D., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P1141; CYGANSKI D, 1984, 7TH INT C PATT REC M; CYGANSKI D, 1984, P IEEE C ASSP SAN DI; CYGANSKI D, 1983, JUN P IEEE C COMP VI, P361; DIRILTEN H, 1977, IEEE T COMPUT, V26, P314, DOI 10.1109/TC.1977.1674832; DUDANI A, 1973, THESIS OHIO STATE U; Fu K.S., 1974, MATH SCI ENG; HARALICK RM, 1982, JUN P IEEE C PATT RE, P573; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; HUANG TS, 1981, IMAGE SEQUENCE ANAL; HUANG TS, 1981, MAR P IEEE INT C AC; LOVELOCK D, 1975, TENSORS DIFFERENTIAL; NAGEL HH, 1981, AUG P IEEE C PATT RE; ORR JA, 1985, MAR INT C AC SPEECH; QUAM L, 1974, AIM254 STANF U STANF; REDDI J, 1981, IEEE T PATTERN ANAL, V3, P240; Sadjadi F. A., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P327; SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990; SCHALKOFF RJ, 1982, IEEE T PATTERN ANAL, V4, P2, DOI 10.1109/TPAMI.1982.4767188; Synge J.L., 1978, TENSOR CALCULUS; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TSAI RY, 1983, JUN P IEEE C COMP VI, P259; TSAI RY, 1981, AUG P IEEE C PATT RE; TSAI RY, 1982, JUN P IEEE C PATT RE	27	57	57	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					662	673		10.1109/TPAMI.1985.4767722	http://dx.doi.org/10.1109/TPAMI.1985.4767722			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869304				2022-12-18	WOS:A1985ATG0500004
J	ZWICKE, PE; KISS, I				ZWICKE, PE; KISS, I			A NEW IMPLEMENTATION OF THE MELLIN TRANSFORM AND ITS APPLICATION TO RADAR CLASSIFICATION OF SHIPS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NORDEN SYST,NORWALK,CT 06856		ZWICKE, PE (corresponding author), UNITED TECHNOL RES CTR,E HARTFORD,CT 06108, USA.							ALTES RA, 1978, J ACOUST SOC AM, V63, P174, DOI 10.1121/1.381708; [Anonymous], 1979, PROGRAMS DIGITAL SIG; BAUDELAIRE P, 1974, P IEEE, V60, P467; CASASENT D, 1978, APPL OPTICS, V17, P655, DOI 10.1364/AO.17.000655; CASASENT D, 1978, APPL OPTICS, V17, P1559, DOI 10.1364/AO.17.001559; CASASENT D, 1977, APPL OPTICS, V16, P1472, DOI 10.1364/AO.16.001472; CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795; CASASENT D, 1977, P IEEE, V65, P77, DOI 10.1109/PROC.1977.10432; Ditkin V.A., 1965, INTEGRAL TRANSFORMS; DOLAN BA, 1965, THESIS STANFORD U; GAMBARDELLA G, 1979, J ACOUST SOC AM, V66, P913, DOI 10.1121/1.383203; Gerardi F., 1959, IRE T CIRCUIT THEORY, V6, P197, DOI [DOI 10.1109/TCT.1959.1086540, 10.1109/TCT.1959.1086540]; GRADSHTEYN I. S, 1994, TABLE INTEGRALS SERI, V5th; HAWKES PW, 1975, PATTERN RECOGN, V7, P59, DOI 10.1016/0031-3203(75)90014-X; Kopec G., 1981, Trends & Perspectives in Signal Processing, V1, P6; MCDONNELL M, 1978, OPT COMMUN, V25, P320, DOI 10.1016/0030-4018(78)90137-2; PESCHON J, 1959, THESIS STANFORD U; PSALTIS D, 1977, OPT COMMUN, V21, P307, DOI 10.1016/0030-4018(77)90289-9; RABINER LR, 1975, THEORY APPLICATION D; ROBBINS GM, 1972, PR INST ELECTR ELECT, V60, P862, DOI 10.1109/PROC.1972.8785; ZWICKE PE, 1981, R80192109 UN TECHN R; 1979, 1288R0014 NORD SYST	22	57	63	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					191	199		10.1109/TPAMI.1983.4767371	http://dx.doi.org/10.1109/TPAMI.1983.4767371			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974	21869100				2022-12-18	WOS:A1983QJ97400007
J	UDUPA, JK; SRIHARI, SN; HERMAN, GT				UDUPA, JK; SRIHARI, SN; HERMAN, GT			BOUNDARY DETECTION IN MULTIDIMENSIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SUNY BUFFALO,DEPT COMP SCI,BUFFALO,NY 14226	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo			Srihari, Sargur N/E-8100-2011					ALTSCHULER MD, 1979, P SPIE, V173, P287; ARTZY E, 1981, COMPUT VISION GRAPH, V15, P1, DOI 10.1016/0146-664X(81)90103-9; GRAY SB, 1971, IEEE T COMPUT, VC 20, P551, DOI 10.1109/T-C.1971.223289; Herman G, 1980, IMAGE RECONSTRUCTION; HERMAN GG, 1979, J COORD CHEM, V9, P1, DOI 10.1080/00958977908073094; HERMAN GT, 1978, COMPUT VISION GRAPH, V7, P130, DOI 10.1016/S0146-664X(78)80018-5; JAMES G, 1968, MATH DICT; LEWITT RM, 1980, MIPG45 STAT U NEW YO; LIU HK, 1977, COMPUT VISION GRAPH, V6, P123, DOI 10.1016/S0146-664X(77)80008-7; LOBREGT S, 1980, IEEE T PATTERN ANAL, V2, P75, DOI 10.1109/TPAMI.1980.4766974; MYLOPOULOS JP, 1971, J ACM, V18, P247, DOI 10.1145/321637.321645; MYLOPOULOS JP, 1971, J ACM, V18, P239, DOI 10.1145/321637.321644; ROSENFELD A, 1974, INFORM CONTROL, V26, P24, DOI 10.1016/S0019-9958(74)90696-2; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570	14	57	57	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					41	50		10.1109/TPAMI.1982.4767193	http://dx.doi.org/10.1109/TPAMI.1982.4767193			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21869001				2022-12-18	WOS:A1982MY53400007
J	DUDA, RO; NITZAN, D; BARRETT, P				DUDA, RO; NITZAN, D; BARRETT, P			USE OF RANGE AND REFLECTANCE DATA TO FIND PLANAR SURFACE REGIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											DUDA, RO (corresponding author), SRI INT,CTR ARTIFICIAL INTELLIGENCE,MENLO PK,CA 94025, USA.							AGIN GJ, 1977, SRI1187 STANF RES I; Barrow H., 1978, COMPUT VIS SYST, V2, P2; BINFORD TO, 1973, COMPUTER, V6, P19, DOI 10.1109/MC.1973.6536714; BURR DJ, 1977, 5TH P INT JOINT C AR, P583; CAULFIELD HJ, 1977, P IEEE, V65, P84, DOI 10.1109/PROC.1977.10433; Duda R. O., 1976, 3rd International Joint Conference on Pattern Recognition, P598; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FELDMAN JA, 1971, 2 INT JOINT C ART IN, P359; GANAPATHY S, 1975, AIM272 STANF U STANF; Garvey T. D., 1976, 3rd International Joint Conference on Pattern Recognition, P567; Gennery D. B., 1977, P 5 INT JOINT C ART, V2, P576; HANNAH MJ, 1974, AIM239 STANF U STANF; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; ISHII M, 1976, PATTERN RECOGN, V8, P229, DOI 10.1016/0031-3203(76)90043-1; ITO T, 1975, 4TH P INT JOINT C AR, P635; JULESZ B, 1962, 1962 P IFIP C, P439; Kiessling A., 1976, 3rd International Joint Conference on Pattern Recognition, P586; LEWIS RA, 1977, 5TH P INT JOINT C AR, P762; LILLESTRAND RL, 1972, IEEE T COMPUT, VC 21, P654, DOI 10.1109/T-C.1972.223570; MARTIN WN, 1978, COMPUT VISION GRAPH, V7, P356, DOI 10.1016/S0146-664X(78)80003-3; Mori K., 1973, COMPUT GRAPHICS IMAG, V2, P393; NEVATIA R, 1977, IEEE T SYST MAN CYB, V7, P820; NEVATIA R, 1976, COMPUT GRAPH IMAGE P, V5, P203; NEVATIA R, 1973, 3RD P INT JOINT C AR, P641; NITZAN D, 1977, P IEEE, V65, P206, DOI 10.1109/PROC.1977.10458; OHLANDER R, 1975, THESIS CARNEGIE MELL; PERKINS DN, 1970, THESIS MASSACHUSETTS; POPPLESTONE RJ, 1975, 4TH P INT JOINT C AR, P664; PRICE K, 1977, 5TH P INT JOINT C AR, P619; QUAM LH, 1971, AIM144 STANF U STANF; RABINOWITZ AD, 1971, TR40320 NEW YORK U D; ROCKER F, 1975, 4TH P INT JOINT C AR, P669; ROCKER F, 1974, 2ND P INT JOINT C PA, P527; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SHAPIRA R, 1974, COMP GRAPH IMAGE PRO, V3, P318; SHIRAI Y, 1971, 2ND P INT JOINT C AR, P80; SHIRAI Y, 1973, COMPUTER GRAPHICS IM, P298; SUGIHARA K, 1977, 5TH P INT JOINT C AR, P706; SUTRO LL, 1973, R635 MASS I TECHN C; TENENBAUM JM, 1973, COMPUTER GRAPHICS IM, V2, P308; TOMITA F, 1973, 3RD P INT JOINT C AR, P564; ULSTAD MS, 1973, PATTERN RECOGN, V5, P323, DOI 10.1016/0031-3203(73)90024-1; Underwood S.A., 1977, COMPUT VISION GRAPH, V6, P1; WILL PM, 1971, ARTIF INTELL, V2, P319, DOI 10.1016/0004-3702(71)90015-4; WINSTON P, 1975, PSYCHOLOGY COMPUTER; YACHIDA M, 1971, PATTERN RECOGN, V3, P307, DOI 10.1016/0031-3203(71)90020-3; Yagi, 1973, COMPUT VISION GRAPH, V2, P131; [No title captured]	50	57	58	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					259	271		10.1109/TPAMI.1979.4766922	http://dx.doi.org/10.1109/TPAMI.1979.4766922			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868857				2022-12-18	WOS:A1979HC30100004
J	Li, JJ; Chen, EP; Ding, ZM; Zhu, L; Lu, K; Shen, HT				Li, Jingjing; Chen, Erpeng; Ding, Zhengming; Zhu, Lei; Lu, Ke; Shen, Heng Tao			Maximum Density Divergence for Domain Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Measurement; Training; Kernel; Task analysis; Adaptation models; Benchmark testing; Games; Domain adaptation; transfer learning; adversarial learning		Unsupervised domain adaptation addresses the problem of transferring knowledge from a well-labeled source domain to an unlabeled target domain where the two domains have distinctive data distributions. Thus, the essence of domain adaptation is to mitigate the distribution divergence between the two domains. The state-of-the-art methods practice this very idea by either conducting adversarial training or minimizing a metric which defines the distribution gaps. In this paper, we propose a new domain adaptation method named adversarial tight match (ATM) which enjoys the benefits of both adversarial training and metric learning. Specifically, at first, we propose a novel distance loss, named maximum density divergence (MDD), to quantify the distribution divergence. MDD minimizes the inter-domain divergence ("match" in ATM) and maximizes the intra-class density ("tight" in ATM). Then, to address the equilibrium challenge issue in adversarial domain adaptation, we consider leveraging the proposed MDD into adversarial domain adaptation framework. At last, we tailor the proposed MDD as a practical learning loss and report our ATM. Both empirical evaluation and theoretical analysis are reported to verify the effectiveness of the proposed method. The experimental results on four benchmarks, both classical and large-scale, show that our method is able to achieve new state-of-the-art performance on most evaluations.	[Li, Jingjing; Chen, Erpeng; Lu, Ke; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China; [Ding, Zhengming] Indiana Univ Purdue Univ, Dept Comp Informat & Technol, Indianapolis, IN 46202 USA; [Zhu, Lei] Shandong Normal Univ, Jinan 250014, Peoples R China	University of Electronic Science & Technology of China; Indiana University System; Indiana University-Purdue University Indianapolis; Shandong Normal University	Li, JJ (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.	lijin117@yeah.net; cep1126@163.com; zd2@iu.edu; leizhu0608@gmail.com; kel@uestc.edu.cn; shenhengtao@hotmail.com	Shen, Heng Tao/ABD-5331-2021; Li, Jing/GYU-5036-2022	Zhu, Lei/0000-0002-2993-7142	National Key R&D Program of China [2018YFE0203900]; National Natural Science Foundation of China [61806039, 61832001]; Sichuan Department of Science and Technology [20ZDYF2771]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Sichuan Department of Science and Technology	This work was supported in part by the National Key R&D Program of China under Grant 2018YFE0203900, in part by the National Natural Science Foundation of China under Grant 61806039 and Grant 61832001, and in part by the Sichuan Department of Science and Technology under Grant 20ZDYF2771.	Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Ding ZM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5434; Ding ZM, 2018, IEEE T IMAGE PROCESS, V27, P5214, DOI 10.1109/TIP.2018.2851067; French Geoffrey, 2018, P INT C LEARN REPR, V6, P6; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Yaroslav, 2015, ICML; Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gretton A, 2012, J MACH LEARN RES, V13, P723; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoffman J, 2018, PR MACH LEARN RES, V80; Jing MM, 2021, IEEE T CYBERNETICS, V51, P3390, DOI 10.1109/TCYB.2020.2974106; Kouw WM, 2021, IEEE T PATTERN ANAL, V43, P766, DOI 10.1109/TPAMI.2019.2945942; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Levin D.A., 2017, MARKOV CHAINS MIXING, V107, DOI DOI 10.1090/MBK/107; Li JJ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P747, DOI 10.1145/3343031.3350902; Li JJ, 2019, IEEE T IMAGE PROCESS, V28, P6103, DOI 10.1109/TIP.2019.2924174; Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854; Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174; Li S, 2021, IEEE T PATTERN ANAL, V43, P2329, DOI 10.1109/TPAMI.2020.2964173; Liu Ming-Yu, 2016, ADV NEURAL INFORM PR, P2; Long MS, 2018, ADV NEUR IN, V31; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2017, PR MACH LEARN RES, V70; Mirza M., 2014, ARXIV; Netzer Y, 2011, NIPS WORKSH DEEP LEA, P2011, DOI DOI 10.2118/18761-MS; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Russo P, 2018, PROC CVPR IEEE, P8099, DOI 10.1109/CVPR.2018.00845; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887; Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6; Shu Rui, 2018, P 6 INT C LEARN REPR, P2; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; Szekely G. J., 2003, BOWLING GREEN STATE, V3, P1; Tzeng E., 2014, ARXIV PREPRINT ARXIV; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Xie SA, 2018, PR MACH LEARN RES, V80; Zhao H, 2019, PR MACH LEARN RES, V97; Zhuang FZ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4119	44	56	56	18	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3918	3930		10.1109/TPAMI.2020.2991050	http://dx.doi.org/10.1109/TPAMI.2020.2991050			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32356736	Green Submitted			2022-12-18	WOS:000702649700017
J	Liang, J; He, R; Sun, ZN; Tan, TN				Liang, Jian; He, Ran; Sun, Zhenan; Tan, Tieniu			Aggregating Randomized Clustering-Promoting Invariant Projections for Domain Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised domain adaptation; domain-invaraint projection; class-clustering; sampling-and-fusion	KERNEL	Unsupervised domain adaptation aims to leverage the labeled source data to learn with the unlabeled target data. Previous trandusctive methods tackle it by iteratively seeking a low-dimensional projection to extract the invariant features and obtaining the pseudo target labels via building a classifier on source data. However, they merely concentrate on minimizing the cross-domain distribution divergence, while ignoring the intra-domain structure especially for the target domain. Even after projection, possible risk factors like imbalanced data distribution may still hinder the performance of target label inference. In this paper, we propose a simple yet effective domain-invariant projection ensemble approach to tackle these two issues together. Specifically, we seek the optimal projection via a novel relaxed domain-irrelevant clustering-promoting term that jointly bridges the cross-domain semantic gap and increases the intra-class compactness in both domains. To further enhance the target label inference, we first develop a sampling-and-fusion' framework, under which multiple projections are independently learned based on various randomized coupled domain subsets. Subsequently, aggregating models such as majority voting are utilized to leverage multiple projections and classify unlabeled target data. Extensive experimental results on six visual benchmarks including object, face, and digit images. demonstrate that the proposed methods gain remarkable margins over state-of-the-art unsupervised domain adaptation methods.	[Liang, Jian] Chinese Acad Sci, Ctr Res Intelligent Percept & Comp, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Liang, Jian] Univ Chinese Acad Sci, Beijing 100190, Peoples R China; [He, Ran; Sun, Zhenan; Tan, Tieniu] Chinese Acad Sci, Ctr Res Intelligent Percept & Comp, CAS Ctr Excellence Brain Sci & Intelligence Techn, Inst Automat,Natl Lab Pattern Recognit, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Automation, CAS	Sun, ZN; Tan, TN (corresponding author), Chinese Acad Sci, Ctr Res Intelligent Percept & Comp, CAS Ctr Excellence Brain Sci & Intelligence Techn, Inst Automat,Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	jian.liang@nlpr.ia.ac.cn; rhe@nlpr.ia.ac.cn; znsun@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn		liang, jian/0000-0003-3890-1894	State Key Development Program [2016YFB1001001]; National Natural Science Foundation of China [61622310, 61473289]	State Key Development Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors would like to greatly thank the associate editor and the reviewers for their valuable comments and advices, and Dr. Dangwei Li and Ying Mao for helpful discussions. This work was funded by State Key Development Program (Grant No. 2016YFB1001001), and National Natural Science Foundation of China (Grant Nos. 61622310, 61473289).	Baktashmotlagh M, 2016, J MACH LEARN RES, V17; Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Bousmalis Konstantinos, 2016, ADV NEURAL INFORM PR, P343; Busto PP, 2017, IEEE I CONF COMP VIS, P754, DOI 10.1109/ICCV.2017.88; Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542; Chen WY, 2016, LECT NOTES COMPUT SC, V9909, P399, DOI 10.1007/978-3-319-46454-1_25; Chidlovskii B, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P451, DOI 10.1145/2939672.2939716; Chu WS, 2013, PROC CVPR IEEE, P3515, DOI 10.1109/CVPR.2013.451; Courty  N., 2017, P ADV NEUR INF PROC, P3733; Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921; Daume H, 2007, P 45 ANN M ASS COMP, V45, P256; Ding ZM, 2017, IEEE T IMAGE PROCESS, V26, P660, DOI 10.1109/TIP.2016.2631887; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Dudik Miroslav, 2005, ADV NEURAL INF PROCE, V18, P323; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532; Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gopalan R, 2014, IEEE T PATTERN ANAL, V36, P2288, DOI 10.1109/TPAMI.2013.249; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gretton A, 2012, J MACH LEARN RES, V13, P723; Gretton A, 2009, NEURAL INF PROCESS S, P131; Griffin G., 2007, 120 CAL I TECHN; Hastie T., 2009, ELEMENTS STAT LEARNI, DOI [10.1007/978-0-387-84858-7, DOI 10.1007/978-0-387-84858-7]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Herath S., 2017, P IEEE C COMP VIS PA, P3845; Hoffman J, 2014, INT J COMPUT VISION, V109, P28, DOI 10.1007/s11263-014-0719-3; Hoffman Judy, 2013, ARXIV13013224; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Koniusz P., 2017, IEEE C COMP VIS PATT, P4478; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li W, 2018, IEEE T PATTERN ANAL, V40, P1114, DOI 10.1109/TPAMI.2017.2704624; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Liu M. -Y., 2016, ADV NEURAL INFORM PR, P469; Long M., 2015, P 32 INT C MACH LEAR, V1, P97; Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136; Long MS, 2017, PR MACH LEARN RES, V70; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1805, DOI 10.1109/TKDE.2013.97; Lopez-Arredondo DL, 2017, PLANT MACRONUTRIENT USE EFFICIENCY: MOLECULAR AND GENOMIC PERSPECTIVES IN CROP PLANTS, P1, DOI 10.1016/B978-0-12-811308-0.00001-6; Luo L, 2019, ACCOUNT FINANC, V59, P1235, DOI 10.1111/acfi.12267; Nene S. A., 1996, COLUMBIA OBJECT IMAG; Niu L, 2016, INT J COMPUT VISION, V118, P130, DOI 10.1007/s11263-015-0862-5; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Scholkopf B., 2001, LEARNING KERNELS SUP; Sener Ozan, 2016, ADV NEURAL INFORM PR, P2; Sha, 2013, P INT C MACH LEARN; Shi Y., 2012, P 29 INT C INT C MAC, P1275; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; Tsai YHH, 2016, PROC CVPR IEEE, P5081, DOI 10.1109/CVPR.2016.549; Tzeng E., 2014, ARXIV PREPRINT ARXIV; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107; Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547; Zhou DY, 2004, ADV NEUR IN, V16, P321	67	56	57	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1027	1042		10.1109/TPAMI.2018.2832198	http://dx.doi.org/10.1109/TPAMI.2018.2832198			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993436				2022-12-18	WOS:000463607400001
J	Shi, BX; Mo, ZP; Wu, Z; Duan, DL; Yeung, SK; Tan, P				Shi, Boxin; Mo, Zhipeng; Wu, Zhe; Duan, Dinglong; Yeung, Sai-Kit; Tan, Ping			A Benchmark Dataset and Evaluation for Non-Lambertian and Uncalibrated Photometric Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; benchmark; dataset; non-Lambertian; uncalibrated	SHAPE; REFLECTANCE; SURFACES; RECONSTRUCTION; NORMALS	Classic photometric stereo is often extended to deal with real-world materials and work with unknown lighting conditions for practicability. To quantitatively evaluate non-Lambertian and uncalibrated photometric stereo, a photometric stereo image dataset containing objects of various shapes with complex reflectance properties and high-quality ground truth normals is still missing. In this paper, we introduce the 'DiLiGenT' dataset with calibrated Directional Lightings, objects of General reflectance with different shininess, and 'ground Truth' normals from high-precision laser scanning. We use our dataset to quantitatively evaluate state-of-the-art photometric stereo methods for general materials and unknown lighting conditions, selected from a newly proposed photometric stereo taxonomy emphasizing non-Lambertian and uncalibrated methods. The dataset and evaluation results are made publicly available, and we hope it can serve as a benchmark platform that inspires future research.	[Shi, Boxin] Peking Univ PKU, Inst Digital Media, Sch Elect Engn & Comp Sci, Beijing 100080, Peoples R China; [Mo, Zhipeng; Yeung, Sai-Kit] Singapore Univ Technol & Design SUTD, Singapore 487372, Singapore; [Tan, Ping] Simon Fraser Univ SFU, Burnaby, BC V5A 1S6, Canada; [Wu, Zhe; Duan, Dinglong] Natl Univ Singapore NUS, P Tans Grp, Singapore 119077, Singapore	Singapore University of Technology & Design; Simon Fraser University	Shi, BX (corresponding author), Peking Univ PKU, Inst Digital Media, Sch Elect Engn & Comp Sci, Beijing 100080, Peoples R China.	shiboxin@pku.edu.cn; zhipeng_mo@mymail.sutd.edu.sg; wuzhe06@gmail.com; dinglong.duan@gmail.com; saikit@sutd.edu.sg; pingtan@sfu.ca			Recruitment Program of Global Experts (Youth Program) in China (a.k.a. 1000 Youth Talents); NEDO project; Singapore MOE Academic Research Fund [MOE2016-T2-2-154]; Heritage Research Grant of the National Heritage Board, Singapore; SUTD Digital Manufacturing and Design (DManD) Centre; Singapore National Research Foundation (NRF); NRF under its IDM Futures Funding Initiative; NSERC [31-611663, 31-611664]; Virtual Singapore Award [NRF2015VSGAA3DCM001-014]	Recruitment Program of Global Experts (Youth Program) in China (a.k.a. 1000 Youth Talents); NEDO project(New Energy and Industrial Technology Development Organization (NEDO)); Singapore MOE Academic Research Fund(Ministry of Education, Singapore); Heritage Research Grant of the National Heritage Board, Singapore; SUTD Digital Manufacturing and Design (DManD) Centre(Singapore University of Technology & Design); Singapore National Research Foundation (NRF)(National Research Foundation, Singapore); NRF under its IDM Futures Funding Initiative; NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); Virtual Singapore Award	The authors thank Dan B. Goldman for providing the code of [2], Tomoaki Higo for evaluating [13] using our data, and Binh-Son Hua for setting up the rendering environment in Section 4.4. Boxin Shi is supported by the Recruitment Program of Global Experts (Youth Program) in China (a.k.a. 1000 Youth Talents), and part of this work was finished with the Artificial Intelligence Research Center, National Institute of AIST, Japan, supported by the NEDO project. Sai-Kit Yeung is supported by Singapore MOE Academic Research Fund MOE2016-T2-2-154, Heritage Research Grant of the National Heritage Board, Singapore, SUTD Digital Manufacturing and Design (DManD) Centrewhich is supported by the Singapore National Research Foundation (NRF) and NRF under its IDM Futures Funding Initiative and Virtual Singapore Award No. NRF2015VSGAA3DCM001-014. Ping Tan is supported by the NSERC Discovery Grant 31-611664 and the NSERC Discovery Accelerator Supplement 31-611663.	Aanaes H, 2016, INT J COMPUT VISION, V120, P153, DOI 10.1007/s11263-016-0902-9; Aanaes H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8; Abrams A, 2012, LECT NOTES COMPUT SC, V7573, P357, DOI 10.1007/978-3-642-33709-3_26; Ackermann Jens, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P259, DOI 10.1109/3DV.2014.63; Ackermann J., 2010, PROC EUR C TRENDS TO, P197; Ackermann J, 2013, FOUND TRENDS COMPUT, V9, P149, DOI 10.1561/0600000065; Ackermann J, 2012, PROC CVPR IEEE, P262, DOI 10.1109/CVPR.2012.6247684; Alldrin N, 2008, PROC CVPR IEEE, P2447; Alldrin NG, 2007, IEEE I CONF COMP VIS, P417; Alldrin NG, 2007, PROC CVPR IEEE, P1822; Anderson R, 2011, IEEE I CONF COMP VIS, P2182, DOI 10.1109/ICCV.2011.6126495; Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898; Basri R., 2008, IEEE COMP SOC C COMP, P1; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Boxin Shi, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P361, DOI 10.1109/3DV.2014.9; Chandraker M., 2007, P IEEE C COMPUTER VI, P1; Chandraker M, 2014, PROC CVPR IEEE, P2179, DOI 10.1109/CVPR.2014.279; Chandraker M, 2013, PROC CVPR IEEE, P2523, DOI 10.1109/CVPR.2013.326; Chandraker M, 2013, IEEE T PATTERN ANAL, V35, P2941, DOI 10.1109/TPAMI.2012.217; Chandraker MK, 2005, PROC CVPR IEEE, P788; Chatterjee A, 2015, PROC CVPR IEEE, P933, DOI 10.1109/CVPR.2015.7298695; Chen CP, 2006, LECT NOTES COMPUT SC, V3953, P72, DOI 10.1007/11744078_6; Chen L, 2017, IEEE I CONF COMP VIS, P3181, DOI 10.1109/ICCV.2017.343; Chen T, 2006, P IEEE C COMP VIS PA, P1825, DOI [10.1109/CVPR.2006.182, DOI 10.1109/CVPR.2006.182]; Chung HS, 2008, PROC CVPR IEEE, P3337; Clark J. J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P29, DOI 10.1109/CVPR.1992.223231; Clark JJ, 2010, IMAGE VISION COMPUT, V28, P704, DOI 10.1016/j.imavis.2008.10.011; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; Corsini M, 2009, COMPUT GRAPH FORUM, V28, P1755, DOI 10.1111/j.1467-8659.2009.01552.x; David Li Yifan, 2013, IEEE Int Conf Rehabil Robot, V2013, P6650373, DOI 10.1109/ICORR.2013.6650373; Del Bue A, 2010, LECT NOTES COMPUT SC, V6314, P283; Dong B, 2014, PROC CVPR IEEE, P2299, DOI 10.1109/CVPR.2014.294; Drbohlav O, 2005, IEEE I CONF COMP VIS, P1850; Drbohlav O, 2002, LECT NOTES COMPUT SC, V2351, P46; Du H, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.84; Fyffe G., 2011, P IEEE INT C COMP PH, P16, DOI [10.1109/ICCPHOT.2011.5753116, DOI 10.1109/ICCPH0T.2011.5753116]; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; Ghosh A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024163; Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P1060, DOI 10.1109/TPAMI.2009.102; Haque SM, 2014, PROC CVPR IEEE, P2283, DOI 10.1109/CVPR.2014.292; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Herbort S, 2011, 3D RES, V2, DOI 10.1007/3DRes.03(2011)4; Hernandez C, 2007, IEEE I CONF COMP VIS, P873; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Higo T, 2010, PROC CVPR IEEE, P1157, DOI 10.1109/CVPR.2010.5540084; Higo T, 2009, IEEE I CONF COMP VIS, P1234, DOI 10.1109/ICCV.2009.5459331; Hold-Geoffroy Y., 2015, P IEEE INT C COMP PH, P1, DOI DOI 10.1109/ICCPHOT.2015.7168379; Hold-Geoffroy Y, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P28, DOI 10.1109/3DV.2015.11; Holroyd M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409086; Hui Z., 2015, P IEEE INT C COMP PH, P1; Hung CH, 2015, IEEE WINT CONF APPL, P302, DOI 10.1109/WACV.2015.47; Ikehata S, 2014, PROC CVPR IEEE, P2187, DOI 10.1109/CVPR.2014.280; Ikehata S, 2012, PROC CVPR IEEE, P318, DOI 10.1109/CVPR.2012.6247691; IKEUCHI K, 1987, INT J ROBOT RES, V6, P15, DOI 10.1177/027836498700600102; Inoshita C, 2014, LECT NOTES COMPUT SC, V8690, P346, DOI 10.1007/978-3-319-10605-2_23; Iwahori Y., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P83, DOI 10.1109/ICPR.1990.118069; Jensen R, 2014, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2014.59; Jia DG, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.4.043105; Johnson M. K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2553, DOI 10.1109/CVPR.2011.5995510; Joshi N, 2007, IEEE I CONF COMP VIS, P1501; Jung J, 2015, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2015.7299082; Kim H, 2010, LECT NOTES COMPUT SC, V6311, P59; Kriegman DJ, 2001, J OPT SOC AM A, V18, P1804, DOI 10.1364/JOSAA.18.001804; Lim J, 2005, IEEE I CONF COMP VIS, P1635; Lu F, 2015, PROC CVPR IEEE, P168, DOI 10.1109/CVPR.2015.7298612; Lu F, 2013, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2013.196; [鲁正 Lu Zheng], 2013, [振动与冲击, Journal of Vibration and Shock], V32, P1; Ma W.-C., 2007, PROC 18 EUR C RENDER, P183, DOI 10.2312/EGWR/EGSR07/183-194; Malzbender T, 2006, EUROGRAPHICS S RENDE, P245; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; Mecca R, 2016, SIAM J IMAGING SCI, V9, P1858, DOI 10.1137/16M1068177; Mecca R, 2014, SIAM J IMAGING SCI, V7, P579, DOI 10.1137/120902458; Miyazaki D, 2010, IEEE IMAGE PROC, P4057, DOI 10.1109/ICIP.2010.5650067; Miyazaki D, 2010, INT J COMPUT VISION, V86, P229, DOI 10.1007/s11263-009-0262-9; Mukaigawa Y, 2007, J OPT SOC AM A, V24, P3326, DOI 10.1364/JOSAA.24.003326; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; Nowrouzezahrai D, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964924; Okabe T, 2009, IEEE I CONF COMP VIS, P1693, DOI 10.1109/ICCV.2009.5459381; Okatani T, 2012, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2012.6247683; Oxholm G, 2014, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2014.277; Papadhimitri T., 2014, PROC BRIT MACH VIS C, P1; Papadhimitri T, 2014, INT J COMPUT VISION, V107, P139, DOI 10.1007/s11263-013-0665-5; Papadhimitri T, 2013, PROC CVPR IEEE, P1474, DOI 10.1109/CVPR.2013.194; Park J, 2013, IEEE I CONF COMP VIS, P1161, DOI 10.1109/ICCV.2013.148; Ping Tan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2977, DOI 10.1109/CVPRW.2009.5206731; Richter SR, 2015, PROC CVPR IEEE, P1128, DOI 10.1109/CVPR.2015.7298716; Romeiro F, 2008, LECT NOTES COMPUT SC, V5305, P859, DOI 10.1007/978-3-540-88693-8_63; Sabzevari R, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P547, DOI 10.1109/3DIMPVT.2012.74; Sato I, 2007, IEEE I CONF COMP VIS, P1493; Sato I, 2012, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.2012.6247685; SATO Y, 1994, J OPT SOC AM A, V11, P2990, DOI 10.1364/JOSAA.11.002990; Schindler G., 2008, P IEEE C COMP VIS PA, P1; Seitz S., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI [10.1109/CVPR.2006.19, DOI 10.1109/CVPR.2006.19]; Shen L, 2009, PROC CVPR IEEE, P1850, DOI 10.1109/CVPRW.2009.5206732; Shi BX, 2016, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2016.403; Shi BX, 2012, LECT NOTES COMPUT SC, V7574, P455, DOI 10.1007/978-3-642-33712-3_33; Shi BX, 2014, IEEE T PATTERN ANAL, V36, P1078, DOI 10.1109/TPAMI.2013.196; Shi BX, 2010, PROC CVPR IEEE, P1118, DOI 10.1109/CVPR.2010.5540091; Simakov D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1202; Solomon F, 1996, IEEE T PATTERN ANAL, V18, P449, DOI 10.1109/34.491627; Sunkavalli K, 2010, LECT NOTES COMPUT SC, V6312, P251, DOI 10.1007/978-3-642-15552-9_19; Takao Toma, 2013, 2013 Abstracts IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2013.6634803; Tan P, 2011, IEEE T PATTERN ANAL, V33, P2506, DOI 10.1109/TPAMI.2011.35; Tan P, 2007, PROC CVPR IEEE, P1814; Tankus A, 2005, IEEE I CONF COMP VIS, P611; Tozza S, 2016, J MATH IMAGING VIS, V56, P57, DOI 10.1007/s10851-016-0633-0; Treibitz T, 2012, LECT NOTES COMPUT SC, V7578, P292, DOI 10.1007/978-3-642-33786-4_22; Ngo TT, 2015, PROC CVPR IEEE, P2310, DOI 10.1109/CVPR.2015.7298844; Tsiotsios C, 2014, PROC CVPR IEEE, P2259, DOI 10.1109/CVPR.2014.289; Tunwattanapong B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461944; Verbiest F, 2008, PROC CVPR IEEE, P2886; VLASIC D, 2009, ACM T GRAPHIC, V28; Wang J, 2015, IEEE I CONF COMP VIS, P3478, DOI 10.1109/ICCV.2015.397; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu L., 2010, P 9 INT C HUM SYST I, P323; Wu TP, 2006, IEEE T PATTERN ANAL, V28, P1830, DOI 10.1109/TPAMI.2006.224; Wu TP, 2010, IEEE T PATTERN ANAL, V32, P546, DOI 10.1109/TPAMI.2009.15; Wu Z, 2013, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2013.197; Xie WY, 2015, PROC CVPR IEEE, P4585, DOI 10.1109/CVPR.2015.7299089; Yeung SK, 2015, IEEE T PATTERN ANAL, V37, P890, DOI 10.1109/TPAMI.2014.2346195; Yu C, 2010, LECT NOTES COMPUT SC, V6314, P115; Yuille A, 1997, PROC CVPR IEEE, P158, DOI 10.1109/CVPR.1997.609314; Zhang L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P618, DOI 10.1109/ICCV.2003.1238405; Zhang Q, 2012, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2012.6247962; Zhou ZL, 2013, PROC CVPR IEEE, P1482, DOI 10.1109/CVPR.2013.195; Zhou ZL, 2010, LECT NOTES COMPUT SC, V6312, P265, DOI 10.1007/978-3-642-15552-9_20; Zickler T, 2008, INT J COMPUT VISION, V79, P13, DOI 10.1007/s11I263-007-0087-3	130	56	57	6	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					271	284		10.1109/TPAMI.2018.2799222	http://dx.doi.org/10.1109/TPAMI.2018.2799222			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29993473				2022-12-18	WOS:000456150600001
J	Xu, Z; Huang, SL; Zhang, Y; Tao, DC				Xu, Zhe; Huang, Shaoli; Zhang, Ya; Tao, Dacheng			Webly-Supervised Fine-Grained Visual Categorization via Deep Domain Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fine-grained visual categorization; part-based model; domain adaptation; webly-supervised learning; semi-supervised learning	ATTRIBUTES; FILTER	Learning visual representations from web data has recently attracted attention for object recognition. Previous studies have mainly focused on overcoming label noise and data bias and have shown promising results by learning directly from web data. However, we argue that it might be better to transfer knowledge from existing human labeling resources to improve performance at nearly no additional cost. In this paper, we propose a new semi-supervised method for learning via web data. Our method has the unique design of exploiting strong supervision, i.e., in addition to standard image-level labels, our method also utilizes detailed annotations including object bounding boxes and part landmarks. By transferring as much knowledge as possible from existing strongly supervised datasets to weakly supervised web images, our method can benefit from sophisticated object recognition algorithms and overcome several typical problems found in webly-supervised learning. We consider the problem of fine-grained visual categorization, in which existing training resources are scarce, as our main research objective. Comprehensive experimentation and extensive analysis demonstrate encouraging performance of the proposed approach, which, at the same time, delivers a new pipeline for fine-grained visual categorization that is likely to be highly effective for real-world applications.	[Xu, Zhe; Zhang, Ya] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China; [Xu, Zhe; Zhang, Ya] Shanghai Jiao Tong Univ, Shanghai Key Lab Multimedia Proc & Transmiss, Shanghai 200240, Peoples R China; [Xu, Zhe; Huang, Shaoli] Univ Technol Sydney, Ctr Artificial Intelligence, 81 Broadway St, Ultimo, NSW 2007, Australia; [Xu, Zhe; Huang, Shaoli] Univ Technol Sydney, Fac Engn & Informat Technol, 81 Broadway St, Ultimo, NSW 2007, Australia; [Tao, Dacheng] Univ Sydney, Sch Informat Technol, J12-1 Cleveland St, Darlington, NSW 2008, Australia; [Tao, Dacheng] Univ Sydney, Fac Engn & Informat Technol, J12-1 Cleveland St, Darlington, NSW 2008, Australia	Shanghai Jiao Tong University; Shanghai Jiao Tong University; University of Technology Sydney; University of Technology Sydney; University of Sydney; University of Sydney	Xu, Z (corresponding author), Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China.; Xu, Z (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Lab Multimedia Proc & Transmiss, Shanghai 200240, Peoples R China.; Xu, Z (corresponding author), Univ Technol Sydney, Ctr Artificial Intelligence, 81 Broadway St, Ultimo, NSW 2007, Australia.; Xu, Z (corresponding author), Univ Technol Sydney, Fac Engn & Informat Technol, 81 Broadway St, Ultimo, NSW 2007, Australia.	xz3030@sjtu.edu.cn; shaoli.huang@student.uts.edu.au; ya_zhang@sjtu.edu.cn; dacheng.tao@sydney.edu.au	Zhang, Ya/Y-8255-2019; huang, shaoli/AAF-2431-2019	Zhang, Ya/0000-0002-5390-9053; Xu, Zhe/0000-0002-3902-2595; huang, shaoli/0000-0002-1445-3196	High Technology Research and Development Program of China [2015AA015801]; NSFC [61221001]; STCSM [12DZ2272600]; 111 Project [B07022]; Australian Research Council [DP-140102164, FT-130101457]	High Technology Research and Development Program of China(National High Technology Research and Development Program of China); NSFC(National Natural Science Foundation of China (NSFC)); STCSM(Science & Technology Commission of Shanghai Municipality (STCSM)); 111 Project(Ministry of Education, China - 111 Project); Australian Research Council(Australian Research Council)	The work is partially supported by the High Technology Research and Development Program of China 2015AA015801, NSFC 61221001, STCSM 12DZ2272600, and the 111 Project B07022, and the Australian Research Council Projects DP-140102164 and FT-130101457. Ya Zhang and Dacheng Tao are the corresponding authors.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Azizpour H, 2012, LECT NOTES COMPUT SC, V7572, P836, DOI 10.1007/978-3-642-33718-5_60; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128; Bergamo A., 2010, ADV NEURAL INFORM PR, P181; Branson S, 2011, IEEE I CONF COMP VIS, P1832, DOI 10.1109/ICCV.2011.6126450; Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47; Chen XL, 2015, IEEE I CONF COMP VIS, P1431, DOI 10.1109/ICCV.2015.168; Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178; Collins B, 2008, LECT NOTES COMPUT SC, V5302, P86, DOI 10.1007/978-3-540-88682-2_8; Cui Y, 2016, PROC CVPR IEEE, P1153, DOI 10.1109/CVPR.2016.130; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412; Donahue J, 2014, PR MACH LEARN RES, V32; Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089; Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242; Fox D, 2010, ADV NEURAL INFORM PR, P244; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Golge E, 2014, LECT NOTES COMPUT SC, V8695, P439, DOI 10.1007/978-3-319-10584-0_29; Hoffman J, 2015, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2015.7298906; Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127; Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132; Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Khosla A, 2011, P CVPR WORKSHOP FINE, V2; Krause J., 2015, ARXIV151106789; Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Li LJ, 2010, INT J COMPUT VISION, V88, P147, DOI 10.1007/s11263-009-0265-6; Li ZY, 2014, LECT NOTES COMPUT SC, V8694, P350, DOI 10.1007/978-3-319-10599-4_23; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu JX, 2012, LECT NOTES COMPUT SC, V7572, P172, DOI 10.1007/978-3-642-33718-5_13; Maji S., 2013, TECH REP; Papandreou G., 2015, ICCV; Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092; Ponce J, 2006, LECT NOTES COMPUT SC, V4170, P29; Rabinovich S. E, 2014, P 3 INT C LEARN REPR; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X; Schroff F, 2011, IEEE T PATTERN ANAL, V33, P754, DOI 10.1109/TPAMI.2010.133; Shih K. J., 2015, ARXIV150706332; Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Van Horn G, 2015, PROC CVPR IEEE, P595, DOI 10.1109/CVPR.2015.7298658; Vasilache, 2015, ARXIV151102251; Wah C., 2011, CNSTR2010001 CAL I T; Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127; Xiao TJ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P177, DOI 10.1145/2647868.2654926; Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685; Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885; Xu Z, 2015, IEEE I CONF COMP VIS, P2524, DOI 10.1109/ICCV.2015.290; Xu Z, 2014, LECT NOTES COMPUT SC, V8689, P600, DOI 10.1007/978-3-319-10590-1_39; Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023; Yang S., 2012, ADV NEURAL INFORM PR, P3122; Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129; Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128; Zhang Y., 2015, ARXIV150404943	64	56	56	2	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1100	1113		10.1109/TPAMI.2016.2637331	http://dx.doi.org/10.1109/TPAMI.2016.2637331			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28113308				2022-12-18	WOS:000428901200007
J	Lee, CY; Gallagher, P; Tu, ZW				Lee, Chen-Yu; Gallagher, Patrick; Tu, Zhuowen			Generalizing Pooling Functions in CNNs: Mixed, Gated, and Tree	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional neural networks; deep learning; pooling functions; supervised classification		In this paper, we seek to improve deep neural networks by generalizing the pooling operations that play a central role in the current architectures. We pursue a careful exploration of approaches to allow pooling to learn and to adapt to complex and variable patterns. The two primary directions lie in: (1) learning a pooling function via (two strategies of) combining of max and average pooling, and (2) learning a pooling function in the form of a tree-structured fusion of pooling filters that are themselves learned. In our experiments every generalized pooling operation we explore improves performance when used in place of average or max pooling. We experimentally demonstrate that the proposed pooling operations provide a boost in invariance properties relative to conventional pooling and set the state of the art on several widely adopted benchmark datasets. These benefits come with only a light increase in computational overhead during training (ranging from additional 5 to 15 percent in time complexity) and a very modest increase in the number of model parameters (e.g., additional 1, 9, and 27 parameters for mixed, gated, and 2-level tree pooling operators, respectively). To gain more insights about our proposed pooling methods, we also visualize the learned pooling masks and the embeddings of the internal feature responses for different pooling operations. Our proposed pooling operations are easy to implement and can be applied within various deep neural network architectures.	[Lee, Chen-Yu] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA; [Gallagher, Patrick; Tu, Zhuowen] Univ Calif San Diego, Dept Cognit Sci, La Jolla, CA 92093 USA	University of California System; University of California San Diego; University of California System; University of California San Diego	Tu, ZW (corresponding author), Univ Calif San Diego, Dept Cognit Sci, La Jolla, CA 92093 USA.	chl260@ucsd.edu; patrick.w.gallagher@gmail.com; ztu@ucsd.edu			Northrop Grumman Contextual Robotics grant; US National Science Foundation [IIS-1216528 (IIS-1360566), IIS-0844566(IIS-1360568), IIS-1618477]	Northrop Grumman Contextual Robotics grant; US National Science Foundation(National Science Foundation (NSF))	This work is supported by US National Science Foundation awards IIS-1216528 (IIS-1360566), IIS-0844566(IIS-1360568), IIS-1618477, and a Northrop Grumman Contextual Robotics grant. We are grateful for the generous donation of the GPUs by NVIDIA. We thank the anonymous reviewers for their constructive comments, and in particular about the suggestion to compare with grouped convolutions.	Agostinelli Forest, 2015, P INT C LEARN REPR; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2013, COMPUT SCI; Boureau Y.-L., 2010, ICML, P111, DOI DOI 10.5555/3104322.3104338; Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555; Bulo SR, 2014, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2014.18; Coates A., 2011, ADV NEURAL INFORM PR, P2528, DOI DOI 10.1016/J.PSYCHRES.2009.03.008; Graham B, 2014, ARXIV14126071; Gulcehre Caglar, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8724, P530, DOI 10.1007/978-3-662-44848-9_34; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Ioannou Y, 2016, ARXIV PREPRINT ARXIV; Irsoy O., 2016, P AS C MACH LEARN HA, P378; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076; Kontschieder P, 2015, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2015.172; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee CY, 2016, JMLR WORKSH CONF PRO, V51, P464; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958; Minker J., 2000, LOGIC BASED ARTIFICI; Mishkin D, 2017, COMPUT VIS IMAGE UND, V161, P11, DOI 10.1016/j.cviu.2017.05.007; Netzer Y., 2011, P NIPS WOKRSH DEEP L; Quinlan J. R., 1993, C4 5 PROGRAMMING MAC, V38; Ranzato M.A., 2007, NIPS P 20 INT C NEUR, V20, P1185; Romero Adriana, 2015, ICLR; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sanjoy D., 2013, INT C MACH LEARN, P1319, DOI DOI 10.5555/3042817.3043084; Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Springenberg J. T, 2015, ARXIV PREPRINT ARXIV; Srivastava Nitish, 2013, NIPS; Srivastava Rupesh Kumar, 2015, ADV NEURAL INFORM PR, P2377; Stollenga M.F., 2014, ADV NEURAL INFORM PR, P3545; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wan L., 2013, P INT C MACHINE LEAR, P1058; Wei Z., 2016, DEEPLY FUSED NETS; Zeiler MD, 2013, ARXIV13013557, DOI DOI 10.1007/978-3-319-26532-2_6	44	56	61	3	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					863	875		10.1109/TPAMI.2017.2703082	http://dx.doi.org/10.1109/TPAMI.2017.2703082			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28504932	hybrid			2022-12-18	WOS:000426687100007
J	Heller, J; Havlena, M; Pajdla, T				Heller, Jan; Havlena, Michal; Pajdla, Tomas			Globally Optimal Hand-Eye Calibration Using Branch-and-Bound	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hand-eye calibration; branch-and-bound algorithm; global optimization	SENSOR	This paper introduces a novel solution to the hand-eye calibration problem. It uses camera measurements directly and, at the same time, requires neither prior knowledge of the external camera calibrations nor a known calibration target. Our algorithm uses branch-and-bound approach to minimize an objective function based on the epipolar constraint. Further, it employs Linear Programming to decide the bounding step of the algorithm. Our technique is able to recover both the unknown rotation and translation simultaneously and the solution is guaranteed to be globally optimal with respect to the L-infinity-norm.	[Heller, Jan; Pajdla, Tomas] Czech Tech Univ, Dept Cybernet, CR-16635 Prague, Czech Republic; [Havlena, Michal] Swiss Fed Inst Technol, Inst Geodesy & Photogrammetry, Zurich, Switzerland	Czech Technical University Prague; Swiss Federal Institutes of Technology Domain; ETH Zurich	Heller, J; Pajdla, T (corresponding author), Czech Tech Univ, Dept Cybernet, CR-16635 Prague, Czech Republic.; Havlena, M (corresponding author), Swiss Fed Inst Technol, Inst Geodesy & Photogrammetry, Zurich, Switzerland.	hellej1@cmp.felk.cvut.cz; michal.havlena@geod.baug.ethz.ch; pajdla@cmp.felk.cvut.cz	Pajdla, Tomas/K-7954-2013	Pajdla, Tomas/0000-0001-6325-0072	EC [FP7-SPACE-2012-312377 PRoViDE, FP7-288553 CloPeMa]; Grant Agency of the CTU Prague [SGS10/277/OHK3/3T/13]	EC(European CommissionEuropean Commission Joint Research Centre); Grant Agency of the CTU Prague	The authors were supported by the EC FP7-SPACE-2012-312377 PRoViDE, by the EC FP7-288553 CloPeMa, and by the Grant Agency of the CTU Prague SGS10/277/OHK3/3T/13 projects.	[Anonymous], 2011, GNU LINEAR PROGRAMMI; [Anonymous], 2011, CVPR; CHOU JCK, 1991, INT J ROBOT RES, V10, P240, DOI 10.1177/027836499101000305; Daniilidis K, 1999, INT J ROBOT RES, V18, P286, DOI 10.1177/02783649922066213; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9; Heller J, 2012, PROC CVPR IEEE, P1608, DOI 10.1109/CVPR.2012.6247853; HORAUD R, 1995, INT J ROBOT RES, V14, P195, DOI 10.1177/027836499501400301; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Lourakis M.I., 2004, LEVMAR LEVENBERG MAR; PARK FC, 1994, IEEE T ROBOTIC AUTOM, V10, P717, DOI 10.1109/70.326576; Ruland T, 2012, PROC CVPR IEEE, P1035, DOI 10.1109/CVPR.2012.6247781; Scaramuzza D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5695, DOI 10.1109/IROS.2006.282372; Seo Y, 2009, IEEE I CONF COMP VIS, P1173, DOI 10.1109/ICCV.2009.5459343; SHIU YC, 1989, IEEE T ROBOTIC AUTOM, V5, P16, DOI 10.1109/70.88014; Stewenius H., 2004, P AS C COMP VIS, P760; Torii A, 2011, INT J COMPUT VISION, V91, P157, DOI 10.1007/s11263-010-0350-x; TSAI R, 1988, P IEEE INT C ROB AUT, V1, P554; TSAI RY, 1989, IEEE T ROBOTIC AUTOM, V5, P345, DOI 10.1109/70.34770; Zhuang HQ, 1998, IEEE T ROBOTIC AUTOM, V14, P612, DOI 10.1109/70.704231; Zijian Zhao, 2011, 2011 IEEE International Conference on Robotics and Automation, P2947	21	56	60	2	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					1027	1033		10.1109/TPAMI.2015.2469299	http://dx.doi.org/10.1109/TPAMI.2015.2469299			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	26353364				2022-12-18	WOS:000374164700016
J	Lu, SJ; Tan, C; Lim, JH				Lu, Shijian; Tan, Cheston; Lim, Joo-Hwee			Robust and Efficient Saliency Modeling from Image Co-Occurrence Histograms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Saliency modeling; visual attention; image co-occurrence histogram	OBJECT DETECTION; ATTENTION; SCALE	This paper presents a visual saliency modeling technique that is efficient and tolerant to the image scale variation. Different from existing approaches that rely on a large number of filters or complicated learning processes, the proposed technique computes saliency from image histograms. Several two-dimensional image co-occurrence histograms are used, which encode not only "how many" (occurrence) but also "where and how" (co-occurrence) image pixels are composed into a visual image, hence capturing the "unusualness" of an object or image region that is often perceived by either global "uncommonness" (i.e., low occurrence frequency) or local "discontinuity" with respect to the surrounding (i.e., low co-occurrence frequency). The proposed technique has a number of advantageous characteristics. It is fast and very easy to implement. At the same time, it involves minimal parameter tuning, requires no training, and is robust to image scale variation. Experiments on the AIM dataset show that a superior shuffled AUC (sAUC) of 0.7221 is obtained, which is higher than the state-of-the-art sAUC of 0.7187.	[Lu, Shijian; Tan, Cheston; Lim, Joo-Hwee] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore	Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)	Lu, SJ (corresponding author), ASTAR, Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis South Tower, Singapore 138632, Singapore.	slu@i2r.a-star.edu.sg; cheston-tan@i2r.a-star.edu.sg; joohwee@i2r.a-star.edu.sg	Lu, Shijian/AAU-4831-2021	Lu, Shijian/0000-0002-6766-2506; Tan, Cheston/0000-0003-1248-4906				Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Aibing Rao, 1999, Proceedings 11th International Conference on Tools with Artificial Intelligence, P183, DOI 10.1109/TAI.1999.809784; [Anonymous], 2006, NIPS; Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727; Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711; Borji A, 2012, PROC CVPR IEEE, P470, DOI 10.1109/CVPR.2012.6247710; Bruce N, 2004, INT C PATT RECOG, P616, DOI 10.1109/ICPR.2004.1334223; Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5; Chen DY, 2012, IEEE T NEUR NET LEAR, V23, P1206, DOI 10.1109/TNNLS.2012.2198888; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676; Feng J, 2011, IEEE I CONF COMP VIS, P1028, DOI 10.1109/ICCV.2011.6126348; Gao F, 2007, PR IEEE COMP DESIGN, P3; Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007; Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Kienzle W, 2007, ADV NEURAL INFORM PR, P689; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Lu SJ, 2012, LECT NOTES COMPUT SC, V7578, P321, DOI 10.1007/978-3-642-33786-4_24; Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467; Moore CM, 1998, J EXP PSYCHOL HUMAN, V24, P1296, DOI 10.1037/0096-1523.24.4.1296; Peng Chang, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P498, DOI 10.1109/CVPR.1999.784727; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093; Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017; TSOTSOS JK, 1990, BEHAV BRAIN SCI, V13, P423, DOI 10.1017/S0140525X00079577; Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231; Wang P, 2012, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2012.6248054; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhao Q, 2012, J VISION, V12, DOI 10.1167/12.6.22; Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9	40	56	58	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					195	201		10.1109/TPAMI.2013.158	http://dx.doi.org/10.1109/TPAMI.2013.158			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231877				2022-12-18	WOS:000327965100017
J	Huang, C; Li, Y; Nevatia, R				Huang, Chang; Li, Yuan; Nevatia, Ramakant			Multiple Target Tracking by Learning-Based Hierarchical Association of Detection Responses	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiple target tracking; hierarchical association; bag ranking; AdaBoost	HUMANS	We propose a hierarchical association approach to multiple target tracking from a single camera by progressively linking detection responses into longer track fragments (i.e., tracklets). Given frame-by-frame detection results, a conservative dual-threshold method that only links very similar detection responses between consecutive frames is adopted to generate initial tracklets with minimum identity switches. Further association of these highly fragmented tracklets at each level of the hierarchy is formulated as a Maximum A Posteriori (MAP) problem that considers initialization, termination, and transition of tracklets as well as the possibility of them being false alarms, which can be efficiently computed by the Hungarian algorithm. The tracklet affinity model, which measures the likelihood of two tracklets belonging to the same target, is a linear combination of automatically learned weak nonparametric models upon various features, which is distinct from most of previous work that relies on heuristic selection of parametric models and manual tuning of their parameters. For this purpose, we develop a novel bag ranking method and train the crucial tracklet affinity models by the boosting algorithm. This bag ranking method utilizes the soft max function to relax the oversufficient objective function used by the conventional instance ranking method. It provides a tighter upper bound of empirical errors in distinguishing correct associations from the incorrect ones, and thus yields more accurate tracklet affinity models for the tracklet association problem. We apply this approach to the challenging multiple pedestrian tracking task. Systematic experiments conducted on two real-life datasets show that the proposed approach outperforms previous state-of-the-art algorithms in terms of tracking accuracy, in particular, considerably reducing fragmentations and identity switches.	[Huang, Chang] Baidu USA LLC, Cupertino, CA 95014 USA; [Li, Yuan] Google Inc, Los Angeles, CA 90049 USA; [Nevatia, Ramakant] Univ So Calif, Inst Robot & Intelligence Syst, Los Angeles, CA 90089 USA	Baidu; Google Incorporated; University of Southern California	Huang, C (corresponding author), Baidu USA LLC, 20883 Steven Creeks Ave,Suite 150, Cupertino, CA 95014 USA.	huangchang@baidu.com; stickyworm@gmail.com; nevatia@usc.edu						[Anonymous], [No title captured]; [Anonymous], 2012, CAVIAR DATASET; BARSHALOM Y, 1980, INFORM SCI SYSTEMS; Berclaz J., 2006, P IEEE C COMP VIS PA; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Brendel W., 2011, P IEEE C COMP VIS PA; Cai Y., 2006, P EUR C COMP VIS; Comaniciu D., 2001, P IEEE INT C COMP VI; Freund Y., 2003, J MACHINE LEARNING R, V4, P933, DOI DOI 10.1162/JMLR.2003.4.6.933; Heckerman D., 1989, P 5 ANN C UNC ART IN, P163; Huang C., 2010, P IEEE C COMP VIS PA; Huang C., 2008, P EUR C COMP VIS; Kaucic R., 2005, P IEEE C COMP VIS PA; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Leibe B., 2007, P IEEE INT C COMP VI; Li Y., 2009, P IEEE C COMP VIS PA; MASON L, 1999, P ADV NEUR INF PROC; Okuma K., 2004, P EUR C COMP VIS; PERERA AGA, 2006, P IEEE C COMP VIS PA; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; SMEATON AF, 2006, P 8 ACM INT WORKSH M; STAUFFER C, 2003, P IEEE WORKSH EV MIN; Tomasi C, 1991, CMUCS91132; Viola Paul, 2001, PROC CVPR IEEE; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; YU Q, 2007, P IEEE C COMP VIS PA; Zhang L., 2008, P IEEE C COMP VIS PA; Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73; Zhu Q., 2006, P IEEE C COMP VIS PA	30	56	64	0	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					898	910		10.1109/TPAMI.2012.159	http://dx.doi.org/10.1109/TPAMI.2012.159			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	23428432				2022-12-18	WOS:000314931000010
J	Kolev, K; Brox, T; Cremers, D				Kolev, Kalin; Brox, Thomas; Cremers, Daniel			Fast Joint Estimation of Silhouettes and Dense 3D Geometry from Multiple Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape from silhouettes; interactive segmentation; convex optimization	ALGORITHMS; OBJECTS	We propose a probabilistic formulation of joint silhouette extraction and 3D reconstruction given a series of calibrated 2D images. Instead of segmenting each image separately in order to construct a 3D surface consistent with the estimated silhouettes, we compute the most probable 3D shape that gives rise to the observed color information. The probabilistic framework, based on Bayesian inference, enables robust 3D reconstruction by optimally taking into account the contribution of all views. We solve the arising maximum a posteriori shape inference in a globally optimal manner by convex relaxation techniques in a spatially continuous representation. For an interactively provided user input in the form of scribbles specifying foreground and background regions, we build corresponding color distributions as multivariate Gaussians and find a volume occupancy that best fits to this data in a variational sense. Compared to classical methods for silhouette-based multiview reconstruction, the proposed approach does not depend on initialization and enjoys significant resilience to violations of the model assumptions due to background clutter, specular reflections, and camera sensor perturbations. In experiments on several real-world data sets, we show that exploiting a silhouette coherency criterion in a multiview setting allows for dramatic improvements of silhouette quality over independent 2D segmentations without any significant increase of computational efforts. This results in more accurate visual hull estimation, needed by a multitude of image-based modeling approaches. We made use of recent advances in parallel computing with a GPU implementation of the proposed method generating reconstructions on volume grids of more than 20 million voxels in up to 4.41 seconds.	[Kolev, Kalin; Cremers, Daniel] Tech Univ Munich, Dept Comp Sci, D-85748 Munich, Germany; [Brox, Thomas] Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany	Technical University of Munich; University of Freiburg	Kolev, K (corresponding author), Tech Univ Munich, Dept Comp Sci, Boltzmanstr 3, D-85748 Munich, Germany.	kalin.kolev@in.tum.de; brox@informatik.uni-freiburg.de; daniel.cremers@in.tum.de						Bai X., 2007, P IEEE INT C COMP VI; Baumgart B.G., 1974, THESIS STANFORD U; Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Campbell N., 2007, BRIT MACH VIS C BMVC, P530; Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; Franco J.-S., 2005, P IEEE INT C COMP VI; Furukawa Yasutaka, 2007, P IEEE C COMP VIS PA; GOLDSCHLAGER LM, 1982, THEOR COMPUT SCI, V21, P105, DOI 10.1016/0304-3975(82)90092-5; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Guan L., 2007, P IEEE INT C COMP VI; Keriven R., 2002, 2002221 CERMICS; Klodt M., 2008, P EUR C COMP VIS OCT; Kolev K., 2008, P EUR C COMP VIS OCT; Kolev K, 2006, LECT NOTES COMPUT SC, V4174, P688; Kolev K, 2009, INT J COMPUT VISION, V84, P80, DOI 10.1007/s11263-009-0233-1; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234; Liu J., 2010, P IEEE INT C COMP VI; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Pock Thomas, 2009, P IEEE INT C COMP VI; POTMESIL M, 1987, COMPUT VISION GRAPH, V40, P1, DOI 10.1016/0734-189X(87)90053-3; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Snow D, 2000, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2000.855839; Strandmark P., 2010, P INT C COMP VIS PAT; SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029; Udupa JK, 2003, P IEEE, V91, P1649, DOI 10.1109/JPROC.2003.817883; Unger M., 2008, P BRIT MACH VIS C SE; Vineet Vibhav, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563095; Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233; Yezzi AJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P59, DOI 10.1109/ICCV.2001.937499	36	56	60	1	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					493	505		10.1109/TPAMI.2011.150	http://dx.doi.org/10.1109/TPAMI.2011.150			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21808082	Green Submitted			2022-12-18	WOS:000299381600006
J	Lee, S; Liu, Y				Lee, Seungkyu; Liu, Yanxi			Curved Glide-Reflection Symmetry Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Symmetry; glide reflection; curved axis; curved surface	MID-SAGITTAL PLANE; AXES; OPTIMIZATION; IMAGES; OBJECT; SHAPE	We generalize the concept of bilateral reflection symmetry to curved glide-reflection symmetry in 2D euclidean space, such that classic reflection symmetry becomes one of its six special cases. We propose a local feature-based approach for curved glide-reflection symmetry detection from real, unsegmented 2D images. Furthermore, we apply curved glide-reflection axis detection for curved reflection surface detection in 3D images. Our method discovers, groups, and connects statistically dominant local glide-reflection axes in an Axis-Parameter-Space (APS) without preassumptions on the types of reflection symmetries. Quantitative evaluations and comparisons against state-of-the-art algorithms on a diverse 64-test-image set and 1,125 Swedish leaf-data images show a promising average detection rate of the proposed algorithm at 80 and 40 percent, respectively, and superior performance over existing reflection symmetry detection algorithms. Potential applications in computer vision, particularly biomedical imaging, include saliency detection from unsegmented images and quantification of deviations from normality. We make our 64-test-image set publicly available.	[Lee, Seungkyu] Samsung Adv Inst Technol, Adv Media Lab, Yongin 446712, Gyeonggi Do, South Korea; [Liu, Yanxi] Penn State Univ, Dept Comp Sci & Elect Engn, University Pk, PA 16802 USA	Samsung; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Lee, S (corresponding author), Samsung Adv Inst Technol, Adv Media Lab, San14, Yongin 446712, Gyeonggi Do, South Korea.	seungkyu74@gmail.com; yanxi@cse.psu.edu			PSU CTSA; Northrop Grumman Gift grant	PSU CTSA; Northrop Grumman Gift grant	The authors would like to thank Loy and Eklundh [15] and Peng et al. [16] for their respective source code and Dr. K.C. Cheng for the zebrafish images. This work is supported in part by a PSU CTSA grant and a Northrop Grumman Gift grant to Yanxi Liu.	Ardekani BA, 1997, IEEE T MED IMAGING, V16, P947, DOI 10.1109/42.650892; BIRKOFF G, 1932, AESTHETIC MEASURE; Bitsakos K, 2008, INT C PATT RECOG, P1017; BRADY M, 1984, SMOOTHED LOCAL SYMME; Bruckstein AM, 1998, PATTERN RECOGN, V31, P181, DOI 10.1016/S0031-3203(97)00018-6; Carlsson S., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P249, DOI 10.1007/BFb0055671; CHEN P.-C., 2007, CMURITR0736; Christopher T.J., 1997, COMPACTIFICATIONS SY; Cobb J., 1948, AM ACADEMY ORTHOPAED, V5, P261; Cornelius H., 2006, P C COMP VIS PATT RE, P191; Curwen RW, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1115, DOI 10.1109/ICCV.1998.710856; D'Errico J, 2009, MATLAB CENTRAL FILE; Dai B, 2007, C IND ELECT APPL, P1827; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forsyth DA, 2002, PRENT HALL PROF TECH; Guillemaud R, 1996, SCHIZOPHR RES, V18, P183, DOI 10.1016/0920-9964(96)85575-7; Heidemann G, 2004, IEEE T PATTERN ANAL, V26, P817, DOI 10.1109/TPAMI.2004.29; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; Kazhdan M, 2002, LECT NOTES COMPUT SC, V2351, P642; Kiryati N, 1998, INT J COMPUT VISION, V29, P29, DOI 10.1023/A:1008034529558; Kootstra G., 2008, P 19 BRIT MACH VIS C, P1115; KUEHNLE A, 1991, PATTERN RECOGN LETT, V12, P249, DOI 10.1016/0167-8655(91)90039-O; Labonte F., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P258, DOI 10.1109/ICCV.1993.378209; Lee S, 2010, IEEE T PATTERN ANAL, V32, P1659, DOI 10.1109/TPAMI.2009.173; Lei YW, 1999, PATTERN RECOGN, V32, P167, DOI 10.1016/S0031-3203(98)00135-6; Levinshtein A., 2009, P IEEE INT C COMP VI; Liu J., 2010, P 10 AS C COM1PUTER; LIU Y, 1996, CMURITR9640; LIU Y, 2000, P MED IM COMP COMP A; LIU Y., 1990, THESIS U MASSACHUSET, P3; Liu Y.-Q.X. Yanxi, 2005, P TECHNICAL SKETCH A; Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332; LIU YX, 1994, INT J ROBOT RES, V13, P148, DOI 10.1177/027836499401300205; Liu YX, 2001, IEEE T MED IMAGING, V20, P175, DOI 10.1109/42.918469; LOCHER P, 1987, EYE MOVEMENTS PHYSL; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508; Lu YX, 2009, FOUND TRENDS COMPUT, V5, P1, DOI 10.1561/0600000008; Mancas M, 2005, INT CONF ACOUST SPEE, P725; Marola G, 2005, IEEE T PATTERN ANAL, V27, P465, DOI 10.1109/TPAMI.2005.45; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; Martinet A, 2006, ACM T GRAPHIC, V25, P439, DOI 10.1145/1138450.1138462; Milner D, 2007, PATTERN RECOGN, V40, P2237, DOI 10.1016/j.patcog.2006.12.008; MINOSHIMA S, 1992, J NUCL MED, V33, P1579; Mitra N.J., 2007, ACM T GRAPHIC, V26, P1, DOI DOI 10.1145/1276377.1276456; Mitra NJ, 2006, ACM T GRAPHIC, V25, P560, DOI 10.1145/1141911.1141924; Mitra S, 2004, PROC CVPR IEEE, P889; MUKHERJEE DP, 1995, PHILOS T R SOC A, V351, P77, DOI 10.1098/rsta.1995.0026; Pauly M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360642; Peng H., 2007, BIOINFORMATICS, V24, P569; Podolak J, 2006, ACM T GRAPHIC, V25, P549, DOI 10.1145/1141911.1141923; PONCE J, 1990, COMPUT VISION GRAPH, V52, P328, DOI 10.1016/0734-189X(90)90079-B; Prasad VSN, 2004, IEEE T IMAGE PROCESS, V13, P1559, DOI 10.1109/TIP.2004.837564; Prasad VSN, 2005, IEEE I CONF COMP VIS, P954; Prima S, 2002, IEEE T MED IMAGING, V21, P122, DOI 10.1109/42.993131; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; Riklin-Raviv T, 2009, IEEE T PATTERN ANAL, V31, P1458, DOI 10.1109/TPAMI.2008.160; SAINTMARC P, 1990, P EURO C COMPUT VISI, P604; Sato Y, 1996, COMPUT VIS IMAGE UND, V64, P175, DOI 10.1006/cviu.1996.0052; Shen DG, 2000, INT C PATT RECOG, P1010, DOI 10.1109/ICPR.2000.903716; Siddiqi K., 2008, SERIES COMPUTATIONAL, V37; Soderkvist O, 2001, THESIS LINKOPING U; Stegmann MB, 2005, PROC SPIE, V5747, P568, DOI 10.1117/12.595222; Sun C, 1999, REAL-TIME IMAGING, V5, P63, DOI 10.1006/rtim.1998.0135; Sun CM, 1997, IEEE T PATTERN ANAL, V19, P164, DOI 10.1109/34.574800; Tuzikov AV, 1997, J MATH IMAGING VIS, V7, P53, DOI 10.1023/A:1008266024101; VanGool L, 1996, PROC CVPR IEEE, P285, DOI 10.1109/CVPR.1996.517087; Weyl H., 1952, SYMMETRY; Wolter J., 1985, VISUAL COMPUT, V1, P37; Yang X, 2005, LECT NOTES COMPUT SC, V3644, P68; YlaJaaski A, 1996, COMPUT VIS IMAGE UND, V63, P399, DOI 10.1006/cviu.1996.0031; Yuan T., 2005, P IEEE INT C IM PROC, V3, pIII; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; Zebrafish Atlas, 2011, ZEBRAFISH ATLAS; ZIELKE T, 1992, LECT NOTES COMPUT SC, V588, P865	75	56	62	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					266	278		10.1109/TPAMI.2011.118	http://dx.doi.org/10.1109/TPAMI.2011.118			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21670486				2022-12-18	WOS:000298105500006
J	Lee, JH; Won, CH				Lee, Jong-Ha; Won, Chang-Hee			Topology Preserving Relaxation Labeling for Nonrigid Point Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Point pattern matching; graph matching; registration; relaxation labeling; nonrigid point matching	COMPATIBILITY COEFFICIENTS; REGISTRATION; ALGORITHM	This paper presents a relaxation labeling process with the newly defined compatibility measure for solving a general nonrigid point matching problem. In the literature, there exists a point matching method using relaxation labeling; however, the compatibility coefficient takes a binary value of zero or one depending on whether a point and a neighbor have corresponding points. Our approach generalizes this relaxation labeling method. The compatibility coefficient takes n-discrete values which measure the correlation between point pairs. In order to improve the speed of the algorithm, we use a diagram of log distance and polar angle bins to compute the correlation. The extensive experiments show that the proposed topology preserving relaxation algorithm significantly improves the matching performance compared to other state-of-the-art point matching algorithms.	[Lee, Jong-Ha; Won, Chang-Hee] Temple Univ, Dept Elect & Comp Engn, Philadelphia, PA 19122 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Lee, JH (corresponding author), Temple Univ, Dept Elect & Comp Engn, 1947 N 12th St, Philadelphia, PA 19122 USA.	jong@temple.edu; cwon@temple.edu		Won, Chang-Hee/0000-0001-8732-198X	Office of the Senior Vice Provost for Research and Strategic Initiatives at Temple University	Office of the Senior Vice Provost for Research and Strategic Initiatives at Temple University	The authors thank Dr. Haibin Ling for his helpful comments on the first draft of this document. This research is supported in part by the Tobacco Formula Fund from the Office of the Senior Vice Provost for Research and Strategic Initiatives at Temple University.	Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; He XC, 2008, OPT ENG, V47, DOI 10.1117/1.2931681; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Jian B, 2005, IEEE I CONF COMP VIS, P1246; Johnson HJ, 2002, IEEE T MED IMAGING, V21, P450, DOI 10.1109/TMI.2002.1009381; KITTLER J, 1989, INT J PATTERN RECOGN, V3, P25; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Myronenko A., 2007, ADV NEURAL INFORM PR, V19, P1009, DOI DOI 10.1109/TPAMI.20; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; Pelillo M, 1997, J MATH IMAGING VIS, V7, P309, DOI 10.1023/A:1008255111261; PELILLO M, 1994, IEEE T PATTERN ANAL, V16, P933, DOI 10.1109/34.310691; Rangarajan A, 1996, NEURAL COMPUT, V8, P1041, DOI 10.1162/neco.1996.8.5.1041; Rangarajan A., 1999, MED IMAGE ANAL, V3, P1; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591; Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558; Wilson RC, 1996, PATTERN RECOGN LETT, V17, P263, DOI 10.1016/0167-8655(95)00115-8; WU QX, 1995, IEEE T GEOSCI REMOTE, V33, P216, DOI 10.1109/36.368206; Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	25	56	62	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					427	432		10.1109/TPAMI.2010.179	http://dx.doi.org/10.1109/TPAMI.2010.179			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	20876932				2022-12-18	WOS:000285313200018
J	Zhou, J; Chen, FL; Gu, JW				Zhou, Jie; Chen, Fanglin; Gu, Jinwei			A Novel Algorithm for Detecting Singular Points from Fingerprint Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Singular points; topological structure; Poincare Index; orientation field	DIRECTIONAL FIELDS; COMPUTATION; MODEL	Fingerprint analysis is typically based on the location and pattern of detected singular points in the images. These singular points (cores and deltas) not only represent the characteristics of local ridge patterns but also determine the topological structure (i.e., fingerprint type) and largely influence the orientation field. In this paper, we propose a novel algorithm for singular points detection. After an initial detection using the conventional Poincare Index method, a so-called DORIC feature is used to remove spurious singular points. Then, the optimal combination of singular points is selected to minimize the difference between the original orientation field and the model-based orientation field reconstructed using the singular points. A core-delta relation is used as a global constraint for the final selection of singular points. Experimental results show that our algorithm is accurate and robust, giving better results than competing approaches. The proposed detection algorithm can also be used for more general 2D oriented patterns, such as fluid flow motion, and so forth.	[Zhou, Jie; Chen, Fanglin; Gu, Jinwei] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Tsinghua University	Zhou, J (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	jzhou@tsinghua.edu.cn; chen-fl06@mails.tsinghua.edu.cn; gujinwei98@mails.tsinghua.edu.cn	Chen, Fanglin/I-1527-2013	Chen, Fanglin/0000-0002-9193-5412	National 863 Hi-Tech Development Program of China [2008AA01Z123]; Natural Science Foundation of China [60205002, 60875017]; Natural Science Foundation of Beijing [4042020]	National 863 Hi-Tech Development Program of China(National High Technology Research and Development Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Beijing(Beijing Natural Science Foundation)	An early version of this manuscript was published in the Proceedings of the International Conference of Biometrics (pp. 261270, 2007). This work was supported by the National 863 Hi-Tech Development Program of China under Grant 2008AA01Z123, by the Natural Science Foundation of China under Grant 60205002 and Grant 60875017, and by the Natural Science Foundation of Beijing under Grant 4042020. The authors would like to thank Dr. Daniel R. Tretter and Professor Shiji Song for their help in revising this paper.	Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cappelli R, 1999, IEEE T PATTERN ANAL, V21, P402, DOI 10.1109/34.765653; Chikkerur S, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P207, DOI 10.1109/AUTOID.2005.34; Cristianini N., 2000, INTRO SUPPORT VECTOR; Fulton W., 1995, ALGEBRAIC TOPOLOGY 1; Gu JW, 2003, PROC CVPR IEEE, P493; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; Ma YW, 1995, COMPUT AIDED DESIGN, V27, P811, DOI 10.1016/0010-4485(95)00002-X; Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144; Nilsson K, 2003, PATTERN RECOGN LETT, V24, P2135, DOI 10.1016/S0167-8655(03)00083-7; NILSSON K, 2002, P WORKSH BIOM AUTH, P39; Nilsson K., 2005, THESIS CHALMERS U TE; Park CH, 2006, PATTERN RECOGN, V39, P839, DOI 10.1016/j.patcog.2005.10.021; Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195; Prabhakar S., 2003, HDB FINGERPRINT RECO; Ramo P, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P242, DOI 10.1109/ICIP.2001.958096; Saff E.B., 2002, FUNDAMENTALS COMPLEX; Scheuermann G, 1998, IEEE T VIS COMPUT GR, V4, P109, DOI 10.1109/2945.694953; SCHEUERMANN G, 1999, THESIS U KAISERSLAUT; SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I; Tico M, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P183, DOI 10.1109/ISCAS.1999.779972; Vapnik V., 2000, NATURE STAT LEARNING; Wang CY, 2007, CHINESE EDUC SOC, V40, P6, DOI 10.2753/CED1061-1932400501; Watson Craig I, 1992, FINGERPRINT DATABASE, V17; Zhang QZ, 2004, PATTERN RECOGN, V37, P2233, DOI 10.1016/j.patcog.2003.12.020; Zhou J, 2004, PATTERN RECOGN, V37, P389, DOI 10.1016/S0031-3203(03)00186-9; Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608	30	56	60	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1239	1250		10.1109/TPAMI.2008.188	http://dx.doi.org/10.1109/TPAMI.2008.188			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443922				2022-12-18	WOS:000266188900008
J	Atkinson, GA; Hancock, ER				Atkinson, Gary A.; Hancock, Edwin R.			Shape estimation using polarization and shading from two views	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						polarization imaging; surface shape recovery; stereo; reflectance function estimation; patch alignment	SURFACE; REFLECTION; DIFFUSE; COMPONENTS; SEPARATION; CURVATURE; FEATURES; VISION	This paper presents a novel method for 3D surface reconstruction that uses polarization and shading information from two views. The method relies on the polarization data acquired using a standard digital camera and a linear polarizer. Fresnel theory is used to process the raw images and to obtain initial estimates of surface normals, assuming that the reflection type is diffuse. Based on this idea, the paper presents two novel contributions to the problem of surface reconstruction. The first is a technique to enhance the surface normal estimates by incorporating shading information into the method. This is done using robust statistics to estimate how the measured pixel brightnesses depend on the surface orientation. This gives an estimate of the object material reflectance function, which is used to refine the estimates of the surface normals. The second contribution is to use the refined estimates to establish correspondence between two views of an object. To do this, surface patches are extracted from each view, which are then aligned by minimising an energy functional based on the surface normal estimates and local topographic properties. The optimum alignment parameters for different patch pairs are then used to establish stereo correspondence. This process results in an unambiguous field of surface normals, which can be integrated to recover the surface depth. Our technique is most suited to smooth nonmetallic surfaces. It complements existing stereo algorithms since it does not require salient surface features to obtain correspondences. An extensive set of experiments, yielding reconstructed objects and reflectance functions, are presented and compared to ground truth.	Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England	University of York - UK	Atkinson, GA (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.	atkinson@cs.york.ac.uk; erh@cs.york.ac.uk	Hancock, Edwin R/C-6071-2008; Hancock, Edwin/N-7548-2019	Hancock, Edwin R/0000-0003-4496-2028; Hancock, Edwin/0000-0003-4496-2028; Atkinson, Gary/0000-0001-9497-2457				Agrawal A, 2005, IEEE I CONF COMP VIS, P174, DOI 10.1109/ICCV.2005.31; Belhumeur PN, 1997, PROC CVPR IEEE, P1060, DOI 10.1109/CVPR.1997.609461; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Clark J, 1997, IMAGE VISION COMPUT, V15, P107, DOI 10.1016/S0262-8856(96)01126-2; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; Drbohlav O, 1999, P SOC PHOTO-OPT INS, V3826, P253, DOI 10.1117/12.364331; Drbohlav O, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P581, DOI 10.1109/ICCV.2001.937570; Forsyth David A, 2012, COMPUTER VISION MODE; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; FRITSCH FN, 1980, SIAM J NUMER ANAL, V17, P238, DOI 10.1137/0717021; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hecht E., 2017, OPTICS, V5th ed.; Jin HL, 2000, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2000.855816; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; Kotz S, 2000, EXTREME VALUE DISTRI; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Miyazaki D, 2002, J OPT SOC AM A, V19, P687, DOI 10.1364/JOSAA.19.000687; Miyazaki D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P982; Miyazaki D, 2004, IEEE T PATTERN ANAL, V26, P73, DOI 10.1109/TPAMI.2004.1261080; MIYAZAKI D, 2005, P SOC PHOTO-OPT INS, V5888, P1; Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113; Ragheb H, 2005, PATTERN RECOGN, V38, P1574, DOI 10.1016/j.patcog.2005.03.025; Rahmann S, 2003, LECT NOTES COMPUT SC, V2652, P810; Rahmann S, 2001, PROC CVPR IEEE, P149; Robles-Kelly A, 2005, GRAPH MODELS, V67, P518, DOI 10.1016/j.gmod.2004.12.003; Schechner YY, 2004, PROC CVPR IEEE, P536; Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511; SHIBATA T, 2005, P SOC PHOTO-OPT INS, V5888, P25; Treuille A, 2004, LECT NOTES COMPUT SC, V3022, P457; Umeyama S, 2004, IEEE T PATTERN ANAL, V26, P639, DOI 10.1109/TPAMI.2004.1273960; WOLFF LB, 1994, J OPT SOC AM A, V11, P2956, DOI 10.1364/JOSAA.11.002956; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; Wolff LB, 1997, IMAGE VISION COMPUT, V15, P81, DOI 10.1016/S0262-8856(96)01123-7; Wolff LB, 1998, INT J COMPUT VISION, V30, P55, DOI 10.1023/A:1008017513536; WOLFF LB, 1989, P SPIE C OPT ILL IM, V1194, P287; WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zickler TE, 2002, INT J COMPUT VISION, V49, P215, DOI 10.1023/A:1020149707513	43	56	61	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					2001	2017		10.1109/TPAMI.2007.1099	http://dx.doi.org/10.1109/TPAMI.2007.1099			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848780	Green Submitted			2022-12-18	WOS:000249343900010
J	Rahtu, E; Salo, M; Heikkila, J				Rahtu, Esa; Salo, Mikko; Heikkila, Janne			A new convexity measure based on a probabilistic interpretation of images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape analysis; object classification; affine invariance		In this paper, we present a novel convexity measure for object shape analysis. The proposed method is based on the idea of generating pairs of points from a set and measuring the probability that a point dividing the corresponding line segments belongs to the same set. The measure is directly applicable to image functions representing shapes and also to gray-scale images which approximate image binarizations. The approach introduced gives rise to a variety of convexity measures which make it possible to obtain more information about the object shape. The proposed measure turns out to be easy to implement using the Fast Fourier Transform and we will consider this in detail. Finally, we illustrate the behavior of our measure in different situations and compare it to other similar ones.	Univ Oulu, Machine Vis Grp, Dept Elect & Informat Engn, Oulu 90014, Finland; Univ Helsinki, Dept Math & Stat, Rolf Nevanlinna Inst, FIN-00014 Helsinki, Finland	University of Oulu; University of Helsinki	Rahtu, E (corresponding author), Univ Oulu, Machine Vis Grp, Dept Elect & Informat Engn, POB 4500, Oulu 90014, Finland.	erahtu@ee.oulu.fi; msa@rni.helsinki.fi; jth@ee.oulu.fi		Rahtu, Esa/0000-0001-8767-0864				[Anonymous], 2001, SHAPE ANAL CLASSIFIC; BOXER L, 1993, PATTERN RECOGN LETT, V14, P163, DOI 10.1016/0167-8655(93)90067-N; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; Frigo M, 1998, INT CONF ACOUST SPEE, P1381; Heikkila J, 2002, INT C PATT RECOG, P119, DOI 10.1109/ICPR.2002.1044627; HELD A, 1994, PATTERN RECOGN LETT, V15, P611, DOI 10.1016/0167-8655(94)90022-1; Hyde S., 1997, LANGUAGE SHAPE; Lee TK, 2003, MED IMAGE ANAL, V7, P47, DOI 10.1016/S1361-8415(02)00090-7; Lehmann E. L., 1998, NONPARAMETRICS STAT; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; POPOV AT, 1996, P 13 INT C PATT REC, V2, P611; Rahtu E, 2005, IEEE T PATTERN ANAL, V27, P908, DOI 10.1109/TPAMI.2005.111; Rahtu E, 2004, INT C PATT RECOG, P692, DOI 10.1109/ICPR.2004.1334271; RONNEBERGER O, 2005, AEROBIOLOGIA, V18, P107; Rosin PL, 2004, INT C PATT RECOG, P11, DOI 10.1109/ICPR.2004.1333693; Rudin W, 1987, REAL COMPLEX ANAL; STERN HI, 1989, PATTERN RECOGN LETT, V10, P229, DOI 10.1016/0167-8655(89)90093-7; Valentine F.A., 1964, CONVEX SETS; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Zunic J, 2004, IEEE T PATTERN ANAL, V26, P923, DOI 10.1109/TPAMI.2004.19	21	56	60	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2006	28	9					1501	1512		10.1109/TPAMI.2006.175	http://dx.doi.org/10.1109/TPAMI.2006.175			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	062NC	16929735				2022-12-18	WOS:000238950800012
J	Matei, B; Shan, Y; Sawhney, HS; Tan, Y; Kumar, R; Huber, D; Hebert, M				Matei, B; Shan, Y; Sawhney, HS; Tan, Y; Kumar, R; Huber, D; Hebert, M			Rapid object indexing using locality sensitive hashing and joint 3D-signature space estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						three-dimensional object recognition; hashing; indexing; pose estimation; approximate nearest neighbor	REPRESENTATION SCHEME; REGISTRATION; RECOGNITION; SIGNATURES	We propose a new method for rapid 3D object indexing that combines feature-based methods with coarse alignment-based matching techniques. Our approach achieves a sublinear complexity on the number of models, maintaining at the same time a high degree of performance for real 3D sensed data that is acquired in largely uncontrolled settings. The key component of our method is to first index surface descriptors computed at salient locations from the scene into the whole model database using the Locality Sensitive Hashing (LSH), a probabilistic approximate nearest neighbor method. Progressively complex geometric constraints are subsequently enforced to further prune the initial candidates and eliminate false correspondences due to inaccuracies in the surface descriptors and the errors of the LSH algorithm. The indexed models are selected based on the MAP rule using posterior probability of the models estimated in the joint 3D-signature space. Experiments with real 3D data employing a large database of vehicles, most of them very similar in shape, containing 1,000,000 features from more than 365 models demonstrate a high degree of performance in the presence of occlusion and obscuration, unmodeled vehicle interiors and part articulations, with an average processing time between 50 and 100 seconds per query.	Sarnoff Corp, Vis Technol Lab, Princeton, NJ 08540 USA; Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Sarnoff Corporation; Carnegie Mellon University	Matei, B (corresponding author), Sarnoff Corp, Vis Technol Lab, 201 Washington Rd, Princeton, NJ 08540 USA.	bmatei@sarnoff.com; yshan@sarnoff.com; hsawhney@sarnoff.com; ytan@sarnoff.com; rkumar@sarnoff.com; dhuber@cs.cmu.edu; hebert@ri.cmu.edu						ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Bawa Mayank, 2005, P 14 INT C WORLD WID, P651, DOI DOI 10.1145/1060745.1060840; BESL P, 1992, IEEE T PATTERN ANAL, V18, P540; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; Delingette H., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P103, DOI 10.1109/ICCV.1993.378230; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FROME A, 2004, P EUR C COMP VIS MAY; Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Grimson W. E. L., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P334, DOI 10.1109/ICCV.1990.139544; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HUBER D, 2004, CVPR, V2, P82; Indyk P, 1998, P 30 S THEOR COMP; Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P213, DOI 10.1109/IM.1997.603868; Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; KESELMAN Y, 2003, P IEEE C COMP VIS PA; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; Lamdan Y., 1988, P IEEE INT C COMP VI, P238; LOWE DG, 1999, P INT C COMP VIS, P525; Matei B, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.854727; Medioni G., 2000, COMPUTATIONAL FRAMEW; Mori G, 2001, PROC CVPR IEEE, P723; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Nister D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P199; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; RIGOUTSOS I, 1995, COMPUT VIS IMAGE UND, V62, P11, DOI 10.1006/cviu.1995.1038; Ruiz-Correa S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1126; Ruiz-Correa S, 2001, COMPUTER VISION PATT, V1, P769; SHAN Y, 2004, P EUR C COMP VIS, V3, P442; SHAN Y, 2004, COMPUTER VISION PATT; Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Yamany SM, 2002, IEEE T PATTERN ANAL, V24, P1105, DOI 10.1109/TPAMI.2002.1023806; ZHANG D, 1999, P IEEE C COMP VIS PA	40	56	58	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2006	28	7					1111	1126		10.1109/TPAMI.2006.148	http://dx.doi.org/10.1109/TPAMI.2006.148			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	041AG	16792100				2022-12-18	WOS:000237424400008
J	Wu, Y; Lin, J; Huang, TS				Wu, Y; Lin, J; Huang, TS			Analyzing and capturing articulated hand motion in image sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion; tracking; video analysis; statistical computing; probabilistic algorithms; face and gesture recognition		Capturing the human hand motion from video involves the estimation of the rigid global hand pose as well as the nonrigid finger articulation. The complexity induced by the high degrees of freedom of the articulated hand challenges many visual tracking techniques. For example, the particle filtering technique is plagued by the demanding requirement of a huge number of particles and the phenomenon of particle degeneracy. This paper presents a novel approach to tracking the articulated hand in video by learning and integrating natural hand motion priors. To cope with the finger articulation, this paper proposes a powerful sequential Monte Carlo tracking algorithm based on importance sampling techniques, where the importance function is based on an initial manifold model of the articulation configuration space learned from motion-captured data. In addition, this paper presents a divide-and-conquer strategy that decouples the hand poses and finger articulations and integrates them in an iterative framework to reduce the complexity of the problem. Our experiments show that this approach is effective and efficient for tracking the articulated hand. This approach can be extended to track other articulated targets.	Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA; Proximex Corp, Cupertino, CA 95014 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA; Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA	Northwestern University; University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign	Wu, Y (corresponding author), Northwestern Univ, Dept Elect & Comp Engn, 2145 Sheridan Rd, Evanston, IL 60208 USA.	yingwu@ece.northwestern.edu; john.lin@proximex.com; huang@ifp.uiuc.edu	Wu, Ying/B-7283-2009					Athitsos V, 2003, PROC CVPR IEEE, P432; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422; BREGLER C, 1995, ADV NEURAL INF PROCE, V7; CHAM TJ, 1999, P COMP VIS PATT REC, V2, P239; Chao E.Y., 1989, BIOMECHANICS HAND BA; Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758; Doucet A., 2001, SEQUENTIAL MONTE CAR; Heap T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P344, DOI 10.1109/ICCV.1998.710741; Heap T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P140, DOI 10.1109/AFGR.1996.557255; HOWE N, 2000, P NEURAL INF PROCESS; ISARD M, 1998, P EUR C COMP VIS, V1, P767; ISARD M, 1996, P EUR C COMP VIS, P343; Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241; KUCH JJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P666, DOI 10.1109/ICCV.1995.466875; LEE JT, 1995, IEEE COMPUT GRAPH, V15, P77, DOI 10.1109/38.403831; Lin J, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P99, DOI 10.1109/MOTION.2002.1182220; LIN J, 2004, THESIS U ILLINOIS UR; LIU J, 2000, SEQUENTIAL MONTE CAR; Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847; Lu S, 2003, PROC CVPR IEEE, P443; MACCORMICK J, 2000, P EUR C COMP VIS, V2, P3; MULDER A, 1998, THESIS S FRASER U CA; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; Rosales R, 2000, PROC CVPR IEEE, P721, DOI 10.1109/CVPR.2000.854946; Segen J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P479, DOI 10.1109/CVPR.1999.786981; Shimada N, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P268, DOI 10.1109/AFGR.1998.670960; SHIMADA N, 2000, P 15 INT C PATT REC, V3, P709; Stenger B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1063; Stenger B, 2001, PROC CVPR IEEE, P310; SUDDERTH E, 2004, P WORKSH GEN MODEL B; THAYANANTHAN A, 2003, P BRIT MACH VIS C, V2, P589; Tomasi C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1441; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Triesch J, 2002, IMAGE VISION COMPUT, V20, P937, DOI 10.1016/S0262-8856(02)00100-2; Wu Y, 2003, PROC CVPR IEEE, P295; Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P426, DOI 10.1109/ICCV.2001.937656; Wu Y, 2001, IEEE SIGNAL PROC MAG, V18, P51; Wu Y, 2000, PROC CVPR IEEE, P88, DOI 10.1109/CVPR.2000.854749; Wu Y., 1999, P IEEE INT C COMP VI, P606; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	42	56	60	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1910	1922		10.1109/TPAMI.2005.233	http://dx.doi.org/10.1109/TPAMI.2005.233			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16355659	Green Submitted			2022-12-18	WOS:000232532600006
J	Werman, M; Keren, D				Werman, M; Keren, D			A Bayesian method for fitting parametric and nonparametric models to noisy data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian fitting; parametric models; nonparametric models	CURVE	We present a simple paradigm for fitting models, parametric and nonparametric, to noisy data, which resolves some of the problems associated with classical MSE algorithms. This is done by considering each point on the model as a possible source for each data point. The paradigm can be used to solve problems which are ill-posed in the classical MSE approach, such as fitting a segment las opposed to a line). It is shown to be nonbiased and to achieve excellent results for general curves, even in the presence of strong discontinuities. Results are shown for a number of fitting problems, including lines, circles, elliptic arcs, segments, rectangles, and general curves, contaminated by Gaussian and uniform noise.	Hebrew Univ Jerusalem, Inst Comp Sci, IL-91904 Jerusalem, Israel; Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel	Hebrew University of Jerusalem; University of Haifa	Werman, M (corresponding author), Hebrew Univ Jerusalem, Inst Comp Sci, IL-91904 Jerusalem, Israel.	werman@cs.huji.ac.il; dkeren@cs.haifa.ac.il						Cheng CL, 1998, J ROY STAT SOC B, V60, P189, DOI 10.1111/1467-9868.00118; Durbin R, 1989, NEURAL COMPUT, V1, P348, DOI 10.1162/neco.1989.1.3.348; Fitzgibbon A. W., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P253, DOI 10.1109/ICPR.1996.546029; GULL S, 1908, MAXIMUM ENTROPY BAYE, P511; Keren D., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P93, DOI 10.1109/ICPR.1990.118071; Keren D, 1999, J MATH IMAGING VIS, V11, P27, DOI 10.1023/A:1008317210576; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; KEREN D, 1993, IEEE T PATTERN ANAL, V15, P982, DOI 10.1109/34.254057; KIRYATI N, 1992, IEEE T PATTERN ANAL, V14, P496, DOI 10.1109/34.126810; Leedan Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P733, DOI 10.1109/ICCV.1998.710799; PNUELI Y, 1994, PATTERN RECOGN LETT, V15, P329, DOI 10.1016/0167-8655(94)90080-9; Press WH., 1980, NUMERICAL RECIPES FO; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; Shekarforoush H, 1996, INT J COMPUT VISION, V19, P289, DOI 10.1007/BF00055148; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; TENEBAUM JB, 1998, ADV NEURAL INFORMATI; Vosselman G, 1996, P WORKSH PERF CHAR V; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P207, DOI 10.1109/34.368167; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2	20	56	63	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2001	23	5					528	534		10.1109/34.922710	http://dx.doi.org/10.1109/34.922710			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431QA		Green Submitted			2022-12-18	WOS:000168641000008
J	Wakahara, T; Kimura, Y; Tomono, A				Wakahara, T; Kimura, Y; Tomono, A			Affine-invariant recognition of gray-scale characters using global affine transformation correlation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	15th International Conference on Pattern Recognition	SEP 03-08, 2000	BARCELONA, SPAIN			gray-scale character recognition; normalized cross-correlation; global affine transformation; noise-tolerant and affine-invariant image matching; successive iteration method	NORMALIZATION; EXTRACTION; FEATURES; LINE	This paper describes a new, promising technique of gray-scale character recognition that offers both noise tolerance and affine-invariance. The key ideas are twofold. First is the use of normalized cross-correlation as a matching measure to realize noise tolerance. Second is the application of global affine transformation (GAT) to the input image so as to achieve affine-invariant correlation with the target image. In particular, optimal GAT is efficiently determined by the successive iteration method using topographic features of gray-scale images as matching constraints. We demonstrate the high matching ability of the proposed GAT correlation method using gray-scale images of numerals subjected to random Gaussian noise and a wide range of affine transformation. Moreover, extensive recognition experiments show that the achieved recognition rate of 94.3 percent against rotation within 30 degrees, scale change within 30 percent, and translation within 20 percent of the character width along with random Gaussian noise is sufficiently high compared to the 42.8 percent offered by simple correlation.	NTT Corp, NTT Cyber Solut Labs, Yokosuka, Kanagawa 2390847, Japan; NTT Corp, NTT Serv Integrat Labs, Musashino, Tokyo 1808585, Japan; Tokai Univ, Fac Engn, Dept Elect, Hiratsuka, Kanagawa 2591292, Japan	Nippon Telegraph & Telephone Corporation; Nippon Telegraph & Telephone Corporation; Tokai University	Wakahara, T (corresponding author), NTT Corp, NTT Cyber Solut Labs, 1-1 Hikari No Oka, Yokosuka, Kanagawa 2390847, Japan.	waka@marsh.hil.ntt.co.jp; kimura.yoshimasa@lab.ntt.co.jp; tomono@keyaki-cc.u-tokai.ac.jp						DUDA RO, 1973, PATTERN CLASSIFICATI, pCH7; Ha TM, 1997, IEEE T PATTERN ANAL, V19, P535, DOI 10.1109/34.589216; Iijima T., 1973, PATTERN RECOGN; LEE SW, 1995, IEEE T PATTERN ANAL, V17, P724, DOI 10.1109/34.391416; Lee SW, 1996, IEEE T PATTERN ANAL, V18, P1045, DOI 10.1109/34.541415; *MATH SOC JAP, 1977, ENC DICT MATH; ROSENFELD A, 1982, DIGITAL PICTURE PROC, pCH4; Sawaki M, 1996, IEICE T INF SYST, VE79D, P491; Simard P., 1993, ADV NEURAL INFORMATI, V5, P50; Suzuki M, 1996, IEICE T INF SYST, VE79D, P504; Uenohara M, 1997, IEEE T PATTERN ANAL, V19, P891, DOI 10.1109/34.608291; Wakahara T, 1998, IEEE T PATTERN ANAL, V20, P1332, DOI 10.1109/34.735806; Wakahara T., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P613, DOI 10.1109/ICDAR.1999.791862; WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062; YAMADA H, 1990, PATTERN RECOGN, V23, P1023, DOI 10.1016/0031-3203(90)90110-7; YASUDA Y, 1993, P 2 INT C DOC AN REC, P830	16	56	60	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2001	23	4					384	395		10.1109/34.917573	http://dx.doi.org/10.1109/34.917573			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	421MJ					2022-12-18	WOS:000168067900004
J	Chaudhuri, BB; Pal, U				Chaudhuri, BB; Pal, U			Skew angle detection of digitized Indian script documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document processing; skew detection; optical character recognition (OCR); document structure analysis; digital library	SYSTEM; IMAGES	Skew angle detection of scanned documents containing most popular Indian scripts (Devnagari and Bangla) is considered. Most characters in these scripts have horizontal lines at the top, called headlines. The character head lines mostly join one another in a word and the word appears as a single component. In the proposed method the components are at first labeled. The upper envelope of a component is found by columnwise scanning from an imaginary line above the component. Portions of upper envelope satisfying the properties of digital straight line are detected. They are clustered as belonging to single text lines. Estimates from individual clusters are combined to get the skew angle. Apart from accuracy and efficiency, an advantage of the method is that character segmentation and zone detection can be readily done from head line information, which is useful in Optical Character Recognition approaches of these scripts.			Chaudhuri, BB (corresponding author), INDIAN STAT INST,COMP VIS & PATTERN RECOGNIT UNIT,203 BT RD,CALCUTTA 35,W BENGAL,INDIA.		Pal, Umapada/AAC-4930-2022					AKIYAMA T, 1990, PATTERN RECOGN, V23, P1141, DOI 10.1016/0031-3203(90)90112-X; BAIRD HS, 1987, P SOC PHOTOGRAPHIC S, V40, P21; Chaudhuri B.B., 1995, J ACOUST SOC INDIA, V23, P67; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; HASHIZUME A, 1986, PATTERN RECOGN LETT, V4, P125, DOI 10.1016/0167-8655(86)90034-6; HINDS SC, 1990, P 10 INT C PATT REC, V1, P464; HOU HS, 1983, DIGITAL DOCUMENT PRO; LE DS, 1994, PATTERN RECOGN, V27, P1325, DOI 10.1016/0031-3203(94)90068-X; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; Pal U, 1996, PATTERN RECOGN LETT, V17, P899, DOI 10.1016/0167-8655(96)00042-6; PAL U, 1995, INT J SYST SCI, V26, P2107, DOI 10.1080/00207729508929157; PAVLIDIS T, 1992, CVGIP-GRAPH MODEL IM, V54, P484, DOI 10.1016/1049-9652(92)90068-9; POSTL W, 1986, P 8 INT C PATT REC, P464; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; Srihari S. N., 1989, Machine Vision and Applications, V2, P141, DOI 10.1007/BF01212455; WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647; YAN H, 1993, CVGIP-GRAPH MODEL IM, V55, P538, DOI 10.1006/cgip.1993.1041	17	56	67	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					182	186		10.1109/34.574803	http://dx.doi.org/10.1109/34.574803			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800014
J	Etemad, K; Doermann, D; Chellappa, R				Etemad, K; Doermann, D; Chellappa, R			Multiscale segmentation of unstructured document pages using soft decision integration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document processing; multiscale analysis; context dependent classification; soft decision integration; wavelet packets; neural networks	CLASSIFICATION	We present an algorithm for layout-independent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information. Multiscale feature vectors are classified locally using a neural network to allow soft/fuzzy multi-class membership assignments. Segmentation is performed by integrating soft local decision vectors to reduce their ''ambiguities.''	UNIV MARYLAND, INST ADV COMP STUDIES, COLLEGE PK, MD 20742 USA	University System of Maryland; University of Maryland College Park	Etemad, K (corresponding author), UNIV MARYLAND, CTR AUTOMAT RES, LANGUAGE & MEDIA PROC LAB, COLLEGE PK, MD 20742 USA.		Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020					ANTONACOPOULOS A, 1994, INT C PATT RECOG, P339, DOI 10.1109/ICPR.1994.576932; Bezdek J.C., 1992, FUZZY MODELS PATTERN; COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; ETEMAD K, 1994, IEEE IMAGE PROC, P441, DOI 10.1109/ICIP.1994.413768; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; FUKUNAGA K, 1990, INTRO STATISTICAL PA; Jain A. K., 1992, Machine Vision and Applications, V5, P169, DOI 10.1007/BF02626996; Kosko B, 1992, NEURAL NETWORKS FUZZ; PAVLIDIS T, 1992, CVGIP-GRAPH MODEL IM, V54, P484, DOI 10.1016/1049-9652(92)90068-9; PAVLIDIS T, 1991, 1ST P INT C DOC AN R, P945; RANDRIAMASY S, 1994, P CVPR, P441; VISWANATHAN M, 1992, SPIE, V1661, P6; WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4; WANG D, 1989, COMPUT VISION GRAPH, V47, P327, DOI 10.1016/0734-189X(89)90116-3; Yanikoglu B. A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P601, DOI 10.1109/ICDAR.1995.601968	16	56	64	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					92	96		10.1109/34.566817	http://dx.doi.org/10.1109/34.566817			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528					2022-12-18	WOS:A1997WE52800012
J	ZHANG, ZY				ZHANG, ZY			ESTIMATING MOTION AND STRUCTURE FROM CORRESPONDENCES OF LINE SEGMENTS BETWEEN 2 PERSPECTIVE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MOTION; STRUCTURE FROM MOTION; LINE SEGMENTS; EPIPOLAR GEOMETRY; PERSPECTIVE IMAGES; OVERLAP; DYNAMIC SCENE ANALYSIS	ALGORITHM; OBJECTS	We present in this paper an algorithm for determining 3D motion and structure from correspondences of line segments between two perspective images. To our knowledge, this paper is the first investigation of use of line segments in motion and structure from motion. Classical methods use their geometric abstraction, namely straight lines, but then three images are necessary for the motion and structure determination process. In this paper we show that it is possible to recover motion from two views when using line segments. The assumption we use is that two matched line segments contain the projection of a common part of the corresponding line segment in space, i.e., they overlap. Indeed, this is what we use to match line segments between different views. This assumption constrains the possible motion between two views to an open set in motion parameter space. A heuristic, consisting of maximizing the overlap, leads to a unique solution. Both synthetic and real data have been used to test the proposed algorithm, and excellent results have been obtained with real data containing a relatively large set of line segments.			ZHANG, ZY (corresponding author), INRIA SOPHIA ANTIPOLIS, 2004 ROUTE LUCIOLES, BP 93, F-06902 SOPHIA ANTIPOLIS, FRANCE.							AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; AYACHE N, 1987, 1ST P INT C COMP VIS, P422; Ballard D.H., 1982, COMPUTER VISION; CHENG JK, 1984, PATTERN RECOGN, V17, P149, DOI 10.1016/0031-3203(84)90042-6; DERICHE R, 1990, 1ST P EUR C COMP VIS, P259; FAUGERAS OD, 1986, JUN P IEEE C COMP VI, P15; FAUGERAS OD, 1992, LECTURE NOTES COMPUT, V588, P563; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; GIAICHECA B, 1993, 2113 INRIA TECHN REP; GIRAUDON G, 1987, INRIA605 RAPP RECH; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; LIU YC, 1988, COMPUT VISION GRAPH, V44, P35, DOI 10.1016/S0734-189X(88)80030-6; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LUONG QT, 1992, THESIS U PARIS 11 OR; Maybank S., 1992, THEORY RECONSTRUCTIO; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SPETSAKIS M, 1989, CARTR482 COMP VIS LA; SPETSAKIS ME, 1990, INT J COMPUT VISION, V4, P171, DOI 10.1007/BF00054994; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VIEVILLE T, IN PRESS INT J COMPU, V17; ZHANG Z, 1992, 3D DYNAMIC SCENE ANA; ZHANG Z, 1994, 2340 INRIA RES REP	25	56	63	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1129	1139						11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500001
J	BENI, G; LIU, XM				BENI, G; LIU, XM			A LEAST BIASED FUZZY CLUSTERING METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CLUSTERING; FUZZY CLUSTERING; MAXIMUM ENTROPY PRINCIPLE; CLUSTER VALIDITY		A new operational definition of cluster is proposed, and a fuzzy clustering algorithm with minimal biases is formulated by making use of the Maximum Entropy Principle to maximize the entropy of the centroids with respect to the data points (clustering entropy). We make no assumptions on the number of clusters or their initial positions. For each value of an adimensional scale parameter beta', the clustering algorithm makes each data point iterate towards one of the cluster's centroids, so that both hard and fuzzy partitions are obtained. Since the clustering algorithm can make a multiscale analysis of the given data set we can obtain both hierarchy and partitioning type clustering. The relative stability with respect to beta' of each cluster structure is defined as the measurement of cluster validity. We determine the specific value of beta' which corresponds to the optimal positions of cluster centroids by minimizing the entropy of the data points with respect to the centroids (clustered entropy). Examples are given to show how this least-biased method succeeds in getting perceptually correct clustering results.			BENI, G (corresponding author), UNIV CALIF RIVERSIDE,COLL ENGN,RIVERSIDE,CA 92521, USA.							[Anonymous], 1974, CLUSTER ANAL; [Anonymous], 1988, ALGORITHM CLUSTERING; BALL GH, 1965, AD699616; BENI G, UNPUB EFFICIENCY COM; Bezdek J.C., 1973, FUZZY MATH PATTERN C; DUBES R, 1976, PATTERN RECOGN, V8, P247, DOI 10.1016/0031-3203(76)90045-5; DUDA RO, 1974, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; GATH I, 1989, IEEE T PATTERN ANAL, V6, P721; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; JAMES M, 1985, CLASSIFICATION ALGOR, pCH7; Jaynes E.T., 1989, PAPERS PROBABILITY S; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; MATTHEWS G, 1991, IEEE T PATTERN ANAL, V13, P175, DOI 10.1109/34.67646; ROSE K, 1990, PATTERN RECOGN LETT, V11, P589, DOI 10.1016/0167-8655(90)90010-Y; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677	16	56	59	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					954	960		10.1109/34.310694	http://dx.doi.org/10.1109/34.310694			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802					2022-12-18	WOS:A1994PE80200014
J	XU, JN				XU, JN			DECOMPOSITION OF CONVEX POLYGONAL MORPHOLOGICAL STRUCTURING ELEMENTS INTO NEIGHBORHOOD SUBSETS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE PROCESSING; MATHEMATICAL MORPHOLOGY; NEIGHBORHOOD PROCESSING; OPTIMAL DECOMPOSITION; PARALLEL IMAGE COMPUTERS; PARALLEL IMPLEMENTATION; STRUCTURING ELEMENT DECOMPOSITION	PROCESSOR	Mathematical morphology provides an effective tool for image analysis. Many parallel image computers support basic morphological operations. To efficiently implement morphological operations on a parallel computer, a structuring element often needs to be decomposed into smaller structuring element that can be easily handled by the particular machine. In this paper, we discuss the decomposition of convex polygon-shaped structuring elements into neighborhood subsets. Such decompositions will lead to efficient implementation of corresponding morphological operations on neighborhood-processing-based parallel image computers. It is proved in this paper that all convex polygons are decomposable. Efficient decomposition algorithms are developed for different machine structures. An O(1) time algorithm, with respect to the image size, is developed for the four-neighbor-connected mesh machines; a linear time algorithm for determining the optimal decomposition is provided for the machines that can quickly perform 3 x 3 morphological operations.			XU, JN (corresponding author), GLASSBORO STATE COLL,DEPT COMP SCI,GLASSBORO,NJ 08028, USA.							BATCHER KE, 1980, IEEE T COMPUT, V29, P836, DOI 10.1109/TC.1980.1675684; CANTONI V, 1988, P IEEE, V76; DUFF MJB, 1973, PATTERN RECOGNITION, V5; FREEMAN H, 1974, COMPUTER SURVEYS, V6; Giardina C., 1988, MORPHOLOGICAL METHOD; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; MATHERON G., 1975, RANDOM SETS INTEGRAL; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; REEVES AP, 1980, IEEE T COMPUT, V29, P278, DOI 10.1109/TC.1980.1675566; REEVES AP, 1984, COMPUT VISION GRAPH, V25, P68, DOI 10.1016/0734-189X(84)90049-5; Serra J, 1982, IMAGE ANAL MATH MORP; STERNBERG SR, 1983, COMPUTER, V16, P22, DOI 10.1109/MC.1983.1654163; STERNBERG SR, 1982, BIOMEDICAL IMAGES CO, P294; XU J, 1989, JUN P IEEE COMP SOC; ZHUANG XH, 1986, COMPUT VISION GRAPH, V35, P370, DOI 10.1016/0734-189X(86)90006-X	15	56	56	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1991	13	2					153	162		10.1109/34.67644	http://dx.doi.org/10.1109/34.67644			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EY699					2022-12-18	WOS:A1991EY69900004
J	FUKUNAGA, K; HAYES, RR				FUKUNAGA, K; HAYES, RR			ESTIMATION OF CLASSIFIER PERFORMANCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											FUKUNAGA, K (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P873, DOI 10.1109/34.31448; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HAN CP, 1970, I STATIST MATH ANN, V2, P117; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; Jain A.K., 1982, HDB STAT, P835, DOI 10.1016/S0169-7161(82)02042-2; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628, DOI 10.1109/TPAMI.1987.4767957; JOHN S, 1961, ANN MATH STAT, V32, P1125, DOI 10.1214/aoms/1177704851; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; MCLACHLAN GJ, 1975, AUST J STAT, V17, P161, DOI 10.1111/j.1467-842X.1975.tb00953.x; NOVAK LM, 1984, 18TH P AS C CIRC SYS, P5; Raudys S., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P280; Raudys S, 1980, IEEE Trans Pattern Anal Mach Intell, V2, P242, DOI 10.1109/TPAMI.1980.4767011; TOUSSAINT GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260	15	56	56	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1989	11	10					1087	1101		10.1109/34.42839	http://dx.doi.org/10.1109/34.42839			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR689					2022-12-18	WOS:A1989AR68900006
J	XIA, Y				XIA, Y			SKELETONIZATION VIA THE REALIZATION OF THE FIRE FRONTS PROPAGATION AND EXTINCTION IN DIGITAL BINARY SHAPES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV PARIS,INST PROGRAMMAT,LAFORIA,F-75230 PARIS,FRANCE	UDICE-French Research Universities; Universite Paris Cite								ARCELLI C, 1981, COMPUT VISION GRAPH, V17, P130, DOI 10.1016/0146-664X(81)90021-6; ARCELLI C, 1985, IEEE T PATTERN ANAL, V7; BLUM H, 1964, TRAMSFORMATION EXTRA; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V11, P123, DOI 10.1016/0146-664X(79)90062-5; BORGEFORSG, 1986, 8TH P ICPR PAR, P336; Born M., 1975, PRINCIPLES OPTICS, VFifth; CALABI L, 1968, AM MATH MON, V75, P335, DOI 10.2307/2313409; DORSTL, 1986, 8TH P ICRP PAR, P286; Duda R.O., 1973, J ROYAL STAT SOC SER; Hilditch C.J., 1969, MACH INTELL, P403; LEVNE D, 1984, VISION MAN MACHINE, pCH10; MATHERON G, ADV MATH MORPHOLOGY; MEYER F, 1985, NOV IEEE P COMP SOC, P470; MONTANARI U, 1969, J ACM, V16, P534, DOI 10.1145/321541.321543; Montanvert A., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P430; MOREAU C, 1985, THESIS U PARIS 6 PAR; NACCACHE NJ, 1984, IEEE T SYST MAN CYB, V14, P409, DOI 10.1109/TSMC.1984.6313233; PAVLIDIS T, 1980, COMPUT VISION GRAPH, V13, P142, DOI 10.1016/S0146-664X(80)80037-2; PAVLIDIS T, 1986, COMPUT VISION GRAPH, V35, P111, DOI 10.1016/0734-189X(86)90128-3; PFLATZ JL, 1972, CACM, V10, P119; ROSENFELD A, 1975, INFORM CONTROL, V29, P286, DOI 10.1016/S0019-9958(75)90448-9; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; Rosenfeld A., 1982, DIGITAL PICTURE PROC; SIMON JC, 1986, 8TH ICRP PAR; SMITH RW, 1987, PATTERN RECOGN, V20, P7, DOI 10.1016/0031-3203(87)90013-6; Suzuki S., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P289; TAMURA H, 1978, 4TH P INT JOINT C PA, P715; TORIWAKI JI, 1981, PROGR PATTERN RECOGN, V1, P189; Xia Y., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P995; XIA Y, 1987, THESIS U PARIS 6 PAR; XIA Y, 1988, 9TH P ICPR ROM; [No title captured]	32	56	60	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1989	11	10					1076	1086		10.1109/34.42838	http://dx.doi.org/10.1109/34.42838			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR689					2022-12-18	WOS:A1989AR68900005
J	KAMGARPARSI, B; KAMGARPARSI, B				KAMGARPARSI, B; KAMGARPARSI, B			EVALUATION OF QUANTIZATION-ERROR IN COMPUTER VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								Beers Y., 1957, INTRO THEORY ERROR, V2; Bevington PR, 1969, DATA REDUCTION ERROR; BLOSTEIN SD, 1987, IEEE T PATTERN ANAL, V9, P752, DOI 10.1109/TPAMI.1987.4767982; BLOSTEIN SD, 1988, IEEE T PATTERN ANAL, V10, P765; HOGG RV, 1983, PROBABILITY STATISTI; Kamgar-Parsi B., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P44, DOI 10.1109/CVPR.1988.196213; KAMGARPARSI B, 1987, P DARPA IMAGE UNDERS, P671; KAMGARPARSI B, UNPUB IEEE T PATTERN; REINGOLD EM, 1977, COMBINATORIAL ALGORI; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8	10	56	61	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					929	940		10.1109/34.35496	http://dx.doi.org/10.1109/34.35496			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800003
J	YESHURUN, Y; SCHWARTZ, EL				YESHURUN, Y; SCHWARTZ, EL			CEPSTRAL FILTERING ON A COLUMNAR IMAGE ARCHITECTURE - A FAST ALGORITHM FOR BINOCULAR STEREO SEGMENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NYU MED CTR,DEPT PSYCHIAT,COMPUTAT NEUROSCI LABS,NEW YORK,NY 10016; NYU,COURANT INST MATH SCI,DEPT COMP SCI,NEW YORK,NY 10012	New York University; New York University	YESHURUN, Y (corresponding author), TEL AVIV UNIV,DEPT COMP SCI,IL-69978 TEL AVIV,ISRAEL.							ALMGREN FA, 1986, HDB PERCEPTION HUMAN; BARNARD S, 1982, COMPUT SURVEYS, V14; Bogert B.P., 1963, P S TIM SER AN, V15, P209; BURT P, 1980, SCIENCE, V208, P615, DOI 10.1126/science.7367885; DOW BM, 1981, EXP BRAIN RES, V44, P213; GOLDMAN PS, 1977, BRAIN RES, V122, P393, DOI 10.1016/0006-8993(77)90453-X; Gonzalez R.C., 1977, DIGITAL IMAGE PROCES; GRIMSON WEL, 1981, IMAGES SURFACES; HORTON JC, 1984, PHILOS T ROY SOC B, V304, P255, DOI 10.1098/rstb.1984.0022; JULESZ B, 1986, VISION RES, V26, P1601, DOI 10.1016/0042-6989(86)90178-1; JULESZ B, 1971, F CYCLOPEAN PERCEPTI; LEVAY S, 1975, J COMP NEUROL, V159, P559, DOI 10.1002/cne.901590408; LIGHT W, 1986, NYU CNSTR586 MED CTR; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; Marr D., 1982, VISION; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; POGGIO GF, 1977, J NEUROPHYSIOL, V40, P1392, DOI 10.1152/jn.1977.40.6.1392; RABINER LR, 1975, THEORY APPLICATION D; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; SCHWARTZ EL, 1986, IEEE COMPUT GRAPH, V6, P36, DOI 10.1109/MCG.1986.276630; SCHWARTZ EL, 1980, BIOL CYBERN, V42, P157; Tyler C. W., 1983, VERGENCE EYE MOVEMEN, P199; TYLER CW, 1975, VISION RES, V15, P583, DOI 10.1016/0042-6989(75)90306-5; VANESSEN DC, 1984, VISION RES, V24, P429, DOI 10.1016/0042-6989(84)90041-5; WOLFSON E, 1986, NYU CNSTR1086 MED CT; YESHURUN Y, 1986, NYU CNSTR1186 MED CT; YESHURUN Y, 1989, COMP NEUROSCIENCE	27	56	56	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1989	11	7					759	767		10.1109/34.192471	http://dx.doi.org/10.1109/34.192471			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AB815		Green Submitted			2022-12-18	WOS:A1989AB81500010
J	STEVENS, RJ; LEHAR, AF; PRESTON, FH				STEVENS, RJ; LEHAR, AF; PRESTON, FH			MANIPULATION AND PRESENTATION OF MULTIDIMENSIONAL IMAGE DATA USING THE PEANO SCAN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											STEVENS, RJ (corresponding author), HOME OFF,SCI RES & DEV BRANCH,ST ALBANS AL4 9HQ,HERTS,ENGLAND.							BUTZ AR, 1971, IEEE T COMPUT, VC 20, P424, DOI 10.1109/T-C.1971.223258; MANDELBROT BB, FRACTALS FORM CHANCE; PATRICK EA, 1968, IEEE T COMPUT    OCT, P949; PEANO G, SELECTED WORKS G PEA; SIMON JC, 1978, CR ACAD SCI PARIS, V286	5	56	66	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					520	526		10.1109/TPAMI.1983.4767431	http://dx.doi.org/10.1109/TPAMI.1983.4767431			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RM118	21869137				2022-12-18	WOS:A1983RM11800008
J	PAL, SK				PAL, SK			A NOTE ON THE QUANTITATIVE MEASURE OF IMAGE-ENHANCEMENT THROUGH FUZZINESS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											PAL, SK (corresponding author), INDIAN STAT INST,ELECT & COMMUNICAT SCI UNIT,CALCUTTA 700035,W BENGAL,INDIA.							[Anonymous], 1975, FUZZY SETS THEIR APP, DOI DOI 10.1016/B978-0-12-775260-0.50021-9; DELUCA A, 1972, INFORM CONTROL, V20, P301, DOI 10.1016/S0019-9958(72)90199-4; Kaufmann A., 1975, INTRO THEORY FUZZY S; PAL SK, 1981, IEEE T SYST MAN CYB, V11, P494; Wang P, 1980, FUZZY SETS THEORY AP	5	56	58	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					204	208		10.1109/TPAMI.1982.4767227	http://dx.doi.org/10.1109/TPAMI.1982.4767227			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869026				2022-12-18	WOS:A1982NE95700016
J	OROURKE, J; BADLER, N				OROURKE, J; BADLER, N			DECOMPOSITION OF 3-DIMENSIONAL OBJECTS INTO SPHERES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											OROURKE, J (corresponding author), UNIV PENN,MOORE SCH ELECT ENGN,DEPT COMP SCI,PHILADELPHIA,PA 19104, USA.							BADLER N, 1978, 1978 P SIGGRAPH, V12, P153; BADLER NI, 1978, 13 U PENNS DEP COMP; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; Blum H., 1964, MODELS PERCEPTION SP, P362; BLUM H, 1977, JUN P IEEE PATT REC, P203; FUCHS H, 1977, COMMUN ACM, V20, P693, DOI 10.1145/359842.359846; MARUYAMA K, 1972, U1UCDCSR72533 U ILL; MONTANARI U, 1969, J ACM, V16, P534, DOI 10.1145/321541.321543; OROURKE J, 1977, THESIS U PENNSYLVANI; SUNGUROFF A, 1978, 1978 P SIGGRAPH, V12, P196	10	56	57	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					295	305		10.1109/TPAMI.1979.4766925	http://dx.doi.org/10.1109/TPAMI.1979.4766925			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868860				2022-12-18	WOS:A1979HC30100007
J	Karras, T; Laine, S; Aila, T				Karras, Tero; Laine, Samuli; Aila, Timo			A Style-Based Generator Architecture for Generative Adversarial Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generators; Convolution; Training; Image resolution; Aerospace electronics; Generative adversarial networks; Interpolation; Generative models; deep learning; neural networks		We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.	[Karras, Tero; Laine, Samuli; Aila, Timo] NVIDIA Corp, Helsinki 00180, Finland	Nvidia Corporation	Laine, S (corresponding author), NVIDIA Corp, Helsinki 00180, Finland.	tkarras@nvidia.com; Blaine@nvidia.com; taila@nvidia.com						Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Achille A, 2018, J MACH LEARN RES, V19; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bau David, 2019, INT C LEARN REPR ICL; Ben-Yosef M., 2018, ARXIV PREPRINT ARXIV; Brock A., 2019, INT C LEARNING REPRE; Chen T.Q., 2018, NEURIPS, P2610; Chen Ting, 2019, ICLR; Chen X, 2016, ADV NEUR IN, V29; Denton E, 2015, DEEP GENERATIVE IMAG, DOI DOI 10.5555/; Desjardins G., 2012, ARXIV12105474; Donahue Jeff, 2017, INT C LEARN REPR ICL; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; DRUCKER H, 1992, IEEE T NEURAL NETWOR, V3, P991, DOI 10.1109/72.165600; Dumoulin V., 2018, FEATURE WISE TRANSFO; Dumoulin Vincent, 2017, ICLR 2017, P4; Dumoulin Vincent, 2016, ARXIV161007629; Durugkar Ishan, 2017, ICLR; Eastwood Cian, 2018, INT C LEARN REPR; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gulrajani I, 2017, P NIPS 2017; Hao GY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2212; Hensel M, 2017, ADV NEUR IN, V30; Higgins I., 2017, P INT C LEARN REPR T; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Kautz Jan, 2018, LECT NOTES COMPUT SC, P172, DOI [DOI 10.1007/978-3-030-01219-9_11, 10.1007/978-3-030-01219-9_11]; Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241; Kim H, 2018, PR MACH LEARN RES, V80; Kingma D.P, P 3 INT C LEARNING R; Kingma D. P, 2014, ARXIV13126114; Kingma Diederik P, 2018, ADV NEURAL INFORM PR; Kudlur M., 2017, P BRIT MACH VIS C BM; Kurach K., 2018, ARXIV180704720; Laine S., 2018, P INT C LEARN REPR; Li YH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2230; Li YJ, 2017, ADV NEUR IN, V30; Lucic M., 2018, ADV NEUR IN, P698; Maas A. L., 2013, P 30 INT C MACH LEAR, P3; Marchesi M., 2017, ABS170600082; Mescheder L, 2018, PR MACH LEARN RES, V80; Miyato Takeru, 2018, ARXIV180205637; Mordido G., 2018, ARXIV180711346; Mukherjee S, 2019, AAAI CONF ARTIF INTE, P4610; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Ridgeway K., 2016, ARXIV161205299; Ros AS, 2018, AAAI CONF ARTIF INTE, P1660; Sainburg T., 2018, ABS180706650; Salimans T., 2016, ADV NEUR IN, P2234; SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P863, DOI 10.1162/neco.1992.4.6.863; Sharma R., 2018, ABS180709295; Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242; Siarohin A., 2019, P INT C LEARN REPR; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Doan T, 2019, AAAI CONF ARTIF INTE, P3470; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; White T., 2016, ARXIV160904468; Yu F., 2015, ARXIVABS150603365 CO; Zhang H, 2019, PR MACH LEARN RES, V97; Zhang R, 2019, PR MACH LEARN RES, V97; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068	64	55	58	36	109	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4217	4228		10.1109/TPAMI.2020.2970919	http://dx.doi.org/10.1109/TPAMI.2020.2970919			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	32012000	Green Submitted			2022-12-18	WOS:000714203900007
J	Luo, WX; Liu, W; Lian, DZ; Tang, JH; Duan, LX; Peng, X; Gao, SH				Luo, Weixin; Liu, Wen; Lian, Dongze; Tang, Jinhui; Duan, Lixin; Peng, Xi; Gao, Shenghua			Video Anomaly Detection with Sparse Coding Inspired Deep Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Anomaly detection; Encoding; Feature extraction; Training; Optimization; Dictionaries; Deep learning; Sparse coding; anomaly detection; stacked recurrent neural networks		This paper presents an anomaly detection method that is based on a sparse coding inspired Deep Neural Networks (DNN). Specifically, in light of the success of sparse coding based anomaly detection, we propose a Temporally-coherent Sparse Coding (TSC), where a temporally-coherent term is used to preserve the similarity between two similar frames. The optimization of sparse coefficients in TSC with the Sequential Iterative Soft-Thresholding Algorithm (SIATA) is equivalent to a special stacked Recurrent Neural Networks (sRNN) architecture. Further, to reduce the computational cost in alternatively updating the dictionary and sparse coefficients in TSC optimization and to alleviate hyperparameters selection in TSC, we stack one more layer on top of the TSC-inspired sRNN to reconstruct the inputs, and arrive at an sRNN-AE. We further improve sRNN-AE in the following aspects: i) rather than using a predefined similarity measurement between two frames, we propose to learn a data-dependent similarity measurement between neighboring frames in sRNN-AE to make it more suitable for anomaly detection; ii) to reduce computational costs in the inference stage, we reduce the depth of the sRNN in sRNN-AE and, consequently, our framework achieves real-time anomaly detection; iii) to improve computational efficiency, we conduct temporal pooling over the appearance features of several consecutive frames for summarizing information temporally, then we feed appearance features and temporally summarized features into a separate sRNN-AE for more robust anomaly detection. To facilitate anomaly detection evaluation, we also build a large-scale anomaly detection dataset which is even larger than the summation of all existing datasets for anomaly detection in terms of both the volume of data and the diversity of scenes. Extensive experiments on both a toy dataset under controlled settings and real datasets demonstrate that our method significantly outperforms existing methods, which validates the effectiveness of our sRNN-AE method for anomaly detection. Codes and data have been released at https://github.com/StevenLiuWen/sRNN_TSC_Anomaly_Detection.	[Luo, Weixin; Liu, Wen; Lian, Dongze; Gao, Shenghua] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China; [Luo, Weixin; Liu, Wen; Lian, Dongze] Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Shanghai 200050, Peoples R China; [Luo, Weixin; Liu, Wen; Lian, Dongze] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Tang, Jinhui] Nanjing Univ Sci & Engn, Sch Comp Sci & Engn, Nanjing 210023, Peoples R China; [Duan, Lixin] Univ Elect Sci & Technol China, Chengdu 610054, Peoples R China; [Peng, Xi] Sichuan Univ, Coll Comp Sci, Chengdu 610017, Peoples R China	ShanghaiTech University; Chinese Academy of Sciences; Shanghai Institute of Microsystem & Information Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; University of Electronic Science & Technology of China; Sichuan University	Gao, SH (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.	luowx@shanghaitech.edu.cn; liuwen@shanghaitech.edu.cn; liandz@shanghaitech.edu.cn; jinhuitang@njust.edu.cn; lxduan@gmail.com; pengx.gm@gmail.com; gaoshh@shanghaitech.edu.cn	于, 于增臣/AAH-4657-2021; liu, wen/HGE-3071-2022; Peng, Xi/B-9002-2012	Tang, Jinhui/0000-0001-9008-222X; Duan, Lixin/0000-0002-0723-4016; , Weixin/0000-0002-0754-6458; Peng, Xi/0000-0002-5727-2790	National Key Research and Development Program of China [2016YFB1001001]; NSFC [61502304]; Fundamental Research Funds for the Central Universities [YJ201949, 2018SCUH0070]; NFSC [61806135]	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); NFSC(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China under Grant 2016YFB1001001 and NSFC (No. 61502304). Also, the work was supported in part by the Fundamental Research Funds for the Central Universities under Grant YJ201949 and 2018SCUH0070, in part by the NFSC under Grant 61806135. Weixin Luo and Wen Liu are the co-first authors.	Abadi M, 2015, P 12 USENIX S OPERAT; Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524; Biswas S, 2013, NAT CONF COMPUT VIS; Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23; Chung JY, 2015, PR MACH LEARN RES, V37, P2067; Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21; Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391; Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315; Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lee H., 2007, ADV NEURAL INF PROCE, P801; Leyva R., 2017, 2017 5 INT WORKSH BI, P1; Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105; Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338; Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45; Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325; Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872; Reddy V, 2011, CVPRW, P55, DOI DOI 10.1109/CVPRW.2011.5981799; Ren H., 2016, COMPREHENSIVE STUDY; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; ROSHTKHARI MJ, 2013, IEEE INT W PERFORM, V117, P1436; Sabokrou M., 2016, ARXIV160900866; Savakis, 2016, THESIS ROCHESTER I T; Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12; Scholkopf B., 2001, LEARNING KERNELS SUP; Simonyan K., 2014, 3 INT C LEARN REPR I; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Soomro K., 2012, ARXIV; Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003; Villegas Ruben, 2017, ICLR, DOI DOI 10.48550/ARXIV.1706.08033; Wang T, 2013, IEEE INT W PERFORM, P45, DOI 10.1109/PETS.2013.6523794; Wisdom S, 2017, INT CONF ACOUST SPEE, P4346, DOI 10.1109/ICASSP.2017.7952977; Xu Dan, 2015, ARXIV151001553; Zhang D, 2005, PROC CVPR IEEE, P611	51	55	55	12	58	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					1070	1084		10.1109/TPAMI.2019.2944377	http://dx.doi.org/10.1109/TPAMI.2019.2944377			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31567072				2022-12-18	WOS:000616309900022
J	Shu, XB; Tang, JH; Qi, GJ; Liu, W; Yang, J				Shu, Xiangbo; Tang, Jinhui; Qi, Guo-Jun; Liu, Wei; Yang, Jian			Hierarchical Long Short-Term Concurrent Memory for Human Interaction Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dynamics; Videos; Logic gates; Deep learning; Task analysis; Pattern recognition; Feeds; Human interaction recognition; long short-term memory; activity recognition; deep learning		In this work, we aim to address the problem of human interaction recognition in videos by exploring the long-term inter-related dynamics among multiple persons. Recently, Long Short-Term Memory (LSTM) has become a popular choice to model individual dynamic for single-person action recognition due to its ability to capture the temporal motion information in a range. However, most existing LSTM-based methods focus only on capturing the dynamics of human interaction by simply combining all dynamics of individuals or modeling them as a whole. Such methods neglect the inter-related dynamics of how human interactions change over time. To this end, we propose a novel Hierarchical Long Short-Term Concurrent Memory (H-LSTCM) to model the long-term inter-related dynamics among a group of persons for recognizing human interactions. Specifically, we first feed each person's static features into a Single-Person LSTM to model the single-person dynamic. Subsequently, at one time step, the outputs of all Single-Person LSTM units are fed into a novel Concurrent LSTM (Co-LSTM) unit, which mainly consists of multiple sub-memory units, a new cell gate, and a new co-memory cell. In the Co-LSTM unit, each sub-memory unit stores individual motion information, while this Co-LSTM unit selectively integrates and stores inter-related motion information between multiple interacting persons from multiple sub-memory units via the cell gate and co-memory cell, respectively. Extensive experiments on several public datasets validate the effectiveness of the proposed H-LSTCM by comparing against baseline and state-of-the-art methods.	[Shu, Xiangbo; Tang, Jinhui; Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China; [Qi, Guo-Jun] Huawei Cloud, Bellevue, WA 98004 USA; [Liu, Wei] Tencent AI Lab, Comp Vis Grp, Shenzhen 518000, Peoples R China	Nanjing University of Science & Technology; Huawei Technologies; Tencent	Tang, JH (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.	shuxb@njust.edu.cn; jinhuitang@njust.edu.cn; guojun.qi@huawei.com; wliu@ee.columbia.edu; csjyang@njust.edu.cn	Shu, Xiangbo/AAC-6245-2022	Shu, Xiangbo/0000-0003-4902-4663; Liu, Wei/0000-0002-3865-8145; Tang, Jinhui/0000-0001-9008-222X	National Key Research and Development Program of China [2016YFB1001001]; National Natural Science Foundation of China [61732007, 61702265, 61672285, 61772268]; National Natural Science Foundation of Jiangsu Province [BK20170856]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Foundation of Jiangsu Province(Natural Science Foundation of Jiangsu Province)	This work was partially supported by theNational Key Research and Development Program of China (Grant No. 2016YFB1001001), the National Natural Science Foundation of China (Grant No. 61732007, 61702265, 61672285, and 61772268), and the National Natural Science Foundation of Jiangsu Province (GrantNo. BK20170856).	Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110; Antic B, 2014, LECT NOTES COMPUT SC, V8689, P33, DOI 10.1007/978-3-319-10590-1_3; Biswas S, 2018, IEEE WINT CONF APPL, P1615, DOI 10.1109/WACV.2018.00180; Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343; Chang XB, 2015, IEEE T IMAGE PROCESS, V24, P1905, DOI 10.1109/TIP.2015.2409564; Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16; Deng ZW, 2016, PROC CVPR IEEE, P4772, DOI 10.1109/CVPR.2016.516; Dengguo Zhang, 2015, 2015 IEEE MTT-S International Microwave Workshop Series on Advanced Materials and Processes for RF and THz Applications (IMWS-AMP). Proceedings, P1, DOI 10.1109/IMWS-AMP.2015.7324911; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Hajimirsadeghi H, 2017, IEEE T PATTERN ANAL, V39, P1839, DOI 10.1109/TPAMI.2016.2613865; Hajimirsadeghi H, 2015, PROC CVPR IEEE, P2596, DOI 10.1109/CVPR.2015.7298875; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Ke Q., 2016, ARXIV PREPRINT ARXIV; Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928; Kong Y, 2016, IEEE T IMAGE PROCESS, V25, P167, DOI 10.1109/TIP.2015.2498410; Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39; Kong Y, 2012, LECT NOTES COMPUT SC, V7572, P300, DOI 10.1007/978-3-642-33718-5_22; Kong Y, 2014, IEEE T PATTERN ANAL, V36, P1775, DOI 10.1109/TPAMI.2014.2303090; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228; Li M., 2016, P 25 INT JOINT C ART, P3654; Li X, 2017, IEEE I CONF COMP VIS, P2895, DOI 10.1109/ICCV.2017.313; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Raptis M, 2013, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2013.342; Robinovitch S. N, 2010, P EUR C COMP VIS, P181; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361; Ryoo MS, 2006, 2006 IEEE COMPUTER S, V2, P1709, DOI DOI 10.1109/CVPR.2006.242; Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41; Shariat S, 2013, IEEE I CONF COMP VIS, P3583, DOI 10.1109/ICCV.2013.445; Shu TM, 2017, PROC CVPR IEEE, P4255, DOI 10.1109/CVPR.2017.453; Shu XB, 2017, IEEE COMPUT SOC CONF, P2176, DOI 10.1109/CVPRW.2017.270; Simonyan K, 2014, ADV NEUR IN, V27; Vahdat A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1729, DOI 10.1109/ICCVW.2011.6130458; Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460; Wang XY, 2017, IEEE T PATTERN ANAL, V39, P1770, DOI 10.1109/TPAMI.2016.2616308; Wang ZH, 2017, IEEE T CIRC SYST VID, V27, P1647, DOI 10.1109/TCSVT.2016.2539699; Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270; Wongun Choi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3273, DOI 10.1109/CVPR.2011.5995707; Wongun Choi, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1282, DOI 10.1109/ICCVW.2009.5457461; Yu T. H., 2010, P BRIT MACH VIS C, P1; Zhang YM, 2012, LECT NOTES COMPUT SC, V7574, P707, DOI 10.1007/978-3-642-33712-3_51	49	55	56	20	99	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					1110	1118		10.1109/TPAMI.2019.2942030	http://dx.doi.org/10.1109/TPAMI.2019.2942030			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31545711	Green Submitted			2022-12-18	WOS:000616309900026
J	Amjad, RA; Geiger, BC				Amjad, Rana Ali; Geiger, Bernhard C.			Learning Representations for Neural Network-Based Classification Using the Information Bottleneck Principle	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Task analysis; Robustness; Cost function; Neurons; Neural networks; Deep learning; information bottleneck; representation learning; regularization; classification; neural networks; stochastic neural networks	DIMENSION	In this theory paper, we investigate training deep neural networks (DNNs) for classification via minimizing the information bottleneck (IB) functional. We show that the resulting optimization problem suffers from two severe issues: First, for deterministic DNNs, either the IB functional is infinite for almost all values of network parameters, making the optimization problem ill-posed, or it is piecewise constant, hence not admitting gradient-based optimization methods. Second, the invariance of the IB functional under bijections prevents it from capturing properties of the learned representation that are desirable for classification, such as robustness and simplicity. We argue that these issues are partly resolved for stochastic DNNs, DNNs that include a (hard or soft) decision rule, or by replacing the IB functional with related, but more well-behaved cost functions. We conclude that recent successes reported about training DNNs using the IB framework must be attributed to such solutions. As a side effect, our results indicate limitations of the IB framework for the analysis of DNNs. We also note that rather than trying to repair the inherent problems in the IB functional, a better approach may be to design regularizers on latent representation enforcing the desired properties directly.	[Amjad, Rana Ali] Tech Univ Munich, Inst Commun Engn, D-80333 Munich, Germany; [Geiger, Bernhard C.] Know Ctr GmbH, A-8010 Graz, Austria	Technical University of Munich	Amjad, RA (corresponding author), Tech Univ Munich, Inst Commun Engn, D-80333 Munich, Germany.	ranaali.amjad@tum.de; geiger@ieee.org		Geiger, Bernhard/0000-0003-3257-743X; Amjad, Rana Ali/0000-0002-0007-4697	German Federal Ministry of Education and Research; Erwin Schrodinger Fellowship of the Austrian Science Fund [J 3765]; Austrian COMET Program -Competence Centers for Excellent Technologies -under Austrian Federal Ministry of Transport, Innovation and Technology; Austrian Federal Ministry of Digital and Economic Affairs; State of Styria	German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF)); Erwin Schrodinger Fellowship of the Austrian Science Fund(Austrian Science Fund (FWF)); Austrian COMET Program -Competence Centers for Excellent Technologies -under Austrian Federal Ministry of Transport, Innovation and Technology; Austrian Federal Ministry of Digital and Economic Affairs; State of Styria	The authors gratefully acknowledge discussions with Artemy Kolchinsky and Brendan Tracey, Santa Fe Institute. We are particularly indebted to Christian Knoll, Graz University of Technology, for his help in making our analysis of representational robustness more clear. This work was supported by the German Federal Ministry of Education and Research in the framework of the Alexander von Humboldt-Professorship. The work of Bernhard C. Geiger has been funded by the Erwin Schrodinger Fellowship J 3765 of the Austrian Science Fund. The Know-Center is funded within the Austrian COMET Program -Competence Centers for Excellent Technologies -under the auspices of the Austrian Federal Ministry of Transport, Innovation and Technology, the Austrian Federal Ministry of Digital and Economic Affairs, and by the State of Styria. COMET is managed by the Austrian Research Promotion Agency FFG.	Achille A, 2018, IEEE T PATTERN ANAL, V40, P2897, DOI 10.1109/TPAMI.2017.2784440; Alemi A. A., 2018, P 35 INT C MACH LEAR; Alemi A. A., 2017, ARXIV171100464; [Anonymous], 2018, J MACH LEARN RES; Arpit D, 2017, PR MACH LEARN RES, V70; Banerjee P. K., 2018, ARXIV181011677V1CSLG; Belharbi S., 2017, ARXIV170901867V4CSLG; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Chang B, 2018, AAAI CONF ARTIF INTE, P2811; Cover TM, 1991, ELEMENTS INFORM THEO; Csiszar I., 1962, ACTA MATH HUNGARICA, V13, P245; DeVries T., 2017, IMPROVED REGULARIZAT; Geiger B. C., 2018, INFORM LOSS DETERMIN; Goldfeld Z., 2018, ARXIV181005728V3CSLG; Goodfellow I., 2016, **DROPPED REF**; Hettinger C., 2017, ARXIV170602480V1CSLG; Hunt BR, 1997, NONLINEARITY, V10, P1031, DOI 10.1088/0951-7715/10/5/002; Jacobsen J.-H., 2018, P 2018 INT C LEARN R; Kolchinsky A., 2018, ARXIV170502436V7CSIT; Kolchinsky A., 2019, P INT C LEARN REPR M; Li H., 2017; Liao R., 2016, P INT C NEUR INF PRO, P5076; Liu K., 2018, THESIS; Mattila P, 2000, STUD MATH, V142, P219, DOI 10.4064/sm-142-3-219-233; Nguyen TP, 2018, MULTIOBJECTIVE DEEP; Novak R., 2018, P INT C LEARN REPR M; Pereyra G., 2017, P INT C LEARN REPR A; Renyi A., 1959, ACTA MATH HUNGARICA, V10, P193; Saxe A. M., 2018, P INT C LEARN REPR M; Shwartz-Ziv R., 2017, PREPRINT; Strouse D. J., 2016, P 32 C UNC ART INT J, P696; Tianxing He, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P245, DOI 10.1109/ICASSP.2014.6853595; Tishby N., 1999, P ALL C COMM CONTR C, P368; Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW); Vera M, 2018, IEEE INT SYMP INFO, P1580; Wu YH, 2015, IEEE T INFORM THEORY, V61, P256, DOI 10.1109/TIT.2014.2366238; Wu YH, 2010, IEEE T INFORM THEORY, V57, P3721, DOI 10.1109/TIT.2010.2050803; Xu H, 2012, MACH LEARN, V86, P391, DOI 10.1007/s10994-011-5268-1; Zahavy T., 2018, P INT C LEARN REPR M; Zhang C., 2017	42	55	56	3	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2225	2239		10.1109/TPAMI.2019.2909031	http://dx.doi.org/10.1109/TPAMI.2019.2909031			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	30951462	Green Submitted			2022-12-18	WOS:000557354900011
J	Baluja, S				Baluja, Shumeet			Hiding Images within Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Containers; Neural networks; Image coding; Image reconstruction; Image color analysis; Training; Receivers; Information hiding; image verification; image trust	PRINCIPAL COMPONENT ANALYSIS; NEURAL-NETWORKS	We present a system to hide a full color image inside another of the same size with minimal quality loss to either image. Deep neural networks are simultaneously trained to create the hiding and revealing processes and are designed to specifically work as a pair. The system is trained on images drawn randomly from the ImageNet database, and works well on natural images from a wide variety of sources. Beyond demonstrating the successful application of deep learning to hiding images, we examine how the result is achieved and apply numerous transformations to analyze if image quality in the host and hidden image can be maintained. These transformation range from simple image manipulations to sophisticated machine learning-based adversaries. Two extensions to the basic system are presented that mitigate the possibility of discovering the content of the hidden image. With these extensions, not only can the hidden information be kept secure, but the system can be used to hide even more than a single image. Applications for this technology include image authentication, digital watermarks, finding exact regions of image manipulation, and storing meta-information about image rendering and content.	[Baluja, Shumeet] Google Inc, Google AI, San Diego, CA 92121 USA	Google Incorporated	Baluja, S (corresponding author), Google Inc, Google AI, San Diego, CA 92121 USA.	shumeet@google.com						Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; [Anonymous], 2017, P INT C LEARN REPR I; [Anonymous], P INT S EL IM SAN FR; [Anonymous], 2017, ICLR; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Balle Johannes, 2018, INT C LEARN REPR ICL; Baluja S, 2008, PATTERN RECOGN, V41, P3467, DOI 10.1016/j.patcog.2008.05.006; Baluja Shumeet, 2017, ADV NEURAL INFORM PR, P2069, DOI DOI 10.5555/3294771.3294968; Boehm B, 2014, CORR; Brandao AS, 2016, IEEE LAT AM T, V14, P1361, DOI 10.1109/TLA.2016.7459621; Chaumont M, 2013, J SYST SOFTWARE, V86, P809, DOI 10.1016/j.jss.2012.11.042; Chaumont M., 2009, RECENT ADV SIGNAL PR, DOI [10.5772/7453, DOI 10.5772/7453]; Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Cohen E, 2001, IEEE T KNOWL DATA EN, V13, P64, DOI 10.1109/69.908981; Cottrell G. W., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V1001, P1070, DOI 10.1117/12.969060; Cox I., 2007, DIGITAL WATER MARKIN; darknet.org.uk, 2014, STEG STEG TOOL DET S; Fridrich J, 2004, PROC SPIE, V5306, P70, DOI 10.1117/12.521353; Fridrich Jessica, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P85, DOI 10.1007/978-3-642-24178-9_7; Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097; Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263; Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3; Friedman W. F., 1918, INTRO METHODS SOLUTI; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goth G, 2005, IEEE DISTRIB SYST ON, V6, P2; Hayat K, 2007, PROC SPIE, V6495, DOI 10.1117/12.703040; Hayes J., 2017, P ADV NEUR INF PROC, V30, P1954; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771; Husien S, 2015, NEURAL COMPUT APPL, V26, P111, DOI 10.1007/s00521-014-1702-1; Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122; Jarusek R, 2018, APPL SOFT COMPUT, V67, P505, DOI 10.1016/j.asoc.2018.03.023; Jarusek R, 2015, ADV INTELL SYST, V378, P317, DOI 10.1007/978-3-319-19824-8_26; Jiang J, 1999, SIGNAL PROCESS-IMAGE, V14, P737, DOI 10.1016/S0923-5965(98)00041-1; Kavitha V, 2004, LECT NOTES ARTIF INT, V3157, P429; Kessler G. C., 2015, OVERVIEW STEGANOGRAP; Kessler GC, 2011, ADV COMPUT, V83, P51, DOI 10.1016/B978-0-12-385510-7.00002-3; Khan Imran, 2010, 2010 International Conference on Emerging Trends in Robotics and Communication Technologies (INTERACT 2010), P46, DOI 10.1109/INTERACT.2010.5706192; Kingma Diederik P., 2015, 3 INT C LEARN REPRES, V3; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Larsen A. B. L., 2015, CORR; Li SJ, 2008, IEEE T CIRC SYST VID, V18, P338, DOI 10.1109/TCSVT.2008.918116; McCullagh Declan, 2001, WIRED; Ozer H, 2003, PROC SPIE, V5020, P55, DOI 10.1117/12.477313; Parikka J., 2017, HIDDEN PLAIN SIGHT S; Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13; Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220; Qamra A, 2005, IEEE T PATTERN ANAL, V27, P379, DOI 10.1109/TPAMI.2005.54; Qian Y., 2015, P SPIE IS T EL IM; Rippel O, 2017, PR MACH LEARN RES, V70; Shi HC, 2018, LECT NOTES COMPUT SC, V10735, P534, DOI 10.1007/978-3-319-77380-3_51; Tamimi AA, 2013, INT J ADV COMPUT SC, V4, P18; Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134; Van de Ville D, 2004, IEEE T CIRC SYST VID, V14, P892, DOI 10.1109/TCSVT.2004.828325; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Volkhonskiy D., 2017, CORR; Wang G, 2012, IEEE T PATTERN ANAL, V34, P2177, DOI 10.1109/TPAMI.2012.29; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Yaghmaee F, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/851920; Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092; Zhang R., 2018, CORR	64	55	57	6	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1685	1697		10.1109/TPAMI.2019.2901877	http://dx.doi.org/10.1109/TPAMI.2019.2901877			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	30835212	hybrid			2022-12-18	WOS:000542967200013
J	Lin, GS; Shen, CH; van den Hengel, A; Reid, I				Lin, Guosheng; Shen, Chunhua; van den Hengel, Anton; Reid, Ian			Exploring Context with Deep Structured Models for Semantic Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantic segmentation; convolutional neural networks; conditional random fields; contextual models	FEATURES	We propose an approach for exploiting contextual information in semantic image segmentation, and particularly investigate the use of patch-patch context and patch-background context in deep CNNs. We formulate deep structured models by combining CNNs and Conditional Random Fields (CRFs) for learning the patch-patch context between image regions. Specifically, we formulate CNN-based pairwise potential functions to capture semantic correlations between neighboring patches. Efficient piecewise training of the proposed deep structured model is then applied in order to avoid repeated expensive CRF inference during the course of back propagation. For capturing the patch-background context, we show that a network design with traditional multi-scale image inputs and sliding pyramid pooling is very effective for improving performance. We perform comprehensive evaluation of the proposed method. We achieve new state-of-the-art performance on a number of challenging semantic segmentation datasets.	[Lin, Guosheng] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore; [Shen, Chunhua; van den Hengel, Anton; Reid, Ian] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Shen, Chunhua; van den Hengel, Anton; Reid, Ian] Australian Ctr Robot Vis, Brisbane, Qld, Australia	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Adelaide; Australian Centre for Robotic Vision	Shen, CH (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.; Shen, CH (corresponding author), Australian Ctr Robot Vis, Brisbane, Qld, Australia.	guosheng.lin@gmail.com; chunhua.shen@adelaide.edu.au; anton.vandenhengel@adelaide.edu.au; ian.reid@adelaide.edu.au	Lin, Guosheng/N-9110-2019	Lin, Guosheng/0000-0002-0329-7458; van den Hengel, Anton/0000-0003-3027-8364; Shen, Chunhua/0000-0002-8648-8718; Reid, Ian/0000-0001-7790-6423	ARC Future Fellowship [FT120100969]; ARC Laureate Fellowship [FL130100102]	ARC Future Fellowship(Australian Research Council); ARC Laureate Fellowship(Australian Research Council)	C. Shen's participation was in part supported by an ARC Future Fellowship (FT120100969). I. Reid's participation was in part supported by an ARC Laureate Fellowship (FL130100102). This work was done when G. Lin was with The University of Adelaide and Australian Centre for Robotic Vision.	[Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26; BESAG J, 1977, BIOMETRIKA, V64, P616, DOI 10.1093/biomet/64.3.616; Cadena C, 2014, IEEE INT CONF ROBOT, P2639, DOI 10.1109/ICRA.2014.6907237; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Chen L.-C., 2015, COMPUT SCI; Chen LC, 2015, PR MACH LEARN RES, V37, P1785; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191; Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025; Dean J., 2012, NIPS 12, V1, P1223; Doersch C, 2014, LECT NOTES COMPUT SC, V8691, P362, DOI 10.1007/978-3-319-10578-9_24; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84; Eigen David, 2014, NEURIPS; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Heesch D, 2010, J SIGNAL PROCESS SYS, V61, P95, DOI 10.1007/s11265-009-0349-0; Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4; Jancsary J, 2012, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2012.6247950; Kendall A, 2015, P BRIT MACH VIS C 20; Kolesnikov A, 2014, LECT NOTES COMPUT SC, V8691, P550, DOI 10.1007/978-3-319-10578-9_36; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Li M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P661, DOI 10.1145/2623330.2623612; LIN GS, 2016, PROC CVPR IEEE, P3194, DOI DOI 10.1109/CVPR.2016.348; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu F., 2015, LEARNING DEPTH SINGL; Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152; Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033; Nowozin S, 2011, IEEE I CONF COMP VIS, P1668, DOI 10.1109/ICCV.2011.6126429; Pinheiro P. H., 2014, P INT C MACH LEARN; Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Schwing A. G., 2015, FULLY CONNECTED DEEP; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Simonyan K, 2015, 3 INT C LEARN REPR I; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Sutton C., 2005, P C UNC ART INT, P568; Tighe J, 2013, PROC CVPR IEEE, P3001, DOI 10.1109/CVPR.2013.386; Tompson J.J., 2014, ADV NEURAL INF PROCE, P1799, DOI DOI 10.5555/2968826.2969027; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Winn J., 2006, CVPR; Yu Fisher, 2016, MULTISCALE CONTEXT A; Zhang R, 2015, IEEE INT CONF ROBOT, P1850, DOI 10.1109/ICRA.2015.7139439; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179	60	55	62	4	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1352	1366		10.1109/TPAMI.2017.2708714	http://dx.doi.org/10.1109/TPAMI.2017.2708714			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28574343	Green Accepted, Green Submitted			2022-12-18	WOS:000431524700006
J	Liu, YJ; Yu, MJ; Li, BJ; He, Y				Liu, Yong-Jin; Yu, Minjing; Li, Bing-Jun; He, Ying			Intrinsic Manifold SLIC: A Simple and Efficient Method for Computing Content-Sensitive Superpixels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Superpixel; image segmentation; centroidal Voronoi tessellation; geodesic distance; image manifold	CENTROIDAL VORONOI TESSELLATIONS	Superpixels are perceptually meaningful atomic regions that can effectively capture image features. Among various methods for computing uniform superpixels, simple linear iterative clustering (SLIC) is popular due to its simplicity and high performance. In this paper, we extend SLIC to compute content-sensitive superpixels, i.e., small superpixels in content-dense regions with high intensity or colour variation and large superpixels in content-sparse regions. Rather than using the conventional SLIC method that clusters pixels in R-5, we map the input image I to a 2-dimensional manifold M subset of R-5, whose area elements are a good measure of the content density in I. We propose a simple method, called intrinsic manifold SLIC (IMSLIC), for computing a geodesic centroidal Voronoi tessellation (GCVT)-a uniform tessellation-on M, which induces the content-sensitive superpixels in I. In contrast to the existing algorithms, IMSLIC characterizes the content sensitivity by measuring areas of Voronoi cells on M. Using a simple and fast approximation to a closed-form solution, the method can compute the GCVT at a very low cost and guarantees that all Voronoi cells are simply connected. We thoroughly evaluate IMSLIC and compare it with eleven representative methods on the BSDS500 dataset and seven representative methods on the NYUV2 dataset. Computational results show that IMSLIC outperforms existing methods in terms of commonly used quality measures pertaining to superpixels such as compactness, adherence to boundaries, and achievable segmentation accuracy. We also evaluate IMSLIC and seven representative methods in an image contour closure application, and the results on two datasets, WHD and WSD, show that IMSLIC achieves the best foreground segmentation performance.	[Liu, Yong-Jin; Yu, Minjing; Li, Bing-Jun] Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; [He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, 50 Nanyang Ave, Singapore 639798, Singapore	Tsinghua University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Liu, YJ (corresponding author), Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	liuyongjin@tsinghua.edu.cn; yumj14@mails.tsinghua.edu.cn; libj15@mails.tsinghua.edu.cn; yhe@ntu.edu.sg	He, Ying/A-3708-2011; Liu, Yong/GWQ-6163-2022	He, Ying/0000-0002-6749-4485; 	Royal Society-Newton Advanced Fellowship; National Key Research and Development Plan [2016YFB1001202]; Natural Science Foundation of China [61521002, 61432003, 61661130156]	Royal Society-Newton Advanced Fellowship; National Key Research and Development Plan; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The author thanks the editor and reviewers for their comments that help improve this paper. This work was supported by the National Key Research and Development Plan (2016YFB1001202), Royal Society-Newton Advanced Fellowship and the Natural Science Foundation of China (61521002, 61432003, 61661130156).	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Alpert R. B. S., 2007, P IEEE C COMP VIS PA, V0, P1, DOI [DOI 10.1109/CVPR.2007.383017, 10.1109/CVPR.2007.383017]; Bertsekas D.P., 1998, NETWORK OPTIMIZATION; BERTSEKAS DP, 1993, NETWORKS, V23, P703, DOI 10.1002/net.3230230808; Bertsekas DP, 1996, J OPTIMIZ THEORY APP, V88, P297, DOI 10.1007/BF02192173; Borenstein E, 2002, LECT NOTES COMPUT SC, V2351, P109; Cai YQ, 2016, COMPUT GRAPH FORUM, V35, P199, DOI 10.1111/cgf.13017; De Silva Vin, 2002, NIPS 02 P 15 INT C N, V15, P705, DOI DOI 10.5555/2968618.2968708; Du Q, 2003, SIAM J SCI COMPUT, V24, P1488, DOI 10.1137/S1064827501391576; Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Fulkerson B., 2009, IEEE I CONF COMP VIS, P670, DOI [10.1109/ICCV.2009.5459175, DOI 10.1109/ICCV.2009.5459175]; Horst R., 2000, INTRO GLOBAL OPTIMIZ; Levinshtein A, 2012, INT J COMPUT VISION, V100, P99, DOI 10.1007/s11263-012-0527-6; Levinshtein A, 2010, LECT NOTES COMPUT SC, V6312, P480, DOI 10.1007/978-3-642-15552-9_35; Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96; Liu YJ, 2016, PROC CVPR IEEE, P651, DOI 10.1109/CVPR.2016.77; Liu YJ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982424; Liu YJ, 2015, IEEE T PATTERN ANAL, V37, P1938, DOI 10.1109/TPAMI.2015.2430342; Liu YJ, 2011, IEEE T PATTERN ANAL, V33, P1502, DOI 10.1109/TPAMI.2010.221; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Micusik B, 2010, INT J COMPUT VISION, V89, P106, DOI 10.1007/s11263-010-0327-9; Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323; Moore A. P., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587471; Schick A, 2014, PATTERN RECOGN LETT, V43, P71, DOI 10.1016/j.patrec.2013.09.013; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Van den Bergh M, 2015, INT J COMPUT VISION, V111, P298, DOI 10.1007/s11263-014-0744-2; Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16; Wang J, 2012, IEEE T PATTERN ANAL, V34, P1241, DOI 10.1109/TPAMI.2012.47; Wang J, 2011, IEEE T IMAGE PROCESS, V20, P3242, DOI 10.1109/TIP.2011.2150237; Wang P, 2013, INT J COMPUT VISION, V103, P1, DOI 10.1007/s11263-012-0588-6; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Weikersdorfer D, 2012, INT C PATT RECOG, P2087	35	55	63	4	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					653	666		10.1109/TPAMI.2017.2686857	http://dx.doi.org/10.1109/TPAMI.2017.2686857			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28358673				2022-12-18	WOS:000424465900011
J	Agudo, A; Moreno-Noguer, F; Calvo, B; Montiel, JMM				Agudo, Antonio; Moreno-Noguer, Francesc; Calvo, Begona; Montiel, J. M. M.			Sequential Non-Rigid Structure from Motion Using Physical Priors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Non-Rigid Structure from Motion; Extended Kalman Filter; Finite Element Method; tracking	SHAPE; MODEL; FACTORIZATION; IMAGES	We propose a new approach to simultaneously recover camera pose and 3D shape of non-rigid and potentially extensible surfaces from a monocular image sequence. For this purpose, we make use of the Extended Kalman Filter based Simultaneous Localization And Mapping (EKF-SLAM) formulation, a Bayesian optimization framework traditionally used in mobile robotics for estimating camera pose and reconstructing rigid scenarios. In order to extend the problem to a deformable domain we represent the object's surface mechanics by means of Navier's equations, which are solved using a Finite Element Method (FEM). With these main ingredients, we can further model the material's stretching, allowing us to go a step further than most of current techniques, typically constrained to surfaces undergoing isometric deformations. We extensively validate our approach in both real and synthetic experiments, and demonstrate its advantages with respect to competing methods. More specifically, we show that besides simultaneously retrieving camera pose and non-rigid shape, our approach is adequate for both isometric and extensible surfaces, does not require neither batch processing all the frames nor tracking points over the whole sequence and runs at several frames per second.	[Agudo, Antonio; Calvo, Begona; Montiel, J. M. M.] Univ Zaragoza, I3A, Zaragoza 50018, Spain; [Moreno-Noguer, Francesc] CSIC UPC, Inst Robot & Informat Ind, Barcelona 08028, Spain	University of Zaragoza; Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII); Universitat Politecnica de Catalunya	Agudo, A; Calvo, B; Montiel, JMM (corresponding author), Univ Zaragoza, I3A, Zaragoza 50018, Spain.; Moreno-Noguer, F (corresponding author), CSIC UPC, Inst Robot & Informat Ind, Barcelona 08028, Spain.	aagudo@unizar.es; fmoreno@iri.upc.edu; bcalvo@unizar.es; josemari@unizar.es	Montiel, Jose María Martínez/A-1197-2012; Calvo, Begoña/F-4091-2011; Agudo, Antonio/C-5147-2017; Calvo, Begoña/ABF-6819-2021	Montiel, Jose María Martínez/0000-0002-3627-7306; Calvo, Begoña/0000-0001-9713-1813; Agudo, Antonio/0000-0001-6845-4998; Calvo, Begoña/0000-0001-9713-1813	MINECO [DPI2011-27939-C02-01, TIN2014-58178-R, DPI2012-32168]; ERA-net CHISTERA project [VISEN PCIN-2013-047]; Spanish MECD [FPU12/04886]	MINECO(Spanish Government); ERA-net CHISTERA project; Spanish MECD(Spanish Government)	This work was partly funded by the MINECO projects Abdomesh DPI2011-27939-C02-01, RobInstruct TIN2014-58178-R and SVMap DPI2012-32168; by the ERA-net CHISTERA project VISEN PCIN-2013-047; and by a scholarship FPU12/04886 from the Spanish MECD. The authors thank P. Gotardo for fruitful discussions, and J. M. Bellon for the laparoscopy sequence.	Agudo A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1586, DOI 10.1109/ICCVW.2011.6130439; Agudo A, 2012, PROC CVPR IEEE, P1418; Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201; Bartoli A, 2012, PROC CVPR IEEE, P2026, DOI 10.1109/CVPR.2012.6247906; BATOZ JL, 1980, INT J NUMER METH ENG, V15, P1771, DOI 10.1002/nme.1620151205; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Brand M, 2005, PROC CVPR IEEE, P122; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760; Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403; Del Bue A, 2006, P IEEE C COMP VIS PA, V1, P1191; Ecker A, 2008, LECT NOTES COMPUT SC, V5302, P127, DOI 10.1007/978-3-540-88682-2_11; Engels Chris, 2006, PHOTOGRAMMETRIC COMP, V2; Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gotardo PFU, 2011, IEEE T PATTERN ANAL, V33, P2051, DOI 10.1109/TPAMI.2011.50; HAMMER PC, 1956, MATH TABLES AIDS COM, V10, P130, DOI DOI 10.2307/2002483; Hartley R, 2008, LECT NOTES COMPUT SC, V5302, P276, DOI 10.1007/978-3-540-88682-2_22; Kita Y, 1996, IEEE T PATTERN ANAL, V18, P1150, DOI 10.1109/34.546253; Klein George, 2007, P1; Malti A, 2013, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2013.200; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9; McInerney T., 1993, P 4 INT C COMP VIS, P33; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; Mikhail E.M., 2001, INTRO MODERN PHOTOGR, V19; Moreno-Noguer F, 2013, IEEE T PATTERN ANAL, V35, P463, DOI 10.1109/TPAMI.2012.102; Moreno-Noguer F, 2011, PROC CVPR IEEE, P1289, DOI 10.1109/CVPR.2011.5995532; Moreno-Noguer F, 2009, PROC CVPR IEEE, P1842, DOI 10.1109/CVPRW.2009.5206758; Nastar C, 1996, IEEE T PATTERN ANAL, V18, P1067, DOI 10.1109/34.544076; Paladini M, 2010, LECT NOTES COMPUT SC, V6312, P15, DOI 10.1007/978-3-642-15552-9_2; Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34; Russell C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3009, DOI 10.1109/CVPR.2011.5995383; Salzmann M, 2008, LECT NOTES COMPUT SC, V5305, P581, DOI 10.1007/978-3-540-88693-8_43; Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158; Sayd P., 2008, P IEEE C COMP VIS PA, P1; Sclaroff S., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P158, DOI 10.1109/MNRAO.1994.346241; Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009; Tao LL, 2013, COMPUT VIS IMAGE UND, V117, P1287, DOI 10.1016/j.cviu.2013.03.005; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tsap LV, 2000, IEEE T PATTERN ANAL, V22, P526, DOI 10.1109/34.857007; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9; Young A., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P399, DOI 10.1109/CVPR.1992.223158; Zienkiewicz OC, 2014, FINITE ELEMENT METHO	47	55	59	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					979	994		10.1109/TPAMI.2015.2469293	http://dx.doi.org/10.1109/TPAMI.2015.2469293			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	27046840	Green Submitted			2022-12-18	WOS:000374164700011
J	Li, J; Duan, LY; Chen, XW; Huang, TJ; Tian, YH				Li, Jia; Duan, Ling-Yu; Chen, Xiaowu; Huang, Tiejun; Tian, Yonghong			Finding the Secret of Image Saliency in the Frequency Domain	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image saliency; Fourier transform; spectral analysis; fixation prediction; learning-based; experimental study	VISUAL SALIENCY; DETECTION MODEL; ATTENTION; FEATURES	There are two sides to every story of visual saliency modeling in the frequency domain. On the one hand, image saliency can be effectively estimated by applying simple operations to the frequency spectrum. On the other hand, it is still unclear which part of the frequency spectrum contributes the most to popping-out targets and suppressing distractors. Toward this end, this paper tentatively explores the secret of image saliency in the frequency domain. From the results obtained in several qualitative and quantitative experiments, we find that the secret of visual saliency may mainly hide in the phases of intermediate frequencies. To explain this finding, we reinterpret the concept of discrete Fourier transform from the perspective of template-based contrast computation and thus develop several principles for designing the saliency detector in the frequency domain. Following these principles, we propose a novel approach to design the saliency detector under the assistance of prior knowledge obtained through both unsupervised and supervised learning processes. Experimental results on a public image benchmark show that the learned saliency detector outperforms 18 state-of-the-art approaches in predicting human fixations.	[Li, Jia; Chen, Xiaowu] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China; [Li, Jia] Beihang Univ, Int Res Inst Multidisciplinary Sci, Beijing 100191, Peoples R China; [Duan, Ling-Yu; Huang, Tiejun; Tian, Yonghong] Peking Univ, Natl Engn Lab Video Technol, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China	Beihang University; Beihang University; Peking University	Li, J (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.	jiali@buaa.edu.cn; lingyu@pku.edu.cn; chen@buaa.edu.cn; tjhuang@pku.edu.cn; yhtian@pku.edu.cn	Li, Jia/AAB-6431-2019	Li, Jia/0000-0002-4346-8696	National Natural Science Foundation of China [61370113, 61325011, 61390515, 61421003]; National Hightech R&D Program of China [2015AA016302]; Supervisor Award Funding for Excellent Doctoral Dissertation of Beijing [20128000103]; Fundamental Research Funds for the Central Universities	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Hightech R&D Program of China(National High Technology Research and Development Program of China); Supervisor Award Funding for Excellent Doctoral Dissertation of Beijing; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported in part by grants from National Natural Science Foundation of China (61370113, 61325011, 61390515 and 61421003), National Hightech R&D Program of China (2015AA016302), Supervisor Award Funding for Excellent Doctoral Dissertation of Beijing (20128000103), and Fundamental Research Funds for the Central Universities. L. Duan is the corresponding author.	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Bian P., 2008, INT C NEUR INF PROC, P251; Borji A, 2014, IEEE T SYST MAN CY-S, V44, P523, DOI 10.1109/TSMC.2013.2279715; Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711; Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706; Bruce N. D. B., 2005, ADV NEURAL INF PROCE, P155; Buzatu O., 2013, P INT S SIGN CIRC SY, P1; Chalmond B, 2006, IEEE T IMAGE PROCESS, V15, P2644, DOI 10.1109/TIP.2006.877380; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401; Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193; Cui X, 2009, C P ACM INT C MULTIM, P617, DOI DOI 10.1145/1631272.1631370; Cui XY, 2012, NEUROCOMPUTING, V86, P24, DOI 10.1016/j.neucom.2011.12.033; Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549; Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126; Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Guo C., 2008, P CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587715; Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267; Hou X., 2009, ADV NEURAL INFORM PR, P681; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Itti L, 2005, PROC CVPR IEEE, P631; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kienzle W, 2007, ADV NEURAL INFORM PR, P689; Li C., 2011, ACM MULTIMEDIA, P1157; Li C, 2013, SENSORS-BASEL, V13, P3409, DOI 10.3390/s130303409; Li J., 2014, MACHINE LEARNING PER; Li J, 2014, INT J COMPUT VISION, V107, P239, DOI 10.1007/s11263-013-0678-0; Li J, 2013, IEEE SIGNAL PROC LET, V20, P845, DOI 10.1109/LSP.2013.2268868; Li J, 2011, IEEE T CIRC SYST VID, V21, P623, DOI 10.1109/TCSVT.2011.2129430; Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6; Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147; Li ZC, 2011, IEEE T IMAGE PROCESS, V20, P2017, DOI 10.1109/TIP.2010.2099128; Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39; Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151; Mei T, 2008, P 16 ACM INT C MULT, P439; Mei Tao, 2007, P 15 ACM INT C MULT, P1075; Navalpakkam V, 2007, NEURON, V53, P605, DOI 10.1016/j.neuron.2007.01.018; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Peters R., 2008, J VISION, V8, P879; Schauerte B., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P137, DOI 10.1109/WACV.2012.6163035; Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9; Shai A., 2007, ACM T GRAPHIC, V26, P10; Tian YH, 2015, INT J COMPUT VISION, V111, P153, DOI 10.1007/s11263-014-0737-1; Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28; Zhai Y., 2006, PROC14TH ACM INT C M, DOI [10.1145/1180639.1180824, DOI 10.1145/1180639.1180824]; Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhang ZM, 2011, PROC CVPR IEEE, P1497, DOI 10.1109/CVPR.2011.5995411; Zhao Q, 2012, J VISION, V12, DOI 10.1167/12.6.22; Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9; Zhu GK, 2013, IEEE T CYBERNETICS, V43, P2032, DOI 10.1109/TSMCB.2013.2238927	57	55	58	2	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2428	2440		10.1109/TPAMI.2015.2424870	http://dx.doi.org/10.1109/TPAMI.2015.2424870			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539848				2022-12-18	WOS:000364831700006
J	Zhang, L; Shen, Y; Li, HY; Lu, JW				Zhang, Lin; Shen, Ying; Li, Hongyu; Lu, Jianwei			3D Palmprint Identification Using Block-Wise Features and Collaborative Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D palmprint; sparse representation; l(1)-minimization; collaborative representation; surface type	FACE RECOGNITION; SPARSE; EFFICIENT; ALGORITHM; SCALE; 2D	Developing 3D palmprint recognition systems has recently begun to draw attention of researchers. Compared with its 2D counterpart, 3D palmprint has several unique merits. However, most of the existing 3D palmprint matching methods are designed for one-to-one verification and they are not efficient to cope with the one-to-many identification case. In this paper, we fill this gap by proposing a collaborative representation (CR) based framework with l(1)-norm or l(2)-norm regularizations for 3D palmprint identification. The effects of different regularization terms have been evaluated in experiments. To use the CR-based classification framework, one key issue is how to extract feature vectors. To this end, we propose a block-wise statistics based feature extraction scheme. We divide a 3D palmprint ROI into uniform blocks and extract a histogram of surface types from each block; histograms from all blocks are then concatenated to form a feature vector. Such feature vectors are highly discriminative and are robust to mere misalignment. Experiments demonstrate that the proposed CR-based framework with an l(2)-norm regularization term can achieve much better recognition accuracy than the other methods. More importantly, its computational complexity is extremely low, making it quite suitable for the large-scale identification application. Source codes are available at http://sse.tongji.edu.cn/linzhang/cr3dpalm/cr3dpalm.htm.	[Zhang, Lin; Shen, Ying; Li, Hongyu; Lu, Jianwei] Tongji Univ, Sch Software Engn, Shanghai 201804, Peoples R China; [Zhang, Lin] Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, Nanjing 210094, Peoples R China; [Lu, Jianwei] Tongji Univ, Adv Inst Translat Med, Shanghai 201804, Peoples R China	Tongji University; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Tongji University	Zhang, L (corresponding author), Tongji Univ, Sch Software Engn, Shanghai 201804, Peoples R China.	cslinzhang@tongji.edu.cn; yingshen@tongji.edu.cn; hyli@tongji.edu.cn; jwlu33@gmail.com		Zhang, Lin/0000-0002-4360-5523	Natural Science Foundation of China [61201394]; National Basic Research Program of China [2013CB967101]; Shanghai Pujiang Program [13PJ1408700, 13PJ1433200, 14PJ1408100]; Jiangsu Key Laboratory of Image and Video Understanding for Social Safety (Nanjing University of Science and Technology) [30920140122007]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China); Shanghai Pujiang Program(Shanghai Pujiang Program); Jiangsu Key Laboratory of Image and Video Understanding for Social Safety (Nanjing University of Science and Technology)	This work was supported in part by the Natural Science Foundation of China under grant no. 61201394, in part by the National Basic Research Program of China under grant no. 2013CB967101, in part by the Shanghai Pujiang Program under grant nos. 13PJ1408700, 13PJ1433200, and 14PJ1408100, and in part by the Jiangsu Key Laboratory of Image and Video Understanding for Social Safety (Nanjing University of Science and Technology) under grant no. 30920140122007.	[Anonymous], 2012, DATA FORMAT INTERCHA, P1; [Anonymous], 2014, POLYU PALMPR DAT; Ashbaugh D.R, 1999, CRC SER PR CRIM; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Cui JR, 2014, NEURAL COMPUT APPL, V24, P497, DOI 10.1007/s00521-012-1265-y; Cummins H, 1961, FINGER PRINTS PALMS; Dai JF, 2012, IEEE T PATTERN ANAL, V34, P1618, DOI 10.1109/TPAMI.2011.237; Dai JF, 2011, IEEE T PATTERN ANAL, V33, P945, DOI 10.1109/TPAMI.2010.164; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48; Flusser J., 2009, MOMENTS MOMENT INVAR; Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016; Islam SMS, 2011, INT J COMPUT VISION, V95, P52, DOI 10.1007/s11263-011-0436-0; Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184; Li W, 2012, IEEE T SYST MAN CY A, V42, P443, DOI 10.1109/TSMCA.2011.2164066; Li W, 2011, IEEE T SYST MAN CY C, V41, P274, DOI 10.1109/TSMCC.2010.2055849; Li W, 2010, PROC CVPR IEEE, P795, DOI 10.1109/CVPR.2010.5540134; Liu M, 2012, INT CONF SIGN PROCES, P1597, DOI 10.1109/ICoSP.2012.6491885; Malioutov DM, 2005, INT CONF ACOUST SPEE, P733; Michael GKO, 2008, IMAGE VISION COMPUT, V26, P1551, DOI 10.1016/j.imavis.2008.06.010; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34; Rigamonti R, 2011, PROC CVPR IEEE, P1545, DOI 10.1109/CVPR.2011.5995313; Shang L, 2006, NEUROCOMPUTING, V69, P1782, DOI 10.1016/j.neucom.2005.11.004; Sun ZN, 2005, PROC CVPR IEEE, P279; Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892; Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7; Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790; Yang B, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043040; Yang JF, 2011, SIAM J SCI COMPUT, V33, P250, DOI 10.1137/090777761; Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286; Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981; Zhang D, 2010, PATTERN RECOGN, V43, P358, DOI 10.1016/j.patcog.2009.04.026; Zhang D, 2009, IEEE T SYST MAN CY C, V39, P505, DOI 10.1109/TSMCC.2009.2020790; Zhang L, 2004, IEEE T SYST MAN CY B, V34, P1335, DOI 10.1109/TSMCB.2004.824521; Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277; Zhang L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100120; Zhang L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095506; Zhang L, 2012, IEEE IMAGE PROC, P81, DOI 10.1109/ICIP.2012.6466800; Zhang L, 2012, IMAGE VISION COMPUT, V30, P1043, DOI 10.1016/j.imavis.2012.09.003; Zuo WM, 2010, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2010.5539909	50	55	61	1	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1730	1736		10.1109/TPAMI.2014.2372764	http://dx.doi.org/10.1109/TPAMI.2014.2372764			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26353008				2022-12-18	WOS:000357591900016
J	Liu, DY; Gu, JW; Hitomi, Y; Gupta, M; Mitsunaga, T; Nayar, SK				Liu, Dengyu; Gu, Jinwei; Hitomi, Yasunobu; Gupta, Mohit; Mitsunaga, Tomoo; Nayar, Shree K.			Efficient Space-Time Sampling with Pixel-Wise Coded Exposure for High-Speed Imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Space-time sampling; dictionary learning; sparse reconstruction; computational camera	SIGNAL RECOVERY; CAMERA	Cameras face a fundamental trade-off between spatial and temporal resolution. Digital still cameras can capture images with high spatial resolution, but most high-speed video cameras have relatively low spatial resolution. It is hard to overcome this trade-off without incurring a significant increase in hardware costs. In this paper, we propose techniques for sampling, representing, and reconstructing the space-time volume to overcome this trade-off. Our approach has two important distinctions compared to previous works: 1) We achieve sparse representation of videos by learning an overcomplete dictionary on video patches, and 2) we adhere to practical hardware constraints on sampling schemes imposed by architectures of current image sensors, which means that our sampling function can be implemented on CMOS image sensors with modified control units in the future. We evaluate components of our approach, sampling function and sparse representation, by comparing them to several existing approaches. We also implement a prototype imaging system with pixel-wise coded exposure control using a liquid crystal on silicon device. System characteristics such as field of view and modulation transfer function are evaluated for our imaging system. Both simulations and experiments on a wide range of scenes show that our method can effectively reconstruct a video from a single coded image while maintaining high spatial resolution.	[Liu, Dengyu; Gu, Jinwei] Rochester Inst Technol, Chester F Carlson Ctr Imaging Sci, Rochester, NY 14623 USA; [Hitomi, Yasunobu; Mitsunaga, Tomoo] Sony Corp, Tokyo, Japan; [Gupta, Mohit; Nayar, Shree K.] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Rochester Institute of Technology; Sony Corporation; Columbia University	Liu, DY (corresponding author), Rochester Inst Technol, Chester F Carlson Ctr Imaging Sci, Rochester, NY 14623 USA.	dxl5849@rit.edu; jwgu@cis.rit.edu; Yasunobu.Hitomi@jp.sony.com; mohitg@cs.columbia.edu; Tomoo.Mitsunaga@jp.sony.com; nayar@cs.columbia.edu			Sony Corporation; US National Science Foundation [IIS 0964429, EAGER 12-57163]; US Office of Naval Research [N00014-08-1-0638]	Sony Corporation; US National Science Foundation(National Science Foundation (NSF)); US Office of Naval Research(Office of Naval Research)	This research was supported in part by Sony Corporation, the US National Science Foundation (grant number IIS 0964429 and EAGER 12-57163), US Office of Naval Research (grant number N00014-08-1-0638), and a gift from Xerox.	Agrawal A, 2010, PROC CVPR IEEE, P599, DOI 10.1109/CVPR.2010.5540161; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2013, SONY DEV NEXT GENERA; Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1; Bub G, 2010, NAT METHODS, V7, P209, DOI [10.1038/NMETH.1429, 10.1038/nmeth.1429]; Burns PA, 2000, PICS 2000: IMAGE PROCESSING, IMAGE QUALITY, IMAGE CAPTURE, SYSTEMS CONFERENCE, PROCEEDINGS, P135; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Elad M., 2006, PROC IEEE COMPUT SOC, V1, P895, DOI DOI 10.1109/CVPR.2006.142; Gu J., 2010, PROC IEEE INT C COMP, P1, DOI [10.1109/ICCPHOT.2010.5585094, DOI 10.1109/ICCPHOT.2010.5585094]; Gupta A, 2009, FORM METHOD SYST DES, V35, P1, DOI 10.1007/s10703-009-0072-2; Gupta M., 2010, EUR C COMP VIS ECCV, V3, P6; Hitomi Y, 2011, IEEE I CONF COMP VIS, P287, DOI 10.1109/ICCV.2011.6126254; Kleinfelder S, 2001, IEEE J SOLID-ST CIRC, V36, P2049, DOI 10.1109/4.972156; Liang W., 2009, P OCEANS OCT, P1, DOI [10.1109/ PES. 2009.5275722, DOI 10.1007/978-0-387-69285-2_1]; Mannami H, 2007, IEEE I CONF COMP VIS, P1282; Marcia R., 2008, P EUR SIGN PROC C, V2; Nagahara H, 2010, LECT NOTES COMPUT SC, V6316, P337, DOI 10.1007/978-3-642-15567-3_25; Nayar SK, 2006, INT J COMPUT VISION, V70, P7, DOI 10.1007/s11263-005-3102-6; Nayar SK, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1168; Raskar R., 2006, P ACM SIGGRAPH, V3; Reddy D, 2011, PROC CVPR IEEE, P329, DOI 10.1109/CVPR.2011.5995542; Ri S, 2006, J ROBOT MECHATRON, V18, P728, DOI 10.20965/jrm.2006.p0728; Sankaranarayanan A. C., 2012, P IEEE INT C COMP PH, P1, DOI DOI 10.1109/ICCPHOT.2012.6215212; Sankaranarayanan AC, 2010, LECT NOTES COMPUT SC, V6311, P129, DOI 10.1007/978-3-642-15549-9_10; Shu XB, 2011, IEEE I CONF COMP VIS, P439, DOI 10.1109/ICCV.2011.6126273; Tai YW, 2010, IEEE T PATTERN ANAL, V32, P1012, DOI 10.1109/TPAMI.2009.97; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Veeraraghavan A, 2011, IEEE T PATTERN ANAL, V33, P671, DOI 10.1109/TPAMI.2010.87; Wakin M., 2006, P PICT COD S; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wilburn B, 2004, PROC CVPR IEEE, P294; Yonemoto K, 2002, IEEE T ELECTRON DEV, V49, P746, DOI 10.3169/itej.56.670	33	55	61	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					248	260		10.1109/TPAMI.2013.129	http://dx.doi.org/10.1109/TPAMI.2013.129			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356347				2022-12-18	WOS:000328899500004
J	Guo, RQ; Dai, QY; Hoiem, D				Guo, Ruiqi; Dai, Qieyun; Hoiem, Derek			Paired Regions for Shadow Detection and Removal	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shadow detection; region classification; shadow removal; enhancement		In this paper, we address the problem of shadow detection and removal from single images of natural scenes. Differently from traditional methods that explore pixel or edge information, we employ a region-based approach. In addition to considering individual regions separately, we predict relative illumination conditions between segmented regions from their appearances and perform pairwise classification based on such information. Classification results are used to build a graph of segments, and graph-cut is used to solve the labeling of shadow and nonshadow regions. Detection results are later refined by image matting, and the shadow-free image is recovered by relighting each pixel based on our lighting model. We evaluate our method on the shadow detection dataset in Zhu et al. [1]. In addition, we created a new dataset with shadow-free ground truth images, which provides a quantitative basis for evaluating shadow removal. We study the effectiveness of features for both unary and pairwise classification.	[Guo, Ruiqi; Dai, Qieyun; Hoiem, Derek] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Guo, RQ (corresponding author), Univ Illinois, Dept Comp Sci, 201 North Goodwin Ave, Urbana, IL 61801 USA.	guo29@illinois.edu; dai9@illinois.edu; dhoiem@illinois.edu			US National Science Foundation (NSF) [IIS-0904209]; Google Research Award	US National Science Foundation (NSF)(National Science Foundation (NSF)); Google Research Award(Google Incorporated)	This work was supported in part by the US National Science Foundation (NSF) under IIS-0904209 and a Google Research Award. The authors would like to thank David Forsyth for useful comments and Kevin Karsch for the images of Fig. 9c.	Arbel E., 2007, P IEEE C COMP VIS PA; Arbel E, 2011, IEEE T PATTERN ANAL, V33, P1202, DOI 10.1109/TPAMI.2010.157; BABA M, 2003, P ACM SIGGRAPH; Barrow H. G., 1978, COMPUTER VISION SYST; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chuang YY, 2003, ACM T GRAPHIC, V22, P494, DOI 10.1145/882262.882298; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Everingham M., 2012, PASCAL VISUAL OBJECT; Finlayson G.D., 2002, P COL IM C; Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18; Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z; Fredembach C., 2005, P BRIT MACH VIS C; Fredembach C., 2004, P COL IM C; Guo RQ, 2011, PROC CVPR IEEE; Karsch K., 2011, P ACM SIGGRAPH; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kwatra M.H.V., 2012, P IEEE INT C COMP PH; Lalonde J.-F., 2010, P 11 EUR C COMP VIS; Lalonde J.F., 2009, P 12 IEEE INT C COMP; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Maxwell B.A., 2008, P IEEE C COMP VIS PA; Narasimhan S.G., 2003, P 9 IEEE INT C COMP; Panagopoulos A, 2011, PROC CVPR IEEE, P673, DOI 10.1109/CVPR.2011.5995585; Waltz D.L., 1972, TECHNICAL REPORT; Wu T.P., 2007, ACM T GRAPHICS, V26; Zhu JJ, 2010, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.2010.5540209	28	55	64	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2956	2967		10.1109/TPAMI.2012.214	http://dx.doi.org/10.1109/TPAMI.2012.214			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV					2022-12-18	WOS:000326502200012
J	Dekel, T; Moses, Y; Avidan, S				Dekel (Basha), Tali; Moses, Yael; Avidan, Shai			Stereo Seam Carving a Geometrically Consistent Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo; retargeting; geometric consistency		Image retargeting algorithms attempt to adapt the image content to the screen without distorting the important objects in the scene. Existing methods address retargeting of a single image. In this paper, we propose a novel method for retargeting a pair of stereo images. Naively retargeting each image independently will distort the geometric structure and hence will impair the perception of the 3D structure of the scene. We show how to extend a single image seam carving to work on a pair of images. Our method minimizes the visual distortion in each of the images as well as the depth distortion. A key property of the proposed method is that it takes into account the visibility relations between pixels in the image pair (occluded and occluding pixels). As a result, our method guarantees, as we formally prove, that the retargeted pair is geometrically consistent with a feasible 3D scene, similar to the original one. Hence, the retargeted stereo pair can be viewed on a stereoscopic display or further processed by any computer vision algorithm. We demonstrate our method on a number of challenging indoor and outdoor stereo images.	[Dekel (Basha), Tali; Avidan, Shai] Tel Aviv Univ, Dept Elect Engn, Sch Elect Engn, IL-69978 Tel Aviv, Israel; [Moses, Yael] Interdisciplinary Ctr, IL-46150 Herzliyya, Israel	Tel Aviv University; Reichman University	Dekel, T (corresponding author), Tel Aviv Univ, Dept Elect Engn, Sch Elect Engn, IL-69978 Tel Aviv, Israel.	talib@eng.tau.ac.il			Israel Science Foundation [1556/10]; European Community [PIRG05-GA-2009-248527]	Israel Science Foundation(Israel Science Foundation); European Community(European Commission)	This work was supported in part by an Israel Science Foundation grant 1556/10 and European Community grant PIRG05-GA-2009-248527. An earlier version of part of this work was published in ICCV 2011 [1].	Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461; BASHA T, 2011, P IEEE INT C COMP VI, P1816; Basha T., 2012, INT J COMPUT VISION, P1; Birklbauer C, 2012, COMPUT GRAPH FORUM, V31, P295, DOI 10.1111/j.1467-8659.2012.03008.x; Chang CH, 2011, IEEE T MULTIMEDIA, V13, P589, DOI 10.1109/TMM.2011.2116775; Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120; Grundmann M, 2010, PROC CVPR IEEE, P569, DOI 10.1109/CVPR.2010.5540165; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hirschmuller Heiko, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383248; Huguet F, 2007, IEEE I CONF COMP VIS, P1342, DOI 10.1109/iccv.2007.4409000; Koppal SJ, 2011, IEEE COMPUT GRAPH, V31, P20, DOI 10.1109/MCG.2010.37; Lang M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778812; Lee KY, 2012, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2012.6247657; Mansfield A, 2010, LECT NOTES COMPUT SC, V6311, P143, DOI 10.1007/978-3-642-15549-9_11; Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159; Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186; Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615; Utsugi K., 2010, P 3DTV C TRUE VIS CA, P1, DOI DOI 10.1109/3DTV.2010.5506316; W-Y Lo, 2010, ACM T GRAPHIC, V29, P147; Wang Liang, 2008, P IEEE C COMP VIS PA; Wang Y, 2008, CELL POLYM, V27, P1; Wolf L., 2007, P IEEE 11 INT C COMP, P1, DOI DOI 10.1109/ICCV.2007.4409010	22	55	60	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2513	2525		10.1109/TPAMI.2013.46	http://dx.doi.org/10.1109/TPAMI.2013.46			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969393	Green Submitted			2022-12-18	WOS:000323175200015
J	Liu, EY; Jain, AK; Tian, J				Liu, Eryun; Jain, Anil K.; Tian, Jie			A Coarse to Fine Minutiae-Based Latent Palmprint Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Palmprint; latent palmprint matching; minutiae clustering; minutia descriptor; match propagation	PROPAGATION	With the availability of live-scan palmprint technology, high resolution palmprint recognition has started to receive significant attention in forensics and law enforcement. In forensic applications, latent palmprints provide critical evidence as it is estimated that about 30 percent of the latents recovered at crime scenes are those of palms. Most of the available high-resolution palmprint matching algorithms essentially follow the minutiae-based fingerprint matching strategy. Considering the large number of minutiae (about 1,000 minutiae in a full palmprint compared to about 100 minutiae in a rolled fingerprint) and large area of foreground region in full palmprints, novel strategies need to be developed for efficient and robust latent palmprint matching. In this paper, a coarse to fine matching strategy based on minutiae clustering and minutiae match propagation is designed specifically for palmprint matching. To deal with the large number of minutiae, a local feature-based minutiae clustering algorithm is designed to cluster minutiae into several groups such that minutiae belonging to the same group have similar local characteristics. The coarse matching is then performed within each cluster to establish initial minutiae correspondences between two palmprints. Starting with each initial correspondence, a minutiae match propagation algorithm searches for mated minutiae in the full palmprint. The proposed palmprint matching algorithm has been evaluated on a latent-to-full palmprint database consisting of 446 latents and 12,489 background full prints. The matching results show a rank-1 identification accuracy of 79.4 percent, which is significantly higher than the 60.8 percent identification accuracy of a state-of-the-art latent palmprint matching algorithm on the same latent database. The average computation time of our algorithm for a single latent-to-full match is about 141 ms for genuine match and 50 ms for impostor match, on a Windows XP desktop system with 2.2-GHz CPU and 1.00-GB RAM. The computation time of our algorithm is an order of magnitude faster than a previously published state-of-the-art-algorithm.	[Liu, Eryun; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Liu, Eryun; Tian, Jie] Xidian Univ, Sch Life Sci & Technol, Xian 710126, Shaanxi, Peoples R China; [Jain, Anil K.] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea; [Tian, Jie] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China	Michigan State University; Xidian University; Korea University; Chinese Academy of Sciences; Institute of Automation, CAS	Liu, EY (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 428 S Shaw Ln,RM 3115, E Lansing, MI 48824 USA.	liueryun@cse.msu.edu; jain@cse.msu.edu; tian@ieee.org	Tian, Jie/H-1190-2011; Life, FP/M-9555-2013; Tian, Jie/M-5976-2013	Tian, Jie/0000-0003-0498-0432; 	World Class University (WCU) program; Ministry of Education, Science and Technology through the National Research Foundation of Korea [R31-10008]; National Natural Science Foundation of China [61100234]	World Class University (WCU) program; Ministry of Education, Science and Technology through the National Research Foundation of Korea; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Anil Jain's research was partially supported by the World Class University (WCU) program funded by the Ministry of Education, Science and Technology through the National Research Foundation of Korea (R31-10008). Eryun Liu's research was partially supported by the National Natural Science Foundation of China under Grant No. 61100234. All correspondence regarding this paper should be addressed to A.K. Jain.	Ashbaugh D.R, 1999, CRC SER PR CRIM; Cao K., 2011, 2011 IEEE INT JOINT, P1; Cao K, 2012, PATTERN RECOGN LETT, V33, P1411, DOI 10.1016/j.patrec.2012.03.007; Cappelli R, 2012, IEEE T SYST MAN CY B, V42, P956, DOI 10.1109/TSMCB.2012.2183635; Chen XJ, 2006, IEEE T IMAGE PROCESS, V15, P767, DOI 10.1109/TIP.2005.860597; Chikkerur S, 2006, LECT NOTES COMPUT SC, V3832, P309; Dai JF, 2012, IEEE T PATTERN ANAL, V34, P1618, DOI 10.1109/TPAMI.2011.237; Dai JF, 2011, IEEE T PATTERN ANAL, V33, P945, DOI 10.1109/TPAMI.2010.164; Dewan Shaila, 2021, NEW YORK TIMES; Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016; Funada J, 1998, INT C PATT RECOG, P1849, DOI 10.1109/ICPR.1998.712091; HALE AR, 1952, AM J ANAT, V91, P147, DOI 10.1002/aja.1000910105; He YL, 2006, IEEE T PATTERN ANAL, V28, P850, DOI 10.1109/TPAMI.2006.119; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jain A. K., 2008, TECHNICAL REPORT; Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242; Kannala J., 2007, PROC IEEE C COMPUT V, P1; Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018; Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maltoni D., 2009, HDB FINGERPRINT RECO; Neurotechnology, 2012, VERIFINGER 4 2 SDK; Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604; Wang H, 2009, IEEE T IMAGE PROCESS, V18, P140, DOI 10.1109/TIP.2008.2006602; Wang Y, 2011, INT CONF ACOUST SPEE, P1, DOI 10.1109/PLASMA.2011.5993071; Yao B, 2004, IEEE IMAGE PROC, P2969; Yao J, 2006, SIGNAL PROCESS-IMAGE, V21, P506, DOI 10.1016/j.image.2006.03.005; Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981; Zhu Q, 2007, ISPRS J PHOTOGRAMM, V62, P295, DOI 10.1016/j.isprsjprs.2007.05.010	31	55	59	0	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2307	2322		10.1109/TPAMI.2013.39	http://dx.doi.org/10.1109/TPAMI.2013.39			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969380	Green Submitted			2022-12-18	WOS:000323175200001
J	Leotta, MJ; Mundy, JL				Leotta, Matthew J.; Mundy, Joseph L.			Vehicle Surveillance with a Generic, Adaptive, 3D Vehicle Model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine vision; road vehicle location monitoring; image shape analysis; image recognition; video signal processing	TRACKING; CLASSIFICATION; SEGMENTATION	In automated surveillance, one is often interested in tracking road vehicles, measuring their shape in 3D world space, and determining vehicle classification. To address these tasks simultaneously, an effective approach is the constrained alignment of a prior model of 3D vehicle shape to images. Previous 3D vehicle models are either generic but overly simple or rigid and overly complex. Rigid models represent exactly one vehicle design, so a large collection is needed. A single generic model can deform to a wide variety of shapes, but those shapes have been far too primitive. This paper uses a generic 3D vehicle model that deforms to match a wide variety of passenger vehicles. It is adjustable in complexity between the two extremes. The model is aligned to images by predicting and matching image intensity edges. Novel algorithms are presented for fitting models to multiple still images and simultaneous tracking while estimating shape in video. Experiments compare the proposed model to simple generic models in accuracy and reliability of 3D shape recovery from images and tracking in video. Standard techniques for classification are also used to compare the models. The proposed model outperforms the existing simple models at each task.	[Leotta, Matthew J.] Kitware Inc, Clifton Pk, NY 12065 USA; [Mundy, Joseph L.] Brown Univ, Sch Engn, Providence, RI 02912 USA	Brown University	Leotta, MJ (corresponding author), Kitware Inc, 28 Corp Dr, Clifton Pk, NY 12065 USA.	matt.leotta@kitware.com; mundy@lems.brown.edu						Ambardekar A.A., 2007, THESIS U NEVADA RENO; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Atev S, 2005, IEEE T INTELL TRANSP, V6, P416, DOI 10.1109/TITS.2005.858786; BEATON AE, 1974, TECHNOMETRICS, V16, P147, DOI 10.2307/1267936; Beymer D, 1997, PROC CVPR IEEE, P495, DOI 10.1109/CVPR.1997.609371; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bouttefroy PLM, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P61, DOI 10.1109/ITSC.2008.4732659; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Dahlkamp H, 2007, INT J COMPUT VISION, V73, P139, DOI 10.1007/s11263-006-9786-4; Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Ferryman JM, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P127; Guo Y.-Z., 2008, 2008 4 INT C WIRELES, P1; Gupte S, 2002, IEEE T INTELL TRANSP, V3, P37, DOI 10.1109/6979.994794; Ha DM, 2004, IMAGE VISION COMPUT, V22, P899, DOI 10.1016/j.imavis.2004.05.006; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Jain V, 2007, COMPUT VIS IMAGE UND, V108, P230, DOI 10.1016/j.cviu.2006.11.024; Jolly MPD, 1996, IEEE T PATTERN ANAL, V18, P293, DOI 10.1109/34.485557; Kanhere NK, 2008, IEEE T INTELL TRANSP, V9, P148, DOI 10.1109/TITS.2007.911357; KOLLER D, 1993, P 12 ISR C ART INT C, P359; KOLLER D, 1994, P EUR C COMP VIS, P189; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; LEOTTA M, 2007, P IEEE INT C COMP VI, V6, P325; Leotta MJ, 2009, PROC CVPR IEEE, P1311, DOI 10.1109/CVPRW.2009.5206738; LEOTTA MJ, 2010, THESIS BROWN U; Liebelt J., 2008, P 2008 IEEE C COMPUT, P1; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Magee DR, 2004, IMAGE VISION COMPUT, V22, P143, DOI 10.1016/S0262-8856(03)00145-8; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; Mundy J. L., 2004, Proceedings. 33rd Applied Imagery Pattern Recognition Workshop, P10; Ottlik A, 2008, INT J COMPUT VISION, V80, P211, DOI 10.1007/s11263-007-0112-6; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Song XF, 2005, IEEE I CONF COMP VIS, P1124; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; Tikhonov A.N., 1977, SOLUTION ILL POSED P; van Leuven J, 2001, IEEE IMTC P, P2049, DOI 10.1109/IMTC.2001.929558; [No title captured]	41	55	59	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1457	1469		10.1109/TPAMI.2010.217	http://dx.doi.org/10.1109/TPAMI.2010.217			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	21135435				2022-12-18	WOS:000290574000013
J	Cremers, D; Kolev, K				Cremers, Daniel; Kolev, Kalin			Multiview Stereo and Silhouette Consistency via Convex Functionals over Convex Domains	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image-based modeling; silhouette and stereo fusion; convex optimization	RECONSTRUCTION	We propose a convex formulation for silhouette and stereo fusion in 3D reconstruction from multiple images. The key idea is to show that the reconstruction problem can be cast as one of minimizing a convex functional, where the exact silhouette consistency is imposed as convex constraints that restrict the domain of feasible functions. As a consequence, we can retain the original stereo-weighted surface area as a cost functional without heuristic modifications of this energy by balloon terms or other strategies, yet still obtain meaningful (nonempty) reconstructions which are guaranteed to be silhouette-consistent. We prove that the proposed convex relaxation approach provides solutions that lie within a bound of the optimal solution. Compared to existing alternatives, the proposed method does not depend on initialization and leads to a simpler and more robust numerical scheme for imposing silhouette consistency obtained by projection onto convex sets. We show that this projection can be solved exactly using an efficient algorithm. We propose a parallel implementation of the resulting convex optimization problem on a graphics card. Given a photoconsistency map and a set of image silhouettes, we are able to compute highly accurate and silhouette-consistent reconstructions for challenging real-world data sets. In particular, experimental results demonstrate that the proposed silhouette constraints help to preserve fine-scale details of the reconstructed shape. Computation times depend on the resolution of the input imagery and vary between a few seconds and a couple of minutes for all experiments in this paper.	[Cremers, Daniel; Kolev, Kalin] Tech Univ Munich, Dept Comp Sci, D-85748 Garching, Germany	Technical University of Munich	Cremers, D (corresponding author), Tech Univ Munich, Dept Comp Sci, Boltzmanstr 3, D-85748 Garching, Germany.	daniel.cremers@in.tum.de; kalin.kolev@in.tum.de			German Research Foundation [CR250/1-2]	German Research Foundation(German Research Foundation (DFG))	The authors thank Reinhard Klein and Dirk Koch for support with indoor image acquisition. They thank Svetlana Matiouk for helping with outdoor image acquisition and camera calibration, Carlos Hernandez and Yasutaka Furukawa for providing the data sets in Figs. 6 and 7, Sudipta Sinha for sharing his results for Fig. 6, and Antonin Chambolle and Thomas Pock for fruitful discussions on projection methods and convex optimization. This research was supported by the German Research Foundation, grant #CR250/1-2.	Baumgart B.G., 1974, THESIS STANFORD U; Boykov Y., 2006, P BRIT MACH VIS C, V3, P1149; Boyle J. P., 1986, ADV ORDER RESTRICTED, P28, DOI DOI 10.1007/978-1-4613-9940-7_3; Cipolla R., 2000, VISUAL MOTION CURVES; CROSS G, 2000, CONFLUENCE COMPUTER, P25; DUAN Y, 2004, EUR C COMP VIS, V3, P238; DYKSTRA RL, 1983, J AM STAT ASSOC, V78, P837, DOI 10.2307/2288193; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Franco J.-S., 2003, BRIT MACH VIS C BMVC, V1, P329, DOI [DOI 10.5244/C.17.32, 10.5244/C.17.32]; Furukawa Y, 2006, LECT NOTES COMPUT SC, V3951, P564; GARGALLO P, 2007, P IEEE INT C COMP VI; HERNANDEZ C, 2007, P IEEE INT C COMP VI; Isidoro J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1335; KOLEV K, 2007, P WORKSH PHOT AN COM; Kolev K., 2008, P EUR C COMP VIS; Kolev K, 2006, LECT NOTES COMPUT SC, V4174, P688; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Lempitsky V, 2006, LECT NOTES COMPUT SC, V3953, P226, DOI 10.1007/11744078_18; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; Matsumoto K, 1999, LECT NOTES COMPUT SC, V1568, P177; Pock Thomas, 2009, P IEEE INT C COMP VI; POLLEFEYS M., 2007, P IEEE INT C COMP VI; Seitz S., 2006, P INT C COMP VIS PAT, P519, DOI DOI 10.1109/CVPR.2006.19; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; Sinha SN, 2005, IEEE I CONF COMP VIS, P349; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Snow D, 2000, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2000.855839; Tran S, 2006, LECT NOTES COMPUT SC, V3952, P219; Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016; Vogiatzis G, 2005, PROC CVPR IEEE, P391; Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234	32	55	61	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1161	1174		10.1109/TPAMI.2010.174	http://dx.doi.org/10.1109/TPAMI.2010.174			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	20820076	Green Submitted			2022-12-18	WOS:000289524000007
J	Cont, A				Cont, Arshia			A Coupled Duration-Focused Architecture for Real-Time Music-to-Score Alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Automatic musical accompaniment; hidden hybrid Markov/semi-Markov models; computer music	HIDDEN MARKOV-MODELS	The capacity for real-time synchronization and coordination is a common ability among trained musicians performing a music score that presents an interesting challenge for machine intelligence. Compared to speech recognition, which has influenced many music information retrieval systems, music's temporal dynamics and complexity pose challenging problems to common approximations regarding time modeling of data streams. In this paper, we propose a design for a real-time music-to-score alignment system. Given a live recording of a musician playing a music score, the system is capable of following the musician in real time within the score and decoding the tempo (or pace) of its performance. The proposed design features two coupled audio and tempo agents within a unique probabilistic inference framework that adaptively updates its parameters based on the real-time context. Online decoding is achieved through the collaboration of the coupled agents in a Hidden Hybrid Markov/semi-Markov framework, where prediction feedback of one agent affects the behavior of the other. We perform evaluations for both real-time alignment and the proposed temporal model. An implementation of the presented system has been widely used in real concert situations worldwide and the readers are encouraged to access the actual system and experiment the results.	Ircam Ctr Pompidou, F-75004 Paris, France		Cont, A (corresponding author), Ircam Ctr Pompidou, 1 Pl Igor Stravinsky, F-75004 Paris, France.	arshia.cont@ircam.fr	Cont, Arshia/C-3926-2014	Cont, Arshia/0000-0002-7352-7212	European Commission	European Commission(European CommissionEuropean Commission Joint Research Centre)	This research was partially funded by the European Commission in the framework of the FP7 SAME project. The author would like to specially thank composer Marco Stroppa, who initiated the artistic challenges that led to the design exposed in this paper. The system descibed in this paper, Antescofo, has been designed specifically for a new work by Stroppa and is today in use for other music pieces and more new works to come.	Boulez Pierre, 1963, PENSER MUSIQUE AUJOU; CONT A, 2005, P IEEE INT C AC SPEE; Cont A., 2007, P 8 INT C MUS INF RE; Cont A, 2006, IEEE INT C AC SPEECH; CONT A, 2008, P INT COMP MUS C AUG; Danneberg R. B., 2007, P INT COMP MUS C ICM, V2, P89; Dannenberg R., 1997, P INT COMP MUS C, P301; Dannenberg R, 2003, P INT COMP MUS C ICM, P27; DANNENBERG RB, 1984, ICMC, V0084, P00193; Dixon S., 2005, P 8 INT C DIG AUD EF; Ferguson JD, 1980, P S APPL HIDD MARK M, P143; Guedon Y, 2005, COMPUT STAT DATA AN, V49, P663, DOI 10.1016/j.csda.2004.05.033; Johnson MT, 2005, IEEE SIGNAL PROC LET, V12, P407, DOI 10.1109/LSP.2005.845598; Keshet J, 2007, IEEE T AUDIO SPEECH, V15, P2373, DOI 10.1109/TASL.2007.903928; Mardia K.V., 2000, DIRECTIONAL STAT; Maybeck P S, 1979, STOCHASTIC MODELS ES, V1; McNab R. J., 1996, Proceedings of the 1st ACM International Conference on Digital Libraries, P11, DOI 10.1145/226931.226934; Moore F. R., 1990, ELEMENTS COMPUTER MU; Muller M., 2007, INFORM RETRIEVAL MUS, V6, P9; Murphy K.P., 2002, DYNAMIC BAYESIAN NET; ORIO N, 2001, P INT COMP MUS C; Peretz I, 2005, ANNU REV PSYCHOL, V56, P89, DOI 10.1146/annurev.psych.56.091103.070225; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Raphael C, 1999, IEEE T PATTERN ANAL, V21, P360, DOI 10.1109/34.761266; Raphael C, 2006, MACH LEARN, V65, P389, DOI 10.1007/s10994-006-8415-3; Rosen B, 1999, OPHTHALMOLOGY, V106, P1, DOI 10.1016/S0161-6420(99)90031-3; *SCOFOMIREX, 2006, SCOR FOLL EV PROP; VERCOE B., 1984, P INT COMP MUS C, P199; XENAKIS I, 1971, FORMALIZED MUSIC; YEH C, 2007, P 8 INT C MUS INF RE, P393; [No title captured]	31	55	56	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					974	987		10.1109/TPAMI.2009.106	http://dx.doi.org/10.1109/TPAMI.2009.106			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431125	Green Submitted			2022-12-18	WOS:000276671900002
J	Cardoso, JD; Capela, A; Rebelo, A; Guedes, C; da Costa, JP				Cardoso, Jaime dos Santos; Capela, Artur; Rebelo, Ana; Guedes, Carlos; da Costa, Joaquim Pinto			Staff Detection with Stable Paths	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Music; optical character recognition; document image processing; image analysis		The preservation of musical works produced in the past requires their digitalization and transformation into a machine-readable format. The processing of handwritten musical scores by computers remains far from ideal. One of the fundamental stages to carry out this task is the staff line detection. We investigate a general-purpose, knowledge-free method for the automatic detection of music staff lines based on a stable path approach. Lines affected by curvature, discontinuities, and inclination are robustly detected. Experimental results show that the proposed technique consistently outperforms well-established algorithms.	[Cardoso, Jaime dos Santos; Capela, Artur; Rebelo, Ana] Univ Porto, INESC Porto, Fac Engn, P-4200465 Oporto, Portugal; [Guedes, Carlos] Escola Super Mus & Artes Espectaculo, INESC Porto, P-4200465 Oporto, Portugal; [da Costa, Joaquim Pinto] Univ Porto, Fac Ciencias, P-4169007 Oporto, Portugal	INESC TEC; Universidade do Porto; INESC TEC; Universidade do Porto; Universidade do Porto	Cardoso, JD (corresponding author), Univ Porto, INESC Porto, Fac Engn, Campus FEUP,Rua Dr Roberto Frias 378, P-4200465 Oporto, Portugal.	jaime.cardos@inescporto.pt; gcapela@inescporto.pt; arebelo@inescporto.pt; carlosguedes@mac.com; jpcosta@fc.up.pt	Cardoso, Jaime S/I-3286-2013; Guedes, Carlos/M-9971-2013; Rebelo, Ana/I-1121-2015; Da Costa, Joaquim F/B-6720-2011	Cardoso, Jaime S/0000-0002-3760-2473; Guedes, Carlos/0000-0002-1898-2183; Rebelo, Ana/0000-0003-4776-6057; Da Costa, Joaquim F/0000-0002-3991-2715; Capela, Artur/0000-0002-3454-8010	Fundacao para a Cincia e a Tecnologia (FCT)-Portugal [PTDC/EIA/71225/2006]	Fundacao para a Cincia e a Tecnologia (FCT)-Portugal(Portuguese Foundation for Science and Technology)	This work was partially funded by Fundacao para a Cincia e a Tecnologia (FCT)-Portugal through project PTDC/EIA/71225/2006. The authors are grateful to the reviewers for their many stimulating and thoughtful comments.	Bainbridge D., 1997, THESIS U CANTERBURY; Capela A, 2008, SIGMAP 2008: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS, P263; CARDOSO JS, P INT C IM IN PRESS; CARTER NP, 1989, THESIS U SURREY; DALITZ C, 2009, STAFF REMOVAL TOOLKI; Dalitz C, 2008, IEEE T PATTERN ANAL, V30, P753, DOI [10.1109/TPAMI.2007.70749, 10.1109/TPAM1.2007.70749]; Fujikane T, 2004, INT J TUBERC LUNG D, V8, P39; GAWEDZKI I, 2002, OPTICAL MUSIC SCORES; Leplumey I., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P902, DOI 10.1109/ICDAR.1993.395591; MAHONEY JV, 1982, THESIS MIT; Miyao H., 2004, J ADV COMPUTATIONAL, V8, P208, DOI DOI 10.20965/JACIII.2004.P0208; Prerau D, 1992, STRUCTURED DOCUMENT, P405; PRERAU D, 1970, THESIS MIT; Rebelo A, 2007, AXMEDIS 2007: THIRD INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P79, DOI 10.1109/AXMEDIS.2007.16; ROACH JW, 1988, PATTERN RECOGN, V21, P33, DOI 10.1016/0031-3203(88)90069-6; Szwoch M, 2005, LECT NOTES COMPUT SC, V3691, P701	16	55	56	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1134	1139		10.1109/TPAMI.2009.34	http://dx.doi.org/10.1109/TPAMI.2009.34			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372615	Green Submitted			2022-12-18	WOS:000265100000013
J	Todorovic, S; Ahuja, N				Todorovic, Sinisa; Ahuja, Narendra			Unsupervised Category Modeling, Recognition, and Segmentation in Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; image segmentation tree; hierarchical object representation; unsupervised learning; graph matching; tree union	OBJECT RECOGNITION; INTEGRATED EDGE; REPRESENTATION; GRAMMARS; GRAPHS	Suppose a set of arbitrary (unlabeled) images contains frequent occurrences of 2D objects from an unknown category. This paper is aimed at simultaneously solving the following related problems: 1) unsupervised identification of photometric, geometric, and topological properties of multiscale regions comprising instances of the 2D category, 2) learning a region-based structural model of the category in terms of these properties, and 3) detection, recognition, and segmentation of objects from the category in new images. To this end, each image is represented by a tree that captures a multiscale image segmentation. The trees are matched to extract the maximally matching subtrees across the set, which are taken as instances of the target category. The extracted subtrees are then fused into a tree union that represents the canonical category model. Detection, recognition, and segmentation of objects from the learned category are achieved simultaneously by finding matches of the category model with the segmentation tree of a new image. Experimental validation on benchmark data sets demonstrates the robustness and high accuracy of the learned category models when only a few training examples are used for learning without any human supervision.	[Todorovic, Sinisa; Ahuja, Narendra] Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Todorovic, S (corresponding author), Univ Illinois, Beckman Inst, 405 N Mathews Ave, Urbana, IL 61801 USA.	sintod@vision.ai.uiuc.edu; ahuja@vision.ai.uiuc.edu			US National Science Foundation [NSF IIS 07-43014]	US National Science Foundation(National Science Foundation (NSF))	The support of the US National Science Foundation under grant NSF IIS 07-43014 is gratefully acknowledged. The authors would like to thank Himanshu Arora and the anonymous reviewers whose thoughtful comments and suggestions improved the quality of the paper.	Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Ahmadyfard AR, 2002, IMAGE VISION COMPUT, V20, P769, DOI 10.1016/S0262-8856(02)00040-9; Ahuja N, 1996, IEEE T PATTERN ANAL, V18, P1211, DOI 10.1109/34.546258; ARORA H, 2006, P INT C PATT REC; Basri R, 1997, INT J COMPUT VISION, V25, P145, DOI 10.1023/A:1007919917506; BORENSTEIN E, 2002, P EUR C COMP VIS ECC, V2, P109; BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898; BRETZNER L, 1999, P INT SCAL SPAC C, P117; Bunke H, 1983, PATTERN RECOGN LETT, V1, P245, DOI 10.1016/0167-8655(83)90033-8; Bunke H, 2003, LECT NOTES COMPUT SC, V2726, P235; Bunke H, 2000, PATTERN RECOGN LETT, V21, P163, DOI 10.1016/S0167-8655(99)00143-9; Bunke H, 2000, COMPUTING, V65, P13; Caelli T, 2004, IEEE T PATTERN ANAL, V26, P515, DOI 10.1109/TPAMI.2004.1265866; Cheng H, 2001, IEEE T IMAGE PROCESS, V10, P511, DOI 10.1109/83.913586; Chong EK., 2013, INTRO OPTIMIZATION; CLEMENS DT, 1991, AITR1307 MIT; CROWLEY JL, 1987, IEEE T PATTERN ANAL, V9, P113, DOI 10.1109/TPAMI.1987.4767876; Demirci MF, 2006, INT J COMPUT VISION, V69, P203, DOI 10.1007/s11263-006-6993-y; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; ESHERA MA, 1986, IEEE T PATTERN ANAL, V8, P604, DOI 10.1109/TPAMI.1986.4767835; Ettinger G. J., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P32, DOI 10.1109/CVPR.1988.196212; FAN TJ, 1989, IEEE T PATTERN ANAL, V11, P1140, DOI 10.1109/34.42853; FELDMAN JA, 1974, ARTIF INTELL, V5, P349, DOI 10.1016/0004-3702(74)90002-2; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R, 2003, PROC CVPR IEEE, P264; FIDLER S, 2006, P IEEE INT C COMP VI, V1, P182; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gupta A, 1998, ALGORITHMICA, V21, P183, DOI 10.1007/PL00009212; Hanson A., 1978, COMPUTER VISION SYST, P303; Jiang XY, 2001, IEEE T PATTERN ANAL, V23, P1144; JIN Y, 2006, P IEEE C COMP VIS PA, V2, P2145; Keselman Y, 2005, IEEE T PATTERN ANAL, V27, P1141, DOI 10.1109/TPAMI.2005.139; KREMPP S, 2002, SEQUENTIAL LEARNING; Leibe B., 2004, EUROPEAN C COMPUTER, P17; Levinshtein A, 2005, LECT NOTES COMPUT SC, V3757, P251, DOI 10.1007/11585978_17; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Luo B, 2003, PATTERN RECOGN, V36, P2213, DOI 10.1016/S0031-3203(03)00084-0; NISHIDA H, 1993, IEEE T PATTERN ANAL, V15, P1298, DOI 10.1109/34.250847; Ommer B., 2006, P IEEE INT C COMP VI, P194; OPELT A, 2006, P IEEE C COMP VIS PA, V1, P3; Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; PELILLO M, 2001, LECT NOTES COMPUTER, V2059, P583; PERRIN B, 1998, P AS C COMP VIS, V1352, P323; RUSSELL BC, 2006, P IEEE INT C COMP VI, V2, P1604; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shokoufandeh A, 2005, IEEE T PATTERN ANAL, V27, P1125, DOI 10.1109/TPAMI.2005.142; Shokoufandeh A, 1999, IMAGE VISION COMPUT, V17, P445, DOI 10.1016/S0262-8856(98)00124-3; Shokoufandeh A, 2006, COMPUT VIS IMAGE UND, V103, P139, DOI 10.1016/j.cviu.2006.05.001; Shotton J, 2005, IEEE I CONF COMP VIS, P503; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siskind JM, 2007, IEEE T PATTERN ANAL, V29, P1504, DOI 10.1109/TPAMI.2007.1169; Sophia T., 2005, THESIS J GUTENBERG U; Storkey AJ, 2003, IEEE T PATTERN ANAL, V25, P859, DOI 10.1109/TPAMI.2003.1206515; Tabb M, 1997, IEEE T IMAGE PROCESS, V6, P642, DOI 10.1109/83.568922; Todorovic S, 2005, IEEE T PATTERN ANAL, V27, P1762, DOI 10.1109/TPAMI.2005.219; TODOROVIC S, 2006, P IEEE INT C COMP VI, V1, P927; TODOROVIC S, INT J COMPU IN PRESS; TODOROVIC S, 2006, COMPUTER VISION IMAG; Torsello A, 2006, IEEE T PATTERN ANAL, V28, P954, DOI 10.1109/TPAMI.2006.125; Torsello A, 2003, PATTERN RECOGN LETT, V24, P1089, DOI 10.1016/S0167-8655(02)00255-6; TORSELLO A, 2002, P EUR C COMP VIS, V3, P822; TOUZANI A, 1988, IEEE T PATTERN ANAL, V10, P970, DOI 10.1109/34.9120; UTANS J, 1994, ADV NEURAL INFORMATI, V6, P285; Wang W, 2006, IEEE T IMAGE PROCESS, V15, P3033, DOI 10.1109/TIP.2006.877496; Weiss I, 2005, IEEE T PATTERN ANAL, V27, P1660, DOI 10.1109/TPAMI.2005.208; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Winn J, 2005, IEEE I CONF COMP VIS, P756; Winston PH, 1975, PSYCHOL COMPUTER VIS, P157; XU Y, 2005, COMPUTER VISION IMAG, V95, P334; ZHANG RF, 2004, P IEEE INC C CVPR, V2, P996	71	55	55	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2008	30	12					2158	2174		10.1109/TPAMI.2008.24	http://dx.doi.org/10.1109/TPAMI.2008.24			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	360CF	18988949				2022-12-18	WOS:000260033900007
J	Fumera, G; Roli, F; Serrau, A				Fumera, Giorgio; Roli, Fabio; Serrau, Alessandra			A theoretical analysis of bagging as a linear combination of classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiple classifier systems; bagging; linear combiners; classifier fusion; pattern classification		We apply an analytical framework for the analysis of linearly combined classifiers to ensembles generated by bagging. This provides an analytical model of bagging misclassification probability as a function of the ensemble size, which is a novel result in the literature. Experimental results on real data sets confirm the theoretical predictions. This allows us to derive a novel and theoretically grounded guideline for choosing bagging ensemble size. Furthermore, our results are consistent with explanations of bagging in terms of classifier instability and variance reduction, support the optimality of the simple average over the weighted average combining rule for ensembles generated by bagging, and apply to other randomization-based methods for constructing classifier ensembles. Although our results do not allow to compare bagging misclassification probability with the one of an individual classifier trained on the original training set, we discuss how the considered theoretical framework could be exploited to this aim.	[Fumera, Giorgio; Roli, Fabio; Serrau, Alessandra] Univ Cagliari, Dept Elect & Elect Engn, I-09123 Cagliari, Italy	University of Cagliari	Fumera, G (corresponding author), Univ Cagliari, Dept Elect & Elect Engn, Piazza Armi, I-09123 Cagliari, Italy.	fumera@diee.unica.it; roli@diee.unica.it; serrau@diee.unica.it		ROLI, FABIO/0000-0003-4103-9190				Banfield RE, 2007, IEEE T PATTERN ANAL, V29, P173, DOI 10.1109/TPAMI.2007.250609; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Chawla N, 2001, PROC CVPR IEEE, P684; DIETTERICH TG, 1999, MACH LEARN, V40, P1; Domigos P., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P155; Fumera G, 2005, LECT NOTES COMPUT SC, V3541, P316; Fumera G, 2005, IEEE T PATTERN ANAL, V27, P942, DOI 10.1109/TPAMI.2005.109; Grandvalet Y, 2004, MACH LEARN, V55, P251, DOI 10.1023/B:MACH.0000027783.34431.42; Gunter S, 2004, INT J PATTERN RECOGN, V18, P1303, DOI 10.1142/S0218001404003678; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; Kuncheva L., 2014, COMBINING PATTERN CL; LATINNE P, 2001, P INT WORKSH MULT CL, V2096, P178; Martinez-Munoz G, 2007, PATTERN RECOGN LETT, V28, P156, DOI 10.1016/j.patrec.2006.06.018; Skurichina M, 1998, PATTERN RECOGN, V31, P909, DOI 10.1016/S0031-3203(97)00110-6; Tumer K, 1996, PATTERN RECOGN, V29, P341, DOI 10.1016/0031-3203(95)00085-2; TUMER K, 1996, THESIS U TEXAS AUSTI; Tumer K., 1999, COMBINING ARTIFICIAL, P127; Valentini G, 2005, IEEE T SYST MAN CY B, V35, P1252, DOI 10.1109/TSMCB.2005.850183	20	55	58	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1293	1299		10.1109/TPAMI.2008.30	http://dx.doi.org/10.1109/TPAMI.2008.30			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550910				2022-12-18	WOS:000256294100014
J	Hernandez, C; Schmitt, F; Cipolla, R				Hernandez, Carlos; Schmitt, Francis; Cipolla, Roberto			Silhouette coherence for camera calibration under circular motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						silhouette coherence; epipolar tangency; image; based visual hull; focal length estimation; circular motion; 3D modeling	PROFILES; STEREO; SHAPE	We present a new approach to camera calibration as a part of a complete and practical system to recover digital copies of sculpture from uncalibrated image sequences taken under turntable motion. In this paper, we introduce the concept of the silhouette coherence of a set of silhouettes generated by a 3D object. We show how the maximization of the silhouette coherence can be exploited to recover the camera poses and focal length. Silhouette coherence can be considered as a generalization of the well-known epipolar tangency constraint for calculating motion from silhouettes or outlines alone. Further, silhouette coherence exploits all the geometric information encoded in the silhouette ( not just at epipolar tangency points) and can be used in many practical situations where point correspondences or outer epipolar tangents are unavailable. We present an algorithm for exploiting silhouette coherence to efficiently and reliably estimate camera motion. We use this algorithm to reconstruct very high quality 3D models from uncalibrated circular motion sequences, even when epipolar tangency points are not available or the silhouettes are truncated. The algorithm has been integrated into a practical system and has been tested on more than 50 uncalibrated sequences to produce high quality photo-realistic models. Three illustrative examples are included in this paper. The algorithm is also evaluated quantitatively by comparing it to a state-of-the-art system that exploits only epipolar tangents.	Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England; GET ENST Telecom Paris, CNRS, UMR 5141, Signal & Image Proc Dept, F-75634 Paris 13, France	University of Cambridge; Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; UDICE-French Research Universities; Universite Paris Cite	Hernandez, C (corresponding author), Univ Cambridge, Dept Engn, MI Lab,Room 426, Cambridge CB2 1PZ, England.	ch394@eng.cam.ac.uk; francis.schmitt@enst.fr; cipolla@eng.cam.ac.uk	Arandjelović, Ognjen/V-5255-2019; Smejda, Ladislav/B-8474-2008	Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla, Roberto/0000-0002-8999-2151				Astrom K, 1999, INT J COMPUT VISION, V33, P51, DOI 10.1023/A:1008113231241; Bottino A, 2003, IEEE T PATTERN ANAL, V25, P1484, DOI 10.1109/TPAMI.2003.1240121; Boyer E, 2006, LECT NOTES COMPUT SC, V3851, P1; CHEUNG KM, 2003, THESIS CARNEGIE MELL; CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775; Cipolla R., 2000, VISUAL MOTION CURVES; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Fitzgibbon A. W., 1998, 3D Structure from Multiple Images of Large-Scale Environments. European Workshop, SMILE'98. Proceedings, P155; Franco J.-S., 2003, BRIT MACH VIS C BMVC, V1, P329, DOI [DOI 10.5244/C.17.32, 10.5244/C.17.32]; FURUKAWA Y, 2004, P ECCV, V2, P287; Gargallo P, 2005, PROC CVPR IEEE, P885; GIBLIN PJ, 1994, J OPT SOC AM A, V11, P1976, DOI 10.1364/JOSAA.11.001976; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HERNANDEZ C, 2006, 559 U CAMBR; Jiang G, 2002, LECT NOTES COMPUT SC, V2350, P537; Jin HL, 2003, PROC CVPR IEEE, P171; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LAVEST JM, 1998, P EUR C COMP VIS, V1, P158; LENSCH H, 2001, J GRAPHICAL MODELS, P245; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; Mendonca PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; PORRILL J, 1991, IMAGE VISION COMPUT, V9, P45, DOI 10.1016/0262-8856(91)90048-T; POWELL MJD, 1964, COMPUT J, V7, P155, DOI 10.1093/comjnl/7.2.155; RIEGER JH, 1986, OPT LETT, V11, P123, DOI 10.1364/OL.11.000123; Sinha SN, 2004, PROC CVPR IEEE, P195; Vijayakumar B, 1996, PROC CVPR IEEE, P327, DOI 10.1109/CVPR.1996.517093; Vogiatzis G, 2005, PROC CVPR IEEE, P391; Wong KYK, 2004, IEEE T IMAGE PROCESS, V13, P379, DOI 10.1109/TIP.2003.821113; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186	31	55	60	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					343	349		10.1109/TPAMI.2007.42	http://dx.doi.org/10.1109/TPAMI.2007.42			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV	17170485	Green Submitted			2022-12-18	WOS:000242826900013
J	Verbeek, J				Verbeek, Jakob			Learning nonlinear image manifolds by global alignment of local linear models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature extraction or construction; machine learning; statistical image representation	MAXIMUM-LIKELIHOOD; MIXTURES; RECOGNITION; EIGENMAPS; KERNEL	Appearance- based methods, based on statistical models of the pixel values in an image ( region) rather than geometrical object models, are increasingly popular in computer vision. In many applications, the number of degrees of freedom ( DOF) in the image generating process is much lower than the number of pixels in the image. If there is a smooth function that maps the DOF to the pixel values, then the images are confined to a low- dimensional manifold embedded in the image space. We propose a method based on probabilistic mixtures of factor analyzers to 1) model the density of images sampled from such manifolds and 2) recover global parameterizations of the manifold. A globally nonlinear probabilistic two- way mapping between coordinates on the manifold and images is obtained by combining several, locally valid, linear mappings. We propose a parameter estimation scheme that improves upon an existing scheme and experimentally compare the presented approach to self- organizing maps, generative topographic mapping, and mixtures of factor analyzers. In addition, we show that the approach also applies to finding mappings between different embeddings of the same manifold.	GRAVIR INRIA, F-38330 Montbonnot St Martin, France		Verbeek, J (corresponding author), GRAVIR INRIA, 655 Ave Europe, F-38330 Montbonnot St Martin, France.	verbeek@inrialpes.fr						Belkin M, 2002, ADV NEUR IN, V14, P585; Bellman RE., 1961, ADAPTIVE CONTROL PRO, DOI [DOI 10.1515/9781400874668, 10.1515/9781400874668]; Bengio Y, 2004, ADV NEUR IN, V16, P177; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Brand  M., 2003, ADV NEURAL INFORM PR, P961, DOI DOI 10.1109/34.682189; Bregler C., 1995, Advances in Neural Information Processing Systems 7, P973; Carr JC, 1997, IEEE T MED IMAGING, V16, P96, DOI 10.1109/42.552059; Chang K, 2001, IEEE T PATTERN ANAL, V23, P22, DOI 10.1109/34.899944; Chretien S, 2000, IEEE T INFORM THEORY, V46, P1800, DOI 10.1109/18.857792; Cramer J.S., 2003, ORIGINS LOGISTIC REG; de Ridder D, 2003, P BRIT MACH VIS C, P319; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fodor I.K., 2002, SURVEY DIMENSION RED, V9, P1, DOI [10.2172/15002155, DOI 10.2172/15002155]; Ghahramani Z, 2000, ADV NEUR IN, V12, P449; Ghahramani Z., 1994, P ADV NEUR INF PROC, P120; Ghahramani Zoubin, 1996, CRGTR961 U TOR; Ham J., 2005, P ANN C UNC ART INT, P120; Ham J.H., 2003, P WORKSH CONT LAB UN; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; He XF, 2004, ADV NEUR IN, V16, P153; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; KAMBHATLA N, 1994, ADV NEURAL INFORMATI, V6, P152, DOI DOI 10.1109/ICNN.1993.298730; KARGER H, 1977, COMMUN PUR APPL MATH, V3, P509; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Kegl B., 2003, ADV NEURAL INFORM PR, V15, P681; Kohonen T., 1995, SELF ORG MAPS; Leonardis A, 2003, PATTERN RECOGN, V36, P1925, DOI 10.1016/S0031-3203(03)00055-4; Levina E., 2005, ADV NEURAL INFORM PR, V17, P777, DOI DOI 10.5555/2976040.2976138; Meng XL, 1997, J ROY STAT SOC B MET, V59, P511, DOI 10.1111/1467-9868.00082; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; OJA E, 1991, P INT C ART NEUR NET, P737; OLIVER JJ, 1996, P INT C MACH LEARN, V13, P364; Peter M, 2002, SEMIN REPROD MED, V20, P249, DOI 10.1055/s-2002-35389; RITTER H, 1993, ARTIFICIAL NEURAL NE, V3, P568; Roweis S, 2002, ADV NEUR IN, V14, P889; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Teh W. Y., 2003, ADV NEURAL INFORMATI, V15, P841; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Verbeek J., 2004, THESIS U AMSTERDAM; Verbeek JJ, 2005, NEUROCOMPUTING, V63, P99, DOI 10.1016/j.neucom.2004.04.008; Verbeek JJ, 2004, ADV NEUR IN, V16, P297; VERBEEK JJ, 2002, P INT C ART NEUR NET, V12, P914; Webb A.R., 2003, STAT PATTERN RECOGNI; Weinberger KQ, 2004, PROC CVPR IEEE, P988; WIEGHARDT J, 2001, THESIS RUHR U BOCHUM	54	55	58	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1236	1250		10.1109/TPAMI.2006.166	http://dx.doi.org/10.1109/TPAMI.2006.166			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886860	Green Submitted			2022-12-18	WOS:000238162400006
J	Park, BG; Lee, KM; Lee, SU				Park, BG; Lee, KM; Lee, SU			Face recognition using Face-ARG matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ARG matching; face recognition; structural representation; stochastic analysis.	EXPRESSION VARIANT FACES; OBJECTS; REPRESENTATION; EIGENFACES; IMAGES; PARTS	In this paper, we propose a novel line feature-based face recognition algorithm. A face is represented by the Face-ARG model, where all the geometric quantities and the structural information are encoded in an Attributed Relational Graph (ARG) structure, then the partial ARG matching is done for matching Face-ARG's. Experimental results demonstrate that the proposed algorithm is quite robust to various facial expression changes, varying illumination conditions and occlusion, even when a single sample per person is given.	Samsung Elect Co Ltd, Digital Media R&D, Suwon 443370, Kyounggi, South Korea; Seoul Natl Univ, Sch Elect Engn & Comp Sci, Seoul 151744, South Korea	Samsung; Samsung Electronics; Seoul National University (SNU)	Park, BG (corresponding author), Samsung Elect Co Ltd, Digital Media R&D, Suwon 443370, Kyounggi, South Korea.	apollo.park@samsung.com; kyoungmu@snu.ac.kr; sanguk@ipl.snu.ac.kr	Lee, Kyoung Mu/AAC-4063-2020	Lee, Kyoung Mu/0000-0001-7210-1036				Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; BRUCE V, 1992, APPL COGNITIVE PSYCH, V6, P619, DOI 10.1002/acp.2350060705; Bruce V, 1988, RECOGNISING FACES; Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; GROSS R, 2002, CMURITR0220; Hwang BW, 2003, IEEE T PATTERN ANAL, V25, P365, DOI 10.1109/TPAMI.2003.1182099; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee T.-W., 1998, INDEPENDENT COMPONEN; Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830; Li SZ, 2001, PROC CVPR IEEE, P207; Martinez A., 1998, 24 CVC, P24; Martinez A.M., 2003, P IEEE C COMP VIS PA; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Martinez AM, 2003, VISION RES, V43, P1047, DOI 10.1016/S0042-6989(03)00079-8; NEVATIA R, 1980, COMPUTER GRAPHICS IM, V13, P250; Park BG, 2003, COMPUT VIS IMAGE UND, V90, P217, DOI 10.1016/S1077-3142(03)00049-3; ROMDHANI S, 2002, P 7 EUR C COMP VIS M; ROTH I, 1995, PERCEPTION REPRESENT; SHASHUA A, 2001, IEEE T PATTERN ANAL, V23; TJAN BS, 1995, VISION RES, V35, P3053, DOI 10.1016/0042-6989(95)00070-G; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Yacoob Y, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P59, DOI 10.1109/AFGR.2002.1004132; Zhao W., 1999, CARTR914 U MAR; Zhao W., 2003, ACM COMPUTING SURVEY, V35	27	55	56	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1982	U1		10.1109/TPAMI.2005.243	http://dx.doi.org/10.1109/TPAMI.2005.243			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16355664				2022-12-18	WOS:000232532600012
J	Fred, ALN; Leitao, JMN				Fred, ALN; Leitao, JMN			A new cluster isolation criterion based on dissimilarity increments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; hierarchical methods; context-based clustering; cluster isolation criteria; dissimilarity increments; model-based clustering	VALIDITY	This paper addresses the problem of cluster defining criteria by proposing a model-based characterization of interpattern relationships. Taking a dissimilarity matrix between patterns as the basic measure for extracting group structure, dissimilarity increments between neighboring patterns within a cluster are analyzed. Empirical evidence suggests modeling the statistical distribution of these increments by an exponential density; we propose to use this statistical model, which characterizes context, to derive a new cluster isolation criterion. The integration of this criterion in a hierarchical agglomerative clustering framework produces a partitioning of the data, while exhibiting data interrelationships in terms of a dendrogram-type graph. The analysis of the criterion is undertaken through a set of examples, showing the versatility of the method in identifying clusters with arbitrary shape and size; the number of clusters is intrinsically found without requiring ad hoc specification of design parameters nor engaging in a computationally demanding optimization procedure.	Univ Tecn Lisboa, Inst Telecomunicacoes, Inst Super Tecn, P-1049001 Lisbon, Portugal	Instituto de Telecomunicacoes; Universidade de Coimbra; Universidade de Lisboa; Instituto Superior Tecnico	Fred, ALN (corresponding author), Univ Tecn Lisboa, Inst Telecomunicacoes, Inst Super Tecn, Av Rovisco Pais, P-1049001 Lisbon, Portugal.	afred@lx.it.pt; jleitao@lx.it.pt	Fred, Ana L. N./A-7464-2016	Fred, Ana L. N./0000-0003-1320-5024; Leitao, Jose/0000-0001-7213-2414				BAILEY TA, 1982, PATTERN RECOGN, V15, P61, DOI 10.1016/0031-3203(82)90002-4; Bajcsy P, 1998, IEEE T PATTERN ANAL, V20, P1011, DOI 10.1109/34.713365; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Bischof H, 1999, INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, P355; Buhmann JM, 1999, INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, P167; Chakravarthy SV, 1996, IEEE T NEURAL NETWOR, V7, P1250, DOI 10.1109/72.536318; Chavent M, 1998, PATTERN RECOGN LETT, V19, P989, DOI 10.1016/S0167-8655(98)00087-7; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Comaniciu D, 1999, PATTERN ANAL APPL, V2, P22, DOI 10.1007/s100440050011; DUBES R, 1979, PATTERN RECOGN, V11, P235, DOI 10.1016/0031-3203(79)90034-7; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; El-Sonbaty Y, 1998, PATTERN RECOGN LETT, V19, P1285, DOI 10.1016/S0167-8655(98)00104-4; Figueiredo M. A. T., 1999, Energy Minimization Methods in Computer Vision and Pattern Recognition. Second International Workshop, EMMCVPR'99. Proceedings (Lecture Notes in Computer Science Vol.1654), P54; Fischer B, 2001, LECT NOTES COMPUT SC, V2134, P235; FRED A, 2002, P 2 INT WORKSH PATT, P257; FRED AL, 1998, P INT C ADV PATT REC, P385; Fred ALN, 2000, INT C PATT RECOG, P190, DOI 10.1109/ICPR.2000.906045; Frigui H, 1999, IEEE T PATTERN ANAL, V21, P450, DOI 10.1109/34.765656; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Gokcay E, 2002, IEEE T PATTERN ANAL, V24, P158, DOI 10.1109/34.982897; GUHA S, 1998, P 1998 ACM SIGMOID I; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; Kaufman L., 2009, FINDING GROUPS DATA; Kothari R, 1999, PATTERN RECOGN LETT, V20, P405, DOI 10.1016/S0167-8655(99)00008-2; MAN Y, 1994, IEEE T PATTERN ANAL, V16, P855, DOI 10.1109/34.308484; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; Merz C., 1996, UCI REPOSITORY MACHI; Mirkin B, 1999, MACH LEARN, V35, P25, DOI 10.1023/A:1007567018844; OOMEN BJ, 1995, P INT C SYST MAN CYB, P1154; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; PAUWELS EJ, 1999, P IS T SPIE C STOR R, V3656, P501; Ristad ES, 1998, IEEE T PATTERN ANAL, V20, P522, DOI 10.1109/34.682181; Roberts SJ, 1998, IEEE T PATTERN ANAL, V20, P1133, DOI 10.1109/34.730550; Sankoff D., 1999, TIME WARPS STRING ED; Stanford D., 1997, PRINCIPAL CURVE CLUS; TENMOTO H, 1998, ADV PATTERN RECOGNIT, V1451, P831; Tyree EW, 1999, PATTERN RECOGN LETT, V20, P21, DOI 10.1016/S0167-8655(98)00125-1; Yin PY, 1998, PATTERN RECOGN LETT, V19, P31, DOI 10.1016/S0167-8655(97)00154-2; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	41	55	56	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2003	25	8					944	958		10.1109/TPAMI.2003.1217600	http://dx.doi.org/10.1109/TPAMI.2003.1217600			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	702XJ		Green Submitted			2022-12-18	WOS:000184249800002
J	Tan, CL; Cao, RN; Shen, PY				Tan, CL; Cao, RN; Shen, PY			Restoration of archival documents using a wavelet technique	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image analysis; wavelet enhancement; wavelet smearing; Canny edge detector; text extraction; image segmentation; bleed-through; show-through; noise cancellation; denoising		This paper addresses a problem of restoring handwritten archival documents by recovering their contents from the interfering handwriting on the reverse side caused by the seeping of ink. We present a novel method that works by first matching both sides of a document such that the interfering strokes are mapped with the corresponding strokes originating from the reverse side. This facilitates the identification of the foreground and interfering strokes. A wavelet reconstruction process then iteratively enhances the foreground strokes and smears the interfering strokes so as to strengthen the discriminating capability of an improved Canny edge detector against the interfering strokes The method has been shown to restore the documents effectively with average precision and recall rates for foreground text extraction at 84 percent and 96 percent, respectively.	Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore; Hotcard Technol Pte Ltd, Singapore 609601, Singapore; Commun Solut Grp, Agilent Technol, Singapore 768923, Singapore	National University of Singapore; Agilent Technologies	Tan, CL (corresponding author), Natl Univ Singapore, Sch Comp, 3 Sci Dr 2, Singapore 117543, Singapore.	tancl@comp.nus.edu.sg; caorn@hotcardtech.com; pei-yi_shen@aglient.com						BERKNER K, 2000, P INT C IM PROC SEPT, V3, P797; Cao R., 2000, P 4 IAPR INT WORKSH, P147; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; Don H.S., 1995, P 3 INT C DOC AN REC, P231; Donoho D. L., 1994, Proceedings of the 16th Annual International Conference of the IEEE Engineering in Medicine and Biology Society. Engineering Advances: New Opportunities for Biomedical Engineers (Cat. No.94CH3474-4), pA24, DOI 10.1109/IEMBS.1994.412133; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Etemad K, 1997, IEEE T PATTERN ANAL, V19, P92, DOI 10.1109/34.566817; Feng L., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P71, DOI 10.1109/ICDAR.1999.791727; Hwang WL, 1996, P SOC PHOTO-OPT INS, V2825, P1003, DOI 10.1117/12.255222; Junker M., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P713, DOI 10.1109/ICDAR.1999.791887; LIANG S, 1994, CVGIP-GRAPH MODEL IM, V56, P402; Liu Y, 1997, IEEE T PATTERN ANAL, V19, P540, DOI 10.1109/34.589217; Lu J, 1996, P SOC PHOTO-OPT INS, V2825, P742, DOI 10.1117/12.255282; LU JA, 1994, OPT ENG, V33, P2151, DOI 10.1117/12.172254; MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; Negishi H., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P143, DOI 10.1109/ICDAR.1999.791745; Niblack W., 1986, INTRO DIGITAL IMAGE, P115; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Sharma G, 2001, IEEE T IMAGE PROCESS, V10, P736, DOI 10.1109/83.918567; SHARMA G, 2000, P INT C IM PROC SEPT, V3, P609; Tan CL, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P16, DOI 10.1109/WACV.2000.895397; WHITE JM, 1983, IBM J RES DEV, V27, P400, DOI 10.1147/rd.274.0400	23	55	55	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2002	24	10					1399	1404						6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	596ZF					2022-12-18	WOS:000178196300010
J	Cooke, T				Cooke, T			Two variations on Fisher's linear discriminant for pattern recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						linear discriminant; classification		Discriminants are often used in pattern recognition to separate clusters of points in some multidimensional "feature" space. This paper provides two fast and simple techniques for improving on the classification performance provided by Fisher's linear discriminant for two classes. Both of these methods are also extended to nonlinear decision surfaces through the use of Mercer kernels.	Ctr Sensor Signal & Informat Proc, Mawson Lakes, SA 5096, Australia		Cooke, T (corresponding author), Ctr Sensor Signal & Informat Proc, SPRI Bldg,1 Warrendi Rd, Mawson Lakes, SA 5096, Australia.	tcooke@cssip.edu.au						ANDERSON TW, 1962, ANN MATH STAT, V33, P420, DOI 10.1214/aoms/1177704568; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chapelle O, 2000, CHOOSING KERNEL PARA; COOKE T, IN PRESS J MULTIVARI; Duda R.O., 1973, J ROYAL STAT SOC SER; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Joachims T., 1999, ADV KERNEL METHODS S; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Mika S, 2001, P AISTATS, P98; Vapnik V.N, 1998, STAT LEARNING THEORY	10	55	60	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2002	24	2					268	273		10.1109/34.982904	http://dx.doi.org/10.1109/34.982904			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	516DC		Green Submitted			2022-12-18	WOS:000173535700009
J	Duta, N; Jain, AK; Dubuisson-Jolly, MP				Duta, N; Jain, AK; Dubuisson-Jolly, MP			Automatic construction of 2D shape models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape models; point correspondence; flexible registration; automatic landmarks; shape clustering	IMAGES; POINT; SEGMENTATION; REGISTRATION	A procedure for automated 2D shape model design is presented. The modeling system is given a set of training example shapes defined by the coordinates of their contour points. The shapes are automatically aligned using Procrustes analysis and clustered to obtain cluster prototypes (typical objects) and statistical information about intracluster shape variation. One difference from previously reported methods is that the training set is first automatically clustered and those shapes considered to be outliers are discarded. In this way, the cluster prototypes are not distorted by outlier shapes. A second difference is in the manner in which registered sets of points are extracted from each shape contour. We propose a flexible point matching technique that takes into account both pose/scale differences as well as nonlinear shape differences between a pair of objects. The matching method is independent of the initial relative position/scale of the two objects and does not require any manually tuned parameters. Our shape model design method was used to learn 11 different shapes from contours that were manually traced in MR brain images. The resulting model was then employed to segment several MR brain images that were not included in the shape-training set. A quantitative analysis of our shape registration approach, within the main cluster of each structure, demonstrated results that compare very well to those achieved by manual registration; achieving an average registration error of about 1 pixel. Our approach can serve as a fully automated substitute to the tedious and time-consuming manual 2D shape registration and analysis.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48823 USA; Siemens Corp Res, Imaging & Visualizat Dept, Princeton, NJ 08540 USA	Michigan State University; Siemens AG	Duta, N (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48823 USA.	dutanico@csc.msu.edu; jain@csc.msu.edu; jolly@scr.siemens.com	Rohlf, F J/A-8710-2008					BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bookstein F L, 1997, Med Image Anal, V1, P225; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; Brett AD, 1999, LECT NOTES COMPUT SC, V1613, P376; Chui H, 1999, LECT NOTES COMPUT SC, V1613, P168; COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4; COOTES TF, 1997, P BRIT MACH VIS C, P110; Davatzikos C, 1996, J COMPUT ASSIST TOMO, V20, P88, DOI 10.1097/00004728-199601000-00017; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Duta N, 1998, IEEE T MED IMAGING, V17, P1049, DOI 10.1109/42.746716; Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998; FIGUEIREDO M, 2000, IEEE T IMAGE PROCESS; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FISKER R, 2000, P COMP VIS PATT REC; Gold S, 1996, NEURAL COMPUT, V8, P787, DOI 10.1162/neco.1996.8.4.787; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x; GUEZIEC A, 1994, INT J COMPUT VISION, V12, P79, DOI 10.1007/BF01420985; Haralick R.M., 1992, COMPUTER ROBOT VISIO, V1; Hill A, 2000, IEEE T PATTERN ANAL, V22, P241, DOI 10.1109/34.841756; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; JAIN AK, 1999, P INT C IM PROC 99; Lundervold A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P231, DOI 10.1109/CVPR.1999.786944; Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8; Neumann A, 1998, COMPUT MED IMAG GRAP, V22, P133, DOI 10.1016/S0895-6111(98)00015-9; Rangarajan A, 1997, LECT NOTES COMPUT SC, V1230, P29; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; Small C.G., 1996, STAT THEORY SHAPE; TON JC, 1989, IEEE T GEOSCI REMOTE, V27, P642, DOI 10.1109/TGRS.1989.35948; ULLMAN S, 1989, COGNITION, V32, P193, DOI 10.1016/0010-0277(89)90036-X	32	55	63	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2001	23	5					433	446		10.1109/34.922703	http://dx.doi.org/10.1109/34.922703			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431QA					2022-12-18	WOS:000168641000001
J	Weiss, I; Ray, M				Weiss, I; Ray, M			Model-based recognition of 3D objects from single images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; invariance; model-based	INVARIANTS; MOTION; SHAPE; 3-D	In this work, we treat major problems of object recognition which have received relatively little attention lately. Among them are the loss of depth information in the projection from a 3D object to a single 2D image, and the complexity of finding feature correspondences between images. We use geometric invariants to reduce the complexity of these problems. There are no geometric invariants of a projection from 3D to 2D. However, given certain modeling assumptions about the 3D object, such invariants can be found. The modeling assumptions can be either a particular model or a generic assumption about a class of models. Here, we use such assumptions for single-view recognition. We find algebraic relations between the invariants of a 3D model and those of its 2D image under general projective projection. These relations can be described geometrically as invariant models in a 3D invariant space, illuminated by invariant "light rays, and projected onto an invariant version of the given image. We apply the method to real images.	Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA; Siemens Med Syst Inc, Nucl Med Grp, Hoffman Estates, IL 60195 USA	University System of Maryland; University of Maryland College Park; Siemens AG	Weiss, I (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.	weiss@cfar.umd.edu; manjit@cfar.umd.edu						BARRETT E, 1998, COMMUNICATION; Beardsley P., 1996, P EUR C COMP VIS, P683; BENARIE J, 1996, P INT C PATT REC, VA, P672; Binford TO, 1996, IMAGE UNDERSTANDING WORKSHOP, 1996 PROCEEDINGS, VOLS I AND II, P89; Bruckstein AM, 1997, IMAGE VISION COMPUT, V15, P335, DOI 10.1016/S0262-8856(96)01140-7; BURNS JB, 1990, P DARPA IMAGE UNDERS, P650; Carlsson S, 1998, INT J COMPUT VISION, V27, P227, DOI 10.1023/A:1007961913417; CARLSSON S, 1994, IMAGE VISION COMPUT, V12, P179, DOI 10.1016/0262-8856(94)90070-1; CURWEN RW, 1997, P DARPA IM UND WORKS, P595; DERICHE R, 1994, P EUR C COMP VIS, VA, P567; GUGGEHEIMER H, 1963, DIFFERENTIAL GEOMETR; Hjaltason GR, 1995, LECT NOTES COMPUT SC, V951, P83; HOPCROFT JP, 1992, GEOMETRIC INVARIANCE; Jacobs D. W., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P439, DOI 10.1109/CVPR.1992.223153; Jacobs DW, 1997, PROC CVPR IEEE, P547, DOI 10.1109/CVPR.1997.609379; KEREN D, 1997, CSTR3812 U MAR; Maybank SJ, 1998, IMAGE VISION COMPUT, V16, P13, DOI 10.1016/S0262-8856(97)00048-6; MEER P, 1992, P INT C PATT REC, VA, P399; Mohan R., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P264, DOI 10.1109/ICCV.1993.378208; MOHR R, 1995, INT J ROBOT RES, V14, P619, DOI 10.1177/027836499501400607; MOSES Y, 1988, INT J COMPUT VISION, V29, P233; PELEG S, 1997, P DARPA IM UND WORKS, P79; Rivlin E, 1997, COMPUT VIS IMAGE UND, V65, P95, DOI 10.1006/cviu.1996.0478; RIVLIN E, 1995, IEEE T PATTERN ANAL, V17, P226, DOI 10.1109/34.368188; Rothwell C.A., 1995, OBJECT RECOGNITION I; Samet H., 1990, DESIGN ANAL SPATIAL, V85; Sato J, 1997, IMAGE VISION COMPUT, V15, P627, DOI 10.1016/S0262-8856(97)00011-5; Shashua A, 1996, IEEE T PATTERN ANAL, V18, P873, DOI 10.1109/34.537342; Sparr G., 1991, P DARPA ESPRIT WORKS, P151; SPRINGER CE, 1994, GEOMETRY ANAL PROJEC; STRUMPEL B, 1993, ALGORITHMS INVARIANT; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; VANGOOL L, 1995, IMAGE VISION COMPUT, V13, P259, DOI 10.1016/0262-8856(95)99715-D; Vieville T, 1996, INT J COMPUT VISION, V17, P7, DOI 10.1007/BF00127817; Vijayakumar B, 1996, PROC CVPR IEEE, P327, DOI 10.1109/CVPR.1996.517093; WEINSHALL D, 1993, INT J COMPUT VISION, V10, P27, DOI 10.1007/BF01440845; Weiss I., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P291, DOI 10.1109/CVPR.1988.196251; Weiss I, 1999, J MATH IMAGING VIS, V10, P175, DOI 10.1023/A:1008383224450; WEISS I, 1993, IEEE T PATTERN ANAL, V15, P943, DOI 10.1109/34.232081; WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536; WEISS I, 1995, ANN MATH ARTIF INTEL, V13, P203, DOI 10.1007/BF01530828; WEISS I, 1996, CSTR3605 U MAR; ZERROUG M, 1994, LECT NOTES COMPUTER, V825; ZISSERMAN A, 1995, ARTIF INTELL, V78, P239, DOI 10.1016/0004-3702(95)00023-2; [No title captured]; [No title captured]	47	55	57	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2001	23	2					116	128		10.1109/34.908963	http://dx.doi.org/10.1109/34.908963			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	401NJ					2022-12-18	WOS:000166933500002
J	Oh, IS; Lee, JS; Suen, CY				Oh, IS; Lee, JS; Suen, CY			Analysis of class separation and combination of class-dependent features for handwriting recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwriting recognition; class separation; nonparametric method; class-dependent feature combination; modular neural network	CHARACTER-RECOGNITION	In this paper, we propose a new approach to combine multiple features in handwriting recognition based on two ideas: feature selection-based combination and class-dependent features. A nonparametric method is used for feature evaluation, and the first part of this paper is devoted to the evaluation of features in terms of their class separation and recognition capabilities. In the second part, multiple feature vectors are combined to produce a new feature vector. Based on the fact that a feature has different discriminating powers for different classes, a new scheme of selecting and combining class-dependent features is proposed. In this scheme, a class is considered to have its own optimal feature vector for discriminating itself from the other classes. Using an architecture of modular neural networks as the classifier, a series of experiments were conducted on unconstrained handwritten numerals. The results indicate that the selected features are effective in separating pattern classes and the new feature vector derived from a combination of two types of such features further improves the recognition rate.	Woosuk Univ, Dept Comp Engn, Wanju Kun 565701, Chonbuk, South Korea; Concordia Univ, Ctr Pattern Recognit & Machine Intelligence, Montreal, PQ H3G 1M8, Canada	Woosuk University; Concordia University - Canada	Oh, IS (corresponding author), Chonnam Natl Univ, Dept Comp Sci, Chonju 561756, Chonbuk, South Korea.							Chhabra A. K., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P397, DOI 10.1109/ICDAR.1993.395708; Duda R.O., 1973, J ROYAL STAT SOC SER; Favata J.T., 1994, P 4 INT WORKSH FRONT, P57; Gader PD, 1996, IEEE T PATTERN ANAL, V18, P1256, DOI 10.1109/34.546262; Heutte L., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P167, DOI 10.1109/ICDAR.1993.395757; Kittler J., 1986, HDB PATTERN RECOGNIT; Kittler Josef, 1996, P 5 INT WORKSH FRONT, P81; Lee SW, 1996, PATTERN RECOGN, V29, P1953, DOI 10.1016/S0031-3203(96)00053-2; OH IS, 1996, P 5 IWFHR, P35; OH IS, 1998, INT J DOC ANAL RECOG, V1, P73; Ripley BD., 1996; Schurmann J, 1996, PATTERN CLASSIFICATI; Srikantan G, 1996, PATTERN RECOGN, V29, P1147, DOI 10.1016/0031-3203(95)00146-8; Strathy N. W., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P74, DOI 10.1109/ICDAR.1995.598947; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2	16	55	59	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1999	21	10					1089	1094		10.1109/34.799913	http://dx.doi.org/10.1109/34.799913			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	248DB		Green Submitted			2022-12-18	WOS:000083259100010
J	Darrell, TJ; Essa, IA; Pentland, AP				Darrell, TJ; Essa, IA; Pentland, AP			Task-specific gesture analysis in real-time using interpolated views	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						gesture recognition; real-time image processing; expression analysis; view-based representation; spatio-temporal gestures	RECOGNITION; MODELS	Hand and face gestures are modeled using an appearance-based approach in which patterns are represented as a vector of similarity scores to a set of view models defined in space and time. These view models are learned from examples using unsupervised clustering techniques. A supervised learning paradigm is then used to interpolate view scores into a task-dependent coordinate system appropriate for recognition and control tasks. We apply this analysis to the problem of context-specific gesture interpolation and recognition, and demonstrate real-time systems which perform these tasks.	MIT,MEDIA LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)	Darrell, TJ (corresponding author), INTERVAL RES,1801 PAGE MILL RD,BLDG C,PALO ALTO,CA 94304, USA.							Bellman RE, 1957, DYNAMIC PROGRAMMING; BEYMER D, 1994, P IEEE C COMP VIS PA, P756; BREUEL T, 1992, IAPR WORKSH MACH VIS; CIPOLLA R, 1992, IAPR WORKSH MACH VIS; DARRELL T, 1993, P IEEE CVPR 93 NEW Y; DARRELL T, 1995, P INT WORKSH FAC GES; ESSA IA, 1994, P IEEE C COMP VIS PA; FUKUMOTO M, 1992, IAPR WORKSH MACH VIS; ISHIBUCHI K, 1992, IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION : PROCEEDINGS, P111, DOI 10.1109/ROMAN.1992.253924; MASE K, 1991, IEICE T E, V74; MOGHADDAM B, 1995, P INT C COMP VIS 199; Murase H., 1993, Proceedings of IEEE Workshop on Qualitative Vision (Cat. No.93TH0521-5), P39, DOI 10.1109/WQV.1993.262951; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; POGGIO T, 1989, TR1140 MIT AI LAB; SAKOE H, 1980, IEEE T ACOUSTICS SPE, V26, P623; TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Waters K., 1991, Journal of Visualization and Computer Animation, V2, P123, DOI 10.1002/vis.4340020405; Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906; YACOOB Y, 1994, P COMP VIS PATT REC, P70	21	55	58	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1996	18	12					1236	1242		10.1109/34.546259	http://dx.doi.org/10.1109/34.546259			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VZ150					2022-12-18	WOS:A1996VZ15000008
J	KANAI, J; RICE, SV; NARTKER, TA; NAGY, G				KANAI, J; RICE, SV; NARTKER, TA; NAGY, G			AUTOMATED EVALUATION OF OCR ZONING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DOCUMENT IMAGE UNDERSTANDING; PAGE SEGMENTATION; LAYOUT ANALYSIS; PERFORMANCE EVALUATION METRIC		Many current optical character recognition (OCR) systems attempt to decompose printed pages into a set of zones, each containing a single column of text, before converting the characters into coded form. We present a methodology for automatically assessing the accuracy of such decompositions, and demonstrate its use in evaluating six OCR systems.	RENSSELAER POLYTECH INST,DEPT ECSE,TROY,NY 12180	Rensselaer Polytechnic Institute	KANAI, J (corresponding author), UNIV NEVADA,INFORMAT SCI RES INST,LAS VEGAS,NV 89154, USA.			Nagy, George/0000-0002-0521-1443				KANAI J, 1993, ISRI TR9302 U NEV TE; LATIFI S, 1993, MAY P ICEE 93 TEHR; RANDRIAMASY S, 1994, SPIE P SERIES, V2181, P217; RICE SV, 1993, ISRI TR9301 U NEV TE; RICE SV, 1992, ADV STRUCTURAL SYNTH, P333; RICE SV, 1993, ISRI TR9304 U NEV TE; SRIHARI S, 1985, COMPUTER TEXT RECOGN	7	55	57	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1995	17	1					86	90		10.1109/34.368146	http://dx.doi.org/10.1109/34.368146			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QB394					2022-12-18	WOS:A1995QB39400012
J	GIGUS, Z; CANNY, J; SEIDEL, R				GIGUS, Z; CANNY, J; SEIDEL, R			EFFICIENTLY COMPUTING AND REPRESENTING ASPECT GRAPHS OF POLYHEDRAL OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ASPECT GRAPHS; LINE DRAWING INTERPRETATION; MODEL BASED VISION; OBJECT RECOGNITION; PERSISTENT DATA STRUCTURES; POLYHEDRAL OBJECTS	SINGULARITIES; RECOGNITION; VISION	We present an efficient algorithm and a new data structure for computing and representing the aspect graph of polyhedral objects under orthographic projection. The aspect graph is an approach to representing 3-D objects by a set of 2-D views, for the purpose of object recognition. In this approach, the viewpoint space is partitioned into regions such that in each region the qualitative structure of the line drawing does not change. The viewing data of an object is the partition of the viewpoint space together with a representative view in each region. The algorithm computes the viewing data for line drawings of polyhedral objects under orthographic projection. For an object of n vertices whose partition is of size m, the partition is constructed in O(n4 log n + m log m) time. After computing the partition, given a view of the object in one region, we use a novel data structure to construct the set of all views in O(C(T)) time and space, where C(T) is the sum of the number of changes between all pairs of neighboring views. A view of size s can be retrieved from this data structure in O(log C(T) + s) time.			GIGUS, Z (corresponding author), UNIV CALIF BERKELEY,DEPT ELECT ENGN & COMP SCI,DIV COMP SCI,BERKELEY,CA 94720, USA.							Arnold V.I., 1979, RUSS MATH SURV+, V34, P1; ARNOLD VI, 1983, RUSS MATH SURV+, V38, P87, DOI 10.1070/RM1983v038n02ABEH003471; Callahan J., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P240; CHAKRAVARTY I, 1982, P SOC PHOTO-OPT INST, V336, P37, DOI 10.1117/12.933609; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; EGGERT D, 1989, NOV P IEEE WORKSH IN, P102; Gigus Z., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P30, DOI 10.1109/CCV.1988.589969; GIGUS Z, 1990, IEEE T PATTERN ANAL, V12, P113, DOI 10.1109/34.44399; GIGUS Z, 1988, JUN P COMP VIS PATT, P654; HEBERT M, 1988, P IEEE COMP SOC C CO, P458; IKEUCHI K, 1987, FEB P DARPA IM UND W, P321; KERGOSIEN YL, 1981, CR ACAD SCI I-MATH, V292, P929; KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KRIEGMAN DJ, 1989, NOV P IEEE WORKSH IN, P116; KRIEGMAN DJ, 1990, 8TH P NAT C ART INT, P1074; Mehlhorn K., 1984, DATA STRUCTURES ALGO; PLANTINGA WH, 1990, INT J COMPUT VISION; PLANTINGA WH, 1987, 736 U WISC MAD TECH; PLANTINGA WH, 1986, 27TH P S F COMP SCI, P123; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; RIEGER JH, 1987, IMAGE VISION COMPUT, V5, P91, DOI 10.1016/0262-8856(87)90033-3; SARNAK N, 1986, COMMUN ACM, V29, P669, DOI 10.1145/6138.6151; SRIPRADISVARAKU.T, 1989, NOV P IEEE WORKSH IN, P109; Stewman J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P494, DOI 10.1109/CCV.1988.590029; STEWMAN J, 1987, DEC P IEE COMP SOC W, P123; [No title captured]; [No title captured]	28	55	60	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1991	13	6					542	551		10.1109/34.87341	http://dx.doi.org/10.1109/34.87341			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FU372					2022-12-18	WOS:A1991FU37200004
J	PRINCE, JL; WILLSKY, AS				PRINCE, JL; WILLSKY, AS			RECONSTRUCTING CONVEX-SETS FROM SUPPORT LINE MEASUREMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,DEPT ELECT ENGN & COMP SCI,INFORMAT & DECIS SYST LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)			Prince, Jerry L/A-3281-2010	Prince, Jerry L/0000-0002-6553-0876				Bellman R., 1970, INTRO MATRIX ANAL, V2nd; BRESLER Y, 1984, P IEEE COMP SOC INT; COLE R, 1987, J ALGORITHM, V8, P19, DOI 10.1016/0196-6774(87)90025-3; EDELSBRUNNER H, 1988, SIAM J COMPUT, V17, P820; GOLDFARB D, 1983, MATH PROGRAM, V27, P1, DOI 10.1007/BF02591962; GRESHAK J, 1985, THESIS MIT CAMBRIDGE; Herman G, 1980, IMAGE RECONSTRUCTION; Horn B., 1986, ROBOT VISION, P1; HUMEL JM, 1986, THESIS MIT CAMBRIDGE; KARL WC, 1989, THESIS MIT CAMBRIDGE; LAND AH, 1973, FORTRAN CODES MATH P; Luenberger D.G, 2016, LINEAR NONLINEAR PRO, DOI 10.1007/978-3-319-18842-3; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; PRINCE JL, 1986, THESIS MIT CAMBRIDGE; PRINCE JL, 1987, MIT LIDSP1638 LAB IN; RADEMACHER H, 1922, MATH Z; ROSSI DJ, 1984, IEEE T ACOUST SPEECH, V32, P886, DOI 10.1109/TASSP.1984.1164405; Santalo L. A., 1976, INTEGRAL GEOMETRY GE, V1; SCHNEITER JS, 1985, THESIS MIT CAMBRIDGE; SKIENA SS, 1988, THESIS U ILLINOIS UR; Spivak M., 1979, COMPREHENSIVE INTRO, VII; Van Trees H., 2013, DETECTION ESTIMATION; VANHOVE PL, 1986, THESIS MIT CAMBRIDGE; VANHOVE PL, 1985, MAR IEEE INT C AC SP, P933; Weiss ML., 1979, GEOMETRY CONVEXITY S	25	55	61	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1990	12	4					377	389		10.1109/34.50623	http://dx.doi.org/10.1109/34.50623			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CV929		Green Submitted			2022-12-18	WOS:A1990CV92900004
J	CHASSERY, JM; GARBAY, C				CHASSERY, JM; GARBAY, C			AN ITERATIVE SEGMENTATION METHOD BASED ON A CONTEXTUAL COLOR AND SHAPE CRITERION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											CHASSERY, JM (corresponding author), EMQC,TIM 3,CERMO,F-38402 ST MARTIN DHERES,FRANCE.							CHASSERY JM, 1983, COMPUT VISION GRAPH, V21, P326, DOI 10.1016/S0734-189X(83)80047-4; CHASSERY JM, 1984, 4EME C REC FORM INT, P51; GARBAY C, 1982, 1ST P IEEE INT S MED, P311; GARBAY C, 1981, ANAL QUANT CYTOL, V4, P272; KIM CE, 1981, IEEE T PATTERN ANAL, V3, P617, DOI 10.1109/TPAMI.1981.4767162; NORDIN B, 1982, 1ST P IEEE COMP SOC, P140; PAVLIDIS T, 1977, STRUCTURAL PATTERN R, P302; ROSENFELD A, 1979, P IEEE, V67, P764, DOI 10.1109/PROC.1979.11326; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1978, PATTERN RECOGN, V10, P181, DOI 10.1016/0031-3203(78)90026-2; SAKAUE K, 1982, 6TH P ICPR MUN, P192; SIGNOR G, 1981, 3EME ACT C REC FORM, P203; SKLANSKY J, 1978, IEEE T SYST MAN CYB, V8, P237, DOI 10.1109/TSMC.1978.4309944; WESKA JS, 1978, COMPUT GRAPHICS IMAG, V7, P259; ZUCKER S, 1977, DIGITAL IMAGE PROCES, P169	15	55	61	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					794	800		10.1109/TPAMI.1984.4767603	http://dx.doi.org/10.1109/TPAMI.1984.4767603			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499660				2022-12-18	WOS:A1984TX36100013
J	DVORNYCHENKO, VN				DVORNYCHENKO, VN			BOUNDS ON (DETERMINISTIC) CORRELATION-FUNCTIONS WITH APPLICATION TO REGISTRATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									FORD AEROSP & COMMUN CORP,NEWPORT BEACH,CA 92660									DUDA RO, 1973, PATTERN CLASSIFICATI, P305; GELB A, 1974, APPLIED OPTIMAL ESTI, P36; JAIN AK, 1975, IEEE T COMMUN, V23, P329; LATHI BP, 1965, SIGNALS SYSTEMS COMM, P515; ROSENFELD A, 1976, DIGITAL PICTURE PROC, P18	5	55	58	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					206	213		10.1109/TPAMI.1983.4767373	http://dx.doi.org/10.1109/TPAMI.1983.4767373			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974	21869102				2022-12-18	WOS:A1983QJ97400010
J	PELEG, S; ROSENFELD, A				PELEG, S; ROSENFELD, A			A MIN-MAX MEDIAL AXIS TRANSFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											PELEG, S (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VISION LAB,COLLEGE PK,MD 20742, USA.		Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				AHUJA N, 1978, IEEE T COMPUT, V27, P375, DOI 10.1109/TC.1978.1675110; Blum H., 1967, MODELS PERCEPTION SP, P363; LEVI G, 1970, INFORM CONTROL, V17, P62, DOI 10.1016/S0019-9958(70)80006-7; MOTTSMITH JC, 1970, PICTURE PROCESSING P, P267; NAKAGAWA Y, 1978, IEEE T SYST MAN CYB, V8, P632; ROSENFEL.A, 1966, J ACM, V13, P471; WANG S, 1979, TR843 U MAR COMP SCI	7	55	55	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					208	210		10.1109/TPAMI.1981.4767082	http://dx.doi.org/10.1109/TPAMI.1981.4767082			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN968	21868939				2022-12-18	WOS:A1981MN96800014
J	BENBASSAT, M; CARLSON, RW; PURI, VK; DAVENPORT, MD; SCHRIVER, JA; LATIF, M; SMITH, R; PORTIGAL, LD; LIPNICK, EH; WEIL, MH				BENBASSAT, M; CARLSON, RW; PURI, VK; DAVENPORT, MD; SCHRIVER, JA; LATIF, M; SMITH, R; PORTIGAL, LD; LIPNICK, EH; WEIL, MH			PATTERN-BASED INTERACTIVE DIAGNOSIS OF MULTIPLE DISORDERS - MEDAS SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF, SCH MED, INST CRIT CARE MED, LOS ANGELES, CA 90027 USA; TEL AVIV UNIV, FAC MANAGEMENT, TEL AVIV, ISRAEL	University of Southern California; Tel Aviv University	BENBASSAT, M (corresponding author), UNIV SO CALIF, SCH MED, DIV CRIT CARE MED, LOS ANGELES, CA 90027 USA.							BENBASSAT M, 1977, PATTERN RECOGN, V9, P99, DOI 10.1016/0031-3203(77)90021-8; BENBASSAT M, 1978, IEEE T COMPUT, V27, P170, DOI 10.1109/TC.1978.1675054; BENBASSAT M, 1978, IEEE T COMPUT, V27, P746, DOI 10.1109/TC.1978.1675182; BENBASSAT M, 1976, 3RD P INT JOINT C PA; BENBASSAT M, UNPUBLISHED; BENBASSAT M, 1978, IEEE COMPUT SOC WORK; FLEHINGER BJ, 1975, IBM J RES DEV, V19, P557, DOI 10.1147/rd.196.0557; GUSTAFSON DH, 1972, COMPUTER DIAGNOSIS D; JACQUEZ JA, 1972, COMPUTER DIAGNOSIS D; LEDLEY RS, 1959, SCIENCE, V130, P9, DOI 10.1126/science.130.3366.9; LEDLEY RS, 1972, COMPUTER DIAGNOSIS D, P152; LICHTENSTEIN A, 1972, ORGAN BEHAV HUM PREF, V8, P21; Lusted LB, 1968, INTRO MEDICAL DECISI; MOISEEVA NI, 1969, P IEEE, V57, P1919, DOI 10.1109/PROC.1969.7437; NORUSIS MJ, 1975, COMPUT BIOMED RES, V8, P173, DOI 10.1016/0010-4809(75)90037-3; NORUSIS MJ, 1975, COMPUT BIOMED RES, V8, P156, DOI 10.1016/0010-4809(75)90036-1; OVERALL JE, 1972, COMPUTER DIAGNOSIS D, P73; PATRICK EA, 1974, IEEE T SYST MAN CYB, VSMC4, P1, DOI 10.1109/TSMC.1974.5408512; POPLE HE, 1977, 5TH P INT JOINT C AR; PREWITT JMS, 1972, COMPUTER DIAGNOSIS D, P294; ROODY D, 1977, MEDICAL ABBREVIATION; Shortliffe E.H., 1976, COMPUTER BASED MEDIC; SHORTLIFFE EH, 1975, COMPUT BIOMED RES, V8, P303, DOI 10.1016/0010-4809(75)90009-9; STEEN E, 1971, DICTIONARY ABBREVIAT; WARNER HR, 1964, ANN NY ACAD SCI, V115, P558; 1974, CIRCULATION       S2, V4, P7	27	55	55	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	2					148	160		10.1109/TPAMI.1980.4766992	http://dx.doi.org/10.1109/TPAMI.1980.4766992			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JH803	21868885				2022-12-18	WOS:A1980JH80300006
J	GILBERT, AL; GILES, MK; FLACHS, GM; ROGERS, RB; U, YH				GILBERT, AL; GILES, MK; FLACHS, GM; ROGERS, RB; U, YH			REAL-TIME VIDEO TRACKING SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NEW MEXICO STATE UNIV,DEPT ELECT ENGN,LAS CRUCES,NM 88003	New Mexico State University	GILBERT, AL (corresponding author), USA,WHITE SANDS MISSILE RANGE,NM 88002, USA.							ANDREWS HL, 1972, INTRO MATH TECHNIQUE, P148; ANGEL ES, 1968, IEEE T MAN MACHI MAR, P15; BOOTH TL, 1968, SEQUENTIAL MACHINES; CHANG CB, 1975, 197559 LINC LAB TECH; CHANG SK, 1971, COMMUN ACM, V14; FLACHS GM, 1975, 1975 P NAT AER EL C; FLACHS GM, 1977, 1977 P NAT AER EL C; FLACHS GM, 1976, 1976 P IEEE NAT AER; GILBERT AL, 1978, JUN P ARM SCI C; Iverson K.E., 1962, PROGRAMMING LANGUAGE; JOHNSTON EG, 1970, PICTURE PROCESSING P; LATHI BP, 1968, RANDOM SIGNALS COMMU, P275; NILSSON NJ, 1965, LEARNING MACHINES F, pCH4; PAPOULIS A, 1965, PROBABILITY RANDOM V, P385; PEREZ PI, 1978, THESIS NEW MEXICO ST; ROGERS RB, 1977, 1ST P INT C MATH MOD; ROMOVIC R, 1966, IEEE T HUM FACTORS E, V7, P65; SELIN I, 1965, DETECTION THEORY, P11; THOMPSON WE, 1978, 1978 T NAT AER EL C; U YH, 1978, THESIS NEW MEXICO ST	20	55	63	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	1					47	56		10.1109/TPAMI.1980.4766969	http://dx.doi.org/10.1109/TPAMI.1980.4766969			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD568	22499622				2022-12-18	WOS:A1980JD56800006
J	KULIKOWSKI, CA				KULIKOWSKI, CA			ARTIFICIAL-INTELLIGENCE METHODS AND SYSTEMS FOR MEDICAL CONSULTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KULIKOWSKI, CA (corresponding author), RUTGERS STATE UNIV, DEPT COMP SCI, COMP SCI LAB, NEW BRUNSWICK, NJ 08903 USA.							[Anonymous], 1980, PRINCIPLES ARTIFICIA; ATKINS J, 1979, 6TH P INT JOINT C AR, P1; BIEMANN K, 1979, P IEEE, V67, P1287, DOI 10.1109/PROC.1979.11444; BLEICH HL, 1969, J CLIN INVEST, V48, P1689, DOI 10.1172/JCI106134; BLUM RL, 1979, 3RD P ANN S COMP APP, P303; BROOKS RE, 1979, 3RD P ANN S COMP APP, P56; CATANZARITE V, 1979, 3RD P S COMP APPL ME, P64; CHANDRASEKARAN B, 1979, 6TH P INT JOINT C AR, P134; CHILANSKY R, 1976, 3RD P ILL C MED INF; CIESIELSKI V, 1978, 4TH P ANN AIM WORKSH; CLANCEY WJ, 1979, INT J MAN MACH STUD, V11, P25, DOI 10.1016/S0020-7373(79)80004-8; CLANCEY WJ, 1979, 6TH P INT JOINT C AR, P155; DAVIS R, 1979, ARTIF INTELL, V12, P121, DOI 10.1016/0004-3702(79)90014-6; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDA RO, 1976, P NAT COMPUT C; ELSTEIN AS, 1976, SCIENCE, V194, P696, DOI 10.1126/science.982034; Elstein AS, 1978, MED PROBLEM SOLVING; FAGAN LM, 1979, 6TH P INT JOINT C AR, P260; FEIGENBAUM EA, 1978, P NAT COMPUT C, P221; FEINSTEIN AR, 1972, ANN INTERN MED, V76, P911, DOI 10.7326/0003-4819-76-6-911; Feinstein AR., 1967, CLIN JUDGMENT; FREIHERR G, 1979, NIH802071 DIV RES RE; FRIES JF, 1976, NEW ENGL J MED, V294, P1400, DOI 10.1056/NEJM197606172942512; FRIES JF, 1972, J AMER MED ASSOC, V222, P1536, DOI 10.1001/jama.222.12.1536; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GORRY GA, 1978, AM J MED, V64, P452, DOI 10.1016/0002-9343(78)90232-2; GORRY GA, 1973, METHOD INFORM MED, V12, P45; GREMY F, 1976, P IFIP WORKING C DEC, P32; HART PE, 1977, SRI155 TECH NOT; HENDRIX G, 1975, 4 P IJCAI, P115; KAK AC, 1979, P IEEE, V67, P1245, DOI 10.1109/PROC.1979.11440; KLEINMUNTZ B, 1968, BEHAV SCI, V13, P75, DOI 10.1002/bs.3830130112; KOMAROFF AL, 1974, NEW ENGL J MED, V290, P307, DOI 10.1056/NEJM197402072900605; KOMAROFF AL, 1979, P IEEE, V67, P1196, DOI 10.1109/PROC.1979.11435; KULIKOWSKI C, 1979, JAN AAAS ANN M; KULIKOWSKI C, ARTIFICIAL INTELLIGE; KULIKOWSKI C, 1972, TR5 RUTG U COMP BIOM; KULIKOWSKI CA, 1970, IEEE T SYST SCI CYB, V6, P83; LEDLEY RS, 1959, SCIENCE, V130, P9, DOI 10.1126/science.130.3366.9; LESSER VR, 1975, IEEE T ACOUST SPEECH, VAS23, P11, DOI 10.1109/TASSP.1975.1162648; LESSER VR, 1977, 5TH P INT JOINT C AR, P79; LICHTER P, 1977, DISCUSSIONS GLAUCOMA; LIPKIN M, 1958, JAMA-J AM MED ASSOC, V166, P113, DOI 10.1001/jama.1958.02990020001001; Lusted, 1968, INTRO MED DECISION M; MCNEIL BJ, 1975, NEW ENGL J MED, V293, P211, DOI 10.1056/NEJM197507312930501; MICHIE D, 1974, MACHINE INTELLIGENCE; MILLER P, 1975, MACTR153 MIT REP; Minsky M., 1968, SEMANTIC INFORM PROC; Minsky M., 2019, FRAMEWORK REPRESENTI; NASH FA, 1954, LANCET, V1, P874; Newell A, 1972, HUMAN PROBLEM SOLVIN; PATIL RS, 1979, MAY AIM WORKSH; PATRICK EA, 1977, IEEE T SYST MAN CYB, V6, P4; PAUKER S, 1978, 4TH P ILL C MED INF, P130; PAUKER SG, 1976, AM J MED, V60, P981, DOI 10.1016/0002-9343(76)90570-2; POPLE H, 1975, P IEEE INTERCON, V31; Pople H. E., 1975, 4TH P INT JOINT C AR, P848; QUILLIAN MR, 1968, SEMANTIC INFORMATION; REGGIA J, 1978, 2ND P ANN S COMP APP, P254; ROSATI RA, 1975, ARCH INTERN MED, V135, P1017, DOI 10.1001/archinte.135.8.1017; Sacerdoti E.D., 1977, STRUCTURE PLANS BEHA; SCHOOLMAN HM, 1978, SCIENCE, V200, P926, DOI 10.1126/science.347580; SCHULTZ JR, 1979, P IEEE, V67, P1237, DOI 10.1109/PROC.1979.11439; SCHWARTZ WB, 1970, NEW ENGL J MED, V283, P1257, DOI 10.1056/NEJM197012032832305; SCHWARTZ WB, 1973, AM J MED, V55, P459, DOI 10.1016/0002-9343(73)90203-9; Shortliffe E.H., 2012, COMPUTER BASED MED C; SHORTLIFFE EH, 1973, COMPUT BIOMED RES, V6, P544, DOI 10.1016/0010-4809(73)90029-3; SHORTLIFFE EH, 1979, P IEEE, V67, P1207, DOI 10.1109/PROC.1979.11436; Shortliffe EH., 1975, MATH BIOSCI, V23, P351, DOI [10.1016/0025-5564(75)90047-4, DOI 10.1016/0025-5564(75)90047-4]; SILVERMAN H, 1975, MACTR143 MIT REP; SPEICHER C, 1978, SURVEY INTERPRETIVE; SWARTOUT WR, 1979, 5TH AIM WORKSH; SZOLOVITS P, 1979, P IEEE, V67, P1224, DOI 10.1109/PROC.1979.11437; SZOLOVITS P, 1978, ARTIF INTELL, V11, P115, DOI 10.1016/0004-3702(78)90014-0; TRIGOBOFF M, 1977, 5TH P IJCAI, P274; VANMELLE W, 1979, 6TH P INT JOINT C AR, P923; VICKERY DM, 1978, TAKE CARE YOURSELF C; WAGNER G, 1978, METHOD INFORM MED, V17, P55, DOI 10.1055/s-0038-1636608; WALSER RL, 1976, 3RD P ILL C MED INF, P159; WARNER HR, 1978, 2ND P ANN S COMP APP, P401; WECHSLER H, 1976, INT J BIOMED COMPUT, V7, P191, DOI 10.1016/0020-7101(76)90026-X; WEISS S, 1978, COMPUT BIOL MED, V8, P25, DOI 10.1016/0010-4825(78)90011-2; WEISS SM, 1978, ARTIF INTELL, V11, P145, DOI 10.1016/0004-3702(78)90015-2; WEISS SM, 1979, 6TH P INT JOINT C AR, P942; Winston Patrick, 1972, MACHINE INTELLIGENCE; WOODBURY MA, 1980, 13TH P ANN HAW C SYS, P590; WORTMAN PM, 1972, COMPUT BIOMED RES, V5, P315, DOI 10.1016/0010-4809(72)90065-1; YERUSHALMY J, 1947, PUBLIC HEALTH REP, V62, P1432, DOI 10.2307/4586294; YOUNG DS, 1976, CLIN CHEM, V22, P1555; YU VL, 1979, COMPUT PROG BIOMED, V9, P95, DOI 10.1016/0010-468X(79)90022-9; [No title captured]; [No title captured]; [No title captured]	93	55	57	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	5					464	476		10.1109/TPAMI.1980.6592368	http://dx.doi.org/10.1109/TPAMI.1980.6592368			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KW185					2022-12-18	WOS:A1980KW18500010
J	Zhong, Z; Zheng, L; Luo, ZM; Li, SZ; Yang, Y				Zhong, Zhun; Zheng, Liang; Luo, Zhiming; Li, Shaozi; Yang, Yi			Learning to Adapt Invariance in Memory for Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Cameras; Adaptation models; Reliability; Australia; Memory modules; Task analysis; Person re-identification; domain adaptation; invariance learning; exemplar memory; graph-based positive prediction	NETWORKS	This work considers the problem of unsupervised domain adaptation in person re-identification (re-ID), which aims to transfer knowledge from the source domain to the target domain. Existing methods are primary to reduce the inter-domain shift between the domains, which however usually overlook the relations among target samples. This paper investigates into the intra-domain variations of the target domain and proposes a novel adaptation framework w.r.t three types of underlying invariance, i.e., Exemplar-Invariance, Camera-Invariance, and Neighborhood-Invariance. Specifically, an exemplar memory is introduced to store features of samples, which can effectively and efficiently enforce the invariance constraints over the global dataset. We further present the Graph-based Positive Prediction (GPP) method to explore reliable neighbors for the target domain, which is built upon the memory and is trained on the source samples. Experiments demonstrate that 1) the three invariance properties are complementary and indispensable for effective domain adaptation, 2) the memory plays a key role in implementing invariance learning and improves the performance with limited extra computation cost, 3) GPP can facilitate the invariance learning and thus significantly improves the results, and 4) our approach produces new state-of-the-art adaptation accuracy on three re-ID large-scale benchmarks.	[Zhong, Zhun; Li, Shaozi] Xiamen Univ, Dept Artificial Intelligence, Xiamen 361005, Fujian, Peoples R China; [Zhong, Zhun; Yang, Yi] Univ Technol Sydney, Ctr Artificial Intelligence, Ultimo, NSW 2007, Australia; [Zheng, Liang] Australian Natl Univ, Res Sch Comp Sci, Canberra, ACT 0200, Australia; [Luo, Zhiming] Xiamen Univ, Postdoctoral Mobile Stn Informat & Commun Engn, Xiamen 361005, Fujian, Peoples R China	Xiamen University; University of Technology Sydney; Australian National University; Xiamen University	Li, SZ (corresponding author), Xiamen Univ, Dept Artificial Intelligence, Xiamen 361005, Fujian, Peoples R China.	zhunzhong007@gmail.com; liangzheng06@gmail.com; zhiming.luo@xmu.edu.cn; szlig@xmu.edu.cn; yee.i.yang@gmail.com	yang, yang/GVT-5210-2022; Yang, Yi/B-9273-2017; yang, yang/GWB-9426-2022; yang, yang/HGT-7999-2022	Yang, Yi/0000-0002-0512-880X; 	National Nature Science Foundation of China [61876159, 61806172, 61572409, U1705286, 61571188]; National Key Research and Development Program of China [2018YFC0831402]; Australian Research Council Discovery Early Career Award - Australian Government [DE200101283]	National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China; Australian Research Council Discovery Early Career Award - Australian Government(Australian Research Council)	This work was supported by the National Nature Science Foundation of China (No. 61876159, 61806172, 61572409, U1705286 & 61571188), the National Key Research and Development Program of China (No. 2018YFC0831402). Dr. Liang Zheng is the recipient of an Australian Research Council Discovery Early Career Award (DE200101283) funded by the Australian Government. Zhun Zhong thanks Wenjing Li for encouragement.	[Anonymous], 2015, DEEP CONVOLUTIONAL N; Bai Y, 2014, PROC INT CONF RECON; Bak S, 2018, LECT NOTES COMPUT SC, V11217, P193, DOI 10.1007/978-3-030-01261-8_12; Bousmalis Konstantinos, 2016, ADV NEURAL INFORM PR, P343; Bruna J., 2014, ICLR, V21, P14; Busto PP, 2017, IEEE I CONF COMP VIS, P754, DOI 10.1109/ICCV.2017.88; Chen Y., 2018, P BRIT MACH VIS C; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Defferrard M., 2016, P ADV NEURAL INFORM, P3844; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110; Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Graves A., 2014, NEURAL TURING MACHIN; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; Hamilton WL, 2017, P 31 INT C NEUR INF, P1025; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hermans Alexander, 2017, ARXIV, P1; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; JasonWeston Sumit, 2015, P INT C LEARN REPR I; Kipf T. N., 2017, 5 INT C LEARN REPR; Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058; Li MX, 2018, LECT NOTES COMPUT SC, V11208, P772, DOI 10.1007/978-3-030-01225-0_45; Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Lin S., 2018, P BRIT MACH VIS C; Long M., 2015, P 32 INT C MACH LEAR, V1, P97; Luo YW, 2019, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2019.00261; Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576; Nair V., 2010, ICML, P807; Niepert M, 2016, PR MACH LEARN RES, V48; Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Saito K, 2018, LECT NOTES COMPUT SC, V11209, P156, DOI 10.1007/978-3-030-01228-1_10; Santoro A, 2016, PR MACH LEARN RES, V48; Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Sohn K., 2019, P INT C LEARN REPR; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sukhbaatar S., 2015, P 28 INT C NEURAL IN, V28, P2440; Sun XX, 2019, PROC CVPR IEEE, P608, DOI 10.1109/CVPR.2019.00070; Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Vinyals Oriol, 2016, ARXIV160604080, P3630; Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242; Wang ZD, 2019, PROC CVPR IEEE, P1117, DOI 10.1109/CVPR.2019.00121; Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016; Wu CY, 2019, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2019.00037; Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895; Wu ZR, 2018, LECT NOTES COMPUT SC, V11211, P712, DOI 10.1007/978-3-030-01234-2_42; Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393; Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107; Yang FX, 2020, IEEE T MULTIMEDIA, V22, P2444, DOI 10.1109/TMM.2019.2957928; Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225; Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878; Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113; Zheng L., 2016, PERSON RE IDENTIFICA; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI [10.1109/CVPR.2019.00224, 10.1109/CVPR.2019.01247]; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zhong Z, 2020, P AAAI C ART INT; Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11; Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389; Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069; Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541; Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	71	54	55	12	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2723	2738		10.1109/TPAMI.2020.2976933	http://dx.doi.org/10.1109/TPAMI.2020.2976933			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32142418	Green Submitted			2022-12-18	WOS:000670578800015
J	Zhuang, XH				Zhuang, Xiahai			Multivariate Mixture Model for Myocardial Segmentation Combining Multi-Source Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Myocardium; Image segmentation; Mixture models; Biomedical imaging; Pathology; Magnetic resonance; Multivariate image; multi-modality; segmentation; registration; medical image analysis; cardiac MRI	WHOLE HEART SEGMENTATION; MR-IMAGES; MAGNETIC-RESONANCE; REGISTRATION; TISSUE; QUANTIFICATION; CLASSIFICATION; PROPAGATION; FRAMEWORK; ATLAS	The author proposes a method for simultaneous registration and segmentation of multi-source images, using the multivariate mixture model (MvMM) and maximum of log-likelihood (LL) framework. Specifically, the method is applied to the problem of myocardial segmentation combining the complementary information from multi-sequence (MS) cardiac magnetic resonance (CMR) images. For the image misalignment and incongruent data, the MvMM is formulated with transformations and is further generalized for dealing with the hetero-coverage multi-modality images (HC-MMIs). The segmentation of MvMM is performed in a virtual common space, to which all the images and misaligned slices are simultaneously registered. Furthermore, this common space can be divided into a number of sub-regions, each of which contains congruent data, thus the HC-MMIs can be modeled using a set of conventional MvMMs. Results show that MvMM obtained significantly better performance compared to the conventional approaches and demonstrated good potential for scar quantification as well as myocardial segmentation. The generalized MvMM has also demonstrated better robustness in the incongruent data, where some images may not fully cover the region of interest, and the full coverage can only be reconstructed combining the images from multiple sources.	[Zhuang, Xiahai] Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China	Fudan University	Zhuang, XH (corresponding author), Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China.	zxh@fudan.edu.cn	Zhuang, Xiahai/AAH-6334-2019	Zhuang, Xiahai/0000-0003-4351-4979	National Natural Science Foundation of China [61971142]; Science and Technology Commission of Shanghai Municipality [17JC1401600]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science and Technology Commission of Shanghai Municipality(Science & Technology Commission of Shanghai Municipality (STCSM))	This work was supported by the National Natural Science Foundation of China (61971142), and the Science and Technology Commission of Shanghai Municipality (17JC1401600). The author would like to thank Chen Liu and Fuping Wu for their helps and discussions of the deep learning algorithms.	Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018; Balafar MA, 2014, ARTIF INTELL REV, V41, P429, DOI 10.1007/s10462-012-9317-3; Balafar MA, 2010, ARTIF INTELL REV, V33, P261, DOI 10.1007/s10462-010-9155-0; Bharati MH, 1998, IND ENG CHEM RES, V37, P4715, DOI 10.1021/ie980334l; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Ciofolo C, 2008, I S BIOMED IMAGING, P225, DOI 10.1109/ISBI.2008.4540973; Descombes X., 1995, P 9 SCAND C IM AN, p349C; Dikici E, 2004, LECT NOTES COMPUT SC, V3216, P250; El Berbari R, 2009, IEEE ENG MED BIO, P4403, DOI 10.1109/IEMBS.2009.5333691; Flett AS, 2011, JACC-CARDIOVASC IMAG, V4, P150, DOI 10.1016/j.jcmg.2010.11.015; Geladi P., 1996, ENCY ANAL CHEM; Hamilton B.A., 2014, DATA SCI BOWL CARDIA; Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883; Hoogendoorn C, 2013, IEEE T MED IMAGING, V32, P28, DOI 10.1109/TMI.2012.2230015; Kim HW, 2009, J AM COLL CARDIOL, V55, P1, DOI 10.1016/j.jacc.2009.06.059; Kolipaka A, 2005, INT J CARDIOVAS IMAG, V21, P303, DOI 10.1007/s10554-004-5806-z; Kwan RKS, 1999, IEEE T MED IMAGING, V18, P1085, DOI 10.1109/42.816072; Lee SJ, 2000, PROC SPIE, V4121, P170, DOI 10.1117/12.402437; Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368; Liang ZR, 2009, IEEE T MED IMAGING, V28, P297, DOI 10.1109/TMI.2008.2004670; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Lorenzo-Valdes M, 2004, MED IMAGE ANAL, V8, P255, DOI 10.1016/j.media.2004.06.005; Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Petitjean C., 2012, RV SEGMENTATION CHAL; Petitjean C., 2009, CARDIAC MR LEFT VENT; Petitjean C, 2011, MED IMAGE ANAL, V15, P169, DOI 10.1016/j.media.2010.12.004; Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315; Pop M., 2018, LNCS; Prats-Montalban JM, 2011, CHEMOMETR INTELL LAB, V107, P1, DOI 10.1016/j.chemolab.2011.03.002; Rajchl M, 2014, IEEE T MED IMAGING, V33, P159, DOI 10.1109/TMI.2013.2282932; Rohlfing T, 2007, IEEE T IMAGE PROCESS, V16, P153, DOI 10.1109/TIP.2006.884936; Ronneberger O., 2016, MICCAI, P234; Rueckert D, 2003, IEEE T MED IMAGING, V22, P1014, DOI 10.1109/TMI.2003.815865; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Shi WZ, 2011, LECT NOTES COMPUT SC, V6666, P163, DOI 10.1007/978-3-642-21028-0_21; Sudlow C., 2018, UK BIOBANK IMAGING S; Suinesiaputra A., 2011, LEFT VENTRICULAR SEG; Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270; Wei D, 2013, MED IMAGE ANAL, V17, P685, DOI 10.1016/j.media.2013.03.001; Xiahai Zhuang, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P581, DOI 10.1007/978-3-319-46723-8_67; Xu RS, 2013, I S BIOMED IMAGING, P856; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424; Zhuang XH, 2016, MED IMAGE ANAL, V31, P77, DOI 10.1016/j.media.2016.02.006; Zhuang XH, 2011, IEEE T MED IMAGING, V30, P1819, DOI 10.1109/TMI.2011.2150240; Zhuang XH, 2010, IEEE T MED IMAGING, V29, P1612, DOI 10.1109/TMI.2010.2047112	48	54	55	2	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2933	2946		10.1109/TPAMI.2018.2869576	http://dx.doi.org/10.1109/TPAMI.2018.2869576			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30207950	Green Submitted			2022-12-18	WOS:000498677600011
J	Liu, H; Lu, JW; Feng, JJ; Zhou, J				Liu, Hao; Lu, Jiwen; Feng, Jianjiang; Zhou, Jie			Two-Stream Transformer Networks for Video-Based Face Alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face alignment; convolutional neural networks; recurrent neural networks; face tracking; biometrics	REGRESSION	In this paper, we propose a two-stream transformer networks (TSTN) approach for video-based face alignment. Unlike conventional image-based face alignment approaches which cannot explicitly model the temporal dependency in videos and motivated by the fact that consistent movements of facial landmarks usually occur across consecutive frames, our TSTN aims to capture the complementary information of both the spatial appearance on still frames and the temporal consistency information across frames. To achieve this, we develop a two-stream architecture, which decomposes the video-based face alignment into spatial and temporal streams accordingly. Specifically, the spatial stream aims to transform the facial image to the landmark positions by preserving the holistic facial shape structure. Accordingly, the temporal stream encodes the video input as active appearance codes, where the temporal consistency information across frames is captured to help shape refinements. Experimental results on the benchmarking video-based face alignment datasets show very competitive performance of our method in comparisons to the state-of-the-arts.	[Liu, Hao; Lu, Jiwen; Feng, Jianjiang; Zhou, Jie] Tsinghua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Liu, Hao; Lu, Jiwen; Feng, Jianjiang; Zhou, Jie] Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China	Tsinghua University; Tsinghua University	Lu, JW (corresponding author), Tsinghua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.; Lu, JW (corresponding author), Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China.	h-liu14@mails.tsinghua.edu.cn; lujiwen@tsinghua.edu.cn; jfeng@tsinghua.edu.cn; jzhou@tsinghua.edu.cn	Liu, Hao/AAE-2455-2020; Lu, Jiwen/C-5291-2009	Liu, Hao/0000-0003-0954-5405; Lu, Jiwen/0000-0002-6121-5529	National Key Research and Development Program of China [2016YFB1001004]; National Natural Science Foundation of China [61672306, 61572271, 61527808, 61373074, 61373090]; National 1000 Young Talents Plan Program; National Basic Research Program of China [2014CB349304]; Shenzhen Fundamental Research Fund [JCYJ20170412170602564]; Ministry of Education of China [20120002110033]; Tsinghua University Initiative Scientific Research Program	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National 1000 Young Talents Plan Program; National Basic Research Program of China(National Basic Research Program of China); Shenzhen Fundamental Research Fund; Ministry of Education of China(Ministry of Education, China); Tsinghua University Initiative Scientific Research Program	This work was supported in part by the National Key Research and Development Program of China under Grant 2016YFB1001004, in part by the National Natural Science Foundation of China under Grant 61672306, Grant 61572271, Grant 61527808, Grant 61373074, and Grant 61373090, in part by the National 1000 Young Talents Plan Program, in part by the National Basic Research Program of China under Grant 2014CB349304, in part by the Shenzhen Fundamental Research Fund (Subject Arrangement) under Grant JCYJ20170412170602564, in part by the Ministry of Education of China under Grant 20120002110033, and in part by the Tsinghua University Initiative Scientific Research Program.	Abadi M, 2015, P 12 USENIX S OPERAT; Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240; Belagiannis V, 2015, IEEE I CONF COMP VIS, P2830, DOI 10.1109/ICCV.2015.324; BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; FGNET, 2014, TALK FAC VID; Gonzalez R.C., 2020, DIGITAL IMAGE PROCES; Gou C, 2016, LECT NOTES COMPUT SC, V9914, P604, DOI 10.1007/978-3-319-48881-3_42; Grewe CM, 2016, LECT NOTES COMPUT SC, V9914, P552, DOI 10.1007/978-3-319-48881-3_38; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Huang ZW, 2013, IEEE I CONF COMP VIS, P3296, DOI 10.1109/ICCV.2013.409; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Ma MH, 2016, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2016.209; McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3; Peng X, 2015, IEEE I CONF COMP VIS, P3880, DOI 10.1109/ICCV.2015.442; Perakis P, 2013, IEEE T PATTERN ANAL, V35, P1552, DOI 10.1109/TPAMI.2012.247; Pigou L., 2015, INT J COMPUT VISION, P1; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Sanchez-Lozano E, 2016, LECT NOTES COMPUT SC, V9912, P645, DOI 10.1007/978-3-319-46484-8_39; Santa Z, 2016, LECT NOTES COMPUT SC, V9914, P521, DOI 10.1007/978-3-319-48881-3_36; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Sun P., 2015, ARXIV150707508; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453; Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989; Wang XY, 2015, IEEE T PATTERN ANAL, V37, P2071, DOI 10.1109/TPAMI.2015.2389830; Wu Y, 2014, PROC CVPR IEEE, P1781, DOI 10.1109/CVPR.2014.230; Wu Y, 2015, INT J COMPUT VISION, V113, P37, DOI 10.1007/s11263-014-0775-8; Xiao ST, 2016, LECT NOTES COMPUT SC, V9905, P57, DOI 10.1007/978-3-319-46448-0_4; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yu X, 2016, IEEE T PATTERN ANAL, V38, P2212, DOI 10.1109/TPAMI.2015.2509999; Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1; Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134	50	54	55	3	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2546	2554		10.1109/TPAMI.2017.2734779	http://dx.doi.org/10.1109/TPAMI.2017.2734779			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	28783622				2022-12-18	WOS:000446683700002
J	Solera, F; Calderara, S; Cucchiara, R				Solera, Francesco; Calderara, Simone; Cucchiara, Rita			Socially Constrained Structural Learning for Groups Detection in Crowd	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Crowd analysis; group detection; Structural SVM; Correlation Clustering; Proxemic theory; Granger causality	TRACKING	Modern crowd theories agree that collective behavior is the result of the underlying interactions among small groups of individuals. In this work, we propose a novel algorithm for detecting social groups in crowds by means of a Correlation Clustering procedure on people trajectories. The affinity between crowd members is learned through an online formulation of the Structural SVM framework and a set of specifically designed features characterizing both their physical and social identity, inspired by Proxemic theory, Granger causality, DTW and Heat-maps. To adhere to sociological observations, we introduce a loss function (G-MITRE) able to deal with the complexity of evaluating group detection performances. We show our algorithm achieves state-of-the-art results when relying on both ground truth trajectories and tracklets previously extracted by available detector/tracker systems.	[Solera, Francesco; Calderara, Simone; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy	Universita di Modena e Reggio Emilia	Solera, F; Calderara, S; Cucchiara, R (corresponding author), Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.	francesco.solera@unimore.it; simone.calderara@unimore.it; rita.cucchiara@unimore.it	Calderara, Simone/M-6932-2015; Cucchiara, Rita/L-3006-2015	Calderara, Simone/0000-0001-9056-1538; Cucchiara, Rita/0000-0002-2239-283X				[Anonymous], [No title captured]; Bandini S., 2012, P MEAS BEH, P308; Bandini S, 2014, PATTERN RECOGN LETT, V44, P16, DOI 10.1016/j.patrec.2013.10.003; Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95; Bazzani L, 2012, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2012.6247888; Berndt D. J., 1994, P 3 INT C KNOWL DISC, P359; Calderara S., 2012, COMP VIS PATT REC WO, P20; Canetti Elias, 1984, CROWDS POWER; Chang MC, 2011, IEEE I CONF COMP VIS, P747, DOI 10.1109/ICCV.2011.6126312; Couzin ID, 2005, NATURE, V433, P513, DOI 10.1038/nature03236; Cristani M., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P290, DOI 10.1109/PASSAT/SocialCom.2011.32; Cristani M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.23; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Feldmann M, 2011, IEEE T SIGNAL PROCES, V59, P1409, DOI 10.1109/TSP.2010.2101064; Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176; GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791; Hall E. T, 1990, HIDDEN DIMENSION; Haslam S.A, 2004, PSYCHOL ORG; Hazewinkel Michiel, 1989, ENCY MATH, V4; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; INGHAM AG, 1974, J EXP SOC PSYCHOL, V10, P371, DOI 10.1016/0022-1031(74)90033-X; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Kendon A., 1990, CUP ARCH, V7; Kleinberg J, 2002, ADV NEUR IN, V14, P431; Lacoste-Julien S., 2013, P 30 INT C MACH LEAR, P53; Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x; Lin WY, 2013, IEEE T CIRC SYST VID, V23, P1980, DOI 10.1109/TCSVT.2013.2269780; Luber M, 2010, IEEE INT CONF ROBOT, P464, DOI 10.1109/ROBOT.2010.5509779; Manenti Lorenza, 2012, Multi-Agent-Based Simulation XII,International Workshop, MABS 2011. Revised Selected Papers, P74, DOI 10.1007/978-3-642-28400-7_6; MCPHAIL C, 1982, SOCIOL METHOD RES, V10, P347, DOI 10.1177/0049124182010003007; Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Moore BE, 2011, COMMUN ACM, V54, P64, DOI 10.1145/2043174.2043192; Moussaid M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047; Oldmeadow J, 2005, CURR RES SOC PSYCHOL, V10, P268; Pang SK, 2011, IEEE T AERO ELEC SYS, V47, P472, DOI 10.1109/TAES.2011.5705687; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Pellegrini S, 2010, LECT NOTES COMPUT SC, V6311, P452, DOI 10.1007/978-3-642-15549-9_33; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Reicher S. D., 1995, EUROPEAN REV SOCIAL, V6, P161, DOI [DOI 10.1080/14792779443000049, 10.1080/14792779443000049]; ROTA GC, 1964, AM MATH MON, V71, P498, DOI 10.2307/2312585; Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285; Solera F, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P7, DOI 10.1109/AVSS.2013.6636608; Spielman D, 2012, CH CRC COMP SCI SER, P495; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Turner JC, 1981, CAHIERS PSYCHOL COGN, V1, P93; Vilain Marc, 1995, P MESS UND C, V6, P45, DOI [DOI 10.3115/1072399.1072405, 10.3115/1072399.1072405]; Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468; Zanotto M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.111	50	54	58	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					995	1008		10.1109/TPAMI.2015.2470658	http://dx.doi.org/10.1109/TPAMI.2015.2470658			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	27046841	Green Submitted			2022-12-18	WOS:000374164700012
J	Schmidt, U; Jancsary, J; Nowozin, S; Roth, S; Rother, C				Schmidt, Uwe; Jancsary, Jeremy; Nowozin, Sebastian; Roth, Stefan; Rother, Carsten			Cascades of Regression Tree Fields for Image Restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Conditional random fields; prediction cascade; loss-based training; image deblurring; image restoration	SCALE MIXTURES; STATISTICS; GAUSSIANS; RECOVERY	Conditional random fields (CRFs) are popular discriminative models for computer vision and have been successfully applied in the domain of image restoration, especially to image denoising. For image deblurring, however, discriminative approaches have been mostly lacking. We posit two reasons for this: First, the blur kernel is often only known at test time, requiring any discriminative approach to cope with considerable variability. Second, given this variability it is quite difficult to construct suitable features for discriminative prediction. To address these challenges we first show a connection between common half-quadratic inference for generative image priors and Gaussian CRFs. Based on this analysis, we then propose a cascade model for image restoration that consists of a Gaussian CRF at each stage. Each stage of our cascade is semi-parametric, i.e., it depends on the instance-specific parameters of the restoration problem, such as the blur kernel. We train our model by loss minimization with synthetically generated training data. Our experiments show that when applied to non-blind image deblurring, the proposed approach is efficient and yields state-of-the-art restoration quality on images corrupted with synthetic and real blur. Moreover, we demonstrate its suitability for image denoising, where we achieve competitive results for grayscale and color images.	[Schmidt, Uwe; Roth, Stefan; Rother, Carsten] Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany; [Nowozin, Sebastian] Microsoft Res Ltd, Cambridge, England; [Jancsary, Jeremy] Nuance Commun, Vienna, Austria	Technical University of Darmstadt; Microsoft	Schmidt, U (corresponding author), Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany.				Microsoft Research; European Research Council under the European Union [307942]	Microsoft Research(Microsoft); European Research Council under the European Union(European Research Council (ERC))	The authors thank Pushmeet Kohli for suggesting the topic of discriminative deblurring using a non-parametric model like the RTF; we also thank Stephan Richter for help in preparation of Fig. 2. Parts of this work have been done when Uwe Schmidt interned at Microsoft Research Cambridge, UK. Funding is partly provided by Microsoft Research through its PhD Scholarship Programme, as well as from the European Research Council under the European Union's Seventh Framework Programme (FP/2007-2013)/ERC Grant Agreement no. 307942. This work was done while C. Rother and J. Jancsary were at Microsoft Research Ltd, Cambridge, United Kingdom.	Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Babacan SD, 2012, LECT NOTES COMPUT SC, V7577, P341, DOI 10.1007/978-3-642-33783-3_25; Barbu A, 2009, PROC CVPR IEEE, P1574, DOI 10.1109/CVPRW.2009.5206811; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952; Champagnat F, 2004, IEEE SIGNAL PROC LET, V11, P709, DOI 10.1109/LSP.2004.833511; CHARBONNIER P, 1994, IEEE IMAGE PROC, P168; Chen YC, 2013, LECT NOTES COMPUT SC, V8142, P271, DOI 10.1007/978-3-642-40602-7_30; Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Cho TS, 2010, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2010.5540214; Dabov K, 2007, IEEE IMAGE PROC, P313, DOI 10.1109/icip.2007.4378954; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Elad M., 2006, P IEEE COMP SOC C CO, V2, P1924; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Frohlich Bjorn, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P1, DOI 10.1007/978-3-642-32717-9_1; GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; Jancsary J, 2012, LECT NOTES COMPUT SC, V7578, P112, DOI 10.1007/978-3-642-33786-4_9; Jancsary J, 2012, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2012.6247950; Kohler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3; Krishnan D., 2009, ADV NEURAL INFORM PR, V22, P1033; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Palmer Jason, 2006, ADV NEURAL INFORM PR, P1059; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Qi Gao, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P62, DOI 10.1007/978-3-642-32717-9_7; RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Schmidt U., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2625, DOI 10.1109/CVPR.2011.5995653; Schmidt U, 2013, PROC CVPR IEEE, P604, DOI 10.1109/CVPR.2013.84; Schmidt U, 2010, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2010.5539844; Schuler CJ, 2013, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2013.142; Tai YW, 2012, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2012.6247653; Tappen M. F., 2007, P IEEE C COMP VIS PA, P1; Tu Z., 2008, IEEE C COMP VIS PATT, P1; Vapnik V., 1974, THEORY PATTERN RECOG; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Wainwright MJ, 2000, ADV NEUR IN, V12, P855; Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	46	54	59	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					677	689		10.1109/TPAMI.2015.2441053	http://dx.doi.org/10.1109/TPAMI.2015.2441053			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26959673	Green Submitted			2022-12-18	WOS:000372549700006
J	Yang, QX; Tang, JH; Ahuja, N				Yang, Qingxiong; Tang, Jinhui; Ahuja, Narendra			Efficient and Robust Specular Highlight Removal	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Specular reflection separation; highlight; bilateral filter	SEPARATING REFLECTION COMPONENTS; COLOR; DIFFUSE; CHROMATICITY	A robust and effective specular highlight removal method is proposed in this paper. It is based on a key observation-the maximum fraction of the diffuse colour component in diffuse local patches in colour images changes smoothly. The specular pixels can thus be treated as noise in this case. This property allows the specular highlights to be removed in an image denoising fashion: an edge-preserving low-pass filter (e.g., the bilateral filter) can be used to smooth the maximum fraction of the colour components of the original image to remove the noise contributed by the specular pixels. Recent developments in fast bilateral filtering techniques enable the proposed method to run over 200 x faster than state-of-the-art techniques on a standard CPU and differentiates it from previous work.	[Yang, Qingxiong] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; [Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China; [Ahuja, Narendra] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL USA	City University of Hong Kong; Nanjing University of Science & Technology; University of Illinois System; University of Illinois Urbana-Champaign	Yang, QX (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	qiyang@cityu.edu.hk; jinhuitang@njust.edu.cn; n-ahuja@illinois.edu	Yang, Qingxiong/K-1729-2015	Yang, Qingxiong/0000-0002-4378-2335; Tang, Jinhui/0000-0001-9008-222X	HP Labs; Research Grants Council of the Hong Kong Special Administrative Region, China [CityU 21201914]	HP Labs; Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council)	This work was supported by a grant from HP Labs and a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. CityU 21201914).	Bajcsy R, 1996, INT J COMPUT VISION, V17, P241, DOI 10.1007/BF00128233; Blake A., 1985, IJCAI, P973; Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574; Fleming RW, 2004, J VISION, V4, P798, DOI 10.1167/4.9.10; Kim H, 2013, PROC CVPR IEEE, P1460, DOI 10.1109/CVPR.2013.192; KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279; LEE SW, 1992, IMAGE VISION COMPUT, V10, P643, DOI 10.1016/0262-8856(92)90009-R; Lin S, 2002, LECT NOTES COMPUT SC, V2352, P210; Lin S, 2001, PROC CVPR IEEE, P341; Mallick SP, 2006, LECT NOTES COMPUT SC, V3951, P550; Mallick SP, 2005, PROC CVPR IEEE, P619; Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113; Paris S., 2009, BILATERAL FILTERING; Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963; Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8; Park J. S., 1990, P 10 INT C PATT REC, VI, P331; Porikli F, 2008, PROC CVPR IEEE, P3895; SATO Y, 1994, J OPT SOC AM A, V11, P2990, DOI 10.1364/JOSAA.11.002990; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Tan P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P164, DOI 10.1109/ICCV.2003.1238333; Tan P., 2006, P IEEE COMP SOC C CO, P1855; Tan R., 2005, HIGHLIGHTREMOVAL SIN; Tan RT, 2005, PROC CVPR IEEE, P125; Tan RT, 2005, IEEE T PATTERN ANAL, V27, P178, DOI 10.1109/TPAMI.2005.36; Tan RT, 2004, IEEE T PATTERN ANAL, V26, P1373, DOI 10.1109/TPAMI.2004.90; Tan RT, 2003, PROC CVPR IEEE, P673; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Yang QX, 2010, LECT NOTES COMPUT SC, V6314, P87, DOI 10.1007/978-3-642-15561-1_7; Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542	29	54	60	8	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1304	1311		10.1109/TPAMI.2014.2360402	http://dx.doi.org/10.1109/TPAMI.2014.2360402			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357351				2022-12-18	WOS:000354377100015
J	Chi, YJ; Porikli, F				Chi, Yuejie; Porikli, Fatih			Classification and Boosting with Multiple Collaborative Representations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-class classification; sparsity; compressive sensing; collaborative representation; boosting	FACE RECOGNITION; SIGNAL RECOVERY; EIGENFACES	Recent advances have shown a great potential to explore collaborative representations of test samples in a dictionary composed of training samples from all classes in multi-class recognition including sparse representations. In this paper, we present two multi-class classification algorithms that make use of multiple collaborative representations in their formulations, and demonstrate performance gain of exploring this extra degree of freedom. We first present the Collaborative Representation Optimized Classifier (CROC), which strikes a balance between the nearest-subspace classifier, which assigns a test sample to the class that minimizes the distance between the sample and its principal projection in the selected class, and a Collaborative Representation based Classifier (CRC), which assigns a test sample to the class that minimizes the distance between the sample and its collaborative components. Several well-known classifiers become special cases of CROC under different regularization parameters. We show classification performance can be improved by optimally tuning the regularization parameter through cross validation. We then propose the Collaborative Representation based Boosting (CRBoosting) algorithm, which generalizes the CROC to incorporate multiple collaborative representations. Extensive numerical examples are provided with performance comparisons of different choices of collaborative representations, in particular when the test sample is available via compressive measurements.	[Chi, Yuejie] Ohio State Univ, Dept Elect & Comp Engn & Biomed Informat, Columbus, OH 43210 USA; [Porikli, Fatih] Australian Natl Univ, Res Sch Engn, NICTA, Canberra, ACT 2601, Australia	University System of Ohio; Ohio State University; Australian National University	Chi, YJ (corresponding author), Ohio State Univ, Dept Elect & Comp Engn & Biomed Informat, Columbus, OH 43210 USA.	chi@ece.osu.edu; fatih.porikli@anu.edu.au	Chi, Yuejie/G-6033-2012; Chi, Yuejie/AAG-5084-2019	Chi, Yuejie/0000-0002-6766-5459; 				Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bi J., 2011, P IEEE CVPR; Calderbank R, 2009, COMPRESSED LEARNING; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S1064827596304010; Chi Y., 2012, P IEEE CVPR; Chi Y., 2013, IEEE T INF THEORY; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Grant M, 2005, CVX MATLAB SOFTWARE; Johnson W.B., 1984, CONTEMP MATH, V26, P1, DOI [10.1090/conm/026/737400, DOI 10.1090/CONM/026/737400]; Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Martinez A., 1998, 24 CVC, P24; Meier L, 2008, J R STAT SOC B, V70, P53, DOI 10.1111/j.1467-9868.2007.00627.x; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Schapire R. E., 1995, COMPUTATIONAL LEARNI, P23, DOI DOI 10.1007/3-540-59119-2_166; Shi Q., 2010, P IEEE CVPR; Shi Q., 2010, P CVPR, P2; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Verdu S., 1998, MULTIUSER DETECTION; Wright J., ARXIV11111014; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang M., 2010, P ECCV; Zhang L., 2011, P IEEE ICCV BARC SPA; Zhang Q., 2010, P IEEE CVPR	32	54	62	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1519	1531		10.1109/TPAMI.2013.236	http://dx.doi.org/10.1109/TPAMI.2013.236			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN	26353335				2022-12-18	WOS:000340191900003
J	Mishra, AK; Aloimonos, Y; Cheong, LF; Kassim, AA				Mishra, Ajay K.; Aloimonos, Yiannis; Cheong, Loong-Fah; Kassim, Ashraf A.			Active Visual Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fixation-based segmentation; object segmentation; polar space; cue integration; scale invariance; visual attention	EYE-MOVEMENTS; ATTENTION; FEATURES; SALIENCY; MODEL	Attention is an integral part of the human visual system and has been widely studied in the visual attention literature. The human eyes fixate at important locations in the scene, and every fixation point lies inside a particular region of arbitrary shape and size, which can either be an entire object or a part of it. Using that fixation point as an identification marker on the object, we propose a method to segment the object of interest by finding the "optimal" closed contour around the fixation point in the polar space, avoiding the perennial problem of scale in the Cartesian space. The proposed segmentation process is carried out in two separate steps: First, all visual cues are combined to generate the probabilistic boundary edge map of the scene; second, in this edge map, the "optimal" closed contour around a given fixation point is found. Having two separate steps also makes it possible to establish a simple feedback between the mid-level cue (regions) and the low-level visual cues (edges). In fact, we propose a segmentation refinement process based on such a feedback process. Finally, our experiments show the promise of the proposed method as an automatic segmentation framework for a general purpose visual system.	[Mishra, Ajay K.; Aloimonos, Yiannis] Univ Maryland, Dept Comp Sci, Comp Vis Lab, College Pk, MD 20742 USA; [Cheong, Loong-Fah; Kassim, Ashraf A.] Natl Univ Singapore, Singapore 117576, Singapore	University System of Maryland; University of Maryland College Park; National University of Singapore	Mishra, AK (corresponding author), Univ Maryland, Dept Comp Sci, Comp Vis Lab, AV Williams Bldg, College Pk, MD 20742 USA.	mishraka@umiacs.umd.edu; yiannis@cs.umd.edu; eleclf@nus.edu.sg; ashraf@nus.edu.sg	Aloimonos, Yiannis/AAI-2969-2020	Aloimonos, Yiannis/0000-0002-8152-4281; Kassim, Ashraf/0000-0001-7435-8564				Achanta R., 2009, P IEEE C COMP VIS PA; Alpert S, 2007, P IEEE C COMP VIS PA; Arbelaez P., 2008, P IEEE C COMP VIS PA, P454; Bagon S, 2008, LECT NOTES COMPUT SC, V5305, P30, DOI 10.1007/978-3-540-88693-8_3; Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5; Cerf M., 2008, P NEUR INF PROC SYST; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Craft E, 2007, J NEUROPHYSIOL, V97, P4310, DOI 10.1152/jn.00203.2007; Dimitrov P, 2000, PROC CVPR IEEE, P417, DOI 10.1109/CVPR.2000.855849; Ding LY, 2010, IEEE T PATTERN ANAL, V32, P2022, DOI 10.1109/TPAMI.2010.28; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2; Gur M, 1997, J NEUROSCI, V17, P2914; Henderson J.M., 1998, EYE MOVEMENTS SCENE; Henderson JM, 2003, PERCEPT PSYCHOPHYS, V65, P725, DOI 10.3758/BF03194809; Hollingworth A, 2001, MEM COGNITION, V29, P296, DOI 10.3758/BF03194923; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Kolmogorov V, 2005, PROC CVPR IEEE, P407; KOWLER E, 1980, VISION RES, V20, P273, DOI 10.1016/0042-6989(80)90113-3; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Martinez AM, 2004, COMPUT VIS IMAGE UND, V95, P72, DOI 10.1016/j.cviu.2004.01.003; Martinez-Conde S, 2004, NAT REV NEUROSCI, V5, P229, DOI 10.1038/nrn1348; Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9; Ogale AS, 2007, INT J COMPUT VISION, V72, P9, DOI 10.1007/s11263-006-8890-9; Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4; Rajashekar U, 2008, IEEE T IMAGE PROCESS, V17, P564, DOI 10.1109/TIP.2008.917218; Rothenstein AL, 2008, IMAGE VISION COMPUT, V26, P114, DOI 10.1016/j.imavis.2005.08.011; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Serences JT, 2006, TRENDS COGN SCI, V10, P38, DOI 10.1016/j.tics.2005.11.008; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; Sinop AK, 2007, IEEE I CONF COMP VIS, P1016, DOI 10.1109/iccv.2007.4408927; STEINBERG RH, 1973, J COMP NEUROL, V148, P229, DOI 10.1002/cne.901480209; Stella X.Y., 2001, P NEUR INF PROC SYST; Thomas OM, 2002, NAT NEUROSCI, V5, P472, DOI 10.1038/nn837; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; Toshev A., 2009, P IEEE C COMP VIS PA; Veksler O, 2008, LECT NOTES COMPUT SC, V5304, P454, DOI 10.1007/978-3-540-88690-7_34; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; WIKLER KC, 1990, J COMP NEUROL, V297, P499, DOI 10.1002/cne.902970404	46	54	62	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2012	34	4					639	653		10.1109/TPAMI.2011.171	http://dx.doi.org/10.1109/TPAMI.2011.171			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	896PO	22383341				2022-12-18	WOS:000300581700002
J	Wang, FY; Chi, CY; Chan, TH; Wang, Y				Wang, Fa-Yu; Chi, Chong-Yung; Chan, Tsung-Han; Wang, Yue			Nonnegative Least-Correlated Component Analysis for Separation of Dependent Sources by Volume Maximization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonnegative blind source separation; nonnegative least-correlated component analysis; dependent sources; joint correlation function of multiple signals; iterative volume maximization	BLIND SEPARATION; MATRIX FACTORIZATION; ALGORITHM	Although significant efforts have been made in developing nonnegative blind source separation techniques, accurate separation of positive yet dependent sources remains a challenging task. In this paper, a joint correlation function of multiple signals is proposed to reveal and confirm that the observations after nonnegative mixing would have higher joint correlation than the original unknown sources. Accordingly, a new nonnegative least-correlated component analysis (nLCA) method is proposed to design the unmixing matrix by minimizing the joint correlation function among the estimated nonnegative sources. In addition to a closed-form solution for unmixing two mixtures of two sources, the general algorithm of nLCA for the multisource case is developed based on an iterative volume maximization (IVM) principle and linear programming. The source identifiability and required conditions are discussed and proven. The proposed nLCA algorithm, denoted by nLCA-IVM, is evaluated with both simulation data and real biomedical data to demonstrate its superior performance over several existing benchmark methods.	[Wang, Fa-Yu; Chi, Chong-Yung; Chan, Tsung-Han] Natl Tsing Hua Univ, Inst Commun Engn, Hsinchu 30013, Taiwan; [Chi, Chong-Yung] Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu 30013, Taiwan; [Wang, Yue] Virginia Polytech Inst & State Univ, Dept Elect & Comp Engn, Arlington, VA 22203 USA; [Wang, Yue] Catholic Univ Amer, Washington, DC 20064 USA	National Tsing Hua University; National Tsing Hua University; Virginia Polytechnic Institute & State University; Catholic University of America	Wang, FY (corresponding author), Natl Tsing Hua Univ, Inst Commun Engn, 101 Sect 2,Kuang Fu Rd, Hsinchu 30013, Taiwan.	wangfaa@ms16.hinet.net; cychi@ee.nthu.edu.tw; tsunghan@mx.nthu.edu.tw; yuewang@vt.edu			National Science Council of the Republic of China (R.O.C.), Taiwan, R.O.C. [NSC 96-2628-E007-003-MY3]; US National Institutes of Health [EB000830, CA109872]; NATIONAL CANCER INSTITUTE [R21CA109872, R33CA109872] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R21EB000830, R33EB000830] Funding Source: NIH RePORTER	National Science Council of the Republic of China (R.O.C.), Taiwan, R.O.C.(Ministry of Science and Technology, Taiwan); US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL CANCER INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	The authors would like to sincerely thank Dr. Wing-Kin Ma and Mr. A. ArulMurugan for their valuable advice, suggestions, and discussions during the preparation of the manuscript. This work was supported partly by the National Science Council of the Republic of China (R.O.C.) under Grant NSC 96-2628-E007-003-MY3, Taiwan, R.O.C., and partly by the US National Institutes of Health under Grants EB000830 and CA109872.	Astakhov SA, 2006, ANAL CHEM, V78, P1620, DOI 10.1021/ac051707c; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Bazaraa MS., 2013, NONLINEAR PROGRAMMIN; Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006; Chan TH, 2008, IEEE T SIGNAL PROCES, V56, P5120, DOI 10.1109/TSP.2008.928937; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P2804, DOI 10.1109/TGRS.2006.881803; Chi C.-Y., 2006, BLIND EQUALIZATION S; Cichocki A., 2012, ADAPTIVE BLIND SIGNA, DOI DOI 10.1002/0470845899; Coleman TF, 1996, SIAM J OPTIMIZ, V6, P1040, DOI 10.1137/S1052623494240456; Dickinson ME, 2001, BIOTECHNIQUES, V31, P1272, DOI 10.2144/01316bt01; Fa Yu Wang, 2006, Proceedings of the 2006 IEEE Signal Processing Society Workshop, P73; FRIEDBERG SH, 1997, LINEAR ALGEBRA; Hastie T, 2009, ELEMENTS STAT LEARNI; Haykin S, 2005, NEURAL NETWORKS COMP; Herschman HR, 2003, SCIENCE, V302, P605, DOI 10.1126/science.1090585; Horn R. A., 1986, MATRIX ANAL; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727; Lang S., 1983, UNDERGRADUATE ANAL; Laurberg Hans, 2008, Computational Intelligence & Neuroscience, DOI 10.1155/2008/764206; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee JS, 2002, IEEE NUCL SCI CONF R, P2027, DOI 10.1109/NSSMIC.2001.1009222; Liu WX, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P293; Lustig I. J., 1994, ORSA Journal on Computing, V6, P1, DOI 10.1287/ijoc.6.1.1; Mansfield JR, 2005, J BIOMED OPT, V10, DOI 10.1117/1.2032458; McDonald DM, 2003, NAT MED, V9, P713, DOI 10.1038/nm0603-713; Mjolsness E, 2001, SCIENCE, V293, P2051, DOI 10.1126/science.293.5537.2051; Nascimento JMP, 2005, IEEE T GEOSCI REMOTE, V43, P898, DOI 10.1109/TGRS.2005.844293; Nuzillard D, 2000, ASTRON ASTROPHYS SUP, V147, P129, DOI 10.1051/aas:2000292; Oja E, 2004, NEURAL COMPUT, V16, P1811, DOI 10.1162/0899766041336413; Padhani AR, 2001, CLIN RADIOL, V56, P607, DOI 10.1053/crad.2001.0762; Prieto A, 1998, SIGNAL PROCESS, V64, P315, DOI 10.1016/S0165-1684(97)00198-9; RABINOVICH A, IEEE T MED IN PRESS; SANTAGO P, 1995, IEEE T IMAGE PROCESS, V4, P1531, DOI 10.1109/83.469934; Stein DWJ, 2002, IEEE SIGNAL PROC MAG, V19, P58, DOI 10.1109/79.974730; SUHLING K, 2005, CELL IMAGING METHODS; SUZUKI K, 2006, RADIOLOGY, V238; Tichavsky P, 2004, IEEE SIGNAL PROC LET, V11, P119, DOI 10.1109/LSP.2003.821658; Wang Y., 2006, IEDM, P1, DOI [DOI 10.1109/ICR.2006.343515, 10.1109/IEDM.2006.346898, DOI 10.1109/IEDM.2006.346898]; Winter ME, 1999, P SOC PHOTO-OPT INS, V3753, P266, DOI 10.1117/12.366289; Zdunek R, 2007, SIGNAL PROCESS, V87, P1904, DOI 10.1016/j.sigpro.2007.01.024	42	54	56	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					875	888		10.1109/TPAMI.2009.72	http://dx.doi.org/10.1109/TPAMI.2009.72			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299711	Green Submitted			2022-12-18	WOS:000275569300008
J	Chan, AB; Vasconcelos, N				Chan, Antoni B.; Vasconcelos, Nuno			Layered Dynamic Textures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dynamic texture; temporal textures; video modeling; motion segmentation; mixture models; linear dynamical systems; Kalman filter; Markov random fields; probabilistic models; expectation-maximization; variational approximation; Gibbs sampling	MAXIMUM-LIKELIHOOD; LINEAR-MODELS	A novel video representation, the layered dynamic texture (LDT), is proposed. The LDT is a generative model, which represents a video as a collection of stochastic layers of different appearance and dynamics. Each layer is modeled as a temporal texture sampled from a different linear dynamical system. The LDT model includes these systems, a collection of hidden layer assignment variables (which control the assignment of pixels to layers), and a Markov random field prior on these variables (which encourages smooth segmentations). An EM algorithm is derived for maximum-likelihood estimation of the model parameters from a training video. It is shown that exact inference is intractable, a problem which is addressed by the introduction of two approximate inference procedures: a Gibbs sampler and a computationally efficient variational approximation. The trade-off between the quality of the two approximations and their complexity is studied experimentally. The ability of the LDT to segment videos into layers of coherent appearance and dynamics is also evaluated, on both synthetic and natural videos. These experiments show that the model possesses an ability to group regions of globally homogeneous, but locally heterogeneous, stochastic dynamics currently unparalleled in the literature.	[Chan, Antoni B.; Vasconcelos, Nuno] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Chan, AB (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, 9500 Gilman Dr,Mail Code 0407, La Jolla, CA 92093 USA.	abchan@ucsd.edu; nuno@ece.ucsd.edu	Chan, Antoni/D-7858-2013	Chan, Antoni/0000-0002-2886-2513; Vasconcelos, Nuno/0000-0002-9024-4302	US National Science Foundation (NSF) [IIS-0534985, DGE-0333451]	US National Science Foundation (NSF)(National Science Foundation (NSF))	The authors thank Rene Vidal for the code from [11], [12], Mubarak Shah for the crowd videos [32], [57], Renaud Peteri, Mark Huiskes, and Sandor Fazekas for the windmill video [58], and the anonymous reviewers for insightful comments. This work was funded by a US National Science Foundation (NSF) award IIS-0534985 and an NSF IGERT award DGE-0333451.	Ali S., 2007, P IEEE C COMP VIS PA; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Bauer D, 2005, J TIME SER ANAL, V26, P631, DOI 10.1111/j.1467-9892.2005.00441.x; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Bishop C.M, 2006, PATTERN RECOGN; CETINGUL E, 2007, P INT WORKSH DYN VIS; Chan A., 2007, P IEEE C COMP VIS PA; CHAN AB, 2006, ADV NEURAL INFORM PR, V18, P203; Chan AB, 2008, IEEE T PATTERN ANAL, V30, P909, DOI 10.1109/TPAMI.2007.70738; CHAN J, 2005, INTELL PROP L B, V10, P1; COOPER L, 2005, P DYN VIS WORKSH IEE; Costantini R, 2008, IEEE T IMAGE PROCESS, V17, P42, DOI 10.1109/TIP.2007.910956; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Doretto G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1236; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; DORETTO G, 2004, P EUR C COMP VIS; Doretto G, 2006, IEEE T PATTERN ANAL, V28, P2006, DOI 10.1109/TPAMI.2006.243; Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584; Frey B. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P416, DOI 10.1109/CVPR.1999.786972; Gelb A., 1974, APPL OPTIMAL ESTIMAT; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Ghahramani Z, 2000, NEURAL COMPUT, V12, P831, DOI 10.1162/089976600300015619; GHAHRAMANI Z, 1996, CRGT962 U TOR DEP SC; Ghanem B., 2007, P IEEE INT C COMP VI; Ghoreyshi A., 2006, P DYN VIS WORKSH EUR; Gray J. I., 1984, Advances in Food Research, V29, P1; Gunawardana A, 2005, J MACH LEARN RES, V6, P2049; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707; Kay S. M., 1993, FUNDAMENTALS STAT SI; KIM CJ, 1994, J ECONOMETRICS, V60, P1, DOI 10.1016/0304-4076(94)90036-1; Liu CB, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1379; LIU CB, 2006, BMVC, V2, P859; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; MACKAY DJC, 1999, LEARNING GRAPHICAL M, P175; Oh SM, 2008, INT J COMPUT VISION, V77, P103, DOI 10.1007/s11263-007-0062-z; OVERSCHEE PV, 1994, AUTOMATICA, V30, P75; Pavlovic V., 2000, ADV NEURAL INFORM PR, V13; PAVLOVIC VI, 1999, P IEEE C COMP VIS PA; Saisan P, 2001, PROC CVPR IEEE, P58; SHI J, 1999, P INT C COMP VIS, P1154; Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x; SHUMWAY RH, 1991, J AM STAT ASSOC, V86, P763, DOI 10.2307/2290410; Siddiqi S., 2007, ADV NEURAL INFORM PR; Soatto S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICCV.2001.937658; Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871; Vasconcelos N, 2001, IEEE T PATTERN ANAL, V23, P217, DOI 10.1109/34.908972; Vidal R, 2005, PROC CVPR IEEE, P516; VIDAL R, 2006, ADV NEURAL INFORM PR; VIDAL R, 2007, P INT C COMP VIS; Vishwanathan SVN, 2007, INT J COMPUT VISION, V73, P95, DOI 10.1007/s11263-006-9352-0; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Wu Y, 2003, PROC CVPR IEEE, P295; Yuan L, 2004, LECT NOTES COMPUT SC, V3022, P603; 2009, COMPREHENSIVE DATABA; 2009, UCF CROWD MOTION DAT; 2009, LAYERED DYNAMIC TEXT	59	54	58	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1862	1879		10.1109/TPAMI.2009.110	http://dx.doi.org/10.1109/TPAMI.2009.110			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696455	Green Submitted			2022-12-18	WOS:000268996500011
J	Holmes, SA; Klein, G; Murray, DW				Holmes, Steven A.; Klein, Georg; Murray, David W.			An O(N-2) Square Root Unscented Kalman Filter for Visual Simultaneous Localization and Mapping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Structure from motion; simultaneous localization and mapping; unscented Kalman filter	CONSISTENCY	This paper develops a Square Root Unscented Kalman Filter (SRUKF) for performing video-rate visual simultaneous localization and mapping (SLAM) using a single camera. The conventional UKF has been proposed previously for SLAM, improving the handling of nonlinearities compared with the more widely used Extended Kalman Filter (EKF). However, no account was taken of the comparative complexity of the algorithms: In SLAM, the UKF scales as O(N-3) in the state length, compared to the EKF's O(N-2), making it unsuitable for video-rate applications with other than unrealistically few scene points. Here, it is shown that the SRUKF provides the same results as the UKF to within machine accuracy and that it can be reposed with complexity O(N-2) for state estimation in visual SLAM. This paper presents results from video-rate experiments on live imagery. Trials using synthesized data show that the consistency of the SRUKF is routinely better than that of the EKF, but that its overall cost settles at an order of magnitude greater than the EKF for large scenes.	[Holmes, Steven A.; Klein, Georg; Murray, David W.] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	University of Oxford	Holmes, SA (corresponding author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.	sah@robots.ox.ac.uk; gk@robots.ox.ac.uk; dwm@robots.ox.ac.uk			UK Engineering and Physical Science Research Council [GR/S97774, EP/D037077]; EPSRC; Engineering and Physical Sciences Research Council [GR/S97774/01] Funding Source: researchfish	UK Engineering and Physical Science Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by Grants GR/S97774 and EP/D037077 from the UK Engineering and Physical Science Research Council. Steven A. Holmes is supported by an EPSRC Research Studentship. The authors are grateful for the insightful comments of the reviewers and for conversations with Dr. Simon Julier and the late Professor Gene H. Golub during his last sabbatical in Oxford.	*2D3 LTD, 2008, BOUJ; Andrade-Cetto J, 2005, IEEE INT CONF ROBOT, P323; AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101; Bailey T, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3562, DOI 10.1109/IROS.2006.281644; Bizup DF, 2003, FUSION 2003: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE OF INFORMATION FUSION, VOLS 1 AND 2, P40; CALLEJA TAV, 2007, THESIS U POLITECNICA; Castellanos JA, 2007, ROBOT AUTON SYST, V55, P21, DOI 10.1016/j.robot.2006.06.005; Chekhlov D, 2006, LECT NOTES COMPUT SC, V4292, P276; Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403; DAVISON AJ, 1998, P 5 EUR C COMP VIS F, P809; Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049; der Merwe R. V., 2001, P IEEE INT C AC SPEE, P3461, DOI DOI 10.1109/ICASSP.2001.940586; Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264; FITZGIBBON AW, 1998, P 5 EUR C COMP VIS, V1, P311; GILL PE, 1974, MATH COMPUT, V28, P505, DOI 10.1090/S0025-5718-1974-0343558-6; GOLUB GH, 2007, COMMUNICATION; HARRIS M, 1987, WRITING INSTRUCTOR, V6, P87; Higham N.J., 1990, ANAL CHOLESKY DECOMP, P161; Holmes S, 2008, IEEE INT CONF ROBOT, P3710, DOI 10.1109/ROBOT.2008.4543780; HOSTETLER LD, 1983, IEEE T AUTOMAT CONTR, V28, P315, DOI 10.1109/TAC.1983.1103232; Huang SD, 2007, IEEE T ROBOT, V23, P1036, DOI 10.1109/TRO.2007.903811; Julier Simon J., 2004, P IEEE, V92; JULIER SJ, 1995, PROCEEDINGS OF THE 1995 AMERICAN CONTROL CONFERENCE, VOLS 1-6, P1628; Julier SJ, 2001, IEEE INT CONF ROBOT, P4238, DOI 10.1109/ROBOT.2001.933280; Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797; Kaess M, 2007, IEEE INT CONF ROBOT, P1670, DOI 10.1109/ROBOT.2007.363563; Kalman R.E., 1961, J BASIC ENG-T ASME, V83, P95, DOI [10.1115/1.3658902, DOI 10.1115/1.3658902]; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Langelaan J, 2005, AEROSP CONF PROC, P3011; Lefebvre T, 2004, INT J CONTROL, V77, P639, DOI 10.1080/00207170410001704998; LEONARD JJ, 1992, INT J ROBOT RES, V11, P286, DOI 10.1177/027836499201100402; LEONARD JJ, 1992, DIRECTED SONAR SENSI; MARTINEZCANTIN R, 2005, P 2005 IEEE INT C IN, P3427; Montiel J., 2006, P ROB SCI SYST; Moutarlier P., 1989, STOCHASTIC MULTISENS; Nister D., 2001, THESIS ROYAL I TECHN; Paul AS, 2005, IEEE IJCNN, P2784; Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a; *REALVIZ SA, 2008, MATCHM; SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404; Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479; Thrun S., 2005, PROBABILISTIC ROBOTI	43	54	67	2	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1251	1263		10.1109/TPAMI.2008.189	http://dx.doi.org/10.1109/TPAMI.2008.189			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443923				2022-12-18	WOS:000266188900009
J	Mellor, M; Hong, BW; Brady, M				Mellor, Matthew; Hong, Byung-Woo; Brady, Michael			Locally rotation, contrast, and scale invariant descriptors for texture analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture; scale invariance; local phase	CLASSIFICATION	Textures within real images vary in brightness, contrast, scale, and skew as imaging conditions change. To enable recognition of textures in real images, it is necessary to employ a similarity measure that is invariant to these properties. Furthermore, since textures often appear on undulating surfaces, such invariances must necessarily be local rather than global. Despite these requirements, it is only relatively recently that texture recognition algorithms with local scale and affine invariance properties have begun to be reported. Typically, they comprise detecting feature points followed by geometric normalization prior to description. We describe a method based on invariant combinations of linear filters. Unlike previous methods, we introduce a novel family of filters, which provides scale invariance, resulting in a texture description invariant to local changes in orientation, contrast, and scale and robust to local skew. Significantly, the family of filters enables local scale invariants to be defined without using a scale selection principle or a large number of filters. A texture discrimination method based on the chi(2) similarity measure applied to histograms derived from our filter responses outperforms existing methods for retrieval and classification results for both the Brodatz textures and the University of Illinois, Urbana-Champaign (UIUC) database, which has been designed to require local invariance.	REACT Engn Ltd, Fleswick Court, Whitehaven CA24 3HZ, Cumbria, England; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; Univ Oxford, Dept Engn Sci, Wolfson Med Vis Lab, Oxford OX1 3PJ, England	University of California System; University of California Los Angeles; University of Oxford	Mellor, M (corresponding author), REACT Engn Ltd, Fleswick Court, Westlakes Sci & Technol Pk, Whitehaven CA24 3HZ, Cumbria, England.	mmellor@react-engineering.co.uk; hong@cs.ucla.edu; jmb@robots.ox.ac.uk		Hong, Byung-Woo/0000-0003-2752-3939				ADELSON EH, 1992, IEEE T INFORM THEORY, V38; BLUNSDEN S, 2005, P IEE INT C VIS INF; Boukerroui D, 2004, J MATH IMAGING VIS, V21, P53, DOI 10.1023/B:JMIV.0000026557.50965.09; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Carneiro G, 2002, LECT NOTES COMPUT SC, V2350, P282; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; FELSBERG M, 2002, THESIS CHRISTIAN ALB; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; Kothe U, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P424; LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679; Lazebnik S., 2004, CVRTR200401 U ILL BE; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; LINDEBERG T, 1996, INT J COMPUTER VISIO, V17; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; Pun CM, 2003, IEEE T PATTERN ANAL, V25, P590, DOI 10.1109/TPAMI.2003.1195993; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; ROMENY BMT, 2003, FRONT ENG VISION MUL; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Schmid C, 2001, PROC CVPR IEEE, P39; Tuytelaars T., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P412; Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255; Varma M., 2003, P IEEE INT C COMP VI; Zhang JG, 2003, PATTERN RECOGN, V36, P657, DOI 10.1016/S0031-3203(02)00099-7	25	54	56	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					52	61		10.1109/TPAMI.2007.1161	http://dx.doi.org/10.1109/TPAMI.2007.1161			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000324				2022-12-18	WOS:000250843500005
J	Felsberg, M; Forssen, PE; Scharr, H				Felsberg, M; Forssen, PE; Scharr, H			Channel smoothing: Efficient robust smoothing of low-level signal features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						robust smoothing; channel representation; diffusion filtering; bilateral filtering; mean-shift; B-spline; orientation smoothing	MEAN SHIFT; IMAGE; DIFFUSION	In this paper, we present a new and efficient method to implement robust smoothing of low-level signal features: B-spline channel smoothing. This method consists of three steps: encoding of the signal features into channels, averaging of the channels, and decoding of the channels. We show that linear smoothing of channels is equivalent to robust smoothing of the signal features if we make use of quadratic B-splines to generate the channels. The linear decoding from B-spline channels allows the derivation of a robust error norm, which is very similar to Tukey's biweight error norm. We compare channel smoothing with three other robust smoothing techniques: nonlinear diffusion, bilateral filtering, and mean-shift filtering, both theoretically and on a 2D orientation-data smoothing task. Channel smoothing is found to be superior in four respects: It has a lower computational complexity, it is easy to implement, it chooses the global minimum error instead of the nearest local minimum, and it can also be used on nonlinear spaces, such as orientation space.	Linkoping Univ, Dept Elect Engn, Comp Vis Lab, S-58183 Linkoping, Sweden; Forschungszentrum Julich GmbH, D-52425 Julich, Germany	Linkoping University; Helmholtz Association; Research Center Julich	Felsberg, M (corresponding author), Linkoping Univ, Dept Elect Engn, Comp Vis Lab, S-58183 Linkoping, Sweden.	mfe@isy.liu.se; perfo@isy.liu.se; h.scharr@fz-juelich.de	Scharr, Hanno/D-9051-2015	Scharr, Hanno/0000-0002-8555-6416; Felsberg, Michael/0000-0002-6096-3648				Aurich V., 1995, MUSTERERKENNUNG, P538; Bishop, 1995, NEURAL NETWORKS PATT; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Bracewell R., 1986, FOURIER TRANSFORM IT; BRUCE AG, 1994, WAVELET APPL, V2242; Chambolle A, 2001, IEEE T IMAGE PROCESS, V10, P993, DOI 10.1109/83.931093; Chan T, 2000, SIAM J APPL MATH, V61, P1338, DOI 10.1137/S003613999935799X; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Chu CK, 1998, J AM STAT ASSOC, V93, P526, DOI 10.2307/2670100; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416; DAHLQUIST G, IN PRESS NUMERICAL M; DEBOOR C, 1990, SPLINEFUNKTIONEN; Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520; FELSBERG M, 2000, P DAGM, P195; FELSBERG M, 2005, SUPPLEMENTAL MAT CHA; Felsberg M., 2002, LITHISYR2461 LINK U; FELSBERG M, 2003, P 13 SCAND C IM AN, P755; Forssen P., 2002, LITHISYR2418 LINK U; FORSSEN PE, 2001, LIUTEKLIC200106; Fukunaga K., 1975, IEEE T INFORMATION T, V21, P23; GODTLIEBSEN F, 1997, J NONPARAMETR STAT, V8, P21; Granlund G.H., 1995, SIGNAL PROCESSING CO; GRANLUND GH, 1978, COMPUT VISION GRAPH, V8, P155, DOI 10.1016/0146-664X(78)90047-3; GRANLUND GH, 2000, P INT WORKSH ALG FRA; Jacob M, 2001, PROC SPIE, V4322, P340, DOI 10.1117/12.431105; JOHANSSON B, 2002, LITHISYR2475 LINK U; KIMMEL R, 2001, J VIS COMMUN IMAGE R, P238; KNUTSSON H, 1994, P IEEE INT C AC SPEE; Louis A K, 1994, WAVELETS; LUDTKE NL, 2002, P IEEE INT C IM PROC, V2, P865; Mrazek P, 2003, LECT NOTES COMPUT SC, V2695, P101; NORDBERG K, 1994, P IEEE INT C IM PROC; PENNEC X, 1989, J MATH IMAGING VIS, V9, P49; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; SNIPPE HP, 1992, BIOL CYBERN, V66, P543, DOI 10.1007/BF00204120; Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181; Tang B, 2000, INT J COMPUT VISION, V36, P149, DOI 10.1023/A:1008152115986; Tomasi C, 1998, P 6 INT C COMP VIS; Tschumperle D, 2002, INT J COMPUT VISION, V50, P237, DOI 10.1023/A:1020870207168; Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930; Vese LA, 2003, SIAM J NUMER ANAL, V40, P2085; Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P260; WEICKERT J, 1996, COMP SUPPL, V11, P221; WEISSTEIN E, 2003, WORLD MATH; Zemel RS, 1998, NEURAL COMPUT, V10, P403, DOI 10.1162/089976698300017818; [No title captured]; [No title captured]	52	54	57	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					209	222		10.1109/TPAMI.2006.29	http://dx.doi.org/10.1109/TPAMI.2006.29			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468618	Green Submitted, Green Published			2022-12-18	WOS:000233824500004
J	Tan, CL; Zhang, L; Zhang, Z; Xia, T				Tan, CL; Zhang, L; Zhang, Z; Xia, T			Restoring warped document images through 3D shape modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image restoration; document image analysis; shape from shading; image warping; image distortion; OCR improvement	RESTORATION	Scanning a document page from a thick bound volume often results in two kinds of distortions in the scanned image, i.e., shade along the "spine" of the book and warping in the shade area. In this paper, we propose an efficient restoration method based on the discovery of the 3D shape of a book surface from the shading information in a scanned document image. From a technical point of view, this shape from shading (SFS) problem in real-world environments is characterized by 1) a proximal and moving light source, 2) Lambertian reflection, 3) nonuniform albedo distribution, and 4) document skew. Taking all these factors into account, we first build practical models (consisting of a 3D geometric model and a 3D optical model) for the practical scanning conditions to reconstruct the 3D shape of the book surface. We next restore the scanned document image using this shape based on deshading and dewarping models. Finally, we evaluate the restoration results by comparing our estimated surface shape with the real shape as well as the OCR performance on original and restored document images. The results show that the geometric and photometric distortions are mostly removed and the OCR results are improved markedly.	Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore; Natl Univ Singapore, Dept Math, Singapore 117543, Singapore	National University of Singapore; National University of Singapore	Tan, CL (corresponding author), Natl Univ Singapore, Sch Comp, 3,Sci Dr 2, Singapore 117543, Singapore.	tancl@comp.nus.edu.sg; zhangli@comp.nus.edu.sg; zhangz@comp.nus.edu.sg; iesxiat@nus.edu.sg						BAIRD H, 1993, P IAPR INT C DOC AN, P730; Baird H., 1990, P IAPR WORKSH SYNT S, P38; Baird H. S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P459, DOI 10.1109/ICDAR.1999.791824; Brown MS, 2004, IEEE T PATTERN ANAL, V26, P1295, DOI 10.1109/TPAMI.2004.87; Cao HG, 2003, PROC INT CONF DOC, P71; Cao HG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P228, DOI 10.1109/ICCV.2003.1238346; Doncescu A, 1997, WORKSHOP ON DOCUMENT IMAGE ANALYSIS (DIA'97), PROCEEDINGS, P5, DOI 10.1109/DIA.1997.627085; Junker M., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P713, DOI 10.1109/ICDAR.1999.791887; KANUNGO T, 1994, INT J IMAG SYST TECH, V5, P220, DOI 10.1002/ima.1850050305; LAVAILLE O, 2001, KP INT C IM PROC OCT, P1074; Pilu M, 2001, PROC CVPR IEEE, P67; RAGHEB H, 2001, P BRIT MACH VIS C, P541; TANG YY, 1993, IEEE T SYST MAN CYB, V23, P155, DOI 10.1109/21.214774; Tsoi YC, 2004, PROC CVPR IEEE, P240; Wada T, 1997, INT J COMPUT VISION, V24, P125, DOI 10.1023/A:1007906904009; Weng Y, 1996, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1996.517129; YAMASHITA A, 2004, P INT C PATT REC; Zhang JY, 2003, IEEE T FUZZY SYST, V11, P593, DOI 10.1109/TFUZZ.2003.817836; Zhang Z, 2004, PROC CVPR IEEE, P10; Zhang Z, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P977, DOI 10.1109/ICIP.2002.1039138; Zhang Z, 2001, IEEE IMAGE PROC, P1074, DOI 10.1109/ICIP.2001.959235; Zhang Z, 2001, PROC INT CONF DOC, P429, DOI 10.1109/ICDAR.2001.953826; ZHANG Z, 2004, P INT C PATT REC	23	54	59	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					195	208						14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468617				2022-12-18	WOS:000233824500003
J	Geiger, D; Liu, TL; Kohn, RV				Geiger, D; Liu, TL; Kohn, RV			Representation and self-similarity of shapes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape representation; self-similarity; variational matching; dynamic programming; MRF	FORM	Representing shapes in a compact and informative form is a significant problem for vision systems that must recognize or classify objects. We describe a compact representation model for two-dimensional (2D) shapes by investigating their self-similarities and constructing their shape axis trees (SA-trees). Our approach can be formulated as a variational one (or, equivalently, as MAP estimation of a Markov random field). We start with a 2D shape, its boundary contour, and two different parameterizations for the contour (one parameterization is oriented counterclockwise and the other clockwise). To measure its self-similarity, the two parameterizations are matched to derive the best set of one-to-one point-to-point correspondences along the contour. The cost functional used in the matching may vary and is determined by the adopted self-similarity criteria, e.g., cocircularity, distance variation, parallelism, and region homogeneity. The loci of middle points of the pairing contour points yield the shape axis and they can be grouped into a unique free tree structure, the SA-tree. By implicitly encoding the (local and global) shape information into an SA-tree, a variety of vision tasks, e.g., shape recognition, comparison, and retrieval, can be performed in a more robust and efficient way via various tree-based algorithms. A dynamic programming algorithm gives the optimal solution in O(N-4), where N is the size of the contour.	NYU, Courant Inst Math Sci, New York, NY 10012 USA; Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan	New York University; Academia Sinica - Taiwan	Geiger, D (corresponding author), NYU, Courant Inst Math Sci, 251 Mercer St, New York, NY 10012 USA.	gieger@cims.nyu.edu; kohn@cims.nyu.edu; liutyng@iis.sinica.edu.tw						ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BINFORD TO, 1971, P IEEE C SYST CONTR; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BURBECK CA, 1995, VISION RES, V35, P1917, DOI 10.1016/0042-6989(94)00286-U; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; FAWCETT R, 1994, IMAGE VISION COMPUT, V12, P615, DOI 10.1016/0262-8856(94)90015-9; HILDRETH E, 1983, MEASUREMENT VISUAL M; Huttenlocher D. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P102; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013; Liu TL, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1129, DOI 10.1109/ICCV.1998.710858; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; Ogniewicz R. L., 1993, DISCRETE VORONOI SKE; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; Pentland A. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P612; PIZER SM, 1987, IEEE T PATTERN ANAL, V9, P505, DOI 10.1109/TPAMI.1987.4767938; PONCE J, 1987, COMPUT VISION GRAPH, V38, P1, DOI 10.1016/S0734-189X(87)80151-2; RICHARDS W, 1985, COMPUT VISION GRAPH, V31, P265, DOI 10.1016/0734-189X(85)90031-3; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; Segen J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P597, DOI 10.1109/CVPR.1989.37907; SHASHA D, 1994, IEEE T SYST MAN CYB, V24, P668, DOI 10.1109/21.286387; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722; Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119; Tari ZSG, 1997, COMPUT VIS IMAGE UND, V66, P133, DOI 10.1006/cviu.1997.0612; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; ULLMAN S, 1989, COGNITION, V32, P193, DOI 10.1016/0010-0277(89)90036-X; ULUPINAR F, 1993, IEEE T PATTERN ANAL, V15, P3, DOI 10.1109/34.184771; Zhu S. C., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P465, DOI 10.1109/ICCV.1995.466903; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	39	54	56	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2003	25	1					86	99		10.1109/TPAMI.2003.1159948	http://dx.doi.org/10.1109/TPAMI.2003.1159948			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	628NL					2022-12-18	WOS:000180002300007
J	Khotanzad, A; Zink, E				Khotanzad, A; Zink, E			Contour line and geographic feature extraction from USGS color topographical paper maps	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color map analysis; map segmentation; topographic map contour line extraction; USGS map analysis; aliasing and false colors	RECOGNITION; ALGORITHM	This paper presents a method for the extraction of contour lines and other geographic information from scanned color images of topographical maps. Although topographic maps are available from many suppliers, this work focuses on United States Geological Survey (USGS) maps. The extraction of contour lines, which are shown with brown color on USGS maps, is a difficult process due to aliasing and false colors induced by the scanning process and due to closely spaced and intersecting/overlapping features inherent to the map. These difficulties render simple approaches such as clustering ineffective. The proposed method overcomes these difficulties using a multistep process. First, a color key set, designed to comprehend color aliasing and false colors, is generated using an eigenvector line-fitting technique in RGB space. Next, area features, representing vegetation and bodies of water, are extracted using RGB color histogram analysis in order to simplify the next stage. Then, linear features corresponding to roads and rivers including contours, are extracted using a valley seeking algorithm operating on a transformed version of the original map. Finally, an A* search algorithm is used to link valleys together to form linear features and to close the gaps caused by intersecting features. The performance of the algorithm is tested on a number of USGS topographic map samples.	So Methodist Univ, Dept Elect Engn, Dallas, TX 75275 USA	Southern Methodist University	Khotanzad, A (corresponding author), So Methodist Univ, Dept Elect Engn, POB 750338, Dallas, TX 75275 USA.							Barr A, 1981, HDB ARTIFICIAL INTEL; Duda R.O., 1973, J ROYAL STAT SOC SER; Dupont F., 1999, P 3 INT WORKSH GRAPH, P53; FRISCHKNECHT S, 1997, P 2 INT WORKSH GREC, P207; Fukunaga K, 1990, STAT PATTERN RECOGNI; GAMBA P, 1999, PATTERN RECOGN, P355; Hedley M., 1992, Journal of Electronic Imaging, V1, P374, DOI 10.1117/12.61158; KHOTANZAD A, 1990, PATTERN RECOGN, V23, P961, DOI 10.1016/0031-3203(90)90105-T; Khotanzad A, 1996, PROCEEDINGS OF THE IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P190, DOI 10.1109/IAI.1996.493751; KHOTANZAD A, 1996, P 4 COL IM C COL SCI, P129; MARCU R, 1996, P 4 COL IM C COL SCI, P151; NEBIKER S, 1995, AUTOMATIC EXTRACTION, P287; Prather R.E., 1976, DISCRETE MATH STRUCT; Trier OD, 1997, IEEE T PATTERN ANAL, V19, P399, DOI 10.1109/34.588025; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062; Wu J., 1994, Journal of Electronic Imaging, V3, P397, DOI 10.1117/12.183755; Yamada H., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P1149, DOI 10.1142/S0218001494000577; YAMADA H, 1993, IEEE T PATTERN ANAL, V15, P380, DOI 10.1109/34.206957; ZAMISKA J, 1986, DS E, P115; ZINK E, 1998, THESIS SO METHODIST	21	54	62	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2003	25	1					18	31		10.1109/TPAMI.2003.1159943	http://dx.doi.org/10.1109/TPAMI.2003.1159943			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	628NL					2022-12-18	WOS:000180002300002
J	Koster, K; Spann, M				Koster, K; Spann, M			MIR: An approach to robust clustering - Application to range image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; robust statistics; region merging; range images; clustering; least-median-of-squares; segmentation comparison	COMPUTER VISION	This paper describes an unsupervised region merging technique based on a novel robust statistical test. The merging decision is derived from the mutual inlier ratio (MIR) of adjacent regions. This ratio is computed using robust regression techniques and a novel method to estimate the robust scale of the Gaussian distribution. A discrimination value to recognize identical Gaussian distributions with the MIR is derived theoretically as a function of the sizes of the compared sets. The presented method to test distributions is compared with the established Kolmogorov-Smirnov test and implemented into a segmentation algorithm for planar range images. The iterative region growing technique is evaluated using an established framework for range image segmentation comparison involving 60 real range images. The evaluation incorporates a comparison with four state-of-the-art algorithms and gives an experimental demonstration of the need for robust methods capable of handling noisy data in real applications.	Nokia Telecommun, Div NMS, NCP R&D, Dusseldorf, Germany; Univ Birmingham, Sch Elect & Elect Engn, Birmingham B15 2TT, W Midlands, England	Nokia Corporation; University of Birmingham	Koster, K (corresponding author), Nokia Telecommun, Div NMS, NCP R&D, Dusseldorf, Germany.	Klaus.Koster@nokia.com; M.Spann@bham.ac.uk						ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Ballard D.H., 1982, COMPUTER VISION; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BLACK MJ, 1996, INT J COMPUTER VISIO, V19; CHANG YL, 1994, IEEE T IMAGE PROCESS, V3, P868, DOI 10.1109/83.336259; Checchin P, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P156, DOI 10.1109/IM.1997.603861; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; Gregory R. L., 1970, INTELLIGENT EYE; Haindl M., 1997, Image Analysis and Processing. 9th International Conference, ICIAP '97 Proceedings, P295; Haralick R.M., 1992, COMPUTER ROBOT VISIO, V1; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; JOLION JM, 1991, IEEE T PATTERN ANAL, V13, P791, DOI 10.1109/34.85669; KOSTER K, 1998, EUROPEAN SIGNAL PROC, V3, P2425; KOSTER K, 1998, VISION INTERFACE, P121; KOSTER K, 1999, THESIS U BIRMINGHAM; Lapin L. L., 1990, PROBABILITY STAT MOD; Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Meer P., 1990, P DARPA IM UND WORKS, P231; Miller JV, 1997, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.1997.609456; MOSCHENI F, 1996, SPIE P VISUAL COMM I; Neisser U., 1967, COGNITIVE PSYCHOL; Press WH, 1995, NUMERICAL RECIPES C; RICHARDS DS, 1990, IEEE T ACOUST SPEECH, V38, P145, DOI 10.1109/29.45627; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; Schalkoff R.J., 1989, DIGITAL IMAGE PROCES; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Stewart CV, 1997, IEEE T PATTERN ANAL, V19, P818, DOI 10.1109/34.608280; TRUCCO E, 1995, IEEE T PATTERN ANAL, V17, P177, DOI 10.1109/34.368172; WANI MA, 1994, IEEE T PATTERN ANAL, V16, P314, DOI 10.1109/34.276131; WILSON R, 1984, IEEE T PATTERN ANAL, V6, P758, DOI 10.1109/TPAMI.1984.4767599; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7	35	54	59	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2000	22	5					430	444		10.1109/34.857001	http://dx.doi.org/10.1109/34.857001			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	337FV					2022-12-18	WOS:000088347500002
J	Cesarini, F; Gori, M; Marinai, S; Soda, G				Cesarini, F; Gori, M; Marinai, S; Soda, G			INFORMys: A flexible invoice-like form-reader system	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						attributed relational graphs; document analysis and recognition; document registration; invoice processing; location of information fields	RECOGNITION	In this paper, we describe a flexible form-reader system capable of extracting textual information from accounting documents, like invoices and bills of service companies. In this kind of document, the extraction of some information fields cannot take place without having detected the corresponding instruction fields, which are only constrained to range in given domains. We propose modeling the document's layout by means of attributed relational graphs, which turn out to be very effective for form registration, as well as for performing a focussed search for instruction fields. This search is carried out by means of a hybrid model, where proper algorithms, based on morphological operations and connected components, are integrated with connectionist models. Experimental results are given in order to assess the actual performance of the system.	Univ Florence, Dipartimento Sistemi & Informat, I-50138 Firenze, Italy; Univ Siena, Dipartimento Ingn Informaz, I-53100 Siena, Italy	University of Florence; University of Siena	Cesarini, F (corresponding author), Univ Florence, Dipartimento Sistemi & Informat, Via S Marta 3, I-50138 Firenze, Italy.			MARINAI, SIMONE/0000-0002-6702-2277				BAIRD HS, 1992, STRUCTURED DOCUMENT, P547; BIANCHINI M, 1995, IEEE T NEURAL NETWOR, V6, P512, DOI 10.1109/72.363492; Casey R., 1992, Machine Vision and Applications, V5, P143, DOI 10.1007/BF02626994; Cesarini F, 1997, PROC INT CONF DOC, P175, DOI 10.1109/ICDAR.1997.619836; CESARINI F, 1996, LECT NOTES COMPUTER, P135; CESARINI F, 1994, P INT C IECON 94, P987; DOERMANN D, 1993, THESIS U MARYLAND CO; Doermann D. S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P497, DOI 10.1109/ICDAR.1993.395687; ESHERA MA, 1986, IEEE T PATTERN ANAL, V8, P604, DOI 10.1109/TPAMI.1986.4767835; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232; FUJISAWA H, 1992, P IEEE, V80, P1079, DOI 10.1109/5.156471; GARRIS MD, 1994, 5469 US DEP COMM TEC; Gori M, 1996, PATTERN RECOGN LETT, V17, P241, DOI 10.1016/0167-8655(95)00101-8; Grimson W. E. L., 1990, OBJECT RECOGNITION C; Hinds S. C., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P464, DOI 10.1109/ICPR.1990.118147; HO TK, 1993, MACH VISION APPL, V6, P157; Lam S. W., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P506, DOI 10.1109/ICDAR.1993.395685; LAM SW, 1991, P 1 INT C DOC AN REC, P112; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; TANG YY, 1995, IEEE T SYST MAN CYB, V25, P738, DOI 10.1109/21.376488; TANG YY, 1994, IEEE T KNOWL DATA EN, V6, P3, DOI 10.1109/69.273022; Taylor S. L., 1992, Machine Vision and Applications, V5, P211, DOI 10.1007/BF02626999; Thien Minh Ha, 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P1053, DOI 10.1142/S021800149400053X; Watanabe T., 1993, Machine Vision and Applications, V6, P163, DOI 10.1007/BF01211939; WATANABE T, 1995, IEEE T PATTERN ANAL, V17, P432, DOI 10.1109/34.385976; Yuan J., 1991, P ICDAR 91, P210; YUAN J, 1995, P 3 INT C DOC AN REC, P752; Zhao S. X., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P351, DOI 10.1109/ICDAR.1995.599011	30	54	59	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1998	20	7					730	745		10.1109/34.689303	http://dx.doi.org/10.1109/34.689303			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZY930					2022-12-18	WOS:000074677200005
J	Vincken, KL; Koster, ASE; Viergever, MA				Vincken, KL; Koster, ASE; Viergever, MA			Probabilistic multiscale image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image segmentation; multiscale analysis; scale space; probability maps; partial volume artifact; object definition	DECOMPOSITION; WAVELETS	A method is presented to segment multidimensional images using a multiscale (hyperstack) approach with probabilistic linking. A hyperstack is a voxel-based multiscale data structure whose levels are constructed by convolving the original image with a Gaussian kernel of increasing width. Between voxels at adjacent scale levels. child-parent linkages are established according to a model-directed linkage scheme. In the resulting tree-like data structure, roots are formed to indicate the most plausible locations in scale space where segments in the original image are represented by a single voxel. The final segmentation is obtained by tracing back the linkages for all roots. The present paper deals with probabilistic (or multiparent) linking, i.e., a set-up in which a child voxel can be linked to more than one parent voxel. The multiparent linkage structure is translated into a list of probabilities that are indicative of which voxels are partial volume voxels and to which extent. Probability maps are generated to visualize the progress of weak linkages in scale space when going from fine to coarser scale. This is shown to be a valuable tool for the detection of voxels that are difficult to segment properly. The output of a probabilistic hyperstack can be directly related to the opacities used in volume renderers. Results are shown both for artificial and real world (medical) images. It is demonstrated that probabilistic linking gives a significantly improved segmentation as compared with conventional (single-parent) linking. The improvement is quantitatively supported by an objective evaluation method.	MACH TECHNOL, NL-2900 ED CAPELLE IJSSEL, NETHERLANDS		Vincken, KL (corresponding author), UNIV UTRECHT HOSP, IMAGE SCI INST, E01334, HEIDELBERGLAAN 100, NL-3584 CX UTRECHT, NETHERLANDS.		Viergever, Max A/J-1215-2014; Vincken, Koen/AAP-3558-2021					BISTER M, 1990, PATTERN RECOGN LETT, V11, P605, DOI 10.1016/0167-8655(90)90013-R; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; de Graaf C. N., 1984, Proceedings of the 1984 International Joint Alpine Symposium on Medical Computer Graphics and Image Communications and Clinical Advances in Neuro CT/NMR (cat. no. 84CH2006-5), P71; DEGRAAF CN, 1991, PROG CLIN BIOL RES, V363, P399; DEGRAAF CN, 1992, COMPUTER BASED MED S, P17; DEGRAAF CN, 1984, INFORMATION PROCESSI, P343; Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484; Florack L. M. J., 1994, Journal of Mathematical Imaging and Vision, V4, P325, DOI 10.1007/BF01262401; GROSSMANN A, 1984, SIAM J MATH ANAL, V15, P723, DOI 10.1137/0515056; KOSTER ASE, UNPUB IEEE T PATTERN; KOSTER ASE, 1995, THESIS UTRECHT U NET; KOSTER ASE, 1997, COMPUTER VISION IMAG, V65; LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511; LIFSHITZ LM, 1990, IEEE T PATTERN ANAL, V12, P529, DOI 10.1109/34.56189; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MEER P, 1988, COMPUT VISION GRAPH, V44, P307, DOI 10.1016/0734-189X(88)90127-2; NIESSEN WJ, 1996, IEEE WORKSH MATH MET, P263; PIZER SM, 1986, INFORMATION PROCESSI, P24; Suermondt H. J., 1990, International Journal of Approximate Reasoning, V4, P283, DOI 10.1016/0888-613X(90)90003-K; Vincken K. L., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P115, DOI 10.1109/VBC.1990.109310; VINCKEN KL, 1992, P SOC PHOTO-OPT INS, V1808, P63, DOI 10.1117/12.131068; VINCKEN KL, 1994, PATTERN RECOGN LETT, V15, P477, DOI 10.1016/0167-8655(94)90139-2; VINCKEN KL, 1995, THESIS UTRECHT U NET; VINCKEN KL, 1995, LECT NOTES COMPUTER, V905, P351; VINCKEN KL, 1996, IEEE C COMP VIS PATT, P21; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; ZUIDERVELD KJ, 1994, S VOL VIS ACM SIGGRA, P59	31	54	54	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					109	120		10.1109/34.574787	http://dx.doi.org/10.1109/34.574787			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800002
J	Shpitalni, M; Lipson, H				Shpitalni, M; Lipson, H			Identification of faces in a 2D line drawing projection of a wireframe object	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						line drawing interpretation; face identification; line labeling; 3D object reconstruction; nonmanifold geometry; image understanding		An important key to reconstructing a three-dimensional object depicted by a two-dimensional line drawing projection is face identification. Identification of edge circuits in a 2D projection corresponding to actual faces of a 3D object becomes complex when the projected object is in wireframe representation. This representation is commonly encountered in drawings made during the conceptual design stage of mechanical parts. When nonmanifold objects are considered, the situation becomes even more complex. This paper discusses the principles underlying face identification and presents an algorithm capable of performing this identification. Face-edge-vertex relationships applicable to nonmanifold objects are also proposed. Examples from a working implementation are given.			Shpitalni, M (corresponding author), TECHNION ISRAEL INST TECHNOL,FAC MECH ENGN,LAB COMP GRAPH & CAD,IL-32000 HAIFA,ISRAEL.							CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; CONTI P, 1991, LECT NOTES COMPUT SC, V539, P130; FRIEDBERG SA, 1986, COMPUT VISION GRAPH, V34, P138, DOI 10.1016/S0734-189X(86)80055-X; GIBBSON A, 1985, ALGORITHMIC GRAPH TH; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; LECLERC YG, 1992, INT J COMPUT VISION, V9, P113, DOI 10.1007/BF00129683; Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X; LIPSON H, 1995, ANN CIRP, V45, P133; Mantyla M., 1988, INTRODUCTION; MARTI E, 1993, SIGNAL PROCESS, V32, P91, DOI 10.1016/0165-1684(93)90038-C; Rich E., 1991, ARTIF INTELL; SHPITALNI M, 1995, UNPUB T ASME; Steinitz E., 1922, ENZYKL MATH WISS GEO, V3AB, P1; Sugihara K., 1986, MACHINE INTERPRETATI; Whiteley W., 1982, STRUCT TOPOL, V7, P13; YIP RKK, 1994, IEEE T PATTERN ANAL, V16, P277, DOI 10.1109/34.276127	17	54	58	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1996	18	10					1000	1012		10.1109/34.541409	http://dx.doi.org/10.1109/34.541409			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VP691					2022-12-18	WOS:A1996VP69100004
J	ISHIDA, T; KORF, RE				ISHIDA, T; KORF, RE			MOVING-TARGET SEARCH - A REAL-TIME SEARCH FOR CHANGING GOALS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SEARCH; REAL-TIME; PROBLEM SOLVING; LEARNING; MOVING TARGET; DELIBERATION; REACTIVENESS; COMMITMENT		We consider the case of heuristic search where the goal may change during the course of the search. For example, the goal may be a target that actively avoids the problem solver. We present a moving-target search algorithm (MTS) to solve this problem, We prove that if the average speed of the target is slower than that of the problem solver, then the problem solver is guaranteed to eventually reach the target in a connected problem space. The original MTS algorithm was constructed with the minimum operations necessary to guarantee its completeness, and hence is not very efficient. To improve its efficiency, we introduce ideas from the area of resource-bounded planning into MTS, including 1) commitment to goals, and 2) deliberation for selecting plans. Experimental results demonstrate that the improved MTS is 10 to 20 times more efficient than the original MTS in uncertain situations.	UNIV CALIF LOS ANGELES, DEPT COMP SCI, LOS ANGELES, CA 90024 USA	University of California System; University of California Los Angeles	ISHIDA, T (corresponding author), KYOTO UNIV, DEPT INFORMAT SCI, KYOTO 60601, JAPAN.		Ishida, Toru/H-5553-2017; Ishida, Toru/AAI-2102-2020	Ishida, Toru/0000-0002-0479-4990; Ishida, Toru/0000-0002-0479-4990				Bratman M. E., 1988, Computational Intelligence, V4, P349, DOI 10.1111/j.1467-8640.1988.tb00284.x; BROWN SS, 1980, OPER RES, V28, P1275, DOI 10.1287/opre.28.6.1275; COHEN PR, 1990, ARTIFICIAL INTELLIGE, V42; Dean T., 1988, AAAI 88. Seventh National Conference on Artificial Intelligence, P49; DOBBIE JM, 1974, OPER RES, V22, P79, DOI 10.1287/opre.22.1.79; Durfee E. H., 1988, AAAI 88. Seventh National Conference on Artificial Intelligence, P66; EAGLE JN, 1990, OPER RES, V38, P110, DOI 10.1287/opre.38.1.110; GEORGEFF MP, 1987, AAAI, P677; HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136; ISHIDA T, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P525; ISHIDA T, 1991, IJCAI 91, P204; KINNY DN, 1991, IJCAI 91, P82; KORF RE, 1990, ARTIF INTELL, V42, P189, DOI 10.1016/0004-3702(90)90054-4; Pearl J., 1984, INTELLIGENT SEARCH S; Pollack M. E., 1990, AAAI-90 Proceedings. Eighth National Conference on Artificial Intelligence, P183; Russell Stuart, 1991, DO RIGHT THING; TIERNEY L, 1983, OPER RES, V31, P720, DOI 10.1287/opre.31.4.720; WASHBURN AR, 1983, OPER RES, V31, P739, DOI 10.1287/opre.31.4.739	18	54	63	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					609	619		10.1109/34.387507	http://dx.doi.org/10.1109/34.387507			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QZ940					2022-12-18	WOS:A1995QZ94000006
J	POSTAIRE, JG; ZHANG, RD; LECOCQBOTTE, C				POSTAIRE, JG; ZHANG, RD; LECOCQBOTTE, C			CLUSTER-ANALYSIS BY BINARY MORPHOLOGY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						BINARY MORPHOLOGY; CLUSTER ANALYSIS; DILATION; EROSION; UNSUPERVISED CLASSIFICATION		A new approach to unsupervised pattern classification, which is based on the use of mathematical morphology operations, is developed. The way a set of multidimensional observations can be represented as a mathematical discrete binary set is shown. Clusters are then detected as well separated subsets by means of binary morphological transformations.			POSTAIRE, JG (corresponding author), UNIV LILLE 1,CTR AUTOMAT,F-59655 VILLENEUVE DASCQ,FRANCE.							BALL GH, 1965, AD699616; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; Duda R.O., 1973, J ROYAL STAT SOC SER; DYNOC JTT, 1979, INT J COMPUT INF SCI, V8, P541; Golder P., 1973, APPLIED STATISTICS, V22, P213; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; MacQueen J., 1967, P 5 BERK S MATH STAT, P281; MATHERON G, 1985, RANDOM SETS INTEGRAL; Minkowski H, 1903, MATH ANN, V57, P447, DOI 10.1007/BF01445180; NARENDRA PM, 1978, P IEEE C PATT RECOGN; POSTAIRE JG, 1981, IEEE T PATTERN ANAL, V3, P163, DOI 10.1109/TPAMI.1981.4767074; POSTAIRE JG, 1985, FOREST SCI, V31, P53; Serra J, 1982, IMAGE ANAL MATH MORP; TOUZANI A, 1988, IEEE T PATTERN ANAL, V10, P970, DOI 10.1109/34.9120	16	54	66	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					170	180		10.1109/34.192490	http://dx.doi.org/10.1109/34.192490			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KL910					2022-12-18	WOS:A1993KL91000009
J	ARCELLI, C; DIBAJA, GS				ARCELLI, C; DIBAJA, GS			A ONE-PASS 2-OPERATION PROCESS TO DETECT THE SKELETAL PIXELS ON THE 4-DISTANCE TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											ARCELLI, C (corresponding author), CNR,IST CIBERNET,I-80072 ARCO FELICE,ITALY.			Sanniti di Baja, Gabriella/0000-0003-2218-0412				ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P463, DOI 10.1109/TPAMI.1985.4767685; ARCELLI C, 1987, PATTERN RECOGN LETT, V6, P245, DOI 10.1016/0167-8655(87)90084-5; ARCELLI C, 1978, IEEE T SYST MAN CYB, V8, P139; Arcelli C., 1986, Image Analysis and Processing. Proceedings of the Third International Conference, P137; ARCELLI C, 1981, COMPUT VISION GRAPH, V17, P130, DOI 10.1016/0146-664X(81)90021-6; Dorst L., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P286; LEVINE MD, 1985, VISION MAN MACHINE, pCH10; PAVLIDIS T, 1980, COMPUT VISION GRAPH, V13, P142, DOI 10.1016/S0146-664X(80)80037-2; ROSENFEL.A, 1966, J ACM, V13, P471; Suzuki S., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P289; TORIWAKI J, 1981, PROGR PATTERN RECOGN, V1, P187; Yokoi S., 1975, COMPUT GRAPHICS IMAG, V4, P63, DOI DOI 10.1016/0146-664X(75)90022-2	12	54	62	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1989	11	4					411	414		10.1109/34.19037	http://dx.doi.org/10.1109/34.19037			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T9100					2022-12-18	WOS:A1989T910000006
J	CHANG, SK; LIU, SH				CHANG, SK; LIU, SH			PICTURE INDEXING AND ABSTRACTION TECHNIQUES FOR PICTORIAL DATABASES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CALIF BERKELEY,DEPT ELECT ENGN & COMP SCI,BERKELEY,CA 94720	University of California System; University of California Berkeley	CHANG, SK (corresponding author), IIT,DEPT ELECT & COMP ENGN,INFORMAT SYST LAB,CHICAGO,IL 60616, USA.							BANERJI RB, 1980, INT J POLICY ANA JUN, P202; BITNER JR, 1979, SIAM J COMPUT, V8, P104; Brown F., 1979, SCH PSYCHOL DIGEST, V8, P37; CHANG NS, 1978, TREE7928 PURD U DEP; CHANG SK, 1980, IEEE T SOFTWARE ENG, V6, P205, DOI 10.1109/TSE.1980.230471; CHANG SK, 1983, NOV P IEEE WORKSH LA, P78; CHANG SK, 1979, P NAT COMPUT C AFIPS, V48, P147; CHANG SK, 1982, JUN P INT C PATT REC, P422; CHANG SK, 1978, INT J POL ANAL INF S, V1, P49; CHIEN YT, 1980, PICTORIAL INFORMATIO; DATE CJ, 1979, INTRO DATABASE SYSTE; DIETTERICH TG, 1981, ARTIFICIAL INTELL, V16, P262; FAGIN R, 1980, RJ2900 REP, P7; FISHMAN DH, 1975, ARTIFICIAL INTELL, V6, P102; GOTLIEB L, 1981, SIAM J COMPUT, V10, P422, DOI 10.1137/0210031; HAYESROTH F, 1978, COMMUN ACM, V21, P401, DOI 10.1145/359488.359503; KING JJ, 1981, STANCS81857 STANF U; LIU SH, 1981, NOV P IEEE WORKSH CO; MAIER D, 1979, SIAM J COMPUT, V8, P599, DOI 10.1137/0208048; MCKEOWN DJ, 1977, APR P WORKSH PICT DA, P40; MENDELSON E, 1979, INTRO MATH LOGIC, P59; MICHALSKI RS, 1980, INT J POLICY ANA DEC, P128; Minker J., 1978, Logic and data bases, P107; POWELL PB, 1978, P NAT C ACM, P585; REITER R, 1978, LOGIC DATA BASES, P150; REUSS JL, 1978, MAY P IEEE COMP SOC, P69; ROGERS R, 1971, MATH LOGIC FORMALIZE, P99; SHAPIRO LG, 1979, CS79005R VIRG POL I, P35; Smith J. M., 1977, ACM Transactions on Database Systems, V2, P105, DOI 10.1145/320544.320546; STEEN SWP, 1972, MATH LOGIC, P115; Tanimoto S.L, 1976, PATTERN RECOGN, P452; VERE SA, 1975, 4TH P INT JOINT C AR, P281; YAMAGUCHI K, SOFTWARE ENG SERIES, V3, P199; ZADEH LA, 1979, MACHINE INTELLIGENCE, V9, P172; ZAISHNAVI VK, 1980, ACTA INFORMAT, V14, P119; [No title captured]	36	54	58	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					475	484		10.1109/TPAMI.1984.4767552	http://dx.doi.org/10.1109/TPAMI.1984.4767552			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	SY289	21869215				2022-12-18	WOS:A1984SY28900008
J	SMITH, SP; JAIN, AK				SMITH, SP; JAIN, AK			TESTING FOR UNIFORMITY IN MULTIDIMENSIONAL DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824	Michigan State University								BENTLEY JL, 1978, J ACM, V25, P536, DOI 10.1145/322092.322095; BISWAS G, 1981, IEEE T PATTERN ANAL, V3, P701, DOI 10.1109/TPAMI.1981.4767175; CHAND DR, 1970, J ACM, V17, P78, DOI 10.1145/321556.321564; CROSS GR, 1982, P IFAC S DIGITAL CON, P24; DUBES R, 1980, ADV COMPUT, V19, P113; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; FUKUNAGA K, 1972, INTRO STATISTICAL PA; Knuth D. E., 1981, ART COMPUTER PROGRAM, V2; PANAYIRCI E, 1981, TR8104 MICH STAT U D; Ripley B. D., 1981, SPAT STAT-NETH; RIPLEY BD, 1977, J APPL PROBAB, V14, P483, DOI 10.2307/3213451; SMITH S, 1982, THESIS MICHIGAN STAT; YOUNG DL, 1982, BIOMETRIKA, V69, P477, DOI 10.1093/biomet/69.2.477	13	54	56	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	1					73	81		10.1109/TPAMI.1984.4767477	http://dx.doi.org/10.1109/TPAMI.1984.4767477			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	SB213	21869167				2022-12-18	WOS:A1984SB21300008
J	MACHUCA, R; PHILLIPS, K				MACHUCA, R; PHILLIPS, K			APPLICATIONS OF VECTOR-FIELDS TO IMAGE-PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NEW MEXICO STATE UNIV,DEPT MATH,LAS CRUCES,NM 88003	New Mexico State University	MACHUCA, R (corresponding author), USA,WHITE SANDS MISSILE RANGE,NM 88002, USA.							[Anonymous], 1978, COURSE DIFFERENTIAL; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; KITCHEN L, 1980, TR887 U MAR COMP SCI; LLOYD N. G., 1978, DEGREE THEORY, V73; MACHUCA R, 1981, IEEE T PATTERN ANAL, V3, P102; Milnor J. W., 1965, TOPOLOGY DIFFERENTIA; ROBINSON G, 1976, AUG P SPIE S ADV IM, V87; ROSENFELD A, 1971, IEEE T COMPUT, V20, P552; SPIVAK M, 1970, DIFFERENTIAL GEOMETR, V2; WINSTON HW, ANAL INTENSITY ARRAY, pCH3	11	54	60	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	3					316	329		10.1109/TPAMI.1983.4767393	http://dx.doi.org/10.1109/TPAMI.1983.4767393			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QS785	21869114				2022-12-18	WOS:A1983QS78500006
J	Tellez, D; Litjens, G; van der Laak, J; Ciompi, F				Tellez, David; Litjens, Geert; van der Laak, Jeroen; Ciompi, Francesco			Neural Image Compression for Gigapixel Histopathology Image Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image coding; Training; Image reconstruction; Image analysis; Neural networks; Visualization; Task analysis; Gigapixel image analysis; computational pathology; convolutional neural networks; representation learning		We propose Neural Image Compression (NIC), a two-step method to build convolutional neural networks for gigapixel image analysis solely using weak image-level labels. First, gigapixel images are compressed using a neural network trained in an unsupervised fashion, retaining high-level information while suppressing pixel-level noise. Second, a convolutional neural network (CNN) is trained on these compressed image representations to predict image-level labels, avoiding the need for fine-grained manual annotations. We compared several encoding strategies, namely reconstruction error minimization, contrastive training and adversarial feature learning, and evaluated NIC on a synthetic task and two public histopathology datasets. We found that NIC can exploit visual cues associated with image-level labels successfully, integrating both global and local visual information. Furthermore, we visualized the regions of the input gigapixel images where the CNN attended to, and confirmed that they overlapped with annotations from human experts.	[Tellez, David; Litjens, Geert; van der Laak, Jeroen; Ciompi, Francesco] Radboud Univ Nijmegen, Dept Pathol, Diagnost Image Anal Grp, Med Ctr, NL-6500 HB Nijmegen, Netherlands	Radboud University Nijmegen	Tellez, D (corresponding author), Radboud Univ Nijmegen, Dept Pathol, Diagnost Image Anal Grp, Med Ctr, NL-6500 HB Nijmegen, Netherlands.	david.tellezm@gmail.com; Geert.Litjens@radboudumc.nl; Jeroen.vanderlaak@radboudumc.nl; francesco.ciompi@radboudumc.nl	Litjens, Geert JS/A-2319-2016; Ciompi, Francesco/P-5598-2015; van der Laak, Jeroen AWM/D-3057-2015	Litjens, Geert JS/0000-0003-1554-1291; Ciompi, Francesco/0000-0001-8327-9606; van der Laak, Jeroen AWM/0000-0001-7982-0754	Junior Researcher grant from the Radboud Institute of Health Sciences (RIHS), Nijmegen, The Netherlands; Dutch Cancer Society [KUN 2015-7970]; Dutch Cancer Society; Alpe d'HuZes fund [KUN 2014-7032]; European Union's Horizon 2020 research and innovation programme [825292]	Junior Researcher grant from the Radboud Institute of Health Sciences (RIHS), Nijmegen, The Netherlands(Netherlands Government); Dutch Cancer Society(KWF Kankerbestrijding); Dutch Cancer Society(KWF Kankerbestrijding); Alpe d'HuZes fund; European Union's Horizon 2020 research and innovation programme	This study was supported by a Junior Researcher grant from the Radboud Institute of Health Sciences (RIHS), Nijmegen, The Netherlands; a grant from the Dutch Cancer Society (KUN 2015-7970); and another grant from the Dutch Cancer Society and the Alpe d'HuZes fund (KUN 2014-7032); this project has also been partially funded by the European Union's Horizon 2020 research and innovation programme under grant agreement No 825292. The authors would like to thank Dr. Mitko Veta for evaluating our predictions in the test set of the TUPAC16 dataset, and the developers of Keras [45], the open source tool that we used to run our deep learning experiments.	Anavi Y, 2015, IEEE ENG MED BIO, P2940, DOI 10.1109/EMBC.2015.7319008; Bandi P, 2017, I S BIOMED IMAGING, P591, DOI 10.1109/ISBI.2017.7950590; Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585; Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9; Chen Tianqi, 2016, TRAINING DEEP NETS S, V6, P6; Chen X, 2016, ADV NEUR IN, V29; Chollet F., 2015, KERAS; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Ciompi F, 2017, I S BIOMED IMAGING, P160, DOI 10.1109/ISBI.2017.7950492; Combalia M., 2018, MED IMAG DEEP LEARN; Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5; Donahue Jeff, 2017, INT C LEARN REPR ICL; Dumoulin Vincent, 2017, ICLR 2017, P4; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P321; Hasan Sadid A., 2018, CLEF2018 WORKING NOT; Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266; Ilse M, 2018, PR MACH LEARN RES, V80; Jetley Saumya, 2018, INT C LEARN REPR; Kingma D. P., 2013, AUTO ENCODING VARIAT; Koch G., 2015, ICML DEEP LEARNING W; Kong J, 2007, I S BIOMED IMAGING, P61, DOI 10.1109/ISBI.2007.356788; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Melekhov I, 2016, INT C PATT RECOG, P378, DOI 10.1109/ICPR.2016.7899663; Nielsen TO, 2010, CLIN CANCER RES, V16, P5222, DOI 10.1158/1078-0432.CCR-10-1282; Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Sertel O, 2009, PATTERN RECOGN, V42, P1093, DOI 10.1016/j.patcog.2008.08.027; Shin HC, 2016, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2016.274; Sirinukunwattana K, 2017, MED IMAGE ANAL, V35, P489, DOI 10.1016/j.media.2016.08.008; Tabesh A, 2007, IEEE T MED IMAGING, V26, P1366, DOI 10.1109/TMI.2007.898536; Tellez D., 2018, C MED IMAGING DEEP L; Tellez D, 2018, IEEE T MED IMAGING, V37, P2126, DOI 10.1109/TMI.2018.2820199; Theis Lucas, 2017, INT C LEARN REPR; Tomczak JM, 2018, P 1 C MED IM DEEP LE, P1; van den Oord A, 2017, ADV NEUR IN, V30; van den Oord Aaron, 2018, ARXIV180703748; Veta M, 2019, MED IMAGE ANAL, V54, P111, DOI 10.1016/j.media.2019.02.012; Wang X., 2018, MED IMAG DEEP LEARN; Weinstein JN, 2013, NAT GENET, V45, P1113, DOI 10.1038/ng.2764; Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462; Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798	45	53	55	5	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					567	578		10.1109/TPAMI.2019.2936841	http://dx.doi.org/10.1109/TPAMI.2019.2936841			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31442971	Green Submitted			2022-12-18	WOS:000607383300012
J	Zhao, J; Xiong, L; Li, JS; Xing, JL; Yan, SC; Feng, JS				Zhao, Jian; Xiong, Lin; Li, Jianshu; Xing, Junliang; Yan, Shuicheng; Feng, Jiashi			3D-Aided Dual-Agent GANs for Unconstrained Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face synthesis; unconstrained face recognition; 3D face model; generative adversarial networks		Synthesizing realistic profile faces is beneficial for more efficiently training deep pose-invariant models for large-scale unconstrained face recognition, by augmenting the number of samples with extreme poses and avoiding costly annotation work. However, learning from synthetic faces may not achieve the desired performance due to the discrepancy betwedistributions of the synthetic and real face images. To narrow this gap, we propose a Dual-Agent Generative Adversarial Network (DA-GAN) model, which can improve the realism of a face simulator's output using unlabeled real faces while preserving the identity information during the realism refinement. The dual agents are specially designed for distinguishing real versus fake and identities simultaneously. In particular, we employ an off-the-shelf 3D face model as a simulator to generate profile face images with varying poses. DA-GAN leverages a fully convolutional network as the generator to generate high-resolution images and an auto-encoder as the discriminator with the dual agents. Besides the novel architecture, we make several key modifications to the standard GAN to preserve pose, texture as well as identity, and stabilize the training process: (i) a pose perception loss; (ii) an identity perception loss; (iii) an adversarial loss with a boundary equilibrium regularization term. Experimental results show that DA-GAN not only achieves outstanding perceptual results but also significantly outperforms state-of-the-arts on the large-scale and challenging NIST IJB-A and CFP unconstrained face recognition benchmarks. In addition, the proposed DA-GAN is also a promising new approach for solving generic transfer learning problems more effectively. DA-GAN is the foundation of our winning entry to the NIST IJB-A face recognition competition in which we secured the 1st places on the tracks of verification and identification.	[Zhao, Jian; Yan, Shuicheng; Feng, Jiashi] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Zhao, Jian] Natl Univ Def Technol, Sch Comp, Changsha 410073, Hunan, Peoples R China; [Xiong, Lin] Panasonic R&D Ctr Singapore, Core Technol Grp, Learning & Vis, Singapore 469332, Singapore; [Li, Jianshu] Natl Univ Singapore, Sch Comp, Singapore 119077, Singapore; [Xing, Junliang] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China; [Yan, Shuicheng] Qihoo 360 AI Inst, Beijing 100015, Peoples R China	National University of Singapore; National University of Defense Technology - China; Panasonic; National University of Singapore; Chinese Academy of Sciences; Institute of Automation, CAS	Zhao, J (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore.	zhaojian90@u.nus.edu; lin.xiong@sg.panasonic.com; jianshu@u.nus.edu; jlxing@nlpr.ia.ac.cn; eleyans@nus.edu.sg; elefjia@nus.edu.sg	Xing, Junliang/HGE-9630-2022; Feng, Jiashi/AGX-6209-2022; Yan, Shuicheng/HCI-1431-2022	Xing, Junliang/0000-0001-6801-0510; Zhao, Jian/0000-0002-3508-756X; Li, Jianshu/0000-0001-8554-6886; Xiong, Lin/0000-0003-3545-227X	China Scholarship Council (CSC) [201503170248]; National Science Foundation of Chian [61672519]; National University of Singapore [R-263-000-C08-133, MOE Tier-I R-263-000-C21-112, NUS IDS R-263-000-C67-646, ECRA R-263-000-C87-133]	China Scholarship Council (CSC)(China Scholarship Council); National Science Foundation of Chian; National University of Singapore(National University of Singapore)	Jian Zhao's research was partially supported by China Scholarship Council (CSC) grant 201503170248. Junliang Xing's research was partially supported by the National Science Foundation of Chian 61672519. Jiashi Feng's research was partially supported by National University of Singapore startup R-263-000-C08-133, MOE Tier-I R-263-000-C21-112, NUS IDS R-263-000-C67-646 and ECRA R-263-000-C87-133. The authors would like to thank Yu Cheng (Nanyang Technological University), Yi Cheng, Yan Xu, Jayashree Karlekar, Sugiri Pranata and Shengmei Shen (Core Technology Group, Learning & Vision, Panasonic R&D Center Singapore) for helpful discussions. Jian Zhao and Lin Xiong make equal contributions. Jian Zhao was an intern at Panasonic R&D Center Singapore during this work. Jian Zhao is the corresponding author. Homepage: https://zhaoj9014.github.io/.	Abdalmageed W., 2016, CORR, P1, DOI DOI 10.1109/WACV.2016.7477555; Ahmed N, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1, DOI 10.1145/2968219.2971457; Berthelot D., 2017, BEGAN BOUNDARY EQUIL, DOI DOI 10.48550/ARXIV.1703.10717; Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020; Chen J, 2015, IEEE ICC, P1801, DOI 10.1109/ICC.2015.7248586; Chen JC, 2016, IEEE WINT CONF APPL; Chen JC, 2018, INT J COMPUT VISION, V126, P272, DOI 10.1007/s11263-017-1029-3; Chen JC, 2016, IEEE IMAGE PROC, P2981, DOI 10.1109/ICIP.2016.7532906; Chollet F., 2015, KERAS; Crosswhite N, 2017, IEEE INT CONF AUTOMA, P1, DOI 10.1109/FG.2017.11; Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6; HASSNER T, 2015, PROC CVPR IEEE, P4295, DOI DOI 10.1109/CVPR.2015.7299058; Hassner T., 2016, P IEEE C COMP VIS PA, P59; Hayat M., 2017, P IEEE C COMP VIS PA, P2767; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267; Kasabov N, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P15, DOI 10.1109/IS.2016.7737434; Kingma D. P., 2013, AUTO ENCODING VARIAT; Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803; Li JS, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1531, DOI 10.1145/3123266.3123438; Li JH, 2016, P IEEE RAS-EMBS INT, P1068, DOI 10.1109/BIOROB.2016.7523773; Liu L., 2018, ARXIV180110324; Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032; Liu L, 2014, IEEE IMAGE PROC, P718, DOI 10.1109/ICIP.2014.7025144; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523; Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35; Mirza M., 2014, ARXIV; Odena A., 2016, SEMISUPERVISED LEARN; Parkhi Omkar M., 2015, BRIT MACH VIS C; Ranjan R., 2017, ARXIV PREPRINT ARXIV; Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137; Rezende Danilo Jimenez, 2014, P 31 INT C INT C MAC; Sagonas C, 2015, IEEE I CONF COMP VIS, P3871, DOI 10.1109/ICCV.2015.441; Sankaranarayanan S., 2016, P IEEE INT C BIOMETR, P1; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang D., 2015, ICB, V4; Xiangyu Zhu, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163096; Xiao S., 2016, ACM MM, P691; Xiao ST, 2016, LECT NOTES COMPUT SC, V9905, P57, DOI 10.1007/978-3-319-46448-0_4; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667; Yin X., 2017, IEEE T IMAGE PROCESS; Yin XX, 2017, HEALTH INFOR SCI, P1, DOI 10.1007/978-3-319-57027-3_1; Zhao QC, 2017, IEEE CONF IMAGING SY, P65; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679	57	53	54	1	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2380	2394		10.1109/TPAMI.2018.2858819	http://dx.doi.org/10.1109/TPAMI.2018.2858819			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30040629				2022-12-18	WOS:000489763000008
J	Wu, GC; Liu, YB; Fang, L; Dai, QH; Chai, TY				Wu, Gaochang; Liu, Yebin; Fang, Lu; Dai, Qionghai; Chai, Tianyou			Light Field Reconstruction Using Convolutional Network on EPI and Extended Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Light field reconstruction; convolutional neural network; epipolar plane image; depth assisted rendering		In this paper, a novel convolutional neural network (CNN)-based framework is developed for light field reconstruction from a sparse set of views. We indicate that the reconstruction can be efficiently modeled as angular restoration on an epipolar plane image (EPI). The main problem in direct reconstruction on the EPI involves an information asymmetry between the spatial and angular dimensions, where the detailed portion in the angular dimensions is damaged by undersampling. Directly upsampling or super-resolving the light field in the angular dimensions causes ghosting effects. To suppress these ghosting effects, we contribute a novel "blur-restoration-deblur" framework. First, the "blur" step is applied to extract the low-frequency components of the light field in the spatial dimensions by convolving each EPI slice with a selected blur kernel. Then, the "restoration" step is implemented by a CNN, which is trained to restore the angular details of the EPI. Finally, we use a non-blind "deblur" operation to recover the spatial high frequencies suppressed by the EPI blur. We evaluate our approach on several datasets, including synthetic scenes, real-world scenes and challenging microscope light field data. We demonstrate the high performance and robustness of the proposed framework compared with state-of-the-art algorithms. We further show extended applications, including depth enhancement and interpolation for unstructured input. More importantly, a novel rendering approach is presented by combining the proposed framework and depth information to handle large disparities.	[Wu, Gaochang; Chai, Tianyou] Northeastern Univ, State Key Lab Synthet Automat Proc Ind, Shenyang 110819, Liaoning, Peoples R China; [Liu, Yebin; Dai, Qionghai] Tsinghua Univ, Dept Automat, Broadband Network & Digital Media Lab, Beijing 100084, Peoples R China; [Fang, Lu] Tsinghua Berkeley Shenzhen Inst, Shenzhen 518055, Peoples R China	Northeastern University - China; Tsinghua University	Liu, YB (corresponding author), Tsinghua Univ, Dept Automat, Broadband Network & Digital Media Lab, Beijing 100084, Peoples R China.; Fang, L (corresponding author), Tsinghua Berkeley Shenzhen Inst, Shenzhen 518055, Peoples R China.	ahwgc2009@163.com; liuyebin@tsinghua.edu.cn; fanglu@sz.tsinghua.edu.cn; qionghaida@tsinghua.edu.cn; tychai@mail.neu.edu.cn	Wu, Gaochang/X-1777-2019; Dai, Qionghai/ABD-5298-2021	Wu, Gaochang/0000-0002-5149-2995; Dai, Qionghai/0000-0001-7043-3061	National key foundation for exploring scientific instrument [2013YQ140517]; NSF of China emergency management project [61550002]; NSF of China [61522111, 61531014, 61673095, 61722209, 61331015]	National key foundation for exploring scientific instrument; NSF of China emergency management project; NSF of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National key foundation for exploring scientific instrument No. 2013YQ140517, the NSF of China emergency management project No. 61550002, the NSF of China grant No. 61522111, No. 61531014, No. 61673095, No. 61722209 and No. 61331015.	Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168; Boominathan V., 2014, ICCP, P1; CHAI JX, COMP GRAPH, P307; Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238; Cho D, 2013, IEEE I CONF COMP VIS, P3280, DOI 10.1109/ICCV.2013.407; Davis A, 2012, COMPUT GRAPH FORUM, V31, P305, DOI 10.1111/j.1467-8659.2012.03009.x; Didyk P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508376; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Eigen David, 2014, NEURIPS; Flynn J., 2015, P IEEE C COMP VIS PA, P5515; Guo XQ, 2016, IEEE T VIS COMPUT GR, V22, P1852, DOI 10.1109/TVCG.2015.2476805; Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156; Ihrke I, 2016, IEEE SIGNAL PROC MAG, V33, P59, DOI 10.1109/MSP.2016.2582220; Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251; Kauvar I, 2015, ACM T GRAPHIC, V34, DOI [10.1145/2682631, 10.1145/2816795.2818070]; Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Krishnan D., 2009, ADV NEURAL INFORM PR, V22, P1033; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Levoy M, 2006, ACM T GRAPHIC, V25, P924, DOI 10.1145/1141911.1141976; Li JQ, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440760; Liang CC, 2015, ADV MATER INTERFACES, V2, DOI 10.1002/admi.201500030; Lin X, 2015, BIOMED OPT EXPRESS, V6, P3179, DOI 10.1364/BOE.6.003179; Lin ZC, 2004, INT J COMPUT VISION, V58, P121, DOI 10.1023/B:VISI.0000015916.91741.27; Meyer S, 2015, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2015.7298747; Pujades S, 2014, PROC CVPR IEEE, P3906, DOI 10.1109/CVPR.2014.499; Riechert C., 2012, BEST ET IBC, P8; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Stewart J., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P150; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Vagharshakyan S, 2015, IEEE IMAGE PROC, P1379, DOI 10.1109/ICIP.2015.7351026; Wang HM, 2007, IEEE T VIS COMPUT GR, V13, P697, DOI 10.1109/TVCG.2007.1019; Wang TC, 2016, LECT NOTES COMPUT SC, V9907, P121, DOI 10.1007/978-3-319-46487-9_8; Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398; Wang Z, 2003, CONF REC ASILOMAR C, P1398; Wanner S., 2013, VISION MODELING VISU, P225, DOI DOI 10.2312/PE.VMV.VMV13.225-226; Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147; Wilburn B., 2005, ACM T GRAPHIC, V24, P3, DOI DOI 10.1145/1073204.1073259; Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178; Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126; Xiao ZL, 2014, PROC CVPR IEEE, P3326, DOI 10.1109/CVPR.2014.425; Yang J, 2008, PROC CVPR IEEE, P173; Yoon Y., 2015, P IEEE INT C COMP VI, P24; Yucer K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2876504; Zhang FL, 2017, IEEE T VIS COMPUT GR, V23, P1561, DOI 10.1109/TVCG.2016.2532329; Zhang ZT, 2015, PROC CVPR IEEE, P3800, DOI 10.1109/CVPR.2015.7299004	52	53	56	6	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1681	1694		10.1109/TPAMI.2018.2845393	http://dx.doi.org/10.1109/TPAMI.2018.2845393			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29994195	Green Submitted			2022-12-18	WOS:000470972300012
J	Luo, Y; Wen, YG; Liu, TL; Tao, DC				Luo, Yong; Wen, Yonggang; Liu, Tongliang; Tao, Dacheng			Transferring Knowledge Fragments for Learning Distance Metric from a Heterogeneous Domain	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Transfer learning; distance metric learning; heterogeneous domains; knowledge fragments; nonlinear	FRAMEWORK	The goal of transfer learning is to improve the performance of target learning task by leveraging information (or transferring knowledge) from other related tasks. In this paper, we examine the problem of transfer distance metric learning (DML), which usually aims to mitigate the label information deficiency issue in the target DML. Most of the current Transfer DML (TDML) methods are not applicable to the scenario where data are drawn from heterogeneous domains. Some existing heterogeneous transfer learning (HTL) approaches can learn target distance metric by usually transforming the samples of source and target domain into a common subspace. However, these approaches lack flexibility in real-world applications, and the learned transformations are often restricted to be linear. This motivates us to develop a general flexible heterogeneous TDML (HTDML) framework. In particular, any (linear/nonlinear) DML algorithms can be employed to learn the source metric beforehand. Then the pre-learned source metric is represented as a set of knowledge fragments to help target metric learning. We show how generalization error in the target domain could be reduced using the proposed transfer strategy, and develop novel algorithm to learn either linear or nonlinear target metric. Extensive experiments on various applications demonstrate the effectiveness of the proposed method.	[Luo, Yong; Wen, Yonggang] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore; [Liu, Tongliang; Tao, Dacheng] Univ Sydney, UBTECH Sydney Artificial Intelligence Ctr, Fac Engn & Informat Technol, 6 Cleveland St, Darlington, NSW 2008, Australia; [Liu, Tongliang; Tao, Dacheng] Univ Sydney, Sch Informat Technol, Fac Engn & Informat Technol, 6 Cleveland St, Darlington, NSW 2008, Australia	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Sydney; University of Sydney	Luo, Y (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.	yluo180@gmail.com; ygwen@ntu.edu.sg; tongliang.liu@sydney.edu.au; dacheng.tao@sydney.edu.au	Liu, Tongliang/AAA-1506-2021; Wen, Yonggang/P-9406-2017	Liu, Tongliang/0000-0002-9640-6472; Wen, Yonggang/0000-0002-2751-5114	Australian Research Council [FL-170100117, DP-180103424, DP-140102164];  [NRF2015ENC-GDCR01001-003];  [NRF2015ENC-GBICRD001-012]	Australian Research Council(Australian Research Council); ; 	The authors would like to thank the handling associate editor and all the anonymous reviewers for their constructive comments. This research was supported in part by Singapore NRF2015ENC-GDCR01001-003, administrated via IMDA, NRF2015ENC-GBICRD001-012, administrated via BCA, DSAIR@NTU, and Australian Research Council Projects FL-170100117, DP-180103424, and DP-140102164.	[Anonymous], 2012, ADV NEURAL INF PROCE; Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Bellet A, 2014, ARXIV13066709V4; BOUCHERON S., 2013, CONCENTRATION INEQUA, DOI [10.1093/acprof:oso/9780199535255.001.0001, DOI 10.1093/ACPROF:OSO/9780199535255.001.0001]; Chatfield K., 2014, ARXIV14053531V4; Chatpatanasiri R, 2010, NEUROCOMPUTING, V73, P1570, DOI 10.1016/j.neucom.2009.11.037; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Dai DX, 2015, PROC CVPR IEEE, P3527, DOI 10.1109/CVPR.2015.7298975; Fei-Fei L., 2004, P IEEE C COMP VIS PA; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Goldberger J., 2004, ADV NEURAL INF PROCE, P1; Hu JL, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629; Huang G.B., 2008, WORKSHOP FACESREAL L; Jin R., 2009, ADV NEURAL INFORM PR, V22; Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Ledoux M., 2013, PROBABILITY BANACH S, P86; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Lim DKH, 2014, PR MACH LEARN RES, V32, P1980; Lin CJ, 2007, NEURAL COMPUT, V19, P2756, DOI 10.1162/neco.2007.19.10.2756; Liu TL, 2017, IEEE T PATTERN ANAL, V39, P227, DOI 10.1109/TPAMI.2016.2544314; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo Y, 2018, IEEE T NEUR NET LEAR, V29, P4051, DOI 10.1109/TNNLS.2017.2750321; Luo Y, 2014, IEEE T IMAGE PROCESS, V23, P3789, DOI 10.1109/TIP.2014.2332398; Mahadevan, 2011, IJCAI, V22, P1541, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-259; Mohammad Norouzi, 2012, ADV NEURAL INFORM PR, P1061; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Qi G. -J., 2012, P SIAM INT C DAT MIN, P528, DOI DOI 10.1137/1.9781611972825.46; Russell S. J, 2002, ADV NEURAL INFORM PR, P12, DOI DOI 10.5555/2968618.2968683; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002; Tianyi Zhou, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P679, DOI 10.1109/ICDM.2010.135; Tyree S., 2011, P 20 INT C WORLD WID, P387, DOI DOI 10.1145/1963405.1963461; Vapnik V, 2015, J MACH LEARN RES, V16, P2023; Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Xu Z., 2013, ARXIV12083422V2; Yang Q., 2017, IJCAI, P2365; Zhang Y., 2011, PROC 25 AAAI C ARTIF, P574	47	53	53	8	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					1013	1026		10.1109/TPAMI.2018.2824309	http://dx.doi.org/10.1109/TPAMI.2018.2824309			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29993977	Green Submitted, Green Accepted			2022-12-18	WOS:000460583500017
J	Armanfard, N; Reilly, JP; Komeili, M				Armanfard, Narges; Reilly, James P.; Komeili, Majid			Local Feature Selection for Data Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Local feature selection; classification; linear programming	FEATURE SUBSET-SELECTION; DIMENSIONALITY REDUCTION; ALGORITHMS; INFORMATION; EIGENMAPS	Typical feature selection methods choose an optimal global feature subset that is applied over all regions of the sample space. In contrast, in this paper we propose a novel localized feature selection (LFS) approach whereby each region of the sample space is associated with its own distinct optimized feature set, which may vary both in membership and size across the sample space. This allows the feature set to optimally adapt to local variations in the sample space. An associated method for measuring the similarities of a query datum to each of the respective classes is also proposed. The proposed method makes no assumptions about the underlying structure of the samples; hence the method is insensitive to the distribution of the data over the sample space. The method is efficiently formulated as a linear programming optimization problem. Furthermore, we demonstrate the method is robust against the over-fitting problem. Experimental results on eleven synthetic and real-world data sets demonstrate the viability of the formulation and the effectiveness of the proposed algorithm. In addition we show several examples where localized feature selection produces better results than a global feature selection method.	[Armanfard, Narges; Reilly, James P.] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada; [Komeili, Majid] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada	McMaster University; University of Toronto	Armanfard, N; Reilly, JP (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.; Komeili, M (corresponding author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.	armanfn@mcmaster.ca; reillyj@mcmaster.ca; mkomeili@ece.utoronto.ca	Reilly, James/AAT-9223-2021		Natural Sciences and Engineering Research Council of Canada (NSERC); MITACS	Natural Sciences and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC)); MITACS	The authors wish to acknowledge the financial support of the Natural Sciences and Engineering Research Council of Canada (NSERC) and MITACS.	Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; [Anonymous], 1979, MULTIPLE OBJECTIVE D; Armanfard N., 2013, P IEEE INT WORKSH MA, P1; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bellman R., 1962, APPL DYNAMIC PROGRAM; Boyd S, 2004, CONVEX OPTIMIZATION; Brown G, 2012, J MACH LEARN RES, V13, P27; Chen B, 2009, IEEE T KNOWL DATA EN, V21, P1475, DOI 10.1109/TKDE.2008.238; Cheng Y, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P93; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fodor I.K, 2002, NEOPLASIA; Gilad-Bachrach R., 2004, P 21 INT C MACH LEAR, P43; He XF, 2005, IEEE I CONF COMP VIS, P1208; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; John G., DNA DATASET STATLOG; Jolliffe I., 2011, INT ENCY STAT SCI; Kenji K, 1992, P 9 INT WORKSH MACH, P249, DOI DOI 10.1016/B978-1-55860-247-2.50037-1; Khushaba RN, 2011, EXPERT SYST APPL, V38, P11515, DOI 10.1016/j.eswa.2011.03.028; Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings, P171; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Langley, 1994, SELECTION RELEVANT F, P171; Lichman M, 2013, UCI MACHINE LEARNING; Liu B, 2013, PATTERN RECOGN, V46, P2798, DOI 10.1016/j.patcog.2013.02.012; Liu ZQ, 2011, BIOINFORMATICS, V27, P3242, DOI 10.1093/bioinformatics/btr547; Lui YM, 2008, LECT NOTES COMPUT SC, V5303, P44, DOI 10.1007/978-3-540-88688-4_4; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; Mavrotas G, 2009, APPL MATH COMPUT, V213, P455, DOI 10.1016/j.amc.2009.03.037; Nie F., 2010, ADV NEURAL INFORM PR, V2, P1813; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Souza A., 2001, LECT NOTES; Sun YJ, 2007, IEEE T PATTERN ANAL, V29, P1035, DOI 10.1109/TPAMI.2007.1093; Sun YJ, 2010, IEEE T PATTERN ANAL, V32, P1610, DOI 10.1109/TPAMI.2009.190; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Thai M. T., 2013, LECT NOTES; Ueda N., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P525, DOI 10.1109/NNSP.1999.788172; Wang L, 2008, IEEE T PATTERN ANAL, V30, P1534, DOI 10.1109/TPAMI.2007.70799; Webb A.R., 2003, STAT PATTERN RECOGNI; Wei HL, 2007, IEEE T PATTERN ANAL, V29, P162, DOI 10.1109/TPAMI.2007.250607; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Zeng H, 2011, IEEE T PATTERN ANAL, V33, P1532, DOI 10.1109/TPAMI.2010.215	44	53	57	0	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1217	1227		10.1109/TPAMI.2015.2478471	http://dx.doi.org/10.1109/TPAMI.2015.2478471			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26390448				2022-12-18	WOS:000375609000013
J	Wilson, RC; Hancock, ER; Pekalska, E; Duin, RPW				Wilson, Richard C.; Hancock, Edwin R.; Pekalska, Elzbieta; Duin, Robert P. W.			Spherical and Hyperbolic Embeddings of Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Embedding; non-euclidean; spherical; hyperbolic	NONLINEAR DIMENSIONALITY REDUCTION; GRAPH; RECOGNITION	Many computer vision and pattern recognition problems may be posed as the analysis of a set of dissimilarities between objects. For many types of data, these dissimilarities are not euclidean (i.e., they do not represent the distances between points in a euclidean space), and therefore cannot be isometrically embedded in a euclidean space. Examples include shape-dissimilarities, graph distances and mesh geodesic distances. In this paper, we provide a means of embedding such non-euclidean data onto surfaces of constant curvature. We aim to embed the data on a space whose radius of curvature is determined by the dissimilarity data. The space can be either of positive curvature (spherical) or of negative curvature (hyperbolic). We give an efficient method for solving the spherical and hyperbolic embedding problems on symmetric dissimilarity data. Our approach gives the radius of curvature and a method for approximating the objects as points on a hyperspherical manifold without optimisation. For objects which do not reside exactly on the manifold, we develop a optimisation-based procedure for approximate embedding on a hyperspherical manifold. We use the exponential map between the manifold and its local tangent space to solve the optimisation problem locally in the euclidean tangent space. This process is efficient enough to allow us to embed data sets of several thousand objects. We apply our method to a variety of data including time warping functions, shape similarities, graph similarity and gesture similarity data. In each case the embedding maintains the local structure of the data while placing the points in a metric space.	[Wilson, Richard C.; Hancock, Edwin R.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England; [Pekalska, Elzbieta] Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England; [Duin, Robert P. W.] Delft Univ Technol, Fac Elect Engn Math & Comp Sci, NL-2628 CJ Delft, Netherlands	University of York - UK; University of Manchester; Delft University of Technology	Wilson, RC (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.	wilson@cs.york.ac.uk; erh@cs.york.ac.uk; pekalska@cs.man.ac.uk; r.duin@ieee.org	Hancock, Edwin/O-7860-2014; Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028	EU [213250]; Royal Society Wolfson Research Merit Award	EU(European Commission); Royal Society Wolfson Research Merit Award(Royal Society of London)	The authors acknowledge financial support from the FET programme within the EU FP7, under the SIMBAD project (contract 213250). Edwin Hancock was also supported by a Royal Society Wolfson Research Merit Award.	Andreu G, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, P1341, DOI 10.1109/ICNN.1997.616230; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Brand  M., 2003, ADV NEURAL INFORM PR, P961, DOI DOI 10.1109/34.682189; Bronstein A.M., 2005, P IEEE INT C IM PROC, V3, P756; BUNKE H, 1993, PATTERN RECOGN, V26, P1797, DOI 10.1016/0031-3203(93)90177-X; Cox M. A. A., 2008, HDB DATA VISUALIZATI, P315; COX TF, 1991, COMMUN STAT THEORY, V20, P2943, DOI 10.1080/03610929108830679; De Leeuw J, 1977, RECENT DEV STAT, P133; De Leeuw J., 1980, MULTIVARIATE ANAL P, V5, P501; Duin R P, 2009, TECHNICAL REPORT; Elad A, 2005, LECT NOTES COMPUT SC, V3459, P443; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; GOLDFARB L, 1984, PATTERN RECOGN, V17, P575, DOI 10.1016/0031-3203(84)90056-6; Hubert L, 1997, BRIT J MATH STAT PSY, V50, P253; Krioukov D, 2010, PHYS REV E, V82, DOI 10.1103/PhysRevE.82.036106; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123; LINDMAN H, 1978, J MATH PSYCHOL, V17, P89, DOI 10.1016/0022-2496(78)90025-1; MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045; Pekalska E, 2005, DISSIMILARITY REPRES; Pekalska E, 2006, LECT NOTES COMPUT SC, V4109, P871; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Robles-Kelly A, 2007, PATTERN RECOGN, V40, P1042, DOI 10.1016/j.patcog.2006.05.031; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SCANNELL JW, 1995, J NEUROSCI, V15, P1463; Schoenberg IJ, 1937, ANN MATH, V38, P787, DOI 10.2307/1968835; Shavitt Y, 2008, IEEE ACM T NETWORK, V16, P25, DOI 10.1109/TNET.2007.899021; Shepard R. N., 1974, PYSCHOMETRIKA, V39; Srivastava A., 2007, IEEE C COMP VIS PATT, P1; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Torgerson W.S., 1958, THEORY METHODS SCALI; Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143; Xiao B, 2005, LECT NOTES COMPUT SC, V3617, P471, DOI 10.1007/11553595_58; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154	35	53	55	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2255	2269		10.1109/TPAMI.2014.2316836	http://dx.doi.org/10.1109/TPAMI.2014.2316836			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353065	Green Accepted			2022-12-18	WOS:000343702400011
J	Weinman, JJ; Butler, Z; Knoll, D; Feild, J				Weinman, Jerod J.; Butler, Zachary; Knoll, Dugan; Feild, Jacqueline			Toward Integrated Scene Text Reading	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene text recognition; cropped word recognition; character recognition; discriminative semi-Markov model; image binarization; skew detection; baseline estimation; text guidelines; word normalization; word segmentation	RECOGNITION; SEGMENTATION; EXTRACTION; MODEL	The growth in digital camera usage combined with a worldly abundance of text has translated to a rich new era for a classic problem of pattern recognition, reading. While traditional document processing often faces challenges such as unusual fonts, noise, and unconstrained lexicons, scene text reading amplifies these challenges and introduces new ones such as motion blur, curved layouts, perspective projection, and occlusion among others. Reading scene text is a complex problem involving many details that must be handled effectively for robust, accurate results. In this work, we describe and evaluate a reading system that combines several pieces, using probabilistic methods for coarsely binarizing a given text region, identifying baselines, and jointly performing word and character segmentation during the recognition process. By using scene context to recognize several words together in a line of text, our system gives state-of-the-art performance on three difficult benchmark data sets.	[Weinman, Jerod J.; Butler, Zachary; Knoll, Dugan] Grinnell Coll, Dept Comp Sci, Noyce Sci Ctr, Grinnell, IA 50112 USA; [Feild, Jacqueline] Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Weinman, JJ (corresponding author), Grinnell Coll, Dept Comp Sci, Noyce Sci Ctr, 1116 8th Ave, Grinnell, IA 50112 USA.	weinman@grinnell.edu; jfeild@cs.umass.edu			Grinnell College; US National Science Foundation	Grinnell College; US National Science Foundation(National Science Foundation (NSF))	The authors thank N. Howe, J. Jonkman, E. Learned-Miller, and C. Sutton for helpful conversations, the anonymous reviewers for feedback that improved the paper, A. Mishra for providing binarized word images, and C. Yi for the text detections. Messrs. Weinman, Butler, and Knoll gratefully acknowledge financial support from Grinnell College. Ms. Feild was supported by a US National Science Foundation Graduate Research Fellowship.	BENGIO Y, 1994, INT C PATT RECOG, P409, DOI 10.1109/ICPR.1994.576966; Caesar T., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P382, DOI 10.1109/ICDAR.1995.599018; Chao Zeng, 2012, Camera-Based Document Analysis and Recognition. 4th International Workshop, CBDAR 2011. Revised Selected Papers, P58, DOI 10.1007/978-3-642-29364-1_5; CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074; Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223; Chen XR, 2004, PROC CVPR IEEE, P366; Cho MS, 2011, PROC INT CONF DOC, P1034, DOI 10.1109/ICDAR.2011.209; Darnton Robert, 2008, NEW YORK REV BOOKS; Elagouni K., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P120, DOI 10.1109/DAS.2012.26; Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041; Feild J., 2012, UMCS2012021; Ferguson JD, 1980, P S APPL HIDD MARK M, P143; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Hull J. J., 1998, DOCUMENT ANAL SYSTEM, V2, P40, DOI DOI 10.1142/9789812797704_0003; Jacobs C, 2005, PROC INT CONF DOC, P695, DOI 10.1109/ICDAR.2005.233; Jing Zhang, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P308, DOI 10.1007/978-3-642-19309-5_24; Jung J, 2011, ETRI J, V33, P78, DOI 10.4218/etrij.11.1510.0029; Kita K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3183, DOI 10.1109/ICPR.2010.779; Koo HI, 2012, IEEE T IMAGE PROCESS, V21, P1169, DOI 10.1109/TIP.2011.2166972; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Yann, 2006, PREDICTING STRUCTURE, P2; Liu CL, 2002, IEEE T PATTERN ANAL, V24, P1425, DOI 10.1109/TPAMI.2002.1046151; Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231; Lucas SM, 2003, PROC INT CONF DOC, P682; Lucas SM, 2003, PROC INT CONF DOC, P462; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; MCCLELLAND JL, 1981, PSYCHOL REV, V88, P375, DOI 10.1037/0033-295X.88.5.375; Mishra A., 2012, P IEEE C COMP VIS PA; Mishra A, 2011, PROC INT CONF DOC, P11, DOI 10.1109/ICDAR.2011.12; Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097; Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60; Neumann L, 2011, PROC INT CONF DOC, P687, DOI 10.1109/ICDAR.2011.144; OHYA J, 1994, IEEE T PATTERN ANAL, V16, P214, DOI 10.1109/34.273729; Saidane Z, 2009, IEEE INT CON MULTI, P266, DOI 10.1109/ICME.2009.5202486; Sarawagi S., 2005, ADV NEURAL INFORM PR, V17, P1185; Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296; Shivakumara P, 2011, PROC INT CONF DOC, P126, DOI 10.1109/ICDAR.2011.34; Simard PY, 2003, PROC INT CONF DOC, P958; Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444; Sutton C, 2009, MACH LEARN, V77, P165, DOI 10.1007/s10994-009-5112-z; Thillou C, 2005, EURASIP J APPL SIG P, V2005, P2127, DOI 10.1155/ASP.2005.2127; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402; Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43; Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264; Weinman J., 2006, P IEEE C COMP VIS PA, P308; Weinman Jerod J., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3987, DOI 10.1109/ICPR.2010.970; Weinman J. J., 2008, THESIS U MASSACHUSET; Weinman JJ, 2009, IEEE T PATTERN ANAL, V31, P1733, DOI 10.1109/TPAMI.2009.38; Weinman JJ, 2008, INT C PATT RECOG, P2664; WILLIAMS PM, 1995, NEURAL COMPUT, V7, P117, DOI 10.1162/neco.1995.7.1.117; Wu V, 1999, IEEE T PATTERN ANAL, V21, P1224, DOI 10.1109/34.809116; Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144; Yamazoe T, 2011, PROC INT CONF DOC, P359, DOI 10.1109/ICDAR.2011.80; Yi Chucai, 2011, IEEE Trans Image Process, V20, P2594, DOI 10.1109/TIP.2011.2126586; Yi-Feng Pan, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P6, DOI 10.1109/ICDAR.2009.97; Zhang HW, 2011, PROC INT CONF DOC, P708, DOI 10.1109/ICDAR.2011.148	57	53	56	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					375	387		10.1109/TPAMI.2013.126	http://dx.doi.org/10.1109/TPAMI.2013.126			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356356				2022-12-18	WOS:000328899500013
J	Kurtek, S; Klassen, E; Gore, JC; Ding, ZH; Srivastava, A				Kurtek, Sebastian; Klassen, Eric; Gore, John C.; Ding, Zhaohua; Srivastava, Anuj			Elastic Geodesic Paths in Shape Space of Parameterized Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape analysis; Riemannian distance; parameterization invariance; path-straightening; geodesics	BASAL GANGLIA; PARAMETRIZATION; ALGORITHM; MODELS	This paper presents a novel Riemannian framework for shape analysis of parameterized surfaces. In particular, it provides efficient algorithms for computing geodesic paths which, in turn, are important for comparing, matching, and deforming surfaces. The novelty of this framework is that geodesics are invariant to the parameterizations of surfaces and other shape-preserving transformations of surfaces. The basic idea is to formulate a space of embedded surfaces (surfaces seen as embeddings of a unit sphere in R-3) and impose a Riemannian metric on it in such a way that the reparameterization group acts on this space by isometries. Under this framework, we solve two optimization problems. One, given any two surfaces at arbitrary rotations and parameterizations, we use a path-straightening approach to find a geodesic path between them under the chosen metric. Second, by modifying a technique presented in [25], we solve for the optimal rotation and parameterization (registration) between surfaces. Their combined solution provides an efficient mechanism for computing geodesic paths in shape spaces of parameterized surfaces. We illustrate these ideas using examples from shape analysis of anatomical structures and other general surfaces.	[Kurtek, Sebastian; Srivastava, Anuj] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA; [Klassen, Eric] Florida State Univ, Dept Math, Tallahassee, FL 32306 USA; [Gore, John C.; Ding, Zhaohua] Vanderbilt Univ, Med Ctr, Inst Imaging Sci, Nashville, TN 37232 USA	State University System of Florida; Florida State University; State University System of Florida; Florida State University; Vanderbilt University	Kurtek, S (corresponding author), Florida State Univ, Dept Stat, 117 N Woodward Ave,POB 3064330, Tallahassee, FL 32306 USA.	skurtek@stat.fsu.edu; klassen@math.fsu.edu; john.gore@vanderbilt.edu; zhaohua.ding@vanderbilt.edu; anuj@stat.fsu.edu	Srivastava, Anuj/L-4705-2019; Ding, Zhaohua/AHC-7551-2022	Ding, Zhaohua/0000-0002-1805-2955; Srivastava, Anuj/0000-0001-7406-0338	US Air Force Office of Scientific Research [FA9550-06-1-0324]; US Office of Naval Research [N00014-09-1-0664]; US National Science Foundation (NSF) [DMS-0915003]; Division Of Mathematical Sciences [0915003] Funding Source: National Science Foundation	US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); US Office of Naval Research(Office of Naval Research); US National Science Foundation (NSF)(National Science Foundation (NSF)); Division Of Mathematical Sciences(National Science Foundation (NSF)NSF - Directorate for Mathematical & Physical Sciences (MPS))	The authors would like to thank Mr. Nathan Lay from the Florida State University Department of Scientific Computing for his help in implementing the methods described in this paper. This research was supported in part by US Air Force Office of Scientific Research FA9550-06-1-0324, US Office of Naval Research N00014-09-1-0664, and US National Science Foundation (NSF) DMS-0915003 (AS).	Almhdie A, 2007, PATTERN RECOGN LETT, V28, P1523, DOI 10.1016/j.patrec.2007.03.005; Ashcraft MH, 2007, PSYCHON B REV, V14, P243, DOI 10.3758/BF03194059; Bouix S, 2005, NEUROIMAGE, V25, P1077, DOI 10.1016/j.neuroimage.2004.12.051; BRECHBUHLER C, 1995, COMPUT VIS IMAGE UND, V61, P154, DOI 10.1006/cviu.1995.1013; Cates J., 2006, 1 MICCAI WORKSHOP MA, P90; Csernansky JG, 2002, AM J PSYCHIAT, V159, P2000, DOI 10.1176/appi.ajp.159.12.2000; Davatzikos C, 1996, J COMPUT ASSIST TOMO, V20, P88, DOI 10.1097/00004728-199601000-00017; Davies RH, 2010, IEEE T MED IMAGING, V29, P961, DOI 10.1109/TMI.2009.2035048; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Gerig G., 2001, P MICCAI, V2208, P24, DOI DOI 10.1007/3-540-45468-3_4; Gorczowski K, 2010, IEEE T PATTERN ANAL, V32, P652, DOI 10.1109/TPAMI.2009.92; Grenander U, 1998, Q APPL MATH, V56, P617, DOI 10.1090/qam/1668732; Gross L, 2006, PLOS BIOL, V4, P680, DOI [10.1371/journal.pbio.0040048, 10.1371/journal.pbio.0040043, 10.1371/journal.pbio.0040305, 10.1371/journal.pbio.0040042, 10.1371/journal.pbio.0040427, 10.1371/journal.pbio.0040212, 10.1371/journal.pbio.0040074, 10.1371/journal.pbio.0040311, 10.1371/journal.pbio.0040096, 10.1371/journal.pbio.0040371, 10.1371/journal.pbio.0040191, 10.1371/journal.pbio.0040323]; GU X, 2007, P 11 IEEE INT C COMP; Gu XF, 2004, LECT NOTES COMPUT SC, V3216, P771; Joshi SC, 1997, INT J PATTERN RECOGN, V11, P1317, DOI 10.1142/S0218001497000615; Joshi SH, 2007, LECT NOTES COMPUT SC, V4679, P387; Joshi Shantanu H, 2007, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2007, P1; Jost J, 2008, UNIVERSITEXT, P1; Kelemen A, 1999, IEEE T MED IMAGING, V18, P828, DOI 10.1109/42.811260; Kilian M., 2006, P ACM SIGGR; Klassen E, 2006, LECT NOTES COMPUT SC, V3951, P95; Kurtek S., 2010, P IEEE C COMP VIS PA; Kurtek S, 2011, LECT NOTES COMPUT SC, V6801, P147, DOI 10.1007/978-3-642-22092-0_13; Kurtek S, 2011, IEEE T MED IMAGING, V30, P849, DOI 10.1109/TMI.2010.2099130; Malladi R, 1996, J MATH IMAGING VIS, V6, P269, DOI 10.1007/BF00119843; Mcnab F, 2008, NAT NEUROSCI, V11, P103, DOI 10.1038/nn2024; Mio W, 2007, INT J COMPUT VISION, V73, P307, DOI [10.1007/s11263-006-9968-0, 10.1007/s11263-006-996S-0]; Osher S, 2003, LEVEL SET METHODS DY; Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274; Seger CA, 2006, NEUROSCIENTIST, V12, P285, DOI 10.1177/1073858405285632; SIDDIQI K, 2006, MEDIAL REPRESENTATIO; Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184; Styner M., 2006, P IM COMP COMP ASS I; Vaillant M, 2005, LECT NOTES COMPUT SC, V3565, P381; Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685; Younes L, 2008, REND LINCEI-MAT APPL, V19, P25; Zhang H., 2010, P EUR STAT OF THE AR	39	53	53	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1717	1730		10.1109/TPAMI.2011.233	http://dx.doi.org/10.1109/TPAMI.2011.233			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22144521				2022-12-18	WOS:000306409100006
J	Kamgar-Parsi, B; Lawson, W; Kamgar-Parsi, B				Kamgar-Parsi, Behrooz; Lawson, Wallace; Kamgar-Parsi, Behzad			Toward Development of a Face Recognition System for Watchlist Surveillance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; automatic surveillance; human-like classification; morphing facial images; biometrics; open world face recognition	3D	The interest in face recognition is moving toward real-world applications and uncontrolled sensing environments. An important application of interest is automated surveillance, where the objective is to recognize and track people who are on a watchlist. For this open world application, a large number of cameras that are increasingly being installed at many locations in shopping malls, metro systems, airports, etc., will be utilized. While a very large number of people will approach or pass by these surveillance cameras, only a small set of individuals must be recognized. That is, the system must reject every subject unless the subject happens to be on the watchlist. While humans routinely reject previously unseen faces as strangers, rejection of previously unseen faces has remained a difficult aspect of automated face recognition. In this paper, we propose an approach motivated by human perceptual ability of face recognition which can handle previously unseen faces. Our approach is based on identifying the decision region(s) in the face space which belong to the target person(s). This is done by generating two large sets of borderline images, projecting just inside and outside of the decision region. For each person on the watchlist, a dedicated classifier is trained. Results of extensive experiments support the effectiveness of our approach. In addition to extensive experiments using our algorithm and prerecorded images, we have conducted considerable live system experiments with people in realistic environments.	[Kamgar-Parsi, Behrooz; Lawson, Wallace] USN, Res Lab, Washington, DC 20375 USA; [Kamgar-Parsi, Behzad] US Off Naval Res, Arlington, VA 22203 USA	United States Department of Defense; United States Navy; Naval Research Laboratory	Kamgar-Parsi, B (corresponding author), USN, Res Lab, 4555 Overlook Ave SW, Washington, DC 20375 USA.				US Naval Research Laboratory; US Office of Naval Research	US Naval Research Laboratory; US Office of Naval Research(Office of Naval Research)	The authors are grateful to Stephen Krawczyk and Roman Stanchak for their valuable assistance in this research. They thank Anil Jain for many helpful comments. They thank the US Naval Research Laboratory and the US Office of Naval Research for their support.	Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Buddharaju P, 2007, IEEE T PATTERN ANAL, V29, P613, DOI 10.1109/TPAMI.2007.1007; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Fahlman, 1988, EMPIRICAL STUDY LEAR; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; HAN Z, 2010, P INT C PATT REC; Kamgar-Parsi B, 2001, IEEE T PATTERN ANAL, V23, P1404, DOI 10.1109/34.977564; KAMGARPARSI B, 2010, Patent No. 7684595; KAMGARPARSI B, 2003, P 4 IINT C AUD VID B, P412; KUMAR N, 2009, P IEEE 12 INT C COMP; LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686, DOI 10.1109/TPAMI.2005.224; Lienhart R, 2002, IEEE IMAGE PROC, P900; Lu XG, 2008, IEEE T PATTERN ANAL, V30, P1346, DOI 10.1109/TPAMI.2007.70784; Milborrow S., 2008, P EUR C COMP VIS; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; PIKE G, 2000, P IEEE C VIS BIOM; Sim T., 2002, P 5 INT C AUT FAC GE; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; UTTAL WR, 1995, PERCEPT PSYCHOPHYS, V57, P668, DOI 10.3758/BF03213272; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang HT, 2004, IEEE IMAGE PROC, P1397; Wang SJ, 2003, IEEE IJCNN, P2258; WECHSLER H, 2006, RELIABLE FACE RECOGN; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; ZHU S, 2009, P 5 INT C IM GRAPH	31	53	56	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					1925	1937		10.1109/TPAMI.2011.68	http://dx.doi.org/10.1109/TPAMI.2011.68			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21422493				2022-12-18	WOS:000293969000002
J	Kenig, T; Kam, Z; Feuer, A				Kenig, Tal; Kam, Zvi; Feuer, Arie			Blind Image Deconvolution Using Machine Learning for Three-Dimensional Microscopy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Blind deconvolution; deblurring; machine learning; PCA; kernel PCA; microscopy	BLUR IDENTIFICATION; RESTORATION; ABERRATION; SEGMENTATION; ALGORITHM	In this work, we propose a novel method for the regularization of blind deconvolution algorithms. The proposed method employs example-based machine learning techniques for modeling the space of point spread functions. During an iterative blind deconvolution process, a prior term attracts the point spread function estimates to the learned point spread function space. We demonstrate the usage of this regularizer within a Bayesian blind deconvolution framework and also integrate into the latter a method for noise reduction, thus creating a complete blind deconvolution method. The application of the proposed algorithm is demonstrated on synthetic and real-world three-dimensional images acquired by a wide-field fluorescence microscope, where the need for blind deconvolution algorithms is indispensable, yielding excellent results.	[Kenig, Tal; Feuer, Arie] Technion Israel Inst Technol, Fac Elect Engn, Haifa, Israel; [Kam, Zvi] Weizmann Inst Sci, Dept Mol Cell Biol, IL-76100 Rehovot, Israel	Technion Israel Institute of Technology; Weizmann Institute of Science		talkenig@tx.technion.ac.il; zvi.kam@weizmann.ac.il; feuer@ee.technion.ac.il			Israeli Ministry of Science and Technology	Israeli Ministry of Science and Technology(Ministry of Science, Technology and Space (MOST), Israel)	The authors gratefully acknowledge the support of the Israeli Ministry of Science and Technology.	AYERS GR, 1988, OPT LETT, V13, P547, DOI 10.1364/OL.13.000547; Booth MJ, 1998, J MICROSC-OXFORD, V192, P90, DOI 10.1111/j.1365-2818.1998.99999.x; Born M., 1999, PRINCIPLES OPTICS, Vseventh, DOI DOI 10.1017/CBO9781139644181; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Boyd R. W, 1983, RADIOMETRY DETECTION; Campisi P., 2007, BLIND IMAGE DECONVOL; CANNON M, 1976, IEEE T ACOUST SPEECH, V24, P58, DOI 10.1109/TASSP.1976.1162770; Carasso AS, 1999, SIAM J NUMER ANAL, V36, P1659, DOI 10.1137/S0036142997320413; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; Csiszar I., 1984, STAT DECISIONS, V1, P205; Dai S., 2008, P IEEE C COMP VIS PA, P1; DAMBREVILLE S, 2006, P INT C IM AN REC, V1, P73; DAMBREVILLE S, 2006, P COMPUTER VISION PA, V1, P977; Dambreville S, 2008, IEEE T PATTERN ANAL, V30, P1385, DOI 10.1109/TPAMI.2007.70774; Datsenko D, 2007, MULTIDIM SYST SIGN P, V18, P103, DOI 10.1007/s11045-007-0018-z; de Monvel JB, 2003, BIOPHYS J, V85, P3991, DOI 10.1016/S0006-3495(03)74813-9; DEPIERRO AR, 1995, IEEE T MED IMAGING, V14, P132, DOI 10.1109/42.370409; Dey N, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P1223; Etyngier P, 2007, IEEE I CONF COMP VIS, P1657; Etyngier P, 2007, LECT NOTES COMPUT SC, V4791, P891; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; FISH DA, 1995, J OPT SOC AM A, V12, P58, DOI 10.1364/JOSAA.12.000058; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; GIBSON SF, 1992, J OPT SOC AM A, V9, P154; Goodman J., 1996, OPT ENG, V2nd, DOI DOI 10.1117/1.601121; GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985; GUSTAFSSON MGL, 1995, P SOC PHOTO-OPT INS, P147; Haralick RM., 1992, COMPUTER ROBOT VISIO; HOLMES TJ, 1992, J OPT SOC AM A, V9, P1052, DOI 10.1364/JOSAA.9.001052; Hom EFY, 2007, J OPT SOC AM A, V24, P1580, DOI 10.1364/JOSAA.24.001580; Jia J., 2007, IEEE C COMP VIS PATT, P1; Joshi N., 2008, 2008 IEEE C COMP VIS, P1; KRISHNAMURTHI V, 1995, APPL OPTICS, V34, P6633, DOI 10.1364/AO.34.006633; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; Kwok JTY, 2004, IEEE T NEURAL NETWOR, V15, P1517, DOI 10.1109/TNN.2004.837781; LAGENDIJK RL, 1988, IEEE T ACOUST SPEECH, V36, P1874, DOI 10.1109/29.9032; LANE RG, 1987, J OPT SOC AM A, V4, P180, DOI 10.1364/JOSAA.4.000180; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; LI D, 2005, P IEEE INT C IM PROC, V1, P905; Li DL, 2007, IEEE T NEURAL NETWOR, V18, P931, DOI 10.1109/TNN.2007.891622; LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605; MACIASGARZA F, 1988, IEEE T ACOUST SPEECH, V36, P1067, DOI 10.1109/29.1629; MARKHAM J, 1998, P SPIE 3 DIM MULT MI, P38; Mika S., 1999, ADV NEURAL INFORM PR, V11; Nakagaki R, 2003, IEEE T IMAGE PROCESS, V12, P1044, DOI 10.1109/TIP.2003.816007; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; Panchapakesan K, 2001, IEEE T IMAGE PROCESS, V10, P465, DOI 10.1109/83.908524; Pankajakshan P, 2008, I S BIOMED IMAGING, P740, DOI 10.1109/ISBI.2008.4541102; Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; RATHI Y, 2006, P SPIE EL IM; Reeves SJ, 1992, IEEE T IMAGE PROCESS, V1, P301, DOI 10.1109/ICASSP.1992.226241; RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; ROUSSON M, 2002, P EUR C COMP VIS, P78; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Scalettar BA, 1996, J MICROSC-OXFORD, V182, P50, DOI 10.1046/j.1365-2818.1996.122402.x; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Starck JL, 2002, PUBL ASTRON SOC PAC, V114, P1051, DOI 10.1086/342606; STOCKHAM TG, 1975, P IEEE, V63, P678, DOI 10.1109/PROC.1975.9800; STOKSETH PA, 1969, J OPT SOC AM, V59, P1314, DOI 10.1364/JOSA.59.001314; STREIBL N, 1985, J OPT SOC AM A, V2, P121, DOI 10.1364/JOSAA.2.000121; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355; TSUMURAYA F, 1994, ASTRON ASTROPHYS, V282, P699; YANG YY, 1994, J OPT SOC AM A, V11, P2401, DOI 10.1364/JOSAA.11.002401; You YL, 1999, IEEE T IMAGE PROCESS, V8, P396, DOI 10.1109/83.748894; Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452; Zhang B, 2007, APPL OPTICS, V46, P1819, DOI 10.1364/AO.46.001819	69	53	54	1	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2010	32	12					2191	2204		10.1109/TPAMI.2010.45	http://dx.doi.org/10.1109/TPAMI.2010.45			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	672BT	20975117	Green Submitted			2022-12-18	WOS:000283558700006
J	Robin, A; Moisan, L; Le Hegarat-Mascle, S				Robin, Amandine; Moisan, Lionel; Le Hegarat-Mascle, Sylvie			An A-Contrario Approach for Subpixel Change Detection in Satellite Imagery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Change detection; a-contrario modeling; significance test; subpixel; mixture model; image series	UNSUPERVISED CHANGE DETECTION; MULTIPLE-SCLEROSIS; NEURAL-NETWORKS; TIME-SERIES; RESOLUTION; ALGORITHMS; EVOLUTION; MODEL	This paper presents a new method for unsupervised subpixel change detection using image series. The method is based on the definition of a probabilistic criterion capable of assessing the level of coherence of an image series relative to a reference classification with a finer resolution. In opposition to approaches based on an a priori model of the data, the model developed here is based on the rejection of a nonstructured model-called a-contrario model-by the observation of structured data. This coherence measure is the core of a stochastic algorithm which automatically selects the image subdomain representing the most likely changes. A theoretical analysis of this model is led to predict its performances, in particular regarding the contrast level of the image as well as the number of change pixels in the image. Numerical simulations are also presented that confirm the high robustness of the method and its capacity to detect changes impacting more than 25 percent of a considered pixel under average conditions. An application to land-cover change detection is then provided using time series of satellite images.	[Robin, Amandine] Univ Witwatersrand, Sch Computat & Appl Math, ZA-2050 Po Wits, South Africa; [Moisan, Lionel] Univ Paris 05, CNRS, UMR 8145, Lab MAP5, F-75270 Paris 06, France; [Le Hegarat-Mascle, Sylvie] Univ Paris 11, Inst Elect Fondamentale, F-91405 Orsay, France	University of Witwatersrand; Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute for Mathematical Sciences (INSMI); UDICE-French Research Universities; Universite Paris Cite; UDICE-French Research Universities; Universite Paris Saclay	Robin, A (corresponding author), Univ Witwatersrand, Sch Computat & Appl Math, ZA-2050 Po Wits, South Africa.	amandine.robin@wits.ac.za; lionel.moisan@parisdescartes.fr; le-hegar@ief.psud.frl	sylvie, le hégarat-mascle/AAB-9960-2022; Moisan, Lionel/A-7400-2010	sylvie, le hégarat-mascle/0000-0001-8494-2289; Moisan, Lionel/0000-0001-6019-2698	Centre National d'Etudes Spatiales (CNES); EADS/ASTRIUM	Centre National d'Etudes Spatiales (CNES)(Centre National D'etudes Spatiales); EADS/ASTRIUM	The authors would like to thank the Centre National d'Etudes Spatiales (CNES) and EADS/ASTRIUM for funding a part of this work. In particular, they are grateful to J. Inglada for fruitful discussions and to the CNES for providing the ADAM database. The main part of this research was done when Amandine Robin was with the Laboratory of Applied Mathematics (MAP5), University of Paris Descartes.	Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825; AGOURIS P, 2000, P INT S SPAT ACC, P18; [Anonymous], 1985, PERCEPTUAL ORG VISUA; BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x; Bonferroni C., 1936, TEORIA STAT CLASSI C, V8, P3; Bontemps S, 2008, REMOTE SENS ENVIRON, V112, P3181, DOI 10.1016/j.rse.2008.03.013; Bosc M, 2003, NEUROIMAGE, V20, P643, DOI 10.1016/S1053-8119(03)00406-3; Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408; Bruzzone L, 2000, INT J REMOTE SENS, V21, P3539, DOI 10.1080/014311600750037552; Bruzzone L, 2000, INT J REMOTE SENS, V21, P817, DOI 10.1080/014311600210614; Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678; CAO F, 2005, COMPUTATIONAL VISON; Cardot H, 2003, J APPL STAT, V30, P1185, DOI 10.1080/0266476032000107187; Clifton C, 2003, APPL INTELL, V18, P215, DOI 10.1023/A:1021942526896; Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676; Conradsen K, 2003, IEEE T GEOSCI REMOTE, V41, P4, DOI 10.1109/TGRS.2002.808066; Desolneux A, 2003, IEEE T PATTERN ANAL, V25, P508, DOI 10.1109/TPAMI.2003.1190576; Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236; ELFISHAWY AS, 1991, SIGNAL PROCESS, V23, P179, DOI 10.1016/0165-1684(91)90072-Q; Faivre R., 1997, Journal of Agricultural, Biological, and Environmental Statistics, V2, P87, DOI 10.2307/1400642; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fung T., 1988, PHOTOGRAMMETRIC ENG, V54, P1449; Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861; Grosjean B, 2009, J MATH IMAGING VIS, V33, P313, DOI 10.1007/s10851-008-0111-4; HOCHBERG Y, 1988, BIOMETRIKA, V75, P800, DOI 10.2307/2336325; Hochberg Y, 1987, MULTIPLE COMPARISON; Horwitz H. M., 1971, P 7 INT S REM SENS E, V2, P1307; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; Kasetkasem T, 2002, IEEE T GEOSCI REMOTE, V40, P1815, DOI 10.1109/TGRS.2002.802498; LE HEGARATMASCLE, 2004, REMOTE SENS ENVIRON, V91, P390; LE HEGARATMASCLE, 2005, REMOTE SENS ENVIRON, V95, P464; Malila W. A., 1980, S MACH PROC REM SENS, P326; Manolakis D, 2001, IEEE T GEOSCI REMOTE, V39, P1392, DOI 10.1109/36.934072; MELGANI F, 2002, OPTICAL ENG, V41, P81; Moisan L, 2004, INT J COMPUT VISION, V57, P201, DOI 10.1023/B:VISI.0000013094.38752.54; Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288; Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698; Rey D, 2002, MED IMAGE ANAL, V6, P163, DOI 10.1016/S1361-8415(02)00056-7; Robin A, 2008, IEEE T GEOSCI REMOTE, V46, P1359, DOI 10.1109/TGRS.2008.916477; SAPORTA G, 1990, PROBABILITES ANAL DO; Yang LM, 2003, PHOTOGRAMM ENG REM S, V69, P1003, DOI 10.14358/PERS.69.9.1003; ZHANG Z, 1994, AI J, V78, P87	43	53	55	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					1977	1993		10.1109/TPAMI.2010.37	http://dx.doi.org/10.1109/TPAMI.2010.37			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20847388	Green Submitted			2022-12-18	WOS:000281990900004
J	Kokkinos, I; Evangelopoulos, G; Maragos, P				Kokkinos, Iasonas; Evangelopoulos, Georgios; Maragos, Petros			Texture Analysis and Segmentation Using Modulation Features, Generative Models, and Weighted Curve Evolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Texture analysis; image segmentation; AM-FM models; demodulation; generative models; curve evolution; cue combination	APPROXIMATIONS; SEPARATION; VISION	In this work, we approach the analysis and segmentation of natural textured images by combining ideas from image analysis and probabilistic modeling. We rely on AM-FM texture models and, specifically, on the Dominant Component Analysis (DCA) paradigm for feature extraction. This method provides a low-dimensional, dense, and smooth descriptor, capturing the essential aspects of texture, namely, scale, orientation, and contrast. Our contributions are at three levels of the texture analysis and segmentation problems: First, at the feature extraction stage, we propose a Regularized Demodulation Algorithm that provides more robust texture features and we explore the merits of modifying the channel selection criterion of DCA. Second, we propose a probabilistic interpretation of DCA and Gabor filtering in general, in terms of Local Generative Models. Extending this point of view to edge detection facilitates the estimation of posterior probabilities for the edge and texture classes. Third, we propose the Weighted Curve Evolution scheme that enhances curve evolution-based segmentation methods by allowing for the locally adaptive combination of heterogeneous cues. Our segmentation results are evaluated on the Berkeley Segmentation Benchmark and compare favorably to current state-of-the-art methods.	[Kokkinos, Iasonas] Ecole Cent Paris, Dept Appl Math, F-92295 Chatenay Malabry, France; [Kokkinos, Iasonas] INRIA Saclay, Saclay, France; [Evangelopoulos, Georgios; Maragos, Petros] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece	UDICE-French Research Universities; Universite Paris Saclay; National Technical University of Athens	Kokkinos, I (corresponding author), Ecole Cent Paris, Dept Appl Math, F-92295 Chatenay Malabry, France.	iasonas.kokkinos@ecp.fr; gevag@cs.ntua.gr; maragos@cs.ntua.gr	Evangelopoulos, Georgios/B-8471-2015	Evangelopoulos, Georgios/0000-0003-2240-1801	Greek Ministry of Education; Greek Secretariat for Research Technology; European Network of Excellence	Greek Ministry of Education(Greek Ministry of Development-GSRT); Greek Secretariat for Research Technology(Greek Ministry of Development-GSRT); European Network of Excellence(European Commission)	The authors thank G. Papandreou for drawing their attention to the efficient distance transform computation in [12] and D. Dimitriadis for the discussions on 1D Gabor ESA. They wish to thank the reviewers for their constructive comments that helped improve the quality of the paper. This research was supported by the Greek Ministry of Education under program "HRAKLEITOS," the Greek Secretariat for Research & Technology under program "Pi ENE Delta-2001," and the European Network of Excellence "MUSCLE." I. Kokkinos was with the National Technical University of Athens when this paper was first submitted.	BELONGIE S, 1998, P 6 INT C COMP VIS; BOVIK AC, 1992, IEEE T INFORM THEORY, V38, P691, DOI 10.1109/18.119731; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; BOVIK AC, 1993, IEEE T SIGNAL PROCES, V41, P3245, DOI 10.1109/78.258071; BROX T, 2004, P 8 EUR C COMP VIS; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DIMITRIADIS D, 2003, P 8 EUR C SPEECH COM; EVANGELOPOULOS G, 2005, P 3 INT WORKSH VLSM, P121; FELZENSWALB P, 1963, TR20041963 CORN CIS; FOWLKES C, 2004, CSD41340 U CAL BERK; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GUMBEL EJ, 1953, J AM STAT ASSOC, V48, P131, DOI 10.2307/2280886; GUO CE, 2003, P 9 INT C COMP VIS; Havlicek JP, 1996, IEEE T IMAGE PROCESS, V5, P1094, DOI 10.1109/83.503927; Havlicek JP, 2000, IEEE T IMAGE PROCESS, V9, P227, DOI 10.1109/83.821736; HAVLICEK JP, 1999, VISUAL COMMUNICATION; JACOBS RA, 1995, NEURAL COMPUT, V7, P867, DOI 10.1162/neco.1995.7.5.867; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0; Kay S. M, 1993, FUNDAMENTALS STAT SI; KICHENASSAMY S, 1995, P 5 INT C COMP VIS; KNUTSSON H, 1993, P IEEE C COMP VIS PA; KOKKINOS I, 2005, P 4 INT WORKSH TEXT; KOKKINOS I, 2004, P INT C IM PROC; LEE TS, 1992, P 2 EUR C COMP VIS; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; Malishevskii AS, 2001, PHYS SOLID STATE+, V43, P1, DOI 10.1134/1.1340176; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; MARAGOS P, 1993, IEEE T SIGNAL PROCES, V41, P3024, DOI 10.1109/78.277799; MARAGOS P, 1995, J OPT SOC AM A, V12, P1867, DOI 10.1364/JOSAA.12.001867; Martin  D., 2001, P 8 INT C COMP VIS; Martin D., 2002, THESIS U CALIFORNIA; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073; MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Papavasiliou KA, 2007, J PEDIATR ORTHOP B, V16, P1, DOI 10.1097/BPB.0b013e328010b73d; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; PERONA P, 1990, P 3 INT C COMP VIS; Poggio T., 1988, Journal of Complexity, V4, P106, DOI 10.1016/0885-064X(88)90024-6; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; RAY N, 2001, P INT C IM PROC; ROUSSON M, 2003, P IEEE C COMP VIS PA; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; TANGSUKSON T, 2000, P INT C IM PROC; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106; WESTIN CF, 1994, P IEEE C COMP VIS PA; YEZZI A, 1999, P 7 INT C COMP VIS; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	56	53	59	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					142	157		10.1109/TPAMI.2008.33	http://dx.doi.org/10.1109/TPAMI.2008.33			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029552				2022-12-18	WOS:000260889700012
J	Wang, F; Vemuri, BC; Rangarajan, A; Eisenschenk, SJ				Wang, Fei; Vemuri, Baba C.; Rangarajan, Anand; Eisenschenk, Stephan J.			Simultaneous nonrigid registration of multiple point sets and atlas construction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						groupwise point set registration; finite-mixture model; Jensen-Shannon divergence; hypothesis testing; thin-plate spline	SHAPE; DISTRIBUTIONS; ALGORITHM	Groupwise registration of a set of shapes represented by unlabeled point sets is a challenging problem since, usually, this involves solving for point correspondence in a nonrigid motion setting. In this paper, we propose a novel and robust algorithm that is capable of simultaneously computing the mean shape, represented by a probability density function, from multiple unlabeled point sets (represented by finite-mixture models), and registering them nonrigidly to this emerging mean shape. This algorithm avoids the correspondence problem by minimizing the Jensen-Shannon (JS) divergence between the point sets represented as finite mixtures of Gaussian densities. We motivate the use of the JS divergence by pointing out its close relationship to hypothesis testing. Essentially, minimizing the JS divergence is asymptotically equivalent to maximizing the likelihood ratio formed from a probability density of the pooled point sets and the product of the probability densities of the individual point sets. We derive the analytic gradient of the cost function, namely, the JS-divergence, in order to efficiently achieve the optimal solution. The cost function is fully symmetric, with no bias toward any of the given shapes to be registered and whose mean is being sought. A by-product of the registration process is a probabilistic atlas, which is defined as the convex combination of the probability densities of the input point sets being aligned. Our algorithm can be especially useful for creating atlases of various shapes present in images and for simultaneously ( rigidly or nonrigidly) registering 3D range data sets (in vision and graphics applications), without having to establish any correspondence. We present experimental results on nonrigidly registering 2D and 3D real and synthetic data ( point sets).	[Wang, Fei] IBM Almaden Res Ctr, San Jose, CA 95120 USA; [Vemuri, Baba C.; Rangarajan, Anand] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA; [Eisenschenk, Stephan J.] Univ Florida, Dept Neurol, McKnight Brain Inst L3 100, Gainesville, FL 32610 USA	International Business Machines (IBM); State University System of Florida; University of Florida; State University System of Florida; University of Florida	Wang, F (corresponding author), IBM Almaden Res Ctr, G1-003,650 Harry Rd, San Jose, CA 95120 USA.	wangfe@us.ibm.com; vemuri@cise.ufl.edu; anand@cise.ufl.edu; stephan.eisenschenk@neurology.ufl.edu	Rangarajan, Anand/A-8652-2009	Rangarajan, Anand/0000-0001-8695-8436	US National Institutes of Health [RO1 NS046812]; US National Science Foundation [NSF 0307712]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE [R01NS042075, R01NS046812] Funding Source: NIH RePORTER	US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); US National Science Foundation(National Science Foundation (NSF)); NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS))	This research was funded in part by US National Institutes of Health grant RO1 NS046812 and US National Science Foundation grant NSF 0307712.	Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Chiang MC, 2007, NEUROIMAGE, V34, P44, DOI 10.1016/j.neuroimage.2006.08.030; Chui H, 2004, IEEE T PATTERN ANAL, V26, P160, DOI 10.1109/TPAMI.2004.1262178; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Duta N, 2001, IEEE T PATTERN ANAL, V23, P433, DOI 10.1109/34.922703; Endres DM, 2003, IEEE T INFORM THEORY, V49, P1858, DOI 10.1109/TIT.2003.813506; Garcin L, 2006, J MATH IMAGING VIS, V25, P329, DOI 10.1007/s10851-006-6729-1; Glaunes J, 2004, PROC CVPR IEEE, P712; Guo H, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P924; He Y, 2003, IEEE T SIGNAL PROCES, V51, P1211, DOI 10.1109/TSP.2003.810305; Hero AO, 2002, IEEE SIGNAL PROC MAG, V19, P85, DOI 10.1109/MSP.2002.1028355; Hill L, 2000, OXFORD LITERARY REV, V22, P3, DOI 10.3366/olr.2000.001; Jian B, 2005, IEEE I CONF COMP VIS, P1246; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; McLachlan G.J., 1988, MIXTURE MODEL INFERE; Sebastian TB, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P70, DOI 10.1109/MMBIA.2000.852362; Small C.G., 1996, STAT THEORY SHAPE; Tagare HD, 1999, IEEE T MED IMAGING, V18, P570, DOI 10.1109/42.790457; Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558; Wang Y, 2002, IEEE T IMAGE PROCESS, V11, P868, DOI 10.1109/TIP.2002.801120; Wang YM, 2000, IEEE T PATTERN ANAL, V22, P738, DOI 10.1109/34.865192; YUILLE AL, 1994, NEURAL COMPUT, V6, P334, DOI 10.1162/neco.1994.6.2.334	25	53	53	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					2011	2022		10.1109/TPAMI.2007.70829	http://dx.doi.org/10.1109/TPAMI.2007.70829			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787248	Green Accepted			2022-12-18	WOS:000259110000013
J	Huckemann, S; Hotz, T; Munk, A				Huckemann, Stephan; Hotz, Thomas; Munk, Axel			Global models for the orientation field of fingerprints: An approach based on quadratic differentials	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprint recognition; orientation field; fingerprint modeling; quadratic differentials; rational functions	VERIFICATION; SYSTEM; CLASSIFICATION; PATTERNS	Quadratic differentials naturally define analytic orientation fields on planar surfaces. We propose to model orientation fields of fingerprints by specifying quadratic differentials. Models for all fingerprint classes such as arches, loops, and whorls are laid out. These models are parameterized by a few geometrically interpretable parameters that are invariant under euclidean motions. We demonstrate their ability in adapting to given observed orientation fields, and we compare them to existing models using the fingerprint images of the NIST Special Database 4. We also illustrate that these models allow for extrapolation into unobserved regions. This goes beyond the scope of earlier models for the orientation field as those are restricted to the observed planar fingerprint region. Within the framework of quadratic differentials, we are able to analytically verify Penrose's formula for the singularities on a palm [19]. Potential applications of these models are the use of their parameters as indexes of large fingerprint databases, as well as the definition of intrinsic coordinates for single fingerprint images.	[Huckemann, Stephan; Hotz, Thomas] Univ Gottingen, Inst Math Stochast, D-37073 Gottingen, Germany	University of Gottingen	Huckemann, S (corresponding author), Univ Gottingen, Inst Math Stochast, Maschmuehlenweg 8-10, D-37073 Gottingen, Germany.	huckeman@math.uni-goettingen.de; hotz@math.uni-goettingen.de; munk@math.uni-goettingen.de						Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; BAZEN AM, 2001, P 3 INT C AUD VID BA, P198; Bhanu B, 2003, IEEE T PATTERN ANAL, V25, P616, DOI 10.1109/TPAMI.2003.1195995; Bonnevie K, 1924, J GENET, V15, P1, DOI 10.1007/BF02983100; Cappelli R, 1999, IEEE T PATTERN ANAL, V21, P402, DOI 10.1109/34.765653; Galton Francis, 1892, FINGER PRINTS; GROTZSCH H, 1993, SITZUNGSBERICHTE PRE, P654; Gu JW, 2004, PATTERN RECOGN, V37, P543, DOI 10.1016/S0031-3203(03)00178-X; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674; JENSEN G, 1975, UNIVALENT FUNCTIONS, pCH8; Jiang XD, 2002, IEEE T PATTERN ANAL, V24, P1121, DOI 10.1109/TPAMI.2002.1023807; KERCKHOFF S, 1986, ANN MATH, V124, P293, DOI 10.2307/1971280; Kholodenko AL, 2000, J GEOM PHYS, V33, P59, DOI 10.1016/S0393-0440(99)00040-6; Kontsevich M, 2003, INVENT MATH, V153, P631, DOI 10.1007/s00222-003-0303-x; Kovacs-Vajna ZM, 2000, IEEE T PATTERN ANAL, V22, P1266, DOI 10.1109/34.888711; Kucken M, 2005, J THEOR BIOL, V235, P71, DOI 10.1016/j.jtbi.2004.12.020; Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140; MARDIA KV, 1992, IMA J MATH APPL MED, V9, P289; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; Pankanti S, 2002, IEEE T PATTERN ANAL, V24, P1010, DOI 10.1109/TPAMI.2002.1023799; PENROSE LS, 1969, SCI AM, V221, P73, DOI 10.1038/scientificamerican1269-72; PENROSE LS, 1973, J MED GENET, V10, P201, DOI 10.1136/jmg.10.3.201; Prabhakar S., 2003, HDB FINGERPRINT RECO; Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800; Senior A, 2001, IEEE T PATTERN ANAL, V23, P1165, DOI 10.1109/34.954606; SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I; Smith C A, 1979, Birth Defects Orig Artic Ser, V15, P43; Strebel K., 1984, QUADRATIC DIFFERENTI; TEICHMULLER O, 1940, ABHANDLUNGEN PREUSSI, V22; Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604; Vizcaya PR, 1996, PATTERN RECOGN, V29, P1221, DOI 10.1016/0031-3203(95)00154-9; Wilson C. L., 1994, Journal of Artificial Neural Networks, V1, P203; Zhou J, 2004, PATTERN RECOGN, V37, P389, DOI 10.1016/S0031-3203(03)00186-9	36	53	55	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1507	1519		10.1109/TPAMI.2007.70826	http://dx.doi.org/10.1109/TPAMI.2007.70826			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	324FZ	18617711	Green Submitted			2022-12-18	WOS:000257504400001
J	Ben Ayed, I; Mitiche, A; Belhadj, Z				Ben Ayed, Ismail; Mitiche, Amar; Belhadj, Ziad			Polarimetric image segmentation via maximum-likelihood approximation and efficient multiphase level-sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						polarimetric images; complex Wishart distribution; complex Gaussian distribution; level set active contour segmentation; maximum-likelihood approximation	APERTURE RADAR IMAGES; REGION COMPETITION; ACTIVE CONTOURS; CLASSIFICATION; MODEL	This study investigates a level set method for complex polarimetric image segmentation. It consists of minimizing a functional containing an original observation term derived from maximum-likelihood approximation and a complex Wishart/Gaussian image representation and a classical boundary length prior. The minimization is carried out efficiently by a new multiphase method which embeds a simple partition constraint directly in curve evolution to guarantee a partition of the image domain from an arbitrary initial partition. Results are shown on both synthetic and real images. Quantitative performance evaluation and comparisons are also given.	Inst Natl Rech Sci, INRS EMT, Montreal, PQ H5A 1K6, Canada; Ecole Super Commun Tunis, SUPCOM, Tunis 2083, Tunisia	University of Quebec; Institut national de la recherche scientifique (INRS); Universite de Carthage	Ben Ayed, I (corresponding author), Inst Natl Rech Sci, INRS EMT, 800,Gauchetiere Ouest, Montreal, PQ H5A 1K6, Canada.	benayedi@emt.inrs.ca; mitiche@emt.inrs.ca; ziad.belhadj@supcom.rnu.tn						Beaulieu JM, 2004, IEEE T GEOSCI REMOTE, V42, P2063, DOI 10.1109/TGRS.2004.835302; Ben Ayed I, 2005, IEEE T PATTERN ANAL, V27, P793, DOI 10.1109/TPAMI.2005.106; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Conradsen K, 2003, IEEE T GEOSCI REMOTE, V41, P4, DOI 10.1109/TGRS.2002.808066; Dong Y, 2001, IEEE T GEOSCI REMOTE, V39, P321, DOI 10.1109/36.905240; Goudail F, 2004, IEEE T PATTERN ANAL, V26, P947, DOI 10.1109/TPAMI.2004.22; Jacques SL, 2002, J BIOMED OPT, V7, P329, DOI 10.1117/1.1484498; Kersten PR, 2005, IEEE T GEOSCI REMOTE, V43, P519, DOI 10.1109/TGRS.2004.842108; Mansouri AR, 2006, COMPUT VIS IMAGE UND, V101, P137, DOI 10.1016/j.cviu.2005.07.008; Martin P, 2004, IEEE T PATTERN ANAL, V26, P799, DOI 10.1109/TPAMI.2004.11; Muirhead R.J., 1982, ASPECTS MULTIVARIATE; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Paragios N, 2004, IEEE T PATTERN ANAL, V26, P402, DOI 10.1109/TPAMI.2004.1262337; Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594; Sethian J. A., 1999, LEVEL SET METHODS FA; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500; Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	19	53	53	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2006	28	9					1493	1500		10.1109/TPAMI.2006.191	http://dx.doi.org/10.1109/TPAMI.2006.191			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	062NC	16929734				2022-12-18	WOS:000238950800011
J	Yan, R; Zhang, J; Yang, J; Hauptmann, AG				Yan, R; Zhang, J; Yang, J; Hauptmann, AG			A discriminative learning framework with pairwise constraints for video object classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						video object classification; pairwise constraints; discriminative learning; margin-based learning	EM	To deal with the problem of insufficient labeled data in video object classification, one solution is to utilize additional pairwise constraints that indicate the relationship between two examples, i.e., whether these examples belong to the same class or not. In this paper, we propose a discriminative learning approach which can incorporate pairwise constraints into a conventional margin-based learning framework. Different from previous work that usually attempts to learn better distance metrics or estimate the underlying data distribution, the proposed approach can directly model the decision boundary and, thus, require fewer model assumptions. Moreover, the proposed approach can handle both labeled data and pairwise constraints in a unified framework. In this work, we investigate two families of pairwise loss functions, namely, convex and nonconvex pairwise loss functions, and then derive three pairwise learning algorithms by plugging in the hinge loss and the logistic loss functions. The proposed learning algorithms were evaluated using a people identification task on two surveillance video data sets. The experiments demonstrated that the proposed pairwise learning algorithms considerably outperform the baseline classifiers using only labeled data and two other pairwise learning algorithms with the same amount of pairwise constraints.	Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA	Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University	Yan, R (corresponding author), Carnegie Mellon Univ, Language Technol Inst, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	yanrong@cs.cmu.edu; jian.zhang@cs.cmu.edu; yang+@cs.cmu.edu; alex@cs.cmu.edu						Allwein E. L., 2001, Journal of Machine Learning Research, V1, P113, DOI 10.1162/15324430152733133; ANTANIA S, 2002, PATTERN RECOGN, V4, P945; BASU S, 2003, P 20 INT C MACH LEAR; Basu Sugato, 2004, KDD, P59, DOI DOI 10.1145/1014052.1014062; BLUM A, 1998, P WORKSH COMP LEARN; Coleman TF, 1996, SIAM J OPTIMIZ, V6, P418, DOI 10.1137/0806023; COMENAREZ AJ, 1997, P IEEE C COMP VIS PA; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Gish H, 1994, IEEE SIGNAL PROC MAG, V11, P18, DOI 10.1109/79.317924; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; HEWISH M, 1991, INT DEFENSE REV, V24; JAIN A, 1993, PATTERN RECOGNITION, V29; JONES M, 2003, P IEEE INT C COMP VI; KIMELDORF G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Kumar S., 2003, P IEEE INT C COMP VI; Kwok J. T., 2003, P 20 INT C MACH LEAR; LAFFERTY J, 2003, P 20 INT C MACH LEAR; LANGE T, 2005, P IEEE C COMP VIS PA; LI F, 2003, P INT C COMP VIS OCT; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; PENTLAND A, 1994, P IEEE C COMP VIS PA, P568; PERONA P, 2003, P IEEE C COMP VIS PA; PIERSON WE, 2000, P SPIE INT SOC OPTIC, V4053; Platt J C, 1999, ADV KERNEL METHODS S; SHAKHNAROVICH G, 2001, P IEEEE C COMP VIS P; SHENTAL N, 2003, P IEEE C COMP VIS PA; SHENTAL N, 2003, P WORKSH CONT LAB UN; SIVIC J, 2003, P INT C COMP VIS OCT; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Wagstaff K., 2001, ICML, V1, P577, DOI DOI 10.1109/TPAMI.2002.1017616; XIE L, 2004, P IEEE WORKSH LEARN; Xing E., 2002, P ADV NEUR INF PROC, V15, P1; Yan R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P516; YANG J, 2004, P INT C COMP VIS PAT; Yu SX, 2001, LECT NOTES COMPUT SC, V2134, P283; YUILLE AL, 2003, P IEEE INT C COMP VI; ZHU J, 2001, ADV NEURAL INFORM PR	37	53	60	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					578	593		10.1109/TPAMI.2006.65	http://dx.doi.org/10.1109/TPAMI.2006.65			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	011FK	16566507	Green Submitted			2022-12-18	WOS:000235253300008
J	Govaert, G; Nadif, M				Govaert, G; Nadif, M			An EM algorithm for the block mixture model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						block mixture model; EM algorithm; variational approximation	MAXIMUM-LIKELIHOOD	Although many clustering procedures aim to construct an optimal partition of objects or, sometimes, of variables, there are other methods, called block clustering methods, which consider simultaneously the two sets and organize the data into homogeneous blocks. Recently, we have proposed a new mixture model called block mixture model which takes into account this situation. This model allows one to embed simultaneous clustering of objects and variables in a mixture approach. We have studied this probabilistic model under the classification likelihood approach and developed a new algorithm for simultaneous partitioning based on the Classification EM algorithm. In this paper, we consider the block clustering problem under the maximum likelihood approach and the goal of our contribution is to estimate the parameters of this model. Unfortunately, the application of the EM algorithm for the block mixture model cannot be made directly; difficulties arise due to the dependence structure in the model and approximations are required. Using a variational approximation, we propose a generalized EM algorithm to estimate the parameters of the block mixture model and, to illustrate our approach, we study the case of binary data by using a Bernoulli block mixture.	Univ Technol Compiegne, CNRS, UMR 6599, HEUDIASYC, F-60205 Compiegne, France; Univ Metz, Inst Univ Technol, F-57045 Metz, France	Picardie Universites; Universite de Technologie de Compiegne; Centre National de la Recherche Scientifique (CNRS); Universite de Lorraine	Govaert, G (corresponding author), Univ Technol Compiegne, CNRS, UMR 6599, HEUDIASYC, BP 20529, F-60205 Compiegne, France.	gerard.govaert@utc.fr; nadif@iut.univ-metz.fr						Bock H., 1979, ANAL DONNEES INFORM, P187; CELEUX G, 1992, COMPUT STAT DATA AN, V14, P315, DOI 10.1016/0167-9473(92)90042-E; Chen CC, 2000, ELECTROCHEM SOLID ST, V3, P103, DOI 10.1149/1.1390971; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dhillon I.S., 2001, P 7 ACM SIGKDD INT C, P269, DOI DOI 10.1145/502512.502550; Govaert G, 1996, COMPUT STAT DATA AN, V23, P65, DOI 10.1016/S0167-9473(96)00021-7; Govaert G., 1995, Control and Cybernetics, V24, P437; Govaert G, 2003, PATTERN RECOGN, V36, P463, DOI 10.1016/S0031-3203(02)00074-2; Govaert G., 1983, THESIS U PARIS 6 FRA; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Hofmann T, 1998, IEEE T PATTERN ANAL, V20, P803, DOI 10.1109/34.709593; JAAKKOLA TS, 1997, THESIS MIT; Jordan MI, 1998, NATO ADV SCI I D-BEH, V89, P105; Mclachlan G., 2000, WILEY SER PROB STAT; SYMONS MJ, 1981, BIOMETRICS, V37, P35, DOI 10.2307/2530520	15	53	55	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					643	647		10.1109/TPAMI.2005.69	http://dx.doi.org/10.1109/TPAMI.2005.69			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794169				2022-12-18	WOS:000226845700015
J	Cappelli, R; Maio, D; Maltoni, D				Cappelli, R; Maio, D; Maltoni, D			Multispace KL for pattern representation and classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						KL transform; PCA; multispace KL; clustering; piecewise-linear approximation; face representation; face recognition	ALGORITHM; SET	This work introduces the Multispace KL (MKL) as a new approach to unsupervised dimensionality reduction for pattern representation and classification. The training set is automatically partitioned into disjoint subsets, according to an optimality criterion; each subset then determines a different KL subspace which is specialized in representing a particular group of patterns. The extension of the classical KL operators and the definition of ad hoc distances allow MKL to be effectively used where KL is commonly employed. The limits of the standard KL transform are pointed out, in particular, MKL is shown to outperform KL when the data distribution is far from a multidimensional Gaussian and to better cope with large sets of patterns, which could cause a severe performance drop in KL.	Univ Bologna, Cdl Sci Informaz, I-47023 Cesena, FO, Italy; Univ Bologna, DEIS, CSITE CNR, I-40136 Bologna, Italy	University of Bologna; University of Bologna	Cappelli, R (corresponding author), Univ Bologna, Cdl Sci Informaz, Via Sacchi 3, I-47023 Cesena, FO, Italy.	cappelli@csr.unibo.it; dmaio@deis.unibo.it; maltoni@csr.unibo.it		Cappelli, Raffaele/0000-0003-3054-9363				Cappelli R., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, P155, DOI 10.1109/DEXA.1999.795159; Cappelli R, 2000, LECT NOTES COMPUT SC, V1857, P351; CAPPELLI R, 1999, P WORKSH AUT ID ADV, P117; Chalmond B, 1999, IEEE T PATTERN ANAL, V21, P422, DOI 10.1109/34.765654; CHANDRASEKARAN S, 1996, CVGIP GRAPHICAL MODE; Frigui H, 1999, IEEE T PATTERN ANAL, V21, P450, DOI 10.1109/34.765656; Fukunaga K, 1990, STAT PATTERN RECOGNI; Hamamoto Y, 1996, PATTERN RECOGN, V29, P1751, DOI 10.1016/0031-3203(96)00027-1; Hartigan J.A., 1975, CLUSTERING ALGORITHM; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hotelling H., 1933, J ED PSYCHOL; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; ILLINGWORTH J, 1987, IEEE T PATTERN ANAL, V9, P690, DOI 10.1109/TPAMI.1987.4767964; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jolliffe I.T., 1986, PRINCIPLE COMPONENT; Karhunen, 1946, ANN ACAD SCI FENNICA, V37, P3, DOI DOI 10.1016/J.COMPBIOMED.2009.01.015; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Loeve M., 1955, PROBABILITY THEORY F; McLachlan, 1997, EM ALGORITHM EXTENSI; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511, DOI 10.1109/TPAMI.1982.4767295; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Swets DL, 1999, IEEE T PATTERN ANAL, V21, P386, DOI 10.1109/34.765652; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Uenohara M, 1997, IEEE T PATTERN ANAL, V19, P891, DOI 10.1109/34.608291; Zhao L, 1999, PATTERN RECOGN, V32, P851, DOI 10.1016/S0031-3203(98)00032-6	28	53	60	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2001	23	9					977	996		10.1109/34.955111	http://dx.doi.org/10.1109/34.955111			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	470RP					2022-12-18	WOS:000170885200004
J	Beis, JS; Lowe, DG				Beis, JS; Lowe, DG			Indexing without invariants in 3D object recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						model-based object recognition; indexing; kd-tree algorithm; nearest-neighbors algorithm	APPEARANCE; MODELS; IMAGES	We present a method of indexing three-dimensional objects from single two-dimensional images. Unlike most other methods to solve this problem, ours does not rely on invariant features. This allows a richer set of shape information to be used in the recognition process. We also suggest the kd-tree as an alternative indexing data structure to the standard hash table. This makes hypothesis recovery more efficient in high-dimensional spaces, which are necessary to achieve specificity in large model databases. Search efficiency is maintained in these regimes by the use of Best-Bin First search, a modified kd-tree search algorithm which locates approximate nearest-neighbors. Neighbors recovered from the index are used to generate probability estimates, local within the feature space, which are then used to rank hypotheses for verification. On average, the ranking process greatly reduces the number of verifications required. Our approach is general in that it can be applied to any real-valued feature vector. In addition, it is straightforward to add to our index information from real images regarding the true probability distributions of the feature groupings used for indexing. In this paper, we provide experiments with both synthetic and real images, as well as details of the practical implementation of our system, which has been applied in the domain of telerobotics.	KnowledgeTech Consulting Inc, Vancouver, BC V6K 2C1, Canada; Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1W5, Canada	University of British Columbia	Beis, JS (corresponding author), KnowledgeTech Consulting Inc, 2980 W 8th Ave, Vancouver, BC V6K 2C1, Canada.	jbeis@knowledgtech.ca; lowe@cs.ubc.ca						BARRETT EB, 1991, CVGIP-IMAG UNDERSTAN, V53, P46, DOI 10.1016/1049-9660(91)90004-9; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; BEIS JS, 1997, THESIS U BRIT COLUMB; BENARIE J, 1990, IEEE T PATTERN ANAL, V12, P760, DOI 10.1109/34.57667; BURNS JB, 1993, IEEE T PATTERN ANAL, V15, P51, DOI 10.1109/34.184774; CALIFANO A, 1994, IEEE T PATTERN ANAL, V16, P373, DOI 10.1109/34.277591; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; DICKINSON SJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P130, DOI 10.1016/1049-9660(92)90013-S; Duda R.O., 1973, J ROYAL STAT SOC SER; Forsyth D., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P598, DOI 10.1109/ICCV.1990.139604; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Grimson W. E. L., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P334, DOI 10.1109/ICCV.1990.139544; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; Lamdan Y., 1988, P IEEE INT C COMP VI, P238; Lloyd JE, 1997, IEEE INT CONF ROBOT, P1297, DOI 10.1109/ROBOT.1997.614316; LLOYD JE, 1992, MULTIRCCL USERS GUID; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Malik R, 1997, IEEE T PATTERN ANAL, V19, P52, DOI 10.1109/34.566810; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nelson RC, 1998, VISION RES, V38, P2469, DOI 10.1016/S0042-6989(98)00030-3; Rothwell C. A., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P109, DOI 10.1109/CVPR.1992.223219; Samet H., 1990, DESIGN ANAL SPATIAL, V85; SCHIELE B, 1996, P 4 EUR C COMP VIS, P610; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; SHIMSHONI I, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P488, DOI 10.1109/ICCV.1995.466900; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P1198, DOI 10.1109/34.177385; Wayner P. C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P473, DOI 10.1109/CVPR.1991.139738; WHEELER MD, 1995, IEEE T PATTERN ANAL, V17, P252, DOI 10.1109/34.368190	33	53	59	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1999	21	10					1000	1015		10.1109/34.799907	http://dx.doi.org/10.1109/34.799907			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	248DB					2022-12-18	WOS:000083259100004
J	Wang, JP				Wang, JP			Stochastic relaxation on partitions with connected components and its application to image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						connected components; Gibbs distribution; simulated annealing; hierarchical segmentation; unsupervised segmentation; multiscale segmentation	MARKOV RANDOM-FIELD; GIBBS RANDOM-FIELDS; TEXTURED IMAGES; UNSUPERVISED SEGMENTATION; ALGORITHM; NOISY; MODEL	We present a new method of segmentation in which images are segmented in partitions with connected components. We give computationally inexpensive algorithms for probability simulation and simulated annealing on the space of partitions with connected components of a general graph. In particular, Hastings algorithms and generalized Metropolis algorithms are defined to avoid heavy computation. To achieve segmentation, we propose a hierarchical approach which at each step minimizes a cost function on the space of partitions with connected components of a graph. The algorithm is applied to segment gray-level, color, and textured images.	Univ Cergy Pontoise, UFR Sci & Tech, F-95302 Cergy Pontoise, France; Ecole Normale Super, DIAM, CMLA, F-94235 Cachan, France	CY Cergy Paris Universite; UDICE-French Research Universities; Universite Paris Saclay	Wang, JP (corresponding author), Univ Cergy Pontoise, UFR Sci & Tech, 2 Av Adolphe Chauvin, F-95302 Cergy Pontoise, France.	wang@cmla.ens-cachan.fr						Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796; AZENCOTT R, 1987, SEMINAIRE BOURBAKI, V697; AZENCOTT R, 1987, P INT C IND APPL MAT; BESAG J, 1986, J R STAT SOC B, V48, P259; BEVERIDGE JR, 1989, INT J COMPUT VISION, V2, P311, DOI 10.1007/BF00158168; BOUMAN C, 1991, IEEE T PATTERN ANAL, V13, P99, DOI 10.1109/34.67641; CATONI O, 1992, ANN PROBAB, V20, P1109, DOI 10.1214/aop/1176989682; CHEN PC, 1979, COMPUT VISION GRAPH, V10, P172, DOI 10.1016/0146-664X(79)90049-2; COOPER DB, 1980, COMPUT VISION GRAPH, V12, P326, DOI 10.1016/0146-664X(80)90018-0; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; GAGALOWICZ A, 1988, P 9 INT C PATT REC R; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1987, P INT C MATH 1986 PR; Hajek B., 1988, MATH OPERATIONS RES, V13; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; HEITZ F, 1994, CVGIP IMAGE UNDERSTA, V59; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; HU RM, 1992, SIGNAL PROCESS, V26, P285, DOI 10.1016/0165-1684(92)90117-F; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; KERVRANN C, 1995, IEEE T IMAGE PROCESS, V4, P856, DOI 10.1109/83.388090; KHOTANZAD A, 1989, IEEE T PATTERN ANAL, V11, P414, DOI 10.1109/34.19038; KOEPFLER G, 1994, SIAM J NUMER ANAL, V31, P282, DOI 10.1137/0731015; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NAGIN PA, 1982, IEEE T PATTERN ANAL, V4, P263, DOI 10.1109/TPAMI.1982.4767243; NGUYEN HH, 1993, CVGIP-GRAPH MODEL IM, V55, P1, DOI 10.1006/cgip.1993.1001; Perez P, 1996, IEEE T INFORM THEORY, V42, P180, DOI 10.1109/18.481788; Pratt W, 1991, DIGITAL IMAGE PROCES; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; WANG JP, STOCHASTIC RELAXATIO; WANG JP, 1994, THESIS PARIS SUD U; WON CS, 1992, CVGIP-GRAPH MODEL IM, V54, P308, DOI 10.1016/1049-9652(92)90078-C	35	53	64	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1998	20	6					619	636		10.1109/34.683775	http://dx.doi.org/10.1109/34.683775			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZV807					2022-12-18	WOS:000074343300004
J	Cho, K; Meer, P; Cabrera, J				Cho, K; Meer, P; Cabrera, J			Performance assessment through bootstrap	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE International Symposium on Computer Vision	NOV, 1995	CORAL GABLES, FL	IEEE		performance evaluation; edge detection; bootstrap		A new performance evaluation paradigm for computer vision systems is proposed. In real situation, the complexity of the input data and/or of the computational procedure can make traditional error propagation methods infeasible. The new approach exploits a resampling technique recently introduced in statistics, the bootstrap. Distributions for the output variables are obtained by perturbing the nuisance properties of the input, i.e., properties with no relevance for the output under ideal conditions. From these bootstrap distributions, the confidence in the adequacy of the assumptions embedded into the computational procedure for the given input is derived. As an example, the new paradigm is applied to the task of edge detection. The performance of several edge detection methods is compared both for synthetic data and real images. The confidence in the output can be used to obtain an edgemap independent of the gradient magnitude.	RUTGERS STATE UNIV,DEPT ELECT & COMP ENGN,PISCATAWAY,NJ 08855; RUTGERS STATE UNIV,DEPT STAT,PISCATAWAY,NJ 08855	Rutgers State University New Brunswick; Rutgers State University New Brunswick	Cho, K (corresponding author), SAMSUNG DATA SYST,OPEN SOLUT CTR,SEOUL,SOUTH KOREA.								0	53	55	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1185	1198		10.1109/34.632979	http://dx.doi.org/10.1109/34.632979			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585					2022-12-18	WOS:A1997YG58500001
J	Uenohara, M; Kanade, T				Uenohara, M; Kanade, T			Use of Fourier and Karhunen-Loeve decomposition for fast pattern matching with a large set of templates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						template matching; pattern matching; Karhunen-Loeve transform; Fourier transform; eigenvector		We present a fast pattern matching algorithm with a large set of templates. The algorithm is based on the typical template matching speeded up by the dual decomposition; the Fourier transform and the Karhunen-Loeve transform. The proposed algorithm is appropriate for the search of an object with unknown distortion within a short period. Patterns with different distortion differ slightly from each other and are highly correlated. The image vector subspace required for effective representation can be defined by a small number of eigenvectors derived by the Kamunen-Loeve transform. A vector subspace spanned by the eigenvectors is generated, and any image vector in the subspace is considered as a pattern to be recognized. The pattern matching of objects with unknown distortion is formulated as the process to extract the portion of the input image, find the pattern most similar to the extracted portion in the subspace, compute normalized correlation between them at each location in the input image, and find the location with the best score. Searching for objects with unknown distortion requires vast computation. The formulation above makes it possible to decompose highly correlated reference images into eigenvectors, as well as to decompose images in frequency domain, and to speed up the process significantly.	CARNEGIE MELLON UNIV,INST ROBOT,PITTSBURGH,PA 15213	Carnegie Mellon University	Uenohara, M (corresponding author), TOSHIBA RES & DEV CTR,KAWASAKI KU,4-1 UKISHIMA CHO,KAWASAKI,KANAGAWA 210,JAPAN.							AMIDI O, 1994, P 5 RI SME WORLD C R; FUKUNAGA K, 1990, INTRO STATISTICAL PA; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Rosenfeld A., 1982, DIGITAL PICTURE PROC; Turk M., 1991, J COGNITIVE NEUROSCI, V3; UENOHARA M, 1995, COMPUT BIOL MED, V25, P249, DOI 10.1016/0010-4825(94)00045-R; Uenohara M., 1995, P 1995 C COMP VIS VI; YOSHIMURA S, 1994, P IROS 94	9	53	58	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1997	19	8					891	898		10.1109/34.608291	http://dx.doi.org/10.1109/34.608291			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XT987		Green Published			2022-12-18	WOS:A1997XT98700007
J	Gimelfarb, GL				Gimelfarb, GL			Texture modeling by multiple pairwise pixel interactions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture; Markov/Gibbs random field; pairwise interaction; maximum likelihood estimate		A Markov random field model with a Gibbs probability distribution (GPD) is proposed for describing particular classes of grayscale images which can be called spatially uniform stochastic textures. The model takes into account only multiple short- and long-range pairwise interactions between the gray levels in the pixels. An effective learning scheme is introduced to recover structure and strength of the interactions using maximal likelihood estimates of the potentials in the GPD as desired parameters. The scheme is based on an analytic initial approximation of the estimates and their subsequent refinement by a stochastic approximation. Experiments in modeling natural textures show the utility of the proposed model.			Gimelfarb, GL (corresponding author), NATL ACAD SCI UKRAINE,VM GLUSHKOV CYBERNET INST,PROSPECT AKAD GLUSHKOVA 40,UA-252022 KIEV 22,UKRAINE.		El-Baz, Ayman/AAC-6689-2019	El-Baz, Ayman/0000-0001-7264-1323; Gimel'farb, Georgy/0000-0003-2120-9391				Averintsev M. B., 1972, PROBABILITY THEORY I, V17, P21; BARNDORFFNIELSE.O, 1978, INFORMATION EXPONENT; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Dobrushin R. L., 1976, Proceedings of the 1975 IEEE-USSR Joint Workshop on Information Theory, P39; Dubes R.C., 1989, J APPL STAT, V16, P131, DOI DOI 10.1080/02664768900000014; ELFADEL IM, 1994, IEEE T PATTERN ANAL, V16, P24, DOI 10.1109/34.273719; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gidas B, 1993, MARKOV RANDOM FIELDS, P471; JACOBSEN M, 1989, SCAND J STAT, V16, P335; KASHYAP RL, 1986, HDB PATTERN RECOGNIT, P247; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; YOUNES L, 1988, ANN I H POINCARE-PR, V24, P269	13	53	54	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1996	18	11					1110	1114		10.1109/34.544081	http://dx.doi.org/10.1109/34.544081			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VU159					2022-12-18	WOS:A1996VU15900007
J	PAUWELS, EJ; VANGOOL, LJ; FIDDELAERS, P; MOONS, T				PAUWELS, EJ; VANGOOL, LJ; FIDDELAERS, P; MOONS, T			AN EXTENDED CLASS OF SCALE-INVARIANT AND RECURSIVE SCALE-SPACE FILTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SCALE SPACE; NON-GAUSSIAN FILTERS; SCALE INVARIANCE; RECURSIVITY; CAUSALITY; SEMIGROUPS	RETINAL GANGLION-CELLS; RECEPTIVE-FIELD; CAT	In this paper we explore how the functional form of scale space filters is determined by a number of a priori conditions. In particular, if we assume scale space filters to be linear, isotropic convolution filters, then two conditions (viz. recursivity and scale-invariance) suffice to narrow down the collection of possible filters to a family that essentially depends on one parameter which determines the qualitative shape of the filter. Gaussian filters correspond to one particular value of this shape-parameter. For other values the filters exhibit a more complicated pattern of excitatory and inhibitory regions. This might well be relevant to the study of the neurophysiology of biological visual systems, for recent research shows the existence of extensive disinhibitory regions outside the periphery of the classical center-surround receptive field of LGN and retinal ganglion cells (in cats). Such regions cannot be accounted for by models based on the second order derivative of the Gaussian. Finally, we investigate how this work ties in with another axiomatic approach of scale space operators (propounded by Lindeberg and Alvarez et al.) which focuses on the semigroup properties of the operator family. We show that only a discrete subset of filters gives rise to an evolution which can be characterized by means of a partial differential equation.	KATHOLIEKE UNIV LEUVEN, DEPT ELECT ENGN, B-3001 LOUVAIN, BELGIUM	KU Leuven	PAUWELS, EJ (corresponding author), KATHOLIEKE UNIV LEUVEN, M12 ESAT LAB, VIS RES GRP, B-3001 LOUVAIN, BELGIUM.							Abramowitz M, 1970, HDB MATH FUNCTIONS; ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127; ALVAREZ L, 1993, COMMUNICATION; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BRACEWELL RN, 1978, FOURIER TRANSFORM IT; Champeney D.C., 1987, HDB FOURIER THEOREMS; CROWLEY JL, 1982, CMURITR827 CARN U RO; DEFEVER F, 1994, COMMUNICATION; DERRINGTON AM, 1982, J PHYSIOL-LONDON, V333, P343, DOI 10.1113/jphysiol.1982.sp014457; ENROTHCUGELL C, 1983, J PHYSIOL-LONDON, V341, P279, DOI 10.1113/jphysiol.1983.sp014806; FLORACK LMJ, 1993, THESIS U UTRECHT NET; Gradshteyn IS., 2001, TABLES INTEGRALS SER; Hille E., 1957, C PUBLICATIONS, VXXXI; LI CY, 1992, VISION RES, V32, P219, DOI 10.1016/0042-6989(92)90131-2; LI CY, 1991, VISION RES, V31, P1529, DOI 10.1016/0042-6989(91)90130-W; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Lindeberg T, 1991, THESIS ROYAL I TECHN; Marr D., 1982, VISION; PAUWELS EJ, 1993, KULESATMI29316 KU LE; RUDIN W, 1981, REAL COMPLEX ANAL; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; WITKIN AP, 1984, IMAGE UNDERSTANDING; YOSIDA K, 1986, FUNCTIONAL ANAL; Young R. A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P564; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	26	53	53	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1995	17	7					691	701		10.1109/34.391411	http://dx.doi.org/10.1109/34.391411			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RF224					2022-12-18	WOS:A1995RF22400005
J	PELILLO, M; REFICE, M				PELILLO, M; REFICE, M			LEARNING COMPATIBILITY COEFFICIENTS FOR RELAXATION LABELING PROCESSES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPATIBILITY COEFFICIENTS; CONSTRAINT SATISFACTION; GRADIENT PROJECTION; LEARNING; NEURAL NETWORKS; NONLINEAR PROGRAMMING; PART-OF-SPEECH DISAMBIGUATION; RELAXATION LABELING	NEURAL NETWORKS; CURVE ENHANCEMENT; COMPUTATION; ALGORITHM; OPERATIONS; PROJECTION; HOPFIELD	Relaxation labeling processes have been widely used in many different domains including image processing, pattern recognition, and artificial intelligence. They are iterative procedures that aim at reducing local ambiguities and achieving global consistency through a parallel exploitation of contextual information, which is quantitatively expressed in terms of a set of ''compatibility coefficients.'' The problem of determining compatibility coefficients has received a considerable attention in the past and many heuristic, statistical-based methods have been suggested. In this paper, we propose a rather different viewpoint to solve this problem: we derive them attempting to optimize the performance of the relaxation algorithm over a sample of training data; no statistical interpretation is given: compatibility coefficients are simply interpreted as real numbers, for which performance is optimal. Experimental results over a novel application of relaxation are given, which prove the effectiveness of the proposed approach.	POLITECN, DIPARTIMENTO ELETTROTECN & ELETTR, I-70125 BARI, ITALY		PELILLO, M (corresponding author), UNIV BARI, DIPARTIMENTO INFORMAT, VIA G AMENDOLA 173, I-70126 BARI, ITALY.							ALMEIDA LB, 1987, 1ST P IEEE INT C NEU, V2, P609; ANDERSON JA, 1983, IEEE T SYST MAN CYB, V13, P799, DOI 10.1109/TSMC.1983.6313074; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BALLARD DH, 1983, NATURE, V306, P21, DOI 10.1038/306021a0; BENEVENGA NJ, 1989, TOXICANTS PLANT ORIG, V3, P203; BOVES L, 1987, P EUROP C SPEECH TEC, P385; CHEN Z, 1990, PATTERN RECOGN, V23, P637, DOI 10.1016/0031-3203(90)90039-N; CHURCH KW, 1989, P INT C ACOUST SPEEC, P695; CRICK F, 1989, NATURE, V337, P129, DOI 10.1038/337129a0; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; DAVIS GW, 1989, IEEE T SYST MAN CYB, V19, P1078, DOI 10.1109/21.44023; DAVIS LS, 1977, IEEE T COMPUT, V26, P1053, DOI 10.1109/TC.1977.1674746; DAVIS LS, 1981, ARTIF INTELL, V17, P245, DOI 10.1016/0004-3702(81)90026-6; DEROUAULT AM, 1986, IEEE T PATTERN ANAL, V8, P742, DOI 10.1109/TPAMI.1986.4767855; EKLUNDH JO, 1980, IEEE T SYST MAN CYB, V10, P150; ELFVING T, 1982, COMPUT VISION GRAPH, V20, P158, DOI 10.1016/0146-664X(82)90042-9; Fahlman SE, 1983, P NAT C AI; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; GENIS CT, 1989, J PARALLEL DISTR COM, V6, P217, DOI 10.1016/0743-7315(89)90060-9; Goldberg DE, 1989, GENETIC ALGORITHMS S; HARALICK RM, 1980, COMPUT VISION GRAPH, V13, P242, DOI 10.1016/0146-664X(80)90048-9; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HARALICK RM, 1978, INFORM SCIENCES, V14, P199, DOI 10.1016/0020-0255(78)90043-9; Hertz J., 1991, INTRO THEORY NEURAL, DOI DOI 10.1201/9780429499661; HINTON GE, 1986, PARALLEL DISTRIBUTED, V1, P283; HOLT MJJ, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P17, DOI 10.1109/ICPR.1992.201712; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; HUMMEL RA, 1983, P NAT C ARTIFICIAL I, P168; Illingworth J., 1987, PATTERN RECOGN, P109; JAMISON TA, 1988, IMAGE VISION COMPUT, V6, P203, DOI 10.1016/0262-8856(88)90010-8; KAMADA M, 1988, PATTERN RECOGN, V21, P175, DOI 10.1016/0031-3203(88)90025-8; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5; Kittler J., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P186; KULLBACK S, 1959, INFORMATION THEORY S; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; LLOYD S. A, 1983, IMAGE VISION COMPUT, V1, P85; Luenberger D.G, 2016, LINEAR NONLINEAR PRO, DOI 10.1007/978-3-319-18842-3; MITCHISON G, 1989, COMP NEUR S, P35; MOHAMMED JL, 1983, IEEE T PATTERN ANAL, V5, P330, DOI 10.1109/TPAMI.1983.4767394; OLEARY DP, 1983, IEEE T SYST MAN CYB, V13, P618, DOI 10.1109/TSMC.1983.6313149; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P886, DOI 10.1109/34.31449; PELEG S, 1979, COMMUN ACM, V22, P598, DOI 10.1145/359168.359174; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; PELEG S, 1979, COMPUT VISION GRAPH, V10, P235, DOI 10.1016/0146-664X(79)90003-0; PELILLO M, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P145, DOI 10.1109/ICPR.1992.201741; PELILLO M, 1992, P INT C SPOKEN LANGU, P389; PELILLO M, 1991, P EUROSPEECH 91 GENO, P757; PELILO M, 1992, P INT C SPOKEN LANGU, P1343; PINEDA FJ, 1987, PHYS REV LETT, V59, P2229, DOI 10.1103/PhysRevLett.59.2229; ROHWER R, 1987, P IEEE ICNN SAN DIEG, P701; ROSEN JB, 1960, J SOC IND APPL MATH, V8, P181, DOI 10.1137/0108011; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Sejnowski T. J., 1987, Complex Systems, V1, P145; Solla S. A., 1988, Complex Systems, V2, P625; Van Laarhoven P.J., 1987, SIMULATED ANNEALING, P7; Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270; WILSON GV, 1988, BIOL CYBERN, V58, P63, DOI 10.1007/BF00363956; YAMAMOTO H, 1979, COMPUT VISION GRAPH, V10, P256, DOI 10.1016/0146-664X(79)90005-4; YU SS, 1992, PATTERN RECOGN, V25, P197, DOI 10.1016/0031-3203(92)90101-N; ZHUANG XH, 1989, IEEE T PATTERN ANAL, V11, P1316, DOI 10.1109/34.41370; Zucker SW, 1989, NEURAL COMPUT, V1, P68, DOI 10.1162/neco.1989.1.1.68; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P117, DOI 10.1109/TPAMI.1981.4767069	69	53	55	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					933	945		10.1109/34.310691	http://dx.doi.org/10.1109/34.310691			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802		Green Submitted			2022-12-18	WOS:A1994PE80200011
J	WELLMAN, MP; HENRION, M				WELLMAN, MP; HENRION, M			EXPLAINING EXPLAINING AWAY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note								Explaining away is a common pattern of reasoning in which the confirmation of one cause of an observed or believed event reduces the need to invoke alternative causes. The opposite of explaining away also can occur, where the confirmation of one cause increases belief in another. We provide a general qualitative probabilistic analysis of intercausal reasoning and identify the property of the interaction among the causes (product synergy) that determines which form of reasoning is appropriate. Product synergy extends the qualitative probabilistic network (QPN) formalism to support qualitative intercausal inference about the directions of change in probabilistic belief. The intercausal relation also justifies Occam's razor, facilitating pruning in the search for likely diagnoses.	ROCKWELL INT CORP,CTR SCI,PALO ALTO,CA 94301	Rockwell Collins	WELLMAN, MP (corresponding author), UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,ANN ARBOR,MI 48109, USA.		Wellman, Michael/AAQ-7063-2020	Wellman, Michael/0000-0002-1691-6844				GEFFNER H, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P524; GEFFNER H, 1988, P AAAI 88 ST PAUL, P449; HENRION M, 1991, 7TH P C UNC ART INT, P142; Henrion M., 1989, UNCERTAINTY ARTIFICI, V3; HENRION M, 1991, UNCERTAINTY ARTIFICI, V6; HENRION M, 1987, NATO ISI SERIES F, V35, P105; MILGROM PR, 1981, BELL J ECON, V12, P380, DOI 10.2307/3003562; PAEK E, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P545; PEARL J, 1988, ARTIF INTELL, V35, P259, DOI 10.1016/0004-3702(88)90015-X; PEARL J, 1989, KYBERNETIKA, V25, P33; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; SHACHTER RD, 1989, P WORKSHOP UNCERTAIN, P303; SHWE MA, 1991, METHOD INFORM MED, V30, P241, DOI 10.1055/s-0038-1634846; Wellman M. P, 1990, FORMULATION TRADEOFF; WELLMAN MP, 1990, ARTIF INTELL, V44, P257, DOI 10.1016/0004-3702(90)90026-V; WELLMAN MP, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P535	16	53	55	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					287	292		10.1109/34.204911	http://dx.doi.org/10.1109/34.204911			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800010
J	SANDINI, G; TISTARELLI, M				SANDINI, G; TISTARELLI, M			ACTIVE TRACKING STRATEGY FOR MONOCULAR DEPTH INFERENCE OVER MULTIPLE FRAMES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SANDINI, G (corresponding author), UNIV GENOA,DEPT COMMUN COMP & SYST SCI,VIA OPERA PIA 11A,I-16145 GENOA,ITALY.		Tistarelli, Massimo/AAH-9437-2021	Tistarelli, Massimo/0000-0002-3406-3048				BAJCSY R, 1985, 3 IEEE WORKSH COMP V, P55; Ballard D.H., 1982, COMPUTER VISION; BHARWANI S, 1986, MAY P WORKSH MOT REP, P73; BRIDWELL NJ, 1983, COMPUT VISION GRAPH, V21, P33, DOI 10.1016/S0734-189X(83)80028-0; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; IKEUCHI K, 1984, AI772 MIT LAB MEM; LAWTON DT, 1983, COMPUT VISION GRAPH, V22, P116, DOI 10.1016/0734-189X(83)90098-1; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MATTHIES L, 1987, 4TH P INT S ROB RES, P120; MORASSO P, 1977, IEEE T SYST MAN CYB, V9, P639; MORASSO P, 1986, NATO ARW SENSORS SEN, V43, P449; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; POGGIO T, 1982, AI683 MIT LAB MEM; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; RICHARDS W, 1983, AI731 MIT LAB MEM; RIEGER JH, 1984, COINS8428 U MASS TEC; SANDINI G, 1985, WINT P 85 TOP M MACH; SANDINI G, 1987, 4TH P INT S ROB RES, P351; SNYDER MA, 1986, MAY P WORKSH MOT REP, P53; SUGIE N, 1970, IEEE T SYST SCI CYB, VSSC6, P103, DOI 10.1109/TSSC.1970.300283; ULLMAN S, 1983, AI721 MIT LAB MEM	24	53	53	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1990	12	1					13	27		10.1109/34.41380	http://dx.doi.org/10.1109/34.41380			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CG247					2022-12-18	WOS:A1990CG24700002
J	KARTIKEYAN, B; SARKAR, A				KARTIKEYAN, B; SARKAR, A			SHAPE-DESCRIPTION BY TIME-SERIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											KARTIKEYAN, B (corresponding author), INDIAN INST TECHNOL,DEPT MATH,KHARAGPUR 721302,W BENGAL,INDIA.		Rohlf, F J/A-8710-2008					ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; AKAIKE H, 1977, P S APPLICATIONS STA; ALT FL, 1962, J ACM, V9, P240, DOI 10.1145/321119.321122; [Anonymous], 1976, TIME SERIES ANAL; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BRILLINGER DR, 1967, SPECTRAL ANAL TIME S; Cramer H., 2004, STATIONARY RELATED S; DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; FENG HYF, 1975, IEEE T COMPUT, VC 24, P636, DOI 10.1109/T-C.1975.224276; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; Gabr M. M., 1981, Journal of Time Series Analysis, V2, P155, DOI 10.1111/j.1467-9892.1981.tb00319.x; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; HAGGAN V, 1981, BIOMETRIKA, V68, P189, DOI 10.1093/biomet/68.1.189; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P2, DOI 10.1109/TPAMI.1979.4766870; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; Priestley M.B., 1981, SPECTRAL ANAL TIME S, V1; PRIESTLEY MB, 1978, STATISTICIAN, V27; RAO C, 1974, LINEAR STATISTICAL I; SARKAR A, 1987, J STATIST COMPUT SIM, V28, P245; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; SHAPIRO LG, 1980, IEEE T PATTERN ANAL, V2, P111, DOI 10.1109/TPAMI.1980.4766989; TANG GY, 1979, IEEE T PATTERN ANAL, V1, P135, DOI 10.1109/TPAMI.1979.4766899; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949; 1986, JANES ALL WORLDS AIR	30	53	56	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					977	984		10.1109/34.35501	http://dx.doi.org/10.1109/34.35501			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800008
J	SAGHRI, JA; FREEMAN, H				SAGHRI, JA; FREEMAN, H			ANALYSIS OF THE PRECISION OF GENERALIZED CHAIN CODES FOR THE REPRESENTATION OF PLANAR CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									RENSSELAER POLYTECH INST,TROY,NY 12181	Rensselaer Polytechnic Institute								FREEMAN H, 1969, IEEE T SYST SCI CYB, VSSC5, P70, DOI 10.1109/TSSC.1969.300247; FREEMAN H, 1980, COMPUT VISION GRAPH, V12, P203, DOI 10.1016/0146-664X(80)90012-X; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; FREEMAN H, 1978, 4TH INT JOINT C PATT; FREEMAN H, 1978, MAY P IEEE COMP SOC; FREEMAN H, 1977, 1976 P NATO ADV STUD; GROEN FCA, 1978, COMPUT VISION GRAPH, V7, P391, DOI 10.1016/S0146-664X(78)80005-7; GROEN FCA, 1977, ANAL DNA BASED MEASU; SAGHRI JA, 1979, IPLTR003 RENSS POL I	9	53	63	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	5					533	539		10.1109/TPAMI.1981.4767146	http://dx.doi.org/10.1109/TPAMI.1981.4767146			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ358	21868973				2022-12-18	WOS:A1981MQ35800004
J	Zhou, TF; Qi, SY; Wang, WG; Shen, JB; Zhu, SC				Zhou, Tianfei; Qi, Siyuan; Wang, Wenguan; Shen, Jianbing; Zhu, Song-Chun			Cascaded Parsing of Human-Object Interaction Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Portable computers; Neural networks; Cognition; Task analysis; Image segmentation; Context modeling; Visualization; Human-object interaction recognition; cascaded parsing; fine-grained relation segmentation		This paper addresses the task of detecting and recognizing human-object interactions (HOI) in images. Considering the intrinsic complexity and structural nature of the task, we introduce a cascaded parsing network (CP-HOI) for a multi-stage, structured HOI understanding. At each cascade stage, an instance detection module progressively refines HOI proposals and feeds them into a structured interaction reasoning module. Each of the two modules is also connected to its predecessor in the previous stage, enabling efficient cross-stage information propagation. The structured interaction reasoning module is built upon a graph parsing neural network (GPNN), which efficiently models potential HOI structures as graphs and mines rich context for comprehensive relation understanding. In particular, GPNN infers a parse graph that i) interprets meaningful HOI structures by a learnable adjacency matrix, and ii) predicts action (edge) labels. Within an end-to-end, message-passing framework, GPNN blends learning and inference, iteratively parsing HOI structures and reasoning HOI representations (i.e., instance and relation features). Further beyond relation detection at a bounding-box level, we make our framework flexible to perform fine-grained pixel-wise relation segmentation; this provides a new glimpse into better relation modeling. A preliminary version of our CP-HOI model reached 1(st) place in the ICCV2019 Person in Context Challenge, on both relation detection and segmentation. In addition, our CP-HOI shows promising results on two popular HOI recognition benchmarks, i.e., V-COCO and HICO-DET.	[Zhou, Tianfei; Wang, Wenguan] Swiss Fed Inst Technol, Zurich, Switzerland; [Qi, Siyuan] Google, Mountain View, CA 94043 USA; [Shen, Jianbing] Univ Macau, Dept Comp & Informat Sci, State Key Lab IOTSC, Macau, Peoples R China; [Zhu, Song-Chun] Tsinghua Univ, Beijing, Peoples R China; [Zhu, Song-Chun] Peking Univ, Beijing, Peoples R China	Swiss Federal Institutes of Technology Domain; ETH Zurich; Google Incorporated; University of Macau; Tsinghua University; Peking University	Wang, WG (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.	ztfei.debug@gmail.com; syqi@cs.ucla.edu; wenguanwang.ai@gmail.com; shenjianbingcg@gmail.com; sczhu@stat.ucla.edu	Zhou, Tianfei/AAC-6115-2022	Zhou, Tianfei/0000-0001-5475-1473; Qi, Siyuan/0000-0002-4070-733X	Zhejiang Lab's Open Fund [2019KD0AB04]; CCF-Baidu Open Fund	Zhejiang Lab's Open Fund; CCF-Baidu Open Fund	This work was supported by the CCF-Baidu Open Fund and Zhejiang Lab's Open Fund (No. 2019KD0AB04).	Bingjie Xu, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P2019, DOI 10.1109/CVPR.2019.00212; Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048; Chao YW, 2015, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2015.122; Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511; Chen LC, 2015, PR MACH LEARN RES, V37, P1785; Cho K., 2014, 8 WORKSH SYNT SEM ST, P103, DOI DOI 10.3115/V1/W14-4012; Delaitre V., 2011, ADV NEURAL INFORM PR, P1503; Desai C, 2012, LECT NOTES COMPUT SC, V7575, P158, DOI 10.1007/978-3-642-33765-9_12; Fan LF, 2019, IEEE I CONF COMP VIS, P5723, DOI 10.1109/ICCV.2019.00582; Fang HS, 2018, LECT NOTES COMPUT SC, V11214, P52, DOI 10.1007/978-3-030-01249-6_4; Fang HS, 2018, AAAI CONF ARTIF INTE, P6821; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906; Gao Chen, 2018, BRIT MACH VIS C; Gibson J.J., 2014, ECOLOGICAL APPROACH, DOI [DOI 10.4324/9781315740218, 10.4324/9781315740218]; Gilmer J, 2017, PR MACH LEARN RES, V70; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872; Gu JX, 2019, PROC CVPR IEEE, P1969, DOI 10.1109/CVPR.2019.00207; Gupta A, 2007, PROC CVPR IEEE, P2564; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Gupta S., 2015, ARXIV PREPRINT ARXIV; Gupta T, 2019, IEEE I CONF COMP VIS, P9676, DOI 10.1109/ICCV.2019.00977; Hamilton W. L., 2017, ARXIV 170905584; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu JF, 2013, IEEE I CONF COMP VIS, P3144, DOI 10.1109/ICCV.2013.390; Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133; Kato K, 2018, LECT NOTES COMPUT SC, V11218, P247, DOI 10.1007/978-3-030-01264-9_15; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041; Li X, 2020, ARXIV 201205007; Li YL, 2019, PROC CVPR IEEE, P3580, DOI 10.1109/CVPR.2019.00370; Liao Y, 2020, PROC CVPR IEEE, P479, DOI 10.1109/CVPR42600.2020.00056; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4; Lu X., 2020, ECCV; Ma CY, 2018, PROC CVPR IEEE, P6790, DOI 10.1109/CVPR.2018.00710; Mallya A, 2016, LECT NOTES COMPUT SC, V9905, P414, DOI 10.1007/978-3-319-46448-0_25; Marino K, 2017, PROC CVPR IEEE, P20, DOI 10.1109/CVPR.2017.10; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Norcliffe-Brown W, 2018, ADV NEUR IN, V31; Ouyang WL, 2017, IEEE I CONF COMP VIS, P1956, DOI 10.1109/ICCV.2017.214; Pang B, 2020, AAAI CONF ARTIF INTE, V34, P11823; Park S, 2018, IEEE T PATTERN ANAL, V40, P1555, DOI 10.1109/TPAMI.2017.2731842; Peyre J, 2019, IEEE I CONF COMP VIS, P1981, DOI 10.1109/ICCV.2019.00207; Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25; Qu M, 2019, ADV NEUR IN, V32; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Schneiderman H, 2004, PROC CVPR IEEE, P29; Shao D, 2018, LECT NOTES COMPUT SC, V11213, P202, DOI 10.1007/978-3-030-01240-3_13; Shao D, 2020, PROC CVPR IEEE, P2613, DOI 10.1109/CVPR42600.2020.00269; Shen LY, 2018, IEEE WINT CONF APPL, P1568, DOI 10.1109/WACV.2018.00181; Sheng-YuWang OliverWang, 2020, COMPUTER VISION PATT; Sui YL, 2013, INT SYM CODE GENER, P1; Tan H., 2019, BMVC; Tompson J.J., 2014, ADV NEURAL INF PROCE, P1799, DOI DOI 10.5555/2968826.2969027; Ulutan Oytun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13614, DOI 10.1109/CVPR42600.2020.01363; Velickovic P., 2018, P INT C LEARN REPR; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wan B, 2019, IEEE I CONF COMP VIS, P9468, DOI 10.1109/ICCV.2019.00956; Wang TC, 2019, IEEE I CONF COMP VIS, P5693, DOI 10.1109/ICCV.2019.00579; Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933; Wang WG, 2019, IEEE I CONF COMP VIS, P5702, DOI 10.1109/ICCV.2019.00580; Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449; Wenguan Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8926, DOI 10.1109/CVPR42600.2020.00895; Wu JC, 2019, PROC CVPR IEEE, P9956, DOI 10.1109/CVPR.2019.01020; Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330; Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41; Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386; Yao BP, 2010, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2010.5540234; Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611; Zhang YB, 2019, PROC CVPR IEEE, P9967, DOI 10.1109/CVPR.2019.01021; Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644; Zheng ZL, 2019, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2019.00683; Zhou PH, 2019, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2019.00093; Zhou TF, 2020, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR42600.2020.00432; Zhuang BH, 2018, AAAI CONF ARTIF INTE, P7631	79	52	52	29	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					2827	2840		10.1109/TPAMI.2021.3049156	http://dx.doi.org/10.1109/TPAMI.2021.3049156			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33400648				2022-12-18	WOS:000803117500006
J	Tian, Z; Shen, CH; Chen, H; He, T				Tian, Zhi; Shen, Chunhua; Chen, Hao; He, Tong			FCOS: A Simple and Strong Anchor-Free Object Detector	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; fully convolutional one-stage object detection; anchor box; deep learning		In computer vision, object detection is one of most important tasks, which underpins a few instance-level recognition tasks and many downstream applications. Recently one-stage methods have gained much attention over two-stage approaches due to their simpler design and competitive performance. Here we propose a fully convolutional one-stage object detector (FCOS) to solve object detection in a per-pixel prediction fashion, analogue to other dense prediction problems such as semantic segmentation. Almost all state-of-the-art object detectors such as RetinaNet, SSD, YOLOv3, and Faster R-CNN rely on pre-defined anchor boxes. In contrast, our proposed detector FCOS is anchor box free, as well as proposal free. By eliminating the pre-defined set of anchor boxes, FCOS completely avoids the complicated computation related to anchor boxes such as calculating the intersection over union (IoU) scores during training. More importantly, we also avoid all hyper-parameters related to anchor boxes, which are often sensitive to the final detection performance. With the only post-processing non-maximum suppression (NMS), we demonstrate a much simpler and flexible detection framework achieving improved detection accuracy. We hope that the proposed FCOS framework can serve as a simple and strong alternative for many other instance-level tasks. Code is available at: git. io/AdelaiDet	[Tian, Zhi; Shen, Chunhua; Chen, Hao; He, Tong] Univ Adelaide, Adelaide, SA 5005, Australia; [Shen, Chunhua] Monash Univ, Clayton, Vic 3800, Australia	University of Adelaide; Monash University	Shen, CH (corresponding author), Univ Adelaide, Adelaide, SA 5005, Australia.	zhi.tian@adelaide.edu.au; chunhua.shen@adelaide.edu.au; hao.chen01@adelaide.edu.au; tong.he@adelaide.edu.au			ARC DP [DP200103797]	ARC DP(Australian Research Council)	This work was supported in part by ARC DP under Grant #DP200103797.	Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Chen Y, 2017, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2017.137; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667; Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221; Fu C.-Y., 2017, ABS170106659 ARXIV; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630; Hao Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8570, DOI 10.1109/CVPR42600.2020.00860; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He T, 2019, PROC CVPR IEEE, P578, DOI 10.1109/CVPR.2019.00067; He T, 2018, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR.2018.00527; Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351; Huang L., 2015, ABS150904874 ARXIV; Kaiwen Duan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P399, DOI 10.1007/978-3-030-58580-8_24; Law H., 2018, P EUR C COMP VIS ECC, P734; Lee Y., 2020, P IEEECVF C COMP VIS, P13906; Li XL, 2020, IEEE WIREL COMMUN, V27, P116, DOI 10.1109/MWC.001.2000076; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu Yifan, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3001940; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079; Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343; Qiu H., 2020, P EUR C COMP VIS; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075; Rufeng Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10223, DOI 10.1109/CVPR42600.2020.01024; Samet N., 2020, P EUR C COMP VIS; Shao Shuai, 2018, ABS180500123 ARXIV, V6, P8; Shen CH, 2013, INT J COMPUT VISION, V103, P326, DOI 10.1007/s11263-013-0608-1; Shrivastava A., 2017, ABS161206851 ARXIV; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972; Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324; Tian Zhi, 2019, ARXIV191107451; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang GT, 2020, PROC CVPR IEEE, P6287, DOI 10.1109/CVPR42600.2020.00632; Wu Y., 2019, DETECTRON2 FACEBOOK; Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1; Xuangeng Chu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12211, DOI 10.1109/CVPR42600.2020.01223; Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975; Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578; Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255; Yu Jiahui., 2016, ACM MM, DOI DOI 10.1145/2964284.2967274; Yuliang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9806, DOI 10.1109/CVPR42600.2020.00983; Zhang SJ, 2020, I S MOD ANAL SIM COM, P1, DOI 10.1007/s00134-020-05977-9; Zhi Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P282, DOI 10.1007/978-3-030-58452-8_17; Zhou X., 2019, ARXIV190407850V2; Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283; Zhu B, 2020, ABS200703496 ARXIV; Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953	62	52	57	66	119	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1922	1933		10.1109/TPAMI.2020.3032166	http://dx.doi.org/10.1109/TPAMI.2020.3032166			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33074804	Green Submitted			2022-12-18	WOS:000764815300020
J	Anwar, S; Barnes, N				Anwar, Saeed; Barnes, Nick			Densely Residual Laplacian Super-Resolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Laplace equations; Feature extraction; Computer architecture; Convolutional neural networks; Image restoration; Super-resolution; laplacian attention; multi-scale attention; densely connected residual blocks; deep convolutional neural network		Super-Resolution convolutional neural networks have recently demonstrated high-quality restoration for single images. However, existing algorithms often require very deep architectures and long training times. Furthermore, current convolutional neural networks for super-resolution are unable to exploit features at multiple scales and weigh them equally or at only static scale only, limiting their learning capability. In this exposition, we present a compact and accurate super-resolution algorithm, namely, densely residual laplacian network (DRLN). The proposed network employs cascading residual on the residual structure to allow the flow of low-frequency information to focus on learning high and mid-level features. In addition, deep supervision is achieved via the densely concatenated residual blocks settings, which also helps in learning from high-level complex features. Moreover, we propose Laplacian attention to model the crucial features to learn the inter and intra-level dependencies between the feature maps. Furthermore, comprehensive quantitative and qualitative evaluations on low-resolution, noisy low-resolution, and real historical image benchmark datasets illustrate that our DRLN algorithm performs favorably against the state-of-the-art methods visually and accurately.	[Anwar, Saeed] Data61 CSIRO, Canberra, ACT 2601, Australia; [Barnes, Nick] CSIRO, Canberra, ACT 2601, Australia; [Barnes, Nick] Australian Natl Univ, Canberra, ACT 0200, Australia	Commonwealth Scientific & Industrial Research Organisation (CSIRO); Commonwealth Scientific & Industrial Research Organisation (CSIRO); Australian National University	Anwar, S (corresponding author), Data61 CSIRO, Canberra, ACT 2601, Australia.	saeed.anwar@data61.csiro.au; nick.barnes@anu.edu.au	Barnes, Nick/Y-2744-2018	Barnes, Nick/0000-0002-9343-9535				Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16; Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132; Deng J., 2009, P 2009 IEEE C COMP V, P248, DOI DOI 10.1109/CVPR.2009.5206848; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Dumoulin Vincent, 2017, ICLR; Fujimoto A, 2016, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON COMICS ANALYSIS, PROCESSING AND UNDERSTANDING (MANPU 2016), DOI 10.1145/3011549.3011551; Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075; Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hu, 2018, ARXIV180208808; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156; Jiao JB, 2017, IEEE COMPUT SOC CONF, P1034, DOI 10.1109/CVPRW.2017.140; Jolicoeur-Martineau Alexia, 2018, ARXIV180700734; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kim J, 2018, TENCON IEEE REGION, P0090, DOI 10.1109/TENCON.2018.8650166; Kingma D.P., 2015, INT C LEARN REPR, P1; Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Maas A.L., 2013, P ICML, V30, P3, DOI DOI 10.1016/0010-0277(84)90022-2; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mudunuri SP, 2016, IEEE T PATTERN ANAL, V38, P1034, DOI 10.1109/TPAMI.2015.2469282; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Park SJ, 2018, LECT NOTES COMPUT SC, V11220, P455, DOI 10.1007/978-3-030-01270-0_27; Paszke A, 2017, NEURAL INFORM PROCES; Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844; Perez-Pellitero E, 2016, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2016.203; Qiu YJ, 2019, IEEE I CONF COMP VIS, P4179, DOI 10.1109/ICCV.2019.00428; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Ren HY, 2017, IEEE COMPUT SOC CONF, P1050, DOI 10.1109/CVPRW.2017.142; Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Singh A, 2014, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2014.364; Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683; Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070; Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50; Zeyde Roman, 2010, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47; Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI [10.1007/978-3-030-01234-2_18, 10.1007/978-3-030-01240-3_22]; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262	56	52	52	49	91	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1192	1204		10.1109/TPAMI.2020.3021088	http://dx.doi.org/10.1109/TPAMI.2020.3021088			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32877331	Green Submitted			2022-12-18	WOS:000752018000010
J	Liu, XW; Li, MM; Tang, C; Xia, JY; Xiong, J; Liu, L; Kloft, M; Zhu, E				Liu, Xinwang; Li, Miaomiao; Tang, Chang; Xia, Jingyuan; Xiong, Jian; Liu, Li; Kloft, Marius; Zhu, En			Efficient and Effective Regularized Incomplete Multi-View Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiple kernel clustering; multiple view learning; incomplete kernel learning		Incomplete multi-view clustering (IMVC) optimally combines multiple pre-specified incomplete views to improve clustering performance. Among various excellent solutions, the recently proposed multiple kernel k-means with incomplete kernels (MKKM-IK) forms a benchmark, which redefines IMVC as a joint optimization problem where the clustering and kernel matrix imputation tasks are alternately performed until convergence. Though demonstrating promising performance in various applications, we observe that the manner of kernel matrix imputation in MKKM-IK would incur intensive computational and storage complexities, over-complicated optimization and limitedly improved clustering performance. In this paper, we first propose an Efficient and Effective Incomplete Multi-view Clustering (EE-IMVC) algorithm to address these issues. Instead of completing the incomplete kernel matrices, EE-IMVC proposes to impute each incomplete base matrix generated by incomplete views with a learned consensus clustering matrix. Moreover, we further improve this algorithm by incorporating prior knowledge to regularize the learned consensus clustering matrix. Two three-step iterative algorithms are carefully developed to solve the resultant optimization problems with linear computational complexity, and their convergence is theoretically proven. After that, we theoretically study the generalization bound of the proposed algorithms. Furthermore, we conduct comprehensive experiments to study the proposed algorithms in terms of clustering accuracy, evolution of the learned consensus clustering matrix and the convergence. As indicated, our algorithms deliver their effectiveness by significantly and consistently outperforming some state-of-the-art ones.	[Liu, Xinwang; Zhu, En] Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China; [Li, Miaomiao] Changsha Coll, Dept Comp, Changsha 410073, Hunan, Peoples R China; [Tang, Chang] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China; [Xia, Jingyuan] Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England; [Xiong, Jian] Southwestern Univ Finance & Econ, Sch Business Adm, Chengdu 611130, Sichuan, Peoples R China; [Liu, Li] Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Hunan, Peoples R China; [Liu, Li] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu 90014, Finland; [Kloft, Marius] Tech Univ Kaiserslautern, Dept Comp Sci, D-67653 Kaiserslautern, Germany	National University of Defense Technology - China; China University of Geosciences; Imperial College London; Southwestern University of Finance & Economics - China; National University of Defense Technology - China; University of Oulu; University of Kaiserslautern	Liu, XW (corresponding author), Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.	xinwangliu@nudt.edu.cn; miaomiaolinudt@gmail.com; tangchang@cug.edu.cn; j.xia16@imperial.ac.uk; xiongjian2017@swufe.edu.cn; li.liu@oulu.fi; kloft@cs.uni-kl.de; enzhu@nudt.edu.cn	Xia, Jingyuan/ABE-7885-2021; Tang, Chang/AAU-8995-2020	Tang, Chang/0000-0002-6515-7696	Natural Science Foundation of China [61773392, 61922088, 61701451]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the Natural Science Foundation of China (project no. 61773392, 61922088 and 61701451).	Bhadra S, 2017, MACH LEARN, V106, P713, DOI 10.1007/s10994-016-5618-0; Bickel S, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P19, DOI 10.1109/ICDM.2004.10095; Cai X., 2013, P 23 INT JOINT C ART, P2598, DOI DOI 10.5555/2540128.2540503; Damoulas T, 2008, BIOINFORMATICS, V24, P1264, DOI 10.1093/bioinformatics/btn112; Du L, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3476; Ghahramani Z., 1993, ADV NEURAL INFORM PR, P120; Gonen M., 2014, NIPS, P1305; Kato T., 2017, ARXIV170204077V2; Kumar R, 2013, I S BIOMED IMAGING, P764; Li M., 2016, IJCAI, P1704; Li SY, 2014, AAAI CONF ARTIF INTE, P1968; Li YQ, 2015, AAAI CONF ARTIF INTE, P2750; Liu J., 2013, IJCAI; Liu TL, 2016, NEURAL COMPUT, V28, P2213, DOI 10.1162/NECO_a_00872; Liu XL, 2019, PLANT SIGNAL BEHAV, V14, DOI 10.1080/15592324.2019.1640562; Liu XW, 2019, IEEE T PATTERN ANAL, V41, P2410, DOI 10.1109/TPAMI.2018.2879108; Liu XW, 2017, AAAI CONF ARTIF INTE, P2266; Liu XW, 2017, AAAI CONF ARTIF INTE, P2259; Liu XW, 2016, AAAI CONF ARTIF INTE, P1888; Lovasz L., 1986, MATCHING THEORY; Maurer A, 2010, IEEE T INFORM THEORY, V56, P5839, DOI 10.1109/TIT.2010.2069250; Nilsback M-E., 2006, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2006., DOI 10.1109/CVPR.2006.42]; Rai P., 2010, P NEURAL INFORM PROC, P1; Shao WX, 2015, LECT NOTES ARTIF INT, V9284, P318, DOI 10.1007/978-3-319-23528-8_20; Tao Z., 2017, P 26 INT JOINT C ART, P2843; Tao ZQ, 2017, AAAI CONF ARTIF INTE, P1546; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Xiang S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P185; Xu C, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2490539; Yan F, 2012, J MACH LEARN RES, V13, P607; Yin Q., 2015, PROC 24 ACM INT C IN, P383; Yu S, 2012, IEEE T PATTERN ANAL, V34, P1031, DOI 10.1109/TPAMI.2011.255; Zhang RZ, 2015, IEEE I CONF COMP VIS, P2084, DOI 10.1109/ICCV.2015.241; Zhu XZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3271	34	52	52	16	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2634	2646		10.1109/TPAMI.2020.2974828	http://dx.doi.org/10.1109/TPAMI.2020.2974828			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32086196	Green Accepted			2022-12-18	WOS:000670578800009
J	Zeng, XY; Ouyang, WL; Yan, JJ; Li, HS; Xiao, T; Wang, K; Liu, Y; Zhou, YC; Yang, B; Wang, Z; Zhou, H; Wang, XG				Zeng, Xingyu; Ouyang, Wanli; Yan, Junjie; Li, Hongsheng; Xiao, Tong; Wang, Kun; Liu, Yu; Zhou, Yucong; Yang, Bin; Wang, Zhe; Zhou, Hui; Wang, Xiaogang			Crafting GBD-Net for Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional neural network; CNN; deep learning; deep model; object detection		The visual cues from multiple support regions of different sizes and resolutions are complementary in classifying a candidate box in object detection. Effective integration of local and contextual visual cues from these regions has become a fundamental problem in object detection. In this paper, we propose a gated bi-directional CNN (GBD-Net) to pass messages among features from different support regions during both feature learning and feature extraction. Such message passing can be implemented through convolution between neighboring support regions in two directions and can be conducted in various layers. Therefore, local and contextual visual patterns can validate the existence of each other by learning their nonlinear relationships and their close interactions are modeled in a more complex way. It is also shown that message passing is not always helpful but dependent on individual samples. Gated functions are therefore needed to control message transmission, whose on-or-offs are controlled by extra visual evidence from the input sample. The effectiveness of GBD-Net is shown through experiments on three object detection datasets, ImageNet, Pascal VOC2007 and Microsoft COCO. Besides the GBD-Net, this paper also shows the details of our approach in winning the ImageNet object detection challenge of 2016, with source code provided on https://github.com/craftGBD/craftGBD. In this winning system, the modified GBD-Net, new pretraining scheme and better region proposal designs are provided. We also show the effectiveness of different network structures and existing techniques for object detection, such as multi-scale testing, left-right flip, bounding box voting, NMS, and context.	[Zeng, Xingyu] Chinese Univ Hong Kong, Shatin, Hong Kong, Peoples R China; [Zeng, Xingyu; Yan, Junjie; Liu, Yu; Zhou, Yucong; Yang, Bin] Sensetime Grp Ltd, Shatin, Hong Kong, Peoples R China; [Ouyang, Wanli] Univ Sydney, Sch Elect & Informat Engn, Camperdown, NSW 2006, Australia; [Ouyang, Wanli; Li, Hongsheng; Xiao, Tong; Wang, Kun; Wang, Zhe; Zhou, Hui; Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong; University of Sydney; Chinese University of Hong Kong	Ouyang, WL (corresponding author), Univ Sydney, Sch Elect & Informat Engn, Camperdown, NSW 2006, Australia.; Ouyang, WL (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.	xyzeng@ee.cuhk.edu.hk; wlouyang@ee.cuhk.edu.hk; yanjunjie@outlook.com; hsli@ee.cuhk.edu.hk; xiaotong@ee.cuhk.edu.hk; kwang@ee.cuhk.edu.hk; liuyu@sensetime.com; zhouyucong@sensetime.com; yb.derek@gmail.com; zwang@ee.cuhk.edu.hk; smarthuizhou@gmail.com; xgwang@ee.cuhk.edu.hk	Zhang, Hui/HHN-8494-2022; Ouyang, Wanli/I-7135-2018	Ouyang, Wanli/0000-0002-9163-2761	SenseTime Group Limited; General Research Fund - Research Grants Council of Hong Kong [CUHK14213616, CUHK14206114, CUHK14205615, CUHK419412, CUHK14203015, CUHK14207814, CUHK14239816]; Hong Kong Innovation and Technology Support Programme [ITS/121/15FX]; National Natural Science Foundation of China [61371192]; ONR [N00014-15-1-2356]	SenseTime Group Limited; General Research Fund - Research Grants Council of Hong Kong(Hong Kong Research Grants Council); Hong Kong Innovation and Technology Support Programme; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); ONR(Office of Naval Research)	This work is supported by SenseTime Group Limited, the General Research Fund sponsored by the Research Grants Council of Hong Kong (Project Nos. CUHK14213616, CUHK14206114, CUHK14205615, CUHK419412, CUHK14203015, CUHK14207814, and CUHK14239816), the Hong Kong Innovation and Technology Support Programme (No. ITS/121/15FX), National Natural Science Foundation of China (No. 61371192), and ONR N00014-15-1-2356. Xingyu Zeng and Wanli Ouyang are equal contributors.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314; Chu X, 2016, PROC CVPR IEEE, P4715, DOI 10.1109/CVPR.2016.510; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Gidaris S., 2016, P BRIT MACHINE VISIO, p90.1; Gidaris S, 2016, PROC CVPR IEEE, P789, DOI 10.1109/CVPR.2016.92; Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641; Glorot X., 2010, PROC MACH LEARN RES, P249; He K., 2014, P EUR C COMPUT VIS; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li H., 2017, ARXIV170205711; Li HY, 2016, PR MACH LEARN RES, V48; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Ouyang WL, 2018, IEEE T PATTERN ANAL, V40, P1874, DOI 10.1109/TPAMI.2017.2738645; Ouyang WL, 2017, IEEE I CONF COMP VIS, P1956, DOI 10.1109/ICCV.2017.214; Ouyang WL, 2016, PROC CVPR IEEE, P864, DOI 10.1109/CVPR.2016.100; Ouyang WL, 2015, IEEE I CONF COMP VIS, P1895, DOI 10.1109/ICCV.2015.220; Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854; Pont-Tuset J, 2015, IEEE I CONF COMP VIS, P1546, DOI 10.1109/ICCV.2015.181; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C., 2016, P IEEE C COMP VIS PA, P2818, DOI DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Yan JJ, 2015, PROC CVPR IEEE, P5107, DOI 10.1109/CVPR.2015.7299146; Yang B, 2016, PROC CVPR IEEE, P6043, DOI 10.1109/CVPR.2016.650; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zeng X., 2015, ARXIV151202736; Zeng XY, 2016, LECT NOTES COMPUT SC, V9911, P354, DOI 10.1007/978-3-319-46478-7_22; Zhang YT, 2015, PROC CVPR IEEE, P249, DOI 10.1109/CVPR.2015.7298621; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	49	52	57	3	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2109	2123		10.1109/TPAMI.2017.2745563	http://dx.doi.org/10.1109/TPAMI.2017.2745563			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28858785	Green Submitted			2022-12-18	WOS:000440868400006
J	Best-Rowden, L; Jain, AK				Best-Rowden, Lacey; Jain, Anil K.			Longitudinal Study of Automatic Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; facial aging; longitudinal study; mixed-effects models; multilevel models; random effects	PERFORMANCE; ALGORITHM	The two underlying premises of automatic face recognition are uniqueness and permanence. This paper investigates the permanence property by addressing the following: Does face recognition ability of state-of-the-art systems degrade with elapsed time between enrolled and query face images? If so, what is the rate of decline w.r.t. the elapsed time? While previous studies have reported degradations in accuracy, no formal statistical analysis of large-scale longitudinal data has been conducted. We conduct such an analysis on two mugshot databases, which are the largest facial aging databases studied to date in terms of number of subjects, images per subject, and elapsed times. Mixed-effects regression models are applied to genuine similarity scores from state-of-the-art COTS face matchers to quantify the population-mean rate of change in genuine scores over time, subject-specific variability, and the influence of age, sex, race, and face image quality. Longitudinal analysis shows that despite decreasing genuine scores, 99% of subjects can still be recognized at 0.01% FAR up to approximately 6 years elapsed time, and that age, sex, and race only marginally influence these trends. The methodology presented here should be periodically repeated to determine age-invariant properties of face recognition as state-of-the-art evolves to better address facial aging.	[Best-Rowden, Lacey; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Best-Rowden, L (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	bestrow1@cse.msu.edu; jain@cse.msu.edu						Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01; Begg MD, 2003, STAT MED, V22, P2591, DOI 10.1002/sim.1524; Bell A, 2015, POLIT SCI RES METH, V3, P133, DOI 10.1017/psrm.2014.7; Bereta M, 2013, PATTERN RECOGN, V46, P2634, DOI 10.1016/j.patcog.2013.03.010; Best-Rowden L, 2015, INT CONF BIOMETR, P214, DOI 10.1109/ICB.2015.7139087; Beveridge JR, 2009, COMPUT VIS IMAGE UND, V113, P750, DOI 10.1016/j.cviu.2008.12.007; Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374; Doddington G., 1998, P INT C SPOK LANG PR; Erbilek M., 2012, P ACM C MULT SEC SEP, P115; Fitzmaurice GM., 2011, APPL LONGITUDINAL AN, V2nd; Gong DH, 2013, IEEE I CONF COMP VIS, P2872, DOI 10.1109/ICCV.2013.357; Grother P., 2014, 8009 NISTIR; Grother P., 2013, 7948 NISTIR; Juefei-Xu F., 2011, INT JOINT C BIOMETRI, P1, DOI 10.1109/IJCB.2011.6117600; Klare B., 2011, INT JOINT C BIOM IJC, P1; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; Ling HB, 2010, IEEE T INF FOREN SEC, V5, P82, DOI 10.1109/TIFS.2009.2038751; Lui YM, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P139; Neuhaus JM, 1998, BIOMETRICS, V54, P638, DOI 10.2307/3109770; Otto C, 2012, LECT NOTES COMPUT SC, V7584, P189, DOI 10.1007/978-3-642-33868-7_19; Panis G., 2015, I ENG TECHNOL BI MAY; Poh N, 2015, IET BIOMETRICS, V4, P236, DOI 10.1049/iet-bmt.2014.0107; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Singh J. K., 2003, Artificial breeding and reproduction management in buffaloes: compendium of the lectures delivered in the Indian Council of Agricultural Research, Summer School, Central Institute for Research on Buffaloes, Sirsa Road, Hisar, Haryana, India, 10-30 June 2003, P127; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; van der Leeden R., 1997, P MULT C; Wang D., 2015, FACE SEARCH SCALE 80; Yadav D., 2016, P IEEE WINT C APPL C, P1; Yager N, 2010, IEEE T PATTERN ANAL, V32, P220, DOI 10.1109/TPAMI.2008.291; Yoon S, 2015, P NATL ACAD SCI USA, V112, P8555, DOI 10.1073/pnas.1410272112	30	52	55	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					148	162		10.1109/TPAMI.2017.2652466	http://dx.doi.org/10.1109/TPAMI.2017.2652466			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28092523				2022-12-18	WOS:000417806000012
J	Rivera, AR; Chae, O				Ramirez Rivera, Adin; Chae, Oksam			Spatiotemporal Directional Number Transitional Graph for Dynamic Texture Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Directional number; dynamic texture; facial expression; spatiotemporal descriptors; transitional graph	BINARY PATTERNS	Spatiotemporal image descriptors are gaining attention in the image research community for better representation of dynamic textures. In this paper, we introduce a dynamic-micro-texture descriptor, i.e., spatiotemporal directional number transitional graph (DNG), which describes both the spatial structure and motion of each local neighborhood by capturing the direction of natural flow in the temporal domain. We use the structure of the local neighborhood, given by its principal directions, and compute the transition of such directions between frames. Moreover, we present the statistics of the direction transitions in a transitional graph, which acts as a signature for a given spatiotemporal region in the dynamic texture. Furthermore, we create a sequence descriptor by dividing the spatiotemporal volume into several regions, computing a transitional graph for each of them, and represent the sequence as a set of graphs. Our results validate the robustness of the proposed descriptor in different scenarios for expression recognition and dynamic texture analysis.	[Ramirez Rivera, Adin] Univ Diego Portales, Escuela Informat & Telecomunicac, Santiago, Chile; [Chae, Oksam] Kyung Hee Univ, Dept Comp Engn, Yongin, South Korea	University Diego Portales; Kyung Hee University	Rivera, AR (corresponding author), Univ Diego Portales, Escuela Informat & Telecomunicac, Santiago, Chile.	adin.ramirez@mail.udp.cl; oschae@khu.ac.kr	Ramírez Rivera, Adín/L-9388-2016	Ramírez Rivera, Adín/0000-0002-4321-9075	CONICYT, under FONDECYT [11130098]; Technological Innovation R&D Program - Small and Medium Business Administration (SMBA, Korea) [S2176380]	CONICYT, under FONDECYT(Comision Nacional de Investigacion Cientifica y Tecnologica (CONICYT)CONICYT FONDECYT); Technological Innovation R&D Program - Small and Medium Business Administration (SMBA, Korea)	This work was supported by a grant funded by CONICYT, under FONDECYT Iniciacion No. 11130098, and by the Technological Innovation R&D Program (S2176380) funded by the Small and Medium Business Administration (SMBA, Korea). Dr. Adin Ramirez Rivera is the corresponding author.	Castillo JAR, 2012, IEEE IMAGE PROC, P2613, DOI 10.1109/ICIP.2012.6467434; Chetverikov D, 2005, ADV SOFT COMP, P17; Derpanis KG, 2010, PROC CVPR IEEE, P191, DOI 10.1109/CVPR.2010.5540213; Ghanem B, 2010, LECT NOTES COMPUT SC, V6312, P223; Guo YM, 2012, LECT NOTES COMPUT SC, V7573, P631, DOI 10.1007/978-3-642-33709-3_45; Huang XH, 2012, IEEE SIGNAL PROC LET, V19, P243, DOI 10.1109/LSP.2012.2188890; Jeni L. A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2168, DOI 10.1109/ICCVW.2011.6130516; Jetto L., 1999, P 7 IEEE MED C CONTR, P2161; Ji Y, 2012, PATTERN RECOGN LETT, V33, P1373, DOI 10.1016/j.patrec.2012.03.006; Kabir Md Hasanul, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P526, DOI 10.1109/AVSS.2010.9; KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6; LU Z, 2005, IEEE WORKSH MOT VID, V2, P241; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Norouznezhad E, 2012, LECT NOTES COMPUT SC, V7574, P736, DOI 10.1007/978-3-642-33712-3_53; Paivarinta J, 2011, LECT NOTES COMPUT SC, V6688, P360, DOI 10.1007/978-3-642-21227-7_34; Peteri R, 2005, LECT NOTES COMPUT SC, V3523, P223; Ramirez Rivera A, 2012, INT C PATT RECOG, P1000; Ravichandran A, 2013, IEEE T PATTERN ANAL, V35, P342, DOI 10.1109/TPAMI.2012.83; Ravichandran A, 2009, PROC CVPR IEEE, P1651, DOI 10.1109/CVPRW.2009.5206847; Rivera AR, 2012, IEEE IMAGE PROC, P2609, DOI 10.1109/ICIP.2012.6467433; Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848; Saisan P, 2001, PROC CVPR IEEE, P58; Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005; Valstar M., 2010, P 3 INT WORKSH EMOTI, P65; Xu Y, 2011, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2011.6126372; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhang WC, 2009, PATTERN ANAL APPL, V12, P301, DOI 10.1007/s10044-008-0123-0; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739; Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002; Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974	31	52	52	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					2146	2152		10.1109/TPAMI.2015.2392774	http://dx.doi.org/10.1109/TPAMI.2015.2392774			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26340258	hybrid			2022-12-18	WOS:000360813400015
J	Xu, ZL; Yan, F; Qi, Y				Xu, Zenglin; Yan, Feng; Qi, Yuan			Bayesian Nonparametric Models for Multiway Data Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiway analysis; network modeling; Gaussian process; tensor/matrix factorization; stochastic blockmodel; nonparametric Bayes; random graphs and exchangeable arrays	NETWORK	Tensor decomposition is a powerful computational tool for multiway data analysis. Many popular tensor decomposition approaches-such as the Tucker decomposition and CANDECOMP/ PARAFAC (CP)-amount to multi-linear factorization. They are insufficient to model (i) complex interactions between data entities, (ii) various data types (e.g., missing data and binary data), and (iii) noisy observations and outliers. To address these issues, we propose tensor-variate latent nonparametric Bayesian models for multiway data analysis. We name these models InfTucker. These new models essentially conduct Tucker decomposition in an infinite feature space. Unlike classical tensor decomposition models, our new approaches handle both continuous and binary data in a probabilistic framework. Unlike previous Bayesian models on matrices and tensors, our models are based on latent Gaussian or t processes with nonlinear covariance functions. Moreover, on network data, our models reduce to nonparametric stochastic blockmodels and can be used to discover latent groups and predict missing interactions. To learn the models efficiently from data, we develop a variational inference technique and explore properties of the Kronecker product for computational efficiency. Compared with a classical variational implementation, this technique reduces both time and space complexities by several orders of magnitude. On real multiway and network data, our new models achieved significantly higher prediction accuracy than state-of-art tensor decomposition methods and blockmodels.	[Xu, Zenglin] Univ Elect Sci & Technol China, Sch Comp Sci & Technol, Chengdu 610051, Peoples R China; [Yan, Feng] Facebook Inc, Menlo Pk, CA 94025 USA; [Qi, Yuan] Purdue Univ, Dept Comp Sci & Dept Stat, W Lafayette, IN 47907 USA	University of Electronic Science & Technology of China; Facebook Inc; Purdue University System; Purdue University; Purdue University West Lafayette Campus	Xu, ZL (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Technol, Chengdu 610051, Peoples R China.	zenglin@gmail.com; yan12@purdue.edu; alanqi@cs.purdue.edu			Div Of Electrical, Commun & Cyber Sys [0941533] Funding Source: National Science Foundation	Div Of Electrical, Commun & Cyber Sys(National Science Foundation (NSF)NSF - Directorate for Engineering (ENG))		Acar E, 2011, CHEMOMETR INTELL LAB, V106, P41, DOI 10.1016/j.chemolab.2010.08.004; Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; ALBERT JH, 1993, J AM STAT ASSOC, V88, P669, DOI 10.2307/2290350; ALDOUS DJ, 1981, J MULTIVARIATE ANAL, V11, P581, DOI 10.1016/0047-259X(81)90099-3; Butland G, 2005, NATURE, V433, P531, DOI 10.1038/nature03239; Chen B, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-552; Chu W, 2005, J MACH LEARN RES, V6, P1019; Chu W., 2009, P 12 INT C AISTATS C; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; Ding N., 2010, J MACHINE LEARNING R, V9, P169; Globerson A, 2007, J MACH LEARN RES, V8, P2265; Gupta A. K., 1999, MATRIX VARIATE DISTR; Harshman R.A., 1970, MULTIMODAL FACTOR AN; Hoff P., 2007, ADV NEURAL INFORM PR, V20; Hoff PD, 2002, J AM STAT ASSOC, V97, P1090, DOI 10.1198/016214502388618906; Hoff PD, 2011, COMPUT STAT DATA AN, V55, P530, DOI 10.1016/j.csda.2010.05.020; KEMP C, 2004, 2004019 MIT AI; Kemp C., 2006, P 21 AAAI; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Lauritzen S. L., 2006, P BRUN FIN CENT C; LAWRENCE N, 2005, P NIPS; Lawrence N.D., 2009, P 26 ANN INT C MACHI, P601, DOI DOI 10.1145/1553374.1553452; LAWRENCE ND, 2004, P NIPS; Lloyd J. R., 2012, P ADV NEURAL INFORM, P1007; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; Miller Kurt T., 2009, NONPARAMETRIC LATENT, P1276; Paisley J, 2009, IEEE T SIGNAL PROCES, V57, P3905, DOI 10.1109/TSP.2009.2024987; Palla K., 2012, P 29 ICML ED UK; Porteous I., 2008, P 22 AAAI; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Saatci Y., 2011, THESIS U CAMBRIDGE C; Schmidt M., 2010, THESIS UBC VANCOUVER; Shashua A., 2005, P 22 ICML BONN GERM; Snijders TAB, 1997, J CLASSIF, V14, P75, DOI 10.1007/s003579900004; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Yan Feng, 2011, UAI, P745; Yang Y., 2013, J ROYAL STAT SOC B; Yu K., 2007, P NIPS; Zhang Y, 2009, ACM SIGCOMM COMP COM, V39, P267, DOI 10.1145/1594977.1592600	40	52	54	0	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					475	487		10.1109/TPAMI.2013.201	http://dx.doi.org/10.1109/TPAMI.2013.201			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353255				2022-12-18	WOS:000349625500020
J	Yang, X; Feng, JJ; Zhou, J				Yang, Xiao; Feng, Jianjiang; Zhou, Jie			Localized Dictionaries Based Orientation Field Estimation for Latent Fingerprints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fingerprint enhancement; latent fingerprint matching; orientation field; dictionary; pose estimation; Hough transform; Markov random field	OBJECT DETECTION; MODEL; ENHANCEMENT; COMPUTATION; EXTRACTION; ALGORITHM; POINTS; ROBUST	Dictionary based orientation field estimation approach has shown promising performance for latent fingerprints. In this paper, we seek to exploit stronger prior knowledge of fingerprints in order to further improve the performance. Realizing that ridge orientations at different locations of fingerprints have different characteristics, we propose a localized dictionaries-based orientation field estimation algorithm, in which noisy orientation patch at a location output by a local estimation approach is replaced by real orientation patch in the local dictionary at the same location. The precondition of applying localized dictionaries is that the pose of the latent fingerprint needs to be estimated. We propose a Hough transform-based fingerprint pose estimation algorithm, in which the predictions about fingerprint pose made by all orientation patches in the latent fingerprint are accumulated. Experimental results on challenging latent fingerprint datasets show the proposed method outperforms previous ones markedly.	[Yang, Xiao; Feng, Jianjiang; Zhou, Jie] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Tsinghua University	Yang, X (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	xiao-yang09@mails.tsinghua.edu.cn; jfeng@tsinghua.edu.cn; jzhou@tsinghua.edu.cn		Yang, Xiao/0000-0003-1105-6686	National Natural Science Foundation of China [61005023, 61373074, 61225008, 61020106004]; National Basic Research Program of China [2014CB349304]; Ministry of Education of China [20120002110033]; Tsinghua University Initiative Scientific Research Program	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China); Ministry of Education of China(Ministry of Education, China); Tsinghua University Initiative Scientific Research Program	This work is supported by the National Natural Science Foundation of China under Grants 61005023, 61373074, 61225008 and 61020106004, the National Basic Research Program of China under Grant 2014CB349304, the Ministry of Education of China under Grant 20120002110033, and the Tsinghua University Initiative Scientific Research Program.	[Anonymous], 12011 ANSI NIST ITL; Areekul V, 2006, INT C PATT RECOG, P497; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79; Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433; Blake A, 2011, MARKOV RANDOM FIELDS FOR VISION AND IMAGE PROCESSING, P1; Candela GT, 1995, 5647 NIST; Cappelli R., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1144, DOI 10.1109/ICPR.2010.286; Cappelli R, 2011, IEEE T SYST MAN CY B, V41, P1511, DOI 10.1109/TSMCB.2011.2155648; Cappelli R, 2009, IEEE T PATTERN ANAL, V31, P742, DOI 10.1109/TPAMI.2008.243; Champod C., 2017, FINGERPRINTS OTHER R, P136; Chen FL, 2011, IEEE T INF FOREN SEC, V6, P346, DOI 10.1109/TIFS.2011.2114345; Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036; Dass SC, 2004, IEEE T IMAGE PROCESS, V13, P1358, DOI 10.1109/TIP.2004.834659; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Dvornychenko V. N., 2006, 7377 NIST; Feng JJ, 2013, IEEE T PATTERN ANAL, V35, P925, DOI 10.1109/TPAMI.2012.155; Feng JJ, 2012, IEEE T INF FOREN SEC, V7, P1498, DOI 10.1109/TIFS.2012.2204254; Gu JW, 2006, IEEE T IMAGE PROCESS, V15, P1952, DOI 10.1109/TIP.2006.873443; Gu JW, 2004, PATTERN RECOGN, V37, P543, DOI 10.1016/S0031-3203(03)00178-X; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; Hou ZJ, 2012, PATTERN RECOGN, V45, P1915, DOI 10.1016/j.patcog.2011.11.003; Huckemann S, 2008, IEEE T PATTERN ANAL, V30, P1507, DOI 10.1109/TPAMI.2007.70826; Indovina M., 2009, 7577 NIST; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531; Jain AK, 2011, IEEE T PATTERN ANAL, V33, P88, DOI 10.1109/TPAMI.2010.59; Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242; Jirachaweng S, 2011, PATTERN RECOGN, V44, P431, DOI 10.1016/j.patcog.2010.08.019; Kamei T, 2004, AUTOMATIC FINGERPRINT RECOGNITION SYSTEMS, P113, DOI 10.1007/0-387-21685-5_6; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; Kaufman L., 1990, FINDING GROUPS DATA; Kucken M, 2005, J THEOR BIOL, V235, P71, DOI 10.1016/j.jtbi.2004.12.020; KUKICH K, 1992, COMPUT SURV, V24, P377; Lee KC, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P41, DOI 10.1109/BSYM.2008.4655521; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Li J, 2006, PATTERN RECOGN, V39, P102, DOI 10.1016/j.patcog.2005.08.010; Li S, 2009, MARKOV RANDOM FIELD; Liu MH, 2007, PATTERN RECOGN, V40, P1793, DOI 10.1016/j.patcog.2006.11.007; Liu MH, 2005, EURASIP J APPL SIG P, V2005, P498, DOI 10.1155/ASP.2005.498; Lo P. Z., 2007, U.S. Patent, Patent No. [11/456 622, 11456622]; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S, 2009, PROC CVPR IEEE, P1038, DOI 10.1109/CVPRW.2009.5206693; Maltoni D., 2009, HDB FINGERPRINT RECO; MEHTRE BM, 1987, PATTERN RECOGN, V20, P429, DOI 10.1016/0031-3203(87)90069-0; Neurotechnology Inc, VERIFINGER; Nilsson K, 2003, PATTERN RECOGN LETT, V24, P2135, DOI 10.1016/S0167-8655(03)00083-7; Novikov SO, 1998, P SOC PHOTO-OPT INS, V3346, P259, DOI 10.1117/12.301375; OGORMAN L, 1989, PATTERN RECOGN, V22, P29, DOI 10.1016/0031-3203(89)90035-6; Oliveira MA, 2008, PATTERN RECOGN, V41, P367, DOI 10.1016/j.patcog.2007.05.019; Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575; Ram S, 2010, PATTERN RECOGN, V43, P342, DOI 10.1016/j.patcog.2009.04.023; RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3; Rerkrai K, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P499, DOI 10.1109/ICIP.2000.899465; SHERLOCK BG, 1994, IEE P-VIS IMAGE SIGN, V141, P87, DOI 10.1049/ip-vis:19949924; SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I; Turroni F., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P152, DOI 10.1109/ICB.2012.6199773; Turroni F, 2011, IEEE T INF FOREN SEC, V6, P1002, DOI 10.1109/TIFS.2011.2150216; Wang Y, 2007, IEEE T PATTERN ANAL, V29, P573, DOI 10.1109/TPAMI.2007.1003; Watson C., 2009, 7553 NIST; Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883; Yoon S., 2010, P SPIE; Yoon S., 2011, P IJCB WASH DC US, P1; Zhao QJ, 2012, IEEE T INF FOREN SEC, V7, P904, DOI 10.1109/TIFS.2012.2187281; Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608	66	52	56	2	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					955	969		10.1109/TPAMI.2013.184	http://dx.doi.org/10.1109/TPAMI.2013.184			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353229				2022-12-18	WOS:000336054200010
J	Cui, Y; Schuon, S; Thrun, S; Stricker, D; Theobalt, C				Cui, Yan; Schuon, Sebastian; Thrun, Sebastian; Stricker, Didier; Theobalt, Christian			Algorithms for 3D Shape Scanning with a Depth Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Superresolution; global alignment; rigid transformation; nonrigid transformation; 3D scanning; time-of-flight; Kinect	RECONSTRUCTION; REGISTRATION; STEREO	We describe a method for 3D object scanning by aligning depth scans that were taken from around an object with a Time-of-Flight (ToF) camera. These ToF cameras can measure depth scans at video rate. Due to comparably simple technology, they bear potential for economical production in big volumes. Our easy-to-use, cost-effective scanning solution, which is based on such a sensor, could make 3D scanning technology more accessible to everyday users. The algorithmic challenge we face is that the sensor's level of random noise is substantial and there is a nontrivial systematic bias. In this paper, we show the surprising result that 3D scans of reasonable quality can also be obtained with a sensor of such low data quality. Established filtering and scan alignment techniques from the literature fail to achieve this goal. In contrast, our algorithm is based on a new combination of a 3D superresolution method with a probabilistic scan alignment approach that explicitly takes into account the sensor's noise characteristics.	[Cui, Yan; Stricker, Didier] German Res Ctr Artificial Intelligence, D-67663 Kaiserslautern, Germany; [Schuon, Sebastian] Stylight GmbH, D-80636 Munich, Germany; [Thrun, Sebastian] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Theobalt, Christian] MPI Informat, D-66123 Saarbrucken, Germany	Stanford University; Max Planck Society	Cui, Y (corresponding author), German Res Ctr Artificial Intelligence, Trippstadter Str 122, D-67663 Kaiserslautern, Germany.	Yan.Cui@dfki.de; sebastian.schuon@stylight.de; thrun@stanford.edu; Didier.Stricker@dfki.de; theobalt@mpii.de						ANDERSON D, 2005, P INT C SENS TECHN; Basri R, 2001, PROC CVPR IEEE, P374; Beder C, 2007, LECT NOTES COMPUT SC, V4713, P11; BENJEMAA R, 1998, P 5 EUR C COMP VIS E, V2, P34; Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bouguet JY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P43, DOI 10.1109/ICCV.1998.710699; Brown BJ, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239472; Cui Y., 2009, P GRAVISMA WORKSH; Cui Y., 2011, P ACM SIGGRAPH; Cui Y, 2010, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2010.5540082; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Diebel JR, 2006, ACM T GRAPHIC, V25, P39, DOI 10.1145/1122501.1122504; Erz M, 2009, LECT NOTES COMPUT SC, V5742, P28, DOI 10.1007/978-3-642-03778-8_3; Furukawa Yasutaka, 2007, P IEEE C COMP VIS PA; Hahne U, 2009, LECT NOTES COMPUT SC, V5742, P70, DOI 10.1007/978-3-642-03778-8_6; Huang QX, 2006, ACM T GRAPHIC, V25, P569, DOI 10.1145/1141911.1141925; Izadi S., 2011, P ACM S US INT SOFTW; Jenke P, 2006, COMPUT GRAPH FORUM, V25, P379, DOI 10.1111/j.1467-8659.2006.00957.x; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Kil Y. J., 2006, P EUR S POINT BAS GR; KIM YM, 2009, P IEEE WORKSH 3 D DI; Kolb A., 2009, P EUROGRAPHICS C; Kutulakos Kiriakos N., 1998, TECHNICAL REPORT, P2; Lange Robert, 2000, 3D TIME FLIGHT DISTA; Lanman D., 2009, ACM SIGGRAPH 2009 CO, P1; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Lindner M, 2010, COMPUT VIS IMAGE UND, V114, P1318, DOI 10.1016/j.cviu.2009.11.002; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; Murray R. M., 1994, MATH INTRO ROBOTIC M; Myronenko A., 2007, ADV NEURAL INFORM PR, V19, P1009, DOI DOI 10.1109/TPAMI.20; Newcombe R.A., 2011, P IEEE INT C COMP VI; Newcombe RA, 2010, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2010.5539794; Rajagopalan AN, 2008, LECT NOTES COMPUT SC, V5096, P304, DOI 10.1007/978-3-540-69321-5_31; Reynolds M., 2011, P IEEE C COMP VIS PA; ROBERT L, 1996, P EUR C COMP VIS; Rosenhahn B., 2003, THESIS U KIEL; Rusinkiewicz S, 2002, ACM T GRAPHIC, V21, P438, DOI 10.1145/566570.566600; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Schuon S., 2009, P IEEE C COMP VIS PA; Vogiatzis G, 2010, STUD COMPUT INTELL, V285, P313; Weickert J., 2006, VISUALIZATION PROCES; Wu C., 2011, P IEEE C COMP VIS PA; Young Min Kim, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563160; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhu J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587761	46	52	56	0	100	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1039	1050		10.1109/TPAMI.2012.190	http://dx.doi.org/10.1109/TPAMI.2012.190			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520250				2022-12-18	WOS:000316126800002
J	Czaja, W; Ehler, M				Czaja, Wojciech; Ehler, Martin			Schroedinger Eigenmaps for the Analysis of Biomedical Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Schroedinger Eigenmaps; Laplacian Eigenmaps; Schroedinger operator on a graph; barrier potential; dimension reduction; manifold learning	DIMENSIONALITY REDUCTION; BRUCHS MEMBRANE; DRUSEN; REGULARIZATION; DIAGNOSIS; TOOL	We introduce Schroedinger Eigenmaps (SE), a new semi-supervised manifold learning and recovery technique. This method is based on an implementation of graph Schroedinger operators with appropriately constructed barrier potentials as carriers of labeled information. We use our approach for the analysis of standard biomedical datasets and new multispectral retinal images.	[Czaja, Wojciech] Univ Maryland, Dept Math, College Pk, MD 20742 USA; [Ehler, Martin] Helmholtz Zentrum Munchen, German Res Ctr Environm Hlth, Inst Biomath & Biometry, D-85764 Neuherberg, Germany; [Ehler, Martin] Eunice Kennedy Shriver Natl Inst Child Hlth & Hum, NIH, Sect Med Biophys, Bethesda, MD 20892 USA	University System of Maryland; University of Maryland College Park; Helmholtz Association; Helmholtz-Center Munich - German Research Center for Environmental Health; National Institutes of Health (NIH) - USA; NIH Eunice Kennedy Shriver National Institute of Child Health & Human Development (NICHD)	Czaja, W (corresponding author), Univ Maryland, Dept Math, College Pk, MD 20742 USA.	wojtek@math.umd.edu; ehlermar@mail.nih.gov			NICHD/NIH; US National Science Foundation [CBET0854233]; NGA [HM15820810009]; ONR [N000140910144]; NIH/DFG [EH 405/1-1/575910]	NICHD/NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child Health & Human Development (NICHD)); US National Science Foundation(National Science Foundation (NSF)); NGA; ONR(Office of Naval Research); NIH/DFG(German Research Foundation (DFG)United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by the Intramural Research Program of NICHD/NIH, by the US National Science Foundation (CBET0854233), by NGA (HM15820810009), by ONR (N000140910144), and by NIH/DFG (EH 405/1-1/575910). The authors also express their gratitude to Drs. R.F. Bonner, B. Brooks, E.Y. Chew, and S.M. Meyers for their assistance with acquiring and analyzing the included datasets. They also acknowledge V.N. Rajapakse and the anonymous referees for their valuable comments and suggestions that led to the improvement of this paper. The authors are grateful to the UCI Machine Learning Repository for providing the Wisconsin Breast Cancer, Cleveland Heart Disease, and Mammographic Mass datasets.	[Anonymous], 2002, LEARNING KERNELS; Aubry M., 2011, P IEEE INT C COMP VI; Bachmann CM, 2005, IEEE T GEOSCI REMOTE, V43, P441, DOI 10.1109/TGRS.2004.842292; Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M., 2002, P NEUR INF PROC SYST; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Belkin M, 2008, J COMPUT SYST SCI, V74, P1289, DOI 10.1016/j.jcss.2007.08.006; Benedetto J.J., 2009, P IEEE INT GEOSC REM; BIRD AEC, 1995, SURV OPHTHALMOL, V39, P367, DOI 10.1016/S0039-6257(05)80092-X; Bonner RF, 1997, SCIENCE, V278, P1481, DOI 10.1126/science.278.5342.1481; Bronstein A. M., 2011, ARXIV11105015V1; Brown JD, 2009, P NATL ACAD SCI USA, V106, P1462, DOI 10.1073/pnas.0812017106; Chew EY, 2009, ARCH OPHTHALMOL-CHIC, V127, P1678, DOI 10.1001/archophthalmol.2009.312; Chew EY, 2009, OPHTHALMOLOGY, V116, P297, DOI 10.1016/j.ophtha.2008.09.019; Chung F. R. K., 1997, P CBMS REGIONAL C SE, V92; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P53, DOI 10.1016/j.acha.2006.04.004; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P31, DOI 10.1016/j.acha.2005.07.005; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; Coleman HR, 2008, LANCET, V372, P1835, DOI 10.1016/S0140-6736(08)61759-6; Czaja W., 2011, RAPID POST; Delori FC, 2000, INVEST OPHTH VIS SCI, V41, P496; DETRANO R, 1989, AM J CARDIOL, V64, P304, DOI 10.1016/0002-9149(89)90524-9; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Ehler M., 2011, SPIE MED IMAGING COM, V7963; Ehler M., 2010, P 6 INT S BIOINF RES; Ehler Martin, 2011, BMC Proc, V5 Suppl 2, pS3, DOI 10.1186/1753-6561-5-S2-S3; Elter M, 2007, MED PHYS, V34, P4164, DOI 10.1118/1.2786864; Gerber S., 2007, P 24 INT C MACH LEAR, P281; Goldberg Y, 2008, J MACH LEARN RES, V9, P1909; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Hageman GS, 2001, PROG RETIN EYE RES, V20, P705, DOI 10.1016/S1350-9462(01)00010-6; Haimovici R, 2001, INVEST OPHTH VIS SCI, V42, P1592; Halevy A., 2011, THESIS U MARYLAND; Kainerstorfer JM, 2010, J BIOMED OPT, V15, DOI 10.1117/1.3463010; Kim M., 2009, P 12 INT C ART INT S; Meyers Sanford M, 2004, Trans Am Ophthalmol Soc, V102, P83; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sbeh Z.B, 2002, IEEE T MED IMAGING, V20, P1321; Sundaresan A, 2008, IEEE T PATTERN ANAL, V30, P1771, DOI 10.1109/TPAMI.2007.70823; Szlam AD, 2008, J MACH LEARN RES, V9, P1711; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Trosset M.W., 2010, TECHNICAL REPORT; von Luxburg U, 2008, ANN STAT, V36, P555, DOI 10.1214/009053607000000640; Wang L, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010329; Wilson RC, 2005, IEEE T PATTERN ANAL, V27, P1112, DOI 10.1109/TPAMI.2005.145; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; Zeeberg BR, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-4-r28; Zhu X., 2003, ICML	49	52	52	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1274	1280		10.1109/TPAMI.2012.270	http://dx.doi.org/10.1109/TPAMI.2012.270			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520264	Green Submitted			2022-12-18	WOS:000316126800019
J	Feng, YS; Lapata, M				Feng, Yansong; Lapata, Mirella			Automatic Caption Generation for News Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Caption generation; image annotation; summarization; topic models	NATURAL-LANGUAGE	This paper is concerned with the task of automatically generating captions for images, which is important for many image-related applications. Examples include video and image retrieval as well as the development of tools that aid visually impaired individuals to access pictorial information. Our approach leverages the vast resource of pictures available on the web and the fact that many of them are captioned and colocated with thematically related documents. Our model learns to create captions from a database of news articles, the pictures embedded in them, and their captions, and consists of two stages. Content selection identifies what the image and accompanying article are about, whereas surface realization determines how to verbalize the chosen content. We approximate content selection with a probabilistic image annotation model that suggests keywords for an image. The model postulates that images and their textual descriptions are generated by a shared set of latent variables (topics) and is trained on a weakly labeled dataset (which treats the captions and associated news articles as image labels). Inspired by recent work in summarization, we propose extractive and abstractive surface realization models. Experimental results show that it is viable to generate captions that are pertinent to the specific content of an image and its associated article, while permitting creativity in the description. Indeed, the output of our abstractive model compares favorably to handwritten captions and is often superior to extractive methods.	[Feng, Yansong] Peking Univ, Inst Comp Sci & Technol, 128 Zhong Guan Cun N St, Beijing 100871, Peoples R China; [Lapata, Mirella] Univ Edinburgh, Informat Forum, Inst Language Cognit & Computat, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland	Peking University; University of Edinburgh	Feng, YS (corresponding author), Peking Univ, Inst Comp Sci & Technol, 128 Zhong Guan Cun N St, Beijing 100871, Peoples R China.	fengyansong@pku.edu.cn; mlap@inf.ed.ac.uk						Abella A, 1995, Proc Annu Symp Comput Appl Med Care, P542; Ahmed A, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P39; Aker A, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1250; Banko N, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P318; Barnard K., 2002, J MACHINE LEARNING R, V3, P1107; Barnard K, 2008, INT J COMPUT VISION, V77, P199, DOI 10.1007/s11263-007-0068-6; Berg T.L., 2005, ADV NEURAL INFORM PR, V17, P137; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; Blei D. M., 2004, THESIS; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bosch A, 2007, THESIS; Boyd-Graber J., 2009, P 22 C ADV NEUR INF; BUCKLEY C, 2005, TREC EXPT EVALUATION, P53; Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPRW.2009.5206800, 10.1109/CVPR.2009.5206800]; Corio Marc, 1999, P 7 EUR WORKSH NAT L, P49; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; Elzer S, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1042; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Feng SL, 2004, PROC CVPR IEEE, P1002; Feng Y., 2008, P 46 ANN M ASS COMP, P272; Ferres L, 2006, LECT NOTES COMPUT SC, V4061, P1122; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Hede P., 2004, PROC RIAO, P306; Hodosh M., 2010, P 14 C COMP NAT LANG, P162; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Jones KS, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P1; Ju Hwang S., 2011, INT J COMPUT VISION, P1; Keller F, 2009, BEHAV RES METHODS, V41, P1, DOI 10.3758/BRM.41.1.12; Klein D, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P423, DOI 10.3115/1075096.1075150; KNESER R, 1997, P EUROSPEECH, P1971; Kojima Atsuhiro, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), P53, DOI 10.1109/ICICIC.2008.440; Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608; Lavrenko V., 2003, P 16 C ADV NEUR INF; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo J., 2009, ADV NEURAL INFORM PR, P1168; Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6; Mani Inderjeet, 2001, AUTOMATIC SUMMARIZAT, V3; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mikolajczyk K, 2003, PROC CVPR IEEE, P257; Mittal VO, 1998, COMPUT LINGUIST, V24, P431; Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097; Noreen EW, 1989, COMPUTER INTENSIVE M; Ozcan M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.29; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Pan JY, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P491, DOI 10.1109/ICDM.2004.10033; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; Salton G., 1983, INTRO MODERN INFORM; SCHMID H, 1994, P INT C NEW METH LAN; Schroff F, 2007, IEEE I CONF COMP VIS, P2120; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Snover Matthew, 2006, P ASS MACH TRANSL AM, P223; Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112; Soricut R, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P1105; Steyvers M., 2007, HDB LATENT SEMANTIC, P439; Tsai C., 2008, RECENT PATENTS COMPU, V1, P55, DOI DOI 10.2174/1874479610801010055; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; WAN S, 2005, P WORKSH US CORP NAT; Wang J., 2009, P BRIT MACH VIS C; Witbrock MJ, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P315, DOI 10.1145/312624.312748; Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411; Zhou L, 2003, P HLT NAACL 2003 TEX, P174	66	52	58	0	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					797	812		10.1109/TPAMI.2012.118	http://dx.doi.org/10.1109/TPAMI.2012.118			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22641700	Green Submitted			2022-12-18	WOS:000314931000003
J	Giannarou, S; Visentini-Scarzanella, M; Yang, GZ				Giannarou, Stamatia; Visentini-Scarzanella, Marco; Yang, Guang-Zhong			Probabilistic Tracking of Affine-Invariant Anisotropic Regions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Salient feature extraction; feature point tracking; image-guided navigation	VISUAL TRACKING; SCALE; CUES	Despite a wide range of feature detectors developed in the computer vision community over the years, direct application of these techniques to surgical navigation has shown significant difficulties due to the paucity of reliable salient features coupled with free-form tissue deformation and changing visual appearance of surgical scenes. The aim of this paper is to propose a novel probabilistic framework to track affine-invariant anisotropic regions under contrastingly different visual appearances during Minimally Invasive Surgery (MIS). The theoretical background of the affine-invariant anisotropic feature detector is presented and a real-time implementation exploiting the computational power of the GPU is proposed. An Extended Kalman Filter (EKF) parameterization scheme is used to adaptively adjust the optimal templates of the detected regions, enabling accurate identification and matching of the tracked features. For effective tracking verification, spatial context and region similarity have also been incorporated. They are used to boost the prediction of the EKF and recover potential tracking failure due to drift or false positives. The proposed framework is compared to the existing methods and their respective performance is evaluated with in vivo video sequences recorded from robotic-assisted MIS procedures, as well as real-world scenes.	[Giannarou, Stamatia; Visentini-Scarzanella, Marco; Yang, Guang-Zhong] Univ London Imperial Coll Sci Technol & Med, Hamlyn Ctr Robot Surg, London SW7 2AZ, England; [Visentini-Scarzanella, Marco] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, Commun & Signal Proc Grp, London SW7 2AZ, England	Imperial College London; Imperial College London	Giannarou, S (corresponding author), Univ London Imperial Coll Sci Technol & Med, Hamlyn Ctr Robot Surg, Bessemer Bldg,S Kensington Campus, London SW7 2AZ, England.	stamatia.giannarou@imperial.ac.uk; marcovs@imperial.ac.uk; g.z.yang@imperial.ac.uk		Giannarou, Stamatia/0000-0002-8745-1343; Visentini-Scarzanella, Marco/0000-0003-0907-8341	Engineering and Physical Sciences Research Council [DT/F003064/1] Funding Source: researchfish; EPSRC [DT/F003064/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Adam A., 2006, IEEE C COMP VIS PATT; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Birchfield ST, 2005, PROC CVPR IEEE, P1158; Bischof H., 2006, BMVC, P47; Bouguet J.Y., 2002, PYRAMIDAL IMPLEMENTA; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Dey D, 2002, IEEE T MED IMAGING, V21, P23, DOI 10.1109/42.981231; Giannarou S, 2009, I S BIOMED IMAGING, P1059, DOI 10.1109/ISBI.2009.5193238; Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104; Hager GD, 2004, PROC CVPR IEEE, P790; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Kadir T., 2004, P 8 EUR C COMP VIS P, P345; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Lindeberg T, 1997, IMAGE VISION COMPUT, V15, P415, DOI 10.1016/S0262-8856(97)01144-X; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Liu H., 2007, P IEEE INT C IM PROC, V3, P217; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B. D., 1981, INT JOINT C ART INT, P674, DOI DOI 10.5555/1623264.1623280; Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Maver J, 2010, IEEE T PATTERN ANAL, V32, P1211, DOI 10.1109/TPAMI.2009.105; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mountney P, 2008, LECT NOTES COMPUT SC, V5242, P364, DOI 10.1007/978-3-540-85990-1_44; Noonan DP, 2010, LECT NOTES COMPUT SC, V6363, P245; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; Richa R, 2010, LECT NOTES COMPUT SC, V6361, P267; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Stoyanov D, 2008, J DISP TECHNOL, V4, P491, DOI 10.1109/JDT.2008.926497; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; Wu Y, 2004, INT J COMPUT VISION, V58, P55, DOI 10.1023/B:VISI.0000016147.97880.cd; Wu Y, 2009, PROC CVPR IEEE, P33, DOI 10.1109/CVPRW.2009.5206719; Yang GZ, 1996, IMAGE VISION COMPUT, V14, P135, DOI 10.1016/0262-8856(95)01047-5; Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146	40	52	53	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					130	143		10.1109/TPAMI.2012.81	http://dx.doi.org/10.1109/TPAMI.2012.81			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22450819				2022-12-18	WOS:000311127700013
J	Jeong, Y; Nister, D; Steedly, D; Szeliski, R; Kweon, IS				Jeong, Yekeun; Nister, David; Steedly, Drew; Szeliski, Richard; Kweon, In-So			Pushing the Envelope of Modern Methods for Bundle Adjustment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; bundle adjustment; structure from motion; block-based; sparse linear solving; point iterations		In this paper, we present results and experiments with several methods for bundle adjustment, producing the fastest bundle adjuster ever published in terms of computation and convergence. From a computational perspective, the fastest methods naturally handle the block-sparse pattern that arises in a reduced camera system. Adapting to the naturally arising block-sparsity allows the use of BLAS3, efficient memory handling, fast variable ordering, and customized sparse solving, all simultaneously. We present two methods; one uses exact minimum degree ordering and block-based LDL solving and the other uses block-based preconditioned conjugate gradients. Both methods are performed on the reduced camera system. We show experimentally that the adaptation to the natural block sparsity allows both of these methods to perform better than previous methods. Further improvements in convergence speed are achieved by the novel use of embedded point iterations. Embedded point iterations take place inside each camera update step, yielding a greater cost decrease from each camera update step and, consequently, a lower minimum. This is especially true for points projecting far out on the flatter region of the robustifier. Intensive analyses from various angles demonstrate the improved performance of the presented bundler.	[Jeong, Yekeun; Nister, David; Steedly, Drew; Szeliski, Richard] Microsoft Corp, Redmond, WA 98052 USA; [Kweon, In-So] Korea Adv Inst Sci & Technol, RCV Lab, Dept Elect Engn, Taejon 305701, South Korea	Microsoft; Korea Advanced Institute of Science & Technology (KAIST)	Jeong, Y (corresponding author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.	yejeong@microsoft.com; dnister@microsoft.com; steedly@microsoft.com; szeliski@microsoft.com; iskweon@ee.kaist.ac.kr	Kweon, In So/C-2023-2011		MKE, Korea [NIPA-2011-C7000-1001-0007]; National Research Foundation; Korean government (MEST) [2011-0018250]	MKE, Korea(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea); National Research Foundation; Korean government (MEST)(Ministry of Education, Science & Technology (MEST), Republic of KoreaKorean Government)	This work was partially done while Yekeun Jeong was an intern at Microsoft Research. This work was supported by the MKE, Korea, under the Human Resources Development Program for Convergence Robot Specialists support program supervised by the NIPA (NIPA-2011-C7000-1001-0007) and a National Research Foundation grant funded by the Korean government (MEST) (No. 2011-0018250).	Agarwal S., 2009, P IEEE INT C COMP VI; Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9_3; Black M.J., 1994, P IEEE CS C COMP VIS; Brown D.C., 1976, INT ARCH PHOTOGRAMME, V21, P3; Byrod M., 2009, P BRIT MACH VIS C; Byrod M, 2010, LECT NOTES COMPUT SC, V6312, P114, DOI 10.1007/978-3-642-15552-9_9; Davis T.A, 2006, DIRECT METHODS SPARS; Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768; Engels C., 2006, P C PHOT COMP VIS SE; Eudes A., 2009, P IEEE CS C COMP VIS; Golub G. H., 2012, J HOPKINS STUDIES MA; Hartley R., 2004, ROBOTICA; Holmes S., 2009, P IEEE INT C ROB AUT; Jeong Y., 2010, P IEEE CS C COMP VIS; Klein G., 2007, 2007 6 IEEE ACM INT, P225; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; Lourakis MIA, 2005, IEEE I CONF COMP VIS, P1526; LOURAKIS MIA, 2004, 340 I COMP SCI FORTH; Mouragnon E., 2006, IEEE COMP SOC C COMP, V1, P363, DOI DOI 10.1109/CVPR.2006.236; Ni K., 2007, P IEEE INT C COMP VI; Saad Y., 2000, SOC IND APPL MATH, V2nd; Shum H.-Y., 1999, P IEEE CS C COMP VIS, P2538; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Steedly D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P996; Steedly D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P223, DOI 10.1109/ICCV.2001.937628; Triggs B., 2000, LECT NOTES COMPUTER, V1883, P298, DOI [DOI 10.1007/3-540-44480-7, DOI 10.1007/3-540-44480-7_21]	26	52	56	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1605	1617		10.1109/TPAMI.2011.256	http://dx.doi.org/10.1109/TPAMI.2011.256			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22745002				2022-12-18	WOS:000305188500012
J	Rasiwasia, N; Vasconcelos, N				Rasiwasia, Nikhil; Vasconcelos, Nuno			Holistic Context Models for Visual Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; scene classification; context; image retrieval; topic models	SCENE; OBJECTS; KERNEL; WORDS	A novel framework to context modeling based on the probability of co-occurrence of objects and scenes is proposed. The modeling is quite simple, and builds upon the availability of robust appearance classifiers. Images are represented by their posterior probabilities with respect to a set of contextual models, built upon the bag-of-features image representation, through two layers of probabilistic modeling. The first layer represents the image in a semantic space, where each dimension encodes an appearance-based posterior probability with respect to a concept. Due to the inherent ambiguity of classifying image patches, this representation suffers from a certain amount of contextual noise. The second layer enables robust inference in the presence of this noise by modeling the distribution of each concept in the semantic space. A thorough and systematic experimental evaluation of the proposed context modeling is presented. It is shown that it captures the contextual "gist" of natural images. Scene classification experiments show that contextual classifiers outperform their appearance-based counterparts, irrespective of the precise choice and accuracy of the latter. The effectiveness of the proposed approach to context modeling is further demonstrated through a comparison to existing approaches on scene classification and image retrieval, on benchmark data sets. In all cases, the proposed approach achieves superior results.	[Rasiwasia, Nikhil; Vasconcelos, Nuno] Univ Calif San Diego, Dept Elect & Comp Engn, Stat Visual Comp Lab, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Rasiwasia, N (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, Stat Visual Comp Lab, EBU 1,Room 5512,9500 Gilman Dr, La Jolla, CA 92093 USA.	nikux@ucsd.edu; nvasconcelos@ucsd.edu		Vasconcelos, Nuno/0000-0002-9024-4302				[Anonymous], 2001, P IEEE C COMP VIS PA; Bar M, 2004, NAT REV NEUROSCI, V5, P617, DOI 10.1038/nrn1476; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Barthe E, 2009, POLICE PRACT RES, V10, P255, DOI 10.1080/15614260802381067; BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X; Blei D. M., 2003, P ACM SIGIR C RES DE; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716; Cai D., 2007, P 7 IEEE INT C DAT M; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Chan A., 2005, P IEEE C COMP VIS PA, V1; Cheng H., 2009, P IEEE INT C COMP VI; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DATTA R, 2007, ACM COMPUT SURV, V39, P65; Duygulu P., 2002, P EUR C COMP VIS; Fei-Fei L, 2005, PROC CVPR IEEE, P524; FENG SL, 2004, P IEEE C COMP VIS PA; Fergus R, 2003, PROC CVPR IEEE, P264; FINK M, 2004, P NEUR INF PROC SYST; Galleguillos C., 2008, P IEEE C COMP VIS PA; Grauman K, 2007, J MACH LEARN RES, V8, P725; Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4; Hofmann T., 1999, P ACM SIGIR C RES DE; Joshi A., 2009, P IEEE C COMP VIS PA; Kivinen J., 2007, P IEEE INT C COMP VI; Lavrenko V, 2003, P ADV NEUR INF PROC; LAZEBNIK S, 2005, P IEEE C COMP VIS PA; Lim J., 2010, P IEEE INT C COMP VI; Liu J., 2009, P IEEE C COMP VIS PA; Liu J, 2007, IEEE CONF WIREL MOB; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; Magalhaes J., 2007, P ACM SIGIR C RES DE; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Oliva A, 2000, COGNITIVE PSYCHOL, V41, P176, DOI 10.1006/cogp.1999.0728; Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2; Platt JC, 2000, ADV NEUR IN, P61; Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155; Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986; RASIWASIA N, 2009, P IEEE C COMP VIS PA; RASIWASIA N, 2008, P IEEE C COMP VIS PA; Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138; Renninger LW, 2004, VISION RES, V44, P2301, DOI 10.1016/j.visres.2004.04.006; Rowley HA, 1996, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.1996.517075; Shotton J., 2007, INT J COMPUT VISION, V81, P1; Sivic J., 2005, P ICCV, P65; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Smith JR, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P445; Sudderth E., 2005, P IEEE INT C COMP VI, V2; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Torralba A., 2004, P ADV NEUR INF PROC; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52; Vasconcelos M., 2006, P IEEE C COMP VIS PA, P1001; Vasconcelos N, 2004, IEEE T SIGNAL PROCES, V52, P2322, DOI 10.1109/TSP.2004.831125; VIOLA P, 2002, INT J COMPUTER VISIO, V1; VOGEL J, 2004, P DAGM04 ANN PATT RE; Wang G, 2009, IEEE I CONF COMP VIS, P428, DOI 10.1109/ICCV.2009.5459167; Westerveld T., 2003, P ACM SIGIR C RES DE; Wolf L, 2006, INT J COMPUT VISION, V69, P251, DOI 10.1007/s11263-006-7538-0; ZHANG H, 2006, P IEEE C COMP VIS PA; Zhou X, 2009, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2009.5459435	62	52	53	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					902	917		10.1109/TPAMI.2011.175	http://dx.doi.org/10.1109/TPAMI.2011.175			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	21844625	Green Submitted			2022-12-18	WOS:000301747400006
J	Naroditsky, O; Zhou, XS; Gallier, J; Roumeliotis, SI; Daniilidis, K				Naroditsky, Oleg; Zhou, Xun S.; Gallier, Jean; Roumeliotis, Stergios I.; Daniilidis, Kostas			Two Efficient Solutions for Visual Odometry Using Directional Correspondence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; structure from motion; visual odometry; minimal problems; Groebner basis		This paper presents two new, efficient solutions to the two-view, relative pose problem from three image point correspondences and one common reference direction. This three-plus-one problem can be used either as a substitute for the classic five-point algorithm, using a vanishing point for the reference direction, or to make use of an inertial measurement unit commonly available on robots and mobile devices where the gravity vector becomes the reference direction. We provide a simple, closed-form solution and a solution based on algebraic geometry which offers numerical advantages. In addition, we introduce a new method for computing visual odometry with RANSAC and four point correspondences per hypothesis. In a set of real experiments, we demonstrate the power of our approach by comparing it to the five-point method in a hypothesize-and-test visual odometry setting.	[Naroditsky, Oleg; Gallier, Jean; Daniilidis, Kostas] Univ Penn, Dept Comp & Informat Sci, GRASP Lab, Philadelphia, PA 19104 USA; [Zhou, Xun S.; Roumeliotis, Stergios I.] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	University of Pennsylvania; University of Minnesota System; University of Minnesota Twin Cities	Naroditsky, O (corresponding author), Univ Penn, Dept Comp & Informat Sci, GRASP Lab, Levine Hall N,3330 Walnut St, Philadelphia, PA 19104 USA.	narodits@cis.upenn.edu; zhou@cs.umn.edu; jean@cis.upenn.edu; stergios@cs.umn.edu; kostas@cis.upenn.edu		Daniilidis, Kostas/0000-0003-0498-0758	US National Science Foundation (NSF) [IIS-0713260, NSF-IIP-0742304, NSF-IIP-0835714]; ARL MAST-CTA [W911NF-08-2-0004]	US National Science Foundation (NSF)(National Science Foundation (NSF)); ARL MAST-CTA	The authors are grateful for support through the following grants: US National Science Foundation (NSF)-IIS-0713260, NSF-IIP-0742304, NSF-IIP-0835714, and ARL MAST-CTA W911NF-08-2-0004.	Armstrong M., 1996, P 4 EUR C COMP VIS, P1; Bujnak M., 2008, P IEEE C COMP VIS PA; Byrod M., 2007, P 11 IEEE INT C COMP; Byrod M., 2007, P AS C COMP VIS JAN; Byrod M., 2008, P IEEE C COMP VIS PA; Byrod M, 2009, INT J COMPUT VISION, V84, P237, DOI 10.1007/s11263-009-0235-z; Cox D., 1997, UNDERGRADUATE TEXTS, DOI 10.1007/978-3-662-41154-4; Cox D. A., 2005, USING ALGEBRAIC GEOM, V185; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fraundorfer F, 2010, LECT NOTES COMPUT SC, V6314, P269, DOI 10.1007/978-3-642-15561-1_20; Hartley R., 2004, ROBOTICA; Kalantari M., 2009, ARXIV            MAY, Vcs.CV; Kalantari M, 2011, J MATH IMAGING VIS, V39, P259, DOI 10.1007/s10851-010-0234-2; Kukelova Z., 2007, P IEEE C COMP VIS PA; Kukelova Z., 2008, P 10 EUR C COMP VIS; Lobo J, 2003, IEEE T PATTERN ANAL, V25, P1597, DOI 10.1109/TPAMI.2003.1251152; Naroditsky O., 2011, MSCIS1115 U PENNS; Naroditsky O., 2011, P IEEE INT C COMP VI; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Nister D, 2004, PROC CVPR IEEE, P652; Stewenius H., 2007, P IEEE C COMP VIS PA; Stewenius H., 2005, MATHS LTH SE     JAN; Stewenius H., 2005, P 10 IEEE INT C COMP; Vieville T., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P591, DOI 10.1109/ICCV.1993.378157	24	52	54	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2012	34	4					818	824		10.1109/TPAMI.2011.226	http://dx.doi.org/10.1109/TPAMI.2011.226			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	896PO	22144517	Green Submitted			2022-12-18	WOS:000300581700015
J	Wang, YC; Liu, K; Hao, Q; Wang, XW; Lau, DL; Hassebrook, LG				Wang, Yongchang; Liu, Kai; Hao, Qi; Wang, Xianwang; Lau, Daniel L.; Hassebrook, Laurence G.			Robust Active Stereo Vision Using Kullback-Leibler Divergence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active stereo vision; phase matching; range data; data fusion; KL divergence	PHASE-MEASURING-PROFILOMETRY; 3-D SHAPE RECONSTRUCTION; SPACETIME STEREO; PATTERN; ACQUISITION; SYSTEM; DEVICE; ERROR; MODEL	Active stereo vision is a method of 3D surface scanning involving the projecting and capturing of a series of light patterns where depth is derived from correspondences between the observed and projected patterns. In contrast, passive stereo vision reveals depth through correspondences between textured images from two or more cameras. By employing a projector, active stereo vision systems find correspondences between two or more cameras, without ambiguity, independent of object texture. In this paper, we present a hybrid 3D reconstruction framework that supplements projected pattern correspondence matching with texture information. The proposed scheme consists of using projected pattern data to derive initial correspondences across cameras and then using texture data to eliminate ambiguities. Pattern modulation data are then used to estimate error models from which Kullback-Leibler divergence refinement is applied to reduce misregistration errors. Using only a small number of patterns, the presented approach reduces measurement errors versus traditional structured light and phase matching methodologies while being insensitive to gamma distortion, projector flickering, and secondary reflections. Experimental results demonstrate these advantages in terms of enhanced 3D reconstruction performance in the presence of noise, deterministic distortions, and conditions of texture and depth contrast.	[Wang, Yongchang] KLA Tencor, San Jose, CA 95134 USA; [Liu, Kai] Sichuan Univ, Sch Elect Engn & Informat, Chengdu 610065, Peoples R China; [Hao, Qi] Univ Alabama, Tuscaloosa, AL 35487 USA; [Wang, Xianwang] Hewlett Packard HP Labs, Cupertino, CA 95014 USA; [Lau, Daniel L.; Hassebrook, Laurence G.] Univ Kentucky, Lexington, KY 40506 USA	KLA Corporation; Sichuan University; University of Alabama System; University of Alabama Tuscaloosa; Hewlett-Packard; University of Kentucky	Liu, K (corresponding author), Sichuan Univ, Sch Elect Engn & Informat, Chengdu 610065, Peoples R China.	ychwang6@gmail.com; kailiu@scu.edu.cn; qh@eng.ua.edu; xianwang_wang@hp.com; dllau@engr.uky.edu; lgh@engr.uky.edu	Hao, Qi/V-3634-2018; Lau, Daniel L/O-5169-2014	Hao, Qi/0000-0002-2792-5965; Lau, Daniel L/0000-0003-1377-4622				Anchini R, 2009, IEEE T INSTRUM MEAS, V58, P1291, DOI 10.1109/TIM.2009.2012952; Baek YM, 2009, LECT NOTES COMPUT SC, V5496, P413, DOI 10.1007/978-3-642-01811-4_37; Baker MJ, 2008, DELTA 2008: FOURTH IEEE INTERNATIONAL SYMPOSIUM ON ELECTRONIC DESIGN, TEST AND APPLICATIONS, PROCEEDINGS, P496, DOI 10.1109/DELTA.2008.90; Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643; Blais F, 2004, J ELECTRON IMAGING, V13, P231, DOI 10.1117/1.1631921; Chen SY, 2008, IEEE T IMAGE PROCESS, V17, P167, DOI 10.1109/TIP.2007.914755; Chen T. H., 2008, P IEEE C COMP VIS PA, P1; Cotting D, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P100, DOI 10.1109/ISMAR.2004.30; Davis J, 2005, IEEE T PATTERN ANAL, V27, P296, DOI 10.1109/TPAMI.2005.37; Dipanda A, 2003, PATTERN RECOGN, V36, P2143, DOI 10.1016/S0031-3203(03)00049-9; Dipanda A, 2005, OPT ENG, V44, DOI 10.1117/1.2055102; Dudley D, 2003, PROC SPIE, V4985, P14, DOI 10.1117/12.480761; Furukawa R., 2005, IEEE COMP SOC C COMP, P107; George H.K., 2004, US Patent, Patent No. 6678057; Guan C, 2003, OPT EXPRESS, V11, P406, DOI 10.1364/OE.11.000406; GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618; Guhring J, 2001, PROC SPIE, V4309, P220; Hassebrook L.G., 2003, ENCY OPTICS ENG, DOI [10.1081/E-EOE 120009793, DOI 10.1081/E-EOE120009793]; Hong D, 2009, APPL OPTICS, V48, P4158, DOI 10.1364/AO.48.004158; Ishiyama R, 2007, APPL OPTICS, V46, P3528, DOI 10.1364/AO.46.003528; KAMGARPARSI B, 1989, IEEE T PATTERN ANAL, V11, P929, DOI 10.1109/34.35496; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Koninckx TP, 2006, IEEE T PATTERN ANAL, V28, P432, DOI 10.1109/TPAMI.2006.62; Kullback S, 1959, INFORM THEORY STAT; Leclercq P, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P606, DOI 10.1109/ICIAP.2003.1234117; Lee H, 2007, INT J OPTOMECHATRONI, V1, P209, DOI 10.1080/15599610701397482; Lehmann S, 2007, IEEE T PATTERN ANAL, V29, P82, DOI 10.1109/TPAMI.2007.250601; Li JL, 2003, J OPT SOC AM A, V20, P106, DOI 10.1364/JOSAA.20.000106; Li YF, 2003, IEEE T ROBOTIC AUTOM, V19, P259, DOI 10.1109/TRA.2003.808859; Liu HY, 2003, OPT COMMUN, V216, P65, DOI 10.1016/S0030-4018(02)02290-3; Liu K, 2010, J OPT SOC AM A, V27, P553, DOI 10.1364/JOSAA.27.000553; Liu K, 2010, OPT EXPRESS, V18, P5229, DOI 10.1364/OE.18.005229; Narasimhan SG, 2008, LECT NOTES COMPUT SC, V5305, P830, DOI 10.1007/978-3-540-88693-8_61; Pages J, 2003, IEEE INT CONF ROBOT, P133; Pan B, 2009, OPT LETT, V34, P416, DOI 10.1364/OL.34.000416; Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346; Rusinkiewicz S, 2002, ACM T GRAPHIC, V21, P438, DOI 10.1145/566570.566600; Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002; Savarese S., 1999, 3D DEPTH RECOVERY GR; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2003, PROC CVPR IEEE, P195; Schechner YY, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P808; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; SRINIVASAN V, 1984, APPL OPTICS, V23, P3105, DOI 10.1364/AO.23.003105; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Tavares PJ, 2007, OPT COMMUN, V274, P307, DOI 10.1016/j.optcom.2007.02.038; Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555; Wang YC, 2007, PROC SPIE, V6555, DOI 10.1117/12.720068; Weise T., 2007, IEEE C COMPUTER VISI, P1; Young M., 2007, PROC IEEE C COMPUTER, P1, DOI DOI 10.1109/CVPR.2007.383292; Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759; Zhang L, 2003, PROC CVPR IEEE, P367; Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035; Zhang S., 2006, P ACM SIGGRAPH; Zhang S., 2008, OPTICAL ENG, V47; ZHOU X, 1994, APPL OPTICS, V33, P8210, DOI 10.1364/AO.33.008210	57	52	62	0	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					548	563		10.1109/TPAMI.2011.162	http://dx.doi.org/10.1109/TPAMI.2011.162			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21808084				2022-12-18	WOS:000299381600010
J	Qi, GJ; Hua, XS; Rui, Y; Tang, JH; Zhang, HJ				Qi, Guo-Jun; Hua, Xian-Sheng; Rui, Yong; Tang, Jinhui; Zhang, Hong-Jiang			Two-Dimensional Multilabel Active Learning with an Efficient Online Adaptation Model for Image Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active learning; online adaption; multilabel classification; image annotation		Conventional active learning dynamically constructs the training set only along the sample dimension. While this is the right strategy in binary classification, it is suboptimal for multilabel image classification. We argue that for each selected sample, only some effective labels need to be annotated while others can be inferred by exploring the label correlations. The reason is that the contributions of different labels to minimizing the classification error are different due to the inherent label correlations. To this end, we propose to select sample-label pairs, rather than only samples, to minimize a multilabel Bayesian classification error bound. We call it two-dimensional active learning because it considers both the sample dimension and the label dimension. Furthermore, as the number of training samples increases rapidly over time due to active learning, it becomes intractable for the offline learner to retrain a new model on the whole training set. So we develop an efficient online learner to adapt the existing model with the new one by minimizing their model distance under a set of multilabel constraints. The effectiveness and efficiency of the proposed method are evaluated on two benchmark data sets and a realistic image collection from a real-world image sharing Web site-Corbis.	[Qi, Guo-Jun] Univ Illinois, Dept Elect & Comp Engn, Everitt Lab, Urbana, IL 61801 USA; [Hua, Xian-Sheng] Microsoft Res Asia, Internet Media Grp, Sigma Ctr, Beijing 100190, Peoples R China; [Rui, Yong] Microsoft Adv Technol Ctr, Sigma Ctr, Microsoft China R&D Grp, Beijing 100190, Peoples R China; [Tang, Jinhui] Natl Univ Singapore, Sch Comp, Singapore 119076, Singapore	University of Illinois System; University of Illinois Urbana-Champaign; Microsoft; Microsoft Research Asia; Microsoft; National University of Singapore	Qi, GJ (corresponding author), Univ Illinois, Dept Elect & Comp Engn, Everitt Lab, MC-702,1406 W Green St, Urbana, IL 61801 USA.	qi4@illinois.edu; xshua@microsoft.com; yongrui@microsoft.com; tangjh@comp.nus.edu.sg; hjzhang@microsoft.com	Qi, Guo-Jun/AAH-8294-2019	Qi, Guo-Jun/0000-0003-3508-1851				Bishop C.M., 2006, SPRINGER, P461; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Brinker K., 2006, DATA INFORM ANAL KNO; CAUWENBERGHS G, 2000, P C NEUR INF PROC SY; CHANG EY, 2005, IEEE T MULTIMEDIA; Chen S., 1999, CMUCS99108 SCH COMP, P99; Cover TM, 2006, ELEMENTS INFORM THEO; DONG A, 2003, P IEEE CS C COMP VIS; ELISSEEFF A, 2002, P C NEUR INF PROC SY; FEIFEI L, 2006, MACH INTELL, V28, P594; FEIFEI L, 2005, P IEEE CS C COMP VIS; FREY BJ, 1998, ADV NEURAL INFORM PR, V10; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; HOI SCH, 2005, P IEEE CS C COMP VIS; JING F, 2004, P IEEE INT C MULT; Kapoor A., 2007, P C UNC ART INT; KAPOOR A, 2007, P IEEE INT C COMP VI; Krause A, 2008, J MACH LEARN RES, V9, P235; LI X, 2004, P INT C IMAG PROC; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; MERIALDO B, 2006, P 4 INT WORKSH AD MU; Minka Thomas P., 2001, P 17 C UNC ART INT; MURPHY KP, 1933, P AC UNC ART INT; Neal R., 1998, VIEW EM ALGORITHM JU; Neal R.M., 1993, PROBABILISTIC INFERE; QI GJ, 2008, P IEEE CS C COMP VIS; QI GJ, 1937, P IEEE CS C COMP VIS; QI GJ, 2006, P INT WORKSH SEM LEA; Qi Guo-Jun, 2007, P ACM C MULT; Roy N, 2001, P INT C MACH LEARN I, ppp441; Snoek C.G., 2006, P 14 ANN ACM INT C M, P421, DOI DOI 10.1145/1180639.1180727; Syed N, 1999, P WORKSH SUPP VECT M; TONG S, 2001, P ACM C MULT; VOLKMER T, 2005, P ACM INT C MULT; Wu J., 2005, P PIERS 2005 HANGZHO, P23; YAN R, 2003, P INT C COMPUTER VIS; YANG J, 2007, P ACM C MULT; ZHU S, 2005, P ANN INT ACM SIGIR	38	52	56	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1880	1897		10.1109/TPAMI.2008.218	http://dx.doi.org/10.1109/TPAMI.2008.218			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696456	Green Submitted			2022-12-18	WOS:000268996500012
J	van der Zant, T; Schomaker, L; Haak, K				van der Zant, Tijn; Schomaker, Lambert; Haak, Koen			Handwritten-word spotting using biologically inspired features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						digital libraries; image retrieval; computer vision; machine learning; computational neuroscience; pattern recognition; handwriting retrieval; Gabor filtering	OBJECT RECOGNITION; RECEPTIVE-FIELDS	For quick access to new handwritten collections, current handwriting recognition methods are too cumbersome. They cannot deal with the lack of labeled data and would require extensive laboratory training for each individual script, style, language, and collection. We propose a biologically inspired whole-word recognition method that is used to incrementally elicit word labels in a live Web-based annotation system, named Monk. Since human labor should be minimized given the massive amount of image data, it becomes important to rely on robust perceptual mechanisms in the machine. Recent computational models of the neurophysiology of vision are applied to isolated word classification. A primate cortex-like mechanism allows us to classify text images that have a low frequency of occurrence. Typically, these images are the most difficult to retrieve and often contain named entities and are regarded as the most important to people. Usually, standard pattern-recognition technology cannot deal with these text images if there are not enough labeled instances. The results of this retrieval system are compared to normalized word-image matching and appear to be very promising.	[van der Zant, Tijn; Schomaker, Lambert] Univ Groningen, AI Dept, NL-9700 AK Groningen, Netherlands; [Haak, Koen] Univ Groningen, Univ Med Ctr Groningen, BCN Neuroimaging Ctr, NL-9713 AW Groningen, Netherlands	University of Groningen; University of Groningen	van der Zant, T (corresponding author), Univ Groningen, AI Dept, Postbus 407, NL-9700 AK Groningen, Netherlands.	tijn@ieee.org; L.Schomaker@ai.rug.nl; K.Haak@ai.rug.nl	Schomaker, Lambert RB/A-9489-2008; Haak, Koen/AAM-5500-2020; Schomaker, Lambert/GYU-5840-2022; Haak, Koen V/G-6417-2018	Schomaker, Lambert RB/0000-0003-2351-930X; Haak, Koen/0000-0001-9309-1906; Haak, Koen V/0000-0001-9309-1906	NWO (Dutch National Scientific Organization)	NWO (Dutch National Scientific Organization)(Netherlands Organization for Scientific Research (NWO))	The authors wish to thank the Astrophysics Department of the University of Groningen and their Astro-Wise Research Group for making their high-performance computing facilities available to AI research. Special thanks go to Edwin Valentijn and his research group for assisting the authors in building a search engine for handwritten text. Also, the authors wish to thank Marco Wiering of Utrecht University for his assistance during the writing of the paper. This work is supported by two separate research grants from the NWO (Dutch National Scientific Organization) with a combined value of more than $ 1 M.	Bishop, 1995, NEURAL NETWORKS PATT; BULACU M, 2007, P 9 INT C DOC AN REC; CAILLAULT E, 2006, P 10 INT WORKSH FRON, P607; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8; Heisele B, 2002, ADV NEUR IN, V14, P1239; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Joachims T., 2005, P INT C MACH LEARN; JOACHIMS T, 2007, P ACM C KNOWL DISC D; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233; Lauer F, 2007, PATTERN RECOGN, V40, P1816, DOI 10.1016/j.patcog.2006.10.011; Lavrenko V, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P278, DOI 10.1109/DIAL.2004.1263256; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liwicki M., 2006, 10 INT WORKSH FRONT; Mikolajczyk K, 2003, PROC CVPR IEEE, P257; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Pal L, 2006, TAPPI J, V5, P10; PARK HS, 1995, P 3 INT C DOC AN REC, V1, P409; Poggio T, 2004, NATURE, V431, P768, DOI 10.1038/nature03014; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; Powell M.J.D., 1987, ALGORITHMS APPROXIMA, P143; RABINOWICZ E, 1986, TRIBOLOGY MECHANICS, V3, P1; Rath T. M., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P369, DOI 10.1145/1008992.1009056; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Sarkar M, 2005, THER DRUG MONIT, V27, P1, DOI 10.1097/00007691-200502000-00001; Schomaker L., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P585; SCHOMAKER L, 2007, P INT C DOC AN REC; SCHOMAKER L, 2008, P INT C DOC REC RETR; SCHOMAKER L, 2008, P C REC RETR IS T SP; Schomaker L, 2007, PATTERN RECOGN LETT, V28, P719, DOI 10.1016/j.patrec.2006.08.005; SERRE T, 2005, 2005036 CBCL MIT; SERRE T, 2005, P COMP VIS PATT REC; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; Ungerleider L.G., 1982, ANAL VISUAL BEHAV; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; VANDERZANT T, 2008, P INT C DOC REC RETR; Weber M, 2000, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2000.854754; XIU P, 2008, P SOC PHOTOOPTICAL I, V6215; Zinger Svitlana, 2007, P RANLP 07 COMP PHON, P79	40	52	52	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					1945	1957		10.1109/TPAMI.2008.144	http://dx.doi.org/10.1109/TPAMI.2008.144			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787243				2022-12-18	WOS:000259110000008
J	Ben-Artzi, G; Hel-Or, H; Hel-Or, Y				Ben-Artzi, Gil; Hel-Or, Hagit; Hel-Or, Yacov			The Gray-Code filter kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image filtering; filters; filter kernels; convolution; Walsh-Hadamard; pattern matching; block matching; pattern detection		In this paper, we introduce a family of filter kernels-the Gray-Code Kernels (GCK) and demonstrate their use in image analysis. Filtering an image with a sequence of Gray-Code Kernels is highly efficient and requires only two operations per pixel for each filter kernel, independent of the size or dimension of the kernel. We show that the family of kernels is large and includes the Walsh-Hadamard kernels, among others. The GCK can be used to approximate any desired kernel and, as such forms, a complete representation. The efficiency of computation using a sequence of GCK filters can be exploited for various real-time applications, such as, pattern detection, feature extraction, texture analysis, texture synthesis, and more.	Bar Ilan Univ, Dept Math, IL-52900 Ramat Gan, Israel; Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel; Sch Comp Sci, Interdisciplinary Ctr, IL-46150 Herzliyya, Israel	Bar Ilan University; University of Haifa; Reichman University	Ben-Artzi, G (corresponding author), Bar Ilan Univ, Dept Math, IL-52900 Ramat Gan, Israel.	gbenart@math.biu.ac.il; hagit@cs.haifa.ac.il; toky@idc.ac.il						Awerbuch B., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, P277, DOI 10.1145/225058.225139; Ben-Artzi G, 2004, INT C PATT RECOG, P556, DOI 10.1109/ICPR.2004.1334198; BENARTZI G, 2004, THESIS BARILAN U RAM; BLUM A, 2003, P 44 ANN IEEE S FDN, P11; Crow F. C., 1984, Computers & Graphics, V18, P207; DRORI I, 2003, IEEE T VISUALIZATION, V9; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GARDNER M, 1986, KNOTTED DOUGHNUTS OT, P23; GENSCH DH, 1978, AIIE T, V10, P362, DOI 10.1080/05695557808975227; GOLDEN B, 1987, NAVAL RES LOGISTICS, V34; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; GOTSMAN C, 1994, COMPUT GRAPH FORUM, V13, P153, DOI 10.1111/1467-8659.1320153; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; Hel-Or Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1486; Hel-Or Y, 1998, J MATH IMAGING VIS, V9, P83, DOI 10.1023/A:1008274211102; KITAJIMA H, 1976, IEEE T COMMUN, V24, P1256, DOI 10.1109/TCOM.1976.1093239; MOSHE Y, 2006, UNPUB P IEEE S SIGN; Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006; Simard P., 1999, ADV NEURAL INFORM PR, V11; Skiena S, 1990, IMPLEMENTING DISCRET; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Werman M., 2003, J WSCG, V11; [No title captured]	26	52	55	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2007	29	3					382	393		10.1109/TPAMI.2007.62	http://dx.doi.org/10.1109/TPAMI.2007.62			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	125CY	17224610	Green Submitted			2022-12-18	WOS:000243420500002
J	Zhong, BJ; Liao, WH				Zhong, Baojiang; Liao, Wenhe			Direct curvature scale space: Theory and corner detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scale space; curve convolution; Gaussian smoothing; curvature; corner detection	RECOGNITION; MULTISCALE; CURVES	The Curvature Scale Space (CSS) technique is considered to be a modern tool in image processing and computer vision. Direct Curvature Scale Space (DCSS) is defined as the CSS that results from convolving the curvature of a planar curve with a Gaussian kernel directly. In this paper we present a theoretical analysis of DCSS in detecting corners on planar curves. The scale space behavior of isolated single and double corner models is investigated and a number of model properties are specified which enable us to transform a DCSS image into a tree organization and, so that corners can be detected in a multiscale sense. To overcome the sensitivity of DCSS to noise, a hybrid strategy to apply CSS and DCSS is suggested.	Nanjing Univ Aeronaut & Astronaut, Dept Math, Nanjing 210016, Peoples R China; Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing 210016, Peoples R China	Nanjing University of Aeronautics & Astronautics; Nanjing University of Aeronautics & Astronautics	Zhong, BJ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Dept Math, Nanjing 210016, Peoples R China.	zhbj@nuaa.edu.cn; njwho@nuaa.edu.cn		Zhong, Baojiang/0000-0002-9899-524X				ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; Bebis G, 1999, PATTERN RECOGN, V32, P1175, DOI 10.1016/S0031-3203(98)00159-9; Garrido A, 1998, PATTERN RECOGN, V31, P791, DOI 10.1016/S0031-3203(97)00104-0; Iijima T., 1962, BULL ELECT LAB, V26, P368; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Mokhtarian F, 2005, PATTERN RECOGN, V38, P1021, DOI 10.1016/j.patcog.2004.11.021; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; MOKHTARIAN F, 2003, CURRVATURE SCALE MAR; PEI SC, 1992, PATTERN RECOGN, V25, P1307, DOI 10.1016/0031-3203(92)90143-7; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; RAY BK, 1995, PATTERN RECOGN, V28, P1765, DOI 10.1016/0031-3203(95)00046-3; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; XIN K, 1995, PATTERN RECOGN, V28, P1145, DOI 10.1016/0031-3203(95)00007-M; Zabulis X, 2005, PATTERN RECOGN, V38, P75, DOI 10.1016/j.patcog.2004.06.003; Zhong BJ, 2004, GEOMETRIC MODELING AND PROCESSING 2004, PROCEEDINGS, P124	16	52	58	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2007	29	3					508	512		10.1109/TPAMI.2007.50	http://dx.doi.org/10.1109/TPAMI.2007.50			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	125CY	17224621				2022-12-18	WOS:000243420500013
J	Rahtu, E; Salo, M; Heikkila, J				Rahtu, E; Salo, M; Heikkila, J			Affine invariant pattern recognition using multiscale autoconvolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						affine invariance; affine invariant features; pattern classification; target identification; object recognition; image transforms		This paper presents a new affine invariant image transform called Multiscale Autoconvolution (MSA). The proposed transform is based on a probabilistic interpretation of the image function. The method is directly applicable to isolated objects and does not require extraction of boundaries or interest points, and the computational load is significantly reduced using the Fast Fourier Transform. The transform values can be used as descriptors for affine invariant pattern classification and, in this article, we illustrate their performance in various object classification tasks. As shown by a comparison with other affine invariant techniques, the new method appears to be suitable for problems where image distortions can be approximated with affine transformations.	Univ Oulu, Dept Elect & Informat Engn, InfotechOulu, Machine Vis Grp, Oulu 90014, Finland; Univ Helsinki, Dept Math & Stat, Rolf Nevanlinna Inst, FIN-00014 Helsinki, Finland	University of Oulu; University of Helsinki	Rahtu, E (corresponding author), Univ Oulu, Dept Elect & Informat Engn, InfotechOulu, Machine Vis Grp, POB 4500, Oulu 90014, Finland.	erahtu@ee.oulu.fi; msa@rni.helsinki.fi; jth@ee.oulu.fi		Rahtu, Esa/0000-0001-8767-0864				ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; Ben-Arie J, 1998, IEEE T PATTERN ANAL, V20, P604, DOI 10.1109/34.683774; BENARIE J, 1997, GABOR ANAL ALGORITHM; BURKHARDT H, 2001, NONLINEAR MODEL BASE, P269; *COL U, 2003, COIL 100 IM DAT; Deans S., 1983, RADON TRANSFORM SOME; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; Forsyth D.A, 2003, COMPUTER VISION; Frigo M, 1998, INT CONF ACOUST SPEE, P1381; Gonzales R, 1993, DIGITAL IMAGE PROCES; Gotze N, 2000, INT C PATT RECOG, P948; Ha VHS, 2001, INT CONF ACOUST SPEE, P1937, DOI 10.1109/ICASSP.2001.941325; Heikkila J, 2002, INT C PATT RECOG, P119, DOI 10.1109/ICPR.2002.1044627; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Khalil MI, 2001, IEEE T PATTERN ANAL, V23, P1152, DOI 10.1109/34.954605; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; MIKOLAJCZYK K, 2002, P EUR C COMP VIS, P128; Petrou M, 2004, IEEE T PATTERN ANAL, V26, P30, DOI 10.1109/TPAMI.2004.1261077; RAHTU E, 2004, P INT C PATT REC; REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675; Rigoutsos I, 1998, PROC CVPR IEEE, P455, DOI 10.1109/CVPR.1998.698645; Ronneberger O, 2002, INT C PATT RECOG, P290, DOI 10.1109/ICPR.2002.1048297; SCHAEL SSM, 2002, P INT C PATT REC, P531; Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P846, DOI 10.1109/34.608288; Xiong HL, 2000, IEEE T IMAGE PROCESS, V9, P2100, DOI 10.1109/83.887977; Yang ZW, 1999, IEEE T PATTERN ANAL, V21, P804, DOI 10.1109/34.784312	26	52	83	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					908	918		10.1109/TPAMI.2005.111	http://dx.doi.org/10.1109/TPAMI.2005.111			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943422				2022-12-18	WOS:000228334700006
J	de Chazal, P; Flynn, J; Reilly, RB				de Chazal, P; Flynn, J; Reilly, RB			Automated processing of shoeprint images based on the Fourier transform for use in forensic science	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing; forensic science; shoeprint; shoe wear; partial-print; automated system; Fourier transform		The development of a system for automatically sorting a database of shoeprint images based on the outsole pattern in response to a reference shoeprint image is presented. The database images are sorted so that those from the same pattern group as the reference shoeprint are likely to be at the start of the list. A database of 476 complete shoeprint images belonging to 140 pattern groups was established with each group containing two or more examples. A panel of human observers performed the grouping of the images into pattern categories. Tests of the system using the database showed that the first-ranked database image belongs to the same pattern category as the reference image 65 percent of the time and that a correct match appears within the first 5 percent of the sorted images 87 percent of the time. The system has translational and rotational invariance so that the spatial positioning of the reference shoeprint images does not have to correspond with the spatial positioning of the shoeprint images of the database. The performance of the system for matching partial-prints was also determined.	Natl Univ Ireland Univ Coll Dublin, Dept Elect & Elect Engn, Dublin 4, Ireland	University College Dublin	de Chazal, P (corresponding author), Natl Univ Ireland Univ Coll Dublin, Dept Elect & Elect Engn, Dublin 4, Ireland.	philip.dechazal@ee.ucd.ie; flynn@ee.ucd.ie; richard.reilly@ucd.ie	Reilly, Richard/N-1080-2019; Reilly, Richard B/F-7034-2011	Reilly, Richard/0000-0001-8578-1245; Reilly, Richard B/0000-0001-8578-1245; de Chazal, Philip/0000-0002-2091-207X				Alexander A, 1999, IEE CONF PUBL, P638, DOI 10.1049/cp:19990401; Ashley W, 1996, FORENSIC SCI INT, V82, P7, DOI 10.1016/0379-0738(96)01962-7; Bodziak WJ., 2000, FOOTWEAR IMPRESSION; Bouridane A, 2000, IEEE IMAGE PROC, P474, DOI 10.1109/ICIP.2000.900998; Geradts Z, 1996, FORENSIC SCI INT, V82, P21, DOI 10.1016/0379-0738(96)01963-9; GIROD A, 1997, EUR M SHOEPR TOOLM E; Girod A, 1996, FORENSIC SCI INT, V82, P59; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Russ J. C., 2016, IMAGE PROCESSING HDB; SAWYER N, 1995, P EUR CONV SEC DET, P86	11	52	53	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					341	350		10.1109/TPAMI.2005.48	http://dx.doi.org/10.1109/TPAMI.2005.48			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747790	Green Submitted			2022-12-18	WOS:000226300200004
J	Zelnik-Manor, L; Irani, M				Zelnik-Manor, L; Irani, M			Multiview constraints on homographies	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						homographies; homologies; motion estimation; multiview analysis	MOTION	The image motion of a planar surface between two camera views is captured by a homography (a 2D projective transformation). The homography depends on the intrinsic and extrinsic camera parameters, as well as on the 3D plane parameters. While camera parameters vary across different views, the plane geometry remains the same. Based on this fact, we derive linear subspace constraints on the relative homographies of multiple (greater than or equal to 2) planes across multiple views. The paper has three main contributions: 1) We show that the collection of all relative homographies (homologies) of a pair of planes across multiple views, spans a 4-dimensional linear subspace. 2) We show how this constraint can be extended to the case of multiple planes across multiple views. 3) We show that, for some restricted cases of camera motion, linear subspace constraints apply also to the set of homographies of a single plane across multiple views. All the results derived in this paper are true for uncalibrated cameras. The possible utility of these multiview constraints for improving homography estimation and for detecting nonrigid motions are also discussed.	Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Weizmann Institute of Science	Zelnik-Manor, L (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.	lihi@wisdom.weizmann.ac.il; irani@wisdom.weizmann.ac.il						BERGEN JR, 1992, P EUR C COMP VIS, P237; BIRCHFIELD S, KLT IMPLEMENTATION K; CARLSSON S, 1998, INT J COMPUTER VISIO, V27; CRIMINISI A, 1998, P EUR C COMP VIS FRE, P846; Fang J.-Q., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P253; FAUGERAS O, 1996, 3 DIMENSIONAL COMPUT; FITZGIBBON AW, 1998, P EUR C COMP VIS, P310; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883; IRANI M, 1998, P EUR C COMP VIS, P829; KANATANI K, 1998, P IAPR WORKSH MACH V, P17; Lucas Bruce D, 1981, P 7 INT JOINT C ART, DOI DOI 10.1042/CS0730285; LUONG QT, 1998, P IEEE C COMP VIS PA, P489; Ma JB, 1998, PROC CVPR IEEE, P219, DOI 10.1109/CVPR.1998.698612; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; PRITCHETT P, 1998, LECT NOTES COMPUTER, V1506, P219; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; SHASHUA A, 1994, IEEE T PATTERN ANAL, V16, P778, DOI 10.1109/34.308472; SHASHUA A, 1996, P EUR C COMP VIS, P196; SINCLAIR D, 1996, SCIA, P181; Springer C. E., 1964, GEOMETRY ANAL PROJEC; Szeliski R., 1998, 3D Structure from Multiple Images of Large-Scale Environments. European Workshop, SMILE'98. Proceedings, P171; TRIGGS B, 1998, P 5 EUR C COMP VIS, P89; TRIGGS B, 2000, P EUR C COMP VIS, P522; VANGOOL L, 1995, P WORKSH GEOM MOD IN; Vieville T, 1996, INT J COMPUT VISION, V20, P213, DOI 10.1007/BF00208720; Zelnik-Manor L., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P710, DOI 10.1109/ICCV.1999.790291; Zelnik-Manor L, 2000, IEEE T PATTERN ANAL, V22, P1105, DOI 10.1109/34.879791; ZHANG Z, 1999, P INT C COMP VIS SEP	31	52	55	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2002	24	2					214	223						10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	516DC					2022-12-18	WOS:000173535700006
J	Danuser, G; Stricker, M				Danuser, G; Stricker, M			Parametric model fitting: From inlier characterization to outlier detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						parametric models; generalized least squares; errors in variables; data snooping; classify-while-fit; self-diagnosis; straight lines; planes	COMPUTER VISION; EDGE-DETECTION; IMAGES; SEGMENTATION; POLYNOMIALS	Parametric models play an important role in broad areas of science and technology. This paper presents a novel framework for the fitting of multiple parametric models. It comprises of a module for parameter estimation based on a solution for generalized least squares problems and of a procedure for error propagation, which takes both the geometric arrangement of the input data points and their precision into account. The results from error propagation are used to complement each model parameter with a precision estimate, to assign an inlier set of data points supporting the fit to each extracted model, and to determine the a priori unknown total number of meaningful models in the data. Although the models are extracted sequentially, the final result is almost independent of the extraction order. This is achieved by further statistical processing which controls the mutual exchange of inlier data between the models. Consequently, sound data classification as well as robust fitting are guaranteed even in areas where different models intersect or touch each other. Apart from the input data and its precision, the framework relies on only one additional control parameter: the confidence level on which the various statistical tests for data and model classification are carried out. We demonstrate the algorithmic performance by fitting straight lines in 2D and planes in 3D with applications to problems of computer vision and pattern recognition. Synthetic data is used to show the robustness and accuracy of the scheme. Image data and range data are used to illustrate its applicability and relevance in respect of real-world problems, e.g., in the domain of image feature extraction.	Marine Biol Lab, Woods Hole, MA 02543 USA; Swiss Reinsurance Analyt & Math Serv, CH-8022 Zurich, Switzerland	Marine Biological Laboratory - Woods Hole	Danuser, G (corresponding author), Marine Biol Lab, Woods Hole, MA 02543 USA.	gdanuser@mbl.edu						Baarda W., 1968, PUBLICATIONS GEODESY, V2, P1; BEATON AE, 1974, TECHNOMETRICS, V16, P147, DOI 10.2307/1267936; BOX MJ, 1971, J ROY STAT SOC B, V33, P171; BRITT HI, 1973, TECHNOMETRICS, V15, P233, DOI 10.2307/1266984; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHEN DS, 1989, IEEE T PATTERN ANAL, V11, P749, DOI 10.1109/34.192470; Danuser G, 1996, P SOC PHOTO-OPT INS, V2782, P180, DOI 10.1117/12.250744; DANUSER G, 1996, 170 ETH ZUR IM SCI L; DANUSER G, 1997, THESIS ETH ZURICH; DEMING W, 1943, STAT ABJUSTMENT DATA; Faugeras O., 1993, 3 DIMENSIONAL COMPUT, P33; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FORSTNER W, 1987, COMPUT VISION GRAPH, V40, P273, DOI 10.1016/S0734-189X(87)80144-5; GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268; Gill P. E., 1981, PRACTICAL OPTIMIZATI; GOLUB GH, 1980, SIAM J NUMER ANAL, V17, P883, DOI 10.1137/0717073; Grimson W. E. L., 1990, OBJECT RECOGNITION C; HAMPEL F, 1986, ROBUST STAT APPPROAC; HAN S, 1993, P INT C COMP VIS 93, P492; HEITGER F, 1995, FEATURE DETECTION US; Huber P., 1981, ROBUST STAT; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; KAMGARPARSI B, 1990, COMPUT VISION GRAPH, V52, P341, DOI 10.1016/0734-189X(90)90080-F; KANATANI K, 1996, MACHINE INTELLIGENCE, V18; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; KITTLE J, 1994, PERFOMRANCE VERSUS M, P111; Klinker G. J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P145; KOCH KR, 1988, PARAMETER ESTIMATION; LEONARDIS A, 1995, INT J COMPUT VISION, V14, P253, DOI 10.1007/BF01679685; MATHENY A, 1995, IEEE T PATTERN ANAL, V17, P967, DOI 10.1109/34.464561; MCLEAN GF, 1995, IEEE T PATTERN ANAL, V17, P1090, DOI 10.1109/34.473236; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; MOHAN R, 1992, IEEE T PATTERN ANAL, V14, P616, DOI 10.1109/34.141553; MONGA O, 1991, CVGIP-IMAG UNDERSTAN, V53, P76, DOI 10.1016/1049-9660(91)90006-B; ONEILL M, 1969, COMPUT J, V12, P52, DOI 10.1093/comjnl/12.1.52; ROTH G, 1993, CVGIP-IMAG UNDERSTAN, V58, P1, DOI 10.1006/ciun.1993.1028; ROTHWELL CA, 1995, INT S COMP VIS COR G, P395; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; RUPPERT D, 1980, J AM STAT ASSOC, V75, P828, DOI 10.2307/2287169; RUTISHAUSER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P573, DOI 10.1109/CVPR.1994.323797; SCHWETLICK H, 1985, TECHNOMETRICS, V27, P17, DOI 10.2307/1270465; Sen A., 1990, REGRESSION ANAL THEO; STEIN F, 1992, DARPA IMAGE UNDERSTA, P667; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; STRICKER M, 1995, LECT NOTES COMPUTER, V970, P90; TAGARE HD, 1990, IEEE T PATTERN ANAL, V12, P1186, DOI [10.1109/34.62607, 10.1117/12.19530]; TAUBIN G, 1993, P 4 INT C COMP VIS B, P658; TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228; WANG ST, 1994, IM UND WORKSH, P1143; WATSON G, 1985, INT S NUMERICAL MATH, V75, P388; WEISS I, 1989, IEEE T PATTERN ANAL, V11, P325, DOI 10.1109/34.21801; YORK D, 1966, CAN J PHYS, V44, P1079, DOI 10.1139/p66-090	53	52	53	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					263	280		10.1109/34.667884	http://dx.doi.org/10.1109/34.667884			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156					2022-12-18	WOS:000073078400004
J	Barequet, G; Sharir, M				Barequet, G; Sharir, M			Partial surface and volume matching in three dimensions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						geometric hashing; computer vision; pattern recognition; partial surface matching; protein matching; molecule docking	3-DIMENSIONAL STRUCTURAL MOTIFS; DIGITAL IMAGE REGISTRATION; OBJECT RECOGNITION; COMPUTER VISION; MEDICAL IMAGES; ORIENTATION; CT; IDENTIFICATION; ALGORITHM; ALIGNMENT	In this paper we present a new technique for partial surface and volume matching of images in three dimensions. In this problem we are given two objects in 3-space, each represented as a set of points, and the goal is to find a rigid motion of one object which makes a sufficiently large portion of its boundary lying sufficiently close to a corresponding portion of the boundary of the second object. This is an important problem in pattern recognition and in computer vision, with many industrial, medical, and chemical applications. Our method treats separately the rotation and the translation components of the Euclidean motion that we seek. The algorithm steps through a sequence of rotations, in a steepest-descent style, and uses a novel technique for scoring the match for any fixed rotation. Experimental results on various examples, involving data from industrial applications, medical imaging, and molecular biology, are presented, and show the accurate and robust performance of our algorithm.	TEL AVIV UNIV, SCH MATH SCI, IL-69978 TEL AVIV, ISRAEL; NYU, COURANT INST MATH SCI, NEW YORK, NY 10012 USA	Tel Aviv University; New York University								ABAGYAN RA, 1988, J BIOMOL STRUCT DYN, V5, P1267, DOI 10.1080/07391102.1988.10506469; ABEL T, 1989, NATURE, V341, P24, DOI 10.1038/341024a0; ALPERT NM, 1990, J NUCL MED, V31, P1717; Anderson T.W, 1958, INTRO MULTIVARIATE S; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; Barrow HG, 1977, P 5 INT JOINT C ART; BEER FP, 1986, VECTOR MECH ENG DYNA; BESL P, 1990, MACHINE VISION 3 DIM; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BESL PJ, 1988, P IEEE, V76, P936, DOI 10.1109/5.5966; Blake A., 1993, ACTIVE VISION; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; BOOKSTEIN FL, 1991, LECT NOTES COMPUT SC, V511, P326, DOI 10.1007/BFb0033763; BOOKSTEIN FL, 1986, INFORMATION PROCESSI, P1; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BROU P, 1984, INT J ROBOT RES, V3, P89, DOI 10.1177/027836498400300406; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; CHAZELLE B, 1988, SIAM J COMPUT, V17, P427, DOI 10.1137/0217026; CHEN CT, 1988, INFORMATION PROCESSI, P601; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; COLLINS DL, 1992, P SOC PHOTO-OPT INS, V1808, P10, DOI 10.1117/12.131063; CONNOLLY ML, 1986, BIOPOLYMERS, V25, P1229, DOI 10.1002/bip.360250705; DECASTRO E, 1987, IEEE T MED IMAGING, V6, P74, DOI 10.1109/TMI.1987.4307800; Evans A.C., 1989, PROC SPIE, V1092, P264, DOI [10.1117/12.953267, DOI 10.1117/12.953267]; Fang T. J., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P678; Faugeras O. D., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P796; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; FERMI G, 1984, J MOL BIOL, V175, P159, DOI 10.1016/0022-2836(84)90472-8; FISCHER D, 1992, LECT NOTES COMPUT SC, V644, P136; FISCHER D, 1992, J BIOMOL STRUCT DYN, V9, P769, DOI 10.1080/07391102.1992.10507955; FISHER RB, 1983, P 8 INT JOINT C ART; Gamboa-Aldeco A., 1986, P SPIE, V0626, P467, DOI [10.1117/12.975430, DOI 10.1117/12.975430]; GARIBOTTO G, 1983, P SPIE APPL DIGITAL, P280; Goldstein H., 1980, CLASSICAL MECH, V2nd ed; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; HAWKES DJ, 1990, NATO ADV SCI I F-COM, V60, P241; HAYNOR DR, 1986, RADIOLOGY, V158, P537, DOI 10.1148/radiology.158.2.3753626; HILL DLG, 1991, BRIT J RADIOL, V64, P1030, DOI 10.1259/0007-1285-64-767-1030; HILL DLG, 1991, P SPIE IMAGE PROCESS, P348; HONG J, 1988, NOV P ICPR ROM, P72; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; HUTTENLOCHER DP, 1993, P IEEE INT C COMP VI; JIANG F, 1991, J MOL BIOL, V219, P79, DOI 10.1016/0022-2836(91)90859-5; JIANG HJ, 1992, P SOC PHOTO-OPT INS, V1660, P356, DOI 10.1117/12.59565; JUNCK L, 1990, J NUCL MED, V31, P1220; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; KAMGARPARSI B, 1989, P IEEE C COMP VIS PA; KATCHALSKIKATZIR E, 1992, P NATL ACAD SCI USA, V89, P2195, DOI 10.1073/pnas.89.6.2195; KENNY PA, 1990, PHYS MED BIOL, V35, P679, DOI 10.1088/0031-9155/35/5/008; KISHON E, 1991, J ROBOTIC SYST, V8, P723, DOI 10.1002/rob.4620080602; KOVACIC S, 1989, P IEEE EMBS, V11, P548, DOI 10.1109/IEMBS.1989.95867; Kruskal J.B., 1983, TIME WARPS STRING ED; KUHL FS, 1984, J COMPUT CHEM, V5, P24, DOI 10.1002/jcc.540050105; KUNTZ ID, 1982, J MOL BIOL, V161, P269, DOI 10.1016/0022-2836(82)90153-X; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; Lamdan Y., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P238, DOI 10.1109/CCV.1988.589995; LAMDAN Y, 1988, APR P IEEE INT C ROB, P1407; LAVALLEE S, 1995, IEEE T PATTERN ANAL, V17, P378, DOI 10.1109/34.385980; Lehninger A, 1978, BIOCHEMISTRY; MANDAVA VR, 1989, IEEE T MED IMAGING, V8, P251, DOI 10.1109/42.34714; MITCHELL EM, 1990, J MOL BIOL, V212, P151, DOI 10.1016/0022-2836(90)90312-A; MOSHFEGHI M, 1991, CVGIP-GRAPH MODEL IM, V53, P271, DOI 10.1016/1049-9652(91)90049-P; NUSSINOV R, 1991, P NATL ACAD SCI USA, V88, P10495, DOI 10.1073/pnas.88.23.10495; PELIZZARI CA, 1989, J COMPUT ASSIST TOMO, V13, P20, DOI 10.1097/00004728-198901000-00004; Potmesil M., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P553; POTMESIL M, 1983, 8TH P INT JOINT C AI, P1089; RICHARDS FM, 1988, PROTEINS, V3, P71, DOI 10.1002/prot.340030202; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; SINGH M, 1979, IEEE T NUCL SCI, V26, P565, DOI 10.1109/TNS.1979.4329692; SPANG HA, 1962, SIAM REV, V4, P343; STOCKMAN G, 1987, COMPUT VISION GRAPH, V40, P361, DOI 10.1016/S0734-189X(87)80147-0; STOCKMAN G, 1984, P IEEE INT C PATTERN, P742; Szeliski R., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P207, DOI 10.1109/CCV.1988.589992; TAUBIN G, 1989, LEMS57 BROWN U DIV E; TOENNIES KD, 1990, IEEE COMPUT GRAPH, V10, P52, DOI 10.1109/38.55153; VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938; VANDERWIEL AM, 1992, J S AM EARTH SCI, V5, P153, DOI 10.1016/0895-9811(92)90036-X; WOLFSON HJ, 1990, IEEE T PATTERN ANAL, V12, P483, DOI 10.1109/34.55108; WOLFSON HJ, 1990, LECT NOTES COMPUT SC, V427, P526, DOI 10.1007/BFb0014902; [No title captured]	84	52	59	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					929	948		10.1109/34.615444	http://dx.doi.org/10.1109/34.615444			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985					2022-12-18	WOS:A1997XX98500001
J	GOLDSZMIDT, M; MORRIS, P; PEARL, J				GOLDSZMIDT, M; MORRIS, P; PEARL, J			A MAXIMUM-ENTROPY APPROACH TO NONMONOTONIC REASONING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							LOGIC; CIRCUMSCRIPTION	We propose an approach to nonmonotonic reasoning that combines the principle of infinitesimal probabilities with that of maximum entropy, thus extending the inferential power of the probabilistic interpretation of defaults. We provide a precise formalization of the consequences entailed by a conditional knowledge base, develop the computational machinery necessary for drawing these consequences, and compare the behavior of the maximum entropy approach to related work in default reasoning. The resulting formalism offers a compromise between two extremes: the cautious approach based on the conditional interpretations of defaults and the bold approach based on minimizing abnormalities.	INTELLICORP, MT VIEW, CA 94040 USA; UNIV CALIF LOS ANGELES, DEPT COMP SCI, LOS ANGELES, CA 90024 USA; UNIV CALIF LOS ANGELES, COGNIT SYST LAB, LOS ANGELES, CA 90024 USA	University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	GOLDSZMIDT, M (corresponding author), ROCKWELL INT CORP, CTR SCI, PALO ALTO, CA 94301 USA.							Adams Ernest W., 1975, LOGIC CONDITIONALS A; AOKI M, 1971, INTRO OPTIMIZATION T, pCH5; BACCHUS F, 1992, 4TH P INT WORKSH NON; BENELIYAHU R, 1990, R158 U CAL LOS ANG C; BORN M, 1949, NATURAL PHILOS CAUSE; Cheeseman P., 1983, P 8 INT JOINT C ART, V1, P198; DELGRANDE JP, 1988, ARTIF INTELL, V36, P63, DOI 10.1016/0004-3702(88)90079-3; Dowling W. F., 1984, Journal of Logic Programming, V1, P267, DOI 10.1016/0743-1066(84)90014-1; Gabbay Dov M., 1985, LOGIC MODELS CONCURR; GEFFNER H, 1992, DEFAULT REASONING CA; GEFFNER HA, 1990, KNOWLEDGE REPRESENTA, P245; GOLDSZMIDT M, 1991, ARTIF INTELL, V52, P121, DOI 10.1016/0004-3702(91)90039-M; GOLDSZMIDT M, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P399; GOLDSZMIDT M, 1992, 3RD P INT C PRINC KN, P661; Goldszmidt M., 1990, 3RD P INT WORKSH NON, P130; GOLDSZMIDT M, 1992, 8TH P C UNC ART INT; HANKS S, 1987, ARTIF INTELL, V33, P379, DOI 10.1016/0004-3702(87)90043-9; Hunter D., 1989, International Journal of Approximate Reasoning, V3, P87, DOI 10.1016/0888-613X(89)90015-7; Jaynes E.T, 1979, MAXIMUM ENTROPY FORM; KRAUS S, 1990, ARTIF INTELL, V44, P167, DOI 10.1016/0004-3702(90)90101-5; LEHMANN D, 1992, ARTIF INTELL, V55, P1, DOI 10.1016/0004-3702(92)90041-U; LEHMANN D, 1989, 1ST P INT C PRINC KN, P212; LIFSCHITZ V, 1989, OPEN PROBLEMS BORDER; MAKINSON D, 1989, LECTURE NOTES ARTIFI, V346; MCCARTHY J, 1986, ARTIF INTELL, V28, P89, DOI 10.1016/0004-3702(86)90032-9; MCCARTHY J, 1980, ARTIF INTELL, V13, P27, DOI 10.1016/0004-3702(80)90011-9; MOORE RC, 1985, ARTIF INTELL, V25, P75, DOI 10.1016/0004-3702(85)90042-6; PEARL J, 1990, THEORETICAL ASPECTS OF REASONING ABOUT KNOWLEDGE, P121; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PEARL J, 1991, PHILOS AI ESSAYS INT, P157; REITER R, 1980, ARTIF INTELL, V13, P81, DOI 10.1016/0004-3702(80)90014-4; Reiter R., 1983, INT J COMPUT MATH, V9, P1; Reiter R., 1987, ARTIF INTELL, V32, P97; SATOH K, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P659; Shoham Y., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence, P389; SHOHAM Y, 1987, P 10 INT JOINT C ART, P388; Tribus M, 1969, RATIONAL DESCRIPTION; [No title captured]	38	52	52	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					220	232		10.1109/34.204904	http://dx.doi.org/10.1109/34.204904			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800004
J	SEKITA, I; KURITA, T; OTSU, N				SEKITA, I; KURITA, T; OTSU, N			COMPLEX AUTOREGRESSIVE MODEL FOR SHAPE-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						BOUNDARY MODELING; COMPLEX AUTOREGRESSIVE MODEL; COMPLEX PARCOR; COMPUTER VISION; LINEAR PREDICTION; SHAPE DESCRIPTOR; SHAPE RECOGNITION	CLASSIFICATION; LENGTH	This paper presents a complex autoregressive model for invariant feature extraction to recognize arbitrary shapes on a plane. A fast algorithm to calculate complex autoregressive coefficients and complex PARCOR coefficients of the model is also shown. The coefficients are invariant to rotation around the origin and to choice of the starting point in tracing a boundary. It is also possible to make them invariant to scale and translation. Experimental results show that complicated shapes like nonconvex boundaries can be recognized in high accuracy, even in the low-order model. It is seen that the complex PARCOR coefficients tend to provide more accurate classification than the complex AR coefficients.			SEKITA, I (corresponding author), MINIST INT TRADE & IND,ELECTROTECH LAB,DIV MACHINE UNDERSTANDING,TSUKUBA,IBARAKI,JAPAN.		Rohlf, F J/A-8710-2008; Kurita, Takio/D-8674-2012	Kurita, Takio/0000-0003-3982-6750				AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; DAS M, 1990, IEEE T PATTERN ANAL, V12, P97, DOI 10.1109/34.41389; DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; Durbin J., 1960, ECONOMETRICA, P233, DOI 10.2307/1401322 0101.35604; Gray Jr A. H., 1976, LINEAR PREDICTION SP; KASYAP RL, 1981, IEEE T INFORM THEORY, V27, P627; Kurita T., 1990, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ73D-II, P1493; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; OTSU N, 1989, IEICE JAPAN D, V496; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; Sebestyen G., 1962, DECISION MAKING PROC, V227, P413; SEKITA I, 1991, ETL TR9112 TECH REP; SEKITA I, 1990, IEICE JAPAN D, V258; TOUSSAINT GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; YOU Z, 1984, COMPUT VISION GRAPH, V28, P185, DOI 10.1016/S0734-189X(84)80021-3; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	20	52	52	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1992	14	4					489	496		10.1109/34.126809	http://dx.doi.org/10.1109/34.126809			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HL193					2022-12-18	WOS:A1992HL19300007
J	FABER, TL; STOKELY, EM				FABER, TL; STOKELY, EM			ORIENTATION OF 3-D STRUCTURES IN MEDICAL IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV TEXAS, HLTH SCI CTR, GRAD PROGRAM BIOMED ENGN, DALLAS, TX 75235 USA	University of Texas System; University of Texas Dallas	FABER, TL (corresponding author), UNIV TEXAS, HLTH SCI CTR, CTR RADIOL IMAGING, DALLAS, TX 75235 USA.							BORISENKO AI, 1968, VECTOR TENSOR ANAL A, P109; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; CYGANSKI D, 1985, IEEE T PATTERN ANAL, V7, P662, DOI 10.1109/TPAMI.1985.4767722; CYGANSKI D, 1984, MAR P IEEE INT C ASS; DIRILTEN H, 1977, IEEE T COMPUT, V26, P314, DOI 10.1109/TC.1977.1674832; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; Faber T. L., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P440; JACKINS CL, 1982, COMPUT GRAPHICS IMAG, V19, P129; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; TEH CH, 1986, COMPUT VISION GRAPH, V33, P318, DOI 10.1016/0734-189X(86)90180-5	12	52	54	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					626	633		10.1109/34.6771	http://dx.doi.org/10.1109/34.6771			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500002
J	DEVROYE, L				DEVROYE, L			ON THE INEQUALITY OF COVER AND HART IN NEAREST NEIGHBOR DISCRIMINATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											DEVROYE, L (corresponding author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3C 3G1,QUEBEC,CANADA.							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; Glick N., 1974, UTILITAS MATHEMATICA, V6, P61; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; Wheeden R. L., 1977, MEASURE INTEGRAL	6	52	53	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					75	78		10.1109/TPAMI.1981.4767052	http://dx.doi.org/10.1109/TPAMI.1981.4767052			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LK116	21868920				2022-12-18	WOS:A1981LK11600008
J	SHAPIRO, LG				SHAPIRO, LG			STRUCTURAL MODEL OF SHAPE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SHAPIRO, LG (corresponding author), VIRGINIA POLYTECH INST & STATE UNIV,DEPT COMP SCI,BLACKSBURG,VA 24061, USA.		Rohlf, F J/A-8710-2008					AGRAWALA AK, 1977, COMPUT VISION GRAPH, V6, P538, DOI 10.1016/S0146-664X(77)80015-4; ALT FL, 1962, J ACM, V11, P240; BARROW HG, 1972, FRONTIERS PATTERN RE, P1; BLUM H, 1964, S MODELS PERCEPTION; CORNEIL DG, 1970, J ACM, V17, P51, DOI 10.1145/321556.321562; DAVIS LS, 1977, IEEE T SYST MAN CYB, V7, P204; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DAVIS LS, 1977, IEEE T COMPUT, V26, P236, DOI 10.1109/TC.1977.1674812; EDEN M, 1962, IRE T INFORM THEOR, V8, P160, DOI 10.1109/TIT.1962.1057695; FENG HYF, 1975, IEEE T COMPUT, VC 24, P636, DOI 10.1109/T-C.1975.224276; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; FU KS, 1977, IEEE T SYST MAN CYB, V7, P734, DOI 10.1109/TSMC.1977.4309608; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; HARALICK RM, 1978, IEEE T SYST MAN CYB, V8, P600, DOI 10.1109/TSMC.1978.4310036; HARALICK RM, UNPUBLISHED; HARALICK RM, 1977, 1ST P IEEE C PATT RE, P183; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1; HOROWITZ SL, 1977, SYNTACTIC PATTERN RE; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; LANGRIDGE D, 1962, FRONTIERS PATTERN RE, P347; LOZANOPEREZ T, 1977, COMPUT GRAPHICS IMAG, V6, P43; MARUYAMA K, 1972, VIVCDCSR72533 U ILL; OCALLAGHAN JF, 1974, COMPUT GRAPHICS IMAG, V3, P300; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P2, DOI 10.1109/TPAMI.1979.4766870; PAVLIDIS T, 1972, PATTERN RECOGN, V4, P5, DOI 10.1016/0031-3203(72)90016-7; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; Rosenberg B., 1972, COMPUT GRAPHICS IMAG, V1, P183; ROSENBERG B, 1975, INT J MAN MACHINE ST, V6, P1; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; SHAW AC, 1970, J ACM, V17, P453, DOI 10.1145/321592.321598; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; Winston PH, 1975, PSYCHOL COMPUTER VIS, P157; YOU KC, 1978 P EIA S EM PATT; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	36	52	52	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	2					111	126		10.1109/TPAMI.1980.4766989	http://dx.doi.org/10.1109/TPAMI.1980.4766989			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JH803	21868882				2022-12-18	WOS:A1980JH80300003
J	WALLACE, TP; MITCHELL, OR				WALLACE, TP; MITCHELL, OR			ANALYSIS OF 3-DIMENSIONAL MOVEMENT USING FOURIER DESCRIPTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											WALLACE, TP (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; PERSOON E, 1974, TREE7430 PURD U SCH; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; WALLACE TP, 1980, COMPUTER GRAPHICS IM, V13, P96; WALLACE TP, 1979, TREE7943 PURD U SCH	7	52	53	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	6					583	588		10.1109/TPAMI.1980.6447707	http://dx.doi.org/10.1109/TPAMI.1980.6447707			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	KS962					2022-12-18	WOS:A1980KS96200013
J	KLINGER, A; RHODES, ML				KLINGER, A; RHODES, ML			ORGANIZATION AND ACCESS OF IMAGE DATA BY AREAS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KLINGER, A (corresponding author), UNIV CALIF LOS ANGELES,DEPT COMP SCI,LOS ANGELES,CA 90024, USA.							ALEXANDRIDIS N, 1976, PICTURE DECOMPOSITIO; ALEXANDRIDIS N, 1977, COMP GRAPH IMAGE P, V6; BREEDING K, 1977, COMMUNICATION; KELLY MD, 1971, MACHINE INTELLIGENCE, V6; Klinger A., 1973, 1st International Joint Conference on Pattern Recognition, P497; KLINGER A, 1971, IEEE T COMPUT, VC 20, P1014, DOI 10.1109/T-C.1971.223397; KLINGER A, 1976, APR P IFIP C MOD ENV, P141; KLINGER A, 1974, OCT P IEEE SYST MAN, P307; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; Klinger A, 1972, OPTIMIZING METHODS S, P303; KLINGER A, 1976, P SAN DIEGO BIOMEDIC, V15, P175; Knuth D., 1973, ART COMPUTER PROGRAM, V2nd; RISEMAN E, 1974, 74C1 U MASS DEP COMP; ROSEN CA, 5953 STANF RES I PRO; ROSEN CA, 1967, 3RD RADC REP; Tanimoto S. L., 1976, Computer Graphics and Image Processing, V5, P333, DOI 10.1016/S0146-664X(76)80012-3; TANIMOTO SL, 1975, COMPUT GRAPH IMAGE P, V2, P104; WALL R, 1977, COMMUNICATION; WARNOCK JE, 1968, ARPA45 U UT COLL SCI; WARNOCK JE, 1969, PERTINENT CONCEPTS C; 1976, POCKET GUIDE CCN; 1976, GC2016499 IBM CORP P	22	52	53	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					50	60		10.1109/TPAMI.1979.4766875	http://dx.doi.org/10.1109/TPAMI.1979.4766875			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA303	21868830				2022-12-18	WOS:A1979HA30300006
J	Marin, J; Biswas, A; Ofli, F; Hynes, N; Salvador, A; Aytar, Y; Weber, I; Torralba, A				Marin, Javier; Biswas, Aritro; Ofli, Ferda; Hynes, Nicholas; Salvador, Amaia; Aytar, Yusuf; Weber, Ingmar; Torralba, Antonio			Recipe1M+: A Dataset for Learning Cross-Modal Embeddings for Cooking Recipes and Food Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cross-modal; deep learning; cooking recipes; food images		In this paper, we introduce Recipe 1M+, a new large-scale, structured corpus of over one million cooking recipes and 13 million food images. As the largest publicly available collection of recipe data, Recipes 1M+ affords the ability to train high-capacity models on aligned, multimodal data. Using these data, we train a neural network to learn a joint embedding of recipes and images that yields impressive results on an image-recipe retrieval task. Moreover, we demonstrate that regularization via the addition of a high-level classification objective both improves retrieval performance to rival that of humans and enables semantic vector arithmetic. We postulate that these embeddings will provide a basis for further exploration of the Recipes 1M+ dataset and food and cooking in general. Code, data and models are publicly available.(1)	[Marin, Javier; Biswas, Aritro; Hynes, Nicholas; Aytar, Yusuf; Torralba, Antonio] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Ofli, Ferda; Weber, Ingmar] Hamad Bin Khalif Univ, Qatar Comp Res Inst, Doha, Qatar; [Salvador, Amaia] Univ Politecn Cataluna, Barcelona 08034, Spain	Massachusetts Institute of Technology (MIT); Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Qatar Computing Research Institute; Universitat Politecnica de Catalunya	Marin, J (corresponding author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	jmarin@csail.mit.edu; abiswas@hbku.edu.qa; fofli@mit.edu; nhynes@mit.edu; amaia.salvador@upc.edu; yusuf@csail.mit.edu; iweber@hbku.edu.qa; torral@csail.mit.edu	Weber, Ingmar/AAE-6909-2020; Ofli, Ferda/G-2027-2017	Weber, Ingmar/0000-0003-4169-2579; Ofli, Ferda/0000-0003-3918-3230	CSAIL-QCRI collaboration projects and the framework of projects - Spanish Ministerio de Economia y Competitividad [TEC2013-43935R, TEC2016-75976-R]; European Regional Development Fund	CSAIL-QCRI collaboration projects and the framework of projects - Spanish Ministerio de Economia y Competitividad; European Regional Development Fund(European Commission)	This work has been supported by CSAIL-QCRI collaboration projects and the framework of projects TEC2013-43935R and TEC2016-75976-R, financed by the Spanish Ministerio de Economia y Competitividad and the European Regional Development Fund. Javier Mari ' n and Aritro Biswas contributed equally.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2014, P INT C MACH LEARN; [Anonymous], 2015, P INT C LEARN REPR; Aytar Y, 2018, IEEE T PATTERN ANAL, V40, P2303, DOI 10.1109/TPAMI.2017.2753232; Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29; Carvalho M, 2018, ACM/SIGIR PROCEEDINGS 2018, P35, DOI 10.1145/3209978.3210036; Castrejon L, 2016, PROC CVPR IEEE, P2940, DOI 10.1109/CVPR.2016.321; Chang M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174025; Chen JJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1020, DOI 10.1145/3240508.3240627; Chen JJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1771, DOI 10.1145/3123266.3123428; Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315; Engilberge M, 2018, PROC CVPR IEEE, P3984, DOI 10.1109/CVPR.2018.00419; Garimella VRK, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5543, DOI 10.1145/2858036.2858234; Herranz L., 2018, FOOD RECOGNITION REC; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kawano Y, 2015, MULTIMED TOOLS APPL, V74, P5263, DOI 10.1007/s11042-014-2000-8; Kiros R., 2015, ADV NEURAL INF PROCE, P3294; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kusmierczyk T, 2016, PROCEEDINGS OF THE 27TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA (HT'16), P243, DOI 10.1145/2914586.2914632; Liu C, 2016, LECT NOTES COMPUT SC, V9677, P37, DOI 10.1007/978-3-319-39601-9_4; Mejova Y., 2016, P INT AAAI C WEB SOC, P250; Mikolov T., 2013, 1 INT LEARN REPR ICL; Min WQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P402, DOI 10.1145/3123266.3123272; Myers A, 2015, IEEE I CONF COMP VIS, P1233, DOI 10.1109/ICCV.2015.146; Ofli F, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P509, DOI 10.1145/3038912.3052663; Quoc Le, 2014, P 31 INT C MACHINE L, V32, P1188; Radford A., 2016, P INT C LEARN REPR; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Salvador A, 2017, PROC CVPR IEEE, P3068, DOI 10.1109/CVPR.2017.327; Sutskever I., 2014, P ADV INT C NEUR INF, P3104; US Department of Agriculture Agricultural Research Service Nutrient Data Laboratory, 2015, USDA NAT NUTR DAT ST; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang X, 2015, PROD LOGIST, P1, DOI 10.1007/978-3-658-06869-1; Xu RH, 2015, IEEE T MULTIMEDIA, V17, P1187, DOI 10.1109/TMM.2015.2438717; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881	38	51	51	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					187	203		10.1109/TPAMI.2019.2927476	http://dx.doi.org/10.1109/TPAMI.2019.2927476			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31295105	Green Submitted, Green Published			2022-12-18	WOS:000597206900013
J	Mai, GC; Cao, K; Yuen, PC; Jain, AK				Mai, Guangcan; Cao, Kai; Yuen, Pong C.; Jain, Anil K.			On the Reconstruction of Face Images from Deep Face Templates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; template security; deep networks; deep templates; template reconstruction; neighborly de-convolutional neural network	RECOGNITION	State-of-the-art face recognition systems are based on deep (convolutional) neural networks. Therefore, it is imperative to determine to what extent face templates derived from deep networks can be inverted to obtain the original face image. In this paper, we study the vulnerabilities of a state-of-the-art face recognition system based on template reconstruction attack. We propose a neighborly de-convolutional neural network (NbNet) to reconstruct face images from their deep templates. In our experiments, we assumed that no knowledge about the target subject and the deep network are available. To train the NbNet reconstruction models, we augmented two benchmark face datasets (VGG-Face and Multi-PIE) with a large collection of images synthesized using a face generator. The proposed reconstruction was evaluated using type-I (comparing the reconstructed images against the original face images used to generate the deep template) and type-II (comparing the reconstructed images against a different face image of the same subject) attacks. Given the images reconstructed from NbNets, we show that for verification, we achieve TAR of 95.20 percent (58.05 percent) on LFW under type-I (type-II) attacks @ FAR of 0.1 percent. Besides, 96.58 percent (92.84 percent) of the images reconstructed from templates of partition fa (fb) can be identified from partition fa in color FERET. Our study demonstrates the need to secure deep templates in face recognition systems.	[Mai, Guangcan; Yuen, Pong C.] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China; [Cao, Kai; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Hong Kong Baptist University; Michigan State University	Yuen, PC (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China.	csgcmai@comp.hkbu.edu.hk; kaicao@cse.msu.edu; pcyuen@comp.hkbu.edu.hk; jain@cse.msu.edu	Mai, Guangcan/AAB-4447-2019	Mai, Guangcan/0000-0002-0326-500X; Yuen, Pong Chi/0000-0002-9343-2202	Hong Kong RGC grant [HKBU 12201414]; Madam Kwok Chung Bo Fun Graduate School Development Fund, HKBU	Hong Kong RGC grant; Madam Kwok Chung Bo Fun Graduate School Development Fund, HKBU	This research was partially supported by a Hong Kong RGC grant (HKBU 12201414) and the Madam Kwok Chung Bo Fun Graduate School Development Fund, HKBU. The authors would like to thank Prof. Wei-Shi Zheng, Dr. Xiangyuan Lan and Miss Huiqi Deng for their helpful suggestions.	Adler A, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1163; Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Nguyen A, 2017, PROC CVPR IEEE, P3510, DOI 10.1109/CVPR.2017.374; [Anonymous], 2018, RANDOM PROBABILITY M; Apple Inc, 2017, FAC ID SEC; Arjovsky M, 2017, PR MACH LEARN RES, V70; Banerjee S, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P37, DOI 10.1109/BTAS.2017.8272680; Berthelot D., 2017, BEGAN BOUNDARY EQUIL, DOI DOI 10.48550/ARXIV.1703.10717; Biggio B, 2015, IEEE SIGNAL PROC MAG, V32, P31, DOI 10.1109/MSP.2015.2426728; Cole F, 2017, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2017.361; Dokuchaev  N., 2015, PROBABILITY THEORY C; Feng YC, 2014, PATTERN RECOGN, V47, P3019, DOI 10.1016/j.patcog.2014.03.003; Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760; Galbally J, 2010, PATTERN RECOGN, V43, P1027, DOI 10.1016/j.patcog.2009.08.022; Gao H., 2017, ARXIV170506820; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodfellow Ian, 2016, NIPS 2016 TUTORIAL G; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Gulrajani I, 2017, P NIPS 2017; Hayat M, 2017, PROC CVPR IEEE, P1551, DOI 10.1109/CVPR.2017.169; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang G., 2012, ADV NEURAL INFORM PR, P764; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Hussain S. U., 2012, BRIT MACH VIS C, P11; Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kawulok M., 2016, ADV FACE DETECTION F, P189, DOI DOI 10.1007/978-3-319-25958-1_8; Kingma D.P, P 3 INT C LEARNING R; Klambauer Gnter, 2017, SELF NORMALIZING NEU; Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803; Liao SC, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014); Lim MH, 2016, PATTERN RECOGN, V60, P706, DOI 10.1016/j.patcog.2016.06.018; Liu SQ, 2016, LECT NOTES COMPUT SC, V9911, P85, DOI 10.1007/978-3-319-46478-7_6; Liu Y, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278091; Mai GC, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P374, DOI 10.1109/BTAS.2017.8272719; Mai G, 2017, IMAGE VISION COMPUT, V58, P254, DOI 10.1016/j.imavis.2016.11.011; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35; Mignon A, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.103; Moghaddam B, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P30, DOI 10.1109/AFGR.1998.670921; Mohanty P, 2007, IEEE T PATTERN ANAL, V29, P2065, DOI 10.1109/TPAMI.2007.1129; Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849; Otto C, 2018, IEEE T PATTERN ANAL, V40, P289, DOI 10.1109/TPAMI.2017.2679100; Parkhi Omkar M., 2015, BRIT MACH VIS C; Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288; Phillips J.J., 2005, PROC CVPR IEEE, V1, P947, DOI DOI 10.1109/CVPR.2005.268; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Salimans T, 2016, ADV NEUR IN, V29; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shao R, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P748, DOI 10.1109/BTAS.2017.8272765; Stallings W., 2017, CRYPTOGRAPHY NETWORK; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586; Wang DY, 2017, IEEE T PATTERN ANAL, V39, P1122, DOI 10.1109/TPAMI.2016.2582166; Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Yi D., 2014, LEARNING FACE REPRES, V1411, P7923; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhmoginov Andrey, 2016, INVERTING FACE EMBED	67	51	53	6	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1188	1202		10.1109/TPAMI.2018.2827389	http://dx.doi.org/10.1109/TPAMI.2018.2827389			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993435	Green Submitted			2022-12-18	WOS:000463607400012
J	Li, W; Abtahi, F; Zhu, ZG; Yin, LJ				Li, Wei; Abtahi, Farnaz; Zhu, Zhigang; Yin, Lijun			EAC-Net: Deep Nets with Enhancing and Cropping for Facial Action Unit Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional neural network; facial analysis; attention coding; regions of interest; facial occlusion; head poses		In this paper, we propose a deep learning based approach for facial action unit (AU) detection by enhancing and cropping regions of interest of face images. The approach is implemented by adding two novel nets (a.k.a. layers): the enhancing layers and the cropping layers, to a pretrained convolutional neural network (CNN) model. For the enhancing layers (noted as E-Net), we have designed an attention map based on facial landmark features and apply it to a pretrained neural network to conduct enhanced learning. For the cropping layers (noted as C-Net), we crop facial regions around the detected landmarks and design individual convolutional layers to learn deeper features for each facial region. We then combine the E-Net and the C-Net to construct a so-called Enhancing and Cropping Net (EAC-Net), which can learn both features enhancing and region cropping functions effectively. The EAC-Net integrates three important elements, i.e., learning transfer, attention coding, and regions of interest processing, making our AU detection approach more efficient and more robust to facial position and orientation changes. Our approach shows a significant performance improvement over the state-of-the-art methods when tested on the BP4D and DISFA AU datasets. The EAC-Net with a slight modification also shows its potentials in estimating accurate AU intensities. We have also studied the performance of the proposed EAC-Net under two very challenging conditions: (1) faces with partial occlusion and (2) faces with large head pose variations. Experimental results show that (1) the EAC-Net learns facial AUs correlation effectively and predicts AUs reliably even with only half of a face being visible, especially for the lower half; (2) Our EAC-Net model also works well under very large head poses, which outperforms significantly a compared baseline approach. It further shows that the EAC-Net works much better without a face frontalization than with face frontalization through image warping as pre-processing, in terms of computational efficiency and AU detection accuracy.	[Li, Wei; Zhu, Zhigang] CUNY City Coll, Grove Sch Engn, Dept Elect Engn, New York, NY 10031 USA; [Abtahi, Farnaz; Zhu, Zhigang] CUNY, Grad Ctr, Dept Comp Sci, New York, NY 10016 USA; [Yin, Lijun] SUNY Binghamton, Thomas J Watson Sch Engn & Appl Sci, Dept Comp Sci, Binghamton, NY 13902 USA	City University of New York (CUNY) System; City College of New York (CUNY); City University of New York (CUNY) System; State University of New York (SUNY) System; State University of New York (SUNY) Binghamton	Li, W (corresponding author), CUNY City Coll, Grove Sch Engn, Dept Elect Engn, New York, NY 10031 USA.	wli3@ccny.cuny.edu; fabtahi@gradcenter.cuny.edu; zhu@cs.ccny.cuny.edu; lijun@cs.binghamton.edu			US National Science Foundation [EFRI -1137172, CNS-1629898, CNS-1205664]; VentureWell [10087-12]; Directorate For Engineering [1137172] Funding Source: National Science Foundation	US National Science Foundation(National Science Foundation (NSF)); VentureWell; Directorate For Engineering(National Science Foundation (NSF)NSF - Directorate for Engineering (ENG))	This work is supported by the US National Science Foundation through Award EFRI -1137172, and VentureWell (formerly NCIIA) through Award 10087-12. The material is also based upon the work supported in part by the US National Science Foundation under grants CNS-1629898 and CNS-1205664.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; BALTRUSAITIS T., 2015, 2015 11 IEEE INT C W, V06, P1, DOI [10.1109/FG.2015.7284869, DOI 10.1109/FG.2015.7284869]; Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600; Chu Wen-Sheng, 2013, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2013, P3515; Ding XY, 2013, IEEE I CONF COMP VIS, P2400, DOI 10.1109/ICCV.2013.298; Ekman Paul, 1997, WHAT FACE REVEALS BA, P2; Eleftheriadis S, 2015, IEEE I CONF COMP VIS, P3792, DOI 10.1109/ICCV.2015.432; Gehrig Tobias, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163152; Girard Jeffrey M., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163106; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Grafsgaard Joseph F., 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P1, DOI 10.1007/978-3-642-39112-5_1; Gudi A., 2015, 2015 11 IEEE INT C W, V6, P1; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hu Y, 2008, PROC CVPR IEEE, P85; Jaiswal Shashank, 2016, APPL COMP VIS WACV 2, P1, DOI DOI 10.1109/WACV.2016.7477625; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50; Li W, 2017, PROC CVPR IEEE, P6766, DOI 10.1109/CVPR.2017.716; Li W, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P482, DOI 10.1145/2818346.2830583; Liu YL, 2013, IEEE INT WORKS GENET, P1, DOI 10.1109/GEFS.2013.6601048; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4; Nicolle J, 2015, 2015 11 IEEE INT C W, V6, P1, DOI DOI 10.1109/FG.2015.7284868; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Song Yale, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163081; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Valstar M., 2006, COMP VIS PATT REC WO, P149; Valstar MF, 2017, IEEE INT CONF AUTOMA, P839, DOI 10.1109/FG.2017.107; Wang ZH, 2013, IEEE I CONF COMP VIS, P3304, DOI 10.1109/ICCV.2013.410; Wu Y, 2016, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2016.370; Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Zeng JB, 2015, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2015.413; Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002; Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374; Zhao KL, 2016, PROC CVPR IEEE, P3391, DOI 10.1109/CVPR.2016.369; Zhao KL, 2015, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2015.7298833; Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731	41	51	53	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2583	2596		10.1109/TPAMI.2018.2791608	http://dx.doi.org/10.1109/TPAMI.2018.2791608			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29994168	hybrid			2022-12-18	WOS:000446683700005
J	Chen, X; Weng, J; Lu, W; Xu, JM				Chen, Xin; Weng, Jian; Lu, Wei; Xu, Jiaming			Multi-Gait Recognition Based on Attribute Discovery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-gait recognition; attributes; human graphlets; dense trajectories; latent structural SVM	RECOGNIZING GAITS; ENERGY IMAGE; PERFORMANCE; EXTRACTION; MODEL	Gait recognition is an important topic in biometrics. Current works primarily focus on recognizing a single person's walking gait. However, a person's gait will change when they walk with other people. How to recognize the gait of multiple people walking is still a challenging problem. This paper proposes an attribute discovery model in a max-margin framework to recognize a person based on gait while walking with multiple people. First, human graphlets are integrated into a tracking-by-detection method to obtain a person's complete silhouette. Then, stable and discriminative attributes are developed using a latent conditional random field (L-CRF) model. The model is trained in the latent structural support vector machine (SVM) framework, in which a new constraint is added to improve the multi-gait recognition performance. In the recognition process, the attribute set of each person is detected by inferring on the trained L-CRF model. Finally, attributes based on dense trajectories are extracted as the final gait features to complete the recognition. The experimental results demonstrate that the proposed method achieves better recognition performance than traditional gait recognition methods under the condition of multiple people walking together.	[Chen, Xin; Weng, Jian] Jinan Univ, Guangdong Engn Res Ctr Data Secur & Privacy Prese, Guangzhou Key Lab Data Secur & Privacy Preserving, Guangzhou 510632, Guangdong, Peoples R China; [Chen, Xin; Weng, Jian] Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Guangdong, Peoples R China; [Lu, Wei] Sun Yat Sen Univ, Guangdong Key Lab Informat Secur Technol, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China; [Xu, Jiaming] Baiyun Dist Bur Justice, Guangzhou 510405, Guangdong, Peoples R China	Jinan University; Jinan University; Sun Yat Sen University	Weng, J (corresponding author), Jinan Univ, Guangdong Engn Res Ctr Data Secur & Privacy Prese, Guangzhou Key Lab Data Secur & Privacy Preserving, Guangzhou 510632, Guangdong, Peoples R China.; Weng, J (corresponding author), Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Guangdong, Peoples R China.	chenxin@stu.jnu.edu.cn; cryptjweng@gmail.com; luwei3@mail.sysu.edu.cn; 19910411xjm@sina.com		Lu, Wei/0000-0002-4068-1766	National Science Foundation of China [61472165, 61373158]; Guangdong Provincial Engineering Technology Research Center on Network Security Detection and Defence [2014B090904067]; Guangdong Provincial Special Funds for Applied Technology Research and development and Transformation of Important Scientific and Technological Achieve [2016B010124009]; Zhuhai Top Discipline-Information Security Guangzhou Key Laboratory of Data Security and Privacy Preserving, Guangdong Key Laboratory of Data Security and Privacy Preserving; National Natural Science Foundation of China; Natural Science Foundation of Guangdong [2016A030313350]; Special Funds for Science and Technology Development of Guangdong [2016KZ010103]; Fundamental Research Funds for the Central Universities [16lgjc83]; Scientific and Technological Achievements Transformation Plan of Sun Yat-sen University	National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Guangdong Provincial Engineering Technology Research Center on Network Security Detection and Defence; Guangdong Provincial Special Funds for Applied Technology Research and development and Transformation of Important Scientific and Technological Achieve; Zhuhai Top Discipline-Information Security Guangzhou Key Laboratory of Data Security and Privacy Preserving, Guangdong Key Laboratory of Data Security and Privacy Preserving; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Guangdong(National Natural Science Foundation of Guangdong Province); Special Funds for Science and Technology Development of Guangdong; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Scientific and Technological Achievements Transformation Plan of Sun Yat-sen University	This work was supported by National Science Foundation of China (Grant Nos. 61472165 and 61373158), Guangdong Provincial Engineering Technology Research Center on Network Security Detection and Defence (Grant No. 2014B090904067), Guangdong Provincial Special Funds for Applied Technology Research and development and Transformation of Important Scientific and Technological Achieve (Grant No. 2016B010124009), the Zhuhai Top Discipline-Information Security Guangzhou Key Laboratory of Data Security and Privacy Preserving, Guangdong Key Laboratory of Data Security and Privacy Preserving, the National Natural Science Foundation of China, the Natural Science Foundation of Guangdong (No. 2016A030313350), the Special Funds for Science and Technology Development of Guangdong (No. 2016KZ010103), the Fundamental Research Funds for the Central Universities (No. 16lgjc83), and Scientific and Technological Achievements Transformation Plan of Sun Yat-sen University.	Ahmed E., 2015, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2015.7299016; Alotaibi M., 2015, 2015 IEEE APPL IM PA, P1, DOI DOI 10.1109/AIPR.2015.7444550; Bashir K., 2009, BMVC, P1; Bashir K., 2009, 3 INT C IMAGING CRIM, P1, DOI DOI 10.1049/IC.2009.0230; Bibby C, 2010, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2010.5539818; Bouchrika I, 2007, LECT NOTES COMPUT SC, V4418, P150; Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012; Chen S, 2014, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2014.148; Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149; Chun-Chieh Lee, 2011, Proceedings of the 2011 International Conference on Machine Learning and Cybernetics (ICMLC 2011), P1785, DOI 10.1109/ICMLC.2011.6017007; Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]; Cunado D, 1997, LECT NOTES COMPUT SC, V1206, P95; Deng Z., 2015, P BRIT MACH VIS C, P1; Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Fragkiadaki K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2073, DOI 10.1109/CVPR.2011.5995366; Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128; Geng Mengyue, 2016, ARXIV161105244V2; Gross Ralph, 2001, CMURITR0118; Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605; Huang XX, 2012, IEEE T IMAGE PROCESS, V21, P2256, DOI 10.1109/TIP.2011.2180914; Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217; Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3; Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Kong Y, 2014, IEEE T PATTERN ANAL, V36, P1775, DOI 10.1109/TPAMI.2014.2303090; Krause J, 2014, INT C PATT RECOG, P26, DOI 10.1109/ICPR.2014.15; Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587; Kusakunniran W, 2014, IEEE T INF FOREN SEC, V9, P1416, DOI 10.1109/TIFS.2014.2336379; Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552; Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113; Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228; Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536; Lin L, 2016, INT J COMPUT VISION, V118, P256, DOI 10.1007/s11263-015-0876-z; Liu Jiawei, 2016, ACM MM, P192, DOI [10.1145/2964284.2967209, DOI 10.1145/2964284.2967209]; Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122; Makihara Y., 2012, IPSJ T COMPUT VISION, V4, P53, DOI DOI 10.2197/ipsjtcva.4.53; Matovski DS, 2012, IEEE T INF FOREN SEC, V7, P543, DOI 10.1109/TIFS.2011.2176118; Milan A, 2015, PROC CVPR IEEE, P5397, DOI 10.1109/CVPR.2015.7299178; NAM H, 2016, PROC CVPR IEEE, P4293, DOI DOI 10.1109/CVPR.2016.465; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Schnitzspan P, 2010, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2010.5540220; Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44; SHI Y, 2006, IEEE 7 INT C EL PACK, P1; Shiraga K., 2016, IEEE INT C BIOM, V2016, P1, DOI DOI 10.1109/ICB.2016.7550060; Su C., 2016, P IEEE IND APPL SOC, P1, DOI [10.1109/IAS.2016.7731939, DOI 10.1109/IAS.2016.7731939]; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tompson J.J., 2014, ADV NEURAL INFORM PR, V27, P1799; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48; Wagnild J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076576; Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260; Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144; Wang Y, 2009, PROC CVPR IEEE, P872, DOI 10.1109/CVPRW.2009.5206709; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669; Xu D, 2012, IEEE T IMAGE PROCESS, V21, P316, DOI 10.1109/TIP.2011.2160956; YANG Y, 2011, PROC CVPR IEEE, P1385, DOI [10.1109/CVPR.2011.5995741, DOI 10.1109/CVPR.2011.5995741]; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]; Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024; Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424; Zheng L., 2017, ARXIV170107732V1; Zheng L., 2016, ARXIV PREPRINT ARXIV; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng Z, 2017, ACM T MULTIM COMPUT, V14, P1, DOI DOI 10.1145/3159171; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zhong Zhun, 2017, PROC CVPR IEEE, P1318, DOI DOI 10.1109/CVPR.2017.389; Zhou Liu, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286491; Zhu YY, 2013, PROC CVPR IEEE, P2491, DOI 10.1109/CVPR.2013.322	74	51	53	4	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1697	1710		10.1109/TPAMI.2017.2726061	http://dx.doi.org/10.1109/TPAMI.2017.2726061			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28708545	hybrid			2022-12-18	WOS:000434294800012
J	Koniusz, P; Yan, F; Gosselin, PH; Mikolajczyk, K				Koniusz, Piotr; Yan, Fei; Gosselin, Philippe-Henri; Mikolajczyk, Krystian			Higher-Order Occurrence Pooling for Bags-of-Words: Visual Concept Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bag-of-words; mid-level features; first-order; second-order; co-occurrence; pooling operator; sparse coding		In object recognition, the Bag-of-Words model assumes: i) extraction of local descriptors from images, ii) embedding the descriptors by a coder to a given visual vocabulary space which results in mid-level features, iii) extracting statistics from mid-level features with a pooling operator that aggregates occurrences of visual words in images into signatures, which we refer to as First-order Occurrence Pooling. This paper investigates higher-order pooling that aggregates over co-occurrences of visual words. We derive Bag-of-Words with Higher-order Occurrence Pooling based on linearisation of Minor Polynomial Kernel, and extend this model to work with various pooling operators. This approach is then effectively used for fusion of various descriptor types. Moreover, we introduce Higher-order Occurrence Pooling performed directly on local image descriptors as well as a novel pooling operator that reduces the correlation in the image signatures. Finally, First-, Second-, and Third-order Occurrence Pooling are evaluated given various coders and pooling operators on several widely used benchmarks. The proposed methods are compared to other approaches such as Fisher Vector Encoding and demonstrate improved results.	[Koniusz, Piotr; Yan, Fei] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford, Surrey, England; [Koniusz, Piotr] NICTA Canberra Res Lab, Comp Vis Res Grp, Canberra, ACT, Australia; [Gosselin, Philippe-Henri] Ecole Natl Super Elect & Applicat, ETIS, Cergy, France; [Mikolajczyk, Krystian] Imperial Coll London, Imperial Comp Vis & Learning Lab, London, England	University of Surrey; Imperial College London	Koniusz, P (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford, Surrey, England.; Koniusz, P (corresponding author), NICTA Canberra Res Lab, Comp Vis Res Grp, Canberra, ACT, Australia.	piotr.koniusz@nicta.com.au; f.yan@surrey.ac.uk; philippe-henri.gosselin@ensea.fr; k.mikolajczyk@imperial.ac.uk			EU Chist-Era EPSRC Visual Sense project [EP/K01904X/1]; BBC; Engineering and Physical Sciences Research Council [EP/N007743/1, EP/K01904X/2] Funding Source: researchfish; EPSRC [EP/N007743/1, EP/K01904X/2] Funding Source: UKRI	EU Chist-Era EPSRC Visual Sense project; BBC; Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work has been supported by EU Chist-Era EPSRC EP/K01904X/1 Visual Sense project and the BBC. The authors would also like to thank Prof. Adrian Hilton (CVSSP) and Dr. Julien Mairal (INRIA LEAR) for their support in preparing this manuscript.	Awais M, 2011, LECT NOTES ARTIF INT, V6911, P140, DOI 10.1007/978-3-642-23780-5_19; Azizpour H., 2014, GENERIC SPECIFIC DEE; Bilmes J., 1997, TR97021 INT COMP SCI; Binder A., 2011, CLEF; Boughorbel S., 2005, P IEEE INT C IM PROC, V3; Boureau Y.L., 2010, P 27 INT C MACH LEAR, P111; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; Everingham M., 2012, PASCAL VISUAL OBJECT; Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943; Gevers T, 2008, P 2008 INT C CONT BA, P141, DOI DOI 10.1145/1386352.1386376; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Huiskes Mark J, 2008, P 1 ACM INT C MULTIM, P39, DOI DOI 10.1145/1460096.1460104; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609; Khan FS, 2014, IEEE T IMAGE PROCESS, V23, P3633, DOI 10.1109/TIP.2014.2331759; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Koniusz P., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2413, DOI 10.1109/ICIP.2011.6116129; Koniusz P., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P762, DOI 10.1109/ICPR.2010.192; Koniusz P., 2013, THESIS; Koniusz P., 2012, COMPUTER VISION IMAG, V117, P479; Koniusz P, 2013, HIGHERORDER OCCURREN; Koniusz P, 2011, IEEE IMAGE PROC, P661; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lee H., 2007, ADV NEURAL INF PROCE, P801; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Lingqiao L., 2011, P INT C COMP VIS, P2486; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Mairal J., 2014, NIPS; Mairal J, 2010, J MACH LEARN RES, V11, P19; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Negrel R, 2012, IEEE IMAGE PROC, P2425, DOI 10.1109/ICIP.2012.6467387; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Nowak S., 2011, CLEF; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Philbin James, 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), DOI 10.1109/CVPR.2008.4587635; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Sanchez J, 2012, PATTERN RECOGN LETT, V33, P2216, DOI 10.1016/j.patrec.2012.07.019; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Tahir M. A., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P178, DOI 10.1109/ICCVW.2009.5457703; Tahir M. A., 2010, P ICPR CONT REC PATT, P162; van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Xiao J., 2014, P INT J COMP VIS; Yan F., 2014, P 12 AS C COMP VIS, P613; Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966; Yan F, 2010, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2010.5539916; Yang J, 2007, MULTIMEDIA C EXHIBIT, P197, DOI [10.1145/1290082.1290111, DOI 10.1145/1290082.1290111]; Yang JC, 2012, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2012.6247948; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yang JJ, 2012, IEEE T IMAGE PROCESS, V21, P2838, DOI 10.1109/TIP.2012.2183139; Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386; Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368; Yu Kai, 2009, ADV NEURAL INFORM PR, P2223; Yu XN, 2011, PROC SPIE, V7877, DOI 10.1117/12.872257; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11	64	51	54	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					313	326		10.1109/TPAMI.2016.2545667	http://dx.doi.org/10.1109/TPAMI.2016.2545667			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	27019477	Green Submitted			2022-12-18	WOS:000395553400008
J	Li, Q; Schonfeld, D				Li, Qun; Schonfeld, Dan			Multilinear Discriminant Analysis for Higher-Order Tensor Data Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Linear discriminant analysis (LDA); multilinear discriminant analysis (MDA); direct general tensor discriminant analysis (DGTDA); constrained multilinear discriminant analysis (CMDA); pattern classification; higher-order tensor	RECOGNITION; ILLUMINATION; EIGENFACES	In the past decade, great efforts have been made to extend linear discriminant analysis for higher-order data classification, generally referred to as multilinear discriminant analysis (MDA). Existing examples include general tensor discriminant analysis (GTDA) and discriminant analysis with tensor representation (DATER). Both the two methods attempt to resolve the problem of tensor mode dependency by iterative approximation. GTDA is known to be the first MDA method that converges over iterations. However, its performance relies highly on the tuning of the parameter in the scatter difference criterion. Although DATER usually results in better classification performance, it does not converge, yet the number of iterations executed has a direct impact on DATER's performance. In this paper, we propose a closed-form solution to the scatter difference objective in GTDA, namely, direct GTDA (DGTDA) which also gets rid of parameter tuning. We demonstrate that DGTDA outperforms GTDA in terms of both efficiency and accuracy. In addition, we propose constrained multilinear discriminant analysis (CMDA) that learns the optimal tensor subspace by iteratively maximizing the scatter ratio criterion. We prove both theoretically and experimentally that the value of the scatter ratio criterion in CMDA approaches its extreme value, if it exists, with bounded error, leading to superior and more stable performance in comparison to DATER.	[Li, Qun] Xerox Corp, PARC, Webster, NY 14580 USA; [Schonfeld, Dan] Univ Illinois, Dept Elect & Comp Engn, Chicago, IL 60607 USA	Xerox; University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	Li, Q (corresponding author), Xerox Corp, PARC, Webster, NY 14580 USA.	Qun.Li@xerox.com; dans@uic.edu						[Anonymous], 2003, PROC CVPR IEEE; [Anonymous], 2001, USF HUMAN ID GAIT CH; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Cai D., 2005, UIUCDCSR20052572 U I; Duda R.O., 2000, PATTERN CLASSIFICATI; Fukunaga R., 1990, INTRO STAT PATT CLAS; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; He X, 2006, ADV NEURAL INFORM PR, P499; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Kong H, 2005, INT CONF ACOUST SPEE, P761; Li Q, 2011, INT CONF ACOUST SPEE, P873; LIU K, 1993, PATTERN RECOGN, V26, P903, DOI 10.1016/0031-3203(93)90056-3; Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004; Lu HP, 2009, IEEE T NEURAL NETWOR, V20, P103, DOI 10.1109/TNN.2008.2004625; Shashua A, 2001, PROC CVPR IEEE, P42; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Tao D., 2006, P IEEE INT C AC SPEE, V2, P177; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang HA, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P629; Wang Y, 2006, INT C PATT RECOG, P33; Yan SC, 2005, PROC CVPR IEEE, P526; Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097; Ye J., 2005, ADV NEURAL INFORM PR, P1569, DOI DOI 10.5555/2976040.2976237	26	51	51	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2524	2537		10.1109/TPAMI.2014.2342214	http://dx.doi.org/10.1109/TPAMI.2014.2342214			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353155				2022-12-18	WOS:000344988000014
J	Min, DB; Lu, JB; Do, MN				Min, Dongbo; Lu, Jiangbo; Do, Minh N.			Joint Histogram-Based Cost Aggregation for Stereo Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cost aggregation; stereo matching; disparity hypotheses; joint histogram		This paper presents a novel method for performing efficient cost aggregation in stereo matching. The cost aggregation problem is reformulated from the perspective of a histogram, giving us the potential to reduce the complexity of the cost aggregation in stereo matching significantly. Differently from previous methods which have tried to reduce the complexity in terms of the size of an image and a matching window, our approach focuses on reducing the computational redundancy that exists among the search range, caused by a repeated filtering for all the hypotheses. Moreover, we also reduce the complexity of the window-based filtering through an efficient sampling scheme inside the matching window. The tradeoff between accuracy and complexity is extensively investigated by varying the parameters used in the proposed method. Experimental results show that the proposed method provides high-quality disparity maps with low complexity and outperforms existing local methods. This paper also provides new insights into complexity-constrained stereo-matching algorithm design.	[Min, Dongbo; Lu, Jiangbo] Adv Digital Sci Ctr, Singapore, Singapore; [Do, Minh N.] Univ Illinois, Coordinated Sci Lab 115, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Min, DB (corresponding author), Adv Digital Sci Ctr, 1 Fusionopolis Way,08-10 Connexis North Tower, Singapore, Singapore.	dongbo@adsc.com.sg; jiangbo.lu@adsc.com.sg; minhdo@illinois.edu	N., Minh/AAX-8498-2020	N., Minh/0000-0001-5132-4986	Human Sixth Sense Programme at the Advanced Digital Sciences Center from Singapore's Agency for Science, Technology and Research (A*STAR)	Human Sixth Sense Programme at the Advanced Digital Sciences Center from Singapore's Agency for Science, Technology and Research (A*STAR)(Agency for Science Technology & Research (A*STAR))	This study is supported by the research grant for the Human Sixth Sense Programme at the Advanced Digital Sciences Center from Singapore's Agency for Science, Technology and Research (A*STAR).	Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; De-Maeztu L, 2011, IEEE I CONF COMP VIS, P1708, DOI 10.1109/ICCV.2011.6126434; De-Maeztu L, 2012, IEEE T PATTERN ANAL, V34, P410, DOI 10.1109/TPAMI.2011.192; Dima C, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P3347, DOI 10.1109/ROBOT.2002.1014228; Ding JT, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-20; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; He KM, 2010, LECT NOTES COMPUT SC, V6311, P1; Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Lu JB, 2012, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2012.6247705; Mattoccia Stefano, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P371; Min D, 2008, IEEE T IMAGE PROCESS, V17, P1431, DOI 10.1109/TIP.2008.925372; Min DB, 2011, IEEE I CONF COMP VIS, P1567, DOI 10.1109/ICCV.2011.6126416; Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8; Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372; Richardt C, 2010, LECT NOTES COMPUT SC, V6313, P510; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Tombari F, 2008, INT C PATT RECOG, P336; Wang L, 2008, LECT NOTES COMPUT SC, V5302, P576, DOI 10.1007/978-3-540-88682-2_44; Yang Q., 2012, P EUR C COMP VIS; Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827; Yang QX, 2010, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2010.5539797; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70; Yoon KJ, 2007, IEEE I CONF COMP VIS, P1357; Yu T., 2007, P WORKSH MOT VID COM, P1; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345; Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478	30	51	58	0	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2539	2545		10.1109/TPAMI.2013.15	http://dx.doi.org/10.1109/TPAMI.2013.15			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969395				2022-12-18	WOS:000323175200017
J	Zhou, XD; Wang, DH; Tian, F; Liu, CL; Nakagawa, M				Zhou, Xiang-Dong; Wang, Da-Han; Tian, Feng; Liu, Cheng-Lin; Nakagawa, Masaki			Handwritten Chinese/Japanese Text Recognition Using Semi-Markov Conditional Random Fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Character string recognition; semi-Markov conditional random field; lattice pruning; beam search	CHINESE CHARACTERS; SEGMENTATION; ONLINE; ALGORITHM	This paper proposes a method for handwritten Chinese/Japanese text (character string) recognition based on semi-Markov conditional random fields (semi-CRFs). The high-order semi-CRF model is defined on a lattice containing all possible segmentation-recognition hypotheses of a string to elegantly fuse the scores of candidate character recognition and the compatibilities of geometric and linguistic contexts by representing them in the feature functions. Based on given models of character recognition and compatibilities, the fusion parameters are optimized by minimizing the negative log-likelihood loss with a margin term on a training string sample set. A forward-backward lattice pruning algorithm is proposed to reduce the computation in training when trigram language models are used, and beam search techniques are investigated to accelerate the decoding speed. We evaluate the performance of the proposed method on unconstrained online handwritten text lines of three databases. On the test sets of databases CASIA-OLHWDB (Chinese) and TUAT Kondate (Japanese), the character level correct rates are 95.20 and 95.44 percent, and the accurate rates are 94.54 and 94.55 percent, respectively. On the test set (online handwritten texts) of ICDAR 2011 Chinese handwriting recognition competition, the proposed method outperforms the best system in competition.	[Zhou, Xiang-Dong; Tian, Feng] Chinese Acad Sci, Beijing Key Lab Human Comp Interact, Inst Software, Beijing 100190, Peoples R China; [Tian, Feng] Chinese Acad Sci, State Key Lab Comp Sci, Beijing 100190, Peoples R China; [Wang, Da-Han; Liu, Cheng-Lin] Chinese Acad Sci, NLPR, Inst Automat, Beijing 100190, Peoples R China; [Nakagawa, Masaki] Tokyo Univ Agr & Technol, Dept Comp & Informat Sci, Koganei, Tokyo 1848588, Japan	Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of Automation, CAS; Tokyo University of Agriculture & Technology	Zhou, XD (corresponding author), Chinese Acad Sci, Beijing Key Lab Human Comp Interact, Inst Software, Beijing 100190, Peoples R China.	xiangdong@iscas.ac.cn; dhwang@nlpr.ia.ac.cn; tianfeng@iscas.ac.cn; liucl@nlpr.ia.ac.cn; nakagawa@cc.tuat.ac.jp	Nakagawa, Masaki/AAJ-5253-2020; Nakagawa, Masaki/B-9966-2013	Nakagawa, Masaki/0000-0001-7872-156X; Nakagawa, Masaki/0000-0001-7872-156X	National Natural Science Foundation of China [61273269, 60933010, 61232013, 61170182]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China under grants nos. 61273269, 60933010, 61232013, and 61170182. The authors would like to thank Qiu-Feng Wang, Yan-Ming Zhang, and Liang Huang for valuable discussions.	Artieres T., 2006, P 10 INT WORKSH FRON, P197; Bahl L. R., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P49; Cheriet M, 2007, CHARACTER RECOGNITION SYSTEMS: A GUIDE FOR STUDENTS AND PRACTIONERS, P1, DOI 10.1002/9780470176535; Cohn T, 2006, LECT NOTES COMPUT SC, V4212, P606; Feng SL, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P30; Fu Q, 2006, INT C PATT RECOG, P974; Gao X, 2005, PROC INT CONF DOC, P735; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Heigold G., 2008, INT C MACH LEARN ICM, P384; Heigold G, 2010, IEEE J-STSP, V4, P917, DOI 10.1109/JSTSP.2010.2076110; Hotta Y, 2005, PROC INT CONF DOC, P685, DOI 10.1109/ICDAR.2005.41; Jeong M, 2009, P ACL IJCNLP 2009 C, P281; Jiang ZW, 2011, PROC INT CONF DOC, P668, DOI 10.1109/ICDAR.2011.140; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Kim M, 2010, PATTERN RECOGN, V43, P3683, DOI 10.1016/j.patcog.2010.05.013; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Li NX, 2013, INT J DOC ANAL RECOG, V16, P17, DOI 10.1007/s10032-011-0178-0; Liang ZZ, 2005, PATTERN RECOGN LETT, V26, P1498, DOI 10.1016/j.patrec.2004.12.001; Liu C.-L., 2006, P 10 IWFHR, P217; Liu CL, 2006, INT C PATT RECOG, P942; Liu CL, 2011, PROC INT CONF DOC, P1464, DOI 10.1109/ICDAR.2011.291; Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17; Liu CL, 2005, PROC INT CONF DOC, P846; Liu CL, 2005, PATTERN RECOGN, V38, P11, DOI 10.1016/j.patcog.2004.05.013; Liu CL, 2004, IEEE T PATTERN ANAL, V26, P1395, DOI 10.1109/TPAMI.2004.104; Liu CL, 2004, IEEE T PATTERN ANAL, V26, P198, DOI 10.1109/TPAMI.2004.1262182; Liu CL, 2002, IEEE T PATTERN ANAL, V24, P1425, DOI 10.1109/TPAMI.2002.1046151; Long T, 2008, TOP GERIATR REHABIL, V24, P1; Lu Y, 2002, INT J PATTERN RECOGN, V16, P85, DOI 10.1142/S0218001402001551; Matsumoto K, 2001, PROC INT CONF DOC, P496, DOI 10.1109/ICDAR.2001.953839; Murase H., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P1143, DOI 10.1109/ICPR.1988.28462; Nakagawa M, 2005, IEICE T INF SYST, VE88D, P1815, DOI 10.1093/ietisy/e88-d.8.1815; Nguyen V.C, 2011, P 28 INT C MACH LEAR; Okanohara D, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P465; Ortmanns S, 1997, COMPUT SPEECH LANG, V11, P43, DOI 10.1006/csla.1996.0022; PAL C, 2006, INT CONF ACOUST SPEE, P581; Povey D., 2003, THESIS; Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545; Qian Xian, 2009, ICML; Qiu-Feng Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1036, DOI 10.1109/ICDAR.2009.96; Sarawagi S., 2005, ADV NEURAL INFORM PR, V17, P1185; Senda S., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P184, DOI 10.1109/ICDAR.2001.953780; Shetty S, 2007, PROC SPIE, V6500, DOI 10.1117/12.704410; Sixtus A, 1999, INT CONF ACOUST SPEE, P593, DOI 10.1109/ICASSP.1999.759736; Stolcke Andreas, 2002, P INT, P901; Su TH, 2009, PATTERN RECOGN, V42, P167, DOI 10.1016/j.patcog.2008.05.012; Sutton C., 2006, INT STAT RELAT LEARN, V2, P93; Tang HS, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P263; Trinh-Minh-Tri Do, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P976, DOI 10.1109/ICDAR.2009.221; Tseng LY, 1998, PATTERN RECOGN LETT, V19, P963, DOI 10.1016/S0167-8655(98)00073-7; Tulyakov S., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P164, DOI 10.1109/ICDAR.2001.953776; Wang CH, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P539; Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264; Wei XH, 2005, PROC INT CONF DOC, P645; Xiang-Dong Zhou, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P521, DOI 10.1109/ICDAR.2009.95; Yao ZB, 2006, INT C PATT RECOG, P320; Ye N, 2009, P 22 ANN C NEUR INF, P1393; Yu D, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P429, DOI 10.1109/ICSC.2007.11; Zhao SY, 2003, PATTERN RECOGN, V36, P145, DOI 10.1016/S0031-3203(02)00041-9; Zhou XD, 2007, PROC INT CONF DOC, P48; Zhu B, 2011, PROC INT CONF DOC, P1130, DOI 10.1109/ICDAR.2011.228; Zhu BL, 2010, INT J DOC ANAL RECOG, V13, P121, DOI 10.1007/s10032-009-0111-y	63	51	55	0	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2413	2426		10.1109/TPAMI.2013.49	http://dx.doi.org/10.1109/TPAMI.2013.49			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969386				2022-12-18	WOS:000323175200008
J	Heo, YS; Lee, KM; Lee, SU				Heo, Yong Seok; Lee, Kyoung Mu; Lee, Sang Uk			Joint Depth Map and Color Consistency Estimation for Stereo Images with Different Illuminations and Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; radiometric variation; mutual information; SIFT; color consistency	MUTUAL-INFORMATION; REGISTRATION	In this paper, we propose a method that infers both accurate depth maps and color-consistent stereo images for radiometrically varying stereo images. In general, stereo matching and performing color consistency between stereo images are a chicken-and-egg problem since it is not a trivial task to simultaneously achieve both goals. Hence, we have developed an iterative framework in which these two processes can boost each other. First, we transform the input color images to log-chromaticity color space, from which a linear relationship can be established during constructing a joint pdf of transformed left and right color images. From this joint pdf, we can estimate a linear function that relates the corresponding pixels in stereo images. Based on this linear property, we present a new stereo matching cost by combining Mutual Information (MI), SIFT descriptor, and segment-based plane-fitting to robustly find correspondence for stereo image pairs which undergo radiometric variations. Meanwhile, we devise a Stereo Color Histogram Equalization (SCHE) method to produce color-consistent stereo image pairs, which conversely boost the disparity map estimation. Experimental results show that our method produces both accurate depth maps and color-consistent stereo images, even for stereo images with severe radiometric differences.	[Heo, Yong Seok; Lee, Kyoung Mu; Lee, Sang Uk] Seoul Natl Univ, Dept Elect Engn & Comp Sci, ASRI, Coll Engn, Seoul 151744, South Korea	Seoul National University (SNU)	Heo, YS (corresponding author), Seoul Natl Univ, Dept Elect Engn & Comp Sci, ASRI, Coll Engn, 599 Gwanangno, Seoul 151744, South Korea.	hys@diehard.snu.ac.kr; kyoungmu@snu.ac.kr; sanguk@ipl.snu.ac.kr	Heo, Yong Seok/AAD-8816-2021; Lee, Kyoung Mu/AAC-4063-2020	Lee, Kyoung Mu/0000-0001-7210-1036	NRF of MEST [314-2008-1-D00377]	NRF of MEST(National Research Foundation of Korea)	This work was partly supported by NRF Grant of MEST (314-2008-1-D00377).	Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chakrabarti A., 2009, P BRIT MACH VIS C; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Ebner M, 2007, COLOR CONSTANCY, V7; Egnal Geoffrey, 2000, MUTUAL INFORM STEREO; Finlayson G, 2005, PATTERN RECOGN, V38, P179, DOI 10.1016/j.patcog.2004.04.010; Goesele M., 2007, P IEEE INT C COMP VI; Heo Y. S., 2009, P IEEE INT C COMP VI; Heo Y. S., 2009, P IEEE C COMP VIS PA; Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hirschmuller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221; Hong L., 2004, P IEEE C COMP VIS PA; Hu X., 2010, P IEEE C COMP VIS PA; Jeon H.-H., 2006, P IEEE INT C MULT EX; Kagarlitsky Y. M. S., 2009, P IEEE INT C COMP VI; Kim J., 2003, P IEEE INT C COMP VI; Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732; Lawrence Zitnick C., 2004, P ACM SIGGRAPH, P2; Lin S., 2002, P EUR C COMP VIS; Liu C., 2008, P EUR C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Montesinos P, 2000, IMAGE VISION COMPUT, V18, P659, DOI 10.1016/S0262-8856(99)00070-0; Ogale A. S., 2004, P IEEE INT C ROB AUT; Pluim JPW, 2000, IEEE T MED IMAGING, V19, P809, DOI 10.1109/42.876307; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Russakoff D. B., 2004, P EUR C COMP VIS; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Seitz S. M., 2009, P IEEE INT C COMP VI; Shen L., 2008, P IEEE C COMP VIS PA; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Sun J., 2005, P IEEE C COMP VIS PA; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Weiss Y., 2001, P IEEE INT C COMP VI; Xiong W., 2006, P CAN C COMP ROB VIS; Yang JN, 2002, VISION RES, V42, P1979, DOI 10.1016/S0042-6989(02)00098-6; Zabih R., 1994, P EUR C COMP VIS	39	51	56	1	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1094	1106		10.1109/TPAMI.2012.167	http://dx.doi.org/10.1109/TPAMI.2012.167			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	22868654				2022-12-18	WOS:000316126800006
J	Bergeron, C; Moore, G; Zaretzki, J; Breneman, CM; Bennett, KP				Bergeron, Charles; Moore, Gregory; Zaretzki, Jed; Breneman, Curt M.; Bennett, Kristin P.			Fast Bundle Algorithm for Multiple-Instance Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Artificial intelligence; machine learning; nonsmooth optimization; bundle methods; multiple-instance learning; ranking; medicine and science	CYTOCHROMES P450	We present a bundle algorithm for multiple-instance classification and ranking. These frameworks yield improved models on many problems possessing special structure. Multiple-instance loss functions are typically nonsmooth and nonconvex, and current algorithms convert these to smooth nonconvex optimization problems that are solved iteratively. Inspired by the latest linear-time subgradient-based methods for support vector machines, we optimize the objective directly using a nonconvex bundle method. Computational results show this method is linearly scalable, while not sacrificing generalization accuracy, permitting modeling on new and larger data sets in computational chemistry and other applications. This new implementation facilitates modeling with kernels.	[Bergeron, Charles; Moore, Gregory; Bennett, Kristin P.] Rensselaer Polytech Inst, Dept Math Sci, Troy, NY 12180 USA; [Bergeron, Charles] Rensselaer Polytech Inst, Dept Elect Syst & Comp Engn, Troy, NY 12180 USA; [Zaretzki, Jed; Breneman, Curt M.] Rensselaer Polytech Inst, Dept Chem & Chem Biol, Troy, NY 12180 USA; [Bennett, Kristin P.] Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute	Bergeron, C (corresponding author), Rensselaer Polytech Inst, Dept Math Sci, 110 8th St, Troy, NY 12180 USA.	chbergeron@gmail.com; mooregm@gmail.com; zaretj@gmail.com; brenec@rpi.edu; bennek@rpi.edu			Fonds quebecois de la recherche sur la nature et les technologies; US Office of Naval Research [N00014-06-1-0014]; US National Institutes of Health [R01LM009731]; NATIONAL LIBRARY OF MEDICINE [R01LM009731] Funding Source: NIH RePORTER	Fonds quebecois de la recherche sur la nature et les technologies(FQRNT); US Office of Naval Research(Office of Naval Research); US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL LIBRARY OF MEDICINE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM))	This work was funded by the Fonds quebecois de la recherche sur la nature et les technologies doctoral fellowship program and grants by the US Office of Naval Research (number N00014-06-1-0014) and the US National Institutes of Health (number R01LM009731). The authors thank Michael Krein and Tao-wei Huang for support with computational issues and data set generation, Dawnmarie Robens for her expert administrative support and caring resourcefulness, and the group of people at the Rensselaer Exploratory Center for Cheminformatics Research (RECCR).	Andrews S., 2003, P ADV NEUR INF PROC, V15; Astorino A, 2007, IEEE T PATTERN ANAL, V29, P2135, DOI [10.1109/TPAMI.2007.1102, 10.1109/TPAMI.2007.1102.]; Auer P, 2004, LECT NOTES COMPUT SC, V3201, P63; Bergeron C., 2008, P 25 INT C MACH LEAR, P48; Blockeel H., 2005, P 22 INT C MACH LEAR, V22, P144; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Brown CM, 2008, DRUG METAB REV, V40, P1, DOI [10.1080/03602530701836662, 10.1080/03602530802309742 ]; Chen YX, 2004, J MACH LEARN RES, V5, P913; Clarke F.H, 1990, CANADIAN MATH SOC SE, V2; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; DOOLY DR, 2002, J MACHINE LEARNING R, V3, P651; Dundar MM, 2008, IEEE T BIO-MED ENG, V55, P1015, DOI 10.1109/TBME.2007.909544; Fuduli A, 2004, SIAM J OPTIMIZ, V14, P743, DOI 10.1137/S1052623402411459; Grtner T., 2002, P 19 INT C MACH LEAR, P179; Guengerich FP, 2008, CHEM RES TOXICOL, V21, P70, DOI 10.1021/tx700079z; Higham N. J., 2002, ACCURACY STABILITY N; Hu Y., 2008, P IEEE C COMP VIS PA; Joachims T, 2006, PROC 22 ACM SIGKDD I, P217, DOI DOI 10.1145/1150402.1150429; Lee Y. J., 2001, P SIAM INT C DAT MIN; Lemarechal C., 1974, P IFIP C 74, P552; Makela MM, 2002, OPTIM METHOD SOFTW, V17, P1, DOI 10.1080/10556780290027828; Mangasarian OL, 2008, J OPTIMIZ THEORY APP, V137, P555, DOI 10.1007/s10957-007-9343-5; Maron O., 1998, P 15 INT C MACH LEAR, V15; Murray Joseph F., 2005, J MACH LEARN RES, V6, P783, DOI 10.5555/1046920.1088699; Ramon J., 2000, P 17 INT MACH LEARN, V17; Rendic S., 1997, DRUG METAB REV, V34, P83; Ruszczynski A. P., 2006, NONLINEAR OPTIMIZATI; Sheridan RP, 2007, J MED CHEM, V50, P3173, DOI 10.1021/jm0613471; Singh SB, 2003, J MED CHEM, V46, P1330, DOI 10.1021/jm020400s; Soumya R., 2001, ICML, P425; Tao QP, 2008, IEEE T PATTERN ANAL, V30, P2084, DOI 10.1109/TPAMI.2007.70846; Teo CH, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P727; Wang J., 2000, PROC 17 INT C MACHIN, P1119; Weidmann N, 2003, LECT NOTES ARTIF INT, V2837, P468; Wolfe P, 1975, MATHEMATICAL PROGRAM, V3, P145, DOI [DOI 10.1007/BFB0120703, 10.1007/BFb0120703]; Wu O., 2010, P SIAM INT C DAT MIN, P430; Zhang Q, 2002, ADV NEUR IN, V14, P1073	37	51	53	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1068	1079		10.1109/TPAMI.2011.194	http://dx.doi.org/10.1109/TPAMI.2011.194			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	21987558				2022-12-18	WOS:000302916600003
J	He, XF; Ji, M; Zhang, CY; Bao, HJ				He, Xiaofei; Ji, Ming; Zhang, Chiyuan; Bao, Hujun			A Variance Minimization Criterion to Feature Selection Using Laplacian Regularization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature selection; dimensionality reduction; manifold; regularization; regression; clustering		In many information processing tasks, one is often confronted with very high-dimensional data. Feature selection techniques are designed to find the meaningful feature subset of the original features which can facilitate clustering, classification, and retrieval. In this paper, we consider the feature selection problem in unsupervised learning scenarios, which is particularly difficult due to the absence of class labels that would guide the search for relevant information. Based on Laplacian regularized least squares, which finds a smooth function on the data manifold and minimizes the empirical loss, we propose two novel feature selection algorithms which aim to minimize the expected prediction error of the regularized regression model. Specifically, we select those features such that the size of the parameter covariance matrix of the regularized regression model is minimized. Motivated from experimental design, we use trace and determinant operators to measure the size of the covariance matrix. Efficient computational schemes are also introduced to solve the corresponding optimization problems. Extensive experimental results over various real-life data sets have demonstrated the superiority of the proposed algorithms.	[He, Xiaofei; Zhang, Chiyuan; Bao, Hujun] Zhejiang Univ, Coll Comp Sci, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China; [Ji, Ming] Univ Illinois, Dept Comp Sci, Siebel Ctr, Urbana, IL 61801 USA	Zhejiang University; University of Illinois System; University of Illinois Urbana-Champaign	He, XF (corresponding author), Zhejiang Univ, Coll Comp Sci, State Key Lab CAD&CG, 388 Yu Hang Tang Rd, Hangzhou 310058, Zhejiang, Peoples R China.	xiaofeihe@cad.zju.edu.cn; mingji1@illinois.edu; zhangchiyuan@zjucadcg.cn; bao@cad.zju.edu.cn	zhang, chi/GRX-3610-2022		National Natural Science Foundation of China [60633070, 60875044]; National Key Basic Research Foundation of China [2009CB320801]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Basic Research Foundation of China(National Basic Research Program of China)	This work was supported by the National Natural Science Foundation of China under Grants 60633070 and 60875044, and the National Key Basic Research Foundation of China under Grant 2009CB320801.	Atkinson A., 2007, OPTIMUM EXPT DESIGNS, V34; Basu S., 2000, P IEEE INT S CIRC SY; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2006, J MACH LEARN RES, V7, P2399; BIE TD, 2007, P 15 EUR S ART NEUR; Boutemedjet S, 2009, IEEE T PATTERN ANAL, V31, P1429, DOI 10.1109/TPAMI.2008.155; Boyd S, 2004, CONVEX OPTIMIZATION; Chung F., 1997, REGIONAL C SERIES MA, V92; DASH M, 2000, P AS C KNOWL DISC DA; Duda R.O., 2000, PATTERN CLASSIFICATI; DY JG, 2000, P 17 INT C MACH LEAR; Flaherty P, 2005, ADV NEURAL INFORM PR, V18; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Harville D.A., 1997, MATRIX ALGEBRA STATI; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; He X., 2005, ADV NEURAL INFORM PR, V18; HE X, 2009, P IEEE INT C COMP VI; Hua Y, 2003, PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PDCAT'2003, PROCEEDINGS, P268, DOI 10.1109/PDCAT.2003.1236303; Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536; Li XL, 2010, IEEE T KNOWL DATA EN, V22, P145, DOI 10.1109/TKDE.2009.64; LIU W, 2008, P IEEE INT C DAT MIN; Lovasz L., 1986, MATCHING THEORY; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; TAO D, 2007, P IEEE INT C DAT MIN; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Toh KC, 1999, OPTIM METHOD SOFTW, V11-2, P545, DOI 10.1080/10556789908805762; Vandenberghe L, 1998, SIAM J MATRIX ANAL A, V19, P499, DOI 10.1137/S0895479896303430; Ververidis D, 2009, IEEE T PATTERN ANAL, V31, P2275, DOI 10.1109/TPAMI.2009.84; Wolf L, 2005, J MACH LEARN RES, V6, P1855; Zhao JD, 2008, NEUROCOMPUTING, V71, P1842, DOI 10.1016/j.neucom.2007.06.014; Zhao Z., 2007, ICML	35	51	57	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2013	2025		10.1109/TPAMI.2011.44	http://dx.doi.org/10.1109/TPAMI.2011.44			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21383399	Green Submitted			2022-12-18	WOS:000293969000009
J	Wu, Z; Ke, QF; Sun, J; Shum, HY				Wu, Zhong; Ke, Qifa; Sun, Jian; Shum, Heung-Yeung			Scalable Face Image Retrieval with Identity-Based Quantization and Multireference Reranking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; content-based image retrieval; inverted indexing; image search		State-of-the-art image retrieval systems achieve scalability by using a bag-of-words representation and textual retrieval methods, but their performance degrades quickly in the face image domain, mainly because they produce visual words with low discriminative power for face images and ignore the special properties of faces. The leading features for face recognition can achieve good retrieval performance, but these features are not suitable for inverted indexing as they are high-dimensional and global and thus not scalable in either computational or storage cost. In this paper, we aim to build a scalable face image retrieval system. For this purpose, we develop a new scalable face representation using both local and global features. In the indexing stage, we exploit special properties of faces to design new component-based local features, which are subsequently quantized into visual words using a novel identity-based quantization scheme. We also use a very small Hamming signature (40 bytes) to encode the discriminative global feature for each face. In the retrieval stage, candidate images are first retrieved from the inverted index of visual words. We then use a new multireference distance to rerank the candidate images using the Hamming signature. On a one millon face database, we show that our local features and global Hamming signatures are complementary-the inverted index based on local features provides candidate images with good recall, while the multireference reranking with global Hamming signature leads to good precision. As a result, our system is not only scalable but also outperforms the linear scan retrieval system using the state-of-the-art face recognition feature in term of the quality.	[Wu, Zhong] Microsoft Bing, City Ctr 8341, Redmond, WA 98052 USA; [Ke, Qifa] Microsoft Res, Mountain View, CA 94043 USA; [Sun, Jian] Microsoft Res Asia, Beijing 100080, Peoples R China; [Shum, Heung-Yeung] Microsoft Corp, City Ctr 24888, Redmond, WA 98052 USA	Microsoft; Microsoft; Microsoft Research Asia; Microsoft	Wu, Z (corresponding author), Microsoft Bing, City Ctr 8341, 1 Microsoft Way, Redmond, WA 98052 USA.	zhowu@microsoft.com; qke@microsoft.com; jiansun@microsoft.com; hshum@microsoft.com						Cao Z., 2010, P IEEE C COMP VIS PA; Carbonell JG, 1997, INT JOINT CONF ARTIF, P708; CHEN J, 2010, P ACM INT C IM VID R; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; HUA G, 2009, P IEEE 12 INT C COMP; HUANG GB, 2008, P EUR C COMP VIS; JEGOU H, 2009, P IEEE 12 INT C COMP; Jegou H, 2008, P 10 EUR C COMP VIS; KULIS B, 2009, P IEEE 12 INT C COMP; KUMAR N, 2009, P IEEE 12 INT C COMP; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; LEE PH, 2009, P IEEE INT C COMP VI; Lei Z, 2007, LECT NOTES COMPUT SC, V4642, P49; LIANG L, 2008, P 10 EUR C COMP VIS; LOWE, 2003, INT J COMPUT VISION, V20, P91; Manning C.D., 2008, INTRO INFORM RETRIEV, P177; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; NISTER D, 2006, P IEEE CS C COMP VIS; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Philbin J., 2008, P IEEE C COMP VIS PA; Philbin J, 2007, CVPR; Pinto N., 2009, P IEEE C COMP VIS PA; RUDINAC S, 2009, P WORKSH IM AN MULT; SALTON G, 1989, P INT S MOB AG; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Sivic J., 2003, P IEEE 9 INT C COMP; Taigman Y., 2009, P BRIT MACH VIS C; Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168; VIOLA P, 2001, P IEEE CS COMP VIS P; Winder S. A. J., 2007, P IEEE C COMP VIS PA; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; WOLF L, 2008, P FAC REAL LIF WORKS; Wright J., 2009, P IEEE C COMP VIS PA; YAN R., 2003, P 11 ACM INT C MULT, P343; YAN R, 2003, P INT C IM VID RETR; Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11	38	51	59	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					1991	2001		10.1109/TPAMI.2011.111	http://dx.doi.org/10.1109/TPAMI.2011.111			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21646678				2022-12-18	WOS:000293969000007
J	Xing, C; Qiu, PH				Xing, Chen; Qiu, Peihua			Intensity-Based Image Registration by Nonparametric Local Smoothing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Degeneration; discontinuity; edge detection; local smoothing; mapping; nonparametric transformation; weighted least squares estimation	NONRIGID REGISTRATION; DENSITY-ESTIMATION; JUMP DETECTION; MAXIMIZATION; RECOGNITION; ROBUST	Image registration is used widely in applications for mapping one image to another. Existing image registration methods are either feature-based or intensity-based. Feature-based methods first extract relevant image features and then find the geometrical transformation that best matches the two corresponding sets of features extracted from the two images. Because identification and extraction of image features is often a challenging and time-consuming process, intensity-based image registration, by which the mapping transformation is estimated directly from the observed image intensities of the two images, has received much attention recently. In the literature, most existing intensity-based image registration methods estimate the mapping transformation globally by solving a minimization/maximization problem defined by the two entire images to register. To this end, it needs to be assumed that the mapping transformation has a certain type of parametric form or it is a continuous bivariate function satisfying certain regularity conditions. In this paper, we propose a novel intensity-based image registration method using nonparametric local smoothing. By this method, the mapping transformation at a given pixel is estimated locally in a neighborhood after certain image features are accommodated in the estimation. Due to the flexibility of local smoothing, this method does not require any parametric form for the mapping transformation. It even allows the transformation to be a discontinuous function. Numerical examples show that it is effective in various applications.	[Xing, Chen; Qiu, Peihua] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Xing, C (corresponding author), Univ Minnesota, Sch Stat, 313 Ford Hall,224 Church St SE, Minneapolis, MN 55455 USA.	xing@stat.umn.edu; qiu@stat.umn.edu			US National Science Foundation (NSF)	US National Science Foundation (NSF)(National Science Foundation (NSF))	This research was supported in part by a US National Science Foundation (NSF) grant. The authors thank Dr. Nick Tustison for helpful conversations regarding the implementation of the software package ANTS. The editor and four referees provided many constructive comments and suggestions, which greatly improved the quality of the paper.	Althof RJ, 1997, IEEE T MED IMAGING, V16, P308, DOI 10.1109/42.585765; Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Beg F., 2005, INT J COMPUT VISION, V6, P139; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Davis MH, 1997, IEEE T MED IMAGING, V16, P317, DOI 10.1109/42.585766; Denton ERE, 1999, J COMPUT ASSIST TOMO, V23, P800, DOI 10.1097/00004728-199909000-00031; Dufaux F, 2000, IEEE T IMAGE PROCESS, V9, P497, DOI 10.1109/83.826785; Fan J.Q., 1996, LOCAL POLYNOMIAL MOD; Freire L, 2002, IEEE T MED IMAGING, V21, P470, DOI 10.1109/TMI.2002.1009383; GOSHTASBY A, 1985, IEEE T SYST MAN CYB, V15, P631, DOI 10.1109/TSMC.1985.6313439; Hall P, 2007, STAT SINICA, V17, P1483; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Keller Y, 2005, IEEE T IMAGE PROCESS, V14, P12, DOI 10.1109/TIP.2004.838692; Klein A, 2009, NEUROIMAGE, V46, P786, DOI 10.1016/j.neuroimage.2008.12.037; LAVINE D, 1983, PATTERN RECOGN, V16, P289, DOI 10.1016/0031-3203(83)90034-1; LI H, 1995, IEEE T IMAGE PROCESS, V4, P320, DOI 10.1109/83.366480; Liu LF, 2006, IEEE T IMAGE PROCESS, V15, P1100, DOI 10.1109/TIP.2005.864161; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; Modersitzki J, 2009, FUND ALGORITHMS, P1, DOI 10.1137/1.9780898718843; Nikou C, 1998, NEUROIMAGE, V8, P30, DOI 10.1006/nimg.1998.0335; Pan W, 2009, IEEE T PATTERN ANAL, V31, P400, DOI 10.1109/TPAMI.2008.83; Papademetris X, 2004, LECT NOTES COMPUT SC, V3216, P763; Peter AM, 2008, IEEE T IMAGE PROCESS, V17, P458, DOI 10.1109/TIP.2008.918038; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Qiu P, 2005, WILEY SER PROBAB ST, P1, DOI 10.1002/0471733156; QIU P, 1996, PATTERN RECOGN, V17, P849; Qiu P, 2008, COMPUT STAT DATA AN, V52, P4828, DOI 10.1016/j.csda.2008.03.027; Qiu PH, 2008, INT CONF BIOMED, P753, DOI 10.1109/BMEI.2008.33; Qiu PH, 1997, J COMPUT GRAPH STAT, V6, P332, DOI 10.2307/1390737; Rajwade A, 2009, IEEE T PATTERN ANAL, V31, P475, DOI 10.1109/TPAMI.2008.97; Ritter N, 1999, IEEE T MED IMAGING, V18, P404, DOI 10.1109/42.774168; Saeed N, 1998, NMR BIOMED, V11, P157, DOI 10.1002/(SICI)1099-1492(199806/08)11:4/5<157::AID-NBM528>3.0.CO;2-L; Sun JG, 2007, J COMPUT GRAPH STAT, V16, P289, DOI 10.1198/106186007x204753; Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012; Tustison NJ, 2009, IEEE T IMAGE PROCESS, V18, P624, DOI 10.1109/TIP.2008.2010072; Wang YM, 2000, MED IMAGE ANAL, V4, P7, DOI 10.1016/S1361-8415(00)00004-9; Wu GR, 2006, IEEE T MED IMAGING, V25, P1145, DOI 10.1109/TMI.2006.879320; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	40	51	54	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2081	2092		10.1109/TPAMI.2011.26	http://dx.doi.org/10.1109/TPAMI.2011.26			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21321367				2022-12-18	WOS:000293969000014
J	Wang, RP; Shan, SG; Chen, XL; Chen, J; Gao, W				Wang, Ruiping; Shan, Shiguang; Chen, Xilin; Chen, Jie; Gao, Wen			Maximal Linear Embedding for Dimensionality Reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; manifold learning; maximal linear patch; landmarks-based global alignment	INTRINSIC DIMENSIONALITY; COMPONENT ANALYSIS; MANIFOLD; FACE; PROJECTION; EIGENMAPS; FRAMEWORK; ALIGNMENT	Over the past few decades, dimensionality reduction has been widely exploited in computer vision and pattern analysis. This paper proposes a simple but effective nonlinear dimensionality reduction algorithm, named Maximal Linear Embedding (MLE). MLE learns a parametric mapping to recover a single global low-dimensional coordinate space and yields an isometric embedding for the manifold. Inspired by geometric intuition, we introduce a reasonable definition of locally linear patch, Maximal Linear Patch (MLP), which seeks to maximize the local neighborhood in which linearity holds. The input data are first decomposed into a collection of local linear models, each depicting an MLP. These local models are then aligned into a global coordinate space, which is achieved by applying MDS to some randomly selected landmarks. The proposed alignment method, called Landmarks-based Global Alignment (LGA), can efficiently produce a closed-form solution with no risk of local optima. It just involves some small-scale eigenvalue problems, while most previous aligning techniques employ time-consuming iterative optimization. Compared with traditional methods such as ISOMAP and LLE, our MLE yields an explicit modeling of the intrinsic variation modes of the observation data. Extensive experiments on both synthetic and real data indicate the effectivity and efficiency of the proposed algorithm.	[Wang, Ruiping] Tsinghua Univ, Dept Automat, Broadband Network & Multimedia Lab, Beijing 100084, Peoples R China; [Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Chen, Jie] Univ Oulu, Dept Elect & Informat Engn, Machine Vis Grp, FI-90014 Oulu, Finland; [Gao, Wen] Peking Univ, Sch EECS, Key Lab Machine Percept MoE, Beijing 100871, Peoples R China	Tsinghua University; Chinese Academy of Sciences; Institute of Computing Technology, CAS; University of Oulu; Peking University	Wang, RP (corresponding author), Tsinghua Univ, Dept Automat, Broadband Network & Multimedia Lab, Room 725,Cent Main Bldg, Beijing 100084, Peoples R China.	rpwang@mail.tsinghua.edu.cn; sgshan@ict.ac.cn; xlchen@ict.ac.cn; jiechen@ee.oulu.fi; wgao@jdl.ac.cn		Shan, Shiguang/0000-0002-8348-392X	Natural Science Foundation of China [61025010, 60872077]; National Basic Research Program of China (973 Program) [2009CB320902]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China)	R. Wang was with the Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, P.R. China, where most of this work was done when he was a PhD candidate. The authors would like to thank Dr. Y. Ma and the anonymous reviewers for their detailed comments and constructive suggestions. They are also grateful to Dr. Yee Whye Teh for sharing the code of LLC. This work was partially supported by the Natural Science Foundation of China under contract, No. 61025010 and No. 60872077, and the National Basic Research Program of China (973 Program) under contract 2009CB320902.	Balasubramanian M, 2002, SCIENCE, V295; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Belkin M, 2002, ADV NEUR IN, V14, P585; Bengio Y, 2004, NEURAL COMPUT, V16, P2197, DOI 10.1162/0899766041732396; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Brand  M., 2003, ADV NEURAL INFORM PR, P961, DOI DOI 10.1109/34.682189; Chen HT, 2005, PROC CVPR IEEE, P846; Cox T.F., 2001, MULTIDIMENSIONAL SCA, V2nd; Cramer J.S., 2003, ORIGINS LOGISTIC REG; DeMers D., 1993, ADV NEURAL INFORM PR, P580; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Duda R.O., 2000, PATTERN CLASSIFICATI; Everitt B., 1984, INTRO LATENT VARIABL; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208; Ghahramani Zoubin, 1996, CRGTR961 U TOR; Ham J., 2004, P 21 INT C MACH LEAR, P47, DOI [10.1145/1015330.1015417, DOI 10.1145/1015330.1015417]; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; He XF, 2005, IEEE I CONF COMP VIS, P1208; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hundley DR, 2003, SIAM PROC S, P194; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493; Kaufman L., 1990, FINDING GROUPS DATA; Kohonen Teuvo, 2001, SELF ORGANIZING MAPS; Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56; Levina E., 2005, ADV NEURAL INFORM PR, V17, P777, DOI DOI 10.5555/2976040.2976138; LIN R, 2006, P 9 EUR C COMP VIS G, V2, P245; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Park J, 2004, PROC CVPR IEEE, P452; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25, DOI 10.1109/TPAMI.1979.4766873; Postma E., 2009, 2009005 TICCTR TILB; Roweis S, 2002, ADV NEUR IN, V14, P889; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; SHA F, 2005, P 22 INT C MACH LEAR, P785; Silva V.D., 2003, NIPS, P721; Teh W. Y., 2003, ADV NEURAL INFORMATI, V15, P841; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R., 1992, Statistics and Computing, V2, P183, DOI 10.1007/BF01889678; VENNA J, 2006, P 14 EUR S ART NEUR, P557; Verbeek J, 2006, IEEE T PATTERN ANAL, V28, P1236, DOI 10.1109/TPAMI.2006.166; VERBEEK JJ, 2002, P INT C ART NEUR NET, V12, P914; Wang J., 2005, P ADV NEUR INF PROC, P1473; Wang RP, 2008, PROC CVPR IEEE, P2940; Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850; Weinberger KQ, 2004, PROC CVPR IEEE, P988; Wen GH, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2398; Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008; Yang L, 2008, IEEE T PATTERN ANAL, V30, P438, DOI 10.1109/TPAMI.2007.70706; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154; Zhao DF, 2009, IEEE T PATTERN ANAL, V31, P86, DOI 10.1109/TPAMI.2008.34	57	51	59	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1776	1792		10.1109/TPAMI.2011.39	http://dx.doi.org/10.1109/TPAMI.2011.39			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21358001				2022-12-18	WOS:000292740000006
J	Padua, FLC; Carceroni, RL; Santos, GAMR; Kutulakos, KN				Padua, Flavio L. C.; Carceroni, Rodrigo L.; Santos, Geraldo A. M. R.; Kutulakos, Kiriakos N.			Linear Sequence-to-Sequence Alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video synchronization; object tracking; epipolar geometry; spatiotemporal alignment; image and video registration		In this paper, we consider the problem of estimating the spatiotemporal alignment between N unsynchronized video sequences of the same dynamic 3D scene, captured from distinct viewpoints. Unlike most existing methods, which work for N 2 and rely on a computationally intensive search in the space of temporal alignments, we present a novel approach that reduces the problem for general N to the robust estimation of a single line in IRN. This line captures all temporal relations between the sequences and can be computed without any prior knowledge of these relations. Considering that the spatial alignment is captured by the parameters of fundamental matrices, an iterative algorithm is used to refine simultaneously the parameters representing the temporal and spatial relations between the sequences. Experimental results with real-world and synthetic sequences show that our method can accurately align the videos even when they have large misalignments (e.g., hundreds of frames), when the problem is seemingly ambiguous (e.g., scenes with roughly periodic motion), and when accurate manual alignment is difficult (e. g., due to slow-moving objects).	[Padua, Flavio L. C.] Ctr Fed Educ Tecnol Minas Gerais, Dept Comp Engn, BR-30510000 Belo Horizonte, MG, Brazil; [Carceroni, Rodrigo L.; Santos, Geraldo A. M. R.] Univ Fed Minas Gerais, Dept Comp Sci, BR-31270010 Belo Horizonte, MG, Brazil; [Kutulakos, Kiriakos N.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Universidade Federal de Minas Gerais; University of Toronto	Padua, FLC (corresponding author), Ctr Fed Educ Tecnol Minas Gerais, Dept Comp Engn, Av Amazonas 7675, BR-30510000 Belo Horizonte, MG, Brazil.	cardeal@lsi.cefetmg.br; carceron@dcc.ufmg.br; massahud@dcc.ufmg.br; kyros@cs.toronto.edu	Pádua, Flávio/N-7791-2013		CNPq-Brazil [300592/2001-9, 478859/2003-1, 521259/2001-0, 308195/2004-3]; Fapemig [EDT 162/07, CEX-227-04, CEX 491/02]; PRPq-UFMG (Fundo Fundep RD); Capes-Brazil. Kiriakos Kutulakos; US National Science Foundation [IRI-9875628]; Natural Sciences and Engineering Research Council of Canada; Alfred P. Sloan Foundation	CNPq-Brazil(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); Fapemig(Fundacao de Amparo a Pesquisa do Estado de Minas Gerais (FAPEMIG)); PRPq-UFMG (Fundo Fundep RD); Capes-Brazil. Kiriakos Kutulakos(Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)); US National Science Foundation(National Science Foundation (NSF)); Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR); Alfred P. Sloan Foundation(Alfred P. Sloan Foundation)	An earlier version of this work appeared in [36]. The authors would like to thank Thomas El-Maraghi, Guilherme Pereira, and Matthew Brown for making available their tracking and image stabilization software. Rodrigo Carceroni, Flavio Padua, and Geraldo Santos thank the support of CNPq-Brazil under Procs. No. 300592/2001-9, No. 478859/2003-1, No. 521259/2001-0, and No. 308195/2004-3; of Fapemig under Procs. No. EDT 162/07, No. CEX-227-04 and No. CEX 491/02; of PRPq-UFMG (Fundo Fundep RD), and of Capes-Brazil. Kiriakos Kutulakos gratefully acknowledges the support of the US National Science Foundation under Grant No. IRI-9875628, the Natural Sciences and Engineering Research Council of Canada under the RGPIN program, and the Alfred P. Sloan Foundation.	ANTHONY W, 2005, P WORKSH MOT VID COM, V2, P132; ATKINSON K. E, 1989, INTRO NUMERICAL ANAL; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; Carceroni RL, 2004, PROC CVPR IEEE, P746; Caspi Y, 2000, PROC CVPR IEEE, P682, DOI 10.1109/CVPR.2000.854940; CASPI Y, 2001, P 8 INT C COMP VIS V, V2, P76; Caspi Y, 2006, INT J COMPUT VISION, V68, P53, DOI 10.1007/s11263-005-4842-z; Dai CX, 2006, IEEE IMAGE PROC, P501, DOI 10.1109/ICIP.2006.312436; Dai CX, 2006, IEEE SIGNAL PROC LET, V13, P737, DOI 10.1109/LSP.2006.879852; *FIFA, 2002, FIFA WORLD CUP ARCH; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hefferon J., 2001, LINEAR ALGEBRA; Horst JA, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P744, DOI 10.1109/ICIP.1997.638603; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Laptev I, 2005, IEEE I CONF COMP VIS, P816; LEE K, 2005, P IM VIS COMP NZ C; Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678; Pooley DW, 2003, IEEE IMAGE PROC, P413; Press WH, 1988, NUMERICAL RECIPES C; RAGUSE K, 2006, P ISPRS COMM 5 S IM, P254; Rao C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P939; REID I, 1996, P 4 ECCV, P647; SHAKIL O, 2006, P IEEE INT C AC SPEE, V2, P257; STEIN G, 1998, P DARPA IM UND WORKS, P521; TOLA E, 2008, P IEEE C COMP VIS PA; TOMASI C, 2000, 205 CS STANF U; Ukrainitz Y, 2006, LECT NOTES COMPUT SC, V3953, P538, DOI 10.1007/11744078_42; Ushizaki M, 2006, INT C PATT RECOG, P71; VEDULA S, 2002, P 13 ACM EUR WORKSH, P65; WEDGE D, 2005, P DIG IM COMP TECHN, P79; WEDGE D, 2007, P IAPR C MACH VIS AP, P190; WOLF L, 2002, P WORKSH VIS MOD DYN; WOLF L, 2002, P 7 ECCV, V2, P370; Wolf L, 2006, INT J COMPUT VISION, V68, P43, DOI 10.1007/s11263-005-4841-0; YAN J, 2004, P ADV CONC INT VIS S; ZELNIKMANOR L, 2001, P IEEE COMP VIS PATT, V2	36	51	53	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					304	320		10.1109/TPAMI.2008.301	http://dx.doi.org/10.1109/TPAMI.2008.301			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075460				2022-12-18	WOS:000272741500009
J	Lyu, SW; Simoncelli, EP				Lyu, Siwei; Simoncelli, Eero P.			Modeling Multiscale Subbands of Photographic Images with Fields of Gaussian Scale Mixtures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image statistics; Markov random field; image denoising	MARKOV RANDOM-FIELDS; RESTORATION; COMPRESSION	The local statistical properties of photographic images, when represented in a multiscale basis, have been described using Gaussian scale mixtures. Here, we use this local description as a substrate for constructing a global field of Gaussian scale mixtures (FoGSM). Specifically, we model multiscale subbands as a product of an exponentiated homogeneous Gaussian Markov random field (hGMRF) and a second independent hGMRF. We show that parameter estimation for this model is feasible and that samples drawn from a FoGSM model have marginal and joint statistics similar to those of the subband coefficients of photographic images. We develop an algorithm for removing additive white Gaussian noise based on the FoGSM model and demonstrate denoising performance comparable with state-of-the-art methods.	[Lyu, Siwei] SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA; [Simoncelli, Eero P.] NYU, Howard Hughes Med Inst, Ctr Neural Sci, New York, NY 10003 USA; [Simoncelli, Eero P.] NYU, Courant Inst Math Sci, New York, NY 10003 USA	State University of New York (SUNY) System; State University of New York (SUNY) Albany; Howard Hughes Medical Institute; New York University; New York University	Lyu, SW (corresponding author), SUNY Albany, Dept Comp Sci, LI 67A,1400 Washington Ave, Albany, NY 12222 USA.	lsw@cs.albany.edu; eero.simoncelli@nyu.edu		Simoncelli, Eero/0000-0002-1206-527X; Lyu, Siwei/0000-0002-0992-685X	Howard Hughes Medical Institute Funding Source: Medline	Howard Hughes Medical Institute(Howard Hughes Medical Institute)		ANDREWS DF, 1974, J ROY STAT SOC B MET, V36, P99; Boyd S., 2005, CONVEX OPTIMIZATION; Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616; CHELLAPPA R, 1985, IEEE T SYST MAN CYB, V15, P298, DOI 10.1109/TSMC.1985.6313361; COIFMAN RR, 1995, WAVELETS STAT; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Figueiredo MAT, 1997, IEEE T IMAGE PROCESS, V6, P1089, DOI 10.1109/83.605407; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; GEHLER P, 2006, P ADV NEUR INF PROC, P419; GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gray RM, 2006, FOUND TRENDS COMMUN, V2, DOI 10.1561/0100000006; Guerrero-Colon JA, 2008, IEEE T IMAGE PROCESS, V17, P27, DOI 10.1109/TIP.2007.911473; Hammond DK, 2006, IEEE IMAGE PROC, P1433, DOI 10.1109/ICIP.2006.312699; HUANG J, 1999, P IEEE INT C COMP VI; Hyvarinen A, 2003, J OPT SOC AM A, V20, P1237, DOI 10.1364/JOSAA.20.001237; HYVARINEN A, 2000, P 1 IEEE INT WORKSH; JENG FC, 1991, IEEE T SIGNAL PROCES, V39, P683, DOI 10.1109/78.80887; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; LYU S, 2007, P ADV NEUR INF PROC, V19; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; PARRA L, 2000, P ADV NEUR INF PROC, V13; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Portilla J, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P37, DOI 10.1109/ICIP.2001.958418; PORTILLA J, 2003, P IEEE INT C IM PROC, V2, P965; PRESS WH, 2002, NUMERICAL RECIPES; RAPHAN M, 2007, P 14 IEEE INT C IM P; Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100; Roth S, 2005, PROC CVPR IEEE, P860; RUE H., 2005, GAUSSIAN MARKOV RAND; Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091; SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085; Simon H., 1996, BUS STRAT REV, V7, P1; Simoncelli E., 1990, SUBBAND IMAGE CODING, P143; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; Simoncelli EP, 1998, CONF REC ASILOMAR C, P673, DOI 10.1109/ACSSC.1997.680530; SRIVASTAVA A, 2002, IEEE T PATTERN ANAL, V28, P217; Tappen M. F., 2007, P IEEE C COMP VIS PA, P1; Teh YW, 2004, J MACH LEARN RES, V4, P1235; Wainwright MJ, 2001, APPL COMPUT HARMON A, V11, P89, DOI 10.1006/acha.2000.0350; Wainwright MJ, 2000, ADV NEUR IN, V12, P855; WANG Z, 2003, P ADV NEUR INF PROC, V16; WEGMANN B, 1990, P SOC PHOTO-OPT INS, V1360, P909, DOI 10.1117/12.24279; Welling M., 2002, ADV NEURAL INFORM PR, P1359; WINKLER P, 2003, IMAGE ANAL RANDOM FI; Yan KL, 2005, NEURAL COMPUT, V17, P397, DOI 10.1162/0899766053011474; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	50	51	52	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					693	706		10.1109/TPAMI.2008.107	http://dx.doi.org/10.1109/TPAMI.2008.107			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Engineering	407WX	19229084	Green Submitted, Green Accepted			2022-12-18	WOS:000263396100009
J	Wong, RCF; Leung, CHC				Wong, R. C. F.; Leung, C. H. C.			Automatic semantic annotation of real-world web images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						decision trees; feature extraction; image annotation; image retrieval; image semantics; metadata; rule induction; scene analysis	RETRIEVAL; SEGMENTATION; RECOGNITION	As the number of Web images is increasing at a rapid rate, searching them semantically presents a significant challenge. Many raw images are constantly uploaded with few meaningful direct annotations of semantic content, limiting their search and discovery. In this paper, we present a semantic annotation technique based on the use of image parametric dimensions and metadata. Using decision trees and rule induction, we develop a rule-based approach to formulate explicit annotations for images fully automatically, so that by the use of our method, a semantic query such as "sunset by the sea in autumn in New York" can be answered and indexed purely by machine. Our system is evaluated quantitatively using more than 100,000 Web images. Experimental results indicate that this approach is able to deliver a highly competent performance, attaining good recall and precision rates of sometimes over 80 percent. This approach enables a new degree of semantic richness to be automatically associated with images which previously could only be performed manually.	[Wong, R. C. F.; Leung, C. H. C.] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Hong Kong Baptist University	Wong, RCF (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	cfwong@comp.hkbu.edu.hk; clement@comp.hkbu.edu.hk						Amores J, 2007, IEEE T PATTERN ANAL, V29, P1818, DOI 10.1109/TPAMI.2007.1098; [Anonymous], 2002, EXCH IM FIL FORM DIG; Athitsos V, 2004, PROC CVPR IEEE, P268; Azzam IA, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P181, DOI 10.1109/ISIMP.2004.1434030; Azzam IA, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P354, DOI 10.1109/MULMM.2004.1265007; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Barnard K, 2005, TRENDS ADV CONTENT B; BIDNER J, 2004, AMPHOTOS COMPLETE BO; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; Chen K, 2003, QUANTUM INF COMPUT, V3, P193; CHO JS, 2005, P ACM S APPL COMP SA, P1190; Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1; Datta Ritendra, 2005, P MIR, P253; DUYGULU P, 2006, CATEGORY LEVEL OBJEC, P258; Feng H., 2004, MULTIMEDIA 04, P960, DOI [10.1145/1027527.1027748, DOI 10.1145/1027527.1027748]; Gausemeier J., 2003, P 2 INT C COMP GRAPH, P133; Jeong S, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P397; Jian MW, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 1, PROCEEDINGS, P764, DOI 10.1109/SNPD.2007.104; Johnson M, 2006, COMPUT GRAPH FORUM, V25, P407, DOI 10.1111/j.1467-8659.2006.00960.x; Kalousis A, 2004, PROC INT C TOOLS ART, P113; Kherfi ML, 2004, ACM COMPUT SURV, V36, P35, DOI 10.1145/1013208.1013210; Krishnapuram R, 2004, IEEE T KNOWL DATA EN, V16, P1185, DOI 10.1109/TKDE.2004.53; Lenman R., 2005, OXFORD COMPANION PHO; Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984; Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847; Lieberman H, 2004, AI MAG, V25, P63; Liu D, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P89, DOI 10.1109/ICME.2006.262557; MENDOZA R, 2005, P AUSTR ONT WORKSH A, P61; Over P, 2004, IEEE MULTIMEDIA, V11, P80, DOI 10.1109/MMUL.2004.1289045; Perina A, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P801, DOI 10.1109/ICIAP.2007.4362874; Rohlfing T, 2004, IEEE T MED IMAGING, V23, P983, DOI 10.1109/TMI.2004.830803; Ruggieri S, 2002, IEEE T KNOWL DATA EN, V14, P438, DOI 10.1109/69.991727; SAUX BL, 2004, P 6 ACM SIGMM INT WO, P91; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Smith RC, 2007, IEEE T VIS COMPUT GR, V13, P1552, DOI 10.1109/TVCG.2007.70581; Sun LJ, 2006, MITOCHONDRION, V6, P136, DOI 10.1016/j.mito.2006.04.003; Tam A.M., 2000, MPEG00M5738 ISOIEC J; Tam AM, 2001, J AM SOC INF SCI TEC, V52, P930, DOI 10.1002/asi.1151; Tsai CF, 2006, ACM T INFORM SYST, V24, P353, DOI 10.1145/1165774.1165777; VANBEEK P, 2001, MPEG01N3966 ISOIEC J; Vasconcelos N, 2007, COMPUTER, V40, P20, DOI 10.1109/MC.2007.239; VENKATESH R, 2006, P INT C MACH LEARN A, P193; Vogel J, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1278387.1278393; Wang J, 2004, LECT NOTES COMPUT SC, V3022, P238; Williams A, 2007, MULTIMED TOOLS APPL, V34, P239, DOI 10.1007/s11042-006-0087-2; Yan R, 2007, P 15 ACM INT C MULT, P991, DOI DOI 10.1145/1291233.1291448; Zoller T, 2007, IEEE T PATTERN ANAL, V29, P1147, DOI 10.1109/TPAMI.2007.1150	47	51	54	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					1933	1944		10.1109/TPAMI.2008.125	http://dx.doi.org/10.1109/TPAMI.2008.125			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787242				2022-12-18	WOS:000259110000007
J	Lin, WC; Liu, YX				Lin, Wen-Chieh; Liu, Yanxi			A lattice-based MRF model for dynamic near-regular texture tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						near-regular texture; visual tracking; dynamic near-regular texture tracking; model-based tracking; texture replacement; video editing	GRAPHICAL MODELS; VIDEO SYNTHESIS; MOTION	A near-regular texture ( NRT) is a geometric and photometric deformation from its regular origin-a congruent wallpaper pattern formed by 2D translations of a single tile. A dynamic NRT is an NRT under motion. Although NRTs are pervasive in man-made and natural environments, effective computational algorithms for NRTs are few. This paper addresses specific computational challenges in modeling and tracking dynamic NRTs, including ambiguous correspondences, occlusions, and drastic illumination and appearance variations. We propose a lattice-based Markov-Random-Field ( MRF) model for dynamic NRTs in a 3D spatiotemporal space. Our model consists of a global lattice structure that characterizes the topological constraint among multiple textons and an image observation model that handles local geometry and appearance variations. Based on the proposed MRF model, we develop a tracking algorithm that utilizes belief propagation and particle filtering to effectively handle the special challenges of the dynamic NRT tracking without any assumption on the motion types or lighting conditions. We provide quantitative evaluations of the proposed method against existing tracking algorithms and demonstrate its applications in video editing.	Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan; Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA; Penn State Univ, Dept Elect Engn, University Pk, PA 16802 USA	National Yang Ming Chiao Tung University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Lin, WC (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.	wclin@cs.nctu.edu.tw; yanxi@cse.psu.edu						Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bar-Joseph Z, 2001, IEEE T VIS COMPUT GR, V7, P120, DOI 10.1109/2945.928165; Bhat KS, 2004, ACM T GRAPHIC, V23, P360, DOI 10.1145/1015706.1015729; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Chetverikov D, 2005, ADV SOFT COMP, P17; Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Doretto G, 2005, PROC CVPR IEEE, P66; Doucet A., 2001, SEQUENTIAL MONTE CAR; Fedotov V., 1989, NMR BASIC PRINCIPLES, V21, P1; FORSYTH DA, 2002, P 7 EUR C COMP VIS 3, P225; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Gr?nbaum B., 1987, TILINGS PATTERNS; GUSKOV I, 2004, P EUR C COMP VIS, P133; GUSKOV I, 2002, P INT C PATT ROC; GUSKOV I, 2003, P 2003 ACM SIGGRAPH, P251; Isard M, 2003, PROC CVPR IEEE, P613; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; KANADE T, 1976, INTERFACE, V5, P21; Khan Z, 2004, LECT NOTES COMPUT SC, V2034, P279; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Li S. Z., 2001, COMP SCI W; LIN WC, 2005, CMURITR0558; Liu YH, 2004, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION SCIENCE AND TECHNOLOGY, VOL 2, P368; Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332; Lobay A, 2004, PROC CVPR IEEE, P400; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; Murphy K.P., 2002, DYNAMIC BAYESIAN NET; NELSON RC, 1992, CVGIP-IMAG UNDERSTAN, V56, P78, DOI 10.1016/1049-9660(92)90087-J; Papoulis A, 2002, PROBABILITY RANDOM V, V4th; PEARL J, 1998, PROBABILISTIC REASON; Pilet J, 2005, PROC CVPR IEEE, P822, DOI 10.1109/CVPR.2005.293; PRITCHARD D, 2003, P EUR; PROVOT X, 1995, GRAPH INTER, P147; Saisan P, 2001, PROC CVPR IEEE, P58; SCHOLZ V, 2004, P 9 INT FALL WORKSH; SCHOLZ V, 2005, P EUR, P439; Sclaroff S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1146, DOI 10.1109/ICCV.1998.710860; Sudderth E., 2004, ADV NEURAL INFORM PR, V17, P1369; Sudderth EB, 2003, PROC CVPR IEEE, P605; Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871; Tsin YH, 2001, PROC CVPR IEEE, P539; Vidal R, 2005, PROC CVPR IEEE, P516; Wang YZ, 2004, PROC CVPR IEEE, P856; Wang YZ, 2004, IEEE T PATTERN ANAL, V26, P1348, DOI 10.1109/TPAMI.2004.76; Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009; Weiss Y, 2001, NEURAL COMPUT, V13, P2173, DOI 10.1162/089976601750541769; Yedidia J., 2001, P INT JOINT C ART IN; Yu T, 2005, PROC CVPR IEEE, P939; Zhu SC, 2005, INT J COMPUT VISION, V62, P121, DOI 10.1007/s11263-005-4638-1	52	51	54	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					777	792		10.1109/TPAMI.2007.1053	http://dx.doi.org/10.1109/TPAMI.2007.1053			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356199	Green Submitted			2022-12-18	WOS:000244855700003
J	Nguyen, HT; Ji, Q; Smeulders, AWM				Nguyen, Hieu T.; Ji, Qiang; Smeulders, Arnold W. M.			Spatio-temporal context for robust multitarget tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multitarget tracking; context-based tracking; probabilistic PCA		In multitarget tracking, the main challenge is to maintain the correct identity of targets even under occlusions or when differences between the targets are small. The paper proposes a new approach to this problem by incorporating the context information. The context of a target in an image sequence has two components: the spatial context including the local background and nearby targets and the temporal context including all appearances of the targets that have been seen previously. The paper considers both aspects. We propose a new model for multitarget tracking based on the classification of each target against its spatial context. The tracker searches a region similar to the target while avoiding nearby targets. The temporal context is included by integrating the entire history of target appearance based on probabilistic principal component analysis (PPCA). We have developed a new incremental scheme that can learn the full set of PPCA parameters accurately online. The experiments show robust tracking performance under the condition of severe clutter, occlusions, and pose changes.	Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA; Univ Amsterdam, Fac Sci, ISLA, NL-1098 SJ Amsterdam, Netherlands	Rensselaer Polytechnic Institute; University of Amsterdam	Nguyen, HT (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, 110 8th St, Troy, NY 12180 USA.	nguyen@ecse.rpi.edu; jiq@rpi.edu; smeulders@science.uva.nl						Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Bar-Shalom Y., 1988, TRACKING DATA ASS; Brand M, 2002, LECT NOTES COMPUT SC, V2350, P707; BRUNSKILL E, 2005, P IEEE INT C ROB AUT; Collins RT, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P346; Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525; Ho J, 2004, PROC CVPR IEEE, P782; Isard M, 2003, PROC CVPR IEEE, P613; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; Khan Z, 2004, PROC CVPR IEEE, P980; Khan Z, 2004, LECT NOTES COMPUT SC, V2034, P279; Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432; LIM J, 2004, P NEUR INF PROC SYST; Lin R.S., 2004, P NEUR INF PROC SYST; MOGHADDAM B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P786, DOI 10.1109/ICCV.1995.466858; Nguyen HT, 2004, LECT NOTES COMPUT SC, V3022, P446; Nguyen HT, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P678, DOI 10.1109/ICCV.2001.937587; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; ROSS D, 2004, P 8 EUR C COMP VIS, V2, P470; Tao H, 2000, PROC CVPR IEEE, P134, DOI 10.1109/CVPR.2000.854760; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; TITTERINGTON DM, 1984, J ROY STAT SOC B MET, V46, P257; Williams O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P353; Yu T, 2004, PROC CVPR IEEE, P834; Zhao T, 2004, PROC CVPR IEEE, P406	27	51	56	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					52	64		10.1109/TPAMI.2007.250599	http://dx.doi.org/10.1109/TPAMI.2007.250599			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108383				2022-12-18	WOS:000241988300005
J	Hill, A; Taylor, CJ; Brett, AD				Hill, A; Taylor, CJ; Brett, AD			A framework for automatic landmark identification using a new method of nonrigid correspondence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						correspondence; critical points; polygonal approximation; automatic landmarks; flexible templates; point distribution models	SHAPE-DESCRIPTION; TRANSFORMATION; SURFACES; MODELS	A framework for automatic landmark indentification is presented based on an algorithm for corresponding the boundaries of two shapes. The auto-landmarking framework employs a binary tree of corresponded pairs of shapes to generate landmarks automatically on each of a set of example shapes. The landmarks are used to train statistical shape models known as Point Distribution Models. The correspondence algorithm locates a matching pair of sparse polygonal approximations, one for each of a pair of boundaries by minimizing a cost function, using a greedy algorithm. The cost function expresses the dissimilarity in both the shape and representation error (with respect to the defining boundary) of the sparse polygons. Results are presented for three classes of shape which exhibit various types of nonrigid deformation.	Kestra Ltd, Skipton BD23 3AE, N Yorkshire, England; Univ Manchester, Div Imaging Sci & Biomed Engn, Manchester M13 9PT, Lancs, England	University of Manchester	Hill, A (corresponding author), Kestra Ltd, Kestra House,Broughton Hall, Skipton BD23 3AE, N Yorkshire, England.	andrew@kestra.com; c.taylor@man.ac.uk; a.brett@man.ac.uk	Taylor, Chris/A-3909-2009	Taylor, Chris/0000-0001-7867-9533				Baumberg A, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P87; BAUMBERG A, 1994, P EUR C COMP VIS, P299; Bookstein F. L., 1991, MORPHOMETRIC TOOLS L; BRECHBUHLER C, 1995, COMPUT VIS IMAGE UND, V61, P154, DOI 10.1006/cviu.1995.1013; Christensen GE, 1997, IEEE T MED IMAGING, V16, P864, DOI 10.1109/42.650882; COHEN I, 1992, LECT NOTES COMPUT SC, V588, P458; COOTES TF, 1992, IMAGE VISION COMPUT, V10, P289, DOI 10.1016/0262-8856(92)90044-4; Duncan J. S., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P318, DOI 10.1109/CVPR.1991.139709; FLEUTE M, 1998, MICCAI, P878; GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x; HILL A, 1994, MED INFORM, V19, P47, DOI 10.3109/14639239409044720; HILL A, 1994, BMVC94 - PROCEEDINGS OF THE 5TH BRITISH MACHINE VISION CONFERENCE, VOLS 1 AND 2, P429; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; JOSHI SC, 1997, P 15 C INF PROC MED, P381; Kambhamettu C., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P222, DOI 10.1109/CVPR.1992.223271; KELEMEN A, 1997, 178 ETH IM SCI LAB; Kotcheff A C, 1998, Med Image Anal, V2, P303; LANITIS A, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P368, DOI 10.1109/ICCV.1995.466919; MARCHANT JA, 1995, IMAGE VISION COMPUT, V13, P3, DOI 10.1016/0262-8856(95)91463-N; Rangarajan A, 1996, LECT NOTES COMPUT SC, V1131, P277, DOI 10.1007/BFb0046965; Rangarajan A, 1997, LECT NOTES COMPUT SC, V1230, P29; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; SHAPIRO LS, 1991, P 2 BRIT MACH VIS C, P78; Szeliski R, 1996, INT J COMPUT VISION, V18, P171, DOI 10.1007/BF00055001; TAGARE HD, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P434, DOI 10.1109/ICCV.1995.466907; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; ZHU PF, 1995, IEEE T PATTERN ANAL, V17, P737, DOI 10.1109/34.400564	29	51	59	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2000	22	3					241	251		10.1109/34.841756	http://dx.doi.org/10.1109/34.841756			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	306EJ					2022-12-18	WOS:000086584100003
J	Bennett, N; Burridge, R; Saito, N				Bennett, N; Burridge, R; Saito, N			A method to detect and characterize ellipses using the Hough Transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hough Transform; ellipse detection; parameter estimation; projective geometry; feature extraction; computer vision		In this paper we describe a new technique for detecting and characterizing ellipsoidal shapes automatically from any type of image. This technique is a single pass algorithm which can extract any group of ellipse parameters or characteristics which can be computed from those parameters without having to detect all five parameters for each ellipsoidal shape. Moreover, the method can explicitly incorporate any a priori knowledge the user may have concerning ellipse parameters. The method is based on techniques from Projective Geometry and on the Hough Transform. This technique can significantly reduce interpretation and computation time by automatically extracting only those features or geometric parameters of interest from images and making exact use of a priori information.	Schlumberger Doll Res Ctr, Ridgefield, CT 06877 USA	Schlumberger	Bennett, N (corresponding author), Schlumberger Doll Res Ctr, Old Quarry Rd, Ridgefield, CT 06877 USA.		Saito, Naoki/A-6138-2012	Saito, Naoki/0000-0001-5234-4719				Cabrera J, 1996, IEEE T PATTERN ANAL, V18, P752, DOI 10.1109/34.506797; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; HALL J, 1996, T SPWLA 37 ANN LOGG; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; Kalviainen H, 1997, PATTERN RECOGN LETT, V18, P77, DOI 10.1016/S0167-8655(96)00132-8; KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6; LEAVERS VF, 1992, CVGIP-IMAG UNDERSTAN, V56, P381, DOI 10.1016/1049-9660(92)90049-9; LYVERS E, 1988, IEEE T PATTERN ANAL, V10, P23; MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MAXWELL EA, 1946, METHODS PLANE PROJEC; MUAMMAR HK, 1991, IEE PROC-E, V138, P27, DOI 10.1049/ip-e.1991.0004; SCOTT DW, 1985, ANN STAT, V13, P1024, DOI 10.1214/aos/1176349654; Shaked D, 1996, COMPUT VIS IMAGE UND, V63, P512, DOI 10.1006/cviu.1996.0038; Soffer M, 1998, COMPUT VIS IMAGE UND, V69, P119, DOI 10.1006/cviu.1997.0557; TSUKUNE H, 1983, IEEE COMPUTER VISION; YUEN H, 1988, AVC88 P 4 ALV VIS C; Ziou D, 1998, PATTERN RECOGN, V31, P587, DOI 10.1016/S0031-3203(97)00090-3	19	51	56	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1999	21	7					652	657		10.1109/34.777377	http://dx.doi.org/10.1109/34.777377			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	216YT		Green Submitted			2022-12-18	WOS:000081472600009
J	Moga, AN; Gabbouj, M				Moga, AN; Gabbouj, M			Parallel image component labeling with watershed transformation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						watersheds; connected components; image segmentation; parallel computing; efficient algorithms	MESH-CONNECTED COMPUTERS; ALGORITHMS	The parallel watershed transformation used in gray scale image segmentation is reconsidered in this paper on the basis of the component labeling problem. The main idea is to break the sequentiality of the watershed transformation and to correctly delimit the extent of all connected components locally, on each processor, simultaneously. The internal fragmentation of the catchment basins, due to domain decomposition, into smaller subcomponents is ulteriorly solved by employing a global connected components operator. Therefore, in a pyramidal structure of master-slave processors, internal contours of adjacent subcomponents within the same component are hierarchically removed. Global final connected areas are efficiently obtained in log(2) N steps on a logical grid of N processors. Timings and segmentation results of the algorithm built on top of the Message Passing Interface (MPI) and tested on the Gray T3D are brought forward to justify the superiority of the novel design solution compared against previous implementations.			Moga, AN (corresponding author), TAMPERE UNIV TECHNOL, SIGNAL PROC LAB, POB 553, FIN-33101 TAMPERE, FINLAND.		Gabbouj, Moncef/G-4293-2014	Gabbouj, Moncef/0000-0002-9788-2323				ALNUWEIRI HM, 1992, IEEE T PATTERN ANAL, V14, P1014, DOI 10.1109/34.159904; ALNUWEIRI HM, 1991, IEEE T PATTERN ANAL, V13, P202, DOI 10.1109/34.67649; Bader DA, 1996, J PARALLEL DISTR COM, V35, P173, DOI 10.1006/jpdc.1996.0079; Bader DA, 1996, J SUPERCOMPUT, V10, P141, DOI 10.1007/BF00130707; Beucher S., 1993, MATH MORPHOLOGY IMAG, P433, DOI DOI 10.1201/9781482277234-12; CHOUDHARY A, 1994, J PARALLEL DISTR COM, V20, P78, DOI 10.1006/jpdc.1994.1007; COPTY N, 1994, J PARALLEL DISTR COM, V21, P160, DOI 10.1006/jpdc.1994.1049; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; CYPHER R, 1989, IEEE T PATTERN ANAL, V11, P258, DOI 10.1109/34.21794; CYPHER RE, 1990, IEEE T COMPUT, V39, P276, DOI 10.1109/12.45215; DOBRIN BP, 1994, P SOC PHOTO-OPT INS, V2180, P209, DOI 10.1117/12.172559; EMBRECHTS H, 1993, CVGIP-IMAG UNDERSTAN, V57, P155, DOI 10.1006/ciun.1993.1010; HAMBRUSCH S, 1994, J PARALLEL DISTR COM, V20, P56, DOI 10.1006/jpdc.1994.1005; Kumar V., 1994, INTRO PARALLEL COMPU, P110; *MESS PASS INT FOR, 1995, MPI MESS PASS INT ST; Message Passing Interface Forum MPI, 1994, MPI MESS PASS INT ST; MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4; Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M; MEYER F, 1991, P 8 C AFCET LYON VIL, P847; MOGA A, 1995, TRANSPUT OCCAM ENG S, P316; Moga A., 1995, P IEEE INT C IM PROC, V2, P101; Moga A., 1995, P IEEE WORKSH NONL S, VII, P991; MOGA AN, 1995, P 12 EUR C CIRC THEO, V1, P339; SAMET H, 1988, IEEE T PATTERN ANAL, V10, P579, DOI 10.1109/34.3918; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; WILLEBEEKLEMAIR M, 1990, J PARALLEL DISTR COM, V8, P135, DOI 10.1016/0743-7315(90)90088-7; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	35	51	53	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					441	450		10.1109/34.589204	http://dx.doi.org/10.1109/34.589204			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300003
J	Szeliski, R; Kang, SB				Szeliski, R; Kang, SB			Shape ambiguities in structure from motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure from motion; ambiguities; bas-relief ambiguity; uncertainty analysis; eigenvalue analysis	RECOVERING 3-D MOTION; NOISY FLOW FIELD; INHERENT AMBIGUITIES	This paper examines the fundamental ambiguities and uncertainties inherent in recovering structure from motion. By examining the eigenvectors associated with null or small eigenvalues of the Hessian matrix, we can quantify the exact nature of these ambiguities and predict how they affect the accuracy of the reconstructed shape. Our results for orthographic cameras show that the bas-relief ambiguity is significant even with many images, unless a large amount of rotation is present. Similar results for perspective cameras suggest that three or more frames and a large amount of rotation are required for metrically accurate reconstruction.	DIGITAL EQUIPMENT CORP, CAMBRIDGE RES LAB, CAMBRIDGE, MA 02139 USA		Szeliski, R (corresponding author), MICROSOFT CORP, RES, 1 MICROSOFT WAY, REDMOND, WA 98052 USA.							ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; Bathe K. J., 1976, NUMERICAL METHODS FI; DANIILIDIS K, 1990, IMAGE VISION COMPUT, V8, P297, DOI 10.1016/0262-8856(90)80006-F; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MATTHIES L, 1987, IEEE T ROBOTIC AUTOM, V3, P239, DOI 10.1109/JRA.1987.1087097; MAYBANK S, 1993, THEORY RECONSTRUCTIO; OLIENSIS J, 1991, IEEE WORKSH VIS MOT, P8; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; SORENSON HW, 1980, PARAMAETER ESTIMATIO; SPETSAKIS ME, 1989, IEEE WORKSH VIS MOT, P229; Szeliski R., 1994, Journal of Visual Communication and Image Representation, V5, P10, DOI 10.1006/jvci.1994.1002; SZELISKI R, 1996, 961 DIG EQ CORP CAMB; TAYLOR CJ, 1992, IEEE INT C ROB AUT N, P1615; Thomas J. I., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P325, DOI 10.1109/ICCV.1993.378197; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; WOLFRAM S, 1991, MATHEMATICA SYSTEM M; YOUNG GSJ, 1992, IEEE T PATTERN ANAL, V14, P995, DOI 10.1109/34.159903	19	51	51	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					506	512		10.1109/34.589211	http://dx.doi.org/10.1109/34.589211			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300010
J	HSIEH, YC; MCKEOWN, DM; PERLANT, FP				HSIEH, YC; MCKEOWN, DM; PERLANT, FP			PERFORMANCE EVALUATION OF SCENE REGISTRATION AND STEREO MATCHING FOR CARTOGRAPHIC FEATURE-EXTRACTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ANALYSIS OF AERIAL IMAGERY; CARTOGRAPHY; COMPUTER VISION; DIGITAL MAPPING; IMAGE UNDERSTANDING; PERFORMANCE EVALUATION; SCENE REGISTRATION; STEREO MATCHING	AERIAL IMAGE-ANALYSIS; SPOT; SYSTEM	One goal of automated cartography is to generate an accurate 3-D model of man-made structures and natural terrain. Some of the most challenging problems in cartographic feature extraction occur in dense urban areas where the level of detail and scene clutter greatly complicate traditional map compilation techniques. In this paper, we describe experiments toward a comprehensive stereo analysis system to recover the 3-D description of an urban area using high-resolution aerial imagery. Given an area of interest in terms of geographic coverage, our system can automatically find the appropriate stereo pair using a spatial database, select control points to register the two images so that epipolar geometry is satisfied, and recover disparity information using two complementary matching techniques. In our research, we do not assume that the initial input images satisfy the epipolar geometry constraint because this is rarely the case in unrectified aerial imagery. Therefore, we argue that stereo mapping research must explicitly address error and uncertainty in both scene registration and stereo matching and that we need techniques to evaluate such errors in a rigorous manner. We also argue that in order to achieve robust behavior, multiple methods for scene feature extraction should be utilized, and if possible, their results should be integrated into a consistent framework. We describe techniques for scene registration using five different features that can be automatically extracted to provide control points for fine image registration. In the stereo matching process, two techniques are utilized: an area-based and a feature-based stereo matcher to generate a disparity map for a scene. We also present some preliminary results on a technique to merge the results of the stereo matching algorithms to provide improved information regarding height estimates. Finally, we describe techniques to generate rigorous performance analysis metrics to compare stereo matching algorithms based on a manually derived 3-D ground truth segmentation. The analysis includes the error estimation metrics for both height and delineation accuracy based on the measurements of deviations from manual estimates. These estimates are computed globally over the entire scene and locally on a structure-by-structure basis. Relative accuracy of the area-based, feature-based, and merged disparity estimates are provided for several different test scenes.	CARNEGIE MELLON UNIV, SCH COMP SCI, DIGITAL MAPPING LAB, PITTSBURGH, PA 15213 USA	Carnegie Mellon University								ARNOLD RD, 1978, MAY P DARPA IM UND W, P771; AVIAD Z, 1990, GENERATION BUILDING; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BARNARD ST, 1990, SEP P DARPA IM UND W, P449; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; BARNARD ST, 1988, APR P DARPA IM UND W, P769; CHENG YC, 1985, IEEE T PATTERN ANAL, V7, P299, DOI 10.1109/TPAMI.1985.4767658; CHEVREL M, 1981, PHOTOGRAMM ENG REM S, V47, P1163; COCHRAN SD, 1989, NOV P WORKSH INT 3 D, P16; COCHRAN SD, 1989, MAY P DARPA IM UND W, P857; COLVOCORESSES AP, 1990, PHOTOGRAMM ENG REM S, V56, P569; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; FISCHLER MA, 1989, INT J COMPUT VISION, V3; GUGAN DJ, 1988, PHOTOGRAMM ENG REM S, V54, P1409; HANNAH MJ, 1989, PHOTOGRAMM ENG REM S, V55, P1765; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; HORN BKP, 1988, APR P DARPA IM UND W, P826; HSIEH YC, 1990, CMUCS90193 SCH COMP; IRVIN RB, 1989, IEEE T SYST MAN CYB, V19, P1564, DOI [10.1109/21.44071, 10.1117/12.952691]; KRATKY V, 1989, PHOTOGRAMM ENG REM S, V55, P311; LUCAS BD, 1984, THESIS CARN U PITTSB; McKeown D. M., 1990, NATO ASI SERIES F, V65, P149; McKeown D. M.  Jr., 1984, New Applications of Data Bases. Based on Proceedings of a Workshop, P19; MCKEOWN DM, 1986, OPT ENG, V25, P333, DOI 10.1117/12.7973830; MCKEOWN DM, 1987, IEEE T GEOSCI REMOTE, V25, P330, DOI 10.1109/TGRS.1987.289804; MCKEOWN DM, 1988, JUN P IEEE COMP VIS, P662; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; MENET S, 1990, SEP P DARPA IM UND W, P720; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P113, DOI 10.1109/34.16708; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; MORAVEC HP, 1980, THESIS STANF U STANF; NASRABADI NM, 1988, APR P IEEE INT C ROB; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; PERLANT FP, 1990, PHOTOGRAMM ENG REM S, V56, P481; THEODOSSIOU EI, 1990, PHOTOGRAMM ENG REM S, V56, P1643; WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162; 1980, MANUAL PHOTOGRAMMETR	37	51	54	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					214	238		10.1109/34.121790	http://dx.doi.org/10.1109/34.121790			25	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900009
J	WHAITE, P; FERRIE, FP				WHAITE, P; FERRIE, FP			FROM UNCERTAINTY TO VISUAL EXPLORATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AUTONOMOUS EXPLORATION; GAZE PLANNING; LASER RANGEFINDER; MINIMIZATION; MODEL FITTING; RANGE IMAGE ANALYSIS; ROBOT VISION; 3-DIMENSIONAL SCENES; UNCERTAINTY		The major question posed by this paper is "what can be inferred from ambiguity in processes of visual interpretation?" We discuss the question in a specific context: the interpretation of scene geometry in the form of parametrized volumetric models. Ambiguity is described as a local probabilistic property of the misfit error surface in the parameter space of superellipsoid models, namely, as an ellipsoid of confidence in which there is a given probability that the true parameters can be found. We show how to project the ellipsoid of confidence back into 3-D space to obtain the shell in which the true 3-D surface most probably lies and introduce what we call the uncertainty image to demonstrate the notion of uncertainty as a local property of the fitted model's surface. We propose a technique that can use this information to plan a new direction of view that minimizes the ambiguity of subsequent interpretation.			WHAITE, P (corresponding author), MCGILL UNIV,INTELLIGENT MACHINES RES CTR,DEPT ELECT ENGN,COMP & ROBOT LAB,MONTREAL H3A 2A7,QUEBEC,CANADA.							ALLEN PK, 1989, NOV P WORKSH INT 3D, P32; Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; FERRIE F, 1990, COMPUT VISION ECCV 9, P23; FERRIE FP, 1989, P IEEE WORKSHOP INTE, P170; Gross A. D., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P690, DOI 10.1109/CCV.1988.590052; Luenberger D.G, 2016, LINEAR NONLINEAR PRO, DOI 10.1007/978-3-319-18842-3; Marr D., 1982, VISION; MOOD AM, 1963, INTRO THEORY STATIST; PENTLAND A, 1987, 1ST INT C COMP VIS, P612; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; PRESS W, 1988, NUMERIC RECIPES C AR; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; SOLINA F, 1988, VISION, P733; 1989, NOV P WORKSH INT 3D	14	51	55	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1991	13	10					1038	1049		10.1109/34.99237	http://dx.doi.org/10.1109/34.99237			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GM763					2022-12-18	WOS:A1991GM76300006
J	ZHOU, XJ; DILLON, TS				ZHOU, XJ; DILLON, TS			A STATISTICAL-HEURISTIC FEATURE-SELECTION CRITERION FOR DECISION TREE INDUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DECISION TREES; FEATURE-SELECTION CRITERION; INDUCTIVE MACHINE LEARNING; KNOWLEDGE ACQUISITION; MULTIVALUED FEATURES; NOISY DATA; STATISTICAL-HEURISTIC METHOD	CATEGORICAL DATA; DESIGN; CLASSIFIER; INFORMATION; VARIANCE; RULE	Many machine learning systems have been developed for constructing decision trees from collections of examples. When they are applied to complicated real-world problems they often suffer from the difficulties of coping with multivalued features and noisy data. To cope with these difficulties, a key issue is a feature-selection criterion for direct handling of multivalued features in noisy environments. This paper proposes a statistical-heuristic criterion, the symmetrical tau-(tau), and then discusses its consistency with a Bayesian classifier and its built-in statistical test. The combination of a measure of proportional-reduction-in-error and cost-of-complexity heuristic enables the symmetrical-tau to be a powerful criterion with many merits, including robustness to noise; fairness to multivalued features; capability to handle a boolean combination of logical features and "middle-cut" preference. The tau-criterion also provides a natural basis for prepruning and dynamic error estimation. On the basis of the tau-criterion, an effective approach for constructing multibranching decision trees in noisy environments is developed. Illustrative examples are also presented.			ZHOU, XJ (corresponding author), LA TROBE UNIV,DEPT COMP SCI,BUNDOORA,VIC 3083,AUSTRALIA.							Duda R.O., 1973, J ROYAL STAT SOC SER; FISHER RA, 1958, STATISTICAL METHODS; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404, DOI 10.1109/TC.1977.1674849; GOODMAN LA, 1954, J AM STAT ASSOC, V49, P732, DOI 10.2307/2281536; HART AE, 1985, R D EXPERT SYSTEMS; HARTMANN CRP, 1982, IEEE T INFORM THEORY, V28, P565, DOI 10.1109/TIT.1982.1056522; HENRICHON EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; Hyafil L., 1976, Information Processing Letters, V5, P15, DOI 10.1016/0020-0190(76)90095-8; KANAL LN, 1979, IEEE T PATTERN ANAL, V1, P194; KONONENKO I, 1984, EXPT AUTOMATIC LEARN; LIGHT RJ, 1971, J AM STAT ASSOC, V66, P534, DOI 10.2307/2283520; MARGOLIN BH, 1974, J AM STAT ASSOC, V69, P755, DOI 10.2307/2286014; MINGERS J, 1987, J OPER RES SOC, V38, P39, DOI 10.1057/jors.1987.5; MIYAKAWA M, 1989, IEEE T COMPUT, V38; MORET BME, 1982, COMPUT SURV, V14, P593, DOI 10.1145/356893.356898; Morgan JN, 1973, THAID SEQUENTIAL SEA; MUI JK, 1980, IEEE T PATTERN ANAL, V2, P429, DOI 10.1109/TPAMI.1980.6592364; Olshen R., 1984, CLASSIFICATION REGRE; PAYNE HJ, 1977, IEEE T COMPUT, V26, P905, DOI 10.1109/TC.1977.1674938; Quinlan J., 1986, MACHINE LEARNING, V1; Quinlan J.R., 1988, MACHINE INTELLIGENCE, V11; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; QUINLAN JR, 1986, MACHINE LEARNING, V2; ROUNDS EM, 1980, PATTERN RECOGN, V12, P313, DOI 10.1016/0031-3203(80)90029-1; SETHI IK, 1982, IEEE T PATTERN ANAL, V4, P441, DOI 10.1109/TPAMI.1982.4767278; SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142, DOI 10.1109/TGE.1977.6498972; WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406, DOI 10.1109/TPAMI.1984.4767546; ZHOU XJ, 1988, 1988 P IEEE INT C SY; ZHOU XJ, IN PRESS COMP STUDY; ZHOU XJ, 1989, 2ND P INT WORKSH ART	30	51	51	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					834	841		10.1109/34.85676	http://dx.doi.org/10.1109/34.85676			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642					2022-12-18	WOS:A1991GC64200011
J	ALEMAMI, S; USHER, M				ALEMAMI, S; USHER, M			ONLINE RECOGNITION OF HANDWRITTEN ARABIC CHARACTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											ALEMAMI, S (corresponding author), UNIV READING,DEPT CYBERNET,READING RG6 2AL,BERKS,ENGLAND.							AMIN A, 1979, CRIN79 U NAC I, P80; AMIN A, 1980, 5TH P INT C PATT REC, P729; BELAID A, 1984, IEE T PATTERN ANAL M, V6; Blair CR., 1960, INF CONTROL, V3, P60; Kim J., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P917; OGAWA H, 1982, PATTERN RECOGN, V15, P299, DOI 10.1016/0031-3203(82)90032-2; RISEMAN EM, 1971, IEEE T COMPUT, VC 20, P397, DOI 10.1109/T-C.1971.223255	7	51	55	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1990	12	7					704	710		10.1109/34.56214	http://dx.doi.org/10.1109/34.56214			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DK894					2022-12-18	WOS:A1990DK89400012
J	MALIK, J; MAYDAN, D				MALIK, J; MAYDAN, D			RECOVERING 3-DIMENSIONAL SHAPE FROM A SINGLE IMAGE OF CURVED OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MALIK, J (corresponding author), UNIV CALIF BERKELEY,DEPT ELECT ENGN & COMP SCI,DIV COMP SCI,BERKELEY,CA 94720, USA.							BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BRADY JM, 1983, P IJCAI 8, P969; BROOKS MJ, 1985, P INT JOINT C ART IN, P932; BRUSS AR, 1983, P INT JT C ART INT K, P1053; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; HORN BKP, 1970, MIT TR79 MAC REP; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; MALIK J, 1987, INT J COMPUT VISION, V1; MALIK J, 1985, STANCS861099 STANF U; Marr D., 1982, VISION; Perkins D., 1968, MIT89 RES LAB EL Q P, P207; POGGIO T, 1985, NATURE, V317; STEVENS KA, 1981, ARTIF INTELL, V17, P47, DOI 10.1016/0004-3702(81)90020-5; SUGIHARA K, 1984, ARTIF INTELL, V23, P59, DOI 10.1016/0004-3702(84)90005-5; SUGIHARA K, 1982, IEEE T PATTERN ANAL, V4, P458, DOI 10.1109/TPAMI.1982.4767289; Tikhonov A., 1977, SOLUTIONS ILL POSED; Witkin A., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence, P714	26	51	56	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1989	11	6					555	566		10.1109/34.24791	http://dx.doi.org/10.1109/34.24791			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U6749					2022-12-18	WOS:A1989U674900002
J	SHAHRARAY, B; ANDERSON, DJ				SHAHRARAY, B; ANDERSON, DJ			OPTIMAL ESTIMATION OF CONTOUR PROPERTIES BY CROSS-VALIDATED REGULARIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,ANN ARBOR,MI 48109	University of Michigan System; University of Michigan	SHAHRARAY, B (corresponding author), AT&T BELL LABS,DEPT MACHINE PERCEPT RES,CRANFORDS CORNER RD,HOLMDEL,NJ 07733, USA.							ADBY PR, 1974, INTRO OPTIMIZATION M; ANDERSSEN RS, 1974, TECHNOMETRICS, V16, P69; Bates D. M, 1982, TREATMENT INTEGRAL E; BATES DM, 1987, COMMUN STAT SIMULAT, V16, P263, DOI 10.1080/03610918708812590; BATES DM, 1985, 775 U WISC DEP STAT; BOULT TE, 1987, 1ST P INT C COMP VIS, P457; BROWN RL, 1975, J ROYAL STAT ASS, V70, P70; CRAVEN P, 1979, NUMER MATH, V31, P377, DOI 10.1007/BF01437407; Duchon Jean, 1976, CONSTRUCTIVE THEORY, V571, P4; Elden L., 1977, BIT (Nordisk Tidskrift for Informationsbehandling), V17, P134, DOI 10.1007/BF01932285; ELDEN L, 1984, BIT, V24, P467, DOI 10.1007/BF01934905; GEISSER S, 1975, J AM STAT ASSOC, V70, P320, DOI 10.2307/2285815; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; KENNEDY WJ, 1980, STATISTICAL COMPUTIN; KIMELDOR.GS, 1970, ANN MATH STAT, V41, P495, DOI 10.1214/aoms/1177697089; LEE D, 1987, 1ST P INT C COMP VIS, P573; LI KC, 1985, ANN STAT, V13, P1352, DOI 10.1214/aos/1176349742; MELKMAN AA, 1979, SIAM J NUMER ANAL, V16, P87, DOI 10.1137/0716007; NYCHKA D, 1984, J AM STAT ASSOC, V79, P832, DOI 10.2307/2288713; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POGGIO T, 1984, P AARPA IM UND WORKS, P257; POGGIO T, 1985, MIT ARTIFICIAL INTEL, V883; RAGOZIN DL, 1983, J APPROXIMATION THEO, P335; REINSCH CH, 1967, NUMER MATH, V10, P177, DOI 10.1007/BF02162161; SCHOENBERG IJ, 1964, P NATL ACAD SCI USA, V52, P947, DOI 10.1073/pnas.52.4.947; SHAHRARAY B, 1985, THESIS U MICHIGAN AN; SHAHRARAY B, 1986, JUN P IEEE COMP SOC, P210; SHIAU JH, 1985, THESIS U WISCONSIN; SILVERMAN BW, 1984, J AM STAT ASSOC, V79, P584, DOI 10.2307/2288404; STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; Tikhonov A., 1977, SOLUTIONS ILL POSED; Tikhonov AN, 1963, SOV MATH DOKL, V4, P1624; WAHBA G, 1975, COMMUN STAT, V4, P125, DOI 10.1080/03610927508827233; WAHBA G, 1975, COMMUN STAT, V4, P1, DOI 10.1080/03610927508827223; WAHBA G, 1985, ANN STAT, V13, P1378, DOI 10.1214/aos/1176349743; Wahba G, 1977, APPL STAT, P507; WAHBA G, 1979, OCT P INT S ILL POS; WAHBA G, 1980, 595 U WISC DEP STAT; Wahba S. S., 1982, STAT DECISION THEORY, P383; Wahbe G., 1980, MONTHLY WEATHER REV, V108, P36; WENDELBERGER J, 1983, THESIS U WISCONSIN M; WENDELBERGER JG, 1981, 648 U WISC DEP STAT; Whittaker E.T., 1922, P EDINBURGH MATH SOC, V41, P63, DOI [10.1017/S0013091500077853, DOI 10.1017/S0013091500077853]; YASUMOTO Y, 1986, IEEE T PATTERN ANAL, V8, P464, DOI 10.1109/TPAMI.1986.4767810	46	51	51	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1989	11	6					600	610		10.1109/34.24794	http://dx.doi.org/10.1109/34.24794			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U6749					2022-12-18	WOS:A1989U674900005
J	WONG, AKC; LU, SW; RIOUX, M				WONG, AKC; LU, SW; RIOUX, M			RECOGNITION AND SHAPE SYNTHESIS OF 3-D OBJECTS BASED ON ATTRIBUTED HYPERGRAPHS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CONCORDIA UNIV,DEPT COMP SCI,MONTREAL H3G 1 M9,QUEBEC,CANADA; NATL RES COUNCIL CANADA,DIV ELECT ENGN,OTTAWA K1A 0R8,ONTARIO,CANADA	Concordia University - Canada; National Research Council Canada	WONG, AKC (corresponding author), UNIV WATERLOO,DEPT SYST DESIGN ENGN,WATERLOO N2L 3G1,ONTARIO,CANADA.							[Anonymous], 1980, PRINCIPLES ARTIFICIA; Ballard D.H., 1982, COMPUTER VISION; Barrow H. G., 1976, Information Processing Letters, V4, P83, DOI 10.1016/0020-0190(76)90049-1; Berge C, 1973, GRAPHS HYPERGRAPHS, P389; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BOYER KL, 1986, IEEE EXPERT      FAL, P73; BROWN CM, 1981, IEEE T PATTERN ANAL, V3, P444, DOI 10.1109/TPAMI.1981.4767129; CASALE MS, 1985, IEEE COMPUT GRAPH, V5, P45, DOI 10.1109/MCG.1985.276402; DAVIS LS, 1980, INFORM SYST, V5, P107, DOI 10.1016/0306-4379(80)90002-2; GENNERY DB, 1979, 6TH P INT JOINT C AR, P320; HAKALAHTI H, 1984, PATTERN RECOGN LETT, V2, P227, DOI 10.1016/0167-8655(84)90029-1; Holland S. W., 1979, Computer Vision and Sensor-based Robots, P81; LU SW, 1985, 1ST P IFAC S ROB C B, P389; LU SW, 1986, OCT P SPIE C INT ROB, P346; NARSINGH D, 1974, GRAPH THEORY APPLICA, P310; RIOUX M, 1984, APPL OPTICS, V23, P3837, DOI 10.1364/AO.23.003837; ROURKE J, 1979, IEEE T PATTERN ANAL, V1, P295; SANFELIU A, 1983, IEEE T SYST MAN CYBE, V13; SHAFER SA, 1983, CMUCS83105; Shapiro L. G., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P416; SHAPIRO LG, 1980, GEO-PROCESSING, V1, P313; SHAPIRO LG, PATTERN RECOGN, V17, P385; TSAI WH, 1983, IEEE T SYST MAN CYB, V13, P48, DOI 10.1109/TSMC.1983.6313029; Wong A. K. C., 1983, 1983 Proceedings of the International Conference on Systems, Man and Cybernetics (Cat. No. 83CH1962-0), P197; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; WONG AKC, 1983, P INT C SYST MAN CYB, P49; WONG AKC, 1987, NATO ADV STUDY I SER, P113	27	51	51	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					279	290		10.1109/34.21797	http://dx.doi.org/10.1109/34.21797			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840					2022-12-18	WOS:A1989T384000008
J	GARBAY, C				GARBAY, C			IMAGE STRUCTURE REPRESENTATION AND PROCESSING - A DISCUSSION OF SOME SEGMENTATION METHODS IN CYTOLOGY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											GARBAY, C (corresponding author), UNIV GRENOBLE 1,CNRS,TIM LAB 3,EQUIPE RECONNAISSANCE FORMES & MICROSCOPIE QUANTITAT,F-38402 ST MARTIN HERES,FRANCE.							BLANZ WE, 1981, PATTERN RECOGNITION, V13; CHASSERY JM, 1983, P SOC PHOTO-OPT INST, V397, P165, DOI 10.1117/12.935294; CHASSERY JM, 1984, IEEE T PATTERN ANAL, V6; FAUGERAS D, 1981, IEEE T PATTERN ANAL, V3; FU KS, 1977, DIGITAL IMAGE PROCES; GAUVAIN C, 1984, ANAL QUANT CYTOL, V6, P168; Haralick R., 1984, IEEE T PATTERN ANAL, V6; LEVIALDI S, 1980, DIGITAL IMAGE PROCES; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Muerle J.L., 1968, PICTORIAL PATTERN RE; NORDIN B, 1982, 1ST P IEEE COMP SOC, P140; ROSENFELD A, 1979, P IEEE, V67, P764, DOI 10.1109/PROC.1979.11326; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; WESKA JS, 1978, COMPUT GRAPHICS IMAG, V7, P259; ZUCKER SW, 1977, DIGITAL IMAGE PROCES	15	51	55	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					140	146		10.1109/TPAMI.1986.4767768	http://dx.doi.org/10.1109/TPAMI.1986.4767768			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869333				2022-12-18	WOS:A1986A107300002
J	VILNROTTER, FM; NEVATIA, R; PRICE, KE				VILNROTTER, FM; NEVATIA, R; PRICE, KE			STRUCTURAL-ANALYSIS OF NATURAL TEXTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF, DEPT ELECT ENGN, LOS ANGELES, CA 90089 USA; UNIV SO CALIF, DEPT COMP SCI, LOS ANGELES, CA 90089 USA	University of Southern California; University of Southern California	VILNROTTER, FM (corresponding author), HUGHES ARTIF INTELLIGENCE CTR, CALABASAS, CA USA.							Bajcsy R.K., 1973, COMPUTER GRAPHICS IM, V2, P118; Ballard D.H., 1982, COMPUTER VISION; Brodatz P., 1966, TEXTURES; CAELLI T, 1978, BIOL CYBERN, V28, P167, DOI 10.1007/BF00337138; CARLUCCI L, 1972, PATTERN RECOGN, V4, P53, DOI 10.1016/0031-3203(72)90019-2; CONNERS RW, 1980, COMPUT VISION GRAPH, V12, P224, DOI 10.1016/0146-664X(80)90013-1; DAVIS LS, 1979, COMPUT VISION GRAPH, V11, P111, DOI 10.1016/0146-664X(79)90061-3; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P251, DOI 10.1109/TPAMI.1979.4766921; EHRICH RW, 1978, COMPUT VISION GRAPH, V8, P174, DOI 10.1016/0146-664X(78)90048-5; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; JULESZ B, 1975, SCI AM, V232, P34, DOI 10.1038/scientificamerican0475-34; LAWS KI, 1980, USCIPI940 U SO CAL R; LU SY, 1978, COMPUT VISION GRAPH, V7, P303, DOI 10.1016/S0146-664X(78)80001-X; LU SY, 1979, COMPUT VISION GRAPH, V9, P234, DOI 10.1016/0146-664X(79)90039-X; MALESON JT, 1977, OCT P DARPA IM UND W, P19; MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090; MATSUYAMA T, 1982, COMPUT VISION GRAPH, V18, P259, DOI 10.1016/0146-664X(82)90035-1; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; NEVATIA R, 1982, MACHINE PERCEPTION; PURKS SR, 1977, J OPT SOC AM, V67, P765, DOI 10.1364/JOSA.67.000765; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; TOMITA F, 1982, IEEE T PATTERN ANAL, V4, P183, DOI 10.1109/TPAMI.1982.4767225; VILNROTTER F, 1981, USCISG100 U SO CAL D; WANG S, 1981, IEEE T SYST MAN CYB, V11, P360, DOI 10.1109/TSMC.1981.4308692; Zucker SW., 1976, COMPUTER GRAPHICS IM, V5, P190, DOI [10.1016/0146-664X(76)90027-7, DOI 10.1016/0146-664X(76)90027-7]	26	51	54	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1986	8	1					76	89		10.1109/TPAMI.1986.4767754	http://dx.doi.org/10.1109/TPAMI.1986.4767754			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AWT86	21869325				2022-12-18	WOS:A1986AWT8600009
J	BELAID, A; HATON, JP				BELAID, A; HATON, JP			A SYNTACTIC APPROACH FOR HANDWRITTEN MATHEMATICAL FORMULA RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											BELAID, A (corresponding author), UNIV NANCY 1,CRIN,PATTERN RECOGNIT & ARTIFICIAL INTELLIGENCE GRP,F-54506 VANDOEUVRE NANCY,FRANCE.							Aho Alfred V., 1977, PRINCIPLES COMPILER; ANDERSON RH, 1968, INTERACTIVE SYSTEMS; BELAID A, 1982, TSI-TECH SCI INF, V1, P155; BELAID A, 1979, THESIS U NANCY 1; BERTHOD M, 1979, SEP C AFCET REC FORM; BERTHOD M, 1974, 2ND IJCPR; BERTHOD M, 1975, THESIS U PARIS 6; Fu K.S., 1974, MATH SCI ENG; HATON JP, 1976, 3RD IJCPR SAN DIEG; ITO MR, 1978, PATTERN RECOGN, V10, P341, DOI 10.1016/0031-3203(78)90005-5; MARI JF, 1979, THESIS U NANCY 1; MARTIN WA, 1971, 2ND P ACM S SYMB ALG; MASINI G, 1978, THESIS U NANCY 1; NARASIMHAN R, 1971, PATTERN RECOGN, V3, P345, DOI 10.1016/0031-3203(71)90027-6; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1; PAVLIDIS T, 1972, FRONTIERS PATTERN RE; TOUSSAINT GT, 1978, PATTERN RECOGN, V10, P189, DOI 10.1016/0031-3203(78)90027-4	17	51	62	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	1					105	111		10.1109/TPAMI.1984.4767483	http://dx.doi.org/10.1109/TPAMI.1984.4767483			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SB213	21869173				2022-12-18	WOS:A1984SB21300014
J	WILSON, R; GRANLUND, GH				WILSON, R; GRANLUND, GH			THE UNCERTAINTY PRINCIPLE IN IMAGE-PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									LINKOPING UNIV, DEPT ELECT ENGN, S-58183 LINKOPING, SWEDEN	Linkoping University								BASTIAANS MJ, 1979, J OPT SOC AM, V69, P1710, DOI 10.1364/JOSA.69.001710; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GRAHAM N, 1980, DETECTING EDGES EDGE; GRANLUND GH, 1978, COMPUT VISION GRAPH, V8, P155, DOI 10.1016/0146-664X(78)90047-3; HEISENBERG W, 1930, PHYSICAL PRINCIPLES; Hughes RL, 1981, SCI AM, V245, P146, DOI [10.1038/scientificamerican0881-146, DOI 10.1038/SCIENTIFICAMERICAN0881-146]; JACOBSON L, 1982, NEW PARADIGM COMPUTA; JAMMER M, 1974, PHILOS QUANTUM MECHA; KNUTSSON H, 1982, THESIS LINKOPING U; KNUTSSON HE, 1983, IEEE T COMMUN, V31, P388, DOI 10.1109/TCOM.1983.1095832; LANDAU HJ, 1962, BELL SYST TECH J, V41, P1295, DOI 10.1002/j.1538-7305.1962.tb03279.x; LANDAU HJ, 1961, BELL SYST TECH J, V40, P65, DOI 10.1002/j.1538-7305.1961.tb03977.x; MANDL F, 1959, QUANTUM MECHANICS; MARR D, 1979, MIT518 AI MEM; SHANMUGAM KS, 1979, IEEE T PATTERN ANAL, V1, P37, DOI 10.1109/TPAMI.1979.4766874; SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969; SLEPIAN D, 1964, BELL SYST TECH J, V43, P3009, DOI 10.1002/j.1538-7305.1964.tb01037.x; SLEPIAN D, 1976, P IEEE, V64, P292, DOI 10.1109/PROC.1976.10110; SLEPIAN D, 1961, BELL SYST TECH J, V40, P43, DOI 10.1002/j.1538-7305.1961.tb03976.x; SLEPIAN D, 1978, BELL SYST TECH J, V57, P1317; THOMSON DJ, 1982, P IEEE, V70, P1055, DOI 10.1109/PROC.1982.12433; Watson A B, 1983, DETECTION RECOGNITIO; WILSON HR, 1979, VISION RES, V19, P19, DOI 10.1016/0042-6989(79)90117-2; Wilson R., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P846; WILSON R, 1984, P IEEE INT C ACOUST; WILSON R, 1983, LITHISYI0581 LINK U; WILSON R, 1983, LITHISYI0579 LINK U	27	51	51	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					758	767		10.1109/TPAMI.1984.4767599	http://dx.doi.org/10.1109/TPAMI.1984.4767599			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499656				2022-12-18	WOS:A1984TX36100009
J	NARENDRA, PM; GOLDBERG, M				NARENDRA, PM; GOLDBERG, M			IMAGE SEGMENTATION WITH DIRECTED TREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV OTTAWA,DEPT ELECT ENGN,OTTAWA K1N 6N5,ONTARIO,CANADA	University of Ottawa	NARENDRA, PM (corresponding author), HONEYWELL INC,CTR SYST & RES,MINNEAPOLIS,MN 55413, USA.							BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1; Duda R, 1995, PATTERN CLASSIFICATI, DOI 10.2307/1573081; FENG HYF, 1975, IEEE T CIRCUITS SYST, VCA22, P427, DOI 10.1109/TCS.1975.1084066; HARALICK RM, 1975, IEEE T CIRCUITS SYST, VCA22, P440, DOI 10.1109/TCS.1975.1084059; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; HUECKEL MJ, 1973, J ASS COMPUT MACH, V4, P634; KETTIG RL, 1976, IEEE T GEOSCI REMOTE, V14, P19, DOI 10.1109/TGE.1976.294460; KOONTZ WLG, 1976, IEEE T COMPUT, V25, P936, DOI 10.1109/TC.1976.1674719; MARTELLI A, 1972, COMPUTER GRAPHICS IM, V1, P169, DOI DOI 10.1016/S0146-664X(72)80013-3; ROBERTSON TV, 1973, TREE7326 PURD U SCH; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	12	51	51	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	2					185	191		10.1109/TPAMI.1980.4766999	http://dx.doi.org/10.1109/TPAMI.1980.4766999			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	JH803	21868892				2022-12-18	WOS:A1980JH80300013
J	PRAGER, JM				PRAGER, JM			EXTRACTING AND LABELING BOUNDARY SEGMENTS IN NATURAL SCENES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,AMHERST,MA 01003	University of Massachusetts System; University of Massachusetts Amherst								BAJCSY R, 1976, IEEE T SYST MAN CYB, V6, P623, DOI 10.1109/TSMC.1976.4309568; BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1; Hanson A., 1978, COMPUTER VISION SYST; LESSER VR, 1977, IJCAI 5; LEV A, 1977, IEEE T SYST MAN CYB, V7, P435, DOI 10.1109/TSMC.1977.4309740; PRAGER JM, 1977, COINS777 U MASS DEP; RISEMAN EM, 1977, COMPUT VISION GRAPH, V6, P221, DOI 10.1016/S0146-664X(77)80028-2; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SOUTHWELL RV, 1935, P ROY SOC          A, V151; TENENBAUM JM, 1976, SRI123 TECH NOT; WALTZ D, AI271 LAB TECH REP; WALTZ DL, 1972, THESIS MIT; YAKIMOVSKY Y, 1976, J ACM, V23, P599, DOI 10.1145/321978.321981; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1977, IEEE T COMPUT, V26, P922; ZUCKER SW, 1976, 477 U MAR COMP SCI C; ZUCKER SW, 1978, ANAL PROBABILISTIC R	17	51	54	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	1					16	27		10.1109/TPAMI.1980.4766966	http://dx.doi.org/10.1109/TPAMI.1980.4766966			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD568	22499619				2022-12-18	WOS:A1980JD56800003
J	SANDERSON, AC; SEGEN, J; RICHEY, E				SANDERSON, AC; SEGEN, J; RICHEY, E			HIERARCHICAL MODELING OF EEG SIGNALS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CARNEGIE MELLON UNIV,PROGRAM BIOMED ENGN,PITTSBURGH,PA 15213; UNIV PITTSBURGH,SCH MED,WESTERN PSYCHIAT INST & CLIN,CLIN ELECTROENCEPHALOG LAB,PITTSBURGH,PA 15261	Carnegie Mellon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Western Psychiatric Institute & Clinic of UPMC	SANDERSON, AC (corresponding author), CARNEGIE MELLON UNIV,DEPT ELECT ENGN,PITTSBURGH,PA 15213, USA.							AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BARLOW JS, 1954, ELECTROEN CLIN NEURO, V6, P321, DOI 10.1016/0013-4694(54)90036-X; BARLOW JS, 1979, IEEE T BIO-MED ENG, V26, P377, DOI 10.1109/TBME.1979.326416; BARLOW JS, 1956, ELECTROENCEPHALOGR C, V8, P325; Berger T, 1971, RATE DISTORTION THEO; BODENSTEIN G, 1977, P IEEE, V65, P642, DOI 10.1109/PROC.1977.10543; BOHLIN T, 1977, MATH BIOSCI, V35, P221, DOI 10.1016/0025-5564(77)90026-8; BOHLIN T, 1973, IBM J RES DEV, V17, P194, DOI 10.1147/rd.173.0194; BRAIZIER MAB, 1952, ELECTROENCEPHALOGR C, V5, P201; BURGER D, 1977, BIOL CYBERN, V26, P131, DOI 10.1007/BF00365224; CARRIE JRG, 1977, COMPUT BIOMED RES, V10, P449, DOI 10.1016/0010-4809(77)90020-9; CHAITIN GJ, 1975, J ACM, V22, P329, DOI 10.1145/321892.321894; Cinlar E., 2013, INTRO STOCHASTIC PRO; DASILVA FHL, 1973, QUANTIFIZIERUNG ELEK, P425; FENWICK PBC, 1967, BIOMED COMPUT, V2, P281; FONTANA RJ, UNPUBLISHED; Fu K.S., 1974, MATH SCI ENG; GERSCH W, 1977, COMPUT BIOMED RES, V10, P113, DOI 10.1016/0010-4809(77)90029-5; GERSCH W, 1970, Mathematical Biosciences, V7, P205, DOI 10.1016/0025-5564(70)90049-0; GERSCH W, 1977, COMPUT BIOMED RES, V10, P297, DOI 10.1016/0010-4809(77)90044-1; GEVINS AS, 1975, P IEEE, V63, P1382, DOI 10.1109/PROC.1975.9966; GIESE DA, 1979, IEEE T SYST MAN CYB, V9, P429, DOI 10.1109/TSMC.1979.4310255; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; Grass AM, 1938, J NEUROPHYSIOL, V1, P521, DOI 10.1152/jn.1938.1.6.521; Hartigan J.A., 1975, CLUSTERING ALGORITHM; ITIL TM, 1973, CURRENT THERAPEUT RE, V16, P80; John E. R., 1977, NEUROMETRICS CLIN AP; JONES RH, 5TH P HAW INT C SYST, P18; JOY RM, 1971, NEUROPHARMACOLOGY, V10, P471, DOI 10.1016/0028-3908(71)90075-X; KASHYAP RL, 1976, DYNAMIC STOCHASTIC M, P135; KAWABATA N, 1973, IEEE T BIO-MED ENG, VBM20, P444, DOI 10.1109/TBME.1973.324218; KLEINER B, 1973, ELECTROEN CLIN NEURO, V35, P331, DOI 10.1016/0013-4694(73)90246-0; MUCCIARDI AM, 1974, PSYCHOTROPIC DRUGS H, P351; Ozaki T., 1975, 8th Hawaii International Conference on System Sciences, P224; PARISOT CR, 1976, COMPUTER TECHNOLOGY; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PRAETORIUS HM, 1977, ELECTROEN CLIN NEURO, V42, P84, DOI 10.1016/0013-4694(77)90153-5; PRIESTLEY MB, 1965, J ROY STAT SOC B, V27, P204; PRIESTLEY MB, 1966, J R STAT SOC B, V28, P228; PRIESTLEY MB, 1969, JR STATIST SOC     B, P140; RAO CR, 1973, LINEAR STATISTICAL I; REDDY DR, 1976, P IEEE, V64, P501, DOI 10.1109/PROC.1976.10158; REMOND A, 1977, EEG INFORMATICS DIDA; REMOND A, 1961, ELECTROEN CLIN NEURO, V20, P64; REMOND A, 1966, ELECTROENCEPHALOGR S, V27, P29; RHODES JM, 1966, PSYCHON SCI, V6, P439; RISSANEN J, 1978, INFORMATICA, V14, P465; SANDERSON AC, 1976, BIOL CYBERN, V22, P61, DOI 10.1007/BF00320131; SEGEN J, 1980, IEEE T INFORM THEORY, V26, P249, DOI 10.1109/TIT.1980.1056151; SEGEN J, 1979, 12TH P ANN S COMP SC; SEGEN J, 1979, 10TH P MOD SIM C PIT; SKLAR B, 1973, IEEE T BIO-MED ENG, VBM20, P20, DOI 10.1109/TBME.1973.324247; SMITH JR, 1974, IEEE T BIO-MED ENG, VBM21, P1, DOI 10.1109/TBME.1974.324354; SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P1, DOI 10.1016/S0019-9958(64)90223-2; SOLOMONOFF RJ, 1964, INFORM CONT, V7, P23; Walter D. O., 1968, ELECTROEN CLIN NEURO, P53; WALTER DO, 1967, ELECTROEN CLIN NEURO, V22, P22, DOI 10.1016/0013-4694(67)90005-3; WALTER DO, 1965, IEEE T BIO-MED ENG, VBM12, P8, DOI 10.1109/TBME.1965.4502335; WALTER DO, 1963, EXP NEUROL, V8, P155, DOI 10.1016/0014-4886(63)90042-6; WALTER WG, 1951, ELECTROEN CLIN NEURO, V3, P281; WENNBERG A, 1971, ELECTROEN CLIN NEURO, V31, P457, DOI 10.1016/0013-4694(71)90167-2; WILLIS DG, 1970, J ACM, V17, P241, DOI 10.1145/321574.321578; ZETTERBERG L H, 1969, Mathematical Biosciences, V5, P227, DOI 10.1016/0025-5564(69)90044-3; ZETTERBERG LH, 1973, AUTOMATION CLIN ELEC, P227; [No title captured]; [No title captured], DOI DOI 10.1016/0013-4694(77)90189-4	66	51	51	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	5					405	415		10.1109/TPAMI.1980.6592361	http://dx.doi.org/10.1109/TPAMI.1980.6592361			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KW185					2022-12-18	WOS:A1980KW18500003
J	Shen, YJ; Yang, CY; Tang, XO; Zhou, BL				Shen, Yujun; Yang, Ceyuan; Tang, Xiaoou; Zhou, Bolei			InterFaceGAN: Interpreting the Disentangled Face Representation Learned by GANs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Faces; Gallium nitride; Generative adversarial networks; Generators; Aerospace electronics; Facial features; Generative adversarial network; face editing; interpretability; explainable artificial intelligence; disentanglement		Although generative adversarial networks (GANs) have made significant progress in face synthesis, there lacks enough understanding of what GANs have learned in the latent representation to map a random code to a photo-realistic image. In this work, we propose a framework called InterFaceGAN to interpret the disentangled face representation learned by the state-of-the-art GAN models and study the properties of the facial semantics encoded in the latent space. We first find that GANs learn various semantics in some linear subspaces of the latent space. After identifying these subspaces, we can realistically manipulate the corresponding facial attributes without retraining the model. We then conduct a detailed study on the correlation between different semantics and manage to better disentangle them via subspace projection, resulting in more precise control of the attribute manipulation. Besides manipulating the gender, age, expression, and presence of eyeglasses, we can even alter the face pose and fix the artifacts accidentally made by GANs. Furthermore, we perform an in-depth face identity analysis and a layer-wise analysis to evaluate the editing results quantitatively. Finally, we apply our approach to real face editing by employing GAN inversion approaches and explicitly training feed-forward models based on the synthetic data established by InterFaceGAN. Extensive experimental results suggest that learning to synthesize faces spontaneously brings a disentangled and controllable face representation.	[Shen, Yujun; Yang, Ceyuan; Tang, Xiaoou; Zhou, Bolei] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Peoples R China	Chinese University of Hong Kong	Zhou, BL (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Peoples R China.	sy116@ie.cuhk.edu.hk; yc019@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk; bzhou@ie.cuhk.edu.hk		Shen, Yujun/0000-0003-3801-6705	Research Grants Council of Hong Kong [24206219]; CUHK Faculty of Engineering; Sense-Time Collaborative Grant	Research Grants Council of Hong Kong(Hong Kong Research Grants Council); CUHK Faculty of Engineering; Sense-Time Collaborative Grant	This work was supported in part by the Early Career Scheme (ECS) through the Research Grants Council of Hong Kong under Grant No.24206219, in part by RSFS grant from CUHK Faculty of Engineering, and in part by Sense-Time Collaborative Grant.	Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453; Abdal Rameen, 2020, P IEEE CVF C COMP VI, P8296, DOI 10.1109/CVPR42600.2020.00832; Arjovsky M, 2017, PR MACH LEARN RES, V70; Arvanitidis G., 2018, INT C LEARN REPR; Bao JM, 2018, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2018.00702; Bau D, 2019, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2019.00460; Bau D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323023; Bau David, 2019, INT C LEARN REPR ICL; Berthelot D., 2017, BEGAN BOUNDARY EQUIL, DOI DOI 10.48550/ARXIV.1703.10717; Bojanowski P, 2018, PR MACH LEARN RES, V80; Brock AM, 2018, PROCEEDINGS PERVASIVE DISPLAYS 2018: THE 7TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, DOI 10.1145/3205873.3205877; Chen NT, 2018, PR MACH LEARN RES, V84; Chen X, 2016, ADV NEUR IN, V29; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Donahue C., 2018, P INT C LEARN REPR I, P1; Donahue Jeff, 2017, INT C LEARN REPR ICL; Dumoulin Vincent, 2017, ICLR 2017, P4; Goetschalckx L, 2019, IEEE I CONF COMP VIS, P5743, DOI 10.1109/ICCV.2019.00584; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gu JQ, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415691; Gulrajani I, 2017, P NIPS 2017; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jahanbani A, 2022, POLYCYCL AROMAT COMP, V42, P1851, DOI 10.1080/10406638.2020.1809472; Karacan L., 2016, ARXIV161200215; Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kuhnel Line, 2018, ARXIV180507632; Laine S., 2018, P 38 INT C INF SYST, P1; Lample Guillaume, 2017, ARXIV170600409; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lin D., 2020, PROC EUR C COMPUT VI, P1; Lipton Z. C., 2017, PROC S INTERPRETABLE, P1; Liu Ming-Yu, 2017, NIPS; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Mal Fangchang, 2018, IEEE INT C ROB AUT I, P1; Odena A, 2017, PR MACH LEARN RES, V70; Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244; Perarnau G, 2016, ARXIV161106355; Radford A., 2016, INT C LEARN REPR; Shao H, 2018, IEEE COMPUT SOC CONF, P428, DOI 10.1109/CVPRW.2018.00071; Shen YJ, 2018, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2018.00092; Shen Yujun, 2018, ARXIV181201288; Shen Yujun, 2020, P IEEE CVF C COMP VI; Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141; Upchurch P, 2017, PROC CVPR IEEE, P6090, DOI 10.1109/CVPR.2017.645; Viazovetskyi Y., 2020, P EUR C COMP VIS, P1; Wang TC, 2019, ADV NEUR IN, V32; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wang Ting-Chun, 2018, ARXIV180806601; Wang XT, 2019, PROC CVPR IEEE, P1692, DOI 10.1109/CVPR.2019.00179; Xiao TH, 2018, LECT NOTES COMPUT SC, V11214, P172, DOI 10.1007/978-3-030-01249-6_11; Yang C., ARXIV191109267, V2019; Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728; Yin X, 2017, IEEE I CONF COMP VIS, P4010, DOI 10.1109/ICCV.2017.430; Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457; Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821; Zhang H, 2019, PR MACH LEARN RES, V97; Zhu JB, 2020, 2020 FIFTEENTH INTERNATIONAL CONFERENCE ON ECOLOGICAL VEHICLES AND RENEWABLE ENERGIES (EVER); Zhu Jiapeng, 2019, ARXIV190608090; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36	68	50	50	23	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2004	2018		10.1109/TPAMI.2020.3034267	http://dx.doi.org/10.1109/TPAMI.2020.3034267			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33108282	Green Submitted			2022-12-18	WOS:000764815300026
J	Zuo, WM; Wu, XH; Lin, L; Zhang, L; Yang, MH				Zuo, Wangmeng; Wu, Xiaohe; Lin, Liang; Zhang, Lei; Yang, Ming-Hsuan			Learning Support Correlation Filters for Visual Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; correlation filters; support vector machine; max-margin learning	ROBUST TRACKING; OBJECT TRACKING	For visual tracking methods based on kernel support vector machines (SVMs), data sampling is usually adopted to reduce the computational cost in training. In addition, budgeting of support vectors is required for computational efficiency Instead of sampling and budgeting, recently the circulant matrix formed by dense sampling of translated image patches has been utilized in kernel correlation filters for fast tracking. In this paper, we derive an equivalent formulation of a SVM model with the circulant matrix expression and present an efficient alternating optimization method for visual tracking. We incorporate the discrete Fourier transform with the proposed alternating optimization process, and pose the tracking problem as an iterative learning of support correlation filters (SCFs). In the fully-supervision setting, our SCF can find the globally optimal solution with real-time performance. For a given circulant data matrix with n(2) samples of n x n pixels, the computational complexity of the proposed algorithm is O(n(2) log n) whereas that of the standard SVM-based approaches is at least O(n(4)). In addition, we extend the SCF-based tracking algorithm with multi-channel features, kernel functions, and scale-adaptive approaches to further improve the tracking performance. Experimental results on a large benchmark dataset show that the proposed SCF-based algorithms perform favorably against the state-of-the-art tracking methods in terms of accuracy and speed.	[Zuo, Wangmeng; Wu, Xiaohe] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China; [Lin, Liang] Sun Yat Sen Univ, Sch Adv Comp, Guangzhou 510006, Guangdong, Peoples R China; [Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hung Hom, Hong Kong, Peoples R China; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95344 USA	Harbin Institute of Technology; Sun Yat Sen University; Hong Kong Polytechnic University; University of California System; University of California Merced	Wu, XH (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.	cswmzuo@gmail.com; angela612@126.com; linliang@ieee.org; cslzhang@comp.polyu.edu.hk; mhyang@ucmerced.edu	xiaohe, wu/GZA-4694-2022; Zuo, Wangmeng/B-3701-2008; Yang, Ming-Hsuan/AAE-7350-2019; Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Zuo, Wangmeng/0000-0002-3330-783X; Liang, Lin/0000-0003-2248-3755; Zhang, Lei/0000-0002-2078-4215	National Defense Science and Technology Innovation Special Zone Project of China [17-163-11-ZT-003-024-01]; NSFC [61671182]; NSF CAREER Grant [1149783]; NSF IIS Grant [1152576]; HK RGC GRF Grant [PolyU 152240/15E]	National Defense Science and Technology Innovation Special Zone Project of China; NSFC(National Natural Science Foundation of China (NSFC)); NSF CAREER Grant(National Science Foundation (NSF)NSF - Office of the Director (OD)); NSF IIS Grant; HK RGC GRF Grant	This work is supported in part by the National Defense Science and Technology Innovation Special Zone Project of China Grant (17-163-11-ZT-003-024-01), NSFC Grant (61671182), NSF CAREER Grant (No. 1149783), NSF IIS Grant (No. 1152576), and HK RGC GRF Grant (PolyU 152240/15E).	Allain M, 2006, IEEE T IMAGE PROCESS, V15, P1130, DOI 10.1109/TIP.2005.864173; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Bai YC, 2012, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2012.6247884; BAO CL, 2012, PROC CVPR IEEE, P1830, DOI DOI 10.1109/CVPR.2012.6247881; Bischof H., 2006, BMVC, P47; Boddeti V. N., 2014, ABS14046031 CORR; Boddeti VN, 2013, PROC CVPR IEEE, P2291, DOI 10.1109/CVPR.2013.297; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; Bolme DS, 2009, PROC CVPR IEEE, P2105, DOI 10.1109/CVPRW.2009.5206701; Boyd S, 2004, CONVEX OPTIMIZATION; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Danelljan M, 2014, BRIT MACHINE VISIO, P1; Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143; Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381; Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13; GOEBEL K, 1972, P AM MATH SOC, V35, P171, DOI 10.2307/2038462; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Gray R. M., 2006, TOEPLITZ CIRCULANT M; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Henriques JF, 2013, IEEE I CONF COMP VIS, P2760, DOI 10.1109/ICCV.2013.343; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; Ho J, 2004, PROC CVPR IEEE, P782; Horn R.A., 2013, MATRIX ANAL, VSecond; Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14; Lee CP, 2013, NEURAL COMPUT, V25, P1302, DOI 10.1162/NECO_a_00434; Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18; Patnaik  R., 2009, P IS T SPIE ELECT IM; Rifkin R, 2003, NATO SCI SERIES 3, V190, P131, DOI DOI 10.1016/S0072-9752(06)80038-2; ROCKAFELLAR RT, 1970, PAC J MATH, V33, P209, DOI 10.2140/pjm.1970.33.209; Rodriguez A, 2013, IEEE T IMAGE PROCESS, V22, P631, DOI 10.1109/TIP.2012.2220151; Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Smeulders A. W. M., 2014, IEEE T PATTERN ANAL, V37, DOI DOI 10.1109/TPAMI.2013.230; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13; Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9; Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62; Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882	45	50	54	5	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1158	1171		10.1109/TPAMI.2018.2829180	http://dx.doi.org/10.1109/TPAMI.2018.2829180			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993910	Green Submitted, hybrid			2022-12-18	WOS:000463607400010
J	Adeli, E; Thung, KH; An, L; Wu, GR; Shi, F; Wang, T; Shen, DG				Adeli, Ehsan; Thung, Kim-Han; An, Le; Wu, Guorong; Shi, Feng; Wang, Tao; Shen, Dinggang			Semi-Supervised Discriminative Classification Robust to Sample-Outliers and Feature-Noises	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Linear discriminant analysis; semi-supervised learning; robust classification; feature selection; sample outlier detection; Alzheimer's disease; Parkinson's disease; biomarker identification; disease diagnosis; nuclear norm; regularization	ALZHEIMERS-DISEASE; DIAGNOSIS	Discriminative methods commonly produce models with relatively good generalization abilities. However, this advantage is challenged in real-world applications (e.g., medical image analysis problems), in which there often exist outlier data points (sample-outliers) and noises in the predictor values (feature-noises). Methods robust to both types of these deviations are somewhat overlooked in the literature. We further argue that denoising can be more effective, if we learn the model using all the available labeled and unlabeled samples, as the intrinsic geometry of the sample manifold can be better constructed using more data points. In this paper, we propose a semi-supervised robust discriminative classification method based on the least-squares formulation of linear discriminant analysis to detect sample-outliers and feature-noises simultaneously, using both labeled training and unlabeled testing data. We conduct several experiments on a synthetic, some benchmark semi-supervised learning, and two brain neurodegenerative disease diagnosis datasets (for Parkinson's and Alzheimer's diseases). Specifically for the application of neurodegenerative diseases diagnosis, incorporating robust machine learning methods can be of great benefit, due to the noisy nature of neuroimaging data. Our results show that our method outperforms the baseline and several state-of-the-art methods, in terms of both accuracy and the area under the ROC curve.	[Adeli, Ehsan] Stanford Univ, Stanford, CA 94305 USA; [Adeli, Ehsan; Thung, Kim-Han; An, Le; Wu, Guorong; Shen, Dinggang] Univ North Carolina Chapel Hill, Dept Radiol, Biomed Res Imaging Ctr BRIC, Chapel Hill, NC 27599 USA; [Shi, Feng] Cedars Sinai Med Ctr, Biomed Imaging Res Inst, Los Angeles, CA 90048 USA; [Wang, Tao] Shanghai Mental Hlth Ctr, Dept Geriatr Psychiat, Shanghai 200000, Peoples R China; [Wang, Tao] Shanghai Jiao Tong Univ, Alzheimers Dis & Related Disorders Ctr, Shanghai 200000, Peoples R China; [Shen, Dinggang] Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea	Stanford University; University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina School of Medicine; Cedars Sinai Medical Center; Shanghai Jiao Tong University; Korea University	Adeli, E (corresponding author), Stanford Univ, Stanford, CA 94305 USA.; Adeli, E (corresponding author), Univ North Carolina Chapel Hill, Dept Radiol, Biomed Res Imaging Ctr BRIC, Chapel Hill, NC 27599 USA.	eadeli@stanford.edu; khthung@email.unc.edu; le_an@med.unc.edu; grwu@med.unc.edu; fengshi@med.unc.edu; wtshhwy@163.com; dgshen@med.unc.edu	Shen, Dinggang/ABF-6812-2020	Shen, Dinggang/0000-0002-7934-5698; Adeli, Ehsan/0000-0002-0579-7763; Wu, Guorong/0000-0002-0550-6145; Wang, Peiyao/0000-0002-5567-3339	NIA NIH HHS [K01 AG049089] Funding Source: Medline; NATIONAL INSTITUTE ON AGING [K01AG049089] Funding Source: NIH RePORTER	NIA NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA)); NATIONAL INSTITUTE ON AGING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))		Belkin M, 2004, LECT NOTES COMPUT SC, V3120, P624, DOI 10.1007/978-3-540-27819-1_43; Bennett KP, 1999, ADV NEUR IN, V11, P368; Bhadauria HS, 2013, COMPUT ELECTR ENG, V39, P1451, DOI 10.1016/j.compeleceng.2012.04.003; Bissantz N, 2009, SIAM J OPTIMIZ, V19, P1828, DOI 10.1137/050639132; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Braak H, 2003, NEUROBIOL AGING, V24, P197, DOI 10.1016/S0197-4580(02)00065-9; Cai D., 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/ICCV.2007.4408856; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Coupe P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087; Croux C, 2001, CAN J STAT, V29, P473, DOI 10.2307/3316042; Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013; De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184; Duchesne S, 2008, IEEE T MED IMAGING, V27, P509, DOI 10.1109/TMI.2007.908685; Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664; Eskildsen SF, 2013, NEUROIMAGE, V65, P511, DOI 10.1016/j.neuroimage.2012.09.058; Fidler S, 2006, IEEE T PATTERN ANAL, V28, P337, DOI 10.1109/TPAMI.2006.46; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fisher RA, 1935, J R STAT SOC, V98, P39, DOI 10.2307/2342435; Fritsch V, 2012, MED IMAGE ANAL, V16, P1359, DOI 10.1016/j.media.2012.05.002; Goldberg A., 2010, P NIPS, V23, P757; Gray KR, 2013, NEUROIMAGE, V65, P167, DOI 10.1016/j.neuroimage.2012.09.065; Huang D, 2016, IEEE T PATTERN ANAL, V38, P363, DOI 10.1109/TPAMI.2015.2448091; Huang D, 2012, LECT NOTES COMPUT SC, V7575, P616, DOI 10.1007/978-3-642-33765-9_44; Jordan A., 2002, P INT C NEUR INF PRO; Joulin A., 2012, ARXIV12066413; Kim S. J., 2005, P NEUR INF PROC SYST, P659; Li H., 2003, P ADV NEUR INF PROC, P97; Li H, 2015, IEEE T IMAGE PROCESS, V24, P2382, DOI 10.1109/TIP.2015.2401511; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu MH, 2014, HUM BRAIN MAPP, V35, P1305, DOI 10.1002/hbm.22254; Liu MX, 2016, IEEE T BIO-MED ENG, V63, P1473, DOI 10.1109/TBME.2015.2496233; Liu SQ, 2015, IEEE T BIO-MED ENG, V62, P1132, DOI 10.1109/TBME.2014.2372011; Lu CW, 2013, PROC CVPR IEEE, P415, DOI 10.1109/CVPR.2013.60; Manjon JV, 2012, MED IMAGE ANAL, V16, P18, DOI 10.1016/j.media.2011.04.003; Marek K, 2011, PROG NEUROBIOL, V95, P629, DOI 10.1016/j.pneurobio.2011.09.005; Meriaux S, 2006, I S BIOMED IMAGING, P936; Min R, 2014, HUM BRAIN MAPP, V35, P5052, DOI 10.1002/hbm.22531; Mueller Susanne G, 2005, Alzheimers Dement, V1, P55, DOI 10.1016/j.jalz.2005.06.003; PEARCE BR, 1984, NEUROCHEM PATHOL, V2, P221; Rodrigues I, 2008, IEEE IMAGE PROC, P1756, DOI 10.1109/ICIP.2008.4712115; Suzumura S, 2014, PR MACH LEARN RES, V32, P1098; Thung KH, 2014, NEUROIMAGE, V91, P386, DOI 10.1016/j.neuroimage.2014.01.033; Tong Tong, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P77, DOI 10.1007/978-3-319-24888-2_10; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wagner A, 2009, PROC CVPR IEEE, P597, DOI 10.1109/CVPRW.2009.5206654; Worker A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114167; Xu H, 2009, J MACH LEARN RES, V10, P1485; Zhu X.J., 2005, COMPUT SCI; Ziegler David A, 2013, Imaging Med, V5, P91	50	50	52	4	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					515	522		10.1109/TPAMI.2018.2794470	http://dx.doi.org/10.1109/TPAMI.2018.2794470			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29994560	Green Accepted			2022-12-18	WOS:000456150600018
J	Aytar, Y; Castrejon, L; Vondrick, C; Pirsiavash, H; Torralba, A				Aytar, Yusuf; Castrejon, Lluis; Vondrick, Carl; Pirsiavash, Hamed; Torralba, Antonio			Cross-Modal Scene Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cross-modal perception; domain adaptation; scene understanding		People can recognize scenes across many different modalities beyond natural images. In this paper, we investigate how to learn cross-modal scene representations that transfer across modalities. To study this problem, we introduce a new cross-modal scene dataset. While convolutional neural networks can categorize scenes well, they also learn an intermediate representation not aligned across modalities, which is undesirable for cross-modal transfer applications. We present methods to regularize cross-modal convolutional neural networks so that they have a shared representation that is agnostic of the modality. Our experiments suggest that our scene representation can help transfer representations across modalities for retrieval. Moreover, our visualizations suggest that units emerge in the shared representation that tend to activate on consistent concepts independently of the modality.	[Aytar, Yusuf; Vondrick, Carl; Torralba, Antonio] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Castrejon, Lluis] Univ Toronto, Dept Comp Sci, Toronto, ON M5S, Canada; [Pirsiavash, Hamed] Univ Maryland Baltimore Cty, 1000 Hilltop Cir,ITE 342, Baltimore, MD 21250 USA	Massachusetts Institute of Technology (MIT); University of Toronto; University System of Maryland; University of Maryland Baltimore County	Vondrick, C (corresponding author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	yusuf@csail.mit.edu; castrejon@cs.toronto.edu; vondrick@mit.edu; hpirsiav@umbc.edu; torralba@mit.edu			NVIDIA Corporation; US National Science Foundation [IIS-1524817]; Google faculty research award; Google PhD fellowship	NVIDIA Corporation; US National Science Foundation(National Science Foundation (NSF)); Google faculty research award(Google Incorporated); Google PhD fellowship(Google Incorporated)	We thank TIG for managing our computer cluster. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the GPUs used for this research. This work was supported by US National Science Foundation grant IIS-1524817, by a Google faculty research award to A.T and by a Google PhD fellowship to C.V. Yusuf Aytar and Lluis Castrejon contributed equally.	[Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Aytar Y, 2016, P 30 INT C NEUR INF, P892; Aytar Y, 2015, COMPUT VIS IMAGE UND, V138, P114, DOI 10.1016/j.cviu.2015.04.004; Ba JL, 2015, IEEE I CONF COMP VIS, P4247, DOI 10.1109/ICCV.2015.483; Bart E, 2005, PROC CVPR IEEE, P672; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Donahue J, 2014, PR MACH LEARN RES, V32; Dosovitskiy A., 2015, ABS150602753 CORR; Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266; Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Fink M, 2005, ADV NEURAL INFORM PR, P449; Fouhey DF, 2014, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2014.260; Frome Andrea, 2013, NEURIPS; Gao T, 2012, LECT NOTES COMPUT SC, V7576, P354, DOI 10.1007/978-3-642-33715-4_26; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524; Khosla A, 2012, LECT NOTES COMPUT SC, V7572, P158, DOI 10.1007/978-3-642-33718-5_12; Kiros R., 2015, ADV NEURAL INF PROCE, P3294; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Long M., 2015, P 32 INT C MACH LEAR, V1, P97; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Owens A., 2015, P IEEE C COMP VIS PA, P2405; Palatucci Mark, 2009, ADV NEURAL INFORM PR, P1410; Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Rasiwasia N, 2014, JMLR WORKSH CONF PRO, V33, P823; Richard S. Zemel, 2014, Arxiv, DOI arXiv:1411.2539; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Socher Richard, 2013, NEURIPS; Torralba A., 2004, NEURAL INFORM PROCES; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vondrick C., 2015, ADV NEURAL INFORM PR, P289; Vondrick C, 2013, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2013.8; Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Zhou B., 2014, CORR, V1412, P6856; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zitnick CL, 2013, IEEE I CONF COMP VIS, P1681, DOI 10.1109/ICCV.2013.211; Zitnick CL, 2013, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR.2013.387	50	50	50	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2303	2314		10.1109/TPAMI.2017.2753232	http://dx.doi.org/10.1109/TPAMI.2017.2753232			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28922114	Green Submitted, hybrid			2022-12-18	WOS:000443875500002
J	Fukui, K; Maki, A				Fukui, Kazuhiro; Maki, Atsuto			Difference Subspace and Its Generalization for Subspace-Based Methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Subspace method; mutual subspace method; canonical angles; difference subspace; 3D object recognition	FACE RECOGNITION	Subspace-based methods are known to provide a practical solution for image set-based object recognition. Based on the insight that local shape differences between objects offer a sensitive cue for recognition, this paper addresses the problem of extracting a subspace representing the difference components between class subspaces generated from each set of object images independently of each other. We first introduce the difference subspace (DS), a novel geometric concept between two subspaces as an extension of a difference vector between two vectors, and describe its effectiveness in analyzing shape differences. We then generalize it to the generalized difference subspace (GDS) for multi-class subspaces, and show the benefit of applying this to subspace and mutual subspace methods, in terms of recognition capability. Furthermore, we extend these methods to kernel DS (KDS) and kernel GDS (KGDS) by a nonlinear kernel mapping to deal with cases involving larger changes in viewing direction. In summary, the contributions of this paper are as follows: 1) a DS/KDS between two class subspaces characterizes shape differences between the two respectively corresponding objects, 2) the projection of an input vector onto a DS/KDS realizes selective visualization of shape differences between objects, and 3) the projection of an input vector or subspace onto a GDS/KGDS is extremely effective at extracting differences between multiple subspaces, and therefore improves object recognition performance. We demonstrate validity through shape analysis on synthetic and real images of 3D objects as well as extensive comparison of performance on classification tests with several related methods; we study the performance in face image classification on the Yale face database B+ and the CMU Multi-PIE database, and hand shape classification of multi-view images.	[Fukui, Kazuhiro] Univ Tsukuba, Dept Comp Sci, Tsukuba, Ibaraki, Japan; [Maki, Atsuto] KTH Royal Inst Technol, Sch Comp Sci & Commun, Stockholm, Sweden	University of Tsukuba; Royal Institute of Technology	Fukui, K (corresponding author), Univ Tsukuba, Dept Comp Sci, Tsukuba, Ibaraki, Japan.	kfukui@cs.tsukuba.ac.jp; atsuto@kth.se						Afriat S.N., 1957, MATH PROC CAMBRIDGE, V53, P800; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur P. N., 1998, INT J COMPUT VISION, V28, P1; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Beveridge JR, 2009, IEEE T PATTERN ANAL, V31, P351, DOI 10.1109/TPAMI.2008.200; Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827; Chikuse Y., 2013, STAT SPECIAL MANIFOL, V174; Fukui K, 2006, LECT NOTES COMPUT SC, V3852, P315; Fukui K., 2003, P INT S ROB RES, P192; Fukui K, 2007, LECT NOTES COMPUT SC, V4844, P467; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; Fukunaga K., 1972, INTRO STAT PATTERN R; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Iijima T., 1973, 1st International Joint Conference on Pattern Recognition, P50; Kawahara T., 2007, ACCV 07 WORKSHOP SUB; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Kim TK, 2010, IEEE T IMAGE PROCESS, V19, P1067, DOI 10.1109/TIP.2009.2038621; Kittler J., 1978, Progress in cybernetics and systems research, vol.III, P92; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Maeda E, 1999, INT CONF ACOUST SPEE, P1025, DOI 10.1109/ICASSP.1999.759880; Maeda K., 1985, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ68D, P345; Maki A, 2004, MACH VISION APPL, V15, P149, DOI 10.1007/s00138-004-0140-y; Ohkawa Y, 2012, IEICE T INF SYST, VE95D, P1619, DOI 10.1587/transinf.E95.D.1619; Oja E., 1983, SUBSPACE METHODPAT; Sakano H, 2000, KES'2000: FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED INTELLIGENT ENGINEERING SYSTEMS & ALLIED TECHNOLOGIES, VOLS 1 AND 2, PROCEEDINGS, P245, DOI 10.1109/KES.2000.885803; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 1998, MUSTERERKENNUNG 1998, P125; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; Tsuda K, 1999, PATTERN RECOGN LETT, V20, P513, DOI 10.1016/S0167-8655(99)00023-9; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; Watanabe S., 1973, 1st International Joint Conference on Pattern Recognition, P25; Wolf L, 2004, J MACH LEARN RES, V4, P913, DOI 10.1162/1532443041827934; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968; YANAI H, 1990, COMPUT STAT DATA AN, V10, P251, DOI 10.1016/0167-9473(90)90005-3; Zhang S, 2007, IEEE T PATTERN ANAL, V29, P1732, DOI 10.1109/TPAMI.2007.1089; [No title captured]	40	50	50	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2164	2177		10.1109/TPAMI.2015.2408358	http://dx.doi.org/10.1109/TPAMI.2015.2408358			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440259				2022-12-18	WOS:000362411000002
J	Hasanbelliu, E; Giraldo, LS; Principe, JC				Hasanbelliu, Erion; Giraldo, Luis Sanchez; Principe, Jose C.			Information Theoretic Shape Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Information theoretic learning; Cauchy-Schwarz divergence; correntropy; non-rigid registration; shape matching; surprise; annealing	POINT; ALGORITHM; REGISTRATION; COMPUTATION; CORRENTROPY	In this paper, we describe two related algorithms that provide both rigid and non-rigid point set registration with different computational complexity and accuracy. The first algorithm utilizes a nonlinear similarity measure known as correntropy. The measure combines second and high order moments in its decision statistic showing improvements especially in the presence of impulsive noise. The algorithm assumes that the correspondence between the point sets is known, which is determined with the surprise metric. The second algorithm mitigates the need to establish a correspondence by representing the point sets as probability density functions (PDF). The registration problem is then treated as a distribution alignment. The method utilizes the Cauchy-Schwarz divergence to measure the similarity/distance between the point sets and recover the spatial transformation function needed to register them. Both algorithms utilize information theoretic descriptors; however, correntropy works at the realizations level, whereas Cauchy-Schwarz divergence works at the PDF level. This allows correntropy to be less computationally expensive, and for correct correspondence, more accurate. The two algorithms are robust against noise and outliers and perform well under varying levels of distortion. They outperform several well-known and state-of-the-art methods for point set registration.	[Hasanbelliu, Erion; Giraldo, Luis Sanchez; Principe, Jose C.] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA	State University System of Florida; University of Florida	Hasanbelliu, E (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.		principe, jose/N-8099-2014					Aresenin V. I., 1977, SOLUTIONS ILL POSED; BELIS M, 1968, IEEE T INFORM THEORY, V14, P593, DOI 10.1109/TIT.1968.1054185; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Bronstein AM, 2007, IEEE T VIS COMPUT GR, V13, P902, DOI 10.1109/TVCG.2007.1041; Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Erdogmus D., 2001, THESIS U FLORIDA GAI; Glaunes J, 2004, PROC CVPR IEEE, P712; Hasanbelliu E., 2012, THESIS U FLORIDA GAI; Hasanbelliu E., 2011, P SOC PHOTO-OPT INS, V8017, P12; Hasanbelliu E., 2012, 2012 INT JOINT C NEU, P1; JAIN V, 2005, P PAC GRAPH, P121; Jeannin S., 1999, MPEG7; Jenssen R, 2006, J FRANKLIN I, V343, P614, DOI 10.1016/j.jfranklin.2006.03.018; Jian B, 2005, IEEE I CONF COMP VIS, P1246; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Kullback S, 1959, INFORM THEORY STAT; Liu WF, 2006, IEEE IJCNN, P4919; Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065; Myronenko A., 2006, 20 ADV NEUR INF PROC; PFAFFELHUBER E, 1977, J STAT PHYS, V16, P69, DOI 10.1007/BF01014606; PFAFFELHUBER E, 1972, INT J NEUROSCI, V3, P83, DOI 10.3109/00207457209147016; Principe JC, 2010, INFORM SCI STAT, P1, DOI 10.1007/978-1-4419-1570-2; RUBINSTEIN RY, 1983, MATH OPER RES, V8, P26, DOI 10.1287/moor.8.1.26; Rudin W., 1976, PRINCIPLES MATH ANAL, V3; Santamaria I, 2006, IEEE T SIGNAL PROCES, V54, P2187, DOI 10.1109/TSP.2006.872524; SIBSON R, 1991, SIAM J SCI STAT COMP, V12, P1304, DOI 10.1137/0912070; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Starck J, 2007, IEEE I CONF COMP VIS, P2189; Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558; Wahba G., 1990, SPLINE MODELS OBSERV; Weaver W., 1949, MATH THEORY INFORM; Yuille A. L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P344, DOI 10.1109/CCV.1988.590011; YUILLE AL, 1989, INT J COMPUT VISION, V3, P155, DOI 10.1007/BF00126430; Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81	41	50	51	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2436	2451		10.1109/TPAMI.2014.2324585	http://dx.doi.org/10.1109/TPAMI.2014.2324585			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353150				2022-12-18	WOS:000344988000009
J	Taghia, J; Ma, ZY; Leijon, A				Taghia, Jalil; Ma, Zhanyu; Leijon, Arne			Bayesian Estimation of the von-Mises Fisher Mixture Model with Variational Inference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian estimation; von-Mises Fisher distribution; mixture model; variational inference; directional distribution; predictive density; gene expressions; speaker identification	DISTRIBUTIONS	This paper addresses the Bayesian estimation of the von-Mises Fisher (vMF) mixture model with variational inference (VI). The learning task in VI consists of optimization of the variational posterior distribution. However, the exact solution by VI does not lead to an analytically tractable solution due to the evaluation of intractable moments involving functional forms of the Bessel function in their arguments. To derive a closed-form solution, we further lower bound the evidence lower bound where the bound is tight at one point in the parameter distribution. While having the value of the bound guaranteed to increase during maximization, we derive an analytically tractable approximation to the posterior distribution which has the same functional form as the assigned prior distribution. The proposed algorithm requires no iterative numerical calculation in the re-estimation procedure, and it can potentially determine the model complexity and avoid the over-fitting problem associated with conventional approaches based on the expectation maximization. Moreover, we derive an analytically tractable approximation to the predictive density of the Bayesian mixture model of vMF distributions. The performance of the proposed approach is verified by experiments with both synthetic and real data.	[Taghia, Jalil; Leijon, Arne] KTH Royal Inst Technol, Commun Theory Lab, Sch Elect Engn, S-10044 Stockholm, Sweden; [Ma, Zhanyu] Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Syst Lab, Beijing 100876, Peoples R China	Royal Institute of Technology; Beijing University of Posts & Telecommunications	Taghia, J (corresponding author), KTH Royal Inst Technol, Commun Theory Lab, Sch Elect Engn, S-10044 Stockholm, Sweden.	taghia@kth.se; mazhanyu@bupt.edu.cn; leijon@kth.se			European Commission within the Marie Curie ITN AUDIS [PITNGA-2008-214699]	European Commission within the Marie Curie ITN AUDIS	This work was funded by the European Commission within the Marie Curie ITN AUDIS, grant PITNGA-2008-214699. The authors would like to thank Gustav Henter for helpful discussions.	ABRAMOWITZ M., 1965, HDB MATH FUNCTIONS; [Anonymous], 1990, ACOUSTIC PHONETIC CO; BAGCHI P, 1991, CAN J STAT, V19, P67, DOI 10.2307/3315537; Banerjee A, 2005, J MACH LEARN RES, V6, P1345; Banerjee A, 2002, IEEE IJCNN, P1590, DOI 10.1109/IJCNN.2002.1007755; Bangert M., 2010, 2010 Ninth International Conference on Machine Learning and Applications (ICMLA 2010), P746, DOI 10.1109/ICMLA.2010.114; Benesty J., 2008, SPRINGER HDB SPPECH; Bishop C.M, 2006, PATTERN RECOGN; Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114; Boyd S, 2004, CONVEX OPTIMIZATION; Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714; Cox R. V., 1995, SPEECH CODING SYNTHE, P49; Damien P, 1999, CAN J STAT, V27, P291, DOI 10.2307/3315639; Dang HTV, 2010, INT CONF ACOUST SPEE, P241, DOI 10.1109/ICASSP.2010.5495994; Dhillon IS, 2003, BIOINFORMATICS, V19, P1612, DOI 10.1093/bioinformatics/btg209; Dhillon IS, 2001, MASSIVE COMP, V2, P357; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fisher NI., 1987, STAT ANAL SPHERICAL, DOI [10.1017/CBO9780511623059, DOI 10.1017/CBO9780511623059]; Fisher NI, 1996, STAT ANAL CIRCULAR D; Gray Jr A. H., 1976, LINEAR PREDICTION SP; GUTTORP P, 1988, J AM STAT ASSOC, V83, P322, DOI 10.2307/2288846; ITAKURA F, 1975, J ACOUST SOC AM, V57, pS35, DOI 10.1121/1.1995189; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Leijon A., 2013, 2013032 TRITAEE KTH; Lopez-Cruz PL, 2011, LECT NOTES ARTIF INT, V7023, P145, DOI 10.1007/978-3-642-25274-7_15; Ma ZY, 2013, IEEE T AUDIO SPEECH, V21, P1777, DOI 10.1109/TASL.2013.2238732; Ma ZY, 2011, IEEE T PATTERN ANAL, V33, P2160, DOI 10.1109/TPAMI.2011.63; MacKay DJ., 2001, LOCAL MINIMA SYMMETR; Mardia K.V., 2000, DIRECTIONAL STAT; MARDIA KV, 1976, BIOMETRIKA, V63, P203, DOI 10.1093/biomet/63.1.203; Mclachlan G., 2000, WILEY SER PROB STAT; Mooney JA, 2003, COMPUT STAT DATA AN, V41, P505, DOI 10.1016/S0167-9473(02)00181-0; Nunez- Antonio G, 2005, COMMUN STAT-SIMUL C, V34, P989, DOI 10.1080/03610910500308495; PIATER JH, 2001, THESIS U MASSACHUSSE; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Salton G., 1983, INTRO MODERN RETRIEV; Sharan R, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P307; Sinkkonen J, 2002, NEURAL COMPUT, V14, P217, DOI 10.1162/089976602753284509; Soong F., 1984, ICASSP 84 IEEE INT C, Vvol 9, ppp 37; Spellman PT, 1998, MOL BIOL CELL, V9, P3273, DOI 10.1091/mbc.9.12.3273; Strehl A., 2000, WORKSHOP ARTIFICIAL, P58; Tang H, 2009, INT CONF ACOUST SPEE, P4101, DOI 10.1109/ICASSP.2009.4960530; Turner R. E., 2011, BAYESIAN TIME SERIES, P109; Vary P., 2006, DIGITAL SPEECH TRANS, P119; WOOD ATA, 1994, COMMUN STAT SIMULAT, V23, P157, DOI 10.1080/03610919408813161; Zhong S, 2004, J MACH LEARN RES, V4, P1001, DOI 10.1162/1532443041827943	46	50	51	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1701	1715		10.1109/TPAMI.2014.2306426	http://dx.doi.org/10.1109/TPAMI.2014.2306426			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352226				2022-12-18	WOS:000340210100001
J	Yang, QX				Yang, Qingxiong			Hardware-Efficient Bilateral Filtering for Stereo Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; bilateral filtering; edge-preserving smoothing	BELIEF PROPAGATION	This paper presents a new bilateral filtering method specially designed for practical stereo vision systems. Parallel algorithms are preferred in these systems due to the real-time performance requirement. Edge-preserving filters like the bilateral filter have been demonstrated to be very effective for high-quality local stereo matching. A hardware-efficient bilateral filter is thus proposed in this paper. When moved to an NVIDIA GeForce GTX 580 GPU, it can process a one megapixel color image at around 417 frames per second. This filter can be directly used for cost aggregation required in any local stereo matching algorithm. Quantitative evaluation shows that it outperforms all the other local stereo methods both in terms of accuracy and speed on Middlebury benchmark. It ranks 12th out of over 120 methods on Middlebury data sets, and the average runtime (including the matching cost computation, occlusion handling, and post processing) is only 15 milliseconds (67 frames per second).	City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	City University of Hong Kong	Yang, QX (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	qiyang@cityu.edu.hk	Yang, Qingxiong/K-1729-2015	Yang, Qingxiong/0000-0002-4378-2335	GRF grant from the Research Grants Council of Hong Kong (RGC)	GRF grant from the Research Grants Council of Hong Kong (RGC)	This work was supported by a GRF grant from the Research Grants Council of Hong Kong (RGC Reference: CityU 122212).	Adams A. B., 2011, THESIS STANFORD U ST; Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x; Adams A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531327; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chen JY, 2007, ACTA OCEANOL SIN, V26, P26; Durand F., 2007, ACM T GRAPHIC, V21, P257; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156; Klaus A, 2006, INT C PATT RECOG, P15; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Min DB, 2011, IEEE I CONF COMP VIS, P1567, DOI 10.1109/ICCV.2011.6126416; Paris S, 2008, FOUND TRENDS COMPUT, V4, P1, DOI 10.1561/0600000020; Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963; Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8; Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188; Porikli F., 2008, P IEEE C COMP VIS PA, P1; Richardt C, 2010, LECT NOTES COMPUT SC, V6313, P510; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D., MIDDLEBURY STEREO EV; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Wang L, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P798; Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211; Yang QX, 2012, LECT NOTES COMPUT SC, V7572, P399, DOI 10.1007/978-3-642-33718-5_29; Yang QX, 2010, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2010.5539797; Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542; Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70	31	50	55	0	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					1026	1032		10.1109/TPAMI.2013.186	http://dx.doi.org/10.1109/TPAMI.2013.186			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353234				2022-12-18	WOS:000336054200015
J	Zhang, YM; Zhang, YF; Swears, E; Larios, N; Wang, ZH; Ji, Q				Zhang, Yongmian; Zhang, Yifan; Swears, Eran; Larios, Natalia; Wang, Ziheng; Ji, Qiang			Modeling Temporal Interactions with Interval Temporal Bayesian Networks for Complex Activity Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Activity recognition; temporal reasoning; Bayesian networks; interval temporal Bayesian networks	EVENT RECOGNITION; REPRESENTATION; FRAMEWORK; TRACKING	Complex activities typically consist of multiple primitive events happening in parallel or sequentially over a period of time. Understanding such activities requires recognizing not only each individual event but, more importantly, capturing their spatiotemporal dependencies over different time intervals. Most of the current graphical model-based approaches have several limitations. First, time-sliced graphical models such as hidden Markov models (HMMs) and dynamic Bayesian networks are typically based on points of time and they hence can only capture three temporal relations: precedes, follows, and equals. Second, HMMs are probabilistic finite-state machines that grow exponentially as the number of parallel events increases. Third, other approaches such as syntactic and description-based methods, while rich in modeling temporal relationships, do not have the expressive power to capture uncertainties. To address these issues, we introduce the interval temporal Bayesian network (ITBN), a novel graphical model that combines the Bayesian Network with the interval algebra to explicitly model the temporal dependencies over time intervals. Advanced machine learning methods are introduced to learn the ITBN model structure and parameters. Experimental results show that by reasoning with spatiotemporal dependencies, the proposed model leads to a significantly improved performance when modeling and recognizing complex activities involving both parallel and sequential events.	[Zhang, Yongmian] Konica Minolta Lab USA Inc, IT Res Div, San Mateo, CA 94403 USA; [Zhang, Yifan] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA; [Zhang, Yifan] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Swears, Eran; Larios, Natalia; Wang, Ziheng; Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Konica Minolta Inc.; Rensselaer Polytechnic Institute; Chinese Academy of Sciences; Institute of Automation, CAS; Rensselaer Polytechnic Institute	Zhang, YM (corresponding author), Konica Minolta Lab USA Inc, IT Res Div, 2855 Campus Dr, San Mateo, CA 94403 USA.	yongmianzhang@gmail.com; yfzhang@nlpr.ia.ac.cn; eran.swears@kitware.com; nlarios@microsoft.com; wangz10@rpi.edu; qji@ecse.rpi.edu			US Defense Advanced Research Projects Agency [HR0011-08-C-0135-S8, HR0011-10-C-0112]; National Natural Science Foundation of China [61202325]	US Defense Advanced Research Projects Agency(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the US Defense Advanced Research Projects Agency under grants HR0011-08-C-0135-S8 and HR0011-10-C-0112. The publication of this paper was supported by the National Natural Science Foundation of China under grant 61202325. Yongmian Zhang and Yifan Zhang contributed equally to this work and should be considered co-first authors.	Albanese M, 2008, IEEE T MULTIMEDIA, V10, P1429, DOI 10.1109/TMM.2008.2010417; Aliferis C.F, 1996, P 12 ANN C UNC ART I; Allen J. E., 1994, Journal of Logic and Computation, V4, P531, DOI 10.1093/logcom/4.5.531; ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; Brand M., 1997, P IEEE C COMP VIS PA; Brendel W., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3329, DOI 10.1109/CVPR.2011.5995491; Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPRW.2009.5206800, 10.1109/CVPR.2009.5206800]; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; de Campos CP, 2011, J MACH LEARN RES, V12, P663; Duong T., 2005, P IEEE C COMP VIS PA; Ferguson J., 1980, P S APPL HIDD MARK M; Fernandez-Leal A, 2009, EXPERT SYST APPL, V36, P27, DOI 10.1016/j.eswa.2007.09.044; Fusier F, 2007, MACH VISION APPL, V18, P167, DOI 10.1007/s00138-006-0054-y; Gong S., 2003, P IEEE INT C COMP VI; GUENOCHE A, 1991, J CLASSIF, V8, P5, DOI 10.1007/BF02616245; Gupta A., 2009, P IEEE C COMP VIS PA; Hakeem A, 2004, P 19 NAT C ART INT; Hakeem A, 2007, ARTIF INTELL, V171, P586, DOI 10.1016/j.artint.2007.04.002; Hamid R., 2003, P IEEE C COMP VIS PA; Hamid R, 2007, P IEEE INT C COMP VI; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005; Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81; Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; JOO S, 2005, P IEEE INT WORKSH PE; Jurie F, 2002, P BRIT MACH VIS C; Kuettel D., 2010, P IEEE C COMP VIS PA; Milch B, 2007, LECT NOTES ARTIF INT, V4455, P10; Milch B, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1352; MITCHELL C, 1995, IEEE T SPEECH AUDI P, V3, P213, DOI 10.1109/89.388149; Morariu V. I., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3289, DOI 10.1109/CVPR.2011.5995386; Natarajan P, 2007, P IEEE WORKSH MOT VI; NEVATIA R, 2003, P 2 IEEE WORKSH EV M; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PERERA AGA, 2006, P IEEE C COMP VIS PA; PINHANEZ CS, 1999, THESIS MIT; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Ryoo M., 2009, P IEEE INT C COMP VI; Ryoo MS, 2009, INT J COMPUT VISION, V82, P1, DOI 10.1007/s11263-008-0181-1; Sanghai S, 2005, J ARTIF INTELL RES, V24, P759, DOI 10.1613/jair.1625; Santos E, 1999, INT J APPROX REASON, V20, P263, DOI 10.1016/S0888-613X(99)00009-2; Santos E, 1991, P 7 C UNC AI, P339; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shi Y, 2006, P IEEE C COMP VIS PA, P1631; Siskind JM, 2001, J ARTIF INTELL RES, V15, P31, DOI 10.1613/jair.790; Smith K, 2005, P IEEE C COMP VIS PA; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6; Young J.D, 1996, P 7 MIDW AI COGN SCI	54	50	57	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2468	2483		10.1109/TPAMI.2013.33	http://dx.doi.org/10.1109/TPAMI.2013.33			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969390				2022-12-18	WOS:000323175200012
J	Mudenagudi, U; Banerjee, S; Kalra, PK				Mudenagudi, Uma; Banerjee, Subhashis; Kalra, Prem Kumar			Space-Time Super-Resolution Using Graph-Cut Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Super-resolution; Markov random field (MRF); maximum a posteriori (MAP); graph-cut; space-time; nonlinear; minimization	LIMITS	We address the problem of super-resolution-obtaining high-resolution images and videos from multiple low-resolution inputs. The increased resolution can be in spatial or temporal dimensions, or even in both. We present a unified framework which uses a generative model of the imaging process and can address spatial super-resolution, space-time super-resolution, image deconvolution, single-image expansion, removal of noise, and image restoration. We model a high-resolution image or video as a Markov random field and use maximum a posteriori estimate as the final solution using graph-cut optimization technique. We derive insights into what super-resolution magnification factors are possible and the conditions necessary for super-resolution. We demonstrate spatial super-resolution reconstruction results with magnifications higher than predicted limits of magnification. We also formulate a scheme for selective super-resolution reconstruction of videos to obtain simultaneous increase of resolutions in both spatial and temporal directions. We show that it is possible to achieve space-time magnification factors beyond what has been suggested in the literature by selectively applying super-resolution constraints. We present results on both synthetic and real input sequences.	[Mudenagudi, Uma] BVB Coll Engn & Technol, Dept Elect & Commun, Vijayanagar 580031, Hubli, India; [Banerjee, Subhashis; Kalra, Prem Kumar] Indian Inst Technol, Dept Comp Sci & Engn, New Delhi 110016, India	KLE Technological University; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Delhi	Mudenagudi, U (corresponding author), BVB Coll Engn & Technol, Dept Elect & Commun, Vijayanagar 580031, Hubli, India.	uma@bvb.edu; suban@cse.iitd.ernet.in; pkalra@cse.iitd.ernet.in	Mudenagudi, Uma/P-8930-2019; UNIVERSITY, KLE TECHNOLOGICAL UNIVERSITY KLE TECHNOLOGICAL/AAM-4008-2021	Mudenagudi, Uma/0000-0003-1111-7522; 	Naval Research Board (NRB), India [DNRD/105/4003/NRB/173]; IIT Delhi; IIIT Hyderabad	Naval Research Board (NRB), India; IIT Delhi; IIIT Hyderabad	This project is partially sanctioned by the Naval Research Board (NRB), India, project saction no.: DNRD/105/4003/NRB/173, a collaborative project with IIT Delhi and IIIT Hyderabad.	Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; BAKER S, 2000, P IEEE C COMP VIS PA; BERGEN JR, 1992, EUR C COMP VIS, P237; BORMAN S, 2004, P SOC PHOTO-OPT INS, P234; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Capel D, 2003, IEEE SIGNAL PROC MAG, V20, P75, DOI 10.1109/MSP.2003.1203211; Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148; CHAUDHURI S, 2004, MOTION FREE SUPER RE; EBRAHIMI M, 2009, P 7 INT C EN MIN MET, P112; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271; Joshi M. V., 2003, P 5 INT C ADV PATT R, P179; KELLER SH, 2007, P 1 INT C SCA SPA VA, P801; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081; Mitzel D, 2009, LECT NOTES COMPUT SC, V5748, P432, DOI 10.1007/978-3-642-03798-6_44; Mudenagudi U, 2006, LECT NOTES COMPUT SC, V3852, P385; Mudenagudi U, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P320, DOI 10.1109/ICVGIP.2008.61; PICKUP LC, 2003, P NEURAL INFORM PROC; RAJ A, 2005, P IEEE INT C COMP VI; RAJ A, 2006, P IEEE C COMP VIS PA; Rajan D, 2003, IEEE T PATTERN ANAL, V25, P1102, DOI 10.1109/TPAMI.2003.1227986; Shechtman E, 2005, IEEE T PATTERN ANAL, V27, P531, DOI 10.1109/TPAMI.2005.85; SHECHTMAN E, 2002, P 7 EUR C COMP VIS, V1, P753	27	50	58	3	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					995	1008		10.1109/TPAMI.2010.167	http://dx.doi.org/10.1109/TPAMI.2010.167			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	20733227				2022-12-18	WOS:000288677800010
J	Quan, XJ; Liu, WY; Qiu, BT				Quan, Xiaojun; Liu, Wenyin; Qiu, Bite			Term Weighting Schemes for Question Categorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Question answering systems; term-weighting; question categorization; text categorization		Term weighting has proven to be an effective way to improve the performance of text categorization. Very recently, with the development of user-interactive question answering or community question answering, there has emerged a need to accurately categorize questions into predefined categories. However, as a question is usually a piece of short text, can the existing term-weighting methods perform consistently in question categorization as they do in text categorization? The answer is not clear, since to the best of our knowledge, we have not seen any work related to this problem despite of its significance. In this study, we investigate the popular unsupervised and supervised term-weighting methods for question categorization. At the same time, we propose three new supervised term-weighting methods, namely, qf*icf, iqf* qf *icf, and vrf. Comparisons of them with existing unsupervised and supervised term-weighting methods are made through a series of experiments on question collections of Yahoo! Answers. The experimental results show that iqf* qf*icf achieves the best performance among all term-weighting methods, while qf*icf and vrf are also competitive for question categorization. Meanwhile, tf*OR is proven to be the most significant one among existing methods. In addition, iqf*qf* icf and vrf are also effective for long document categorization.	[Quan, Xiaojun; Liu, Wenyin; Qiu, Bite] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	City University of Hong Kong	Quan, XJ (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.	xiaoquan@student.cityu.edu.hk; csliuwy@cityu.edu.hk; biteqiu@student.cityu.edu.hk	LIU, Wenyin/C-1345-2012	Quan, Xiaojun/0000-0002-8385-1083	City University of Hong Kong [7002560]; Research Grants Council of the Hong Kong Special Administrative Region, China [CityU 117907]	City University of Hong Kong(City University of Hong Kong); Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council)	The work described in this paper was fully supported by a grant from City University of Hong Kong (Project No. 7002560) and a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. CityU 117907). The authors thank Yandong Liu, Jiang Bian, and Eugene Agichtein for providing the question collection.	Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; DEBOLE F, 2003, P SAC 03 18 ACM S AP, P784, DOI DOI 10.1145/952532.952688; Deng ZH, 2004, LECT NOTES COMPUT SC, V3007, P588; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; GALAVOTTI L, 2000, P 4 EUR C RES ADV TE, P59; Information Office of the State Council, 2003, P 26 IN FORMATION SY; Joachims T., 1998, P EUROPEAN C MACHINE, P137, DOI [10.1007/bfb0026683, 10.1007/BFb0026683]; Kohavi R., 1995, INT JOINT C ART INT, V14, P1137, DOI DOI 10.1067/MOD.2000.109031; Lan M, 2005, IEEE IJCNN, P546; Lan M., 2006, PROC AAAI C ARTIF IN, P763; Lan M, 2009, IEEE T PATTERN ANAL, V31, P721, DOI 10.1109/TPAMI.2008.110; Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS, P556, DOI 10.1109/ICPST.2002.1053604; Liu Y., 2008, P 31 ANN INT ACM SIG, P483, DOI DOI 10.1145/1390334.1390417; MAZZOLA S, 1990, PATTERN RECOGN, V23, P179, DOI 10.1016/0031-3203(90)90058-S; MLADENIC D, 1998, P WORKING NOTES LEAR; Porter MF, 2006, PROGRAM-ELECTRON LIB, V40, P211, DOI 10.1108/eb046814; PRESCOTT L, 2006, YAHOO ANSWERS CAPTUR; Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582; SALON G, 1973, J DOC, V29, P351; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Salton G., 1989, AUTOMATIC TEXT PROCE; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Soucy P, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1130; WENYIN L, 2009, WORLD WIDE WEB, V12, P107, DOI DOI 10.1007/S11280-008-0051-3.; WU H, 1981, P 4 ANN INT ACM SIGI, P30; Yang Yiming, 1997, P 14 INT C MACHINE L, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42, DOI 10.1145/312624.312647; Zobel J., 1998, SIGIR Forum, V32, P18, DOI 10.1145/281250.281256; 2009, BAIDU KNOWS	31	50	55	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					1009	1021		10.1109/TPAMI.2010.154	http://dx.doi.org/10.1109/TPAMI.2010.154			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	20733219				2022-12-18	WOS:000288677800011
J	He, Q; Chang, KY; Lim, EP; Banerjee, A				He, Qi; Chang, Kuiyu; Lim, Ee-Peng; Banerjee, Arindam			Keep It Simple with Time: A Reexamination of Probabilistic Topic Detection Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Topic detection; probabilistic model; time-aware; bursty feature; online; DPM; TFIDF		Topic detection (TD) is a fundamental research issue in the Topic Detection and Tracking (TDT) community with practical implications; TD helps analysts to separate the wheat from the chaff among the thousands of incoming news streams. In this paper, we propose a simple and effective topic detection model called the temporal Discriminative Probabilistic Model (DPM), which is shown to be theoretically equivalent to the classic vector space model with feature selection and temporally discriminative weights. We compare DPM to its various probabilistic cousins, ranging from mixture models like von-Mises Fisher (vMF) to mixed membership models like Latent Dirichlet Allocation (LDA). Benchmark results on the TDT3 data set show that sophisticated models, such as vMF and LDA, do not necessarily lead to better results; in the case of LDA, notably worst performance was obtained under variational inference, which is likely due to the significantly large number of LDA model parameters involved for document-level topic detection. On the contrary, using a relatively simple time-aware probabilistic model such as DPM suffices for both offline and online topic detection tasks, making DPM a theoretically elegant and effective model for practical topic detection.	[He, Qi] Penn State Univ, Coll Informat Sci & Technol, State Coll, PA 16802 USA; [Chang, Kuiyu] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Lim, Ee-Peng] Singapore Management Univ, Sch Informat Syst, Singapore 178902, Singapore; [Banerjee, Arindam] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Singapore Management University; University of Minnesota System; University of Minnesota Twin Cities	He, Q (corresponding author), Penn State Univ, Coll Informat Sci & Technol, 320 IST Bldg, State Coll, PA 16802 USA.	qhe@ist.psu.edu; kuiyu.chang@pmail.ntu.edu.sg; eplim@smu.edu.sg; banerjee@cs.umn.edu	CHANG, Kuiyu/A-3734-2011; LIM, Ee Peng/E-8562-2012	LIM, Ee Peng/0000-0003-0065-8665; He, Qi/0000-0001-5257-6843	US National Science Foundation (NSF) [IIS-0812183]; Div Of Information & Intelligent Systems [0812183] Funding Source: National Science Foundation	US National Science Foundation (NSF)(National Science Foundation (NSF)); Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	The authors thank the anonymous reviewers for their keen insight and valuable feedback. This research was supported in part by US National Science Foundation (NSF) Grant IIS-0812183.	Ahmed A., 2008, P 8 SIAM INT C DAT M; Allan J., 2005, P 38 ANN HAW INT C S; Allan J., 2002, TOPIC DETECTION TRAC; Allan J., 1998, P DARPA BROADC NEWS; Allan James, 2000, P 9 INT C INF KNOWL; Ariew R., 1976, OCKHAMS RAZOR HIST P; BANERJEE A, 2003, P ACM SIGKDD 03; Banerjee Arindam, 2007, P SIAM INT C DAT MIN; BASU S, 2004, P SIAM INT C DAT MIN; Blei D., 2006, P INT C MACH LEARN; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Brants T., 2003, P ACM SIGIR 03; DASGUPTA S, 1999, P IEEE S FDN COMP SC; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; ELKAN C, 2006, P INT C MACH LEARN; FUNG GPC, 2005, P INT C VER LARG DAT; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; HE Q, 2006, P 25 INT C CONC MOD; HE Q, 2007, P SIAM INT C DAT MIN; HE Q, 2009, P C INF KNOWL MAN; HE Q, 2007, P ACM SIGIR 07; HOFMANN T, 1999, P ACM SIGIR 99; Joachims T., 1997, P INT C MACH LEARN; Kleinberg J., 2002, P ACM SIGKDD 02; Kumaran G., 2004, P ACM SIGIR 04; Lacoste-Julien Simon, 2008, ADV NEURAL INFORM PR, V21; LEBANON G, 2003, P C UNC ART INT; LI W, 2007, P C UNC ART INT; Martin A., 1997, P EUR; McLachlan Geoffrey J., 2004, DISCRIMINANT ANAL ST, V544; Neal R. M, 1998, 9815 DEP STAT U TOR; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Stokes N., 2001, P ACM SIGIR 01; TEH Y, 2004, TR653 U CAL; Tsyrnbal  A., 2004, PROBLEM CONCEPT DRIF; WANG X, 2006, P ACM SIGKDD 06; YANG CC, 2006, P 15 INT C WORLD WID; Yang Y., 1998, P ACM SIGIR 98; Yang Y., 2002, P ACM SIGKDD 02; Zhang J., 2005, P NEUR INF PROC SYST; ZHU Y, 2003, P ACM SIGKDD 03; 2004, TDT ANNOTATION MANUA	44	50	55	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1795	1808		10.1109/TPAMI.2009.203	http://dx.doi.org/10.1109/TPAMI.2009.203			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20724757	Green Published			2022-12-18	WOS:000281000700006
J	Carter, KM; Raich, R; Finn, WG; Hero, AO				Carter, Kevin M.; Raich, Raviv; Finn, William G.; Hero, Alfred O., III			FINE: Fisher Information Nonparametric Embedding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Information geometry; statistical manifold; dimensionality reduction; multidimensional scaling	REDUCTION	We consider the problems of clustering, classification, and visualization of high-dimensional data when no straightforward euclidean representation exists. In this paper, we propose using the properties of information geometry and statistical manifolds in order to define similarities between data sets using the Fisher information distance. We will show that this metric can be approximated using entirely nonparametric methods, as the parameterization and geometry of the manifold is generally unknown. Furthermore, by using multidimensional scaling methods, we are able to reconstruct the statistical manifold in a low-dimensional euclidean space; enabling effective learning on the data. As a whole, we refer to our framework as Fisher Information Nonparametric Embedding (FINE) and illustrate its uses on practical problems, including a biomedical application and document classification.	[Carter, Kevin M.; Hero, Alfred O., III] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA; [Raich, Raviv] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA; [Finn, William G.] Univ Michigan, Dept Pathol, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan; Oregon State University; University of Michigan System; University of Michigan	Carter, KM (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, 1301 Beal Ave, Ann Arbor, MI 48109 USA.	kmcarter@umich.edu; raich@eecs.oregonstate.edu; wgfinn@umich.edu; hero@eecs.umich.edu		Hero, Alfred/0000-0002-2531-9670	US National Science Foundation [CCR-0325571]	US National Science Foundation(National Science Foundation (NSF))	The authors would like to thank the reviewers for their efforts toward improving this paper. This work is partially funded by US National Science Foundation, grant No. CCR-0325571.	Amari S., 2000, METHODS INFORM GEOME; Arandjelovic O, 2005, PROC CVPR IEEE, P581; Belkin M., 2002, ADV NEURAL INFORM PR, V14; Carter K. M., 2009, THESIS U MICHIGAN; Carter KM, 2009, IEEE J-STSP, V3, P148, DOI 10.1109/JSTSP.2008.2011112; CARTER KM, 2008, P IEEE INT C AC SPEE, P1861; Cox T.F., 1994, MULTIDIMENSIONAL SCA; Finn WG, 2009, CYTOM PART B-CLIN CY, V76B, P1, DOI 10.1002/cyto.b.20435; Huang SP, 2005, THIRD INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P63; KASS R., 1997, GEOMETRICAL FDN ASYM; Kim H, 2005, J MACH LEARN RES, V6, P37; Lafferty J, 2005, J MACH LEARN RES, V6, P129; Lee S., 2007, P IEEE C COMP VIS PA, V2007, P1, DOI DOI 10.1109/CVPR.2007.383138; RAICH R, 2006, P IEEE INT C AC SPEE, V5; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SALOJARVI J, 2003, P INT C ART NEUR NET, P161; Srivastava A., 2007, IEEE C COMP VIS PATT, P1; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TERRELL GR, 1990, J AM STAT ASSOC, V85, P470, DOI 10.2307/2289786; Zhou SK, 2006, IEEE T PATTERN ANAL, V28, P917, DOI 10.1109/TPAMI.2006.120	20	50	55	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					2093	U195		10.1109/TPAMI.2009.67	http://dx.doi.org/10.1109/TPAMI.2009.67			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	493VV	19762935	Green Submitted			2022-12-18	WOS:000269767600014
J	Terrades, OR; Valveny, E; Tabbone, S				Ramos Terrades, Oriol; Valveny, Ernest; Tabbone, Salvatore			Optimal Classifier Fusion in a Non-Bayesian Probabilistic Framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Classifier fusion; linear combination rules; random variable	COMBINING MULTIPLE CLASSIFIERS; IMAGE RETRIEVAL; RELEVANCE; CONFIDENCE; ALGORITHMS	The combination of the output of classifiers has been one of the strategies used to improve classification rates in general purpose classification systems. Some of the most common approaches can be explained using the Bayes' formula. In this paper, we tackle the problem of the combination of classifiers using a non-Bayesian probabilistic framework. This approach permits us to derive two linear combination rules that minimize misclassification rates under some constraints on the distribution of classifiers. In order to show the validity of this approach we have compared it with other popular combination rules from a theoretical viewpoint using a synthetic data set, and experimentally using two standard databases: the MNIST handwritten digit database and the GREC symbol database. Results on the synthetic data set show the validity of the theoretical approach. Indeed, results on real data show that the proposed methods outperform other common combination schemes.	[Ramos Terrades, Oriol; Valveny, Ernest] Univ Automous Barcelona, Comp Vis Ctr, Bellaterra 08193, Spain; [Ramos Terrades, Oriol; Valveny, Ernest] Univ Automous Barcelona, Dept Comp Sci, Bellaterra 08193, Spain; [Tabbone, Salvatore] Univ Nancy 2, F-54506 Vandoeuvre Les Nancy, France; [Tabbone, Salvatore] LORIA, F-54506 Vandoeuvre Les Nancy, France	Autonomous University of Barcelona; Centre de Visio per Computador (CVC); Autonomous University of Barcelona; Universite de Lorraine; Universite de Lorraine	Terrades, OR (corresponding author), Univ Automous Barcelona, Comp Vis Ctr, Edifici O,Campus UAB, Bellaterra 08193, Spain.	oriolrt@cvc.uab.cat; ernest@cvc.uab.cat; tabbone@loria.fr	Terrades, Oriol Ramos/L-4917-2014; Valveny, Ernest/C-3585-2009; Valveny, Ernest/GSN-8920-2022	Terrades, Oriol Ramos/0000-0002-3333-8812; Valveny, Ernest/0000-0002-0368-9697; 	Spanish research program Consolider Ingenio; MIPRCV [CSD2007-00018];  [TIN2006-15694-C02-02]	Spanish research program Consolider Ingenio; MIPRCV; 	This research has been partially supported by TIN2006-15694-C02-02, Spain and by the Spanish research program Consolider Ingenio 2010: MIPRCV (CSD2007-00018). The authors wish to thank the reviewers for their helpful comments which have improved the quality of this paper.	Alkoot FM, 1999, PATTERN RECOGN LETT, V20, P1361, DOI 10.1016/S0167-8655(99)00107-5; BOUTEMEDJET S, 2007, P ANN C ADV NEUR INF; Breiman L., 1994, 421 U CAL DEP STAT; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chen PH, 2005, APPL STOCH MODEL BUS, V21, P111, DOI 10.1002/asmb.537; Dietterich TG, 1994, J ARTIF INTELL RES, V2, P263; Escalera S, 2006, INT C PATT RECOG, P104; Freund Y, 1996, P 13 INT C MACH LEAR, P148, DOI DOI 10.5555/3091696.3091715; Friedman J., 1998, ADDITIVE LOGISTIC RE; Ho, 1992, THESIS STATE U NEW Y; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kherfi ML, 2003, J VIS COMMUN IMAGE R, V14, P428, DOI 10.1016/S1047-3203(03)00043-9; KIM WY, 1999, NEW REGION BASED SHA; Kittler J, 2000, LECT NOTES COMPUT SC, V1876, P45; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; Kuncheva LI, 2000, INT C PATT RECOG, P168, DOI 10.1109/ICPR.2000.906041; LIPPMANN RP, 1988, SIGARCH COMPUTER ARC, V16, P7; LLADOS J, 2002, P GRAPH REC ALG APPL, P105; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; Melnik O, 2004, IEEE T PATTERN ANAL, V26, P973, DOI 10.1109/TPAMI.2004.48; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Platt JC, 2000, ADV NEUR IN, P61; Pujol O, 2006, IEEE T PATTERN ANAL, V28, P1007, DOI 10.1109/TPAMI.2006.116; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Skurichina M, 2002, PATTERN ANAL APPL, V5, P121, DOI 10.1007/s100440200011; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Stejic Z, 2005, SIGNAL PROCESS, V85, P297, DOI 10.1016/j.sigpro.2004.10.003; Tabbone S, 2006, COMPUT VIS IMAGE UND, V102, P42, DOI 10.1016/j.cviu.2005.06.005; Tax DMJ, 2000, PATTERN RECOGN, V33, P1475, DOI 10.1016/S0031-3203(99)00138-7; Terrades OR, 2005, PROC INT CONF DOC, P700, DOI 10.1109/ICDAR.2005.153; Torralba A., 2004, P C COMP VIS PATT RE; Tumer K., 1996, Connection Science, V8, P385, DOI 10.1080/095400996116839; Tumer K, 1996, PATTERN RECOGN, V29, P341, DOI 10.1016/0031-3203(95)00085-2; VALVENY E, 2004, P INT WORKSH GRAPH R, P368; van Breukelen M, 1998, KYBERNETIKA, V34, P381; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008	41	50	53	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1630	1644		10.1109/TPAMI.2008.224	http://dx.doi.org/10.1109/TPAMI.2008.224			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD	19574623				2022-12-18	WOS:000267369800007
J	Franco, JS; Boyer, E				Franco, Jean-Sebastien; Boyer, Edmond			Efficient Polyhedral Modeling from Silhouettes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Modeling from multiple views; modeling from silhouettes; shape from silhouettes; 3D reconstruction; visual hull	VISUAL HULLS; SHAPE; OBJECTS; RECONSTRUCTION; CONSTRUCTION; OPERATIONS; ALGORITHM; CONTOURS; VIEWS	Modeling from silhouettes is a popular and useful topic in computer vision. Many methods exist to compute the surface of the visual hull from silhouettes, but few address the problem of ensuring good topological properties of the surface, such as manifoldness. This paper provides an efficient algorithm to compute such a surface in the form of a polyhedral mesh. It relies on a small number of geometric operations to compute a visual hull polyhedron in a single pass. Such simplicity enables the algorithm to combine the advantages of being fast, producing pixel-exact surfaces, and repeatably yield manifold and watertight polyhedra in general experimental conditions with real data, as verified with all data sets tested. The algorithm is fully described, its complexity analyzed, and the modeling results given.	[Franco, Jean-Sebastien] LaBRI CNRS INRIA, Sud Ouest Equipe IPARLA, F-33405 Talence, France; [Boyer, Edmond] INRIA Rhone Alpes, Lab Jean Kuntzmann, Equipe Percept, F-38334 Saint Ismier, France	UDICE-French Research Universities; Universite de Bordeaux; UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA); Centre National de la Recherche Scientifique (CNRS); Inria	Franco, JS (corresponding author), LaBRI CNRS INRIA, Sud Ouest Equipe IPARLA, 351 Cours Liberat, F-33405 Talence, France.	jean-sebastien.franco@labri.fr; Edmond.Boyer@inrialpes.fr						BAUMGART BG, 1974, STANCS74463 STANF U; Boyer E, 1997, INT J COMPUT VISION, V22, P219, DOI 10.1023/A:1007978616082; Boyer E, 2003, PROC CVPR IEEE, P695; Brand M, 2004, PROC CVPR IEEE, P30; CHEUNG G, 2003, P IEEE C COMP VIS PA; Cheung GKM, 2000, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2000.854944; CHIEN CH, 1986, COMPUT VISION GRAPH, V36, P100, DOI 10.1016/S0734-189X(86)80031-7; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; CROSS G, 1998, P 6 INT C COMP VIS; DEBLEDRENNESSON I, 1995, INT J PATTERN RECOGN, V9, P635, DOI 10.1142/S0218001495000249; Dyer Charles R, 2001, FDN IMAGE UNDERSTAND, P469; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Fortune S., 1995, Proceedings. Third Symposium on Solid Modeling and Applications, P225, DOI 10.1145/218013.218065; FURUKAWA Y, 2006, P EUR C COMP VIS; Giblin P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P136; HACHENBERGER P, 1963, P ACM S SOL PHYS MOD, P163; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hoffmann C.M., 1989, GEOMETRIC SOLID MODE; HOFFMANN CM, 1989, IEEE COMPUT GRAPH, V9, P50, DOI 10.1109/38.41469; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; Isidoro J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1335; KANG K, 2001, P 8 INT C COMP VIS; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LAVEAU S, 1996, P 4 EUR C COMP VIS; Lazebnik S, 2001, PROC CVPR IEEE, P156; LAZEBNIK S, 2002, THESIS U ILLINOIS UR; Lazebnik S, 2007, INT J COMPUT VISION, V74, P137, DOI 10.1007/s11263-006-0008-x; Li M, 2004, PROC GRAPH INTERF, P41; Li M, 2003, PROC GRAPH INTERF, P65; Liang C, 2005, PROC CVPR IEEE, P878; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; Matusik W., 2002, EFFICIENT VISUAL HUL; MATUSIK W, 2001, P EUR WORKSH REND; NIEM W, 1994, P EUR WORKSH COMB RE; POTMESIL M, 1987, COMPUT VISION GRAPH, V40, P1, DOI 10.1016/0734-189X(87)90053-3; REQUICHA AAG, 1985, P IEEE, V73, P30, DOI 10.1109/PROC.1985.13108; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; SINHA S, 2005, P 10 INT C COMP VIS; SLABAUGH GG, 2001, P INT WORKSH VOL GRA; SRIVASTAVA SK, 1990, COMPUT VISION GRAPH, V49, P68, DOI 10.1016/0734-189X(90)90163-P; Sullivan S, 1998, IEEE T PATTERN ANAL, V20, P1091, DOI 10.1109/34.722621; SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787	46	50	61	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2009	31	3					414	427		10.1109/TPAMI.2008.104	http://dx.doi.org/10.1109/TPAMI.2008.104			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	394VO	19147872	Green Submitted			2022-12-18	WOS:000262480200003
J	Huang, XL; Metaxas, DN				Huang, Xiaolei; Metaxas, Dimitris N.			Metamorphs: Deformable shape and appearance models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; deformable models; shape; appearance; region; edge; boundary; implicit shape representation; free-form deformations; nonparametric intensity statistics; distance transform; level set	ACTIVE CONTOURS; MEDICAL IMAGES; SEGMENTATION; TRACKING; SNAKES	This paper presents a new deformable modeling strategy that is aimed at integrating shape and appearance in a unified space. If we think of traditional deformable models as "active contours" or "evolving curve fronts," the new deformable shape and appearance models that we propose are " deforming disks or volumes." Each model not only has boundary shape but also interior appearance. The model shape is implicitly embedded in a higher dimensional space of distance transforms and is thus represented by a distance map "image." This way, both the shape and the appearance of the model are defined in the pixel space. A common deformation scheme, that is, the Free-Form Deformations (FFDs), parameterizes warping deformations of the volumetric space in which the model is embedded, hence simultaneously deforming both model boundary and interior. When applied to segmentation, a Metamorphs model can be initialized by covering a seed region far from the object boundary, and then the model efficiently evolves and converges to an optimal solution. The model dynamics are derived in a unified variational framework that consists of edge-based and region-based energy terms, both of which are differentiable with respect to the common set of FFD parameters. As the model deforms, its interior appearance statistics are adaptively learned and, then, toward the next-step deformation, the model examines not only edge information but also its exterior region statistics to ensure that it only expands to new territory with consistent appearance statistics. The Metamorphs formulation also allows natural merging and competition of multiple models. We demonstrate the robustness of Metamorphs by using both natural and medical images that have high noise levels, intensity inhomogeneity, and complex texture.	[Huang, Xiaolei] Lehigh Univ, Comp Sci & Engn Dept, Bethlehem, PA 18015 USA; [Metaxas, Dimitris N.] Rutgers State Univ, Div Comp & Informat Sci, Piscataway, NJ 08854 USA	Lehigh University; Rutgers State University New Brunswick	Huang, XL (corresponding author), Lehigh Univ, Comp Sci & Engn Dept, 19 Mem Dr W, Bethlehem, PA 18015 USA.	huang@cse.lehigh.edu; dnm@cs.rutgers.edu		Huang, Sharon Xiaolei/0000-0003-2338-6535				Akgul YS, 2003, IEEE T PATTERN ANAL, V25, P174, DOI 10.1109/TPAMI.2003.1177150; Amini AA, 2001, IEEE T MED IMAGING, V20, P94, DOI 10.1109/42.913176; Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928; Berthod M, 1996, IMAGE VISION COMPUT, V14, P285, DOI 10.1016/0262-8856(95)01072-6; CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871; Chakraborty A, 1999, IEEE T PATTERN ANAL, V21, P12, DOI 10.1109/34.745730; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Duda R.O., 1973, J ROYAL STAT SOC SER; Elgammal A, 2003, IEEE T PATTERN ANAL, V25, P1499, DOI 10.1109/TPAMI.2003.1240123; Faloutsos P, 1997, IEEE T VIS COMPUT GR, V3, P201, DOI 10.1109/2945.620488; Govindaraju NK, 2005, ACM T GRAPHIC, V24, P991, DOI 10.1145/1073204.1073301; Haralick RM., 1992, COMPUTER ROBOT VISIO; Harwood D., 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48; Huang SL, 2004, J COLD REG ENG, V18, P2, DOI 10.1061/(ASCE)0887-381X(2004)18:1(2); HUANG X, 2005, P 4 INT WORKSH EN MI, P119; Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171; Huang XL, 2004, LECT NOTES COMPUT SC, V3216, P60; Jehan-Besson S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P408; Jones T., 1997, P INF PROC MED IM, P113; KARANTZALOS K, 2005, P 4 IEEE WORKSH VAR; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; MAKRUTZKI PATRIC, 2000, VERDECKTE ERMITTLUNG, P256; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9; Metaxas D, 1996, PHYS BASED DEFORMABL; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; PARAGIOS NK, 2000, THESIS U NICE SOPHIA; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sonka M., 2014, IMAGE PROCESSING ANA; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; WOLF L, 2006, P 9 EUR C COMP VIS, P481, DOI DOI 10.1007/11744047_37; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; XU HXC, 2003, IEEE T PATTERN ANAL, V25, P755; Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665; Yezzi A.  Jr., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P898, DOI 10.1109/ICCV.1999.790317; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	50	50	50	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1444	1459		10.1109/TPAMI.2007.70795	http://dx.doi.org/10.1109/TPAMI.2007.70795			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566497				2022-12-18	WOS:000256679700010
J	Vidal, E; Thollard, F; de la Higuera, C; Casacuberta, F; Carrasco, RC				Vidal, E; Thollard, F; de la Higuera, C; Casacuberta, F; Carrasco, RC			Probabilistic finite-state machines - Part II	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						automata; classes defined by grammars or automata; machine learning; language acquisition; language models; language parsing and understanding; machine translation; speech recognition and synthesis; structural pattern recognition; syntactic pattern recognition	CONTEXT-FREE GRAMMARS; EVEN LINEAR LANGUAGES; GRAMMATICAL INFERENCE; STATISTICAL-ESTIMATION; TRANSDUCERS; TRANSLATION; IDENTIFICATION; COMPLEXITY; MODELS	Probabilistic finite- state machines are used today in a variety of areas in pattern recognition or in fields to which pattern recognition is linked. In Part I of this paper, we surveyed these objects and studied their properties. In this Part II, we study the relations between probabilistic finite- state automata and other well- known devices that generate strings like hidden Markov models and n- grams and provide theorems, algorithms, and properties that represent a current state of the art of these objects.	Univ Politecn Valencia, Dept Sistemas Informat & Computac, E-46071 Valencia, Spain; Univ Politecn Valencia, Inst Informat Technol, E-46071 Valencia, Spain; EURISE, Fac Sci & Tech, FR-42023 St Etienne, France; Univ Alicante, Dept Lenguajes & Sistemas Informat, E-03071 Alicante, Spain	Universitat Politecnica de Valencia; Universitat Politecnica de Valencia; Universitat d'Alacant	Vidal, E (corresponding author), Univ Politecn Valencia, Dept Sistemas Informat & Computac, Camino Vera S-N, E-46071 Valencia, Spain.	evidal@iti.upv.es; Franck.Thollard@univ-st-etienne.fr; Colin.Delahiguera@univ-st-etienne.fr; fcn@iti.upv.es; carrasco@dlsi.ua.es	; Casacuberta, Francisco/T-3667-2017	, Colin/0000-0002-1703-9572; Casacuberta, Francisco/0000-0002-8497-5598				Abe H, 2001, ARTIF CELL BLOOD SUB, V29, P275, DOI 10.1081/BIO-100104230; ABE N, 1992, MACH LEARN, V9, P205, DOI 10.1007/BF00992677; ABE N, 1998, P 3 WORKSH COMP LEAR, P52; ALSHAWI H, 2000, COMPUTATIONAL LINGUI, V26; ALSHAWI H, 2000, MACHINE TRANSLATION; Amengual JC, 2001, MACH LEARN, V44, P143, DOI 10.1023/A:1010832230794; Angluin D, 1988, YALEUDCSRR614; [Anonymous], 1998, STAT METHODS SPEECH; [Anonymous], [No title captured]; BALASUBRAMANIAN V, 1993, AITR1370 MASS I TECH; Bangalore S., 2000, P WORKSH EMB MACH TR, P52; BANGALORE S, 2001, P N AM CHAPTER ASS C; Baum LE, 1972, INEQUALITIES, V3, P1; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Bengio Y, 2001, IEEE T NEURAL NETWOR, V12, P113, DOI 10.1109/72.896800; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Bunke H, 2001, HIDDEN MARKOV MODELS, V45; CARRASCO R, 1994, P 2 INT C GRAMM INF, P139; Carrasco RC, 1999, RAIRO-INF THEOR APPL, V33, P1, DOI 10.1051/ita:1999102; Carrasco RC, 2001, MACH LEARN, V44, P185, DOI 10.1023/A:1010836331703; CASACUBERTA F, 1995, PATTERN RECOGN LETT, V16, P565, DOI 10.1016/0167-8655(95)80002-B; Casacuberta F, 2004, COMPUT LINGUIST, V30, P205, DOI 10.1162/089120104323093294; Casacuberta F, 1996, INT J PATTERN RECOGN, V10, P183, DOI 10.1142/S0218001496000153; CASACUBERTA F, 1990, IEEE T PATTERN ANAL, V12, P691, DOI 10.1109/34.56212; CASACUBERTA F, 2004, IN PRES PATTERN RECO; Casacuberta F., 2002, P WORKSH SPEECH TO S, P39; CASACUBERTA F, 2003, COMPUTER SPEECH LANG; CASACUBERTA F, 2004, P 5 INT C GRAMM INF, P15; CASACUBERTA F, 2000, P 5 INT C GRAMM INF, P1; CASACUBERTA F, 1996, P 3 INT C GRAMM INF, P282; CASACUBERTA F, 2001, P WORKSH AUT SPEECH; CASACUBERTA F, 1995, P 6 SPAN S PATT REC, P201; CHAUDHURI R, 1986, J ACM, V33, P702, DOI 10.1145/6490.214099; Chen S. F., 1996, P 34 ANN M ASS COMP, V34, P310, DOI DOI 10.3115/981863.981904; Clark A, 2004, J MACH LEARN RES, V5, P473; DELAHIGUERA C, 2000, P 5 INT C GRAMM INF, P15; DENIS F, 1997, ALGORITHMIC LEARNING; DENIS F, 1993, P 13 S THEOR ASP COM, P231; DUPONT P, 1998, P 4 INT C GRAMM INF, P232; DUPONT P, 2000, P 5 INT C GRAMM INF, P51; DUPONT P, 2004, PATTERN RECOGNITION; Eilenberg S., 1974, AUTOMATA LANGUAGES M; Eisner Jason, 2002, P 40 ANN M ASS COMP; Fred ALN, 2000, LECT NOTES ARTIF INT, V1891, P103; GARCIA P, 1987, IEEE T PATTERN ANAL, V9, P841, DOI 10.1109/TPAMI.1987.4767991; GARCIA P, 1990, IEEE T PATTERN ANAL, V12, P920, DOI 10.1109/34.57687; GOLD EM, 1978, INFORM CONTROL, V37, P302, DOI 10.1016/S0019-9958(78)90562-4; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Goodman J. T., 2001, BIT PROGR LANGUAGE M; HORNING JJ, 1972, INFORMATION PROCESSI, V71, P519; KAMMEYER T, 1996, FDN GENETIC ALGORITH, V4; Kapur S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P303, DOI 10.1145/130385.130419; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; Kearns M., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, P433, DOI 10.1145/73007.73049; Kearns M., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, P273, DOI 10.1145/195058.195155; KERMORVANT C, 2002, P INT C GRAMM INF, V2484; KERMORVANT C, 2002, P 6 INT C GRAMM INF, P149; KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394; Kneser Reinhard, 1993, P EUR C SPEECH COMM, P973; Knight K, 1998, LECT NOTES ARTIF INT, V1529, P421; Koshiba T., 2000, Acta Cybernetica, V14, P469; Koshiba T, 1997, THEOR COMPUT SCI, V185, P63, DOI 10.1016/S0304-3975(97)00016-9; Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X; Llobet R, 2003, LECT NOTES COMPUT SC, V2652, P411; Llorens D, 2002, INT J PATTERN RECOGN, V16, P275, DOI 10.1142/S0218001402001666; LLORENS D, 2000, THESIS U POLITECNICA; MAKINEN E, 1999, A19993 U TAMP; MARYANSKI FJ, 1979, INT J COMPUT INF SCI, V8, P89, DOI 10.1007/BF00989665; McAllester D. A., 2000, COLT, P1; McLachlan, 1997, EM ALGORITHM EXTENSI; McNaughton R., 1974, Mathematical Systems Theory, V8, P60, DOI 10.1007/BF01761708; Mohri M, 1997, COMPUT LINGUIST, V23, P269; Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184; Mohri M, 2000, THEOR COMPUT SCI, V231, P17, DOI 10.1016/S0304-3975(99)00014-6; Molina A, 2002, J MACH LEARN RES, V2, P595, DOI 10.1162/153244302320884551; NEDERHOFF MJ, 2000, COMPUTATIONAL LINGUI, V26; Ney H, 1997, TEXT SPEECH LANG TEC, V2, P174; ONCINA J, 1993, IEEE T PATTERN ANAL, V15, P448, DOI 10.1109/34.211465; Orlitsky A, 2003, ANN IEEE SYMP FOUND, P179, DOI 10.1109/SFCS.2003.1238192; PAREKH R, 1997, P WORKSH AUT IND GRA; Pico D, 2001, MACH LEARN, V44, P121, DOI 10.1023/A:1010880113956; PICO D, 2000, P JOINT INT ASS PATT, P417; Picone J., 1990, IEEE ASSP Magazine, V7, P26, DOI 10.1109/53.54527; PITT L, 1993, J ACM, V40, P95, DOI 10.1145/138027.138042; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ron D., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, P31, DOI 10.1145/225298.225302; SAKAKIBARA Y, 1990, THEOR COMPUT SCI, V76, P223, DOI 10.1016/0304-3975(90)90017-C; SAKAKIBARA Y, 1994, NUCLEIC ACIDS RES, V22, P5112, DOI 10.1093/nar/22.23.5112; SANCHEZ J, 1996, P 6 INT WORKSH ADV S, P50; Sanchez JA, 1997, IEEE T PATTERN ANAL, V19, P1052, DOI 10.1109/34.615455; Stolcke Andreas, 1994, P 2 INT C GRAMM INF, P106; TAKADA Y, 1988, INFORM PROCESS LETT, V28, P193, DOI 10.1016/0020-0190(88)90208-6; THOLLARD F, 2001, ICML, P561; Thollard F., 2000, P 17 INT C MACH LEAR, P975; THOLLARD F, 2002, P 6 INT C GRAMM INF, P269; TOSELLI A, 2004, INT J PATTERN RECOGN; VALIANT LG, 1984, COMM ASS COMPUTING M, V127, P1134; Vidal E, 2005, IEEE T PATTERN ANAL, V27, P1013, DOI 10.1109/TPAMI.2005.147; VIDAL E, 1989, STRUCTURAL PATTERN A, P17; VIDAL E, 1996, P 3 INT C GRAMM INF, P179; VILAR JM, 2000, P 5 INT C GRAMM INF, P298; WETHERELL C, 1980, COMPUTING SURVEYS, V12; WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; Young-Lai M, 2000, MACH LEARN, V40, P111, DOI 10.1023/A:1007653929870; Zalcstein Y., 1972, J COMPUT SYST SCI, V6, P151	106	50	55	3	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1026	1039		10.1109/TPAMI.2005.148	http://dx.doi.org/10.1109/TPAMI.2005.148			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013751	Green Submitted			2022-12-18	WOS:000229024300003
J	Gong, ML; Yang, YH				Gong, ML; Yang, YH			Unambiguous stereo matching using reliability-based dynamic programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo; dynamic programming.		An efficient unambiguous stereo matching technique is presented in this paper. Our main contribution is to introduce a new reliability measure to dynamic programming approaches in general. For stereo vision application, the reliability of a proposed match on a scanline is defined as the cost difference between the globally best disparity assignment that includes the match and the globally best assignment that does not include the match. A reliability-based dynamic programming algorithm is derived accordingly, which can selectively assign disparities to pixels when the corresponding reliabilities exceed a given threshold. The experimental results show that the new approach can produce dense (>70 percent of the unoccluded pixels) and reliable (error rate <0.5 percent) matches efficiently (<0.2 sec on a 2GHz P4) for the four Middlebury stereo data sets.	Laurentian Univ, Dept Math & Comp Sci, Sudbury, ON P3E 2C6, Canada; Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada	Laurentian University; University of Alberta	Gong, ML (corresponding author), Laurentian Univ, Dept Math & Comp Sci, Ramsey Lake Rd, Sudbury, ON P3E 2C6, Canada.	gong@cs.laurentian.ca; yang@cs.ualberta.ca		Gong, Minglun/0000-0001-5820-5381				Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Felzenszwalb P. F., 2004, P IEEE C COMP VIS PA; GEIGER D, 1992, LECT NOTES COMPUT SC, V588, P425; Gong ML, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P610; Manduchi R., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P26, DOI 10.1109/ICIAP.1999.797566; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; SARA R, 2002, P 7 EUR C COMP VIS, V2, P900; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Veksler O, 2002, INT J COMPUT VISION, V47, P247, DOI 10.1023/A:1014506211316; VEKSLER O, 2003, P IEEE C COMP VIS PA	11	50	51	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					998	1003		10.1109/TPAMI.2005.120	http://dx.doi.org/10.1109/TPAMI.2005.120			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943431				2022-12-18	WOS:000228334700015
J	Singh, S				Singh, S			Multiresolution estimates of classification complexity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; classification complexity; feature space partitioning	PATTERN-CLASSIFICATION; PROBABILITY	In this paper, we study two measures of classification complexity based on feature space partitioning: "purity" and "neighborhood separability." The new measures of complexity are compared with probabilistic distance measures and a number of other nonparametric estimates of classification complexity on a total of 10 databases from the University of Calfornia, Irvine, (UCl) repository.	Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England	University of Exeter	Singh, S (corresponding author), Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England.	s.singh@ex.ac.uk						[Anonymous], MATH THEORY PROBABIL; Ben-Bassat M., 1982, HDB STATISTICS, P773, DOI DOI 10.1016/S0169-7161(82)02038-0; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; BOHM C, 2001, ACM SURVEYS; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CHERNOFF A, 1966, ANN I STAT MATH, V18, P179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver PA, 1982, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI; FIX E, 1949, 2149004 US AIR FORC; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GLICK N, 1973, ANN I STAT MATH, V25, P373, DOI 10.1007/BF02479383; Ho T.K., 2001, P 2 INT WORKSH MULT, P53; HO TK, 1994, INT C PATT RECOG, P178, DOI 10.1109/ICPR.1994.576899; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289, DOI 10.1109/34.990132; Ho TK, 2000, INT C PATT RECOG, P43, DOI 10.1109/ICPR.2000.906015; Ho TK, 1998, COMPUT VIS IMAGE UND, V70, P101, DOI 10.1006/cviu.1998.0624; Ho TK, 2000, LECT NOTES COMPUT SC, V1857, P97; HUNTER GM, 1978, THESIS PRINCETON U; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; Kishore JK, 2001, INFORM SCIENCES, V131, P65, DOI 10.1016/S0020-0255(00)00081-5; Kohn AF, 1996, PATTERN RECOGN, V29, P873, DOI 10.1016/0031-3203(95)00122-0; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MADDOX J, 1990, NATURE, V344, P705; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Perlin K., 1989, 16 ANN C COMP GRAPH, P253; PIERSON WE, UNPUB USE BOUNDARY M; PIERSON WE, 1998, THESIS OHIO STAT U; PIERSON WE, 1998, P SPIE C AUT TARG RE, V7; RAHMAN AFR, 1998, P INT C IM AN PROC, P893; RAUDYS S, 1980, IEEE T PATTERN ANAL, V2, P243; SANCHO JL, 1996, P IEE C MATHS SIGN P; SANCHO JL, 1996, SIGNAL PROCESSING CO; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; Singh S, 2003, PATTERN ANAL APPL, V6, P134, DOI 10.1007/s10044-002-0186-2; SINGH S, 2002, P 15 INT C PATTERN R, V2, P144; Sohn SY, 1999, IEEE T PATTERN ANAL, V21, P1137, DOI 10.1109/34.809107; Therrien C. W., 1989, DECISION ESTIMATION; TOUSSAINT GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; VAPNIK VN, 1998, STAT LEARNING THEOER; WALLACE CS, 1968, COMPUT J, V11, P185, DOI 10.1093/comjnl/11.2.185; WILLIAMS AC, 1997, P SPIE ITN S OPT ENG; XIE QB, 1993, IEEE T PATTERN ANAL, V15, P1326, DOI 10.1109/34.250849; YOUNG TY, 1986, HDB PATTERN RECOGNIT; [No title captured]	47	50	50	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1534	1539		10.1109/TPAMI.2003.1251146	http://dx.doi.org/10.1109/TPAMI.2003.1251146			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA					2022-12-18	WOS:000186765000003
J	Feng, XJ; Williams, CKI; Felderhof, SN				Feng, XJ; Williams, CKI; Felderhof, SN			Combining belief networks and neural networks for scene segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tree-structured belief network (TSBN); hierarchical modeling; Markov random field (MRF); neural network; scaled-likelihood method; conditional maximum-liklihood training; Gaussian mixture model; expectation-maximization (EM)	HIDDEN MARKOV-MODELS; IMAGE; RECOGNITION	We are concerned with the problem of image segmentation, in which each pixel is assigned to one of a predefined finite number of labels. In Bayesian image analysis, this requires fusing together local predictions for the class labels with a prior model of label images. Following the work of [5], we consider the use of tree-structured belief networks (TSBNs) as prior models. The parameters in the TSBN are trained using a maximum-likelihood objective function with the EM algorithm and the resulting model is evaluated by calculating how efficiently it codes label images. A number of authors have used Gaussian mixture models to connect the label field to the image data. In this paper, we compare this approach to the scaled-likelihood method of [42], [31], where local predictions of pixel classification from neural networks are fused with the TSBN prior. Our results show a higher performance is obtained with the neural networks. We evaluate the classification results obtained and emphasize not only the maximum a posteriori segmentation, but also the uncertainty, as evidenced e.g., by the pixelwise posterior marginal entropies. We also investigate the use of conditional maximum-likelihood training for the TSBN and find that this gives rise to improved classification performance over the ML-trained TSBN.	Natl Inst Biol Stand & Controls, Informat Lab, Potters Bar EN6 3QG, Herts, England; Univ Edinburgh, Div Informat, Edinburgh EH1 2QL, Midlothian, Scotland	National Institute for Biological Standards & Control; University of Edinburgh	Feng, XJ (corresponding author), Natl Inst Biol Stand & Controls, Informat Lab, Blanche Lane S Mimms, Potters Bar EN6 3QG, Herts, England.	xfeng@nibsc.ac.uk; c.k.i.williams@ed.ac.uk; stephenf@dai.ed.ac.uk						Ballard D.H., 1982, COMPUTER VISION; BASSEVILLE M, 1992, IEEE T INFORM THEORY, V38, P766, DOI 10.1109/18.119735; BESAG J, 1986, J R STAT SOC B, V48, P259; Bishop, 1995, NEURAL NETWORKS PATT; BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898; Cheng H, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P610, DOI 10.1109/ICIP.1998.723575; Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; De Bonet JS, 1998, ADV NEUR IN, V10, P773; FELDMAN JA, 1974, ARTIF INTELL, V5, P349, DOI 10.1016/0004-3702(74)90002-2; Fieguth PW, 1998, COMPUT VIS IMAGE UND, V70, P157, DOI 10.1006/cviu.1997.0630; FREY B, 1998, ADV NEURAL INFORMATI, V10; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GOPALAKRISHNAN PS, 1991, IEEE T INFORM THEORY, V37, P107, DOI 10.1109/18.61108; Jensen F.V., 1996, INTRO BAYESIAN NETWO; KITTLER J, 1994, ADV APPL STAT SER, V2, P61; Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696; KROGH A, 1994, INT C PATT RECOG, P140, DOI 10.1109/ICPR.1994.576891; Laferte JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777; LAFERTE JM, 1995, P 5 INT C COMP VIS; Lauritzen S.L., 1996, OXFORD STAT SCI SERI, V17, P298; LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640; LILLESAND TM, 1998, REMOTE SENSING IMAGE; LUCKE H, 1995, SPEECH COMMUN, V16, P89, DOI 10.1016/0167-6393(94)00046-D; LUETTGEN MR, 1995, IEEE T IMAGE PROCESS, V4, P194, DOI 10.1109/83.342185; LUETTGEN MR, 1994, IEEE T IMAGE PROCESS, V3, P41, DOI 10.1109/83.265979; Mardia KV, 1997, PATTERN RECOGN LETT, V18, P1197, DOI 10.1016/S0167-8655(97)00103-7; McCauley JD, 1995, IEEE T GEOSCI REMOTE, V33, P1313, DOI 10.1109/36.477185; MCKEOWN DM, 1985, IEEE T PATTERN ANAL, V7, P570, DOI 10.1109/TPAMI.1985.4767704; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; MORGAN N, 1995, P IEEE, V83, P742, DOI 10.1109/5.381844; Neal RM., 1996, BAYESIAN LEARNING NE, P29; Nickels KM, 1997, IMAGE VISION COMPUT, V15, P781, DOI 10.1016/S0262-8856(97)00021-8; OHTA Y, 1985, KNOWLEDGE BASED INTE; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Perez P, 2000, PATTERN RECOGN, V33, P573, DOI 10.1016/S0031-3203(99)00073-4; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Richard MD, 1991, NEURAL COMPUT, V3, P461, DOI 10.1162/neco.1991.3.4.461; RIIS SK, 1997, P INT C AC SPEECH SI; RONEN O, 1995, IEEE SIGNAL PROC LET, V2, P157, DOI 10.1109/97.404132; Saul L, 1998, NATO ADV SCI I D-BEH, V89, P541; SMYTH P, 1994, PATTERN RECOGN, V27, P149, DOI 10.1016/0031-3203(94)90024-8; STORKEY AJ, 2001, P 8 INT WORKSH ART I; WEINBERGER M, 1999, HPL98193R1; WEINBERGER M, 1996, P IEEE DAT COMPR C; WEISS Y, 2000, ADV NEURAL INFORMATI, V12; WELCH RM, 1989, J GEOPHYS RES-ATMOS, V94, P14767, DOI 10.1029/JD094iD12p14767; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; WILLIAMS CKI, 1999, ADV NEURAL INFORMATI, V11; WRIGHT WA, 1995, NEURAL NETWORKS, P165; WRIGHT WA, 1989, P 5 ALV VIS C READ U, P227	51	50	58	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2002	24	4					467	483		10.1109/34.993555	http://dx.doi.org/10.1109/34.993555			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	534FM					2022-12-18	WOS:000174574100004
J	Elder, JH; Goldberg, RM				Elder, JH; Goldberg, RM			Image editing in the contour domain	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image editing; edge detection; reconstruction; contour grouping; segmentation	OCCLUDING CONTOUR; SHAPE; BLUR	Image editing systems are essentially pixel-based. In this paper, we propose a novel method for image editing in which the primitive working unit is not a pixel but an edge. The feasibility of this proposal is suggested by recent work showing that a gray-scale image can be accurately represented by its edge map if a suitable edge model and scale selection method are employed [1]. In particular, an efficient algorithm has been reported to invert such an edge representation to yield a high-fidelity reconstruction of the original image [2], [3]. We have combined these algorithms together with an efficient method for contour grouping and an intuitive user interface to allow users to perform image editing operations (crop, paste, delete) directly in the contour domain. Experimental results suggest that this novel combination of vision algorithms may increase the efficiency of certain classes of image editing operations.	York Univ, Dept Psychol, N York, ON M3J 1P3, Canada; John P Robarts Res Inst, Imaging Res Labs, London, ON N6A 5K8, Canada	York University - Canada; Western University (University of Western Ontario)	Elder, JH (corresponding author), York Univ, Dept Psychol, 4700 Keele St, N York, ON M3J 1P3, Canada.	jelder@yorku.ca; goldberg@irus.rri.on.ca						ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; BONET JSD, 1998, IEEE C COMP VIS PATT, P641; ELDER J, 1996, P 4 EUR C COMP VIS, P57; Elder JH, 1998, PERCEPTION, V27, P11; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Elder JH, 1999, INT J COMPUT VISION, V34, P97, DOI 10.1023/A:1008183703117; Elder JH, 1998, PROC CVPR IEEE, P374, DOI 10.1109/CVPR.1998.698633; Elder JH, 1996, PROC CVPR IEEE, P27, DOI 10.1109/CVPR.1996.517049; Elder JH, 1998, VISION RES, V38, P143, DOI 10.1016/S0042-6989(97)00138-7; ELDER JH, 1996, P 4 EUR C COMP VIS, P399; FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Heeger D. J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P229, DOI 10.1145/218380.218446; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455; KASS M, 1987, P INT C COMP VIS, V87, P259; Klein AK, 1997, IEEE T MED IMAGING, V16, P468, DOI 10.1109/42.640737; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; Koffka K., 1935, PRINCIPLES GESTALT P; Mortensen E. N., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P452, DOI 10.1109/CVPR.1999.784720; Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480; MORTENSEN EN, 1995, P 22 ANN C COMP GRAP, P191, DOI DOI 10.1145/218380.218442; MUMFORD D, 1992, ALGEBRAIC GEOMETRY A; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; PETERHANS E, 1989, J NEUROSCI, V9, P1749; PRESS W, 1992, NUMERICAL RECIPES C, P871; SAUND E, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P597, DOI 10.1109/ICCV.1995.466884; ULLMAN S, 1976, BIOL CYBERN, V25, P1; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; Williams LR, 1997, INT J COMPUT VISION, V23, P93, DOI 10.1023/A:1007967925618	29	50	57	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2001	23	3					291	296		10.1109/34.910881	http://dx.doi.org/10.1109/34.910881			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407MW					2022-12-18	WOS:000167276200005
J	Zheng, JY; Murata, A				Zheng, JY; Murata, A			Acquiring a complete 3D model from specular motion under the illumination of circular-shaped light sources	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape from highlight; 3D model reconstruction; specular motion; epipolar-plane images; surface geometry; specular motion stereo	SEQUENCES	In this work, we recover 3D models of objects with specular surfaces. An object is rotated and its continuous images are taken. Circular-shaped light sources that generate conic rays are used to illuminate the rotating object in such a way that highlighted stripes can be observed on most of the specular surfaces. Surface shapes can be computed from the motions of highlights in the continuous images; either specular motion stereo or single specular trace mode can be used. When the lights are properly set, each point on the object can be highlighted during the rotation. The shape for each rotation plane is measured independently using its corresponding epipolar plane image. A 3D shape model is subsequently reconstructed by combining shapes at different rotation planes. Computing a shape is simple and requires only the motion of highlight on each rotation plane. The novelty of this paper is the complete modeling of a general type of specular objects that has not been accomplished before.	Kyushu Inst Technol, Fac Comp Sci & Syst Engn, Iizuka, Fukuoka 8208500, Japan	Kyushu Institute of Technology	Zheng, JY (corresponding author), Kyushu Inst Technol, Fac Comp Sci & Syst Engn, 680-4 Kawazu, Iizuka, Fukuoka 8208500, Japan.	zheng@mse.kyutech.ac.jp						Baker H. H., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P2, DOI 10.1109/CVPR.1988.196209; BELLVERCEBREROS C, 1992, OPT COMMUN, V92, P187, DOI 10.1016/0030-4018(92)90619-3; BLACK A, 1988, P 2 ICCV, P394; CLARK J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P981, DOI 10.1109/ICCV.1995.466827; Healey G., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P151; HORN PK, 1989, SHAPE SHADING; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; OREN M, 1995, T 5 ICCV, P740; Zheng J. Y., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P777, DOI 10.1109/CVPR.1992.223175; Zheng JY, 1997, IEEE T PATTERN ANAL, V19, P513, DOI 10.1109/34.589212; ZHENG JY, 1994, IEEE T PATTERN ANAL, V16, P163, DOI 10.1109/34.273734; ZHENG JY, 1994, P ICARCV 94, V1, P459; ZHENG JY, 1994, P 12 ICPR, V1, P331; ZHENG JY, 1996, P 13 ICPR, V1, P869; ZHENG JY, 1995, P 5 ICCV, P92; ZHENG JY, 1998, P 6 ICCV; ZISSERMAN A, 1989, IMAGE VISUAL COMPUTI, V7, P287	17	50	53	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2000	22	8					913	920						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	354GN					2022-12-18	WOS:000089321500015
J	Bradshaw, KJ; Reid, ID; Murray, DW				Bradshaw, KJ; Reid, ID; Murray, DW			The active recovery of 3D motion trajectories and their use in prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active vision; active camera platform; visual tracking; ground plane motion; interacting filters; prediction	HEAD EYE PLATFORM; TRACKING; SACCADE; PURSUIT	This paper describes the theory and real-time implementation using an active camera platform of a method of planar trajectory recovery, and of the use of those trajectories to facilitate prediction over delays in the visual feedback loop. Image-based position and velocity demands for tracking are generated by detecting and segmenting optical flow within a central region of the image, and a projective construct is used to map the camera platform's joint angles into a Euclidean coordinate system within a plane, typically the ground plane, in the scene. A set of extended Kalman filters with different dynamics is implemented to analyze the trajectories, and these compete to provide the best description of the motion within an interacting multiple model. Prediction from the optimum motion model is used within the visual feedback loop to overcome visual latency. It is demonstrated that prediction from the 3D planar description gives better tracking performance than prediction based on a filtered description of observer-based 2D motion trajectories.			Bradshaw, KJ (corresponding author), UNIV OXFORD, DEPT ENGN SCI, PARKS RD, OXFORD OX1 3PJ, ENGLAND.			Reid, Ian/0000-0001-7790-6423				ANDERSSON P, 1985, INT J CONTROL, V42, P1175, DOI 10.1080/00207178508933420; BARSHALOM Y, 1989, IEEE T AERO ELEC SYS, V25, P296, DOI 10.1109/7.18693; BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225; BLOM HAP, 1984, 23RD P IEEE C DEC CO, P656; BRADSHAW KJ, 1994, IMAGE VISION COMPUT, V12, P155, DOI 10.1016/0262-8856(94)90067-1; BRADSHAW KJ, 1995, THESIS U OXFORD; BROWN C, 1990, BIOL CYBERN, V63, P61, DOI 10.1007/BF00202454; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Carpenter RHS, 1988, MOVEMENTS EYES; CHANG CB, 1984, IEEE T AUTOMAT CONTR, V29, P98, DOI 10.1109/TAC.1984.1103466; Clark J. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P514, DOI 10.1109/CCV.1988.590032; FAIRLEY SM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1100, DOI 10.1109/ICCV.1995.466812; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; INTILLE SS, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P672, DOI 10.1109/ICCV.1995.466874; KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538; KOLLER D, 1992, P 2 EUR C COMP VIS S, P437; Mohnhaupt M., 1991, Robotics and Autonomous Systems, V8, P65, DOI 10.1016/0921-8890(91)90015-D; Mundy J., 1992, GEOMETRIC INVARIANCE; Murray D. W., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P403, DOI 10.1109/ICCV.1993.378187; MURRAY DW, 1995, INT J COMPUT VISION, V16, P205, DOI 10.1007/BF01539627; PAHLAVAN K, 1992, CVGIP-IMAG UNDERSTAN, V56, P41, DOI 10.1016/1049-9660(92)90084-G; PAHLAVAN K, 1993, P 4 INT C COMP VIS B, P412; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Reid ID, 1996, INT J COMPUT VISION, V18, P41, DOI 10.1007/BF00126139; REID ID, 1993, P 4 INT C COMP VIS B, P76; SHARKEY PM, 1993, MECHATRONICS, V3, P517, DOI 10.1016/0957-4158(93)90021-S; SHARKEY PM, 1993, P SPIE SENSOR FUSION, V6; SULLIVAN GD, 1992, PHILOS T ROY SOC B, V337, P361, DOI 10.1098/rstb.1992.0114; TAN TN, 1992, P 2 EUR C COMP VIS S, P277; WATSON GA, 1992, SPIE P ACQUISITION T, V4, P83; WATSON GA, 1992, SPIE, V1698, P236	31	50	55	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					219	234		10.1109/34.584099	http://dx.doi.org/10.1109/34.584099			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR582					2022-12-18	WOS:A1997WR58200003
J	Subrahmonia, J; Cooper, DB; Keren, D				Subrahmonia, J; Cooper, DB; Keren, D			Practical reliable Bayesian recognition of 2D and 3D objects using implicit polynomials and algebraic invariants	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						implicit polynomials; algebraic invariants; Bayesian recognition; Mahalanobis distance	3-D; SYSTEM; VISION	Patches of quadric curves and surfaces such as spheres, planes, and cylinders have found widespread use in modeling and recognition of objects of interest in computer vision. In this paper, we treat use of more complex higher degree polynomial curves and surfaces of degree higher than 2, which have many desirable properties for object recognition and position estimation, and attack the instability problem arising in their use with partial and noisy data. The scenario discussed in this paper is one where we have a set of objects that are modeled as implicit polynomial functions, or a set of representations of classes of objects with each object in a class modeled as an implicit polynomial function, stored in the database. Then, given partial data from one of the objects, we want to recognize the object (or the object class) or collect more data in order to get better parameter estimates for more reliable recognition. Two problems arising in this scenario are discussed in this paper: 1) the problem of recognizing these polynomials by comparing them in terms of their coefficients, which are global descriptors, or in terms of algebraic invariants, i.e., functions of the polynomial coefficients that are independent of translations, rotations, and general linear transformation of the data; and 2) the problem of where to collect data so as to improve the parameter estimates as quickly as possible. We solve these problems by formulating them within a probabilistic framework. We use an asymptotic Bayesian approximation which results in computationally attractive solutions to the two problems. Among the key ideas discussed in this paper are the intrinsic dimensionality of polynomials and the use of the Mahalanobis distance as an effective tool for comparing polynomials in terms of their coefficients or algebraic invariants.	BROWN UNIV, DIV ENGN, LAB ENGN MAN MACHINE SYST, PROVIDENCE, RI 02912 USA; UNIV HAIFA, DEPT MATH & COMP SCI, HAIFA, ISRAEL	Brown University; University of Haifa	Subrahmonia, J (corresponding author), IBM CORP, TJ WATSON RES CTR, HANDWRITING ALGORITHMS GRP, HAWTHORNE, NY 10532 USA.							BOLLE RM, 1986, IEEE T PATTERN ANAL, V8, P619, DOI 10.1109/TPAMI.1986.4767836; BOLLE RM, 1984, IEEE T PATTERN ANAL, V6, P418, DOI 10.1109/TPAMI.1984.4767547; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; CERNUSCHIFRIAS B, 1984, THESIS BROWN U PROVI; CHEN CH, 1989, IEEE T SYST MAN CYB, V19, P1535, DOI 10.1109/21.44070; COOPER D, 1974, IEEE T PATTERN ANAL, V20; COOPER DB, 1983, IEEE T PATTERN ANAL, V5, P299, DOI 10.1109/TPAMI.1983.4767392; COOPER DB, 1976, IEEE T COMPUT, V25, P1020; Faugeras O. D., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P8; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; Grace John Hilton, 1903, ALGEBRA INVARIANTS; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P1143, DOI 10.1109/34.334397; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; KEREN D, 1992, IEEE C COMP VIS PATT, P791; LEI Z, 1995, 140 LEMS BROWN U DIV; MARKANDEY V, 1992, IEEE T ROBOTIC AUTOM, V8, P186, DOI 10.1109/70.134273; PRATT V, 1987, ACM SIGGRAPH, V21, P145; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; SILVERMAN JF, 1988, IEEE T PATTERN ANAL, V10, P482, DOI 10.1109/34.3912; SUBRAHMONIA J, 1992, LEMS107 BROWN U; SUBRAHMONIA J, 1992, P SPIE C BOST MASS J; TAUBIN G, 1992, ARTIF INT, P375; TAUBIN G, 1994, IEEE T PATTERN ANAL, V16, P287, DOI 10.1109/34.276128; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Wald A, 1943, T AM MATH SOC, V54, P426, DOI 10.2307/1990256; WEISS I, 1991, 1ST P DARPA ESPRIT W, P345; WHAITE P, 1991, IEEE T PATTERN ANAL, V13, P1038, DOI 10.1109/34.99237; [No title captured]	29	50	52	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1996	18	5					505	519		10.1109/34.494640	http://dx.doi.org/10.1109/34.494640			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL691					2022-12-18	WOS:A1996UL69100003
J	AGHAJAN, HK; KAILATH, T				AGHAJAN, HK; KAILATH, T			SLIDE - SUBSPACE-BASED LINE DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						LINE FITTING; EDGE DETECTION; SUBSPACE FITTING; ARRAY PROCESSING; OBJECT RECOGNITION; PROJECTION; HOUGH TRANSFORM	SIGNALS	An analogy is made between each straight line in an image and a planar propagating wavefront impinging on an array of sensors so as to obtain a mathematical model exploited in recent high resolution methods for direction-of-arrival estimation in sensor array processing. The new so-called SLIDE (Subspace-Based Line Detection) algorithm then exploits the spatial coherence between the contributions of each line in different rows of the image to enhance and distinguish a signal subspace that is defined by the desired line parameters. SLIDE yields closed-form and high resolution estimates for line parameters, and its computational complexity and storage requirements are far less than those of the standard method of the Hough transform. If unknown a priori, the number of lines is also estimated in the proposed technique. The signal representation employed in this formulation is also generalized to handle grey-scale images as well. The technique has also been generalized to fitting planes in 3-D images. Potential application areas of the proposed technique include road tracking in robotic vision, mask-wafer alignment and linewidth measurement in semiconductor manufacturing, aerial image analysis, text alignment in document analysis, particle tracking in hubble chambers, and similar applications.			AGHAJAN, HK (corresponding author), STANFORD UNIV,DEPT ELECT ENGN,INFORMAT SYST LAB,STANFORD,CA 94305, USA.							Aghajan HK, 1993, IEEE T IMAGE PROCESS, V2, P454, DOI 10.1109/83.242355; AGHAJAN HK, 1993, P IEEE ICASSP MINNEA, P89; AGHAJAN HK, 1992, P IEEE ICASSP SAN FR, P121; Deans S., 1983, RADON TRANSFORM SOME; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; GOLUB GH, 1984, MATRIX COMPUTATIONS; Haykin S., 1991, ADAPTIVE FILTER THEO; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Jain A. K., 1989, FUNDAMENTALS DIGITAL; KIRYATI N, 1991, IEEE T PATTERN ANAL, V13, P602, DOI 10.1109/34.87346; NIBLACK W, 1988, JUN P IEEE COMP SOC, P574; Orfanidis S.J., 1988, OPTIMUM SIGNAL PROCE; Parlett B. N., 1998, SYMMETRIC EIGENVALUE, V20, DOI DOI 10.1137/1.9781611971163; PAULRAJ A, 1985, 19TH P AS C CIRC SYS; PAULRAJ A, 1986, P IEEE           JUL, P1044; ROY R, 1989, IEEE T ACOUST SPEECH, V37, P984, DOI 10.1109/29.32276; SCHMIDT RO, 1986, IEEE T ANTENN PROPAG, V34, P276, DOI 10.1109/TAP.1986.1143830; VIBERG M, 1991, IEEE T SIGNAL PROCES, V39, P2436, DOI 10.1109/78.97999; WAX M, 1989, IEEE T ACOUST SPEECH, V37, P1190, DOI 10.1109/29.31267; WAX M, 1985, IEEE T ACOUST SPEECH, V33, P387, DOI 10.1109/TASSP.1985.1164557; XU G, 1991, P IEEE ICASSP TORONT, P3069	21	50	51	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1994	16	11					1057	1073		10.1109/34.334386	http://dx.doi.org/10.1109/34.334386			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PW081					2022-12-18	WOS:A1994PW08100001
J	XIE, QB; LASZLO, CA; WARD, RK				XIE, QB; LASZLO, CA; WARD, RK			VECTOR QUANTIZATION TECHNIQUE FOR NONPARAMETRIC CLASSIFIER DESIGN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CONDENSING ALGORITHMS; DATA REDUCTION; KAPPA-NEAREST-NEIGHBOR (KAPPA-NN) CLASSIFIER; NONPARAMETRIC CLASSIFICATION; PARZEN KERNEL CLASSIFIER; VECTOR QUANTIZATION		An effective data reduction technique based on vector quantization is introduced for nonparametric classifier design. Two new nonparametric classifiers are developed, and their performance is evaluated using various examples. The new methods maintain a classification accuracy that is competitive with that of classical methods but, at the same time, yields very high data reduction rates.			XIE, QB (corresponding author), UNIV BRITISH COLUMBIA,DEPT ELECT ENGN,VANCOUVER V6T 1Z4,BC,CANADA.							DEVIJVER PA, 1980, 5TH P INT C PATT REC, P72; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115, DOI 10.1109/TPAMI.1984.4767485; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P423, DOI 10.1109/34.19040; FUKUNAGA K, 1990, INTRO STATISTICAL PA; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GERSHO A, 1979, IEEE T INFORM THEORY, V25, P373, DOI 10.1109/TIT.1979.1056067; Hand D. J, 1981, WILEY SERIES PROBABI; HAND DJ, 1982, KERNEL DISCRIMINANT; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1988, 2ND P IEEE INT C NEU, V1, P61; Kohonen T., 1988, NEURAL NETWORKS, V1, P303; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; NASRABADI N, 1988, IEEE P ICNN 88, V2, P1101; NESS JWV, 1976, TECHNOMETRICS, V18, P175; NESS JWV, 1979, TECHNOMETRICS, V21, P119	15	50	54	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1326	1330		10.1109/34.250849	http://dx.doi.org/10.1109/34.250849			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176		Green Submitted			2022-12-18	WOS:A1993MP17600010
J	MALINA, W				MALINA, W			ON AN EXTENDED FISHER CRITERION FOR FEATURE-SELECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MALINA, W (corresponding author), GDANSK POLYTECH INST,INST INFORMAT,GDANSK,POLAND.							CHIEN YT, 1968, INFORM CONTROL, V12, P394, DOI 10.1016/S0019-9958(68)90420-8; Duda R., 1973, PATTERN CLASSIFICATI, p[114, 221]; FOLEY D, 1975, IEEE T C, V26, P281; FRIEDMAN HP, 1967, J AM STAT ASSOC, V62, P1159, DOI 10.2307/2283767; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P917, DOI 10.1109/T-C.1970.222799; KITTLER J, 1977, IEEE T COMPUT, V26, P604, DOI 10.1109/TC.1977.1674885; KOZAKOS D, 1977, IEEE T SYST MAN CYBE, V7, P661; LANKASTER P, 1969, THEORY MATRICES, pCH1; SAMMON JW, 1970, IEEE T COMPUT, VC 19, P826, DOI 10.1109/T-C.1970.223047; WATANABE S, 1965, 4TH P PRAG C INF THE; WATANABE S, 1966, COINS S; WILKS S, 1973, MATH STATISTICS, P573	13	50	51	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	5					611	614		10.1109/TPAMI.1981.4767154	http://dx.doi.org/10.1109/TPAMI.1981.4767154			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ358	21868980				2022-12-18	WOS:A1981MQ35800012
J	PAVLIDIS, T; ALI, F				PAVLIDIS, T; ALI, F			HIERARCHICAL SYNTACTIC SHAPE ANALYZER	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PRINCETON UNIV,DEPT ELECT ENGN & COMP SCI,PRINCETON,NJ 08540	Princeton University	PAVLIDIS, T (corresponding author), UNIV CALIF BERKELEY,DEPT ELECT ENGN & COMP SCI,BERKELEY,CA 94720, USA.							Aho A.V., 1972, THEORY PARSING TRANS; Aho AV, 1974, DESIGN ANAL COMPUTER; ALI F, 1977, IEEE T SYST MAN CYB, V7, P537, DOI 10.1109/TSMC.1977.4309763; CHANG LP, 1976, 201 PRINC U COMP SCI; COOPER DB, 1976, IEEE T COMPUT, V25, P1020; DAVIS LS, 1977, IEEE T C, V26, P297; Duda R.O., 1973, J ROYAL STAT SOC SER; Ejiri M., 1973, COMPUT VISION GRAPH, V2, P326, DOI 10.1016/0146-664X(73)90011-7; FENG HYF, 1975, IEEE T COMPUT, VC 24, P636, DOI 10.1109/T-C.1975.224276; Fu K.S., 1974, MATH SCI ENG; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95, DOI 10.1109/TSMC.1975.5409159; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; FU KS, 1977, SYNTACTIC PATTERN RE; FUNG LW, 1975, IEEE T COMPUT, VC 24, P662, DOI 10.1109/T-C.1975.224278; FUNG LW, 1975, IEEE T INFORM THEORY, V21, P423, DOI 10.1109/TIT.1975.1055406; HARLOW CA, 1973, COMPUTER GRAPHICS IM, V2, P60; HARMON LD, 1972, P IEEE, V60, P1165, DOI 10.1109/PROC.1972.8878; HOROWITZ SL, 1975, COMMUN ACM, V18, P281, DOI 10.1145/360762.360810; Jarvis J. F., 1976, 3rd International Joint Conference on Pattern Recognition, P189; LEDLEY RS, 1964, SCIENCE, V146, P216, DOI 10.1126/science.146.3641.216; LEE HC, 1972, IEEE T COMPUT, VC 21, P660, DOI 10.1109/T-C.1972.223571; LEMKIN P, 1975, TR386 U MAR TECH REP; MCCLURE DE, 1975, Q APPL MATH, V33, P1; MOAYER B, 1976, IEEE T COMPUT, V25, P262, DOI 10.1109/TC.1976.5009253; MOAYER B, 1975, PATTERN RECOGN, V7, P1, DOI 10.1016/0031-3203(75)90011-4; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PAVLIDIS T, 1975, IEEE T SYST MAN CYB, V5, P610, DOI 10.1109/TSMC.1975.4309402; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PAVLIDIS T, 1976, PATTERN RECOGNITION, P389; Pavlidis T., 1977, STRUCTURAL PATTERN R; PAVLIDIS T, 1977, 7TH ANN AUT PATTN RE, P147; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; ROSENFELD A, 1970, SHAPE SYNTHESIS 1; ROSENFELD A, 1975, TR407 U MAR TECH REP; STOCKMAN G, 1976, COMMUN ACM, V19, P688, DOI 10.1145/360373.360378; SWAIN PH, 1972, PATTERN RECOGN, V4, P83, DOI 10.1016/0031-3203(72)90021-0; THOMSON K, 1975, UNIX PROGRAMMERS MAN	37	50	50	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					2	9		10.1109/TPAMI.1979.4766870	http://dx.doi.org/10.1109/TPAMI.1979.4766870			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	HA303	21868825				2022-12-18	WOS:A1979HA30300001
J	Tung, F; Mori, G				Tung, Frederick; Mori, Greg			Deep Neural Network Compression by In-Parallel Pruning-Quantization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Quantization (signal); Image coding; Neural networks; Visualization; Training; Convolution; Network architecture; Deep learning; neural network compression; weight pruning; weight quantization; Bayesian optimization		Deep neural networks enable state-of-the-art accuracy on visual recognition tasks such as image classification and object detection. However, modern networks contain millions of learned connections, and the current trend is towards deeper and more densely connected architectures. This poses a challenge to the deployment of state-of-the-art networks on resource-constrained systems, such as smartphones or mobile robots. In general, a more efficient utilization of computation resources would assist in deployment scenarios from embedded platforms to computing clusters running ensembles of networks. In this paper, we propose a deep network compression algorithm that performs weight pruning and quantization jointly, and in parallel with fine-tuning. Our approach takes advantage of the complementary nature of pruning and quantization and recovers from premature pruning errors, which is not possible with two-stage approaches. In experiments on ImageNet, CLIP-Q (Compression Learning by In-Parallel Pruning-Quantization) improves the state-of-the-art in network compression on AlexNet, VGGNet, GoogLeNet, and ResNet. We additionally demonstrate that CLIP-Q is complementary to efficient network architecture design by compressing MobileNet and ShuffleNet, and that CLIP-Q generalizes beyond convolutional networks by compressing a memory network for visual question answering.	[Tung, Frederick; Mori, Greg] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Simon Fraser University	Tung, F (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	ftung@sfu.ca; mori@cs.sfu.ca			Natural Sciences and Engineering Research Council of Canada	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR)	This work was supported by the Natural Sciences and Engineering Research Council of Canada.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2015, ICLR; [Anonymous], [No title captured]; [Anonymous], 2018, P INT C LEARN REPR W; [Anonymous], 2018, P INT C LEARN REPR; [Anonymous], [No title captured]; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Chang B., 2018, ICLR POSTER; Chen L.-C., 2015, COMPUT SCI; Cheng Y, 2015, IEEE I CONF COMP VIS, P2857, DOI 10.1109/ICCV.2015.327; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Courbariaux M, 2015, ADV NEUR IN, V28; Cun YL., 1990, ADV NEURAL INF PROCE, P598, DOI DOI 10.5555/109230.109298; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Denil Misha, 2013, NIPS, DOI DOI 10.5555/2999792.2999852; Denton E, 2014, ADV NEUR IN, V27; Dong XY, 2017, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR.2017.205; Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194; Figurnov Mikhail, 2016, NEURIPS; Gardner JR, 2014, PR MACH LEARN RES, V32, P937; Guo YW, 2017, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2017.430; Guo YW, 2016, ADV NEUR IN, V29; Gysel P, 2018, IEEE T NEUR NET LEAR, V29, P5784, DOI 10.1109/TNNLS.2018.2808319; Han S., 2017, P INT C LEARN REPR; Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104; Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30; Hassibi Babak, 1992, ADV NEURAL INFORM PR, V1, P8; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton G., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1109/TPAMI.2012.59; Howard A. G., 2017, MOBILENETS EFFICIENT; Hu RH, 2017, IEEE I CONF COMP VIS, P804, DOI 10.1109/ICCV.2017.93; Huang G, 2018, P INT C LEARN REPR; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39; Iandola F.N., 2016, ARXIV PREPRINT ARXIV; Jaderberg Max, 2014, P BRIT MACH VIS C, P2, DOI DOI 10.5244/C.28.88; Juefei-Xu F, 2017, PROC CVPR IEEE, P4284, DOI 10.1109/CVPR.2017.456; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lebedev V, 2016, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2016.280; Li XX, 2017, PROC CVPR IEEE, P6459, DOI 10.1109/CVPR.2017.684; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu JM, 2017, AAAI CONF ARTIF INTE, P2245; Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9; Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Park E, 2017, PROC CVPR IEEE, P7197, DOI 10.1109/CVPR.2017.761; Park J., 2017, P INT C LEARN REPR; Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Romero Adriana, 2015, ICLR 2015; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Snoek J., 2012, P 25 INT C NEUR INF, V2, P2951, DOI DOI 10.48550/ARXIV.1206.2944; Srinivas S., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.5244/C.29.31; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Ullrich Karen, 2017, P INT C LEARN REPR; Wang Z., 2013, INT JOINT C ART INT; Wen W, 2016, ADV NEUR IN, V29; Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521; Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28; Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643; Yang ZC, 2015, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2015.173; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809; Zhou H, 2016, LECT NOTES COMPUT SC, V9908, P662, DOI 10.1007/978-3-319-46493-0_40; Zhou K, 2016, DESTECH TRANS COMP; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540	70	49	53	3	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					568	579		10.1109/TPAMI.2018.2886192	http://dx.doi.org/10.1109/TPAMI.2018.2886192			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30561340				2022-12-18	WOS:000525365300004
J	Emambakhsh, M; Evans, A				Emambakhsh, Mehryar; Evans, Adrian			Nasal Patches and Curves for Expression-Robust 3D Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; facial landmarking; nose region; feature selection; Gabor wavelets; surface normals	KEYPOINT DETECTION; TEXTURE FEATURES; REPRESENTATION; SEGMENTATION; REGISTRATION	The potential of the nasal region for expression robust 3D face recognition is thoroughly investigated by a novel five-step algorithm. First, the nose tip location is coarsely detected and the face is segmented, aligned and the nasal region cropped. Then, a very accurate and consistent nasal landmarking algorithm detects seven keypoints on the nasal region. In the third step, a feature extraction algorithm based on the surface normals of Gabor-wavelet filtered depth maps is utilised and, then, a set of spherical patches and curves are localised over the nasal region to provide the feature descriptors. The last step applies a genetic algorithm-based feature selector to detect the most stable patches and curves over different facial expressions. The algorithm provides the highest reported nasal region-based recognition ranks on the FRGC, Bosphorus and BU-3DFE datasets. The results are comparable with, and in many cases better than, many state-of-the-art 3D face recognition algorithms, which use the whole facial domain. The proposed method does not rely on sophisticated alignment or denoising steps, is very robust when only one sample per subject is used in the gallery, and does not require a training step for the landmarking algorithm.	[Emambakhsh, Mehryar] Heriot Watt Univ, Inst Sensors Signals & Syst, Edinburgh, Midlothian, Scotland; [Evans, Adrian] Univ Bath, Dept Elect & Elect Engn, Bath, Avon, England	Heriot Watt University; University of Bath	Emambakhsh, M (corresponding author), Heriot Watt Univ, Inst Sensors Signals & Syst, Edinburgh, Midlothian, Scotland.	m.emambakhsh@hw.ac.uk; A.N.Evans@bath.ac.uk		Evans, Adrian/0000-0001-8586-8295; Emambakhsh, Mehryar/0000-0001-6416-7668				Aissi H, 2009, EUR J OPER RES, V197, P427, DOI 10.1016/j.ejor.2008.09.012; Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0; Alyuz N., 2008, 2 IEEE INT C BIOM TH, P1; Alyuz N, 2010, IEEE T INF FOREN SEC, V5, P425, DOI 10.1109/TIFS.2010.2054081; Berretti S, 2013, IEEE T INF FOREN SEC, V8, P374, DOI 10.1109/TIFS.2012.2235833; Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210; Creusot C, 2013, INT J COMPUT VISION, V102, P146, DOI 10.1007/s11263-012-0605-9; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; Dibeklioglu H, 2009, LECT NOTES COMPUT SC, V5558, P309, DOI 10.1007/978-3-642-01793-3_32; Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48; Drira H, 2009, LECT NOTES COMPUT SC, V5558, P357, DOI 10.1007/978-3-642-01793-3_37; Emambakhsh M., 2011, P 4 IET INT C IM CRI, P1; Emambakhsh M., 2013, 2013 IEEE 6 INT C BI, P1, DOI [DOI 10.1109/BTAS.2013.6712732, 10.1109/BTAS.2013.6712732]; Emambakhsh M, 2010, INT J AP MAT COM-POL, V20, P711, DOI 10.2478/v10006-010-0054-y; Hajati F, 2012, PATTERN RECOGN, V45, P969, DOI 10.1016/j.patcog.2011.08.025; Huibin Li, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3053, DOI 10.1109/ICIP.2011.6116308; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406; Li HB, 2014, NEUROCOMPUTING, V133, P179, DOI 10.1016/j.neucom.2013.11.018; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Mohammadzade H, 2013, IEEE T PATTERN ANAL, V35, P381, DOI 10.1109/TPAMI.2012.107; Moorhouse A., 2009, AUDIO T IRE PROFESSI, P1; Phillips PJ, 2005, PROC CVPR IEEE, P947; Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14; Raguram R, 2011, INT J COMPUT VISION, V95, P213, DOI 10.1007/s11263-011-0445-z; Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6; Segundo MP, 2010, IEEE T SYST MAN CY B, V40, P1319, DOI 10.1109/TSMCB.2009.2038233; Smeets D, 2013, COMPUT VIS IMAGE UND, V117, P158, DOI 10.1016/j.cviu.2012.10.002; Spreeuwers L, 2011, INT J COMPUT VISION, V93, P389, DOI 10.1007/s11263-011-0426-2; Srinivas N., 1994, Evolutionary Computation, V2, P221, DOI 10.1162/evco.1994.2.3.221; Wang YM, 2008, LECT NOTES COMPUT SC, V5302, P603, DOI 10.1007/978-3-540-88682-2_46; Wang YM, 2010, IEEE T PATTERN ANAL, V32, P1858, DOI 10.1109/TPAMI.2009.200; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	39	49	54	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					995	1007		10.1109/TPAMI.2016.2565473	http://dx.doi.org/10.1109/TPAMI.2016.2565473			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	28113700	Green Published, Green Submitted			2022-12-18	WOS:000399250000012
J	Gebru, ID; Alameda-Pineda, X; Forbes, F; Horaud, R				Gebru, Israel Dejene; Alameda-Pineda, Xavier; Forbes, Florence; Horaud, Radu			EM Algorithms for Weighted-Data Clustering with Application to Audio-Visual Scene Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Finite mixtures; expectation-maximization; weighted-data clustering; robust clustering; outlier detection; model selection; minimum message length; audio-visual fusion; speaker localization	MIXTURE	Data clustering has received a lot of attention and numerous methods, algorithms and software packages are available. Among these techniques, parametric finite-mixture models play a central role due to their interesting mathematical properties and to the existence of maximum-likelihood estimators based on expectation-maximization (EM). In this paper we propose a new mixture model that associates a weight with each observed point. We introduce the weighted-data Gaussian mixture and we derive two EM algorithms. The first one considers a fixed weight for each observation. The second one treats each weight as a random variable following a gamma distribution. We propose a model selection method based on a minimum message length criterion, provide a weight initialization strategy, and validate the proposed algorithms by comparing them with several state of the art parametric and non-parametric clustering techniques. We also demonstrate the effectiveness and robustness of the proposed clustering technique in the presence of heterogeneous data, namely audio-visual scene analysis.	[Gebru, Israel Dejene; Alameda-Pineda, Xavier; Forbes, Florence; Horaud, Radu] INRIA Grenoble Rhone Alpes, Montbonnot St Martin, France; [Alameda-Pineda, Xavier] Univ Trento, Multimodal Human Understanding Grp, Trento, Italy	University of Trento	Gebru, ID (corresponding author), INRIA Grenoble Rhone Alpes, Montbonnot St Martin, France.	israel-dejene.gebru@inria.fr; xavier.alamedapineda@unitn.it; florence.forbes@inria.fr; radu.horaud@inria.fr	Gebru, Israel Dejene/W-2439-2019; Gebru, Israel D/ABA-4507-2021; Horaud, Radu/AAR-5982-2021	Gebru, Israel Dejene/0000-0003-1433-5891; Horaud, Radu/0000-0001-5232-024X; Alameda-Pineda, Xavier/0000-0002-5354-1084	European Union FP7 ERC Advanced Grant VHIA [340113]; STREP EARS [609645]; XEROX University Affairs Committee (UAC) grant; MIUR Active Aging at Home project [CTN01_00128]	European Union FP7 ERC Advanced Grant VHIA; STREP EARS; XEROX University Affairs Committee (UAC) grant; MIUR Active Aging at Home project	Funding from the European Union FP7 ERC Advanced Grant VHIA (#340113) and STREP EARS (#609645) is greatly acknowledged. F. Forbes and R. Horaud are partially supported by a XEROX University Affairs Committee (UAC) grant (2015-2017). X. Alameda-PIneda acknowledges support from the MIUR Active Aging at Home project #CTN01_00128.	Ackerman M, 2012, P 26 AAAI C ART INT, P858; Andrews JL, 2012, STAT COMPUT, V22, P1021, DOI 10.1007/s11222-011-9272-x; Archambeau C, 2007, NEURAL NETWORKS, V20, P129, DOI 10.1016/j.neunet.2006.06.009; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Baudry JP, 2010, J COMPUT GRAPH STAT, V19, P332, DOI 10.1198/jcgs.2010.08111; Bishop C.M, 2006, PATTERN RECOGN; Celeux G, 2001, J COMPUT GRAPH STAT, V10, P697, DOI 10.1198/106186001317243403; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; Deleforge A, 2015, IEEE-ACM T AUDIO SPE, V23, P718, DOI 10.1109/TASLP.2015.2405475; Feldman Dan, 2012, P 23 ANN ACM SIAM S, P1343; Ferrari V, 2009, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2009.5206495; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Forbes F, 2014, STAT COMPUT, V24, P971, DOI 10.1007/s11222-013-9414-4; Forbes Florence., 2010, AISTATS, V2010, P225; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1023/A:1022606404104; Gorur D, 2010, J COMPUT SCI TECH-CH, V25, P653, DOI [10.1007/s11390-010-1051-1, 10.1007/s11390-010-9355-8]; Hennig Christian, 2010, Advances in Data Analysis and Classification, V4, P3, DOI 10.1007/s11634-010-0058-3; Kotz S., 2004, MULTIVARIATE T DISTR; Kulis B., 2004, P 10 ACM SIGKDD INT, P551, DOI DOI 10.1145/1014052.1014118; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee S, 2014, STAT COMPUT, V24, P181, DOI 10.1007/s11222-012-9362-4; Long Bo, 2006, P 23 INT C MACH LEAR, P585, DOI DOI 10.1145/1143844.1143918; Mclachlan G., 2000, WILEY SER PROB STAT; Melnykov V., 2014, J COMPUT GRAPHICAL S; Olshen R., 1984, CLASSIFICATION REGRE; Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081; Rasmussen CE, 2000, ADV NEUR IN, V12, P554; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233; Street William Nick, 1993, IS T SPIE 1993 INT S, V1905, P861; Sun JY, 2010, PATTERN RECOGN LETT, V31, P2447, DOI 10.1016/j.patrec.2010.07.015; Svensen M, 2005, NEUROCOMPUTING, V64, P235, DOI 10.1016/j.neucom.2004.11.018; Tseng GC, 2007, BIOINFORMATICS, V23, P2247, DOI 10.1093/bioinformatics/btm320; Wei X, 2012, SIGNAL PROCESS, V92, P224, DOI 10.1016/j.sigpro.2011.07.010; Yerebakan H.Z., 2014, ADV NEURAL INFORM PR, P28; Zhao Y., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P515, DOI 10.1145/584792.584877; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	38	49	50	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2402	2415		10.1109/TPAMI.2016.2522425	http://dx.doi.org/10.1109/TPAMI.2016.2522425			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	27824582	Green Submitted			2022-12-18	WOS:000387984700005
J	Zheng, Q; Kumar, A; Pan, G				Zheng, Qian; Kumar, Ajay; Pan, Gang			A 3D Feature Descriptor Recovered from a Single 2D Palmprint Image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Palmprint recognition; biometrics; contactless palmprint matching; 3D feature from a single 2D image; ordinal features		Design and development of efficient and accurate feature descriptors is critical for the success of many computer vision applications. This paper proposes a new feature descriptor, referred to as DoN, for the 2D palmprint matching. The descriptor is extracted for each point on the palmprint. It is based on the ordinal measure which partially describes the difference of the neighboring points' normal vectors. DoN has at least two advantages: 1) it describes the 3D information, which is expected to be highly stable under commonly occurring illumination variations during contactless imaging; 2) the size of DoN for each point is only one bit, which is computationally simple to extract, easy to match, and efficient to storage. We show that such 3D information can be extracted from a single 2D palmprint image. The analysis for the effectiveness of ordinal measure for palmprint matching is also provided. Four publicly available 2D palmprint databases are used to evaluate the effectiveness of DoN, both for identification and the verification. Our method on all these databases achieves the state-of-the-art performance.	[Zheng, Qian; Kumar, Ajay] Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China; [Zheng, Qian; Pan, Gang] Zhejiang Univ, Dept Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China	Hong Kong Polytechnic University; Zhejiang University	Zheng, Q; Kumar, A (corresponding author), Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.; Zheng, Q; Pan, G (corresponding author), Zhejiang Univ, Dept Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.	csqiazheng@comp.polyu.edu.hk; Ajay.Kumar@polyu.edu.hk; gpan@zju.edu.cn	Pan, Gang/B-5978-2013	Pan, Gang/0000-0002-4049-6181	Hong Kong Polytechnic University [PolyU 5169/13E, A-SA79]	Hong Kong Polytechnic University(Hong Kong Polytechnic University)	This work was supported by project no. PolyU 5169/13E and grant no. A-SA79 from The Hong Kong Polytechnic University. The algorithm(s) described in this paper are part of pending US Patent filed in 2014.	[Anonymous], 2012, POLYU PALMPR PALMPR; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275; Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4; Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011; Kanhangad V, 2011, IEEE T INF FOREN SEC, V6, P1014, DOI 10.1109/TIFS.2011.2121062; Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184; Kumar A, 2015, IEEE T PATTERN ANAL, V37, P681, DOI 10.1109/TPAMI.2014.2339818; Kumar A, 2011, IEEE T SYST MAN CY C, V41, P743, DOI 10.1109/TSMCC.2010.2089516; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Maltoni D., 2009, HDB FINGERPRINT RECO; Sinha P, 2002, LECT NOTES COMPUT SC, V2525, P249; Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240; Sun ZN, 2005, PROC CVPR IEEE, P279; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882; Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981; Zheng Q, 2016, IEEE T INF FOREN SEC, V11, P633, DOI 10.1109/TIFS.2015.2503265	18	49	50	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1272	1279		10.1109/TPAMI.2015.2509968	http://dx.doi.org/10.1109/TPAMI.2015.2509968			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	27164564				2022-12-18	WOS:000375609000017
J	Sironi, A; Tekin, B; Rigamonti, R; Lepetit, V; Fua, P				Sironi, Amos; Tekin, Bugra; Rigamonti, Roberto; Lepetit, Vincent; Fua, Pascal			Learning Separable Filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional sparse coding; filter learning; features extraction; separable convolution; segmentation of linear structures; image denoising; convolutional neural networks; tensor decomposition	SPARSE; SEGMENTATION	Learning filters to produce sparse image representations in terms of overcomplete dictionaries has emerged as a powerful way to create image features for many different purposes. Unfortunately, these filters are usually both numerous and non-separable, making their use computationally expensive. In this paper, we show that such filters can be computed as linear combinations of a smaller number of separable ones, thus greatly reducing the computational complexity at no cost in terms of performance. This makes filter learning approaches practical even for large images or 3D volumes, and we show that we significantly outperform state-of-the-art methods on the curvilinear structure extraction task, in terms of both accuracy and speed. Moreover, our approach is general and can be used on generic convolutional filter banks to reduce the complexity of the feature extraction step.	[Sironi, Amos; Tekin, Bugra; Rigamonti, Roberto; Fua, Pascal] Ecole Polytech Fed Lausanne, IC Fac, Comp Vis Lab, CH-1015 Lausanne, Switzerland; [Lepetit, Vincent] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Graz University of Technology	Sironi, A (corresponding author), Ecole Polytech Fed Lausanne, IC Fac, Comp Vis Lab, CH-1015 Lausanne, Switzerland.	amos.sironi@epfl.ch; bugra.tekin@epfl.ch; roberto.rigamonti@epfl.ch; lepetit@icg.tugraz.at; pascal.fua@epfl.ch		Rigamonti, Roberto/0000-0001-7283-7203; Fua, Pascal/0000-0002-6702-9970	EU ERC project MicroNano	EU ERC project MicroNano	This work was supported in part by EU ERC project MicroNano.	Acar E, 2011, J CHEMOMETR, V25, P67, DOI 10.1002/cem.1335; Ascoli G., 2010, DIGITAL RECONSTRUCTI; Bach F., 2012, FDN TRENDS MACHINE L; Bauckhage Christian, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P45; Bauckhage C., 2006, P IEEE COMP SOC C CO, P95; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bishop CM, 2006, PATTERN RECOGNITION; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Bristow H, 2013, PROC CVPR IEEE, P391, DOI 10.1109/CVPR.2013.57; Coates Adam, 2011, P 28 INT C MACH LEAR, P921; Denil Misha, 2013, NIPS, DOI DOI 10.5555/2999792.2999852; Dentinel Zarembaw, 2014, NEURIPS, P1269; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908; Fazel M, 2001, P AMER CONTR CONF, P4734, DOI 10.1109/ACC.2001.945730; Gonzalez G, 2009, PROC CVPR IEEE, P1582, DOI 10.1109/CVPRW.2009.5206511; Hawe S, 2013, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2013.63; Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200; Kavukcuoglu Koray, 2010, ADV NEURAL INFORM PR, V23, P1090; Kienzle W., 2005, P NIPS, V17, P673; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Law MWK, 2008, LECT NOTES COMPUT SC, V5305, P368, DOI 10.1007/978-3-540-88693-8_27; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 2010, MNIST HANDWRITTEN DI; Lee H, 2009, P 26 ANN INT C MACH, V26, P609, DOI [10.1145/1553374.1553453, DOI 10.1145/1553374.1553453]; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Mamalet Franck, 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. 22nd International Conference on Artificial Neural Networks, P58, DOI 10.1007/978-3-642-33266-1_8; Meila M, 2007, J MULTIVARIATE ANAL, V98, P873, DOI 10.1016/j.jmva.2006.11.013; Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Palm R. B., 2012, THESIS TU DENMARK KO; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; Pirsiavash H, 2012, PROC CVPR IEEE, P3226, DOI 10.1109/CVPR.2012.6248058; Rigamonti R., 2011, EPFLREPORT166951; Rigamonti R, 2013, PROC CVPR IEEE, P2754, DOI 10.1109/CVPR.2013.355; Rigamonti R, 2011, PROC CVPR IEEE, P1545, DOI 10.1109/CVPR.2011.5995313; Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477; Santamaria-Pang A, 2007, LECT NOTES COMPUT SC, V4792, P486; Savas B, 2007, PATTERN RECOGN, V40, P993, DOI 10.1016/j.patcog.2006.08.004; Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627; TREITEL S, 1971, IEEE T GEOSCI ELECT, VGE 9, P10, DOI 10.1109/TGE.1971.271457; Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046; VANRIJSBERGEN CJ, 1974, J DOC, V30, P365, DOI 10.1108/eb026584; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957	46	49	55	1	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					94	106		10.1109/TPAMI.2014.2343229	http://dx.doi.org/10.1109/TPAMI.2014.2343229			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353211	Green Submitted, Green Published			2022-12-18	WOS:000346970600009
J	Cuingnet, R; Glaunes, JA; Chupin, M; Benali, H; Colliot, O				Cuingnet, Remi; Glaunes, Joan Alexis; Chupin, Marie; Benali, Habib; Colliot, Olivier		Alzheimer's Dis Neuroimaging Initi	Spatial and Anatomical Regularization of SVM: A General Framework for Neuroimaging Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SVM; regularization; Laplacian; Alzheimer's disease; neuroimaging	MILD COGNITIVE IMPAIRMENT; DIMENSIONAL PATTERN-CLASSIFICATION; ALZHEIMERS-DISEASE; MRI; AD; DIAGNOSIS; SEGMENTATION; RECOGNITION; KERNELS; ATROPHY	This paper presents a framework to introduce spatial and anatomical priors in SVM for brain image analysis based on regularization operators. A notion of proximity based on prior anatomical knowledge between the image points is defined by a graph (e.g., brain connectivity graph) or a metric (e.g., Fisher metric on statistical manifolds). A regularization operator is then defined from the graph Laplacian, in the discrete case, or from the Laplace-Beltrami operator, in the continuous case. The regularization operator is then introduced into the SVM, which exponentially penalizes high-frequency components with respect to the graph or to the metric and thus constrains the classification function to be smooth with respect to the prior. It yields a new SVM optimization problem whose kernel is a heat kernel on graphs or on manifolds. We then present different types of priors and provide efficient-computations of the Gram matrix. The proposed framework is finally applied to-the classification of brain Magnetic Resonance (MR) images (based on Gray Matter (GM) concentration maps and cortical thickness measures) from 137 patients with Alzheimer's Disease (AD) and 162 elderly controls. The results demonstrate that the proposed classifier generates less-noisy and consequently more interpretable feature maps with high classification performances.	[Cuingnet, Remi] Philips Res, F-92156 Suresnes, France; [Glaunes, Joan Alexis] Univ Paris 05, MAP5, UMR 8145, Paris, France; [Glaunes, Joan Alexis; Chupin, Marie] Equipe Cogimage CRICM, Ex CNRS, LENA, UPR 640, F-75651 Paris 13, France; [Glaunes, Joan Alexis; Chupin, Marie] Univ Paris 06, Ctr Rech, Inst Cerveau & Moelle Epiniere, LIMR S 975, Paris, France; [Glaunes, Joan Alexis; Chupin, Marie] INSERM, U975, Paris, France; [Glaunes, Joan Alexis; Chupin, Marie] CNRS, UMR 7225, Paris, France; [Glaunes, Joan Alexis; Chupin, Marie] ICM Inst Cerveau & Moelle Epiniere, Paris, France; [Benali, Habib] Fac Med Pierre & Marie Curie, Lab Imagerie Fonct LIF, F-75634 Paris 13, France	Philips; Philips Research; Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute for Mathematical Sciences (INSMI); UDICE-French Research Universities; Universite Paris Cite; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Sorbonne Universite; Institut National de la Sante et de la Recherche Medicale (Inserm); Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute for Biology (INSB); UDICE-French Research Universities; Universite Paris Cite; UDICE-French Research Universities; Sorbonne Universite; UDICE-French Research Universities; Sorbonne Universite	Cuingnet, R (corresponding author), Philips Res, 33 Rue Verdun, F-92156 Suresnes, France.	remi.cuingnet@philips.com; alexis.glaunes@mi.parisdescartes.fr; marie.chupin@upmc.fr; habib.benali@imed.jussieu.fr; olivier.colliot@upmc.fr	; Colliot, Olivier/B-2092-2012	Glaunes, Joan Alexis/0000-0002-4963-9396; Cuingnet, Remi/0000-0002-9104-2446; Colliot, Olivier/0000-0002-9836-654X	ANR [ANR-09-EMER-006]; Alzheimers Disease Neuroimaging Initiative (ADNI); NIH [U01 AG024904]	ANR(French National Research Agency (ANR)); Alzheimers Disease Neuroimaging Initiative (ADNI); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by ANR (project HM-TC, number ANR-09-EMER-006). The authors would also like to thank Olivier Druet for the useful discussions. Data collection and sharing for this project was funded by the Alzheimers Disease Neuroimaging Initiative (ADNI; Principal Investigator: Michael Weiner; NIH grant U01 AG024904). ADNI data are disseminated by the Laboratory of Neuro Imaging at the University of California, Los Angeles. Data used in preparation of this paper were obtained from the Alzheirner's Disease Neuroimaging Initiative (ADNI) database (adni.loni.ucla.edix). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.ucla.edu/wpcontent/uploads/how_to_apply/ADNI_Authorship_List.pdf. E-mail: remi.cuingnet@gmail.com.	Amari S.-I., 1987, DIFFERENTIAL GEOMETR, V1; Andrade A, 2001, HUM BRAIN MAPP, V12, P79, DOI 10.1002/1097-0193(200102)12:2<79::AID-HBM1005>3.0.CO;2-I; Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018; Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007; Bloch I, 2005, PATTERN RECOGN LETT, V26, P449, DOI 10.1016/j.patrec.2004.08.009; Busatto GF, 2003, NEUROBIOL AGING, V24, P221, DOI 10.1016/S0197-4580(02)00084-2; Cachia A, 2003, IEEE T MED IMAGING, V22, P754, DOI 10.1109/TMI.2003.814781; Chung MK, 2005, LECT NOTES COMPUT SC, V3565, P627; Chupin M, 2009, HIPPOCAMPUS, V19, P579, DOI 10.1002/hipo.20626; Colliot O, 2008, RADIOLOGY, V248, P194, DOI 10.1148/radiol.2481070876; Cuingnet R., 2011, P WORKSH MACH LEARN, P201; Cuingnet R, 2011, MED IMAGE ANAL, V15, P729, DOI 10.1016/j.media.2011.05.007; Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013; Davatzikos C, 2008, NEUROIMAGE, V41, P1220, DOI 10.1016/j.neuroimage.2008.03.050; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021; Druet O, 2004, MATH N PRINC, V45, P1; Duchesne S, 2008, IEEE T MED IMAGING, V27, P509, DOI 10.1109/TMI.2007.908685; Duchesne S, 2009, ACAD RADIOL, V16, P61, DOI 10.1016/j.acra.2008.05.024; Ecker C, 2010, NEUROIMAGE, V49, P44, DOI 10.1016/j.neuroimage.2009.08.024; Fan Y, 2008, NEUROIMAGE, V39, P1731, DOI 10.1016/j.neuroimage.2007.10.031; Fan Y, 2007, IEEE T MED IMAGING, V26, P93, DOI 10.1109/TMI.2006.886812; Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4; Fischl B, 2000, P NATL ACAD SCI USA, V97, P11050, DOI 10.1073/pnas.200033797; Gartner T., 2003, ACM SIGKDD EXPLORATI, V5, P49; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gerardin E, 2009, NEUROIMAGE, V47, P1476, DOI 10.1016/j.neuroimage.2009.05.036; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gomez-Chova L, 2008, IEEE GEOSCI REMOTE S, V5, P336, DOI 10.1109/LGRS.2008.916070; Good CD, 2001, NEUROIMAGE, V14, P21, DOI 10.1006/nimg.2001.0786; Hagmann P, 2008, PLOS BIOL, V6, P1479, DOI 10.1371/journal.pbio.0060159; Hebey E, 1996, SOBOLEV SPACES RIEMA; Hinrichs C, 2009, NEUROIMAGE, V48, P138, DOI 10.1016/j.neuroimage.2009.05.056; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049; Jost J, 2008, UNIVERSITEXT, P1; Kloppel S, 2008, BRAIN, V131, P2969, DOI 10.1093/brain/awn239; Kloppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319; Kondor R.I., 2002, P 19 INT C MACHINE L, P315; Lafferty J, 2005, J MACH LEARN RES, V6, P129; Lao ZQ, 2004, NEUROIMAGE, V21, P46, DOI 10.1016/j.neuroimage.2003.09.027; Lerch JP, 2008, NEUROBIOL AGING, V29, P23, DOI 10.1016/j.neurobiolaging.2006.09.013; Querbes O, 2009, BRAIN, V132, P2036, DOI 10.1093/brain/awp105; Rapaport F, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-35; Remi C., 2010, ADV NEURAL INF PROCE, P460; Rosenberg S., 1997, LONDON MATH SOC STUD, DOI DOI 10.1017/CBO9780511623783; Scholkopf B, 1998, ADV NEUR IN, V10, P640; Scholkopf B., 1996, Artificial Neural Networks - ICANN 96. 1996 International Conference Proceedings, P47; Scholkopf B., 2001, LEARNING KERNELS; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Shawe-Taylor J., 2000, SUPPORT VECTOR MACHI; Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Smola AJ, 1998, ALGORITHMICA, V22, P211, DOI 10.1007/PL00013831; Smola AJ, 2003, LECT NOTES ARTIF INT, V2777, P144, DOI 10.1007/978-3-540-45167-9_12; Thompson PM, 2004, NEUROIMAGE, V23, pS2, DOI 10.1016/j.neuroimage.2004.07.071; Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Vemuri P, 2008, NEUROIMAGE, V39, P1186, DOI 10.1016/j.neuroimage.2007.09.073; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Whitwell JL, 2008, NEUROLOGY, V70, P512, DOI 10.1212/01.wnl.0000280575.77437.a2	61	49	51	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					682	696		10.1109/TPAMI.2012.142	http://dx.doi.org/10.1109/TPAMI.2012.142			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22732664	Green Submitted			2022-12-18	WOS:000314792900013
J	Frank, J; Mannor, S; Pineau, J; Precup, D				Frank, Jordan; Mannor, Shie; Pineau, Joelle; Precup, Doina			Time Series Analysis Using Geometric Template Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Activity recognition; gait recognition; supervised learning; unsupervised learning; wearable computing; time series classification	EMBEDDING DIMENSION; CLASSIFICATION; AUTHENTICATION	We present a novel framework for analyzing univariate time series data. At the heart of the approach is a versatile algorithm for measuring the similarity of two segments of time series called geometric template matching (GeTeM). First, we use GeTeM to compute a similarity measure for clustering and nearest-neighbor classification. Next, we present a semi-supervised learning algorithm that uses the similarity measure with hierarchical clustering in order to improve classification performance when unlabeled training data are available. Finally, we present a boosting framework called TDEBOOST, which uses an ensemble of GeTeM classifiers. TDEBOOST augments the traditional boosting approach with an additional step in which the features used as inputs to the classifier are adapted at each step to improve the training error. We empirically evaluate the proposed approaches on several datasets, such as accelerometer data collected from wearable sensors and ECG data.	[Frank, Jordan; Pineau, Joelle; Precup, Doina] McGill Univ, Sch Comp Sci, Montreal, PQ H3A 0E9, Canada; [Mannor, Shie] Technion Israel Inst Technol, Fac Elect Engn, Dept Elect Engn, IL-32000 Haifa, Israel	McGill University; Technion Israel Institute of Technology	Frank, J (corresponding author), McGill Univ, Sch Comp Sci, McConnell Engn Bldg,3480 Univ St, Montreal, PQ H3A 0E9, Canada.	jordan.frank@cs.mcgill.ca; shie.mannor@ee.technion.ac.il; jpineau@cs.mcgill.ca; dprecup@cs.mcgill.ca			NSERC; FQRNT; Israel Science Foundation [890015]; European Union under the Harvest Program under the PASCAL2 Network of Excellence	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); FQRNT(FQRNT); Israel Science Foundation(Israel Science Foundation); European Union under the Harvest Program under the PASCAL2 Network of Excellence	This work was supported in part by NSERC, FQRNT, the Israel Science Foundation under contract 890015, and the European Union under the Harvest Program under the PASCAL2 Network of Excellence. The authors thank the anonymous reviewers for their insightful feedback.	Agrawal R., 1993, Foundations of Data Organization and Algorithms. 4th International Conference. FODO '93 Proceedings, P69; Ailisto H, 2005, PROC SPIE, V5779, P7, DOI 10.1117/12.603331; Bachlin M, 2009, LECT NOTES COMPUT SC, V5558, P1040, DOI 10.1007/978-3-642-01793-3_105; Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1; Bergmann B., 1988, MULTIPLE HYPOTHESES, P100, DOI DOI 10.1007/978-3-642-52307-6_8; Berndt DJ, 1994, WORKSH KNOWL DISC DA, P229; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; Burrus C.S., 1997, INTRO WAVELETS WAVEL; Bush Keith, 2009, ADV NEURAL INFORM PR, P189; BUZUG T, 1992, PHYS REV A, V45, P7073, DOI 10.1103/PhysRevA.45.7073; Chan KP, 1999, PROC INT CONF DATA, P126, DOI 10.1109/ICDE.1999.754915; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Corduas M, 2008, COMPUT STAT DATA AN, V52, P1860, DOI 10.1016/j.csda.2007.06.001; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; Dunn J. C., 1974, J CYBERNETICS, V4, P95, DOI 10.1080/01969727408546059; Durbin J., 1960, ECONOMETRICA, P233, DOI 10.2307/1401322 0101.35604; Esteller R, 1999, INT CONF ACOUST SPEE, P2343, DOI 10.1109/ICASSP.1999.758408; Faloutsos C., 1994, SIGMOD Record, V23, P419, DOI 10.1145/191843.191925; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372; Gafurov D, 2007, IEEE T INF FOREN SEC, V2, P491, DOI 10.1109/TIFS.2007.902030; GALKA A, 2000, TOPICS NONLINEAR TIM; Ge DF, 2002, BIOMED ENG ONLINE, V1, DOI 10.1186/1475-925X-1-5; GEAPA Batista., 2011, P SIAM INT C DAT MIN, P699, DOI [10. 1137/1.9781611972818.60, DOI 10.1137/1.9781611972818.60]; Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215; Heinz EA, 2003, LECT NOTES COMPUT SC, V2875, P252; Huynh Tam, 2005, P 2005 JOINT C SMART, P159, DOI DOI 10.1145/1107548.1107591; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; JUANG BH, 1985, AT&T TECH J, V64, P391, DOI 10.1002/j.1538-7305.1985.tb00439.x; Kalpakis K, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P273, DOI 10.1109/ICDM.2001.989529; Kantz H., 2004, NONLINEAR TIME SERIE; KENNEL MB, 1992, PHYS REV A, V45, P3403, DOI 10.1103/PhysRevA.45.3403; Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476; Keogh E, 2006, UCR TIME SERIES CLAS; Korn F., 1997, SIGMOD Record, V26, P289, DOI 10.1145/253262.253332; Lemire D, 2009, PATTERN RECOGN, V42, P2169, DOI 10.1016/j.patcog.2008.11.030; Lester J, 2006, LECT NOTES COMPUT SC, V3968, P1; Michael S, 2005, APPL NONLINEAR TIME; Mukherjee I., 2010, P ADV NEUR INF PROC; Ratanamahatana CA, 2004, SIAM PROC S, P11; Ravi Nishkam, 2005, P 17 C INN APPL ART, V3, P1541, DOI DOI 10.1007/978-3-642-02481-8_120; ROSCHKE J, 1991, BIOL CYBERN, V64, P307, DOI 10.1007/BF00199594; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; SAUER T, 1991, J STAT PHYS, V65, P579, DOI 10.1007/BF01053745; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; Smyth P, 1997, ADV NEUR IN, V9, P648; Subramanya A., 2006, P 22 C UNC ART INT; Takens F, 1981, LECT NOTES MATH, V898, P365; Ward JA, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1889681.1889687; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Xi X., 2006, P 23 INT C MACHINE L, P1033, DOI 10.1145/1143844.1143974; Zhu J., 2005, TECHNICAL REPORT	53	49	61	2	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					740	754		10.1109/TPAMI.2012.121	http://dx.doi.org/10.1109/TPAMI.2012.121			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22641699				2022-12-18	WOS:000314792900017
J	Liu, ZY; Qiao, H; Xu, L				Liu, Zhi-Yong; Qiao, Hong; Xu, Lei			An Extended Path Following Algorithm for Graph-Matching Problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph matching; convex relaxation; concave relaxation; directed graph; PATH following algorithm		The path following algorithm was proposed recently to approximately solve the matching problems on undirected graph models and exhibited a state-of-the-art performance on matching accuracy. In this paper, we extend the path following algorithm to the matching problems on directed graph models by proposing a concave relaxation for the problem. Based on the concave and convex relaxations, a series of objective functions are constructed, and the Frank-Wolfe algorithm is then utilized to minimize them. Several experiments on synthetic and real data witness the validity of the extended path following algorithm.	[Liu, Zhi-Yong; Qiao, Hong] Chinese Acad Sci, State Key Lab Management & Control Complex Syst, Inst Automat, Beijing 100190, Peoples R China; [Xu, Lei] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese University of Hong Kong	Liu, ZY (corresponding author), Chinese Acad Sci, State Key Lab Management & Control Complex Syst, Inst Automat, Beijing 100190, Peoples R China.	zhiyong.liu@ia.ac.cn; hong.qiao@ia.ac.cn; lxu@cse.cuhk.edu.hk	Xu, Lei/D-6781-2013; LIU, ZHi-YONG/K-3837-2012	Xu, Lei/0000-0002-2752-1573	National Science Foundation of China (NSFC) [60975002, 61033011]; National Basic Research Program of China (973 Program) [2009CB825404]	National Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China)	The authors thanks the anonymous reviewers whose comments greatly improved the manuscript, and Zhi-Yong Liu thanks Dr. Zaslavskiy for some helpful discussions on the QAP. This work was supported by the National Science Foundation of China (NSFC) (grants 60975002, 61033011), and the National Basic Research Program of China (973 Program) (grant 2009CB825404).	ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474; Boyd S, 2004, CONVEX OPTIMIZATION; Burkard RE, 1997, J GLOBAL OPTIM, V10, P391, DOI 10.1023/A:1008293323270; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; DEMBO A, 1988, IEEE T INFORM THEORY, V34, P352, DOI 10.1109/18.2651; ESHERA MA, 1986, IEEE T PATTERN ANAL, V8, P604, DOI 10.1109/TPAMI.1986.4767835; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Hopcroft J.E, 1974, STOC, P172, DOI [10.1145/800119.803896, DOI 10.1145/800119.803896]; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Myers R, 2000, IEEE T PATTERN ANAL, V22, P628, DOI 10.1109/34.862201; Singh R, 2008, P NATL ACAD SCI USA, V105, P12763, DOI 10.1073/pnas.0806627105; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Xu L., 1989, P EURASIP WORKSH 199, P151; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zhan XZ, 2005, SIAM J MATRIX ANAL A, V27, P851, DOI 10.1137/050627812; 李炯生, 1997, 数学研究与评论, V17, P327	16	49	53	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1451	1456		10.1109/TPAMI.2012.45	http://dx.doi.org/10.1109/TPAMI.2012.45			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22331851	Green Submitted			2022-12-18	WOS:000304138300016
J	Couprie, M; Bertrand, G				Couprie, Michel; Bertrand, Gilles			New Characterizations of Simple Points in 2D, 3D, and 4D Discrete Spaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Thinning; skeleton; topology preservation; simple point; cubical complex; collapse; confluence; 4D space	PARALLEL THINNING ALGORITHMS; TOPOLOGY PRESERVATION; CONNECTIVITY	A point of a discrete object is called simple if it can be deleted from this object without altering topology. In this paper, we present new characterizations of simple points, which hold in dimensions 2, 3, and 4 and lead to efficient algorithms for detecting such points. In order to prove these characterizations, we establish two confluence properties of the collapse operation which hold in the neighborhood of a point in spaces of low dimension. We develop this work in the framework of cubical complexes, which provides a sound topological basis for image analysis and retrieves the main notions and results of digital topology, in particular the notion of simple point.	[Couprie, Michel; Bertrand, Gilles] Univ Paris Est, LABINFO IGM, A2SI ESIEE, ESIEE 2,UMR CNRS 8049, F-93162 Noisy Le Grand, France	Universite Gustave-Eiffel; ESIEE Paris; Centre National de la Recherche Scientifique (CNRS); Ecole des Ponts ParisTech	Couprie, M (corresponding author), Univ Paris Est, LABINFO IGM, A2SI ESIEE, ESIEE 2,UMR CNRS 8049, Bd Blaise Pascal BP 99, F-93162 Noisy Le Grand, France.	m.couprie@esiee.fr; g.bertrand@esiee.fr						Bertrand G, 2008, J MATH IMAGING VIS, V31, P35, DOI 10.1007/s10851-007-0063-0; BERTRAND G, 1995, CR ACAD SCI I-MATH, V321, P1077; BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P169, DOI 10.1016/0167-8655(94)90046-9; BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P1003, DOI 10.1016/0167-8655(94)90032-9; BERTRAND G, 2003, 3 D SIMPLE POI UNPUB; Bertrand G, 2007, CR MATH, V345, P363, DOI 10.1016/j.crma.2007.09.001; Bertrand G, 2006, LECT NOTES COMPUT SC, V4245, P580; Bing R., 1964, LECTURES MODERN MATH, V2, P93; COUPRIE M, 2008, COUNTER EXAMPLE CONF; COUPRIE M, 2007, IGM200708 U DEM; Couprie M, 2008, LECT NOTES COMPUT SC, V4992, P105, DOI 10.1007/978-3-540-79126-3_11; Cousty J, 2007, LECT NOTES COMPUT SC, V4466, P474; Daragon X, 2005, J MATH IMAGING VIS, V23, P379, DOI 10.1007/s10851-005-2029-4; DUDA O, 1967, AD650926 STANF RES I; GIBLIN P, 1981, GRAPHS SURFACES HOMO; GOLAY MJE, 1969, IEEE T COMPUT, VC 18, P733, DOI 10.1109/T-C.1969.222756; Kong T. Y., 1997, Discrete Geometry for Computer Imagery. 7th International Workshop, DGCI'97. Proceedings, P3; KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3; KONG TY, 1995, INT J PATTERN RECOGN, V9, P813, DOI 10.1142/S0218001495000341; KONG TY, 1993, P SPIE VISION GEOMET, V2, P69; KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5; Niethammer M, 2006, IEEE T IMAGE PROCESS, V15, P2462, DOI 10.1109/TIP.2006.877309; PASSAT N, 2007, IGM200704 U DEM; RONSE C, 1988, DISCRETE APPL MATH, V21, P67, DOI 10.1016/0166-218X(88)90034-0; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; SAHA PK, 1994, PATTERN RECOGN, V27, P295, DOI 10.1016/0031-3203(94)90060-4; Whitehead JHC, 1939, P LOND MATH SOC, V45, P243; ZEEMAN E, 1963, SEM COMB TOP IHES; ZEEMAN EC, 1964, TOPOLOGY, V2, P341	29	49	51	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					637	648		10.1109/TPAMI.2008.117	http://dx.doi.org/10.1109/TPAMI.2008.117			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407WX	19229080	Green Submitted			2022-12-18	WOS:000263396100005
J	Toyoda, T; Hasegawa, O				Toyoda, Takahiro; Hasegawa, Osamu			Random field model for integration of local information and global information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						conditional random field; local information; global information; image labeling; scene analysis		This paper presents a proposal of a general framework that explicitly models local information and global information in a conditional random field. The proposed method extracts global image features as well as local ones and uses them to predict the scene of the input image. Scene-based top-down information is generated based on the predicted scene. It represents a global spatial configuration of labels and category compatibility over an image. Incorporation of the global information helps to resolve local ambiguities and achieves locally and globally consistent image recognition. In spite of the model's simplicity, the proposed method demonstrates good performance in image labeling of two data sets.	[Toyoda, Takahiro; Hasegawa, Osamu] Tokyo Inst Technol, Midori Ku, Yokohama, Kanagawa 2268503, Japan	Tokyo Institute of Technology	Toyoda, T (corresponding author), Tokyo Inst Technol, Midori Ku, R2-52,4259 Nagatsuta, Yokohama, Kanagawa 2268503, Japan.	t.toyodajp@gmail.com; hasegawa.o.aa@m.titech.ac.jp						Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; HE X, 2006, P 9 EUR C COMP VIS, V1, P38; He XM, 2004, PROC CVPR IEEE, P695; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Kumar S, 2005, IEEE I CONF COMP VIS, P1284; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; LEVIN A, 2006, P EUR C COMP VIS, V4, P581; SHOTTON J, 2006, P EUR C COMP VIS, V1, P1, DOI DOI 10.1007/11744023_; TORRALBA A, 2005, ADV NEURAL INFORM PR, V17, P1401; TOYODA T, 2006, P IEEE CS C COMP VIS, V1, P1106	12	49	54	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1483	1489		10.1109/TPAMI.2008.105	http://dx.doi.org/10.1109/TPAMI.2008.105			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566500				2022-12-18	WOS:000256679700013
J	Markou, M; Singh, S				Markou, Markos; Singh, Sameer			A neural network-based novelty detector for image sequence analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						novelty detection; neural networks; video analysis; object classification; feature extraction and selection	INTRUSION	This paper proposes a new model of "novelty detection" for image sequence analysis using neural networks. This model uses the concept of artificially generated negative data to form closed decision boundaries using a multilayer perceptron. The neural network output is novelty filtered by thresholding the output of multiple networks (one per known class) to which the sample is input and clustered for determining which clusters represent novel classes. After labeling these novel clusters, new networks are trained on this data. We perform experiments with video-based image sequence data containing a number of novel classes. The performance of the novelty filter is evaluated using two performance metrics and we compare our proposed model on the basis of these with five baseline novelty detectors. We also discuss the results of retraining each model after novelty detection. On the basis of Chi-square performance metric, we prove at 5 percent significance level that our optimized novelty detector performs at the same level as an ideal novelty detector that does not make any mistakes.	Univ Loughborough, Res Sch Informat, Loughborough LE11 3TU, Leics, England	Loughborough University	Markou, M (corresponding author), Gordiou Desmou 35, CY-6045 Larnax, Cyprus.	m.markou@exeter.ac.uk; s.singh@lboro.ac.uk						BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; Bishop, 1995, NEURAL NETWORKS PATT; BISHOP CM, 1994, IEE P-VIS IMAGE SIGN, V141, P217, DOI 10.1049/ip-vis:19941330; BYUNGHO H, 1999, P IEEE IJCNN C, V5, P3086; Dasgupta D, 2000, IEEE SYS MAN CYBERN, P125, DOI 10.1109/ICSMC.2000.884976; Dasgupta D., 1996, P INT C INT SYST; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; Diaz I, 2002, IEEE IJCNN, P2070, DOI 10.1109/IJCNN.2002.1007460; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046; Fahlman S.E., 1990, ADV NEURAL INFORM PR, P524; FLECK MM, 1996, P EUR C COMP VIS, V2, P592; Ford A., 1998, COLOR SPACE CONVERSI; Guh RS, 1999, ARTIF INTELL ENG, V13, P413, DOI 10.1016/S0954-1810(99)00022-9; Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; King SP, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON CONTROL APPLICATIONS, VOLS 1 & 2, P221, DOI 10.1109/CCA.2002.1040189; Ko H, 2000, IEEE T NEURAL NETWOR, V11, P1152, DOI 10.1109/72.870046; Kohonen T, 1988, SELF ORG ASSOCIATIVE; KOHONEN T, 2001, SELF ORGANISING MAPS; KWOK T, 1999, IEEE T NEURAL NETWOR, V8, P1131; LAWS KL, 1980, 940 U SO CAL; LeCun Y., 1990, ADV NEURAL INFORM PR, P396, DOI DOI 10.1111/DSU.12130; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Manikopoulos C, 2002, IEEE COMMUN MAG, V40, P76, DOI 10.1109/MCOM.2002.1039860; Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018; MARKOU M, 2005, THESIS U EXETER UK; Mindru F., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P368, DOI 10.1109/CVPR.1999.786965; Nabney I. T., 2002, ADV PTRN RECOGNIT; ODIN T, 2000, P CONC MON DIAGN ENG; Plataniotis K., 2000, DIGITAL SIGNAL PROC; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Ryan J, 1998, ADV NEUR IN, V10, P943; Scholkopf B., 2001, LEARNING KERNELS SUP; Singh S, 2004, IEEE T KNOWL DATA EN, V16, P396, DOI 10.1109/TKDE.2004.1269665; SINGH S, 2003, P WORKSH ART NEUR NE, P108; Sonka M., 2014, IMAGE PROCESSING ANA; TARASSENKO L, 1909, P IEE COLL COND MON, P41; TARASSENKO L, 1995, P 4 IEE INT C ART NE, P442; Tax D. M. J., 1998, Advances in Pattern Recognition. Joint IAPR International Workshops SSPR'98 and SPR'98. Proceedings, P593, DOI 10.1007/BFb0033283; Terrillon J. C., 2002, P INT C VIS INT, P369; Thompson BB, 2002, IEEE IJCNN, P2878, DOI 10.1109/IJCNN.2002.1007605; Umbaugh SE., 1998, COMPUTER VISION IMAG; UNSER M, 1986, SIGNAL PROCESS, V11, P61, DOI 10.1016/0165-1684(86)90095-2; VASCONCELOS GC, 1994, P NIPS WORKSH NOV DE; Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731	48	49	53	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2006	28	10					1664	1677		10.1109/TPAMI.2006.196	http://dx.doi.org/10.1109/TPAMI.2006.196			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	071ME	16986546				2022-12-18	WOS:000239605500009
J	Ramanan, D; Forsyth, DA; Barnard, K				Ramanan, Deva; Forsyth, David A.; Barnard, Kobus			Building models of animals from video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tracking; video analysis; object recognition; texture; shape	TRACKING	This paper argues that tracking, object detection, and model building are all similar activities. We describe a fully automatic system that builds 2D articulated models known as pictorial structures from videos of animals. The learned model can be used to detect the animal in the original video - in this sense, the system can be viewed as a generalized tracker ( one that is capable of modeling objects while tracking them). The learned model can be matched to a visual library; here, the system can be viewed as a video recognition algorithm. The learned model can also be used to detect the animal in novel images - in this case, the system can be seen as a method for learning models for object recognition. We find that we can significantly improve the pictorial structures by augmenting them with a discriminative texture model learned from a texture library. We develop a novel texture descriptor that outperforms the state- of- the- art for animal textures. We demonstrate the entire system on real video sequences of three different animals. We show that we can automatically track and identify the given animal. We use the learned models to recognize animals from two data sets; images taken by professional photographers from the Corel collection, and assorted images from the Web returned by Google. We demonstrate quite good performance on both data sets. Comparing our results with simple baselines, we show that, for the Google set, we can detect, localize, and recover part articulations from a collection demonstrably hard for object recognition.	Toyota Technol Inst, Chicago, IL 60637 USA; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA	Toyota Technological Institute - Chicago; University of Illinois System; University of Illinois Urbana-Champaign; University of Arizona	Ramanan, D (corresponding author), Toyota Technol Inst, Chicago, IL 60637 USA.	ramanan@tti-c.org; daf@cs.uiuc.edu; kobus@cs.arizona.edu		Barnard, Kobus/0000-0002-8568-9518				BERG A, 2001, P IEEE C COMP VIS PA; Blackman S. S., 1999, DESIGN ANAL MODERN T; BRAND M, 2001, P COMP VIS PATT REC; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; BURL M, 1998, P EUR C COMP VIS, P628; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cootes Timothy F, 1998, P EUR C COMP VIS; Coughlan J. M., 2002, P EUR C COMP VIS; Dana KJ, 1997, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.1997.609313; DORKO G, UNPUB IEEE T PATTERN; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; Felzenszwalb P. F., 2005, INT J COMPUTER VISIO, V61; Fergus R., 2003, P IEEE C COMP VIS PA; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; GAVRILA DM, 2000, P EUR C COMP VIS, P37; Grenander U., 1991, HANDS PATTERN THEORE; Hemera Technologies Inc, 2002, HEM PHOT OBJ; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; Indyk P, 1998, P 30 S THEOR COMP; IOFFE S, 2001, INT J COMPUTER VISIO; IOFFE S, 1999, ICCV, P1092; Ioffe S., 2001, P INT C COMP VIS; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; JOLIC N, 2001, P IEEE C COMP VIS PA; KUMAR MP, 2004, P IND C VIS GRAPH IM; LAZEBNIK S, 2003, P INT C COMP VIS; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; LEUNG T, 1995, P INT C COMP VIS; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Mori G., 2002, P EUR C COMP VIS; Nilsback M. E., 2004, P IEEE C COMP VIS PA; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; PHILLIPS PJ, 2002, P INT C AUT FAC GEST; Ramanan D., 2005, THESIS U CALIFORNIA; Ramanan D., 2003, P IEEE C COMP VIS PA; RAMANAN D, 2003, P INT C COMP VIS; RAMANAN D, 2005, P IEEE C COMP VIS PA; ROHR K, 1993, P IEEE C COMP VIS PA, P9; Rother C., 2004, P ACM SIGGRAPH; SCHMID C, 2001, P COMP VIS PATT REC; Sidenbladh H., 2000, P EUR C COMP VIS; Song Y, 2000, PROC CVPR IEEE, P810, DOI 10.1109/CVPR.2000.855904; Sullivan J., 2002, P EUR C COMP VIS; TORRESANI L, 2001, IEEE C COMP VIS PATT; Toyama K, 2002, INT J COMPUT VISION, V48, P9, DOI 10.1023/A:1014899027014; VARMA M, 2003, P IEEE C COMP VIS PA; Viola Paul, 2001, PROC CVPR IEEE; WAINWRIGHT M, 2001, P ADV NEURAL INFORMA, V14; Weber M, 2000, LECT NOTES COMPUT SC, V1842, P18	51	49	49	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1319	1334		10.1109/TPAMI.2006.155	http://dx.doi.org/10.1109/TPAMI.2006.155			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886866	Green Submitted			2022-12-18	WOS:000238162400012
J	Beare, R				Beare, R			A locally constrained watershed transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; constrained watershed transform; constrained region growing; covered cost; Minkowski cost; seeded region growing.	GEODESIC ACTIVE CONTOURS	The watershed transform, from mathematical morphology, is a powerful and flexible tool for segmentation. However, it does not allow a priori knowledge relating to characteristics of region boundaries to be included in the way that other approaches do. This paper introduces the locally constrained watershed transform, which includes border constraints by modifying the underlying path definition upon which the watershed transform depends. This approach maintains many of the desirable properties of the watershed transform, such as well-defined stopping conditions and efficient implementation, while offering more stable segmentation in the presence of noisy or incomplete boundaries.	Monash Univ, Monash Med Ctr, Dept Med, Clayton, Vic 3168, Australia	Monash University	Beare, R (corresponding author), Monash Univ, Monash Med Ctr, Dept Med, 246 Clayton Rd, Clayton, Vic 3168, Australia.	richard.beare@med.monash.edu.au		Beare, Richard/0000-0002-7530-5664				ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; BEARE RJ, 2002, P 6 INT S ISMM 02, P91; Beucher S., 1993, MATH MORPHOLOGY IMAG, P433, DOI DOI 10.1201/9781482277234-12; Beucher S., 1979, INT WORKSH IM PROC R; Breen EJ, 1994, COMP IMAG VIS, V2, P249; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533; HIGGINS WE, 1993, COMPUT MED IMAG GRAP, V17, P387, DOI 10.1016/0895-6111(93)90033-J; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MEIJSTER A, 2004, THESIS U GRONINGEN; Meyer F, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P69; MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4; Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M; Nguyen HT, 2003, IEEE T PATTERN ANAL, V25, P330, DOI 10.1109/TPAMI.2003.1182096; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187; Sethian J. A., 1999, LEVEL SET METHODS FA; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; ZANOGUERA F, 1999, P INT C IM PROC	20	49	53	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2006	28	7					1063	1074		10.1109/TPAMI.2006.132	http://dx.doi.org/10.1109/TPAMI.2006.132			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	041AG	16792096				2022-12-18	WOS:000237424400004
J	Schindler, K; Suter, D				Schindler, K; Suter, D			Two-view multibody structure-and-motion with outliers through model selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dynamic scenes; structure-and-motion; model selection; 3D motion segmentation	EPIPOLAR GEOMETRY; SEGMENTATION; RECONSTRUCTION; ALGORITHM; SCENE	Multibody structure- and- motion ( MSaM) is the problem to establish the multiple- view geometry of several views of a 3D scene taken at different times, where the scene consists of multiple rigid objects moving relative to each other. We examine the case of two views. The setting is the following: Given are a set of corresponding image points in two images, which originate from an unknown number of moving scene objects, each giving rise to a motion model. Furthermore, the measurement noise is unknown, and there are a number of gross errors, which are outliers to all models. The task is to find an optimal set of motion models for the measurements. It is solved through Monte- Carlo sampling, careful statistical analysis of the sampled set of motion models, and simultaneous selection of multiple motion models to best explain the measurements. The framework is not restricted to any particular model selection mechanism because it is developed from a Bayesian viewpoint: Different model selection criteria are seen as different priors for the set of moving objects, which allow one to bias the selection procedure for different purposes.	Monash Univ, Dept Elect & Comp Syst Engn, Clayton, Vic 3800, Australia	Monash University	Schindler, K (corresponding author), Monash Univ, Dept Elect & Comp Syst Engn, Clayton Campus,Wellington Rd, Clayton, Vic 3800, Australia.	konrad.schindler@eng.monash.edu.au; d.suter@eng.monash.edu.au		Suter, David/0000-0001-6306-3023; Pauldurai, Jona/0000-0002-7217-0872				Akaike H., 1973, 2 INT S INF THEOR, P267, DOI DOI 10.1007/978-1-4612-1694-0_15; Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377; Bretthorst GL, 1996, FUND THEOR PHYS, V62, P1; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; Forsyth David A, 2012, COMPUTER VISION MODE; George EI, 2000, BIOMETRIKA, V87, P731, DOI 10.1093/biomet/87.4.731; Glover F., 1993, MODERN HEURISTIC TEC, P70; Han M, 2000, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2000.854908; HARTLEY R, 1992, P 2 EUR C COMP VIS, P579; HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Huang K, 2004, PROC CVPR IEEE, P631; Huber PJ, 1981, ROBUST STAT; Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770; Kanatani K, 2004, IEEE T PATTERN ANAL, V26, P1307, DOI 10.1109/TPAMI.2004.93; Kanatani K, 1998, INT J COMPUT VISION, V26, P171, DOI 10.1023/A:1007948927139; KANATANI K, 1996, STAT OPTIMATION GEOM; LEONARDIS A, 1995, INT J COMPUT VISION, V14, P253, DOI 10.1007/BF01679685; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Ma Y., 2004, INVITATION 3 D VISIO; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; MATSUNAGA C, 2000, P 6 EUR C COMP VIS, V2; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; Schiavetti A, 2005, J PEDIAT HEMATOL ONC, V27, P3, DOI 10.1097/01.mph.0000149238.60772.7f; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X; Shashua A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P592, DOI 10.1109/ICCV.2001.937680; STRIETZEL M, 1995, TRANSPUT OCCAM ENG S, P90; STURM P, 2002, P 7 EUR C COMP VIS, P867; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tong WS, 2004, IEEE T PATTERN ANAL, V26, P1167, DOI 10.1109/TPAMI.2004.72; Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; TORR PHS, 1999, MSRTR9916; Vidal R, 2004, LECT NOTES COMPUT SC, V3021, P1; VIDAL R, 2002, P ECCV WORKSH VIS MO; VIDAL R, 2003, P IEEE C COMP VIS PA; WALLACE CS, 1968, COMPUT J, V11, P185, DOI 10.1093/comjnl/11.2.185; Wand M.P., 1995, KERNEL SMOOTHING; Wang HZ, 2004, LECT NOTES COMPUT SC, V3023, P107; Wang HZ, 2004, INT J COMPUT VISION, V59, P139, DOI 10.1023/B:VISI.0000022287.61260.b0; Wolf L, 2001, PROC CVPR IEEE, P263; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2	46	49	49	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					983	995		10.1109/TPAMI.2006.130	http://dx.doi.org/10.1109/TPAMI.2006.130			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724591				2022-12-18	WOS:000236734400011
J	Torsello, A; Hidovic-Rowe, D; Pelillo, M				Torsello, A; Hidovic-Rowe, D; Pelillo, M			Polynomial-time metrics for attributed trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						metrics; tree matching; polynomial; time algorithms; shape recognition	EDITING DISTANCE; GRAPHS; SHAPE; RECOGNITION	We address the problem of comparing attributed trees and propose four novel distance measures centered around the notion of a maximal similarity common subtree. The proposed measures are general and defined on trees endowed with either symbolic or continuous- valued attributes and can be applied to rooted as well as unrooted trees. We prove that our measures satisfy the metric constraints and provide a polynomial- time algorithm to compute them. This is a remarkable and attractive property, since the computation of traditional edit- distance- based metrics is, in general, NP- complete, at least in the unordered case. We experimentally validate the usefulness of our metrics on shape matching tasks and compare them with ( an approximation of) edit- distance.	Univ Ca Foscari di Venezia, Dipartimento Informat, I-30172 Venice, Italy; Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England	Universita Ca Foscari Venezia; University of Birmingham	Torsello, A (corresponding author), Univ Ca Foscari di Venezia, Dipartimento Informat, Via Torino 155, I-30172 Venice, Italy.	torsello@dsi.unive.it; D.Hidovic@cs.bham.ac.uk; pelillo@dsi.unive.it	Torsello, Andrea/K-6352-2016	Torsello, Andrea/0000-0001-9189-4924				Ahuja R. K., 1993, NETWORK FLOWS; Barrow H. G., 1976, Information Processing Letters, V4, P83, DOI 10.1016/0020-0190(76)90049-1; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7; Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; ESHERA MA, 1986, IEEE T PATTERN ANAL, V8, P604, DOI 10.1109/TPAMI.1986.4767835; Fernandez ML, 2001, PATTERN RECOGN LETT, V22, P753, DOI 10.1016/S0167-8655(01)00017-4; Hidovic D, 2004, INT J PATTERN RECOGN, V18, P299, DOI 10.1142/S0218001404003216; Ioffe S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P690, DOI 10.1109/ICCV.2001.937589; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Kaizhong Zhang, 1996, International Journal of Foundations of Computer Science, V7, P43, DOI 10.1142/S0129054196000051; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; Matula D. W., 1978, ANN DISCRETE MATH, V2, P91; MOAYER B, 1986, IEEE T PATTERN ANAL, V8, P376, DOI 10.1109/TPAMI.1986.4767798; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; Pavan M, 2003, PROC CVPR IEEE, P145; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; Peura M., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P1160, DOI 10.1109/ICIAP.1999.797760; SAMET H, 1982, IEEE T PATTERN ANAL, V4, P298, DOI 10.1109/TPAMI.1982.4767246; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; SHAPIRO LG, 1982, IEEE T PATTERN ANAL, V4, P595, DOI 10.1109/TPAMI.1982.4767312; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shokoufandeh A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P491, DOI 10.1109/CVPR.1999.784726; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; TANAKA E, 1994, IEEE T PATTERN ANAL, V16, P1233, DOI 10.1109/34.387483; Torsello A, 2004, INT C PATT RECOG, P467, DOI 10.1109/ICPR.2004.1334263; Torsello A, 2001, LECT NOTES COMPUT SC, V2134, P438; TORSELLO A, 2004, P 8 EUR C COMP VIS, V4, P414; TORSELLO A, 2001, P INT WORKSH VIS FOR, P260; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; Valiente G, 2001, EIGHTH SYMPOSIUM ON STRING PROCESSING AND INFORMATION RETRIEVAL, PROCEEDINGS, P212, DOI 10.1109/SPIRE.2001.989761; VALIENTE G, 2002, ALGORITHMS TREES GRA; Wallis WD, 2001, PATTERN RECOGN LETT, V22, P701, DOI 10.1016/S0167-8655(01)00022-8; Wang JTL, 2001, PATTERN RECOGN, V34, P127, DOI 10.1016/S0031-3203(99)00199-5; Wang JTL, 2002, PATTERN RECOGN, V35, P473, DOI 10.1016/S0031-3203(01)00055-3; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; ZHANG KZ, 1989, SIAM J COMPUT, V18, P1245, DOI 10.1137/0218082; ZHANG KZ, 1992, INFORM PROCESS LETT, V42, P133, DOI 10.1016/0020-0190(92)90136-J; Zhang KZ, 1996, ALGORITHMICA, V15, P205, DOI 10.1007/BF01975866; Zhu SC, 1996, INT J COMPUT VISION, V20, P187	44	49	48	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1087	1099		10.1109/TPAMI.2005.146	http://dx.doi.org/10.1109/TPAMI.2005.146			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013756	Green Submitted			2022-12-18	WOS:000229024300008
J	Lin, MH; Tomasi, C				Lin, MH; Tomasi, C			Surfaces with occlusions from layered stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						binocular stereo vision; energy minimization; graph cuts; hybrid system; smooth surfaces; surface fitting; boundary localization; sharp discontinuities; quantitative comparison	ALGORITHM	We propose a new binocular stereo algorithm that estimates scene structure as a collection of smooth surface patches. The disparities within each patch are modeled by a continuous-valued spline, while the extent of each patch is represented via a pixelwise partitioning of the images. Disparities and extents are alternately estimated in an iterative, energy minimization framework. Experimental results demonstrate that, for scenes consisting of smooth surfaces, the proposed algorithm significantly improves upon the state of the art.	Acuity Technol, Menlo Pk, CA 94025 USA; Duke Univ, Dept Comp Sci, Levine Sci Res Ctr, Sect D, Durham, NC 27708 USA	Duke University	Lin, MH (corresponding author), Acuity Technol, 3475 Edison Way,Bldg P, Menlo Pk, CA 94025 USA.	michelin@cs.stanford.edu; tomasi@cs.duke.edu						Baker S, 1998, PROC CVPR IEEE, P434, DOI 10.1109/CVPR.1998.698642; BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683; ISHIKAWA H, 1998, P EUR C COMP VIS, V1, P232; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Lin M., 2002, THESIS STANFORD U; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184	21	49	55	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					1073	1078		10.1109/TPAMI.2004.54	http://dx.doi.org/10.1109/TPAMI.2004.54			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641736	Green Submitted			2022-12-18	WOS:000221872400010
J	Tino, P; Nabney, I				Tino, P; Nabney, I			Hierarchical GTM: Constructing localized nonlinear projection manifolds in a principled way	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hierarchical probabilistic model; generative topographic mapping; data visualization; EM algorithm; density estimation; directional curvature	ALGORITHM	It has been argued that a single two-dimensional visualization plot may not be sufficient to capture all of the interesting aspects of complex data sets and, therefore, a hierarchical visualization system is desirable. In this paper, we extend an existing locally linear hierarchical visualization system PhiVis [1] in several directions: 1) We allow for nonlinear projection manifolds. The basic building block is the Generative Topographic Mapping (GTM). 2) We introduce a general formulation of hierarchical probabilistic models consisting of local probabilistic models organized in a hierarchical tree. General training equations are derived, regardless of the position of the model in the tree. 3) Using tools from differential geometry, we derive expressions for local directional curvatures of the projection manifold. Like PhiVis, our system is statistically principled and is built interactively in a top-down fashion using the EM algorithm. It enables the user to interactively highlight those data in the ancestor visualization plots which are captured by a child model. We also incorporate into our system a hierarchical, locally selective representation of magnification factors and directional curvatures of the projection manifolds. Such information is important for further refinement of the hierarchical visualization plot, as well as for controlling the amount of regularization imposed on the local models. We demonstrate the principle of the approach on a toy data set and apply our system to two more complex 12- and 18-dimensional data sets.	Aston Univ, Neural Computat Res Grp, Birmingham B4 7ET, W Midlands, England	Aston University	Tino, P (corresponding author), Aston Univ, Neural Computat Res Grp, Birmingham B4 7ET, W Midlands, England.	tinop@aston.ac.uk	Tino, Peter/Z-5748-2019	Tino, Peter/0000-0003-2330-128X; Nabney, Ian/0000-0001-7382-2855; Nabney, Ian T/0000-0003-1513-993X				Amari S.-i., 1985, DIFFERENTIAL GEOMETR, V28; AURENHAMMER F, 1991, ACM COMPUT SURV, V23, P345, DOI DOI 10.1145/116873.116880; BATES DM, 1980, J ROY STAT SOC B MET, V42, P1; Bishop, 1995, NEURAL NETWORKS PATT; Bishop CM, 1998, NEUROCOMPUTING, V21, P203, DOI 10.1016/S0925-2312(98)00043-5; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Bishop CM, 1998, IEEE T PATTERN ANAL, V20, P281, DOI 10.1109/34.667885; BISHOP CM, 1997, P IEE 5 INT C ART NE, P64; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Horn R. A., 1986, MATRIX ANAL; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Miikkulainen R., 1990, Connection Science, V2, P83, DOI 10.1080/09540099008915664; Press WH, 1988, NUMERICAL RECIPES C; ROSE K, 1990, PHYS REV LETT, V65, P945, DOI 10.1103/PhysRevLett.65.945; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; ULTSCH A, 1990, INTERNATIONAL NEURAL NETWORK CONFERENCE, VOLS 1 AND 2, P305; ULTSCH A, 1993, INFORMATION CLASSIFI, P301; VERSINO C, 1996, P ICONIP 96 INT C NE, V2, P921; VERSINO C, 1996, P ICANN 96 INT C ART, P221; Vesanto J., 1999, Intelligent Data Analysis, V3, P111, DOI 10.1016/S1088-467X(99)00013-X; Wild C.J., 1989, NONLINEAR REGRESSION	23	49	53	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2002	24	5					639	656		10.1109/34.1000238	http://dx.doi.org/10.1109/34.1000238			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	544XU		Green Submitted, Green Accepted			2022-12-18	WOS:000175187800006
J	Zhang, YF; Yang, YH				Zhang, YF; Yang, YH			Multiple illuminant direction detection with application to image synthesis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; critical point; illuminant direction detection; image synthesis	SHAPE	In the early 1980s, Pentland observed that the human's eye is sensitive to the change of intensities. On an image of a smooth surface, the change of intensities is maximal whenever the illuminant direction is perpendicular to the normal of the surface. This motivates us to introduce the concept of critical points, where the surface normal is perpendicular to some light source direction. Apparently, the illuminant direction has a simple geometric relationship with the corresponding critical points. In this paper, for simplicity reasons, we restrict our discussions to the shading of a Lambertian sphere of known size in a multiple distant light source environment. A novel global representation of the intensity function is derived. Based on this intensity characterization, the least-squares and iteration techniques are used to determine critical points and, thus, the light source directions and their intensities if certain conditions are satisfied. The performance of this new approach is evaluated using both synthetic images and real images. As an application, we use it as a tool to determine light sources in real image synthesis. The experimental results show that this technique can be used to superimpose synthetic objects with a real scene.	Trident Microsyst Inc, Sunnyvale, CA 94085 USA; Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada	University of Alberta	Zhang, YF (corresponding author), Trident Microsyst Inc, 1090 E Arque Ave, Sunnyvale, CA 94085 USA.	yzhang@tridentmicro.com; yang@cs.ualberta.ca						BROOKS MJ, 1985, P INT JOINT C ART IN, P932; CHOJNACKI W, 1994, J OPT SOC AM A, V11, P118, DOI 10.1364/JOSAA.11.000118; Chojnacki W., 1994, Proceedings of the 7th Australian Joint Conference on Artificial Intelligence. Artificial Intelligence. AI'94. Sowing the Seeds for the Future, P530; Debevec P., 1998, ANN C SERIES, P189; GIBBINS D, 1994, THESIS FLINDERS U S; HOUGEN DR, 1993, P INT C COMP VIS, P148; Kim CY, 1998, J OPT SOC AM A, V15, P2341, DOI 10.1364/JOSAA.15.002341; LEE CH, 1985, ARTIF INTELL, V26, P125, DOI 10.1016/0004-3702(85)90026-8; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; Sato I, 1999, IEEE T VIS COMPUT GR, V5, P1, DOI 10.1109/2945.764865; SATO I, 1999, IEEE C CVPR JUN, P306; WEINSHALL D, 1990, 1264 MIT; YANG Y, 1991, IEEE P COMP VIS PATT, P534; Yang Y.-H., 1998, Proceedings. Vision Interfaces '98, P271; Zhang YF, 2000, PROC CVPR IEEE, P269, DOI 10.1109/CVPR.2000.855829; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658	17	49	53	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					915	920		10.1109/34.946995	http://dx.doi.org/10.1109/34.946995			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH					2022-12-18	WOS:000170283300012
J	Reed, MK; Allen, PK				Reed, MK; Allen, PK			Constraint-based sensor planning for scene modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D scene reconstruction; model acquisition; sensor planning; active vision		We describe an automated scene modeling system that consists of two components operating in an interleaved fashion: an incremental modeler that builds solid models from range imagery and a sensor planner that analyzes the resulting model and computes the next sensor position. This planning component is target-driven and computes sensor positions using model information about the imaged surfaces and the unexplored space in a scene. The method is shape-independent and uses a continuous-space representation that preserves the accuracy of sensed data. It is able to completely acquire a scene by repeatedly planning sensor positions, utilizing a partial model to determine volumes of visibility for contiguous areas of unexplored scene. These visibility volumes are combined with sensor placement constraints to compute sets of occlusion-free sensor positions that are guaranteed to improve the quality of the model. We show results for the acquisition of a scene that includes multiple, distinct objects with high occlusion.	Blue Sky Studios, White Plains, NY 10601 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Reed, MK (corresponding author), Blue Sky Studios, 44 S Broadway, White Plains, NY 10601 USA.	reed@blueskystudios.com; allen@cs.columbia.edu						Abrams S, 1999, INT J ROBOT RES, V18, P267, DOI 10.1177/02783649922066204; BANTA JE, 1995, P INT SYST ADV MAN S; CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043; Cohen J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P119, DOI 10.1145/237170.237220; Connolly C., 1985, 1985 IEEE INT C ROBO, P432; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Hoover A., 1994, Proceedings of the 1994 Second CAD-Based Vision Workshop (Cat. No.94TH0595-9), P74, DOI 10.1109/CADVIS.1994.284514; KUTULAKOS KN, 1994, THESIS U WISCONSIN; MAVER J, 1990, P DARPA IMAGE UNDERS, P482; PITO R, 1995, P SPIE S INT SYST AD; REED M, 1997, P IEEE C COMP VIS PA; Reed MK, 1999, IMAGE VISION COMPUT, V17, P99, DOI 10.1016/S0262-8856(98)00114-0; SOBH TM, 1995, COMPUT VIS IMAGE UND, V61, P468, DOI 10.1006/cviu.1995.1035; Stamos I, 1998, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.1998.698650; TARABANIS K, 1990, P 13 IASTED INT S RO; TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940; TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P72, DOI 10.1109/70.345939; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Whaite P., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P3, DOI 10.1109/CVPR.1992.223235; WHAITE P, 1997, IEEE T PATTERN ANAL, V19; WHEELER M, 1998, P 6 INT C COMP VIS	21	49	52	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2000	22	12					1460	1467		10.1109/34.895979	http://dx.doi.org/10.1109/34.895979			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	383UR		Green Submitted			2022-12-18	WOS:000165901900009
J	Govindu, V; Shekhar, C				Govindu, V; Shekhar, C			Alignment using distributions of local geometric properties	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pose estimation; correspondenceless image alignment; geometric properties; statistical distributions	IMAGE REGISTRATION; MOTION; CORRESPONDENCES	We describe a framework for aligning images without needing to establish explicit feature correspondences. We assume that the geometry between the two images can be adequately described by an affine transformation and develop a framework that uses the statistical distribution of geometric properties of image contours to estimate the relevant transformation parameters. The estimates obtained using the proposed method are robust to illumination conditions, sensor characteristics, etc., since image contours are relatively invariant to these changes. Moreover, the distributional nature of our method alleviates some of the common problems due to contour fragmentation, occlusion, clutter, etc. We provide empirical evidence of the accuracy and robustness of our algorithm. Finally, we demonstrate our method on both real and synthetic images, including multisensor image pairs.	Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Govindu, V (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.	venu@cfar.umd.edu; shekhar@cfar.umd.edu						BASU A, 1990, INT J ROBOT RES, V9, P35, DOI 10.1177/027836499000900503; BERGEN JR, 1992, P EUR C COMP VIS, P237; BLAKE A, 1990, ARTIF INTELL, P323; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; BRUCKSTEIN AM, 1993, CVGIP-IMAG UNDERSTAN, V58, P49, DOI 10.1006/ciun.1993.1031; Chou T., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P534; FLUSSER J, 1994, IEEE T GEOSCI REMOTE, V32, P382, DOI 10.1109/36.295052; FUA P, 1994, P DARPA IM UND WORKS, P981; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Irani M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P959, DOI 10.1109/ICCV.1998.710832; IRANI M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P454, DOI 10.1109/CVPR.1994.323866; Kumar S, 1996, PROC CVPR IEEE, P594, DOI 10.1109/CVPR.1996.517133; LI H, 1995, IEEE T IMAGE PROCESS, V4, P320, DOI 10.1109/83.366480; MEER P, 1990, P INT C PATTERN RECO, VC, P121; PEI SC, 1994, IMAGE VISION COMPUT, V12, P475, DOI 10.1016/0262-8856(94)90001-9; SATO J, 1994, P 3 EUR C COMP VIS, VB, P165; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; Shekhar C, 1999, PATTERN RECOGN, V32, P39, DOI 10.1016/S0031-3203(98)00089-2; VIOLA P, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P16, DOI 10.1109/ICCV.1995.466930; WEISS I, 1992, ARTIF INT, P135; WITKIN A, 1981, ARTIFICIAL INTELLIGE, V17	21	49	50	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1999	21	10					1031	1043		10.1109/34.799909	http://dx.doi.org/10.1109/34.799909			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	248DB					2022-12-18	WOS:000083259100006
J	MATHENY, A; GOLDGOF, DB				MATHENY, A; GOLDGOF, DB			THE USE OF 3-DIMENSIONAL AND 4-DIMENSIONAL SURFACE HARMONICS FOR RIGID AND NONRIGID SHAPE RECOVERY AND REPRESENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SPHERICAL HARMONICS; SURFACE HARMONICS; RIGID MOTION; SHAPE RECOVERY; SHAPE REPRESENTATION		The use of spherical harmonics for rigid and nonrigid shape representation is well known, This paper extends the method to surface harmonics defined on domains other than the sphere and to four-dimensional spherical harmonics, These harmonics enable us to represent shapes which cannot be represented as a global function in spherical coordinates, but can be in other coordinate systems, Prolate and oblate spheroidal harmonics and cylindrical harmonics are examples of surface harmonics which we find useful, Nonrigid shapes are represented as functions of space and time either by including the time-dependence as a separate factor or by using four-dimensional spherical harmonics, This paper compares the errors of fitting various surface harmonics to an assortment of synthetic and real data samples, both rigid and nonrigid. In all cases we use a linear least-squares approach to find the best fit to given range data. It is found that for some shapes there is a variation among geometries in the number of harmonics functions needed to achieve a desired accuracy, In particular, it was found that four-dimensional spherical harmonics provide an improved model of the motion of the left ventricle of the heart.			MATHENY, A (corresponding author), UNIV S FLORIDA,DEPT COMP SCI & ENGN,TAMPA,FL 33620, USA.		Goldgof, Dmitry/ABF-1366-2020					Arfken G., 1985, MATH METHODS PHYS, V3rd, P957; Arscott FM., 1964, PERIODIC DIFFERENTIA; ARSCOTT FM, 1962, TABLES LAME POLYNOMI; Ballard D.H., 1982, COMPUTER VISION; BANDER M, 1966, REV MOD PHYS, V38, P330, DOI 10.1103/RevModPhys.38.330; Bateman H, 1955, HIGHER TRANSCENDENTA; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; BOWYER KW, IN PRESS HDB PATTERN, V2; BUTKOV E, 1968, MATH PHYSICS; CHEN CW, 1994, IEEE T PATTERN ANAL, V16, P342, DOI 10.1109/34.277589; CHEN CW, 1990, 3RD P INT C COMP VIS; CHEN CW, 1990, INT J IMAG SYST TECH, V2, P385; CHEN SS, 1986, COMPUT VISION GRAPH, V36, P175, DOI 10.1016/0734-189X(86)90075-7; COPPINI G, 1987, TIME VARYING IMAGE P; GOLDGOF DB, 1988, P IEEE CS C COMPUTER; GOLUB GH, 1971, HDB AUTOMATIC COMPUT, V2; HANSON AJ, 1988, COMPUT VISION GRAPH, V44, P191, DOI 10.1016/S0734-189X(88)80005-7; Hobson EW., 1931, THEORY SPHERICAL ELL; KAMBHAMETTU C, 1992, SPIE SPSE S ELECTRON, V1450, P311; Lebedev NN., 1965, SPECIAL FUNCTIONS TH, DOI [10.1063/1.3047047, DOI 10.1063/1.3047047]; MacRobert T.M., 1967, SPHERICAL HARMONICS; MISHRA SK, 1991, P IEEE WORKSHOP VISU; Press WH, 1988, NUMERICAL RECIPES C; RIOUX M, 1988, NRCC 3 DIMENSIONAL I; ROBB RA, 1983, P IEEE, V71, P308, DOI 10.1109/PROC.1983.12589; SCHUDY RB, 1979, 6 C COMP APPL RAD CO, P366; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; Stratton J.A., 1956, SPHEROIDAL WAVE FUNC; YETTRAM AL, 1982, J BIOMECH ENG-T ASME, V104, P148, DOI 10.1115/1.3138329; YOUNG AA, 1989, COMPUT VISION GRAPH, V47, P111, DOI 10.1016/0734-189X(89)90059-5; [No title captured]; [No title captured]	33	49	51	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1995	17	10					967	981		10.1109/34.464561	http://dx.doi.org/10.1109/34.464561			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RX289					2022-12-18	WOS:A1995RX28900004
J	ENNESSER, F; MEDIONI, G				ENNESSER, F; MEDIONI, G			FINDING WALDO, OR FOCUS OF ATTENTION USING LOCAL COLOR INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						OBJECT RECOGNITION; FOCUS OF ATTENTION; COLOR IMAGES; COLOR QUANTIZATION; COLOR HISTOGRAMS		We present a method to locate an ''object'' in a color image, or more precisely, to select a set of likely locations for the object. The model is assumed to be of known color distribution, which permits the use color-space processing. A new method is presented, which exploits more information than the previous Backprojection Algorithm of Swain and Ballard at a competitive complexity. Precisely, the new algorithm is based on matching local histograms with the model, instead of directly replacing pixels with a confidence that they belong to the object. We prove that a simple version of this algorithm degenerates into Backprojection in the worst case. In addition, we show how to estimate the scale of the model. Results are shown on pictures digitized from the famous ''Where is Waldo'' books. issues concerning the optimal choice of a color space and its quantization are carefully considered and studied in this application. We also propose to use co-occurrence histograms to deal with cases where important color variations can be expected.			ENNESSER, F (corresponding author), UNIV SO CALIF,INST ROBOT & INTELLIGENT SYST,LOS ANGELES,CA 90089, USA.							Ballard D.H., 1982, COMPUTER VISION; BELL GH, 1965, AD699616; Duda R.O., 1973, J ROYAL STAT SOC SER; FINLAYSON G, 1993, P IEEE INT C COMPUTE; Grimson W. E. L., 1990, OBJECT RECOGNITION C; HEALEY GE, 1992, PHYSICS BASED VISION, P166; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; NOVAK CL, 1992, ENCY ARTIFICIAL INTE, P192; OHTA Y, CGIP, V13, P222; Pratt W. K., 1978, DIGITAL IMAGE PROCES; STEIN F, 1992, JAN IM UND WORKSH SA; SWAIN MJ, P ICCV 90, P390; SYEDAMAHMOOD TF, P ECCV 92, P115	14	49	51	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1995	17	8					805	809		10.1109/34.400571	http://dx.doi.org/10.1109/34.400571			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RL035					2022-12-18	WOS:A1995RL03500007
J	YAMADA, H; YAMAMOTO, K; HOSOKAWA, K				YAMADA, H; YAMAMOTO, K; HOSOKAWA, K			DIRECTIONAL MATHEMATICAL MORPHOLOGY AND REFORMALIZED HOUGH TRANSFORMATION FOR THE ANALYSIS OF TOPOGRAPHIC MAPS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DIRECTIONAL FEATURE PLANE; FEATURE EXTRACTION; GENERALIZED HOUGH TRANSFORM; MATHEMATICAL MORPHOLOGY; MULTIANGLED PARALLELISM; SYMBOL RECOGNITION; TOPOGRAPHIC MAP ANALYSIS		One of the most difficult and important problems encountered in the automatic digitizing of graphical topographic maps is the identification and separate digitizing of different kinds of features. Essentially, in topographic maps, there are two kinds of geometric features: linear features, such as roads and railways that have an arbitrary length, and symbols, which indicate a type of building or area of land usage or even numerical information. In this paper, these two types of features are extracted and recognized by using methods based on multiangled parallelism (MAP). The MAP operation method performs parallel calculation on directional feature planes. The linear features are extracted using erosion-dilation operations on the directional feature planes, and the symbols are extracted using a reformalized and parallel version of the generalized Hough transformation on the same directional planes, which we call the MAP matching method. The methods have been applied to a 1/25 000 scale map.	FUJIFACOM CORP,TECH ENGN GRP,HINO,JAPAN		YAMADA, H (corresponding author), ELECTROTECH LAB,DIV MACHINE UNDERSTANDING,IMAGE UNDERSTANDING SECT,TSUKUBA,JAPAN.							BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; Kamei K., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P1109, DOI 10.1109/ICPR.1988.28455; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; SERRA J, 1986, COMPUT VISION GRAPH, V35, P283, DOI 10.1016/0734-189X(86)90002-2; Serra J, 1982, IMAGE ANAL MATH MORP; YAMADA H, 1991, PATTERN RECOGN, V24, P479, DOI 10.1016/0031-3203(91)90015-W; YAMADA H, 1988, IEEE T PATTERN ANAL, V10, P731, DOI 10.1109/34.6784; Yamada H., 1990, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ73D-II, P553; YAMADA H, 1990, 10TH P INT C PATT RE, V2, P524	10	49	53	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1993	15	4					380	387		10.1109/34.206957	http://dx.doi.org/10.1109/34.206957			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KU543					2022-12-18	WOS:A1993KU54300005
J	BOSE, CB; AMIR, I				BOSE, CB; AMIR, I			DESIGN OF FIDUCIALS FOR ACCURATE REGISTRATION USING MACHINE VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									AT&T BELL LABS,PRINCETON,NJ 08540	AT&T	BOSE, CB (corresponding author), AT&T BELL LABS,MURRAY HILL,NJ 07974, USA.							BERENSTEIN CA, 1987, COMPUT VISION GRAPH, V40, P334, DOI 10.1016/S0734-189X(87)80146-9; Hill J.W., 1980, MACH INTELL, P75; HO C, 1982 WORKSH IND APPL, P153; HYDE PD, 1983, PATTERN RECOGN, V16, P413, DOI 10.1016/0031-3203(83)90063-8; OVERINGTON I, 1987, IMAGE VISION COMPUT, V5, P217, DOI 10.1016/0262-8856(87)90052-7; RANGANATH HS, 1986, IMAGE VISION COMPUT, V4, P151, DOI 10.1016/0262-8856(86)90058-2; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9	7	49	54	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1196	1200		10.1109/34.62609	http://dx.doi.org/10.1109/34.62609			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500					2022-12-18	WOS:A1990EN50000008
J	NITZAN, D				NITZAN, D			3-DIMENSIONAL VISION STRUCTURE FOR ROBOT APPLICATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review											NITZAN, D (corresponding author), SRI INT,ROBOT LAB,MENLO PK,CA 94025, USA.							ALTSCHULER MD, 1981, P SOC PHOTO-OPT INST, V283, P15; Ballard D.H., 1982, COMPUTER VISION; BESL JB, 1985, COMPUT SURV, V17; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BOLLES RC, 1984, MAR P IEEE INT C ROB, P78; BOLLES RC, 1986, INT J ROBOT RES, V5; COWAN CK, 1987, IEEE T PATTERN ANAL; FISCHLER MA, 1980, SRI213 INT A I CTR T; GOODWIN FE, 1985, SME MS851005 TECH PA; HEBERT M, 1985, DEC P IM UND WORKSH; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; JOHNSTON AR, 1973, NPO13460 JET PROP LA; KENDER JR, 1976, SATURATION HUE NORMA; Kitagawa H., 1983, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ66D, P65; KOSHIKAWA K, 1982, T SICE, V18, P77; KREMERS JH, 1983, NAVSEA S5000283 SRI; KREMERS JH, 1985, NAVSEA S50002832 SRI; KROTKOV E, 1986, 1986 P IEEE ROB AUT, P1093; MILLER RK, 1984, 3 D MACHINE VISION; MULGAONKAR PG, 1985, 3RD IEEE WORKSH COMP, P11; NITZAN D, 1977, P IEEE, V65, P206, DOI 10.1109/PROC.1977.10458; NITZAN D, 1983, SEP P 83 INT C ADV R; Ohta T.I., 1981, P INT JOINT C ART IN, P746; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; PENTLAND A, 1985, 9TH P INT JOINT C AR, P988; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; PRATT WK, 1971, IEEE T COMMUN TECHN, VCO19, P980, DOI 10.1109/TCOM.1971.1090769; ROSEN CA, 1979, COMPUTER VISION SENS; Rosenfeld A., 1976, DIGITAL IMAGE PROCES; STEVENS KA, 1979, ARTIFICIAL INTELLIGE, V2; TSUJI S, 1983, SEP P 83 INT C ADV R, P133; WITKIN AP, 1981, ARTIF INTELL, V17; WOODHAM RJ, 1981, ARTIF INTELL, V17, P117, DOI 10.1016/0004-3702(81)90022-9; WOODHAM RJ, 1978, 22ND P SPIE TECHN S, P136; [No title captured]	37	49	58	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1988	10	3					291	309		10.1109/34.3895	http://dx.doi.org/10.1109/34.3895			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	N5337					2022-12-18	WOS:A1988N533700002
J	BARTLETT, SL; BESL, PJ; COLE, CL; JAIN, R; MUKHERJEE, D; SKIFSTAD, KD				BARTLETT, SL; BESL, PJ; COLE, CL; JAIN, R; MUKHERJEE, D; SKIFSTAD, KD			AUTOMATIC SOLDER JOINT INSPECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BARTLETT, SL (corresponding author), UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,COMP VIS RES LAB,ANN ARBOR,MI 48109, USA.							AKIYAMA N, 1984, B JPN SOC PREC ENG, V18, P165; BERNARD CD, 1976, IBM TR002761 TECH RE, P1; Besl P. J., 1985, IEEE Journal of Robotics and Automation, VRA-1, P42, DOI 10.1109/JRA.1985.1086997; BESL PJ, 1985, CRIM RSDTR1785 U MIC; BOLHOUSE VC, 1985, JUN VISION 85 C P DE; BUNZE V, 1985, CONDUCTOR        JUN, P2; CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309; DAVY JG, 1985 SOLD TECHN SEM; DYE R, 1974, BSR4149 BEND CORP TE; FEIVESON AH, 1983, IEEE T PATTERN ANAL, V5, P48, DOI 10.1109/TPAMI.1983.4767343; FRIEDMAN JH, 1977, IEEE T COMP      APR, P404; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GINSBERG A, P AAAI 86, V1, P436; JARVIS JF, 1980, IEEE T PATTERN ANAL, V2, P77, DOI 10.1109/TPAMI.1980.4766975; JUHA M, 1986, EC AUTOMATED XRAY IN; JUHA M, 1985, AUTOMATED INSPECTION; MANKO HH, 1964, SOLDERS SOLDERING; MCINTOSH WE, 1983, ROBOTICS TODAY   JUN, P75; MURPHY F, 1984, IPC TECH REV     JUN, P13; NAKAGAWA Y, 1982, P SOC PHOTO-OPT INST, V336, P121, DOI 10.1117/12.933619; Nakagawa Y., 1985, Hitachi Review, V34, P55; NAKAGAWA Y, 1983, 1ST INT S ROB RES BR; PERKINS WA, 1984, PATTERN RECOGN, V17, P135, DOI 10.1016/0031-3203(84)90040-2; ROSENFELD A, 1984, COMPUT VISION GRAPHI, V34, P99; SANZ JLC, 1986, J OPT SOC AM A, V3, P1465, DOI 10.1364/JOSAA.3.001465; STERLING WM, 1979, AUG P IEEE C PATT RE, P93; VANZETTI R, 1981, 24TH P IPC ANN M, P1; WATSON LT, 1984, PATTERN RECOGN, V17, P493, DOI 10.1016/0031-3203(84)90047-5; WEST GAW, 1984, IEEE T SYST MAN CYB, V14, P767, DOI 10.1109/TSMC.1984.6313300; WILKINS DC, P AAAI 86, V1, P448; WOODGATE RW, 1983, HDB MACHINE SOLDERIN; 1978, IPC WORKSHOP HDB	32	49	56	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1988	10	1					31	43		10.1109/34.3865	http://dx.doi.org/10.1109/34.3865			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	L4366					2022-12-18	WOS:A1988L436600004
J	MORGENTHALER, DG; ROSENFELD, A				MORGENTHALER, DG; ROSENFELD, A			MULTIDIMENSIONAL EDGE-DETECTION BY HYPERSURFACE FITTING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MORGENTHALER, DG (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							BEAUDET PR, 1978, 4TH P INT C PATT REC, P579; HERMAN GT, 1978, COMPUT VISION GRAPH, V7, P130, DOI 10.1016/S0146-664X(78)80018-5; LIU HK, 1977, COMPUT VISION GRAPH, V6, P123, DOI 10.1016/S0146-664X(77)80008-7; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003; ZUCKER SW, 1979, AUG P IEEE COMP SOC, P162	5	49	49	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					482	486		10.1109/TPAMI.1981.4767134	http://dx.doi.org/10.1109/TPAMI.1981.4767134			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ357	21868969				2022-12-18	WOS:A1981MQ35700013
J	TSOTSOS, JK; MYLOPOULOS, J; COVVEY, HD; ZUCKER, SW				TSOTSOS, JK; MYLOPOULOS, J; COVVEY, HD; ZUCKER, SW			A FRAMEWORK FOR VISUAL-MOTION UNDERSTANDING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV TORONTO,CARDIOVASC UNIT,TORONTO M5S 1A1,ONTARIO,CANADA; UNIV TORONTO,CARDIOVASC UNIT,TORONTO M5S 1A1,ONTARIO,CANADA; MCGILL UNIV,DEPT ELECT ENGN,MONTREAL H3C 3G1,QUEBEC,CANADA	University of Toronto; University of Toronto; McGill University	TSOTSOS, JK (corresponding author), TORONTO GEN HOSP,CARDIOVASC UNIT,TORONTO,ONTARIO,CANADA.		Tsotsos, John/N-1131-2019; Tsotsos, John K/G-3436-2011	Tsotsos, John/0000-0002-8621-9147; 				BADLER N, 1975, TR80 U TOR DEP COMP; BRACHMAN R, 1979, ASSOCIATIVE NETWORKS; LEVESQUE H, 1979, ASSOCIATIVE NETWORKS; MARTIN W, 1978, COMPUT GRAPHICS IMAG, V7; Miller G., 1972, CODING PROCESSES HUM; MINSKY M, 1975, PSYCHOLOGY COMPUTER; NAGEL HH, 1978, P INT JOINT C PATTER; TSOTSOS JK, 1978, TR93 U TOR DEP COMP; TsoTsos JK, 1980, THESIS U TORONTO; ZUCKER S, 1977, IEEE T COMPUT, V26; ZUCKER SW, 1978, PATTERN DIRECTED INF	11	49	49	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	6					563	573		10.1109/TPAMI.1980.6447704	http://dx.doi.org/10.1109/TPAMI.1980.6447704			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KS962					2022-12-18	WOS:A1980KS96200010
J	Han, JW; Yao, XW; Cheng, G; Feng, XX; Xu, D				Han, Junwei; Yao, Xiwen; Cheng, Gong; Feng, Xiaoxu; Xu, Dong			P-CNN: Part-Based Convolutional Neural Networks for Fine-Grained Visual Categorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Training; Detectors; Streaming media; Measurement; Feature extraction; Convolutional neural networks; Part localization network; part classification network; duplex focal loss; fine-grained visual categorization		This paper proposes an end-to-end fine-grained visual categorization system, termed Part-based Convolutional Neural Network (P-CNN), which consists of three modules. The first module is a Squeeze-and-Excitation (SE) block, which learns to recalibrate channel-wise feature responses by emphasizing informative channels and suppressing less useful ones. The second module is a Part Localization Network (PLN) used to locate distinctive object parts, through which a bank of convolutional filters are learned as discriminative part detectors. Thus, a group of informative parts can be discovered by convolving the feature maps with each part detector. The third module is a Part Classification Network (PCN) that has two streams. The first stream classifies each individual object part into image-level categories. The second stream concatenates part features and global feature into a joint feature for the final classification. In order to learn powerful part features and boost the joint feature capability, we propose a Duplex Focal Loss used for metric learning and part classification, which focuses on training hard examples. We further merge PLN and PCN into a unified network for an end-to-end training process via a simple training technique. Comprehensive experiments and comparisons with state-of-the-art methods on three benchmark datasets demonstrate the effectiveness of our proposed method.	[Han, Junwei; Yao, Xiwen; Cheng, Gong; Feng, Xiaoxu] Northwestern Polytech Univ, Sch Automat, Xian 710072, Shaanxi, Peoples R China; [Xu, Dong] Univ Sydney, Sch Elect & Informat Engn, Camperdown, NSW 2006, Australia	Northwestern Polytechnical University; University of Sydney	Cheng, G (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Shaanxi, Peoples R China.	junweihan2010@gmail.com; yaoxiwen@nwpu.edu.cn; gcheng@nwpu.edu.cn; fengxiaox@mail.nwpu.edu.cn; dong.xu@sydney.edu.au	Xu, Dong/A-3694-2011; Yao, Xiwen/GRS-8209-2022	Xu, Dong/0000-0003-2775-9730; Yao, Xiwen/0000-0002-7466-7428; Feng, Xiaoxu/0000-0003-2639-2447	National Key Research and Development Plan of China [2018YFB1402600]; National Science Foundation of China (NSFC) [61701415, 61772425, 61773315, 61790552]; Young Star of Science and Technology in Shaanxi Province [2018KJXX-029]; Fundamental Research Funds for the Central Universities [3102018zy023, 3102019AX09]; Australian Research Council Future Fellowship [FT180100116]	National Key Research and Development Plan of China; National Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Young Star of Science and Technology in Shaanxi Province; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Australian Research Council Future Fellowship(Australian Research Council)	This work was supported in part by the National Key Research and Development Plan of China under Grant 2018YFB1402600, in part by the National Science Foundation of China (NSFC) under Grants 61701415, 61772425, 61773315, and 61790552, in part by the Young Star of Science and Technology in Shaanxi Province under grant 2018KJXX-029, in part by the Fundamental Research Funds for the Central Universities under Grant 3102018zy023 and 3102019AX09, and in part by the Australian Research Council Future Fellowship under Grant FT180100116. J. Han and X. Yao contributed equally to this work.	Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110; [Anonymous], 2011, TECH REP CNS T 2011; Branson S., 2014, PROC BRIT MACH VIS C; Branson S, 2013, PROC CVPR IEEE, P1806, DOI 10.1109/CVPR.2013.236; Cai SJ, 2017, IEEE I CONF COMP VIS, P511, DOI 10.1109/ICCV.2017.63; Chen TS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P627; Cui Y, 2018, PROC CVPR IEEE, P4109, DOI 10.1109/CVPR.2018.00432; Cui Y, 2017, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2017.325; Cui Y, 2016, PROC CVPR IEEE, P1153, DOI 10.1109/CVPR.2016.130; Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476; Gao SH, 2014, IEEE T IMAGE PROCESS, V23, P623, DOI 10.1109/TIP.2013.2290593; Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Harwood B, 2017, IEEE I CONF COMP VIS, P2840, DOI 10.1109/ICCV.2017.307; He XT, 2017, PROC CVPR IEEE, P7332, DOI 10.1109/CVPR.2017.775; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132; Jaderberg M, 2015, ADV NEUR IN, V28; Kong S, 2017, PROC CVPR IEEE, P7025, DOI 10.1109/CVPR.2017.743; Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194; Krause J, 2014, INT C PATT RECOG, P26, DOI 10.1109/ICPR.2014.15; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775; Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu Xiao., 2016, ABS160306765 CORR; Maji S., 2013, TECH REP; Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041; Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995; Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13; Sermanet P., 2015, INT C LEARN REPR ICL; Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Song JF, 2017, IEEE I CONF COMP VIS, P5552, DOI 10.1109/ICCV.2017.592; Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49; Sun QL, 2018, NEUROCOMPUTING, V282, P174, DOI 10.1016/j.neucom.2017.12.020; Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276; Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436; Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131; Wei X, 2018, LECT NOTES COMPUT SC, V11207, P365, DOI 10.1007/978-3-030-01219-9_22; Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002; Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133; Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971; Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685; Xie LX, 2014, IEEE T IMAGE PROCESS, V23, P1994, DOI 10.1109/TIP.2014.2310117; Xu Z, 2018, IEEE T PATTERN ANAL, V40, P1100, DOI 10.1109/TPAMI.2016.2637331; Xu Z, 2017, IEEE T IMAGE PROCESS, V26, P135, DOI 10.1109/TIP.2016.2621661; Yao HT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P342, DOI 10.1145/3123266.3123278; Yao HT, 2018, IEEE T IMAGE PROCESS, V27, P10, DOI 10.1109/TIP.2017.2751960; Yao HT, 2016, IEEE T IMAGE PROCESS, V25, P4858, DOI 10.1109/TIP.2016.2599102; Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhang XF, 2016, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2016.126; Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289; Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498; Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou F, 2016, PROC CVPR IEEE, P1124, DOI 10.1109/CVPR.2016.127	59	48	49	34	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					579	590		10.1109/TPAMI.2019.2933510	http://dx.doi.org/10.1109/TPAMI.2019.2933510			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	31398107				2022-12-18	WOS:000740006100004
J	Li, XL; Zhang, H; Wang, R; Nie, FP				Li, Xuelong; Zhang, Han; Wang, Rong; Nie, Feiping			Multiview Clustering: A Scalable and Parameter-Free Bipartite Graph Fusion Method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiview clustering; scalable and parameter-free; graph fusion; connectivity constraint; initialization-independent		Multiview clustering partitions data into different groups according to their heterogeneous features. Most existing methods degenerate the applicability of models due to their intractable hyper-parameters triggered by various regularization terms. Moreover, traditional spectral based methods always encounter the expensive time overheads and fail in exploring the explicit clusters from graphs. In this paper, we present a scalable and parameter-free graph fusion framework for multiview clustering, seeking for a joint graph compatible across multiple views in a self-supervised weighting manner. Our formulation coalesces multiple view-wise graphs straightforward and learns the weights as well as the joint graph interactively, which could actively release the model from any weight-related hyper-parameters. Meanwhile, we manipulate the joint graph by a connectivity constraint such that the connected components indicate clusters directly. The designed algorithmis initialization-independent and time-economical which obtains the stable performance and scales well with the data size. Substantial experiments on toy data as well as real datasets are conducted that verify the superiority of the proposed method compared to the state-of-the-arts over the clustering performance and time expenditure.	[Li, Xuelong; Zhang, Han; Nie, Feiping] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China; [Li, Xuelong; Zhang, Han; Wang, Rong; Nie, Feiping] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China; [Wang, Rong] Northwestern Polytech Univ, Sch Cybersecur, Xian 710072, Shaanxi, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University	Nie, FP (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Nie, FP (corresponding author), Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.	xuelong_li@nwpu.edu.cn; zhanghan0805@mail.nwpu.edu.cn; wangrong@nwpu.edu.cn; feipingnie@gmail.com		Nie, Feiping/0000-0002-0871-6519; Wang, Rong/0000-0001-9240-6726	National Key Research and Development Program of China [2018AAA0101902]; National Natural Science Foundation of China [61871470, 61761130079, 61751202, 61772427, 61936014]; Inno vation Foundation for Doctor Dissertation of Northwestern Polytechnical University [CX201918]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Inno vation Foundation for Doctor Dissertation of Northwestern Polytechnical University	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0101902, in part by the National Natural Science Foundation of China under Grant 61871470, Grant 61761130079, Grant 61751202, Grant 61772427, and Grant 61936014, and in part by the Inno vation Foundation for Doctor Dissertation of Northwestern Polytechnical University under Grant CX201918.	APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; Bertsekas D.P., 2019, REINFORCEMENT LEARNI; Bickel S, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P19, DOI 10.1109/ICDM.2004.10095; Cai D, 2015, IEEE T CYBERNETICS, V45, P1669, DOI 10.1109/TCYB.2014.2358564; CAO XC, 2015, PROC CVPR IEEE, P586, DOI DOI 10.1109/CVPR.2015.7298657; Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P4381, DOI 10.1109/TIP.2015.2463223; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Dheeru D., 2019, UCI MACHINE LEARNING; Du F, 2017, ALGORITHMS, V10, DOI 10.3390/a10040128; FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652; Fanti C, 2004, ADV NEUR IN, V16, P1603; Feng L, 2017, SOFT COMPUT, V21, P1937, DOI 10.1007/s00500-016-2120-3; Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906; Hu ZX, 2020, INFORM FUSION, V55, P251, DOI 10.1016/j.inffus.2019.09.005; Huang J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3569; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Kang Z, 2020, AAAI CONF ARTIF INTE, V34, P4412; Kang Z, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105102; Kang Z, 2020, NEURAL NETWORKS, V122, P279, DOI 10.1016/j.neunet.2019.10.010; Kang Z, 2020, IEEE T CYBERNETICS, V50, P1833, DOI 10.1109/TCYB.2018.2887094; Kang Z, 2019, KNOWL-BASED SYST, V163, P510, DOI 10.1016/j.knosys.2018.09.009; Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053; Kumar A., 2011, P 28 INT C MACH LEAR, P393, DOI DOI 10.5555/3104482.3104532; Kumar Abhishek, 2011, NEURIPS, P2, DOI DOI 10.5555/2986459.2986617; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li YQ, 2015, AAAI CONF ARTIF INTE, P2750; Lin Z., 2009, UILUENG092215; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Liu J., 2013, PROC SOC IND APPL MA, P252, DOI [10.1137/1.9781611972832.28, DOI 10.1137/1.9781611972832.28]; Liu W., 2010, P 27 INT C MACH LEAR, P679; Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P2833, DOI 10.1109/TIP.2016.2553459; Ng AY, 2002, ADV NEUR IN, V14, P849; Nie F., 2016, IJCAI, P1881; Nie FP, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564; Nie FP, 2018, IEEE T IMAGE PROCESS, V27, P1501, DOI 10.1109/TIP.2017.2754939; Nie FP, 2016, AAAI CONF ARTIF INTE, P1969; SHERMAN AH, 1978, SIAM J NUMER ANAL, V15, P755, DOI 10.1137/0715050; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105; Wang C., 2017, P BRIT MACH VIS C LO; Wang H, 2020, IEEE T KNOWL DATA EN, V32, P1116, DOI 10.1109/TKDE.2019.2903810; Wang M, 2016, IEEE T KNOWL DATA EN, V28, P1864, DOI 10.1109/TKDE.2016.2535367; Wang Y, 2018, IEEE T NEUR NET LEAR, V29, P4833, DOI 10.1109/TNNLS.2017.2777489; Winn J, 2005, IEEE I CONF COMP VIS, P756; Xia RK, 2014, AAAI CONF ARTIF INTE, P2149; Xu JL, 2017, IEEE T IMAGE PROCESS, V26, P3016, DOI 10.1109/TIP.2017.2665976; Yin QY, 2018, IEEE T NEUR NET LEAR, V29, P5541, DOI 10.1109/TNNLS.2017.2786743; Yin QY, 2015, NEUROCOMPUTING, V156, P12, DOI 10.1016/j.neucom.2015.01.017; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361; Zhan K, 2019, IEEE T IMAGE PROCESS, V28, P1261, DOI 10.1109/TIP.2018.2877335; Zhan K, 2018, IEEE T CYBERNETICS, V48, P2887, DOI 10.1109/TCYB.2017.2751646; Zhang Z, 2019, IEEE T PATTERN ANAL, V41, P1774, DOI 10.1109/TPAMI.2018.2847335; Zhao HD, 2017, AAAI CONF ARTIF INTE, P2921; Zhao L, 2015, IEEE T MULTIMEDIA, V17, P1936, DOI 10.1109/TMM.2015.2477058; Zhou D., 2007, P 24 INT C MACHINE L, P1159, DOI DOI 10.1145/1273496.1273642; Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378; Zong LL, 2017, NEURAL NETWORKS, V88, P74, DOI 10.1016/j.neunet.2017.02.003	59	48	48	25	59	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					330	344		10.1109/TPAMI.2020.3011148	http://dx.doi.org/10.1109/TPAMI.2020.3011148			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750830				2022-12-18	WOS:000728561300024
J	Pan, JS; Dong, JX; Liu, Y; Zhang, JW; Ren, JM; Tang, JH; Tai, YW; Yang, MH				Pan, Jinshan; Dong, Jiangxin; Liu, Yang; Zhang, Jiawei; Ren, Jimmy; Tang, Jinhui; Tai, Yu-Wing; Yang, Ming-Hsuan			Physics-Based Generative Adversarial Models for Image Restoration and Beyond	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image restoration; Generative adversarial networks; Gallium nitride; Physics; Task analysis; Mathematical model; Degradation; Generative adversarial network; physics model; low-level vision; image restoration	REMOVAL	We present an algorithm to directly solve numerous image restoration problems (e.g., image deblurring, image dehazing, and image deraining). These problems are ill-posed, and the common assumptions for existing methods are usually based on heuristic image priors. In this paper, we show that these problems can be solved by generative models with adversarial learning. However, a straightforward formulation based on a straightforward generative adversarial network (GAN) does not perform well in these tasks, and some structures of the estimated images are usually not preserved well. Motivated by an interesting observation that the estimated results should be consistent with the observed inputs under the physics models, we propose an algorithm that guides the estimation process of a specific task within the GAN framework. The proposed model is trained in an end-to-end fashion and can be applied to a variety of image restoration and low-level vision problems. Extensive experiments demonstrate that the proposed method performs favorably against state-of-the-art algorithms.	[Pan, Jinshan; Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China; [Dong, Jiangxin; Liu, Yang] Dalian Univ Technol, Sch Math & Sci, Dalian 116024, Peoples R China; [Zhang, Jiawei; Ren, Jimmy] SenseTime Res, Shenzhen 518000, Peoples R China; [Tai, Yu-Wing] Tencent, Shenzhen 518054, Peoples R China; [Yang, Ming-Hsuan] Univ Calif, Sch Engn, Merced, CA 95344 USA	Nanjing University of Science & Technology; Dalian University of Technology; Tencent; University of California System; University of California Merced	Yang, MH (corresponding author), Univ Calif, Sch Engn, Merced, CA 95344 USA.	sdluran@gmail.com; dongjxjx@gmail.com; lewisyangliu@gmail.com; zhjw1988@gmail.com; rensijie@sensetime.com; jinhuitang@njust.edu.cn; yuwingtai@tencent.com; mhyang@ucmerced.edu	Yang, Ming-Hsuan/T-9533-2019; Tai, Yuwing/C-2047-2011	Yang, Ming-Hsuan/0000-0003-4848-2304; Ren, Jimmy/0000-0002-5888-3083; Tai, Yuwing/0000-0002-3148-0380	National Natural Science Foundation of China [61922043, 61872421, 61732007]; Natural Science Foundation of Jiangsu Province [BK20180471]; National Science Foundation CAREER [1149783]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Jiangsu Province(Natural Science Foundation of Jiangsu Province); National Science Foundation CAREER(National Science Foundation (NSF))	This work was supported in part by the National Natural Science Foundation of China (Nos. 61922043, 61872421, 61732007), the Natural Science Foundation of Jiangsu Province (No. BK20180471), and National Science Foundation CAREER (No. 1149783).	Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185; Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681; Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36; Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84; Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186; Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]; Hradi M., 2015, BRIT MACH VIS C; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jain V, 2008, P ADV NEUR INF PROC, P769; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kim TH, 2017, IEEE I CONF COMP VIS, P4058, DOI 10.1109/ICCV.2017.435; Kingma D.P, P 3 INT C LEARNING R; Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lempitsky V., 2016, ARXIV160708022V3; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511; Li LRH, 2018, PROC CVPR IEEE, P6616, DOI 10.1109/CVPR.2018.00692; Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299; Liao RJ, 2015, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2015.68; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu SF, 2016, LECT NOTES COMPUT SC, V9908, P560, DOI 10.1007/978-3-319-46493-0_34; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388; Mao X., 2016, MULTICLASS GENERATIV; Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82; Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35; Pan JS, 2017, IEEE T PATTERN ANAL, V39, P342, DOI 10.1109/TPAMI.2016.2551244; Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180; Pan JS, 2016, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2016.56; Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4; Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10; Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Schmidt U, 2013, PROC CVPR IEEE, P604, DOI 10.1109/CVPR.2013.84; Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418; Schuler CJ, 2013, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2013.142; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Sonderby C.K., 2017, ICLR, P1; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Xiao L, 2016, LECT NOTES COMPUT SC, V9907, P734, DOI 10.1007/978-3-319-46487-9_45; Xie J., 2012, ADV NEURAL INFORM PR, P341, DOI DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Xu L, 2015, PR MACH LEARN RES, V37, P1669; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Xu XY, 2017, IEEE I CONF COMP VIS, P251, DOI 10.1109/ICCV.2017.36; Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183; Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407; Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337; Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	65	48	48	27	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2449	2462		10.1109/TPAMI.2020.2969348	http://dx.doi.org/10.1109/TPAMI.2020.2969348			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	31995475	Green Submitted			2022-12-18	WOS:000692540900020
J	Liu, LQ; Shen, CH; van den Hengel, A				Liu, Lingqiao; Shen, Chunhua; van den Hengel, Anton			Cross-Convolutional-Layer Pooling for Image Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional networks; deep learning; pooling; fine-grained object recognition		Recent studies have shown that a Deep Convolutional Neural Network (DCNN) trained on a large image dataset can be used as a universal image descriptor and that doing so leads to impressive performance for a variety of image recognition tasks. Most of these studies adopt activations from a single DCNN layer, usually a fully-connected layer, as the image representation. In this paper, we proposed a novel way to extract image representations from two consecutive convolutional layers: one layer is used for local feature extraction and the other serves as guidance to pool the extracted features. By taking different viewpoints of convolutional layers, we further develop two schemes to realize this idea. The first directly uses convolutional layers from a DCNN. The second applies the pretrained CNN on densely sampled image regions and treats the fully-connected activations of each image region as a convolutional layer's feature activations. We then train another convolutional layer on top of that as the pooling-guidance convolutional layer. By applying our method to three popular visual classification tasks, we find that our first scheme tends to perform better on applications which demand strong discrimination on lower-level visual patterns while the latter excels in cases that require discrimination on category-level patterns. Overall, the proposed method achieves superior performance over existing approaches for extracting image representations from a DCNN. In addition, we apply cross-layer pooling to the problem of image retrieval and propose schemes to reduce the computational cost. Experimental results suggest that the proposed method achieves promising results for the image retrieval task.	[Liu, Lingqiao; Shen, Chunhua; van den Hengel, Anton] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	University of Adelaide	Liu, LQ (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	lingqiao.liu@adelaide.edu.au; chunhua.shen@adelaide.edu.au; anton.vandenhengel@adelaide.edu.au		liu, lingqiao/0000-0003-3584-795X; van den Hengel, Anton/0000-0003-3027-8364	Data to Decisions Cooperative Research Centre; Australian Research Council Future Fellowship [FT120100969]; Australian Research Council [DP160103710, LP130100156]	Data to Decisions Cooperative Research Centre; Australian Research Council Future Fellowship(Australian Research Council); Australian Research Council(Australian Research Council)	This work was in part supported by the Data to Decisions Cooperative Research Centre; and Australian Research Council Future Fellowship (FT120100969), and Australian Research Council projects DP160103710, and LP130100156. C. Shen is the corresponding author.	Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arandjelovic R, 2011, IEEE I CONF COMP VIS, P375, DOI 10.1109/ICCV.2011.6126265; Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen Q, 2012, PROC CVPR IEEE, P3426, DOI 10.1109/CVPR.2012.6248083; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Cimpoi M., 2015, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2015.7299007; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Doersch Carl, 2013, NIPS; Donahue J, 2014, PR MACH LEARN RES, V32; Dong J, 2013, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2013.112; Everingham M., 2007, PASCAL VISUAL OBJECT, DOI DOI 10.1007/S11263-014-0733-5; Gatys L. A., 2015, ADV NEURAL INFORM PR, V28, P262, DOI DOI 10.1016/0014-5793(76)80724-7; Gatys LA., 2015, PROC CVPR IEEE, V16, P326, DOI [10.1167/16.12.326, DOI 10.1109/CVPR.2016.265]; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Li L.-J., 2010, NEURAL INFORM PROCES, P1378; Li Y., 2016, INT J COMPUT VISION, P1; Li Y., 2014, P IEEE C COMP VIS PA, P971; Li Y, 2015, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2015.7298699; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu L., 2014, P ADV NEUR INF PROC, V27, P1143; Liu LQ, 2015, PROC CVPR IEEE, P4749, DOI 10.1109/CVPR.2015.7299107; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330; Ustyuzhaninov I., 2016, TEXTURE SYNTHESIS US; Welinder P., 2010, CNSTR2010001 CALTECH; Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150; Yoo D., 2014, FISHER KERNEL DEEP N; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhang N, 2012, PROC CVPR IEEE, P3665, DOI 10.1109/CVPR.2012.6248364; Zhao R.-W., 2016, P BRIT MACH VIS C	43	48	50	2	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2305	2313		10.1109/TPAMI.2016.2637921	http://dx.doi.org/10.1109/TPAMI.2016.2637921			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	27959804	Green Submitted, Green Published			2022-12-18	WOS:000412028600015
J	Segev, N; Harel, M; Mannor, S; Crammer, K; El-Yaniv, R				Segev, Noam; Harel, Maayan; Mannor, Shie; Crammer, Koby; El-Yaniv, Ran			Learn on Source, Refine on Target: A Model Transfer Learning Framework with Random Forests	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Transfer learning; model transfer; random forest; decision tree	DOMAIN ADAPTATION; RECOGNITION	We propose novel model transfer-learning methods that refine a decision forest model M learned within a "source" domain using a training set sampled from a "target" domain, assumed to be a variation of the source. We present two random forest transfer algorithms. The first algorithm searches greedily for locally optimal modifications of each tree structure by trying to locally expand or reduce the tree around individual nodes. The second algorithm does not modify structure, but only the parameter (thresholds) associated with decision nodes. We also propose to combine both methods by considering an ensemble that contains the union of the two forests. The proposed methods exhibit impressive experimental results over a range of problems.	[Segev, Noam; El-Yaniv, Ran] Technion Israel Inst Technol, Dept Comp Sci, IL-3200003 Haifa, Israel; [Harel, Maayan; Mannor, Shie; Crammer, Koby] Technion Israel Inst Technol, Dept Elect Engn, IL-3200003 Haifa, Israel	Technion Israel Institute of Technology; Technion Israel Institute of Technology	Segev, N (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-3200003 Haifa, Israel.	nsegev@cs.technion.ac.il; maayangal@gmail.com; shie@ee.technion.ac.il; koby@ee.technion.ac.il; rani@cs.technion.ac.il		Mannor, Shie/0000-0003-4439-7647	Israel Science Foundation [1890/14, 920/12]	Israel Science Foundation(Israel Science Foundation)	This research was supported in part by The Israel Science Foundation, grant No. 1890/14, and grant No. 920/12.	Agrawal, 2003, P 9 ACM SIGKDD INT C, P571, DOI DOI 10.1145/956750.956821; Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], 2005, P 22 INT C MACHINE L, DOI DOI 10.1145/1102351.1102415; [Anonymous], 2007, P 15 ACM INT C MULTI; [Anonymous], [No title captured], DOI DOI 10.1109/CVPR.2010.5539857; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100; Baxter J, 2000, J ARTIF INTELL RES, V12, P149, DOI 10.1613/jair.731; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 2017, CLASSIFICATION REGRE; Burges, 1998, MNIST DATABASE HANDW; Caruana R, 1998, LEARNING TO LEARN, P95, DOI 10.1007/978-1-4615-5529-2_5; Cortez P, 2009, DECIS SUPPORT SYST, V47, P547, DOI 10.1016/j.dss.2009.05.016; Dai W., 2007, PROC INT C MACH LEAR, P193, DOI [10.1145/1273496.1273521, DOI 10.1145/1273496.1273521]; Daume III Hal, 2007, P 45 ANN M ASS COMP, P256, DOI DOI 10.48550/ARXIV.0907.1815; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P71, DOI 10.1145/347090.347107; Dredze M, 2010, MACH LEARN, V79, P123, DOI 10.1007/s10994-009-5148-0; Duan L., 2009, P 26 ANN INT C MACH, P289, DOI DOI 10.1145/1553374.1553411; Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819; Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Eaton E, 2008, LECT NOTES ARTIF INT, V5211, P317, DOI 10.1007/978-3-540-87479-9_39; Eruhimov V., 2008, P 3 WORKSH NEW CHALL, P135; Evgeniou A., 2007, ADV NEURAL INF PROCE, V19, P41, DOI DOI 10.2139/SSRN.1031158; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; Faddoul Jean Baptiste, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P681, DOI 10.1007/978-3-642-33460-3_49; Faddoul J. B., 2010, 2010 Ninth International Conference on Machine Learning and Applications (ICMLA 2010), P367, DOI 10.1109/ICMLA.2010.61; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285; Gama J, 2006, INTELL DATA ANAL, V10, P23, DOI 10.3233/IDA-2006-10103; Germain P, 2015, J MACH LEARN RES, V16, P787; Germain Pascal, 2009, INT C MACH LEARN; Goussies NA, 2014, J MACH LEARN RES, V15, P3667; Harel M., 2011, PROC 28 INT C MACH L, P401; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Hulten G., 2005, J MACH LEARN RES, V1, P1; Hunt E., 1966, EXPT INDUCTION; Jiang J., 2007, ACL, V7, P264; Jiang J., 2008, LIT SURVEY DOMAIN AD; Jiang W, 2008, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2008.4711716; Jie L, 2011, IEEE I CONF COMP VIS, P1863, DOI 10.1109/ICCV.2011.6126454; Kamishima T, 2009, IEEE DATA MINING, P219, DOI 10.1109/ICDM.2009.9; Kienzle W., 2006, P 23 INT C MACH LEAR, P457, DOI DOI 10.1145/1143844.1143902; Langford J., 2003, ADV NEURAL INFORM PR, P439; Lawrence N.D., 2004, P 21 INT C MACH LEAR, P65, DOI DOI 10.1145/1015330.1015382; Lee JW, 2007, IEEE IJCNN, P726, DOI 10.1109/IJCNN.2007.4371047; Levy O., 2012, P 26 AAAI C ART INT, P991; Lichman M, 2013, UCI MACHINE LEARNING; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Lounici K., 2009, P 22 ANN C LEARN THE, P73; Louppe G., 2013, ADV NEURAL INFORM PR, V26, P431, DOI DOI 10.5555/2999611.2999660; Lu Z., 2013, P 2013 SIAM INT C DA, P641; Luo P., 2008, P 17 ACM C INF KNOWL, P103; Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI [10.1007/978-1-4419-9326-7, 10.1007/978-1-4419-9326-7_1]; McAllester D, 2003, LECT NOTES ARTIF INT, V2777, P203, DOI 10.1007/978-3-540-45167-9_16; Mehta M., 1995, KDD-95 Proceedings. First International Conference on Knowledge Discovery and Data Mining, P216; Nunez M, 2007, J MACH LEARN RES, V8, P2595; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pan SJ., 2008, PROC NATL CONF ARTIF, V8, P677; Pardoe D., 2010, ICML, P863; Quinlan J.R., 1993, PROGRAMS MACHINE LEA, V1; Raina R., 2007, LEARNING, P759, DOI DOI 10.1145/1273496.1273592; Rettinger A., 2006, P NAT C ART INT, V21, P464; RODNER E, 2008, P VIS MOD VIS WORKSH, P159; Rodner E, 2011, PATTERN RECOGN LETT, V32, P244, DOI 10.1016/j.patrec.2010.08.009; Rodner E, 2009, LECT NOTES COMPUT SC, V5748, P252, DOI 10.1007/978-3-642-03798-6_26; Ruckert U, 2008, LECT NOTES ARTIF INT, V5212, P220, DOI 10.1007/978-3-540-87481-2_15; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Schapire RE, 1998, ANN STAT, V26, P1651; Schwaighofer A., 2005, ADV NEURAL INFORM PR, P1209; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Simm J, 2014, IEICE T INF SYST, VE97D, P1677, DOI 10.1587/transinf.E97.D.1677; Subramanya A., 2006, P 22 C ANN C UNC ART, P494; Thrun S., 1994, CMUCS94184 DTIC, V184, P94; Tommasi T, 2010, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2010.5540064; Williams, 2007, NEURAL INFORM PROCES, P153, DOI DOI 10.5555/2981562.2981582; Wu P., 2004, PROC 21 INT C MACH L, P110; Yu K., 2005, P 22 INT C MACH LEAR, P1012, DOI DOI 10.1145/1102351.1102479	83	48	51	3	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1811	1824		10.1109/TPAMI.2016.2618118	http://dx.doi.org/10.1109/TPAMI.2016.2618118			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	28113392	Green Submitted			2022-12-18	WOS:000406840800009
J	Hariharan, B; Arbelaez, P; Girshick, R; Malik, J				Hariharan, Bharath; Arbelaez, Pablo; Girshick, Ross; Malik, Jitendra			Object Instance Segmentation and Fine-Grained Localization Using Hypercolumns	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Segmentation; detection; convolutional networks; part labeling		Recognition algorithms based on convolutional networks (CNNs) typically use the output of the last layer as a feature representation. However, the information in this layer may be too coarse spatially to allow precise localization. On the contrary, earlier layers may be precise in localization but will not capture semantics. To get the best of both worlds, we define the hypercolumn at a pixel as the vector of activations of all CNN units above that pixel. Using hypercolumns as pixel descriptors, we show results on three fine-grained localization tasks: simultaneous detection and segmentation, where we improve state-of-the-art from 49.7 mean AP(r) to 62.4, keypoint localization, where we get a 3.3 point boost over a strong regression baseline using CNN features, and part labeling, where we show a 6.6 point gain over a strong baseline.	[Hariharan, Bharath; Girshick, Ross] Facebook AI Res, Menlo Pk, CA 94025 USA; [Arbelaez, Pablo] Univ Los Andes, Bogota 111711, Colombia; [Malik, Jitendra] Univ Calif Berkeley, Berkeley, CA 94720 USA	Facebook Inc; Universidad de los Andes (Colombia); University of California System; University of California Berkeley	Hariharan, B (corresponding author), Facebook AI Res, Menlo Pk, CA 94025 USA.	bharathh@fb.com; pa.arbelaez@uniandes.edu.co; rbg@fb.com; malik@eecs.berkeley.edu		Arbelaez, Pablo/0000-0001-5244-2407	ONR MURI [N000141010933]; Google Research Grant; Microsoft Research fellowship	ONR MURI(MURIOffice of Naval Research); Google Research Grant(Google Incorporated); Microsoft Research fellowship(Microsoft)	This work was supported by ONR MURI N000141010933, a Google Research Grant and a Microsoft Research fellowship. We thank NVIDIA for providing GPUs through their academic program. We thank the reviewers for their helpful comments. This work was done while Bharath Hariharan was a graduate student at University of California Berkeley. Ross Girshick was at Microsoft Research when this work was done.	[Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Barron JT, 2013, IEEE I CONF COMP VIS, P3448, DOI 10.1109/ICCV.2013.428; Borenstein E, 2002, LECT NOTES COMPUT SC, V2351, P109; Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13; Branson S., 2014, P BRIT MACH VIS C, V1; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254; Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025; Dai QY, 2012, PROC CVPR IEEE, P3322, DOI 10.1109/CVPR.2012.6248070; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong J, 2014, LECT NOTES COMPUT SC, V8693, P299, DOI 10.1007/978-3-319-10602-1_20; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Fidler S, 2013, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2013.423; Girshick R., 2014, ARXIV14091556; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gkioxari G., 2014, ARXIV14065212; Gkioxari G., 2014, P IEEE C COMP VIS PA, P3528; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Ionescu C, 2014, PROC CVPR IEEE, P1661, DOI 10.1109/CVPR.2014.215; JONES DG, 1992, LECT NOTES COMPUT SC, V588, P661; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luo P, 2013, IEEE I CONF COMP VIS, P2648, DOI 10.1109/ICCV.2013.329; Maire M., 2014, AS C COMP VIS, P237; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Parkhi OM, 2011, IEEE I CONF COMP VIS, P1427, DOI 10.1109/ICCV.2011.6126398; Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Tompson J.J., 2014, ADV NEURAL INF PROCE, P1799, DOI DOI 10.5555/2968826.2969027; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Wang HY, 2015, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2015.7298788; Wang P, 2015, IEEE I CONF COMP VIS, P1573, DOI 10.1109/ICCV.2015.184; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489; Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437; Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yang Y, 2012, IEEE T PATTERN ANAL, V34, P1731, DOI 10.1109/TPAMI.2011.208; Yihang Bo, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2265, DOI 10.1109/CVPR.2011.5995609; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54	56	48	51	1	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					627	639		10.1109/TPAMI.2016.2578328	http://dx.doi.org/10.1109/TPAMI.2016.2578328			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	27295654				2022-12-18	WOS:000397717600002
J	Liu, GC; Xu, H; Tang, JH; Liu, QS; Yan, SC				Liu, Guangcan; Xu, Huan; Tang, Jinhui; Liu, Qingshan; Yan, Shuicheng			A Deterministic Analysis for LRR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Low-rank representation; parameter estimation; subspace clustering; outlier detection	MOTION SEGMENTATION; SUBSPACE	The recently proposed low-rank representation (LRR) method has been empirically shown to be useful in various tasks such as motion segmentation, image segmentation, saliency detection and face recognition. While potentially powerful, LRR depends heavily on the configuration of its key parameter, lambda. In realistic environments where the prior knowledge about data is lacking, however, it is still unknown how to choose lambda in a suitable way. Even more, there is a lack of rigorous analysis about the success conditions of the method, and thus the significance of LRR is a little bit vague. In this paper we therefore establish a theoretical analysis for LRR, striving for figuring out under which conditions LRR can be successful, and deriving a moderately good estimate to the key parameter lambda as well. Simulations on synthetic data points and experiments on real motion sequences verify our claims.	[Liu, Guangcan] Nanjing Univ Informat Sci & Technol, Sch Informat & Control, Nanjing, Peoples R China; [Xu, Huan] Natl Univ Singapore, Dept Mech Engn, Block E2,05-13, Singapore, Singapore; [Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China; [Liu, Qingshan] Nanjing Univ Informat Sci & Technol, Sch Informat & Control, B DAT, Nanjing, Peoples R China; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Block E4,08-27, Singapore, Singapore	Nanjing University of Information Science & Technology; National University of Singapore; Nanjing University of Science & Technology; Nanjing University of Information Science & Technology; National University of Singapore	Liu, GC (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Informat & Control, Nanjing, Peoples R China.	gcliu@nuist.edu.cn; mpexuh@nus.edu.sg; tangjh1981@acm.org; qsliu@nuist.edu.cn; eleyans@nus.edu.sg	liu, qingqing/HHD-0360-2022; xu, huan/R-5436-2016; Yan, Shuicheng/HCI-1431-2022; Liu, Qing/GWC-9222-2022	xu, huan/0000-0002-5712-0308; Tang, Jinhui/0000-0001-9008-222X	startup fund of Nanjing University of Information Science and Technology; NSF of Jiangsu Province [2012045]; NSFC [61272223]	startup fund of Nanjing University of Information Science and Technology; NSF of Jiangsu Province; NSFC(National Natural Science Foundation of China (NSFC))	This work was supported by the startup fund of the Nanjing University of Information Science and Technology, NSF of Jiangsu Province under Grant 2012045, and NSFC Grant 61272223.	Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Chen GL, 2009, INT J COMPUT VISION, V81, P317, DOI 10.1007/s11263-008-0178-9; Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Favaro P, 2011, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2011.5995365; Fazel M., 2002, MATRIX RANK MINIMIZA; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Goh A, 2007, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2007.383235; Gross D, 2011, IEEE T INFORM THEORY, V57, P1548, DOI 10.1109/TIT.2011.2104999; Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679; Knyazev AV, 2002, SIAM J SCI COMPUT, V23, P2008, DOI 10.1137/S1064827500377332; Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274; Lauer F, 2009, IEEE I CONF COMP VIS, P678, DOI 10.1109/ICCV.2009.5459173; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Liu G., 2014, P ADV NEUR INF PROC, P1206; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422; Liu Guangcan, 2012, J MACH LEARN RES P T, P703; Ma Y, 2008, SIAM REV, V50, P413, DOI 10.1137/060655523; Rao S, 2010, IEEE T PATTERN ANAL, V32, P1832, DOI 10.1109/TPAMI.2009.191; Rockafellar R. T., 1970, CONVEX ANAL; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Soltanolkotabi M, 2014, ANN STAT, V42, P669, DOI 10.1214/13-AOS1199; Soltanolkotabi M, 2012, ANN STAT, V40, P2195, DOI 10.1214/12-AOS1034; Sugaya Y, 2004, IEICE T INF SYST, VE87D, P1935; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Vidal R, 2008, INT J COMPUT VISION, V79, P85, DOI 10.1007/s11263-007-0099-z; Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Xu H, 2012, IEEE T INFORM THEORY, V58, P3047, DOI 10.1109/TIT.2011.2173156; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94; Zhang T, 2012, INT J COMPUT VISION, V100, P217, DOI 10.1007/s11263-012-0535-6	35	48	52	0	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					417	430		10.1109/TPAMI.2015.2453969	http://dx.doi.org/10.1109/TPAMI.2015.2453969			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046488				2022-12-18	WOS:000370738900001
J	Martinel, N; Das, A; Micheloni, C; Roy-Chowdhury, AK				Martinel, Niki; Das, Abir; Micheloni, Christian; Roy-Chowdhury, Amit K.			Re-Identification in the Function Space of Feature Warps	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature transformation; Person re-identification; warp function space	RECOGNITION; APPEARANCE; TRACKING	Person re-identification in a non-overlapping multicamera scenario is an open challenge in computer vision because of the large changes in appearances caused by variations in viewing angle, lighting, background clutter, and occlusion over multiple cameras. As a result of these variations, features describing the same person get transformed between cameras. To model the transformation of features, the feature space is nonlinearly warped to get the "warp functions". The warp functions between two instances of the same target form the set of feasible warp functions while those between instances of different targets form the set of infeasible warp functions. In this work, we build upon the observation that feature transformations between cameras lie in a nonlinear function space of all possible feature transformations. The space consisting of all the feasible and infeasible warp functions is the warp function space (WFS). We propose to learn a discriminating surface separating these two sets of warp functions in the WFS and to re-identify persons by classifying a test warp function as feasible or infeasible. Towards this objective, a Random Forest (RF) classifier is employed which effectively chooses the warp function components according to their importance in separating the feasible and the infeasible warp functions in the WFS. Extensive experiments on five datasets are carried out to show the superior performance of the proposed approach over state-of-the-art person re-identification methods. We show that our approach outperforms all other methods when large illumination variations are considered. At the same time it has been shown that our method reaches the best average performance over multiple combinations of the datasets, thus, showing that our method is not designed only to address a specific challenge posed by a particular dataset.	[Martinel, Niki; Micheloni, Christian] Univ Udine, Dept Math & Comp Sci, I-33100 Udine, Italy; [Das, Abir; Roy-Chowdhury, Amit K.] Univ Calif Riverside, Dept Elect Engn, Riverside, CA 92521 USA	University of Udine; University of California System; University of California Riverside	Martinel, N (corresponding author), Univ Udine, Dept Math & Comp Sci, I-33100 Udine, Italy.	niki.martinel@uniud.it; abir.das@email.ucr.edu; christian.micheloni@uniud.it; amitrc@ee.ucr.edu		Roy-Chowdhury, Amit/0000-0001-6690-9725; Micheloni, Christian/0000-0003-4503-7483	US National Science Foundation (NSF) [IIS-1316934, CNS-1330110]; Italian Ministry of Defense project "ADVISORIII"	US National Science Foundation (NSF)(National Science Foundation (NSF)); Italian Ministry of Defense project "ADVISORIII"	Amit K. Roy-Chowdhury is the corresponding author. This work was partially supported by the US National Science Foundation (NSF) grants IIS-1316934, CNS-1330110 and Italian Ministry of Defense project "ADVISORIII". The first two authors should be considered as joint first authors.	An L, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P244, DOI 10.1109/AVSS.2013.6636647; Avraham Tamar, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, P381, DOI 10.1007/978-3-642-33863-2_38; Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008; Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008; Bazzani Loris, 2010, INT C PATT REC; Bellet Aurelien, 2013, ARXIV13066709; Berndt DJ, 1994, KDD WORKSH, V10, P359; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22; Datta A, 2012, INT C PATT RECOG, P2367; Dikmen M., 2010, P AS C COMP VIS, V4, P501; Ess A, 2007, IEEE I CONF COMP VIS, P2065; Feichtinger H.G., 1998, GABOR ANAL ALGORITHM; Gilbert A, 2006, LECT NOTES COMPUT SC, V3952, P125; Gray D., 2007, IEEE INT WORKSH PERF, V3, P1; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Guanwen Zhang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P677, DOI 10.1007/978-3-642-37431-9_52; Heikkila M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68; Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003; Junqua J.-C., 1995, ROBUSTNESS AUTOMATIC; Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406; Kostinger Martin, 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247939; Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461; Liu C., 2012, ECCV LECT NOTES COMP, V7583, P391; Liu X, 2012, PATTERN RECOGN, V45, P4204, DOI 10.1016/j.patcog.2012.05.019; Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57; Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41; Martinel N., 2012, IEEE COMPUTER SOC C, DOI DOI 10.1109/CVPRW.2012.6239203; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Muller M., 2007, INFORM RETRIEVAL MUS, V3, P69, DOI [10.1007/978-3-540- 74048-3_4, DOI 10.1007/978-3-540-74048-3]; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Pkalska E., 2005, DISSIMILARITY REPRES, V64; Porikli F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P133; PROSSER B, 2008, BRIT MACH VIS C LEED; Prosser B. J., 2010, PROC BRIT MACH VIS C, P6, DOI DOI 10.5244/C.24.21; Salvador  S., 2004, KDD WORKSH MIN TEMP, P70; Satta R, 2012, LECT NOTES COMPUT SC, V7583, P453, DOI 10.1007/978-3-642-33863-2_45; Satta R, 2012, PATTERN RECOGN LETT, V33, P1838, DOI 10.1016/j.patrec.2012.03.026; Schmid C, 2001, PROC CVPR IEEE, P39; Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42; Siebler C., 2010, ICDSC 10, P199; Van Der Maaten L.J.P., 2009, J MACH LEARN RES, V10, P1, DOI [10.1080/ 135062804440 0 0102, DOI 10.1080/13506280444000102]; Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246; Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143; Vezzani R., 2014, ACM COMPUT SURV, V46, P1; Wu Y, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P209, DOI 10.1109/AVSS.2012.21; Yang L, 2006, DISTANCE METRIC LEAR; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138	58	48	49	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1656	1669		10.1109/TPAMI.2014.2377748	http://dx.doi.org/10.1109/TPAMI.2014.2377748			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26353002	hybrid, Green Submitted			2022-12-18	WOS:000357591900010
J	Wojek, C; Walk, S; Roth, S; Schindler, K; Schiele, B				Wojek, Christian; Walk, Stefan; Roth, Stefan; Schindler, Konrad; Schiele, Bernt			Monocular Visual Scene Understanding: Understanding Multi-Object Traffic Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene understanding; tracking; scene tracklets; tracking-by-detection; MCMC	TRACKING; SEGMENTATION	Following recent advances in detection, context modeling, and tracking, scene understanding has been the focus of renewed interest in computer vision research. This paper presents a novel probabilistic 3D scene model that integrates state-of-the-art multiclass object detection, object tracking and scene labeling together with geometric 3D reasoning. Our model is able to represent complex object interactions such as inter-object occlusion, physical exclusion between objects, and geometric context. Inference in this model allows us to jointly recover the 3D scene context and perform 3D multi-object tracking from a mobile observer, for objects of multiple categories, using only monocular video as input. Contrary to many other approaches, our system performs explicit occlusion reasoning and is therefore capable of tracking objects that are partially occluded for extended periods of time, or objects that have never been observed to their full extent. In addition, we show that a joint scene tracklet model for the evidence collected over multiple frames substantially improves performance. The approach is evaluated for different types of challenging onboard sequences. We first show a substantial improvement to the state of the art in 3D multipeople tracking. Moreover, a similar performance gain is achieved for multiclass 3D tracking of cars and trucks on a challenging dataset.	[Wojek, Christian; Schiele, Bernt] Max Planck Inst Informat, D-66123 Saarbrucken, Germany; [Walk, Stefan; Schindler, Konrad] ETH, Photogrammetry & Remote Sensing Grp, CH-8093 Zurich, Switzerland; [Roth, Stefan] Tech Univ Darmstadt, GRIS, D-64283 Darmstadt, Germany	Max Planck Society; Swiss Federal Institutes of Technology Domain; ETH Zurich; Technical University of Darmstadt	Wojek, C (corresponding author), Max Planck Inst Informat, Campus E1 4, D-66123 Saarbrucken, Germany.	cwojek@mpi-inf.mpg.de; stefan.walk@geod.baug.ethz.ch; sroth@cs.tu-darmstadt.de; konrad.schindler@geod.baug.ethz.ch; schiele@mpi-inf.mpg.de		Pauldurai, Jona/0000-0002-7217-0872				Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Andriyenko A., 2010, P EUR C COMP VIS; Breitenstein M.D., 2009, P 12 IEEE INT C COMP; Brostow G. J., 2008, P EUR C COMP VIS; Choi W., 2010, P EUR C COMP VIS; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dalal N., 2006, THESIS I NATL POLYTE; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Enzweiler M, 2010, PROC CVPR IEEE, P990, DOI 10.1109/CVPR.2010.5540111; Ess A., 2008, P IEEE C COMP VIS PA; Ess A., 2009, P ICRA WORKSH PEOPL; Ess A., 2009, P BRIT MED VIS C; Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109; Franke U., 2005, P DAGM; Gao T., 2011, P IEEE C COMP VIS PA; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; Geiger A, 2011, PROC CVPR IEEE; Gilks W. R., 1995, MARKOV CHAIN MONTE C, DOI 10.1201/b14835; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Gupta A., 2010, P EUR C COMP VIS; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Huang C., 2008, P EUR C COMP VIS; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79; Jorge P.M., 2004, P 6 INT WORKSH PERF; Kaucic R., 2005, P IEEE C COMP VIS PA; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kwak S., 2011, P 13 IEEE INT C COMP; Li Y., 2009, P IEEE C COMP VIS PA; Lin Y.-Y., 2004, P EUR C COMP VIS; Maji S, 2008, PROC CVPR IEEE, P2245; Nillius P., 2006, P IEEE C COMP VIS PA; Okuma K., 2004, P EUR C COMP VIS; PERERA AGA, 2006, P IEEE C COMP VIS PA; Pirsiavash H., 2011, P IEEE C COMP VIS PA; Platt JC, 2000, ADV NEUR IN, P61; Shashua A., 2004, P IEEE INT C INT VEH; Shet V., 2007, P IEEE C COMP VIS PA; Shitrit H.B., 2011, P 12 IEEE INT C COMP; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Sigal L., 2006, P IEEE C COMP VIS PA; Singh VK, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P37; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Varma M., 2002, P 7 EUR C COMP VIS; Vedaldi A., 2009, P NEUR INF PROC SYST; Walk S., 2010, CVPR; Wang X., 2009, P 12 IEEE INT C COMP; Winn J., 2006, P IEEE C COMP VIS PA; Wojek C., 2010, P EUR C COMP VIS; Wojek C, 2011, PROC CVPR IEEE; Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638; Wu B, 2009, INT J COMPUT VISION, V82, P185, DOI 10.1007/s11263-008-0194-9; Xing J., 2009, P IEEE C COMP VIS PA; Zhang L., 2008, P IEEE C COMP VIS PA; Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770	59	48	51	1	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					882	897		10.1109/TPAMI.2012.174	http://dx.doi.org/10.1109/TPAMI.2012.174			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22889818				2022-12-18	WOS:000314931000009
J	Mittal, S; Anand, S; Meer, P				Mittal, Sushil; Anand, Saket; Meer, Peter			Generalized Projection-Based M-Estimator	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generalized projection-based M-estimator; robust estimation; heteroscedasticity; RANSAC	RANDOM SAMPLE CONSENSUS; ROBUST; SEGMENTATION; MOTION; FACTORIZATION; MODELS	We propose a novel robust estimation algorithm-the generalized projection-based M-estimator (gpbM), which does not require the user to specify any scale parameters. The algorithm is general and can handle heteroscedastic data with multiple linear constraints for single and multicarrier problems. The gpbM has three distinct stages-scale estimation, robust model estimation, and inlier/outlier dichotomy. In contrast, in its predecessor pbM, each model hypotheses was associated with a different scale estimate. For data containing multiple inlier structures with generally different noise covariances, the estimator iteratively determines one structure at a time. The model estimation can be further optimized by using Grassmann manifold theory. We present several homoscedastic and heteroscedastic synthetic and real-world computer vision problems with single and multiple carriers.	[Mittal, Sushil] Columbia Univ, Dept Stat, New York, NY 10027 USA; [Anand, Saket; Meer, Peter] Rutgers State Univ, Dept Elect & Comp Engn, CAIP Ctr, Piscataway, NJ 08854 USA	Columbia University; Rutgers State University New Brunswick	Mittal, S (corresponding author), Columbia Univ, Dept Stat, New York, NY 10027 USA.	mittal@stat.columbia.edu; anands@eden.rutgers.edu; meer@jove.rutgers.edu						Bab-Hadiashar A, 1999, ROBOTICA, V17, P649, DOI 10.1017/S0263574799001812; Chen GL, 2009, INT J COMPUT VISION, V81, P317, DOI 10.1007/s11263-008-0178-9; Chin T.-J., 2009, NIPS, V22, P333; Chin TJ, 2009, IEEE I CONF COMP VIS, P413, DOI 10.1109/ICCV.2009.5459150; Choi J, 2009, PROC CVPR IEEE, P675, DOI 10.1109/CVPRW.2009.5206678; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Elhamifar E, 2009, PROC CVPR IEEE, P2782; Fan LX, 2008, LECT NOTES COMPUT SC, V5304, P182; Favaro P, 2011, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2011.5995365; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frahm J.-M., 2006, P COMP VIS PATT REC, V1, P453, DOI DOI 10.1109/CVPR.2006.235; Georgescu B, 2004, IEEE T PATTERN ANAL, V26, P674, DOI 10.1109/TPAMI.2004.2; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gruber A, 2004, PROC CVPR IEEE, P707; Hartley R., 2004, ROBOTICA; Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332; Lauer F, 2009, IEEE I CONF COMP VIS, P678, DOI 10.1109/ICCV.2009.5459173; Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940; Matei BC, 2006, IEEE T PATTERN ANAL, V28, P1537, DOI 10.1109/TPAMI.2006.205; Mittal S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2689, DOI 10.1109/CVPR.2011.5995514; Mittal S, 2012, IMAGE VISION COMPUT, V30, P417, DOI 10.1016/j.imavis.2011.09.005; Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37; Raguram R, 2011, IEEE I CONF COMP VIS, P1299, DOI 10.1109/ICCV.2011.6126382; Raguram R, 2009, IEEE I CONF COMP VIS, P2074, DOI 10.1109/ICCV.2009.5459456; SUBBARAO R, 2006, P IEEE C COMP VIS PA; Subbarao R, 2006, LECT NOTES COMPUT SC, V3951, P301; Sugaya Y, 2004, LECT NOTES COMPUT SC, V3247, P13; Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Triggs B, 1996, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.1996.517170; Tron R., 2008, P IEEE C COMP VIS PA, P1; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Vidal R., 2005, IEEE T PATTERN ANAL, V27, P1; Vidal R, 2006, INT J COMPUT VISION, V68, P7, DOI 10.1007/s11263-005-4839-7; Wang HZ, 2010, IEEE T PATTERN ANAL, V32, P178, DOI 10.1109/TPAMI.2009.148; Wang HZ, 2004, LECT NOTES COMPUT SC, V3023, P107; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94	40	48	49	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2351	2364		10.1109/TPAMI.2012.52	http://dx.doi.org/10.1109/TPAMI.2012.52			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22350164	Green Submitted			2022-12-18	WOS:000309913700006
J	Zhang, GF; Jia, JY; Hua, W; Bao, HJ				Zhang, Guofeng; Jia, Jiaya; Hua, Wei; Bao, Hujun			Robust Bilayer Segmentation and Motion/Depth Estimation with a Handheld Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bilayer segmentation; depth recovery; motion estimation; video editing		Extracting high-quality dynamic foreground layers from a video sequence is a challenging problem due to the coupling of color, motion, and occlusion. Many approaches assume that the background scene is static or undergoes the planar perspective transformation. In this paper, we relax these restrictions and present a comprehensive system for accurately computing object motion, layer, and depth information. A novel algorithm that combines different clues to extract the foreground layer is proposed, where a voting-like scheme robust to outliers is employed in optimization. The system is capable of handling difficult examples in which the background is nonplanar and the camera freely moves during video capturing. Our work finds several applications, such as high-quality view interpolation and video editing.	[Zhang, Guofeng; Hua, Wei; Bao, Hujun] Zhejiang Univ, State Key Lab CAD&CG, Zijingang Campus, Hangzhou 310058, Zhejiang, Peoples R China; [Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Zhejiang University; Chinese University of Hong Kong	Zhang, GF (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Zijingang Campus, Hangzhou 310058, Zhejiang, Peoples R China.	zhangguofeng@cad.zju.edu.cn; leojia@cse.cuhk.edu.hk; huawei@cad.zju.edu.cn; bao@cad.zju.edu.cn	Jia, Jiaya/I-3251-2012		973 program of China [2009CB320804]; NSF of China [60633070, 60903135]; Research Grants Council of the Hong Kong Special Administrative Region [412708]	973 program of China(National Basic Research Program of China); NSF of China(National Natural Science Foundation of China (NSFC)); Research Grants Council of the Hong Kong Special Administrative Region(Hong Kong Research Grants Council)	The authors would like to thank the associate editor and all of the reviewers for their constructive comments to improve the manuscript. This work is supported by the 973 program of China (No. 2009CB320804), NSF of China (Nos. 60633070 and 60903135), and a grant from the Research Grants Council of the Hong Kong Special Administrative Region (Project No. 412708).	AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376; BAKER S, 2007, P IEEE INT C COMP VI, P1, DOI DOI 10.1109/ICCV.2007.4408903; BHAT P, 2007, RENDERING TECHNIQUES, P327; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; BROX T, 2004, P 8 EUR C COMP VIS, V4, P25; BROX T, 2009, P IEEE CS C COMP VIS; Bruhn A, 2005, IEEE I CONF COMP VIS, P749; Chuang YY, 2001, PROC CVPR IEEE, P264; Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; CRIMINISI A, 2006, P IEEE C COMP VIS PA, V1, P53; Dong ZL, 2009, COMPUT GRAPH FORUM, V28, P1745, DOI 10.1111/j.1467-8659.2009.01551.x; Elgammal A., 2000, COMPUTER VISION ECCV, P751, DOI [10.1007/3-540-45053-X_48, DOI 10.1007/3-540-45053-X_48]; Hartley R., 2004, ROBOTICA; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Khan S, 2001, PROC CVPR IEEE, P746; Kolmogorov V, 2005, PROC CVPR IEEE, P407; Kumar MP, 2005, IEEE I CONF COMP VIS, P33; Kunz T, 2007, IEEE CONF WIREL MOB; LEMPITSKY VS, 2008, P IEEE CS C COMP VIS; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719; Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234; LIU C, 2008, P IEEE CS C COMP VIS; LIU F, 2009, P IEEE CS C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; MARK WR, 1997, P S INT 3D GRAPH, V180, P7; OLIVEIRA MM, 2001, P INT C VIS IM IM PR, P261; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Sheikh Y, 2005, PROC CVPR IEEE, P74; Sun J, 2005, PROC CVPR IEEE, P399; Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628; SZELISKI R, 1997, P SIGGRAPH, P251; Wang J, 2005, IEEE I CONF COMP VIS, P936; Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233; WANG J, 2007, P IEEE CS C COMP VIS; Wedel A., 2009, P IEEE INT C COMP VI; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; Xu L, 2008, LECT NOTES COMPUT SC, V5302, P671; YIN P, 2007, P IEEE CS C COMP VIS; ZHANG G, 2007, P IEEE CS C COMP VIS; Zhang GF, 2009, IEEE T VIS COMPUT GR, V15, P828, DOI 10.1109/TVCG.2009.47; Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52	47	48	56	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					603	617		10.1109/TPAMI.2010.115	http://dx.doi.org/10.1109/TPAMI.2010.115			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	20530810	Green Submitted			2022-12-18	WOS:000286204700012
J	Ouyang, WL; Cham, WK				Ouyang, Wanli; Cham, Wai-Kuen			Fast Algorithm for Walsh Hadamard Transform on Sliding Windows	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fast algorithm; Walsh Hadamard Transform; pattern matching; template matching; feature extraction		This paper proposes a fast algorithm for Walsh Hadamard Transform on sliding windows which can be used to implement pattern matching most efficiently. The computational requirement of the proposed algorithm is about 1.5 additions per projection vector per sample, which is the lowest among existing fast algorithms for Walsh Hadamard Transform on sliding windows.	[Ouyang, Wanli; Cham, Wai-Kuen] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong	Ouyang, WL (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Ho Sin Hang Engn Bldg, Shatin, Hong Kong, Peoples R China.	wlouyang@ee.cuhk.edu.hk; wkcham@ee.cuhk.edu.hk	Ouyang, Wanli/I-7135-2018	Ouyang, Wanli/0000-0002-9163-2761				Aksoy MS, 2004, J INTELL MANUF, V15, P569, DOI 10.1023/B:JIMS.0000034120.86709.8c; [Anonymous], 2003, H264 ITUT; Ben-Artzi G, 2007, IEEE T PATTERN ANAL, V29, P382, DOI 10.1109/TPAMI.2007.62; BENYEHUDA M, 2005, P IEEE INT C IM PROC; CHAM WK, 1987, IEE PROC-F, V134, P141, DOI 10.1049/ip-f-1.1987.0028; Dufour RM, 2002, IEEE T IMAGE PROCESS, V11, P1385, DOI 10.1109/TIP.2002.806245; Fitzgibbon A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1176; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; Luczak T, 1997, IEEE T INFORM THEORY, V43, P1439, DOI 10.1109/18.623143; Mak CM, 2008, IEEE T CIRC SYST VID, V18, P735, DOI 10.1109/TCSVT.2008.918790; Mak CM, 2005, I S INTELL SIG PROC, P349; Moshe Y, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P185, DOI 10.1109/ISSPIT.2006.270794; Omachi S, 2007, IEEE T IMAGE PROCESS, V16, P2139, DOI 10.1109/TIP.2007.901243; SHANKS JL, 1969, IEEE T COMPUT, VC 18, P457, DOI 10.1109/T-C.1969.222685; VANDERBRUG GJ, 1977, IEEE T COMPUT, V26, P384, DOI 10.1109/TC.1977.1674847	15	48	51	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					165	U175		10.1109/TPAMI.2009.104	http://dx.doi.org/10.1109/TPAMI.2009.104			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926906				2022-12-18	WOS:000271826700013
J	Moreno-Noguer, F; Sanfeliu, A; Samaras, D				Moreno-Noguer, Francesc; Sanfeliu, Alberto; Samaras, Dimitris			Dependent multiple cue integration for robust tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian tracking; multiple cue integration	COLOR	We propose a new technique for fusing multiple cues to robustly segment an object from its background in video sequences that suffer from abrupt changes of both illumination and position of the target. Robustness is achieved by the integration of appearance and geometric object features and by their estimation using Bayesian filters, such as Kalman or particle filters. In particular, each filter estimates the state of a specific object feature, conditionally dependent on another feature estimated by a distinct filter. This dependence provides improved target representations, permitting us to segment it out from the background even in nonstationary sequences. Considering that the procedure of the Bayesian filters may be described by a "hypotheses generation-hypotheses correction" strategy, the major novelty of our methodology compared to previous approaches is that the mutual dependence between filters is considered during the feature observation, that is, into the "hypotheses-correction" stage, instead of considering it when generating the hypotheses. This proves to be much more effective in terms of accuracy and reliability. The proposed method is analytically justified and applied to develop a robust tracking system that adapts online and simultaneously the color space where the image points are represented, the color distributions, the contour of the object, and its bounding box. Results with synthetic data and real video sequences demonstrate the robustness and versatility of our method.	[Moreno-Noguer, Francesc] Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland; [Sanfeliu, Alberto] UPC, CSIC, Inst Robot & Informat Ind, Barcelona 08028, Spain; [Samaras, Dimitris] SUNY Stony Brook, Dept Comp Sci, Image Anal Lab, Stony Brook, NY 11794 USA	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII); Universitat Politecnica de Catalunya; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Moreno-Noguer, F (corresponding author), Ecole Polytech Fed Lausanne, Comp Vis Lab, BC 307,Bldg BC,Stn 14, CH-1015 Lausanne, Switzerland.	fmorenoguer@gmail.com; sanfeliu@iri.upc.edu; samaras@cs.sunysb.edu	Moreno-Noguer, Francesc/G-3915-2014	Moreno-Noguer, Francesc/0000-0002-8640-684X; Sanfeliu, Alberto/0000-0003-3868-9678				Bar -Shalom Y., 2001, ESTIMATION APPL TRAC; Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614; Branson K, 2005, PROC CVPR IEEE, P1039; Darrell T, 2000, INT J COMPUT VISION, V37, P175, DOI 10.1023/A:1008103604354; DOUCET N, 2001, SEQUENTIAL M CARLO P; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Hayman E, 2002, LECT NOTES COMPUT SC, V2352, P469; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1998, P 5 EUR C COMP VIS, V1, P893; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Khan S, 2001, PROC CVPR IEEE, P746; Khan Z, 2004, PROC CVPR IEEE, P980; Leichter I, 2004, PROC CVPR IEEE, P445; MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374; MACKCORMICK J, 2000, P 6 EUR C COMP VIS, V2, P3; Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346; Moreno-Noguer F, 2005, IEEE I CONF COMP VIS, P1713, DOI 10.1109/ICCV.2005.126; Moreno-Noguer F, 2006, INT C PATT RECOG, P43; Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; Sidenbladh H., 2000, LNCS, V2, P702; Spengler M, 2003, MACH VISION APPL, V14, P50, DOI 10.1007/s00138-002-0095-9; Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882; TOYAMA K, 2000, P 4 AS C COMP VIS; Triesch J, 2001, NEURAL COMPUT, V13, P2049, DOI 10.1162/089976601750399308; Wu Y, 2004, INT J COMPUT VISION, V58, P55, DOI 10.1023/B:VISI.0000016147.97880.cd	28	48	50	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					670	685		10.1109/TPAMI.2007.70727	http://dx.doi.org/10.1109/TPAMI.2007.70727			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276972	Green Submitted			2022-12-18	WOS:000253135600010
J	Ortner, M; Descombes, X; Zerubia, J				Ortner, Mathias; Descombes, Xavier; Zerubia, Josiane			A marked point process of rectangles and segments for automatic analysis of Digital Elevation Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing; Poisson point process; stochastic geometry; dense urban area; Digital Elevation Models; land register; building detection; MCMC; RJMCMC; simulated annealing	OBJECT RECOGNITION; IMAGES; EXTRACTION; BUILDINGS	This work presents a framework for automatic feature extraction from images using stochastic geometry. Features in images are modeled as realizations of a spatial point process of geometrical shapes. This framework allows the incorporation of a priori knowledge on the spatial repartition of features. More specifically, we present a model based on the superposition of a process of segments and a process of rectangles. The former is dedicated to the detection of linear networks of discontinuities, whereas the latter aims at segmenting homogeneous areas. An energy is defined, favoring connections of segments, alignments of rectangles, and a relevant interaction between both types of objects. The estimation is performed by minimizing the energy using a simulated annealing algorithm. The proposed model is applied to the analysis of Digital Elevation Models (DEMs). These images are raster data representing the altimetry of a dense urban area. We present results on real data provided by the French National Geographic Institute (IGN) consisting in low-quality DEMs of various types.	INRIA Sophia Antipolis, Ariana Project, F-06902 Sophia Antipolis, France		Ortner, M (corresponding author), Astrium EADS Co, Toulouse, France.	mathias.ortner@gmail.com; Josiane.Zerubia@inria.fr		Zerubia, Josiane/0000-0002-7444-0856				BADDELEY A, 1993, STAT IMAGES, V1, P233; BESAG J, 1986, J R STAT SOC B, V48, P259; Fischer A, 1998, COMPUT VIS IMAGE UND, V72, P185, DOI 10.1006/cviu.1998.0721; FRADKIN M, 1999, P IEEE C COMP VIS PA, V1, P262; FRADKIN M, 1999, P ISPRS C AUT EXTR G; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEYER CJ, 1994, SCAND J STAT, V21, P359; GREEN PJ, 1995, BIOMETRIKA, V57, P97; JIBRINI H, 2002, THESIS ENST PARIS; Lacoste C., 2004, THESIS U NICE SOPHIA; LACOSTE C, 2002, 4516 INRIA; Mayer H, 1999, COMPUT VIS IMAGE UND, V74, P138, DOI 10.1006/cviu.1999.0750; ORTNER M, 2004, THESIS U NICE SOPHIA; ORTNER M, 2006, INT J COMPUTER VISIO; ORTNER M, 2003, 4919 INRIA; ORTNER M, 2003, P C INT TRAIT AN IM; ORTNER M, MONTE CARLO METHODS, P4; ORTNER M, 2006, P IEEE INT C AC SPEE; ORTNER M, 2005, 5712 INRIA; Pievatolo A, 1998, J ROY STAT SOC B, V60, P609, DOI 10.1111/1467-9868.00143; Rue H, 1998, ADV APPL PROBAB, V30, P64, DOI 10.1017/S0001867800008089; Rue H, 1999, BIOMETRIKA, V86, P649, DOI 10.1093/biomet/86.3.649; SRIVASTAVA A, 1999, J STAT PLANNING INFE; Stoica R, 2004, INT J COMPUT VISION, V57, P121, DOI 10.1023/B:VISI.0000013086.45688.5d; STOICA R, 2001, THESIS U NICE SOPHIA; STRAUSS DJ, 1975, BIOMETRIKA, V62, P467, DOI 10.1093/biomet/62.2.467; van Lieshout, 2000, MARKOV POINT PROCESS; van Lieshout, 1999, STOCHASTIC GEOMETRY; VANLIESHOUT MNM, 1994, ADV APPL PROBAB, V26, P281, DOI 10.1017/S0001867800026197; VIVEROSCANCINO O, 2003, THESIS U NICE SOPHIA; Winkler G., 2003, IMAGE ANAL RANDOM FI	32	48	51	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					105	119		10.1109/TPAMI.2007.1159	http://dx.doi.org/10.1109/TPAMI.2007.1159			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000328	Green Submitted, Green Published			2022-12-18	WOS:000250843500009
J	Malassiotis, S; Strintzis, MG				Malassiotis, Sotiris; Strintzis, Michael G.			Snapshots: A novel local surface descriptor and matching algorithm for robust 3D surface alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						surface matching; object recognition; partially overlapping surfaces	REGISTRATION	In this paper, a novel local surface descriptor is proposed and applied to the problem of aligning partial views of a 3D object. The descriptor is based on taking "snapshots" of the surface over each point using a virtual camera oriented perpendicularly to the surface. This representation has the advantage of imposing minimal loss of information be robust to self-occlusions and also be very efficient to compute. Then, we describe an efficient search technique to deal with the rotation ambiguity of our representation and experimentally demonstrate the benefits of our approaches which are pronounced especially when we align views with small overlap.	Ctr Res & Technol Hellas, Informat & Telemat Inst, Thermi 57001, Greece; Aristotle Univ Thessaloniki, Dept Elect & Comp Engn, Thessaloniki 54124, Greece	Centre for Research & Technology Hellas; Aristotle University of Thessaloniki	Malassiotis, S (corresponding author), Ctr Res & Technol Hellas, Informat & Telemat Inst, 1st Km Thermi Panorama Rd,POB 60361, Thermi 57001, Greece.	malasiot@iti.gr; strintzi@eng.auth.gr						Arya S, 2000, COMP GEOM-THEOR APPL, V17, P135, DOI 10.1016/S0925-7721(00)00022-5; BELONGIE S, 2002, IEEE T PATTERN ANAL, V24, P1229; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; DALLEY G, 2003, P 3 INT C 3D DIG IM, P246; Delingette H., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P103, DOI 10.1109/ICCV.1993.378230; FORSTER F, 2001, P INT C AUGM VIRT EN; FROME A, 2004, P EUR C COMP VIS MAY; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; KANGASPUOSKARI M, 1993, J FLUID STRUCT, V7, P707, DOI 10.1006/jfls.1993.1041; KAZHDAN M, 2003, S GEOM PROC, P167; Lucchese L, 2002, IEEE T PATTERN ANAL, V24, P1468, DOI 10.1109/TPAMI.2002.1046160; Malassiotis S, 2005, PATTERN RECOGN, V38, P2537, DOI 10.1016/j.patcog.2005.02.001; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; STEIN F, 1997, INT J COMPUT VISION, V25, P63; Sun Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P263, DOI 10.1109/ICCV.2001.937634; Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749; Yamany S. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1098, DOI 10.1109/ICCV.1999.790402; ZHANG DM, 1999, EMMCVPR, P30	22	48	49	2	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1285	1290		10.1109/TPAMI.2007.1060	http://dx.doi.org/10.1109/TPAMI.2007.1060			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496386				2022-12-18	WOS:000246395300016
J	Kovacs, L; Sziranyi, T				Kovacs, Levente; Sziranyi, Tamas			Focus area extraction by blind deconvolution for defining regions of interest	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						transform methods; feature representation; indexing methods; sharpening and deblurring; video retrieval	DEPTH	We present an automatic focus area estimation method, working with a single image without a priori information about the image, the camera, or the scene. It produces relative focus maps by localized blind deconvolution and a new residual error-based classification. Evaluation and comparison is performed and applicability is shown through image indexing.	Univ Pannonia, Dept Image Proc & Neurocomp KNT, H-8200 Veszprem, Hungary; Hungarian Acad Sci, Comp & Automat Res Inst, MTA SZTAKI, H-1111 Budapest, Hungary	University of Pannonia; Hungarian Academy of Sciences; Hungarian Institute for Computer Science & Control	Kovacs, L (corresponding author), Univ Pannonia, Dept Image Proc & Neurocomp KNT, Egyetem 10, H-8200 Veszprem, Hungary.	kla@vision.vein.hu; sziranyi@sztaki.hu	Sziranyi, Tamas/A-3410-2008; Kovacs, Levente/J-4547-2017	Kovacs, Levente/0000-0001-7792-4947; Sziranyi, Tamas/0000-0003-2989-0214				AYERS GR, 1988, OPT LETT, V13, P547, DOI 10.1364/OL.13.000547; Brodatz P., 1999, TEXTURES PHOTOGRAPHI; CHI CY, 1991, IEEE T GEOSCCIENCE R, V29; CZUNI L, 2003, P 8 INT WORKSH VIS C, P76; DIJK J, 2002, P ASCI2002, P39; ENS J, 1993, IEEE T PATTERN ANAL, V15, P97, DOI 10.1109/34.192482; Favaro P, 2005, IEEE T PATTERN ANAL, V27, P406, DOI 10.1109/TPAMI.2005.43; FISH DA, 1995, J OPT SOC AM A, V12, P58, DOI 10.1364/JOSAA.12.000058; Hanbury A, 2005, COMPUT IMAGING VIS, V30, P377; HOPGOOD JR, 1999, P 1999 IEEE WORKSH A; Jalobeanu A, 2004, IEEE T IMAGE PROCESS, V13, P613, DOI 10.1109/TIP.2003.819969; Jefferies SM, 2002, OPT EXPRESS, V10, P46, DOI 10.1364/OE.10.000046; Jiang M, 2003, J X-RAY SCI TECHNOL, V11, P13; Kovacs L, 2005, OPT LETT, V30, P3021, DOI 10.1364/OL.30.003021; KOVACS L, 2005, P 7 INT C ADV CONC I, P300; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; Lim S. H., 2005, 200514 HPL; LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605; Papoulis A., 2002, PROBABILITY RANDOM V; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; Sziranyi T, 1996, INT J CIRC THEOR APP, V24, P381, DOI 10.1002/(SICI)1097-007X(199605/06)24:3<381::AID-CTA923>3.0.CO;2-8; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P85, DOI 10.1109/34.899949	23	48	52	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2007	29	6					1080	1085		10.1109/TPAMI.2007.1079	http://dx.doi.org/10.1109/TPAMI.2007.1079			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	155TJ	17431304	Green Accepted			2022-12-18	WOS:000245600800012
J	Zhang, L; Seitz, SM				Zhang, Li; Seitz, Steven M.			Estimating optimal parameters for MRF stereo from a single image pair	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo matching; parameter setting; Markov Random Fields		This paper presents a novel approach for estimating the parameters for MRF-based stereo algorithms. This approach is based on a new formulation of stereo as a maximum a posterior (MAP) problem in which both a disparity map and MRF parameters are estimated from the stereo pair itself. We present an iterative algorithm for the MAP estimation that alternates between estimating the parameters while fixing the disparity map and estimating the disparity map while fixing the parameters. The estimated parameters include robust truncation thresholds for both data and neighborhood terms, as well as a regularization weight. The regularization weight can be either a constant for the whole image or spatially-varying, depending on local intensity gradients. In the latter case, the weights for intensity gradients are also estimated. Our approach works as a wrapper for existing stereo algorithms based on graph cuts or belief propagation, automatically tuning their parameters to improve performance without requiring the stereo code to be modified. Experiments demonstrate that our approach moves a baseline belief propagation stereo algorithm up six slots in the Middlebury rankings.	Columbia Univ, Comp Sci Dept, New York, NY 10027 USA; Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Columbia University; University of Washington; University of Washington Seattle	Zhang, L (corresponding author), Columbia Univ, Comp Sci Dept, 450 Mudd Hall,500 W 120 St, New York, NY 10027 USA.	lizhang@cs.columbia.edu; seitz@cs.washington.edu						Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chen L, 2004, 13TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, PROCEEDINGS, P192, DOI 10.1109/HPDC.2004.1323528; Felzenszwalb PR, 2004, PROC CVPR IEEE, P261; FREEMAN W, 2003, P NIPS, P1335; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Higdon DM, 1997, IEEE T MED IMAGING, V16, P516, DOI 10.1109/42.640741; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; MohammadDjafari A, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P473, DOI 10.1109/ICIP.1996.560890; Rother C, 2005, PROC CVPR IEEE, P589; ROTHER C, 2004, P ACM SIGGRAPH, P309; RUDIN LI, 1994, IEEE IMAGE PROC, P31; Saquib SS, 1998, IEEE T IMAGE PROCESS, V7, P1029, DOI 10.1109/83.701163; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Sun J, 2005, PROC CVPR IEEE, P399; Sun J, 2002, LECT NOTES COMPUT SC, V2351, P510; SZELISKI R, 2006, P EUR C COMP VIS, P19; Tao H, 2001, PROC CVPR IEEE, P118; Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900; Wang J, 2005, IEEE I CONF COMP VIS, P936; Weisberg HF, 2001, POLIT BEHAV, V23, P75, DOI 10.1023/A:1017621731652; Yang L, 2004, INT C PATT RECOG, P303, DOI 10.1109/ICPR.2004.1334180; Zhou ZY, 1997, IEEE T IMAGE PROCESS, V6, P844, DOI 10.1109/83.585235; Zitnick CL, 2005, IEEE I CONF COMP VIS, P1308; 2002, MIDDLEBURY STEREO VI	29	48	48	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					331	342		10.1109/TPAMI.2007.36	http://dx.doi.org/10.1109/TPAMI.2007.36			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV	17170484	Green Submitted			2022-12-18	WOS:000242826900012
J	Wu, TP; Tang, KL; Tang, CK; Wong, TT				Wu, Tai-Pang; Tang, Kam-Lun; Tang, Chi-Keung; Wong, Tien-Tsin			Dense photometric stereo: A Markov random field approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						photometric stereo; Markov random fields; belief propagation; graph cuts; normal and surface reconstruction; robust inference; real-time relighting	SHAPE; SURFACES; REFLECTANCE; IMAGES	We address the problem of robust normal reconstruction by dense photometric stereo, in the presence of complex geometry, shadows, highlight, transparencies, variable attenuation in light intensities, and inaccurate estimation in light directions. The input is a dense set of noisy photometric images, conveniently captured by using a very simple set-up consisting of a digital video camera, a reflective mirror sphere, and a handheld spotlight. We formulate the dense photometric stereo problem as a Markov network and investigate two important inference algorithms for Markov Random Fields (MRFs) - graph cuts and belief propagation - to optimize for the most likely setting for each node in the network. In the graph cut algorithm, the MRF formulation is translated into one of energy minimization. A discontinuity-preserving metric is introduced as the compatibility function, which allows alpha-expansion to efficiently perform the maximum a posteriori (MAP) estimation. Using the identical dense input and the same MRF formulation, our tensor belief propagation algorithm recovers faithful normal directions, preserves underlying discontinuities, improves the normal estimation from one of discrete to continuous, and drastically reduces the storage requirement and running time. Both algorithms produce comparable and very faithful normals for complex scenes. Although the discontinuity-preserving metric in graph cuts permits efficient inference of optimal discrete labels with a theoretical guarantee, our estimation algorithm using tensor belief propagation converges to comparable results, but runs faster because very compact messages are passed and combined. We present very encouraging results on normal reconstruction. A simple algorithm is proposed to reconstruct a surface from a normal map recovered by our method. With the reconstructed surface, an inverse process, known as relighting in computer graphics, is proposed to synthesize novel images of the given scene under user-specified light source and direction. The synthesis is made to run in real time by exploiting the state-of-the-art graphics processing unit (GPU). Our method offers many unique advantages over previous relighting methods and can handle a wide range of novel light sources and directions.	Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Hong Kong University of Science & Technology; Chinese University of Hong Kong	Wu, TP (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Clear Water Bay, Kowloon, Hong Kong, Peoples R China.	pang@cs.ust.hk; kamlun.tang@gmail.com; cktang@cs.ust.hk; ttwong@cse.cuhk.edu.hk						Ballard D.H., 1982, COMPUTER VISION; Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898; Basri R, 2001, PROC CVPR IEEE, P374; Belhumeur PN, 1996, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.1996.517085; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; Forsyth David A, 2012, COMPUTER VISION MODE; GOLDMAN DB, 2005, P INT C COMP VIS; Haeberli P., 1992, SYNTHETIC LIGHTING P; HAGER G, 1996, P IEEE C COMP VIS PA; Hertzmann A, 2003, PROC CVPR IEEE, P533; Ho PM, 2005, IEEE T CIRC SYST VID, V15, P355, DOI 10.1109/TCSVT.2004.842601; Horn B., 1986, ROBOT VISION, P1; Horn B.K., 1978, DETERMINING SHAPE RE; Jeffry N., 1994, EUR WORKSH REND, P359; JU Y, 2003, P INT C IM PROC, P421; Kay G, 1995, GRAPH MODEL IM PROC, V57, P365, DOI 10.1006/gmip.1995.1032; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kovesi P, 2005, IEEE I CONF COMP VIS, P994; Landy M.S., 1991, COMPUTATIONAL MODELS; Lee K. M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P479, DOI 10.1109/CVPR.1992.223147; Leung CS, 2006, IEEE T IMAGE PROCESS, V15, P1031, DOI 10.1109/TIP.2005.863936; Li Y, 2004, IEEE T PATTERN ANAL, V26, P45, DOI 10.1109/TPAMI.2004.1261078; Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320; Medioni G., 2000, COMPUTATIONAL FRAMEW; Nayar SK, 1996, IEEE INT CONF ROBOT, P1326, DOI 10.1109/ROBOT.1996.506890; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Ng R, 2003, ACM T GRAPHIC, V22, P376, DOI 10.1145/882262.882280; Nishino K., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P618, DOI 10.1109/CVPR.1999.787003; Petrovic N, 2001, PROC CVPR IEEE, P743; Shan Y, 2001, PROC CVPR IEEE, P794; Solomon F, 1996, IEEE T PATTERN ANAL, V18, P449, DOI 10.1109/34.491627; SOLOMON F, 2003, IEEE T PATTERN ANAL, V25, P787; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; TAGARE HD, 1991, IEEE T PATTERN ANAL, V13, P133, DOI 10.1109/34.67643; Tang KL, 2005, PROC CVPR IEEE, P132; Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900; Vasilescu MAO, 2004, ACM T GRAPHIC, V23, P336, DOI 10.1145/1015706.1015725; Wong TT, 2002, IEEE T MULTIMEDIA, V4, P361, DOI 10.1109/TMM.2002.802835; WONG TT, 1997, P 8 EUR WORKSH REND, P13; WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu TP, 2005, PROC CVPR IEEE, P140; ZHANG Z, 1998, P INT C COMP VIS JAN	48	48	48	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1830	1846		10.1109/TPAMI.2006.224	http://dx.doi.org/10.1109/TPAMI.2006.224			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063687				2022-12-18	WOS:000240443400010
J	Gijbels, I; Lambert, A; Qiu, PH				Gijbels, I; Lambert, A; Qiu, PH			Edge-preserving image denoising and estimation of discontinuous surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						corners; edges; jump-preserving estimation; local linear fit; noise; nonparametric regression; smoothing; surface fitting; weighted residual mean square	STATISTICAL-ANALYSIS; NONLINEAR DIFFUSION; RECONSTRUCTION; RESTORATION; ALGORITHMS; 1ST-ORDER; RECOVERY; PARALLEL; MODELS; GIBBS	In this paper, we are interested in the problem of estimating a discontinuous surface from noisy data. A novel procedure for this problem is proposed based on local linear kernel smoothing, in which local neighborhoods are adapted to the local smoothness of the surface measured by the observed data. The procedure can therefore remove noise correctly in continuity regions of the surface and preserve discontinuities at the same time. Since an image can be regarded as a surface of the image intensity function and such a surface has discontinuities at the outlines of objects, this procedure can be applied directly to image denoising. Numerical studies show that it works well in applications, compared to some existing procedures.	Univ Leuven, Univ Ctr Stat, Dept Math, B-3001 Heverlee, Belgium; Catholic Univ Louvain, Inst Stat, B-1348 Louvain, Belgium; Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA	KU Leuven; Universite Catholique Louvain; University of Minnesota System; University of Minnesota Twin Cities	Gijbels, I (corresponding author), Univ Leuven, Univ Ctr Stat, Dept Math, Croylaan 54, B-3001 Heverlee, Belgium.	irene.gijbels@wis.kuleuven.be; alambert@stat.ucl.ac.be; qiu@stat.umn.edu	Gijbels, Irene/AAI-1699-2019	Gijbels, Irene/0000-0002-4443-9803				Arigovindan M, 2005, IEEE T IMAGE PROCESS, V14, P450, DOI 10.1109/TIP.2004.841203; Barash D, 2004, IMAGE VISION COMPUT, V22, P73, DOI 10.1016/j.imavis.2003.08.005; Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; BOVIK AC, 1987, IEEE T PATTERN ANAL, V9, P181, DOI 10.1109/TPAMI.1987.4767894; BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222; Chabat F, 1999, IMAGE VISION COMPUT, V17, P761, DOI 10.1016/S0262-8856(98)00150-4; Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1522, DOI 10.1109/83.862630; Chu CK, 1998, J AM STAT ASSOC, V93, P526, DOI 10.2307/2670100; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P281, DOI 10.1109/TPAMI.2003.1177159; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; DONOHO DL, 2001, LECT NOTES COMPUTATI, P149; Fan J.Q., 1996, LOCAL POLYNOMIAL MOD; Fessler JA, 2000, IEEE T IMAGE PROCESS, V9, P1049, DOI 10.1109/83.846247; Figueiredo MAT, 2001, IEEE T IMAGE PROCESS, V10, P1322, DOI 10.1109/83.941856; GALLAGHER NC, 1981, IEEE T ACOUST SPEECH, V29, P1136, DOI 10.1109/TASSP.1981.1163708; GARCIA MA, 1994, P IEEE INT C MULT FU, P559; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GIJBELS I, 2005, EDGE PRESERVING IMAG; GIJELS I, 2006, IN PRESS ANN I STAT, V58; Godtliebsen F., 1994, J APPL STAT, V21, P459; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; Haavisto P., 1991, Journal of Circuits, Systems and Computers, V1, P125, DOI 10.1142/S0218126691000021; Huang T.S., 1981, TOP APPL PHYS; Hummel A, 1987, P IEEE COMP VIS PATT, P204; LI SZ, 1995, IEEE T PATTERN ANAL, V17, P576, DOI 10.1109/34.387504; Marroquin JL, 2001, IEEE T PATTERN ANAL, V23, P337, DOI 10.1109/34.917570; MOUSSOUR.J, 1974, J STAT PHYS, V10, P11, DOI 10.1007/BF01011714; NASON GP, 1994, J COMPUTATIONAL GRAP, V3, P163; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; POGGIO T, 1985, COMPUT VISION GRAPH, V31, P139, DOI 10.1016/S0734-189X(85)80003-7; Polzehl J, 2000, J R STAT SOC B, V62, P335, DOI 10.1111/1467-9868.00235; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Qiu P, 2005, WILEY SER PROBAB ST, P1, DOI 10.1002/0471733156; Qiu PH, 2004, TECHNOMETRICS, V46, P87, DOI 10.1198/004017004000000149; Qiu PH, 1998, ANN STAT, V26, P2218; Rivera M, 2002, COMPUT VIS IMAGE UND, V88, P76, DOI 10.1006/cviu.2002.0975; SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339; SINHA SS, 1992, IEEE T PATTERN ANAL, V14, P36, DOI 10.1109/34.107012; STEVENSON RL, 1992, IEEE T PATTERN ANAL, V14, P897, DOI 10.1109/34.161349; Strohmer T, 1997, IEEE T IMAGE PROCESS, V6, P540, DOI 10.1109/83.563319; SUN T, 1994, SIGNAL PROCESS, V35, P213, DOI 10.1016/0165-1684(94)90212-7; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Tukey J. W., 1977, EXPLORATORY DATA ANA; Yang GZ, 1996, IMAGE VISION COMPUT, V14, P135, DOI 10.1016/0262-8856(95)01047-5; YI JH, 1995, IEEE T PATTERN ANAL, V17, P624, DOI 10.1109/34.387510	52	48	58	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2006	28	7					1075	1087		10.1109/TPAMI.2006.140	http://dx.doi.org/10.1109/TPAMI.2006.140			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	041AG	16792097				2022-12-18	WOS:000237424400005
J	Elder, JH; Krupnik, A; Johnston, LA				Elder, JH; Krupnik, A; Johnston, LA			Contour grouping with prior models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						perceptual organization; grouping; contours; edges; graph search; Bayesian probabilistic inference; segmentation; remote sensing; skin detection	EDGE; IMAGES; SEGMENTATION; ORGANIZATION; STATISTICS; PROXIMITY; INFERENCE; CLOSURE; SNAKES; CURVE	Conventional approaches to perceptual grouping assume little specific knowledge about the object(s) of interest. However, there are many applications in which such knowledge is available and useful. Here, we address the problem of finding the bounding contour of an object in an image when some prior knowledge about the object is available. We introduce a framework for combining prior probabilistic knowledge of the appearance of the object with probabilistic models for contour grouping. A constructive search technique is used to compute candidate closed object boundaries, which are then evaluated by combining figure, ground, and prior probabilities to compute the maximum a posteriori estimate. A significant advantage of our formulation is that it rigorously combines probabilistic local cues with important global constraints such as simplicity (no self-intersections), closure, completeness, and nontrivial scale priors. We apply this approach to the problem of computing exact lake boundaries from satellite imagery, given approximate prior knowledge from an existing digital database. We quantitatively evaluate the performance of our algorithm and find that it exceeds the performance of human mapping experts and a competing active contour approach, even with relatively weak prior knowledge. While the priors may be task-specific, the approach is general, as we demonstrate by applying it to a completely different problem: the computation of human skin boundaries in natural imagery.	York Univ, Ctr Vis Res, N York, ON M3J 1P3, Canada; Technion Israel Inst Technol, Dept Civil Engn, IL-32000 Haifa, Israel	York University - Canada; Technion Israel Institute of Technology	Elder, JH (corresponding author), York Univ, Ctr Vis Res, 4700 Keele St, N York, ON M3J 1P3, Canada.	jelder@yorku.ca; amonk@softhome.net; leighj@mirror.cvr.yorku.ca	Johnston, Leigh A/D-7102-2014	Johnston, Leigh A/0000-0002-5032-4674				ALTER TD, 1995, THESIS MIT; Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; [Anonymous], 1938, SOURCE BOOK GESTALT; Borra S, 1997, IEEE T PATTERN ANAL, V19, P1306, DOI 10.1109/34.632991; BRUNSWIK E, 1953, AM J PSYCHOL, V66, P20, DOI 10.2307/1417965; Castano RL, 1996, COMPUT VIS IMAGE UND, V64, P399, DOI 10.1006/cviu.1996.0068; CAVANAGH P, 1999, MIT ENCY COGNITIVE S, P844; Cavanagh P., 1991, REPRESENTATION VISIO, P295; Cazorla M, 2002, PATTERN RECOGN, V35, P1869, DOI 10.1016/S0031-3203(01)00150-9; Chesnaud C, 1999, IEEE T PATTERN ANAL, V21, P1145, DOI 10.1109/34.809108; COX IJ, 1993, INT J COMPUT VISION, V11, P5, DOI 10.1007/BF01420590; Crevier D, 1999, COMPUT VIS IMAGE UND, V76, P36, DOI 10.1006/cviu.1999.0785; CREVIER D, 2001, RECENT ADV PERCEPTUA, P163; DUDEK G, 1990, P 10 INT C PATT REC; ELDER J, 1993, VISION RES, V33, P981, DOI 10.1016/0042-6989(93)90080-G; Elder JH, 1998, PERCEPTION, V27, P11; Elder J.H., 1998, P IEEE CS WORKSH PER; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Elder JH, 2001, IEEE T PATTERN ANAL, V23, P291, DOI 10.1109/34.910881; ELDER JH, 1996, P 4 EUR C COMP VIS, P399; Fua P, 1998, INT J COMPUT VISION, V26, P215, DOI 10.1023/A:1007905112118; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; HUTTENLOCHER DP, 1992, INT J COMPUT VISION, V8, P7, DOI 10.1007/BF00126398; Jacobs D. W., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P770, DOI 10.1109/CVPR.1993.341167; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008; Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198; Kanizsa G., 1979, ORG VISION; Kaschube M, 2001, NEUROCOMPUTING, V38, P1335, DOI 10.1016/S0925-2312(01)00493-3; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Koffka K., 1935, PRINCIPLES GESTALT P; KOVACS I, 1993, P NATL ACAD SCI USA, V90, P7495, DOI 10.1073/pnas.90.16.7495; Kruger N, 1998, NEURAL PROCESS LETT, V8, P117, DOI 10.1023/A:1009688428205; Laptev I, 2000, MACH VISION APPL, V12, P23, DOI 10.1007/s001380050121; LEUNG T, 1998, P 5 EUR C COMP VIS J; LINDENBAUM M, 2000, P EUR C COMP VIS, V2, P257; Liu TL, 1997, LECT NOTES COMPUT SC, V1223, P295; LOWE DG, 1989, INT J COMPUT VISION, V3, P119, DOI 10.1007/BF00126428; Mahamud S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P891, DOI 10.1109/ICCV.1999.790316; MALLAT S, 1989, IEEE T PATTERN ANAL, V11, P7; MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; Murino V, 1996, COMPUT VIS IMAGE UND, V64, P157, DOI 10.1006/cviu.1996.0051; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; RISEMAN EM, 1977, COMPUT VISION GRAPH, V6, P221, DOI 10.1016/S0146-664X(77)80028-2; Rock I., 1983, LOGIC PERCEPTION; ROCKLAND KS, 1994, VISUAL NEUROSCIENCE; SAUND E, 1992, P IEEE C COMP VIS PA, P817; SIGMAN M, 2001, P NATL ACAD SCI; Simoncelli EP, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P379; Simoncelli EP, 1999, P SOC PHOTO-OPT INS, V3813, P188, DOI 10.1117/12.366779; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Weaver W., 1949, MATH THEORY INFORM; Williams LR, 1999, INT J COMPUT VISION, V34, P81, DOI 10.1023/A:1008187804026; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; WILLIAMS LR, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P408, DOI 10.1109/ICCV.1995.466910; Yuille AL, 2000, IEEE T PATTERN ANAL, V22, P160, DOI 10.1109/34.825754; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; ZUCKER SW, 1983, PERCEPT PSYCHOPHYS, V34, P513, DOI 10.3758/BF03205904	62	48	58	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2003	25	6					661	674		10.1109/TPAMI.2003.1201818	http://dx.doi.org/10.1109/TPAMI.2003.1201818			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	680DP					2022-12-18	WOS:000182961300003
J	Mignotte, M; Collet, C; Perez, P; Bouthemy, P				Mignotte, M; Collet, C; Perez, P; Bouthemy, P			Hybrid genetic optimization and statistical model-based approach for the classification of shadow shapes in sonar imagery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						deformable template; objective function; simulated annealing; gradient-based algorithm; genetic optimization; shape recognition; sonar imagery	DEFORMABLE TEMPLATES; SEGMENTATION; RESTORATION	We present an original statistical classification method using a deformable template model to separate natural objects from man-made objects in an image provided by a high resolution sonar. A prior knowledge of the manufactured object shadow shape is captured by a prototype template, along with a set of admissible linear transformations, to take into account the shape variability. Then, the classification problem is defined as a two-step process. First, the detection problem of a region of interest in the input image is stated as the minimization of a cost function. Second, the value of this function at convergence allows one to determine whether the desired object is present or not in the sonar image. The energy minimization problem is tackled using relaxation techniques. In this context, we compare the results obtained with a deterministic relaxation technique (a gradient-based algorithm) and two stochastic relaxation methods: Simulated Annealing (SA) and a hybrid Genetic Algorithm (GA). This latter method has been successfully tested on real and synthetic sonar images, yielding very promising results.	Ecole Navale, Grp Traitement Signal, F-29240 Brest, France; Inst Natl Rech Informat & Automat, IRISA, F-35042 Rennes, France		Mignotte, M (corresponding author), Ecole Navale, Grp Traitement Signal, BP 600, F-29240 Brest, France.	collet@poseidon.ecole.navale.fr; perez@irisa.fr; bouthemy@irisa.fr	Mignotte, Max/F-7014-2015					BESAG J, 1986, J R STAT SOC B, V48, P259; Fisher Y., 1995, FRACTAL IMAGE COMPRE; GALERNE P, 1997, P EUR S LAS OPT MAN, V1, P306; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GOLDBERG DE, 1989, GENETIC ALGORITHM; GOODMAN JW, 1976, J OPT SOC AM, V66, P1145, DOI 10.1364/JOSA.66.001145; GRENANDER U, 1993, ADV APPL STAT, V16, P89; HYLAND JC, 1995, P SOC PHOTO-OPT INS, V2496, P442, DOI 10.1117/12.211341; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; Jolly MPD, 1996, IEEE T PATTERN ANAL, V18, P293, DOI 10.1109/34.485557; Kervrann C, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P937, DOI 10.1109/ICIP.1996.559654; KLUGE K, 1995, P AS C COMP VIS, P141; Lakshmanan S, 1996, IEEE T PATTERN ANAL, V18, P438, DOI 10.1109/34.491625; MIGNOTTE M, 1997, P INT C AC SPEECH SI, V4, P2781; MIGNOTTE M, 1998, P IEEE INT C AC SPEE, V5, P2541; Nakazawa Y, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P689, DOI 10.1109/ICIP.1996.560972; REGAZZONI CS, 1993, SIGNAL PROCESS, V34, P43, DOI 10.1016/0165-1684(93)90026-7; Schmitt F., 1996, SPIE, V2823, P1	18	48	55	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2000	22	2					129	141		10.1109/34.825752	http://dx.doi.org/10.1109/34.825752			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	292JU					2022-12-18	WOS:000085791400001
J	Sullivan, S; Ponce, J				Sullivan, S; Ponce, J			Automatic model construction and pose estimation from photographs using triangular splines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automatic model acquisition; shape representation; pose estimation	OBJECT; SILHOUETTES; CONTOURS; MESHES	This paper addresses the automatic construction of complex spline object models from a few photographs. Our approach combines silhouettes from registered images to construct a G(1)-continuous triangular spline approximation of an object with unknown topology. We apply a similar optimization procedure to estimate the pose of a modeled object from a single image. Experimental examples of model construction and pose estimation are presented for several complex objects.	Rhythm & Hues Studios, Los Angeles, CA 90025 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Sullivan, S (corresponding author), Rhythm & Hues Studios, Los Angeles, CA 90025 USA.	sullivan@rhythm.com; ponce@cs.uiuc.edu						BAUMGART BG, 1974, THESIS STANFORD U PA; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BOYER E, 1996, LECT NOTES COMPUTER, V1065, P109; BRUNIE L, 1992, LECT NOTES COMPUT SC, V588, P670; CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0; Chiyokura H., 1983, Computer Graphics, V17, P289, DOI 10.1145/964967.801160; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; CONNOLLY CI, 1989, P IEEE WORKSHOP INTE, P124; DYER C, 1994, P CVPR, P331; Eck M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P325, DOI 10.1145/237170.237271; Farin G, 1990, CURVES SURFACES COMP; GIBLIN P, 1986, INT C COMP VIS LOND, P136; Hoppe H., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P295, DOI 10.1145/192161.192233; HOPPE H, 1993, COMPUTER GRAPHIC AUG, P113; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; LOOP C, 1994, COMPUT AIDED GEOM D, V11, P303, DOI 10.1145/192161.192238; NIEM W, 1994, EUR WORKSH COMB REAL; Peters J, 1995, COMPUT AIDED DESIGN, V27, P895, DOI 10.1016/0010-4485(95)00010-0; Shirman L. A., 1991, Computer-Aided Geometric Design, V8, P217, DOI 10.1016/0167-8396(91)90005-V; Shirman L. A., 1987, Computer-Aided Geometric Design, V4, P279, DOI 10.1016/0167-8396(87)90003-3; SRIVASTAVA SK, 1990, COMPUT VISION GRAPH, V49, P68, DOI 10.1016/0734-189X(90)90163-P; SULLIVAN S, 1994, IEEE T PATTERN ANAL, V16, P1183, DOI 10.1109/34.387489; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; VELTKAMP R, 1994, LECT NOTES COMPUTER; Vijayakumar B, 1996, PROC CVPR IEEE, P327, DOI 10.1109/CVPR.1996.517093	26	48	49	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1998	20	10					1091	1097		10.1109/34.722621	http://dx.doi.org/10.1109/34.722621			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	128QB					2022-12-18	WOS:000076416400006
J	PARK, HC; CHIN, RT				PARK, HC; CHIN, RT			DECOMPOSITION OF ARBITRARILY-SHAPED MORPHOLOGICAL STRUCTURING ELEMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MATHEMATICAL MORPHOLOGY; STRUCTURING ELEMENT DECOMPOSITION; CONCAVE BOUNDARY		For image processing systems that have a limited size of region of support, say 3 x 3, direct implementation of morphological operations by a structuring element larger than the prefixed size is impossible. The decomposition of morphological operations by a large structuring element into a sequence of recursive operations, each using a smaller structuring element, enables the implementation of large morphological operations. In this paper, we present the decomposition of arbitrarily shaped (convex or concave) structuring elements into 3 x 3 elements, optimized with respect to the number of 3 x 3 elements. The decomposition is based on the concept of factorization of a structuring element into its prime factors. For a given structuring element, all its corresponding 3 x 3 prime concave factors are first determined. From the set of the prime factors, the decomposability of the structuring element is then established, and subsequently the structuring element is decomposed into a smallest possible set of 3 x 3 elements. Examples of optimal decomposition and structuring elements that are not decomposable are presented.	UNIV WISCONSIN,DEPT ELECT & COMP ENGN,MADISON,WI 53706; HONG KONG UNIV SCI & TECHNOL,DEPT COMP SCI,HONG KONG,HONG KONG	University of Wisconsin System; University of Wisconsin Madison; Hong Kong University of Science & Technology			Chin, Roland Tai Hong/E-9856-2010					Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; KANUNGO T, 1990, P SOC PHOTO-OPT INS, V1350, P419, DOI 10.1117/12.23609; LI D, 1990, P SOC PHOTO-OPT INS, V1350, P408, DOI 10.1117/12.23608; MARAGOS PA, 1985, IEEE T ACOUST SPEECH, V34, P1228; PARK H, 1994, IEEE T PATTERN ANAL, V16; PITAS I, 1990, IEEE T PATTERN ANAL, V12, P38, DOI 10.1109/34.41382; STERNBERG SR, 1983, COMPUTER, V16, P22, DOI 10.1109/MC.1983.1654163; XU JN, 1991, IEEE T PATTERN ANAL, V13, P153, DOI 10.1109/34.67644; ZHUANG X, 1992, P IEEE C COMPUTER VI; ZHUANG XH, 1986, COMPUT VISION GRAPH, V35, P370, DOI 10.1016/0734-189X(86)90006-X	11	48	60	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1995	17	1					2	15		10.1109/34.368156	http://dx.doi.org/10.1109/34.368156			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QB394					2022-12-18	WOS:A1995QB39400002
J	RAO, KR; BENARIE, J				RAO, KR; BENARIE, J			OPTIMAL EDGE-DETECTION USING EXPANSION MATCHING AND RESTORATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								This paper discusses the application of a newly developed expansion matching method for edge detection. Expansion matching optimizes a novel matching criterion called Discriminative Signal to Noise Ratio (DSNR) and has been shown to robustly recognize templates under conditions of noise, severe occlusion, and superposition. The DSNR criterion is better suited to evaluate matching in practical conditions than the traditional SNR since it considers as ''noise,'' even the off-center response of the filter to the template itself. In this paper, we introduce a family of optimal DSNR edge detectors based on the expansion filter for several edge models. For step edges, the optimal DSNR Step Expansion Filter (SEF) is compared with the widely used Canny Edge Detector (CED). Experimental comparisons show that our edge detector yields better performance than the CED in terms of DSNR even under very adverse noise conditions. As for boundary detection, the SEF consistently yields higher figures of merit than the CED on a synthetic binary image over a wide range of noise levels. Results also show that the design parameters of size or width of the SEF are less critical than the CED variance. This means that a single scale of the SEF spans a larger range of input noise than a single scale of the CED. Experiments on a noisy image reveal that the SEF yields less noisy edge elements and preserves structural details more accurately. On the other hand, the CED output has better suppression of multiple responses than the corresponding SEF output.			RAO, KR (corresponding author), IIT,DEPT ELECT & COMP ENGN,COMP VIS & NEURAL NETWORK LAB,CHICAGO,IL 60616, USA.							Ben-Arie J, 1993, IEEE T CIRC SYST VID, V3, P71, DOI 10.1109/76.180691; BENARIE J, 1994, IN PRESS INT J MACHI; BENARIE J, 1992, NEURAL NETWORKS HUMA, P231; BENARIE J, 1993, APR P IEEE INT C AC, pV145; BENARIE J, 1991, NOV P IEEE INT JOINT, P958; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Castan S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P709, DOI 10.1109/ICPR.1990.118199; DEMOMENT G, 1989, IEEE T ACOUST SPEECH, V37, P2024, DOI 10.1109/29.45551; DERICHE R, 1987, INT J COMPUT VISION, P167; DICKLEY FM, 1977, IEEE T PATTERN ANAL, V1, P37; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; Jain A. K., 1989, FUNDAMENTALS DIGITAL; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MODESTINO JW, COMPUT GRAPHICS IMAG, V6, P409; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; Pratt W. K., 1978, DIGITAL IMAGE PROCES; RAO KR, 1993, JUN P IEEE C COMP VI, P791; RAO KR, 1993, MAY P IEEE INT S CIR, P547; SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275; SARKAR S, 1991, CVGIP-IMAG UNDERSTAN, V54, P224, DOI 10.1016/1049-9660(91)90065-W; Saunders H., 1989, PROBABILITY RANDOM V; Shen J., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P109; SPACEK LA, 1986, IMAGE VISION COMPUT, V4, P43, DOI 10.1016/0262-8856(86)90007-7	24	48	49	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1994	16	12					1169	1182		10.1109/34.387490	http://dx.doi.org/10.1109/34.387490			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QA715					2022-12-18	WOS:A1994QA71500002
J	TAKEDA, H; FACCHINETTI, C; LATOMBE, JC				TAKEDA, H; FACCHINETTI, C; LATOMBE, JC			PLANNING THE MOTIONS OF A MOBILE ROBOT IN A SENSORY UNCERTAINTY FIELD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							NAVIGATION	Failures in mobile robot navigation are often caused by errors in localizing the robot relative to its environment. This paper explores the idea that these errors can be considerably reduced by planning paths taking the robot through positions where pertinent features of the environment can be sensed. It introduces the notion of a ''Sensory Uncertainty Field'' (SUF). For every possible robot configuration q, this field estimates the distribution of possible errors in the robot configuration that would be computed by a localization function matching the data given by the sensors against an environment model, if the robot was at q. A planner is proposed which uses a precomputed SUF to generate paths that minimize expected errors or any other criterion combining, say, path length and errors. This paper describes in detail the computation of a specific SUF for a mobile robot equipped with a classical line-striping camera/laser range sensor. It presents an implemented SUF-based motion planner for this robot and shows paths generated by this planner. Navigation experiments were conducted with mobile robots using paths generated by the SUF-based planner and other paths. The former paths were tracked with greater precision than the others. The final section of the paper discusses additional research issues related to SUF-based planning.	INST MICROTECHNOL,NEUCHATEL,SWITZERLAND; STANFORD UNIV,DEPT COMP SCI,ROBOT LAB,STANFORD,CA 94305; STANFORD UNIV,COMP SCI ROBOT LAB,STANFORD,CA 94305	Stanford University; Stanford University	TAKEDA, H (corresponding author), HITACHI LTD,SYST DEV LAB,1099 OHZENJI,ASAO KU,KAWASAKI,KANAGAWA 215,JAPAN.							[Anonymous], 1980, PRINCIPLES ARTIFICIA; [Anonymous], 1983, DATA STRUCTURES ALGO; Ayache N, 1991, ARTIFICIAL VISION MO; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P137, DOI 10.1109/TPAMI.1984.4767499; BUCKLEY SJ, 1986, THESIS MIT CAMBRIDGE; Caloud P., 1990, Proceedings. IROS '90. IEEE International Workshop on Intelligent Robots and Systems '90. Towards a New Frontier of Applications (Cat. No.90TH0332-7), P67, DOI 10.1109/IROS.1990.262370; CANNY JF, 1989, 1989 P IEEE INT C RO, P177; CHATILA R, 1985, IEEE INT C ROB AUT, P138; Choi W., 1991, P IEEE RSJ INT WORKS, P24; COWAN GK, 1988, IEEE T PATTERN ANAL, V10, P407; CROWLEY JL, 1989, MAY P IEEE INT C ROB, P674; DESAI RS, 1988, THESIS U MICHIGAN; DONALD BR, 1988, ARTIF INTELL, V37, P223, DOI 10.1016/0004-3702(88)90056-2; DONALD BR, 1991, IEEE INT C ROB AUT S, P190; DONALD BR, 1992, J ROBOT AUTONOMOUS S, V9, P41; DRUMHELLER M, 1985, MIT826 AI LAB TECH R; Duda R.O., 1973, J ROYAL STAT SOC SER; DUFAY B, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300401; DURRANTWHYTE HF, 1988, IEEE J ROBOT AUTOM, V4, P23, DOI 10.1109/56.768; ELFES A, 1992, IEEE T ROBOTIC AUTOM, P2561; ERDMANN MA, 1986, IEEE T ROBOTIC AUTOM, P1569; ERDMANN ME, 1984, MIT810 AI LAB TECH R; ERDMANN ME, 1990, MIT1155 AI LAB TECH; FACCHINETTI C, 1993, SEP P SWISS VIS C ZU, P45; FACCHINETTI C, 1993, SEP P ICSPAT 93 SANT; FOX A, 1992, UIUCBIAIRCV9205 U IL; GOTTSCHLICH SN, 1991, 9TH P NAT C ART INT, P646; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GUIBAS LJ, 1991, P S DISCR ALG, P259; HUTCHINSON S, 1991, IEEE T ROBOTIC AUTOM, P1722; KRIEGMAN DJ, 1989, IEEE T ROBOTIC AUTOM, V5, P792, DOI 10.1109/70.88100; Latombe J.-C., 1992, LANDMARK BASED ROBOT; Latombe J.-C, 2012, ROBOT MOTION PLANNIN, V124; LATOMBE JC, 1991, ARTIF INTELL, V52, P1, DOI 10.1016/0004-3702(91)90023-D; LAUGIER C, 1986, P EUROPEAN C ARTIFIC; LAZANAS A, 1992, 10TH P NAT C ART INT, P816; LEONARD JJ, 1991, IEEE T ROBOTIC AUTOM, V7, P376, DOI 10.1109/70.88147; LEONARD JJ, 1992, INT J ROBOT RES, V11, P286, DOI 10.1177/027836499201100402; LEVITT T, 1987, P DARPA IMAGE UNDERS, P447; LOZANOPEREZ T, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300101; LOZANOPEREZ T, 1976, AITR397 MIT AI LAB T; LUMELSKY V, 1990, IEEE T SYST MAN CYB, V20, P1058, DOI 10.1109/21.59969; MAHADEVAN S, 1990, AUTOMATIC PROGRAMMIN; MILLER D, 1985, IEEE T ROBOTIC AUTOM, P122; MORAVEC HP, 1985, IEEE T ROBOTIC AUTOM, P116; NAKAMURA Y, 1989, IEEE INT C ROB AUT, P668; PERTINTROCCAZ J, 1988, ROBOTICS RES, V4, P455; ROTH Y, 1992, IEEE T ROBOTIC AUTOM, P2625; SABATER A, 1991, IEEE T ROBOTIC AUTOM, P2718; TAKEDA H, 1992, STANCS921424 STANF U; TAKEDA H, 1992, IEEE T ROBOTIC AUTOM, P2465; TARABANIS K, 1991, IEEE T ROBOTIC AUTOM, P76; TAYLOR RH, 1976, THESIS STANF U DEP C; XIE S, 1990, IEEE T ROBOTIC AUTOM, P748; ZHANG ZY, 1992, INT J ROBOT RES, V11, P269, DOI 10.1177/027836499201100401; ZHENG JY, 1991, IEEE T ROBOTIC AUTOM, P2004	56	48	49	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1994	16	10					1002	1017		10.1109/34.329009	http://dx.doi.org/10.1109/34.329009			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PM827					2022-12-18	WOS:A1994PM82700004
J	MUSAVI, MT; CHAN, KH; HUMMELS, DM; KALANTRI, K				MUSAVI, MT; CHAN, KH; HUMMELS, DM; KALANTRI, K			ON THE GENERALIZATION ABILITY OF NEURAL-NETWORK CLASSIFIERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter								This correspondence presents a method for evaluation of artificial neural network (ANN) classifiers. In order to find the performance of the network over all possible input ranges, a probabilistic input model is defined, The expected error of the output over this input range is taken as a measure of generalization ability. Two essential elements for carrying out the proposed evaluation technique are estimation of the input probability density and numerical integration. A nonparametric method, which depends on the nearest M neighbors, is used to locally estimate the distribution around each training pattern. An orthogonalization procedure is utilized to determine the covariance matrices of local densities. A Monte Carlo method is used to perform the numerical integration. The proposed evaluation technique has been used to investigate the generalization ability of back propagation (BP), radial basis function (RBF) and probabilistic neural network (PNN) classifiers for three test problems.	ELECTROOPT INFORMAT SYST,SANTA MONICA,CA		MUSAVI, MT (corresponding author), UNIV MAINE,DEPT ELECT & COMP ENGN,ORONO,ME 04469, USA.							BILLINTON R., 1992, RELIABILITY EVALUATI; Broomhead D. S., 1988, Complex Systems, V2, P321; CHAN KH, 1990, THESIS U MAINE; DENG C, 1990, JUN P INT JOINT C NE, V1, P241; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; EPANECHN.VA, 1969, THEOR PROBAB APPL+, V14, P153, DOI 10.1137/1114019; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P1087, DOI 10.1109/34.42839; Golub G. H., 1996, MATRIX COMPUTATIONS; HATAOKA N, 1990, JUN P INT JOINT C NE, V1, P57; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LEEN M, 1990, JUN P P INT JOINT C, V1, P51; LIPPMANN RP, 1989, IEEE COMMUNICATI NOV, P47; MEISEL WS, 1972, COMPUTER ORIENTED AP, V83; MICCHELLI CA, 1986, CONSTR APPROX, V2, P11, DOI 10.1007/BF01893414; Moody J, 1989, NEURAL COMPUT, V1, P281, DOI 10.1162/neco.1989.1.2.281; MUSAVI MT, 1992, NEURAL NETWORKS, V5, P595, DOI 10.1016/S0893-6080(05)80038-3; MUSAVI MT, 1991, MAY P AN NEUR NETW A, P110; POWELL MJD, 1985, IMA C ALGORITHMS APP; Richard MD, 1991, NEURAL COMPUT, V3, P461, DOI 10.1162/neco.1991.3.4.461; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SHYU HJ, 1990, JUN P INT JOINT C NE, V1, P101; Specht D F, 1990, IEEE Trans Neural Netw, V1, P111, DOI 10.1109/72.80210; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264667; STRANG G, 1976, LINEAR ALGEBRA ITS A; VRCKOVNIK CR, 1990, JUN P INT JOINT C NE, V1, P45; YOSHIMOTO S, 1990, JUN P INT JOINT C NE, V3, P689; YU YH, 1990, JUN P INT JOINT C NE, P167	27	48	49	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					659	663		10.1109/34.295911	http://dx.doi.org/10.1109/34.295911			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200012
J	YOUNG, GSJ; CHELLAPPA, R				YOUNG, GSJ; CHELLAPPA, R			STATISTICAL-ANALYSIS OF INHERENT AMBIGUITIES IN RECOVERING 3-D MOTION FROM A NOISY FLOW FIELD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							3-DIMENSIONAL MOTION; VISUAL-MOTION; OPTICAL-FLOW; IMAGES; PARAMETERS; SEQUENCE; OBJECTS; UNIQUENESS	In this paper, the inherent ambiguities in recovering 3-D motion information from a single optical flow field are studied using a statistical model. These ambiguities are quantified using the Cramer-Rao lower bound, which is a lower bound for the error variances of motion parameter estimates. This performance bound is independent of the motion estimation algorithms and can always be computed for any arbitrary 3-D motion of a rigid surface by inverting a 5 x 5 matrix. As a special case, the performance bound for the motion of 3-D rigid planar surfaces is studied in detail. The dependence of the bound on several factors, such as the underlying motion, surface position, surface orientation, field of view, and density of available pixels are derived as closed-form expressions. A subset of our results support Adiv's analysis of the inherent ambiguities of motion parameters. For the general motion of an arbitrary surface, it turns out that not every pixel gives information regarding 3-D motion estimation. We show that the aperture problem in computing the optical flow restricts the nontrivial information about the 3-D motion to a sparse set of pixels at which both components of the flow velocity are observable. Computer simulations are used to study the dependence of the inherent ambiguities on the underlying motion, the field of view, and the number of feature points for the motion in front of a nonplanar environment. It is shown that a smoothness constraint introduced by fitting local patches to 3-D depths gives lower bounds. However, this reduction is very small. Further, fitting local patches also relaxes the aperture problem since the motion information is not restricted to points at which both optical flow components are observable.	UNIV MARYLAND,INST ADV COMP STUDIES,DEPT ELECT ENGN,COLL PK,MD 20742; UNIV MARYLAND,CTR AUTOMAT RES,COLL PK,MD 20742	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park	YOUNG, GSJ (corresponding author), IBM CORP,AUSTIN,TX, USA.		Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAJ-1504-2020					ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AGGARWAL JK, 1986, MAY P IEEE WORKSH MO; ALOIMONOS J, 1989, INTEGRATION VISUAL M; ANANDAN P, 1985, DEC P DARPA IM UND W, P186; ANANDAN P, 1984, OCT P DARPA IM UND W, P236; ANANDAN P, 1987, MAY INT C COMP VIS L, P219; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; BROIDA TJ, 1989, J OPT SOC AM A, V6, P879, DOI 10.1364/JOSAA.6.000879; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; CERNUSCHIFRIAS B, 1989, IEEE T PATTERN ANAL, V11, P1028, DOI 10.1109/34.42835; Hildreth E., 1984, MEASUREMENT VISUAL M; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1987, INT J COMPUT VISION, V1, P259, DOI 10.1007/BF00127824; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; Sorenson H. W, 1980, CONTROL SYSTEMS THEO; SPETSAKIS ME, 1989, MAR P IEEE WORKSH VI, P229; STRANG G, 1980, LINEAR ALGEBRA ITS A; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; ULLMAN S, 1981, COMPUTER, V14, P57, DOI 10.1109/C-M.1981.220564; WAXMAN AM, 1987, INT J COMPUT VISION, V1, P239, DOI 10.1007/BF00127823; WENG J, 1989, MAR P IEEE WORKSH VI, P359; YOUNG GSJ, 1990, IEEE T PATTERN ANAL, V12, P735, DOI 10.1109/34.57666	27	48	50	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1992	14	10					995	1013		10.1109/34.159903	http://dx.doi.org/10.1109/34.159903			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR944					2022-12-18	WOS:A1992JR94400003
J	FUKUNAGA, K; HUMMELS, DM				FUKUNAGA, K; HUMMELS, DM			LEAVE-ONE-OUT PROCEDURES FOR NONPARAMETRIC ERROR-ESTIMATES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											FUKUNAGA, K (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634, DOI 10.1109/TPAMI.1987.4767958; FUKUNAGA K, 1972, INTRO STATISTICAL PA, pCH5	2	48	49	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1989	11	4					421	423		10.1109/34.19039	http://dx.doi.org/10.1109/34.19039			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T9100					2022-12-18	WOS:A1989T910000008
J	WECHSLER, H; ZIMMERMAN, GL				WECHSLER, H; ZIMMERMAN, GL			2-D INVARIANT OBJECT RECOGNITION USING DISTRIBUTED ASSOCIATIVE MEMORY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MINNESOTA,DEPT ELECT ENGN,MINNEAPOLIS,MN 55455	University of Minnesota System; University of Minnesota Twin Cities	WECHSLER, H (corresponding author), GEORGE MASON UNIV,DEPT COMP SCI,FAIRFAX,VA 22030, USA.							Anderson C. H., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V579, P72, DOI 10.1117/12.950785; ANDERSON JA, 1977, PSYCHOL REV, V84, P413, DOI 10.1037/0033-295X.84.5.413; BINFORD TO, 1971, P IEEE C SYSTEMS CON; CAMPBELL FW, 1970, J OPT SOC AM, V60, P555, DOI 10.1364/JOSA.60.000555; CASASENT D, 1977, P IEEE, V65, P77, DOI 10.1109/PROC.1977.10432; CASE SK, 1981, APPL OPTICS, V20, P2670, DOI 10.1364/AO.20.002670; CHAKRAVARTY I, 1982, P SOC PHOTO-OPT INST, V336, P37, DOI 10.1117/12.933609; HEBB OD, 1949, ORG BEHAVIOR; HOPFIELD JJ, 1982, APR P NAT AC SCI, V79; HUBEL D, 1979, SCI AM           OCT; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KOHONEN T, 1984, SELF ORG ASS MEMORIE; LANE RG, 1987, IEEE T ACOUST SPEECH, V35, P520, DOI 10.1109/TASSP.1987.1165157; Marr D., 1982, VISION; MASSONE L, 1985, COMPUT VISION GRAPH, V30, P169, DOI 10.1016/0734-189X(85)90095-7; MESSNER RA, 1985, COMPUT VISION GRAPH, V31, P50, DOI 10.1016/S0734-189X(85)80075-X; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; REITBOECK HJ, 1984, BIOL CYBERN, V51, P113, DOI 10.1007/BF00357924; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, DOI DOI 10.7551/MITPRESS/5236.001.0001; SCHWARTZ EL, 1977, BIOL CYBERN, V25; SIMON HA, 1984, SCI ARTIFICIAL; STILES GS, 1985, IEEE T PATTERN ANAL, V7, P358, DOI 10.1109/TPAMI.1985.4767667; WILSON HR, 1979, VISION RES, V19, P19, DOI 10.1016/0042-6989(79)90117-2; [No title captured]	24	48	51	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					811	821		10.1109/34.9104	http://dx.doi.org/10.1109/34.9104			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100004
J	LUNSCHER, WHHJ; BEDDOES, MP				LUNSCHER, WHHJ; BEDDOES, MP			OPTIMAL EDGE DETECTOR DESIGN .1. PARAMETER SELECTION AND NOISE EFFECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV BRITISH COLUMBIA,DEPT ELECT ENGN,VANCOUVER V6T 1W5,BC,CANADA	University of British Columbia	LUNSCHER, WHHJ (corresponding author), DEVELCON ELECTR LTD,DIV RES & DEV,SASKATOON,SASKATCHEWAN,CANADA.							CLARK J, 1983, COMMUNICATION; DICKEY FM, 1977, APPL OPTICS, V16, P145, DOI 10.1364/AO.16.000145; Duff G., 1966, DIFFERENTIAL EQUATIO; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; GRIMSON WEL, 1981, PHILOS T ROY SOC B, V292, P217, DOI 10.1098/rstb.1981.0031; Hale J. A. G., 1976, 3rd International Joint Conference on Pattern Recognition, P764; Heuckel M., 1973, J ASSOC COMPUT MACH, V20, P634; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; KITCHEN L, 1981, IEEE T SYST MAN CYB, V11, P597, DOI 10.1109/TSMC.1981.4308758; LEIPNIK R, 1960, INFORM CONTR, V3, P18, DOI DOI 10.1016/S0019-9958(60)90227-8; LOGAN BF, 1977, AT&T TECH J, V56, P487, DOI 10.1002/j.1538-7305.1977.tb00522.x; LUNSCHER WHHJ, 1986, IEEE T PATTERN ANAL, V8, P178, DOI 10.1109/TPAMI.1986.4767771; LUNSCHER WHHJ, 1983, IEEE T PATTERN ANAL, V5, P678, DOI 10.1109/TPAMI.1983.4767462; MACLEOD IDG, 1970, PICTURE LANGUAGE MAC, P231; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARR D, 1979, J OPT SOC AM, V69, P914, DOI 10.1364/JOSA.69.000914; PALEY R, 1934, AM MATH SOC C PUBL, V19; Roberts L, 1965, MACHINE PERCEPTION 3; SHANMUGAM KS, 1979, IEEE T PATTERN ANAL, V1, P37, DOI 10.1109/TPAMI.1979.4766874; Smith P. H., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P653	21	48	50	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					164	177		10.1109/TPAMI.1986.4767770	http://dx.doi.org/10.1109/TPAMI.1986.4767770			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869335				2022-12-18	WOS:A1986A107300004
J	MILLER, R; STOUT, QF				MILLER, R; STOUT, QF			GEOMETRIC ALGORITHMS FOR DIGITIZED PICTURES ON A MESH-CONNECTED COMPUTER	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MILLER, R (corresponding author), SUNY BINGHAMTON,DEPT MATH SCI,BINGHAMTON,NY 13901, USA.			Stout, Quentin/0000-0002-8047-7348				ATALLAH MJ, 1981, JHU8116 J HOPK U REP; BENTLEY JL, 1980, COMMUN ACM, V23, P214, DOI 10.1145/358841.358850; BEYER WT, 1969, THESIS MIT CAMBRIDGE; DANIELSSON PE, 1981, COMPUTER, V14, P53, DOI 10.1109/C-M.1981.220251; DYER CR, 1981, IEEE T PATTERN ANAL, V3, P29, DOI 10.1109/TPAMI.1981.4767048; FISCHLER MA, 1980, PATTERN RECOGN, V12, P35, DOI 10.1016/0031-3203(80)90052-7; FREEMAN H, 1975, COMMUN ACM, V18, P409, DOI 10.1145/360881.360919; GOLAY MJE, 1969, IEEE T COMPUT, VC 18, P733, DOI 10.1109/T-C.1969.222756; GRAY SB, 1971, IEEE T COMPUT, VC 20, P551, DOI 10.1109/T-C.1971.223289; Hubler A., 1982, Elektronische Informationsverarbeitung und Kybernetik (EIK), V18, P141; HWANG K, 1982, IEEE COMPUT, V15, P51; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; LEVIALDI S, 1972, COMMUN ACM, V15, P7, DOI 10.1145/361237.361240; Miller R., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P240; Minsky M., 1969, PERCEPTRONS; Moore E., 1962, P S APPL MATH, V14, P17, DOI DOI 10.1090/PSAPM/014/9961; NASSIMI D, 1980, SIAM J COMPUT, V9, P744, DOI 10.1137/0209058; REEVES AP, 1984, COMPUT VISION GRAPH, V25, P68, DOI 10.1016/0734-189X(84)90049-5; REINGOLD EM, 1977, COMBINATORIAL ALGORI, pCH8; ROSENFELD A, 1983, COMPUTER, V16, P14, DOI 10.1109/MC.1983.1654162; Shamos MI, 1978, THESIS YALE U NEW HA; SKLANSKY J, 1970, PATTERN RECOGN, V2, P3, DOI 10.1016/0031-3203(70)90037-3; STEFANELLI R, 1971, J ACM, V18, P255, DOI 10.1145/321637.321646; Stout Q. F., 1983, Proceedings of the 1983 International Conference on Parallel Processing, P214; Stout Q. F., 1982, 23rd Annual Symposium on Foundations of Computer Science, P272, DOI 10.1109/SFCS.1982.48; STOUT QF, 1983, 15TH P ANN ACM S THE, P24; STOUT QF, UNPUB GEOMETRIC ALGO; THOMPSON CD, 1977, COMMUN ACM, V20, P263, DOI 10.1145/359461.359481; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; UNGER SH, 1959, P IRE, V47, P1737, DOI 10.1109/JRPROC.1959.287109; UNGER SH, 1958, P IRE, V46, P1744, DOI 10.1109/JRPROC.1958.286755; UNGER SH, 1962, P S MATH THEORY AUTO, P577; VANSCOY FL, 1980, IEEE T COMPUT, V29, P563, DOI 10.1109/TC.1980.1675627; VOSS K, N826 FRIEDR U JEN FO; WARSHALL S, 1962, J ACM, V9, P11, DOI 10.1145/321105.321107	35	48	50	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	2					216	228		10.1109/TPAMI.1985.4767645	http://dx.doi.org/10.1109/TPAMI.1985.4767645			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ACP84	21869258	Green Published			2022-12-18	WOS:A1985ACP8400008
J	LEVINE, MD; SHAHEEN, SI				LEVINE, MD; SHAHEEN, SI			A MODULAR COMPUTER VISION SYSTEM FOR PICTURE SEGMENTATION AND INTERPRETATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CAIRO,DEPT ELECTR & COMMUN ENGN,GIZA,EGYPT	Egyptian Knowledge Bank (EKB); Cairo University	LEVINE, MD (corresponding author), MCGILL UNIV,DEPT ELECT ENGN,MONTREAL H3C 3G1,QUEBEC,CANADA.		Shaheen, Samir Ibrahim/AAF-4442-2020	Shaheen, Samir Ibrahim/0000-0002-2449-6130				ARBIB MA, 1975, COINS75C9 U MASS DEP; BALLARD DH, 1978, COMPUTER VISION SYST, P271; BARROW HG, 1976, 121 AI CTR STANF RES; DATE DJ, 1975, INTRO DATABASE SYSTE; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; Hanson A., 1978, COMPUTER VISION SYST, P303; Hanson A. R., 1978, COMPUTER VISION SYST, P129; HARLOW CA, 1972, IALTR1772 U MISS COL; KELLY MD, 1971, MACH INTELL, V6, P397; LESSER VR, 1975, IEEE T ACOUST SPEECH, VAS23, P11, DOI 10.1109/TASSP.1975.1162648; LEVINE MD, 1978, COMPUTER VISION SYST, P335; SAKAI T, 1976, 3RD INT JOINT C PATT; SHAHEEN SI, 1979, THESIS MCGILL U MONT; SHAHEEN SI, 1980, 1980 C PATT REC BRIT; SHAHEEN SI, 1978, 2ND NAT C CAN SOC CO; TENENBAUM JM, 1977, ARTIF INTELL, V8, P241, DOI 10.1016/0004-3702(77)90031-5; TENENBAUM JM, 1973, SRI84 AI CTR STANF R; TING D, 1979, THESIS MCGILL U MONT; WALTZ D, 1975, PSYCHOL VISION; YAKIMOVSKY Y, 1973, 3RD P INT JOINT C AR, P580; ZUCKER SW, 1977, PATTERN RECOGNITION; ZUCKER SW, 1978, 7815R MCGILL U DEP E	22	48	54	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	5					540	556		10.1109/TPAMI.1981.4767147	http://dx.doi.org/10.1109/TPAMI.1981.4767147			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ358	21868974				2022-12-18	WOS:A1981MQ35800005
J	Opitz, M; Waltner, G; Possegger, H; Bischof, H				Opitz, Michael; Waltner, Georg; Possegger, Horst; Bischof, Horst			Deep Metric Learning with BIER: Boosting Independent Embeddings Robustly	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Measurement; Training; Boosting; Correlation; Feature extraction; Robustness; Task analysis; Metric learning; deep learning; convolutional neural network		Learning similarity functions between image pairs with deep neural networks yields highly correlated activations of embeddings. In this work, we show how to improve the robustness of such embeddings by exploiting the independence within ensembles. To this end, we divide the last embedding layer of a deep network into an embedding ensemble and formulate the task of training this ensemble as an online gradient boosting problem. Each learner receives a reweighted training sample from the previous learners. Further, we propose two loss functions which increase the diversity in our ensemble. These loss functions can be applied either for weight initialization or during training. Together, our contributions leverage large embedding sizes more effectively by significantly reducing correlation of the embedding and consequently increase retrieval accuracy of the embedding. Our method works with any differentiable loss function and does not introduce any additional parameters during test time. We evaluate our metric learning method on image retrieval tasks and show that it improves over state-of-the-art methods on the CUB-200-2011, Cars-196, Stanford Online Products, In-Shop Clothes Retrieval and VehicleID datasets. Therefore, our findings suggest that by dividing deep networks at the end into several smaller and diverse networks, we can significantly reduce overfitting.	[Opitz, Michael; Waltner, Georg; Possegger, Horst; Bischof, Horst] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria	Graz University of Technology	Opitz, M (corresponding author), Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria.	michael.opitz@icg.tugraz.at; waltner@icg.tugraz.at; possegger@icg.tugraz.at; bischof@icg.tugraz.at		Bischof, Horst/0000-0002-9096-6671	Austrian Research Promotion Agency (FFG) project MANGO [836488]; NVIDIA Corporation; Austrian Research Promotion Agency (FFG) project Darknet [858591]	Austrian Research Promotion Agency (FFG) project MANGO; NVIDIA Corporation; Austrian Research Promotion Agency (FFG) project Darknet	This project was supported by the Austrian Research Promotion Agency (FFG) projects MANGO (836488) and Darknet (858591). We gratefully acknowledge the support of NVIDIA Corporation with the donation of GPUs used for this research.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; [Anonymous], P INT C NEUR INF PRO; [Anonymous], 2016, P INT C LEARN REPR; [Anonymous], P AS C COMP VIS; [Anonymous], 2012, ADV NEURAL INF PROCE; [Anonymous], P INT C LEARN REPR; [Anonymous], P INT C LEARN REPR; [Anonymous], 2016, P INT C LEARN REPR; [Anonymous], 2013, SURVEY METRIC LEARNI; [Anonymous], P COMP VIS WINT WORK; [Anonymous], ADV NEURAL INF PROCE; [Anonymous], P 30 INT C NEUR INF; [Anonymous], P BRIT MACH VIS C; Bai Y, 2017, IEEE INT CON MULTI, P1452, DOI 10.1109/ICME.2017.8019371; Bengio Y, 2006, P 19 INT C NEUR INF, P153; Beygelzimer A, 2015, ADV NEUR IN, V28; Beygelzimer A, 2015, PR MACH LEARN RES, V37, P2323; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.3390/risks8030083; Chen HH, 2010, IEEE T KNOWL DATA EN, V22, P1738, DOI 10.1109/TKDE.2010.26; Chen S. -T., 2012, P 29 INT C MACH LEAR, P1873; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Ganin Y, 2016, J MACH LEARN RES, V17; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; Harwood B, 2017, IEEE I CONF COMP VIS, P2840, DOI 10.1109/ICCV.2017.307; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hong J, 2016, INT SOC DESIGN CONF, P109, DOI 10.1109/ISOCC.2016.7799757; Jia Y., 2014, P 22 ACM INT C MULT, P675; Jinbo Bi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2617, DOI 10.1109/CVPR.2011.5995363; Karianakis N., 2015, BOOSTING CONVOLUTION; Kingma D.P., 2015, ICLR, P1; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kumar BGV, 2016, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2016.581; Law MT, 2013, IEEE I CONF COMP VIS, P249, DOI 10.1109/ICCV.2013.38; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Leistner C., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1362, DOI 10.1109/ICCVW.2009.5457451; Liu MZ, 2012, LECT NOTES COMPUT SC, V7575, P646, DOI 10.1007/978-3-642-33765-9_46; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47; Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376; Opitz M, 2017, IEEE I CONF COMP VIS, P5199, DOI 10.1109/ICCV.2017.555; Radford A., 2016, P INT C LEARN REPR; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shen CH, 2012, J MACH LEARN RES, V13, P1007; Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sohn K, 2016, ADV NEUR IN, V29; Song HO, 2017, PROC CVPR IEEE, P2206, DOI 10.1109/CVPR.2017.237; Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41; Wang J, 2017, IEEE I CONF COMP VIS, P2612, DOI 10.1109/ICCV.2017.283; Wang S, 2010, PROC INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2010.5596702; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930; Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309; Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18; Yuan YH, 2017, IEEE I CONF COMP VIS, P814, DOI 10.1109/ICCV.2017.94; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	74	47	47	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					276	290		10.1109/TPAMI.2018.2848925	http://dx.doi.org/10.1109/TPAMI.2018.2848925			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	29994466	Green Submitted			2022-12-18	WOS:000508386100003
J	Zhang, WM; Zhao, X; Morvan, JM; Chen, LM				Zhang, Wuming; Zhao, Xi; Morvan, Jean-Marie; Chen, Liming			Improving Shadow Suppression for Illumination Robust Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; lighting normalization; illumination and texture analysis	NORMALIZATION; HISTOGRAM; IMAGE; REPRESENTATION; RETINEX; 3D	2D face analysis techniques, such as face landmarking, face recognition and face verification, are reasonably dependent on illumination conditions which are usually uncontrolled and unpredictable in the real world. The current massive data-driven approach, e.g., deep learning-based face recognition, requires a huge amount of labeled training face data that hardly cover the infinite lighting variations that can be encountered in real-life applications. An illumination robust preprocessing method thus remains a very interesting but also a significant challenge in reliable face analysis. In this paper we propose a novel model driven approach to improve lighting normalization of face images. Specifically, we propose to build the underlying reflectance model which characterizes interactions between skin surface, lighting source and camera sensor, and elaborate the formation of face color appearance. The proposed illumination processing pipeline enables generation of the Chromaticity Intrinsic Image (CII) in a log chromaticity space which is robust to illumination variations. Moreover, as an advantage over most prevailing methods, a photo-realistic color face image is subsequently reconstructed, which eliminates a wide variety of shadows whilst retaining the color information and identity details. Experimental results under different scenarios and using various face databases show the effectiveness of the proposed approach in dealing with lighting variations, including both soft and hard shadows, in face recognition.	[Zhang, Wuming; Chen, Liming] Univ Lyon, Ecole Cent Lyon, CNRS, Dept Math & Comp Sci,Lab LIRIS,UMR 5205, F-69310 Ecully, France; [Zhao, Xi] Xi An Jiao Tong Univ, Sch Management, Xian 710049, Shaanxi, Peoples R China; [Morvan, Jean-Marie] Univ Lyon 1, CNRS, UMR 5208, Inst Camille Jordan, F-69622 Villeurbanne, France; [Morvan, Jean-Marie] King Abdullah Univ Sci & Technol, Visual Comp Ctr, Thuwal 239556900, Saudi Arabia	Centre National de la Recherche Scientifique (CNRS); Ecole Centrale de Lyon; Institut National des Sciences Appliquees de Lyon - INSA Lyon; Xi'an Jiaotong University; Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute for Mathematical Sciences (INSMI); UDICE-French Research Universities; Universite Claude Bernard Lyon 1; Ecole Centrale de Lyon; Institut National des Sciences Appliquees de Lyon - INSA Lyon; Universite Jean Monnet; King Abdullah University of Science & Technology	Zhao, X (corresponding author), Xi An Jiao Tong Univ, Sch Management, Xian 710049, Shaanxi, Peoples R China.	wuming.zhang@ec-lyon.fr; zhaoxi1@hotmail.com; jean-marie.morvan@kaust.edu.sa; liming.chen@ec-lyon.fr		Chen, Liming/0000-0002-3654-9498	French Research Agency; Agence Nationale de Recherche (ANR) [ANR-13-CORD-0004-02, ANR-13-INSE-0004-02]; National Nature Science Foundation of China [91746111, 61303121]; Partner University Fund (PUF) through the 4D Vision project; Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University	French Research Agency(French National Research Agency (ANR)); Agence Nationale de Recherche (ANR)(French National Research Agency (ANR)); National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Partner University Fund (PUF) through the 4D Vision project; Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University	This work was partially supported by the French Research Agency, Agence Nationale de Recherche (ANR) through the Jemime Project under Grant ANR-13-CORD-0004-02, the Biofence project under Grant ANR-13-INSE-0004-02, the National Nature Science Foundation of China under Grant 91746111, 61303121, the Partner University Fund (PUF) through the 4D Vision project, and Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University.	Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229; Ahonen T., 2008 19 INT C PATT R, P1; Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195; Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353; Du S., 2005, P IEEE INT C IM PROC; Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18; Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z; FREEDMAN D, 1981, Z WAHRSCHEINLICHKEIT, V57, P453, DOI 10.1007/BF01025868; He KM, 2010, LECT NOTES COMPUT SC, V6311, P1; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356; Kee SC, 2000, IEICE T INF SYST, VE83D, P1466; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; MACLEOD DIA, 1979, J OPT SOC AM, V69, P1183, DOI 10.1364/JOSA.69.001183; Madooei A, 2015, IEEE IMAGE PROC, P4357, DOI 10.1109/ICIP.2015.7351629; Omer I, 2004, PROC CVPR IEEE, P946; Parkhi Omkar M., 2015, BRIT MACH VIS C; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Phillips PJ, 2005, PROC CVPR IEEE, P947; PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839; PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X; Riklin-Raviv T., 1999, P IEEE COMP SOC C CO; Shan SG, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P157; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Stan Z. L., 2005, HDB FACE RECOGNITION; Struc V, 2011, ADVANCES IN FACE IMAGE ANALYSIS: TECHNIQUES AND TECHNOLOGIES, P279, DOI 10.4018/978-1-61520-991-0.ch015; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998; Wang HT, 2004, PROC CVPR IEEE, P498; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1968, DOI 10.1109/TPAMI.2008.244; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nded.; Xie XD, 2006, PATTERN RECOGN LETT, V27, P609, DOI 10.1016/j.patrec.2005.09.026; Zhang L, 2005, PROC CVPR IEEE, P209; Zhang TP, 2009, PATTERN RECOGN, V42, P251, DOI 10.1016/j.patcog.2008.03.017; Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255; Zhang WC, 2005, IEEE I CONF COMP VIS, P786; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhao X, 2014, IEEE T CYBERNETICS, V44, P725, DOI 10.1109/TCYB.2013.2291196	44	47	49	2	53	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					611	624		10.1109/TPAMI.2018.2803179	http://dx.doi.org/10.1109/TPAMI.2018.2803179			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29994507	Green Submitted			2022-12-18	WOS:000458168800007
J	Guan, NY; Liu, TL; Zhang, YMZ; Tao, DC; Davis, LS				Guan, Naiyang; Liu, Tongliang; Zhang, Yangmuzi; Tao, Dacheng; Davis, Larry S.			Truncated Cauchy Non-Negative Matrix Factorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Non-negative matrix factorization; truncated cauchy loss; robust statistics; half-quadratic programming	LINEAR-ESTIMATION; FACE RECOGNITION; MINIMIZATION; PARAMETERS; OBJECTS; PARTS	Non-negative matrix factorization (NMF) minimizes the euclidean distance between the data matrix and its low rank approximation, and it fails when applied to corrupted data because the loss function is sensitive to outliers. In this paper, we propose a Truncated CauchyNMF loss that handle outliers by truncating large errors, and develop a Truncated CauchyNMF to robustly learn the subspace on noisy datasets contaminated by outliers. We theoretically analyze the robustness of Truncated CauchyNMF comparing with the competing models and theoretically prove that Truncated CauchyNMF has a generalization bound which converges at a rate of order O(root ln n/n), where n is the sample size. We evaluate Truncated CauchyNMF by image clustering on both simulated and real datasets. The experimental results on the datasets containing gross corruptions validate the effectiveness and robustness of Truncated CauchyNMF for learning robust subspaces.	[Guan, Naiyang] Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China; [Guan, Naiyang] Natl Inst Def Technol Innovat, Beijing 100010, Peoples R China; [Liu, Tongliang; Tao, Dacheng] Univ Sydney, UBTECH Sydney Artificial Intelligence Ctr, 6 Cleveland St, Darlington 2008, NSW, England; [Liu, Tongliang; Tao, Dacheng] Univ Sydney, Sch Informat Technol, Fac Engn & Informat Technol, 6 Cleveland St, Darlington 2008, NSW, England; [Zhang, Yangmuzi] Google, Mountain View, CA 94043 USA; [Davis, Larry S.] Univ Maryland, UMIACS, College Pk, MD 20742 USA	National University of Defense Technology - China; Google Incorporated; University System of Maryland; University of Maryland College Park	Guan, NY (corresponding author), Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.; Guan, NY (corresponding author), Natl Inst Def Technol Innovat, Beijing 100010, Peoples R China.	ny.guan@gmail.com; tongliang.liu@sydney.edu.au; yangmuzi.zhang@gmail.com; dacheng.tao@sydney.edu.au; lsd@umiacs.umd.edu	Liu, Tongliang/AAA-1506-2021	Liu, Tongliang/0000-0002-9640-6472	Australian Research Council [FL-170100117, DP-180103424, DP-140102164, LP-150100671]; National Natural Science Foundation of China [61502515]	Australian Research Council(Australian Research Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The work was supported in part by the Australian Research Council Projects FL-170100117, DP-180103424, DP-140102164, LP-150100671, and the National Natural Science Foundation of China under Grant 61502515. Naiyang Guan and Tongliang Liu contribute equally to this work.	Baccini A, 1996, ST CLASS DAT ANAL, P359; Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Ben Harnza A, 2006, IEEE T SIGNAL PROCES, V54, P3637, DOI 10.1109/TSP.2006.879282; Bhattacharya Chiranjib, 2016, P 33 INT C MACH LEAR, P1426; Boyd S, 2004, CONVEX OPTIMIZATION; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; CANE GJ, 1974, J AM STAT ASSOC, V69, P243, DOI 10.2307/2285535; Cauchy AL, 1827, EXERCICES MATH, V2, P42; CHAN LK, 1970, J AM STAT ASSOC, V65, P851, DOI 10.2307/2284592; Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277; Donoho D., 1982, BREAKDOWN PROPERTIES; Du L, 2012, IEEE DATA MINING, P201, DOI 10.1109/ICDM.2012.39; Gao H.C., 2015, P THETH ACM INT C IN, V15, P871; GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335; Gillis N, 2014, J MACH LEARN RES, V15, P1249; GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027; Guan N., 2012, ARXIV12073438V1; Guan NY, 2012, IEEE T SIGNAL PROCES, V60, P2882, DOI 10.1109/TSP.2012.2190406; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Huber P. J., 2011, ROBUST STAT; Jia Y., 2011, ADV NEURAL INFORM PR, V24, P397; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kong D., 2011, P 20 ACM INT C INFOR, P673, DOI [10.1145/2063576.2063676, DOI 10.1145/2063576.2063676]; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lam EY, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P798, DOI 10.1109/APCCAS.2008.4746143; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee DD, 2001, ADV NEUR IN, V13, P556; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Lijun Zhang, 2011, Frontiers of Electrical and Electronic Engineering in China, V6, P192, DOI 10.1007/s11460-011-0128-0; Lin CJ, 2007, NEURAL COMPUT, V19, P2756, DOI 10.1162/neco.2007.19.10.2756; Liu TL, 2014, INT CONF INFO SCI, P100, DOI 10.1109/ICIST.2014.6920341; Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065; Logothetis NK, 1996, ANNU REV NEUROSCI, V19, P577, DOI 10.1146/annurev.ne.19.030196.003045; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Martinez A., 1998, 24 CVC U AUT BARC, V24; Nagy F, 2006, J UNIVERS COMPUT SCI, V12, P1332; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Nesterov Y., 1983, SOV MATH DOKL, V27, P372; Nikolova M, 2007, IEEE T IMAGE PROCESS, V16, P1623, DOI 10.1109/TIP.2007.896622; Pan QH, 2014, AAAI CONF ARTIF INTE, P2027; Pauca VP, 2006, LINEAR ALGEBRA APPL, V416, P29, DOI 10.1016/j.laa.2005.06.025; Pauca VP, 2004, SIAM PROC S, P452; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300; Sandler R, 2011, IEEE T PATTERN ANAL, V33, P1590, DOI 10.1109/TPAMI.2011.18; WACHSMUTH E, 1994, CEREB CORTEX, V4, P509, DOI 10.1093/cercor/4.5.509; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu S.-H., 2015, P 2 WORKSH NAT LANG, P7; Zhang T, 2002, J MACH LEARN RES, V2, P527, DOI 10.1162/153244302760200713; Zhou ZH, 2009, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2009.5459383	50	47	48	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					246	259		10.1109/TPAMI.2017.2777841	http://dx.doi.org/10.1109/TPAMI.2017.2777841			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990056	Green Published, Green Submitted			2022-12-18	WOS:000452434800019
J	Fu, ZY; Xiang, T; Kodirov, E; Gong, SG				Fu, Zhenyong; Xiang, Tao; Kodirov, Elyor; Gong, Shaogang			Zero-Shot Learning on Semantic Class Prototype Graph	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Zero-shot learning; semantic embedding; class prototype graph; hubness; semantic manifold; absorbing Markov chain process	DIMENSIONALITY REDUCTION; LAPLACIAN EIGENMAPS; RECOGNITION; CLASSIFICATION	Zero-Shot Learning (ZSL) for visual recognition is typically achieved by exploiting a semantic embedding space. In such a space, both seen and unseen class labels as well as image features can be embedded so that the similarity among them can be measured directly. In this work, we consider that the key to effective ZSL is to compute an optimal distance metric in the semantic embedding space. Existing ZSL works employ either euclidean or cosine distances. However, in a high-dimensional space where the projected class labels (prototypes) are sparse, these distances are suboptimal, resulting in a number of problems including hubness and domain shift. To overcome these problems, a novel manifold distance computed on a semantic class prototype graph is proposed which takes into account the rich intrinsic semantic structure, i.e., semantic manifold, of the class prototype distribution. To further alleviate the domain shift problem, a new regularisation term is introduced into a ranking loss based embedding model. Specifically, the ranking loss objective is regularised by unseen class prototypes to prevent the projected object features from being biased towards the seen prototypes. Extensive experiments on four benchmarks show that our method significantly outperforms the state-of-the-art.	[Fu, Zhenyong; Xiang, Tao; Kodirov, Elyor; Gong, Shaogang] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England	University of London; Queen Mary University London	Xiang, T (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.	z.fu@qmul.ac.uk; t.xiang@qmul.ac.uk; e.kodirov@qmul.ac.uk; s.gong@qmul.ac.uk		Gong, Shaogang/0000-0001-8156-2299	European Research Council under the FP7 Project SUNNY [313243]	European Research Council under the FP7 Project SUNNY	The authors were funded in part by the European Research Council under the FP7 Project SUNNY (grant agreement no. 313243).	Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911; Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Al-Halah Z, 2015, IEEE WINT CONF APPL, P837, DOI 10.1109/WACV.2015.116; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Ba JL, 2015, IEEE I CONF COMP VIS, P4247, DOI 10.1109/ICCV.2015.483; Bart E., 2005, P BRIT MACH VIS C; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bruna J., 2014, 2 INT C LEARN REPR; Bucher M, 2016, LECT NOTES COMPUT SC, V9909, P730, DOI 10.1007/978-3-319-46454-1_44; Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575; Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; Dinu G., 2014, CORR; Donahue J, 2014, PR MACH LEARN RES, V32; Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321; Fang C, 2012, LECT NOTES COMPUT SC, V7575, P402, DOI 10.1007/978-3-642-33765-9_29; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Ferrari Vittorio, 2007, NIPS; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; Frome Andrea, 2013, NEURIPS; Fu YW, 2016, PROC CVPR IEEE, P5337, DOI 10.1109/CVPR.2016.576; Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354; Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38; FU ZY, 2015, PROC CVPR IEEE, P2635, DOI DOI 10.1109/CVPR.2015.7298879; Golub G. H., 2012, MATRIX COMPUTATIONS; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Huang S, 2015, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2015.7298638; Karlin Samuel, 2014, 1 COURSE STOCHASTIC; Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Long Y, 2017, PROC CVPR IEEE, P6165, DOI 10.1109/CVPR.2017.653; Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313; Mensink T, 2012, LECT NOTES COMPUT SC, V7573, P488, DOI 10.1007/978-3-642-33709-3_35; Mikolov T., 2013, ARXIV; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Morgado P, 2017, PROC CVPR IEEE, P2037, DOI 10.1109/CVPR.2017.220; Norouzi Mohammad, 2014, ICLR; Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033; Palatucci Mark, 2009, ADV NEURAL INFORM PR, P1410; Radovanovic M, 2010, J MACH LEARN RES, V11, P2487; Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13; Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627; Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121; Romera-Paredes Bernardino, 2015, ICML; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; SHEPARD RN, 1980, SCIENCE, V210, P390, DOI 10.1126/science.210.4468.390; Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9; Socher R., 2013, EMNLP, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wah C., 2011, TECH REP; Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15; Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474; ZHANG ZM, 2016, PROC CVPR IEEE, P6034, DOI DOI 10.1109/CVPR.2016.649	66	47	50	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					2009	2022		10.1109/TPAMI.2017.2737007	http://dx.doi.org/10.1109/TPAMI.2017.2737007			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28796607	Green Submitted			2022-12-18	WOS:000437271100016
J	Pepik, B; Stark, M; Gehler, P; Schiele, B				Pepik, Bojan; Stark, Michael; Gehler, Peter; Schiele, Bernt			Multi-View and 3D Deformable Part Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; 3D object models; deformable part models; structured output learning	OBJECT DETECTION; PICTORIAL STRUCTURES; RECOGNITION; REPRESENTATION; ORGANIZATION	As objects are inherently 3D, they have been modeled in 3D in the early days of computer vision. Due to the ambiguities arising from mapping 2D features to 3D models, 3D object representations have been neglected and 2D feature-based models are the predominant paradigm in object detection nowadays. While such models have achieved outstanding bounding box detection performance, they come with limited expressiveness, as they are clearly limited in their capability of reasoning about 3D shape or viewpoints. In this work, we bring the worlds of 3D and 2D object representations closer, by building an object detector which leverages the expressive power of 3D object representations while at the same time can be robustly matched to image evidence. To that end, we gradually extend the successful deformable part model [1] to include viewpoint information and part-level 3D geometry information, resulting in several different models with different level of expressiveness. We end up with a 3D object model, consisting of multiple object parts represented in 3D and a continuous appearance model. We experimentally verify that our models, while providing richer object hypotheses than the 2D object models, provide consistently better joint object localization and viewpoint estimation than the state-of-the-art multi-view and 3D object detectors on various benchmarks (KITTI [2], 3D object classes [3], Pascal3D+ [4], Pascal VOC 2007 [5], EPFL multi-view cars [6]).	[Pepik, Bojan; Stark, Michael; Schiele, Bernt] Max Planck Inst Informat, D-66123 Saarbrucken, Germany; [Gehler, Peter] Max Planck Inst Intelligent Syst, D-72076 Tubingen, Germany	Max Planck Society; Max Planck Society	Pepik, B (corresponding author), Max Planck Inst Informat, D-66123 Saarbrucken, Germany.	bpepikj@mpi-inf.mpg.de; stark@mpi-inf.mpg.de; pgehler@tuebingen.mpg.de; schiele@mpi-inf.mpg.de						Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Arie-Nachimson M, 2009, IEEE I CONF COMP VIS, P1341, DOI 10.1109/ICCV.2009.5459310; Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487; Bao S. Y., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2025, DOI 10.1109/CVPR.2011.5995462; Bao SY, 2012, LECT NOTES COMPUT SC, V7572, P86, DOI 10.1007/978-3-642-33718-5_7; Blaschko MB, 2008, LECT NOTES COMPUT SC, V5302, P2, DOI 10.1007/978-3-540-88682-2_2; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109; Everingham M., 2007, PASCAL VOC 2007 RESU; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Felzenszwalb PF, 2010, DISCRIMINATIVELY TRA; Fergus R, 2003, PROC CVPR IEEE, P264; Fidler S., 2012, P ADV NEURAL INFORM, P611; Fidler S, 2013, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2013.423; Geiger A., 2011, ADV NEURAL INFORM PR, VVol. 24, P1467; Geiger A., 2012, P IEEE COMP SOC C CO; Geiger A, 2014, IEEE T PATTERN ANAL, V36, P1012, DOI 10.1109/TPAMI.2013.185; Girshick R., 2011, ADV NEURAL INFORM PR, V24, P442; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Glasner D, 2011, IEEE I CONF COMP VIS, P1275, DOI 10.1109/ICCV.2011.6126379; GREEN K, 1995, COMPUT VIS IMAGE UND, V62, P177, DOI 10.1006/cviu.1995.1049; Gu CH, 2010, LECT NOTES COMPUT SC, V6315, P408; Hao S, 2009, IEEE I CONF COMP VIS, P213, DOI 10.1109/ICCV.2009.5459168; Hejrati M., 2012, NIPS; Hejrati M, 2014, PROC CVPR IEEE, P2449, DOI 10.1109/CVPR.2014.314; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lehmann AD, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.8; LEIBE B, 2006, CATEGORY LEVEL OBJEC; Liebelt J, 2010, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2010.5539836; Lopez-Sastre RJ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130367; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Ozuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633; Payet N, 2011, IEEE I CONF COMP VIS, P983, DOI 10.1109/ICCV.2011.6126342; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; Pepikj Bojan, 2013, PROC CVPR IEEE, P3286, DOI DOI 10.1109/CVPR.2013.422; Savarese S, 2007, IEEE I CONF COMP VIS, P1245; Sermanet P., 2014, 2 INT C LEARN REPR B; Stark L., 1993, Proceedings of IEEE Workshop on Qualitative Vision (Cat. No.93TH0521-5), P11, DOI 10.1109/WQV.1993.262954; Stark M., 2010, P BRIT MACH VIS C, P1, DOI [10.5244/C.24.106, DOI 10.5244/C.24.106]; Stark M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.36; Sun M, 2010, LECT NOTES COMPUT SC, V6315, P658, DOI 10.1007/978-3-642-15555-0_48; Szegedy C, 2013, ADV NEURAL INFORM PR, P2553; Thomas A., 2006, P IEEE C COMP VIS PA, V2, P1589; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10; Wojek C, 2010, LECT NOTES COMPUT SC, V6314, P467, DOI 10.1007/978-3-642-15561-1_34; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Xiang Y, 2012, PROC CVPR IEEE, P3410, DOI 10.1109/CVPR.2012.6248081; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yan P., 2007, COMP VIS 2007 ICCV 2, P1; Yoruk E, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P538, DOI 10.1109/ICCVW.2013.127; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]; Zia M. Z., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P569, DOI 10.1109/ICCVW.2011.6130294; Zia MZ, 2013, IEEE T PATTERN ANAL, V35, P2608, DOI 10.1109/TPAMI.2013.87	64	47	50	2	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2232	2245		10.1109/TPAMI.2015.2408347	http://dx.doi.org/10.1109/TPAMI.2015.2408347			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440264				2022-12-18	WOS:000362411000007
J	Delgado-Friedrichs, O; Robins, V; Sheppard, A				Delgado-Friedrichs, Olaf; Robins, Vanessa; Sheppard, Adrian			Skeletonization and Partitioning of Digital Images Using Discrete Morse Theory	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Curve skeleton; surface skeleton; medial axis transform; watershed transform; discrete Morse theory; persistent homology	EFFICIENT COMPUTATION; SMALE COMPLEXES; SEGMENTATION; TOPOLOGY	We show how discrete Morse theory provides a rigorous and unifying foundation for defining skeletons and partitions of grayscale digital images. We model a grayscale image as a cubical complex with a real-valued function defined on its vertices (the voxel values). This function is extended to a discrete gradient vector field using the algorithm presented in Robins, Wood, Sheppard TPAMI 33:1646 (2011). In the current paper we define basins (the building blocks of a partition) and segments of the skeleton using the stable and unstable sets associated with critical cells. The natural connection between Morse theory and homology allows us to prove the topological validity of these constructions; for example, that the skeleton is homotopic to the initial object. We simplify the basins and skeletons via Morse-theoretic cancellation of critical cells in the discrete gradient vector field using a strategy informed by persistent homology. Simple working Python code for our algorithms for efficient vector field traversal is included. Example data are taken from micro-CT images of porous materials, an application area where accurate topological models of pore connectivity are vital for fluid-flow modelling.	[Delgado-Friedrichs, Olaf; Robins, Vanessa; Sheppard, Adrian] Australian Natl Univ, Dept Appl Math, Res Sch Phys & Engn, Canberra, ACT 0200, Australia	Australian National University	Delgado-Friedrichs, O (corresponding author), Australian Natl Univ, Dept Appl Math, Res Sch Phys & Engn, GPO Box 4, Canberra, ACT 0200, Australia.	olaf.delgado@googlemail.com; vanessa.robins@anu.edu.au; Adrian.Sheppard@anu.edu.au	Robins, Vanessa/A-7010-2012; Sheppard, Adrian/W-4050-2019; Sheppard, Adrian/A-7410-2008	Robins, Vanessa/0000-0001-7118-8491; Sheppard, Adrian/0000-0001-9792-4143; Sheppard, Adrian/0000-0001-9792-4143	ARC [DP110102888]	ARC(Australian Research Council)	This research was supported in part by ARC Discovery Project DP110102888.	Allili M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P173, DOI 10.1109/ICIP.2001.958452; [Anonymous], 2002, S M LOTHAR COMBIN; Arcelli C, 2011, IEEE T PATTERN ANAL, V33, P709, DOI 10.1109/TPAMI.2010.140; Bakke S, 1997, SPE J, V2, P136, DOI 10.2118/35479-PA; Bauer U., 2014, TOPOL METHOD NONL AN, P103, DOI DOI 10.1007/978-3-319-04099-8; Bauer U, 2012, DISCRETE COMPUT GEOM, V47, P347, DOI 10.1007/s00454-011-9350-z; Beucher S, 1994, COMP IMAG VIS, V2, P69; Beucher S., 1979, INT WORK IMAGE PROCE; Beucher S., 1993, MATH MORPHOLOGY IMAG, P433, DOI DOI 10.1201/9781482277234-12; Biasotti S, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1391729.1391731; Biasotti S, 2008, MATH VIS, P145, DOI 10.1007/978-3-540-33265-7_5; Bleau A, 2000, COMPUT VIS IMAGE UND, V77, P317, DOI 10.1006/cviu.2000.0822; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; Borgefors G., 1998, Advances in Pattern Recognition. Joint IAPR International Workshops SSPR'98 and SPR'98. Proceedings, P220, DOI 10.1007/BFb0033240; Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002; Couprie M, 1997, P SOC PHOTO-OPT INS, V3168, P136, DOI 10.1117/12.292778; Delgado-Friedrichs O., 2014, IEEE INT C IM PROC P; Edelsbrunner H, 2003, DISCRETE COMPUT GEOM, V30, P87, DOI 10.1007/s00454-003-2926-5; Edelsbrunner H., 2010, COMPUTATIONAL TOPOLO; Edelsbrunner H, 2009, LECT NOTES COMPUT SC, V5903, P36, DOI 10.1007/978-3-642-10470-1_4; Forman R, 1998, ADV MATH, V134, P90, DOI 10.1006/aima.1997.1650; G_unther D., 2014, PROC TOPOLOGICAL MET, VIII, P135; Glantz R, 2008, ADV WATER RESOUR, V31, P787, DOI 10.1016/j.advwatres.2008.01.015; Guenther D, 2012, VISUAL COMPUT, V28, P959, DOI 10.1007/s00371-012-0726-8; Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110; Gyulassy A, 2007, IEEE T VIS COMPUT GR, V13, P1440, DOI 10.1109/TVCG.2007.70552; Gyulassy A, 2012, IEEE T VIS COMPUT GR, V18, P2014, DOI 10.1109/TVCG.2012.209; Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603; Haris K, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P338, DOI 10.1109/ICIP.1998.727211; King H, 2005, EXP MATH, V14, P435, DOI 10.1080/10586458.2005.10128941; Kondic L, 2012, EPL-EUROPHYS LETT, V97, DOI 10.1209/0295-5075/97/54001; KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5; Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738; Lewiner T., 2005, THESIS PUC RIO RIO D; Lewiner T, 2013, COMPUT AIDED GEOM D, V30, P609, DOI 10.1016/j.cagd.2012.03.012; Lien J.M., 2006, P 2006 ACM S SOL PHY, P219, DOI 10.1145/1128888.1128919; Matsumoto Y., 2002, INTRO MORSE THEORY; Maxwell J.C., 1870, PHILOS MAGAZ J SCI, V40, P421; Meissner M., 2001, VOLVIS VOXEL DATA RE; Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M; Mischaikow K, 2013, DISCRETE COMPUT GEOM, V50, P330, DOI 10.1007/s00454-013-9529-6; Prodanovic M, 2007, ADV WATER RESOUR, V30, P214, DOI 10.1016/j.advwatres.2005.05.015; Robins V., 2014, MATH TOOLS PHYS, P211; Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95; Sheppard A. P., 2005, NETWORK GENERATION C; Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x; Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8; Silin D, 2006, PHYSICA A, V371, P336, DOI 10.1016/j.physa.2006.04.048; Sousbie T, 2011, MON NOT R ASTRON SOC, V414, P384, DOI 10.1111/j.1365-2966.2011.18395.x; van de Weygaert Rien, 2011, Transactions on Computational Science XIV. Special Issue on Voronoi Diagrams and Delaunay Triangulation, P60, DOI 10.1007/978-3-642-25249-5_3; Wagner H., 2012, TOPOLOGICAL METHODS, P91, DOI DOI 10.1007/978-3-642-23175-9_7; Whitehead JHC, 1939, P LOND MATH SOC, V45, P243; Whitehouse D., 2013, VOLUMINOUS WEB BASED	53	47	47	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2015	37	3					654	666		10.1109/TPAMI.2014.2346172	http://dx.doi.org/10.1109/TPAMI.2014.2346172			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VK	26353267	Green Published			2022-12-18	WOS:000349626200013
J	Zhang, XL				Zhang, Xiao-Lei			Convex Discriminative Multitask Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convex optimization; cutting-plane algorithm; discriminative clustering; unsupervised multitask learning		Multitask clustering tries to improve the clustering performance of multiple tasks simultaneously by taking their relationship into account. Most existing multitask clustering algorithms fall into the type of generative clustering, and none are formulated as convex optimization problems. In this paper, we propose two convex Discriminative Multitask Clustering (DMTC) objectives to address the problems. The first one aims to learn a shared feature representation, which can be seen as a technical combination of the convex multitask feature learning and the convex Multiclass Maximum Margin Clustering (M3C). The second one aims to learn the task relationship, which can be seen as a combination of the convex multitask relationship learning and M3C. The objectives of the two algorithms are solved in a uniform procedure by the efficient cutting-plane algorithm and further unified in the Bayesian framework. Experimental results on a toy problem and two benchmark data sets demonstrate the effectiveness of the proposed algorithms.	Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China	Tsinghua University	Zhang, XL (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.	huoshan6@126.com			China Postdoctoral Science Foundation [2012M520278]	China Postdoctoral Science Foundation(China Postdoctoral Science Foundation)	The author would like to thank Prof. DeLiang Wang for providing the Ohio Supercomputing Center, Columbus, OH, for the experimental running. This work was supported by the China Postdoctoral Science Foundation funded project under Grant 2012M520278.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; Argyriou A., 2007, NIPS, V19, P41, DOI DOI 10.1007/S10994-007-5040-8; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Argyriou A, 2009, J MACH LEARN RES, V10, P2507; Bach F., 2007, P ADV NEUR INF PROC, V20, P1; Bakker B, 2004, J MACH LEARN RES, V4, P83, DOI 10.1162/153244304322765658; Bengio Y., 2011, JMLR WORKSH C P, V7, P1, DOI [10.1109/IJCNN.2011.6033302, DOI 10.1109/IJCNN.2011.6033302]; Boyd S, 2004, CONVEX OPTIMIZATION; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chen D, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE OF MANAGEMENT SCIENCE AND INFORMATION SYSTEM, VOLS 1-4, P1375; Chen JH, 2013, IEEE T PATTERN ANAL, V35, P1025, DOI 10.1109/TPAMI.2012.189; Dai Wenyuan, 2008, P 25 INT C MACH LEAR, P2, DOI DOI 10.1145/1390156.1390182; Deng WG, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P100, DOI 10.1109/ICICEE.2012.35; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; Evgeniou T, 2007, MARKET SCI, V26, P805, DOI 10.1287/mksc.1070.0291; Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113; Gomes Ryan G, 2011, NEURAL INFORM PROCES, P558; Gu Q., 2011, UAI 11, P266; Gu QQ, 2009, IEEE DATA MINING, P159, DOI 10.1109/ICDM.2009.32; Han J., VASA, DOI [10.1002/1521-3773(20010316)40:63.3.CO;2-C, DOI 10.1002/1521-3773(20010316)40:63.3.CO;2-C]; Huy T., 2012, KNOWL INF SYST, V36, P1; Jacob L., 2009, P ADV NEUR INF PROC, V25, P1; KELLEY JE, 1960, J SOC IND APPL MATH, V8, P703, DOI 10.1137/0108053; Krause Andreas, 2010, ADV NEURAL INFORM PR, V23, P5; Kulis B., 2012, ICML, P1; Lawrence N.D., 2004, P 21 INT C MACH LEAR, P65, DOI DOI 10.1145/1015330.1015382; Li Y.-F., 2009, P 12 INT C ART INT S, V5, P344; Liu J., 2009, P 25 C UNCERTAINTY A, P339, DOI DOI 10.5555/1795114.1795154; Liu QH, 2009, IEEE T PATTERN ANAL, V31, P1074, DOI 10.1109/TPAMI.2008.296; Ng AY, 2002, ADV NEUR IN, V14, P849; Thach NH, 2011, LECT NOTES COMPUT SC, V6804, P123, DOI 10.1007/978-3-642-21916-0_14; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Romera-Paredes B., 2012, J MACHINE LEARNING, V22, P951; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Su ZX, 2009, SMI 2009: IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P1, DOI 10.1109/SMI.2009.5170156; Teh Yee W, 2005, ADV NEURAL INFORM PR, P1385, DOI DOI 10.1198/016214506000000302; Thrun S, 1998, LEARNING TO LEARN, P3; Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237; Vega-Pons S, 2011, INT J PATTERN RECOGN, V25, P337, DOI 10.1142/S0218001411008683; Wang F, 2010, IEEE T NEURAL NETWOR, V21, P319, DOI 10.1109/TNN.2009.2036998; Wang Y, 2011, INT CONF ACOUST SPEE, P1, DOI 10.1109/PLASMA.2011.5993071; Wenhao Jiang, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P789, DOI 10.1007/978-3-642-33486-3_50; Xie S., 2012, P 21 INT C PATT REC, P1; Xu L., 2005, NEURAL INFORM PROCES, P1537; Xu L., 2005, P 20 NAT C ART INT, V2, P904; Xu Z, 2009, ADV NEURAL INFORM PR, P1825; Xue Y, 2007, J MACH LEARN RES, V8, P35; Yang HQ, 2011, IEEE T NEURAL NETWOR, V22, P433, DOI 10.1109/TNN.2010.2103571; Ye J., 2007, PROC NIPS 07, V20, P1649; Ye J.P, 2013, P 30 INT C MACH LEAR, P1; Yi J., 2012, 4 AAAI WORKSH HUM CO, P1; Yi JF, 2012, IEEE DATA MINING, P1176, DOI 10.1109/ICDM.2012.123; Zhang JW, 2010, AAAI CONF ARTIF INTE, P655; Zhang JW, 2011, NEUROCOMPUTING, V74, P1720, DOI 10.1016/j.neucom.2011.02.004; Zhang K, 2009, IEEE T NEURAL NETWOR, V20, P583, DOI 10.1109/TNN.2008.2010620; Zhang XL, 2012, IEEE T SYST MAN CY B, V42, P1669, DOI 10.1109/TSMCB.2012.2197824; Zhang Y., 2010, PROC INT C NEURAL IN, P2559; Zhang Y, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 6, P733; Zhang ZH, 2012, PATTERN RECOGN, V45, P465, DOI 10.1016/j.patcog.2011.05.011; Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702	64	47	49	2	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					28	40		10.1109/TPAMI.2014.2343221	http://dx.doi.org/10.1109/TPAMI.2014.2343221			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353206	Green Submitted			2022-12-18	WOS:000346970600004
J	Heo, J; Savvides, M				Heo, Jingu; Savvides, Marios			Gender and Ethnicity Specific Generic Elastic Models from a Single 2D Image for Novel 2D Pose Face Synthesis and Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generic elastic models; gender and ethnicity specific models; face synthesis; face recognition	SHAPE; RECONSTRUCTION; MOTION; RACE	In this paper, we propose a novel method for generating a realistic 3D human face from a single 2D face image for the purpose of synthesizing new 2D face images at arbitrary poses using gender and ethnicity specific models. We employ the Generic Elastic Model (GEM) approach, which elastically deforms a generic 3D depth-map based on the sparse observations of an input face image in order to estimate the depth of the face image. Particularly, we show that Gender and Ethnicity specific GEMs (GE-GEMs) can approximate the 3D shape of the input face image more accurately, achieving a better generalization of 3D face modeling and reconstruction compared to the original GEM approach. We qualitatively validate our method using publicly available databases by showing each reconstructed 3D shape generated from a single image and new synthesized poses of the same person at arbitrary angles. For quantitative comparisons, we compare our synthesized results against 3D scanned data and also perform face recognition using synthesized images generated from a single enrollment frontal image. We obtain promising results for handling pose and expression changes based on the proposed method.	[Heo, Jingu] Samsung Adv Inst Technol, Yongin 446712, Gyeonggi Do, South Korea; [Savvides, Marios] Carnegie Mellon Univ, Cylab Biometr Ctr, Pittsburgh, PA 15213 USA	Samsung; Carnegie Mellon University	Heo, J (corresponding author), Samsung Adv Inst Technol, Yongin 446712, Gyeonggi Do, South Korea.	jinguheo@gmail.com; msavvid@ri.cmu.edu			Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the Army Research Laboratory (ARL)	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the Army Research Laboratory (ARL)	The authors would like to express deep gratitude to Prof. Takeo Kanade for many insightful discussions and helpful feedback on this work and to our sponsors. This research was funded by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the Army Research Laboratory (ARL). All statements of fact, opinion, or conclusions contained herein are those of the authors and should not be construed as representing the official views or policies of IARPA, the ODNI, or the US Government. The authors would like to thank the various members of Biometrics Lab for help with different modules such as automatic facial landmarking and others.	Atick JJ, 1996, NETWORK-COMP NEURAL, V7, P1, DOI 10.1080/0954898X.1996.11978652; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Blanz V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P202, DOI 10.1109/AFGR.2002.1004155; BRIGHAM JC, 1978, J APPL SOC PSYCHOL, V8, P306, DOI 10.1111/j.1559-1816.1978.tb00786.x; Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760; COOTES TF, 2000, P 4 IEEE INT C AUT F; Dovgard R., 2004, P EUR C COMP VIS, V3022; Durou J. D., 2004, 20042RIRIT; Fidaleo D, 2007, LECT NOTES COMPUT SC, V4778, P124; Gross R., 2008, P INT C AUT FAC GEST; Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774; Hartley R., 2004, ROBOTICA; Heo J., 2009, THESIS CARNEGIE MELL; Hou XW, 2001, PROC CVPR IEEE, P828; Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731; Loop C., 1987, SMOOTH SUBDIVISION S; Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847; MALPASS RS, 1969, J PERS SOC PSYCHOL, V13, P330, DOI 10.1037/h0028434; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; OTOOLE AJ, 1994, MEM COGNITION, V22, P208, DOI 10.3758/BF03208892; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Romdhani S., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P483; Seshadri K, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P319; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Vapnik V.N, 1998, STAT LEARNING THEORY; Wang SF, 2006, LECT NOTES COMPUT SC, V3852, P427; Xiao J, 2004, PROC CVPR IEEE, P535; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhao WY, 2000, PROC CVPR IEEE, P286, DOI 10.1109/CVPR.2000.855831	32	47	51	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2341	2350		10.1109/TPAMI.2011.275	http://dx.doi.org/10.1109/TPAMI.2011.275			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	021VO	22201062				2022-12-18	WOS:000309913700005
J	Gopalan, R; Taheri, S; Turaga, P; Chellappa, R				Gopalan, Raghuraman; Taheri, Sima; Turaga, Pavan; Chellappa, Rama			A Blur-Robust Descriptor with Applications to Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Blur; convolution; subspace; Grassmann manifold; face recognition	INVARIANTS; GEOMETRY	Understanding the effect of blur is an important problem in unconstrained visual analysis. We address this problem in the context of image-based recognition by a fusion of image-formation models and differential geometric tools. First, we discuss the space spanned by blurred versions of an image and then, under certain assumptions, provide a differential geometric analysis of that space. More specifically, we create a subspace resulting from convolution of an image with a complete set of orthonormal basis functions of a prespecified maximum size (that can represent an arbitrary blur kernel within that size), and show that the corresponding subspaces created from a clean image and its blurred versions are equal under the ideal case of zero noise and some assumptions on the properties of blur kernels. We then study the practical utility of this subspace representation for the problem of direct recognition of blurred faces by viewing the subspaces as points on the Grassmann manifold and present methods to perform recognition for cases where the blur is both homogenous and spatially varying. We empirically analyze the effect of noise, as well as the presence of other facial variations between the gallery and probe images, and provide comparisons with existing approaches on standard data sets.	[Gopalan, Raghuraman] AT&T Labs Res, Video & Multimedia Dept, Middletown, NJ 07748 USA; [Taheri, Sima] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA; [Taheri, Sima; Chellappa, Rama] Univ Maryland, Ctr Automat Res UMIACS, College Pk, MD 20742 USA; [Turaga, Pavan] Arizona State Univ, Sch Arts, Tempe, AZ 85287 USA; [Turaga, Pavan] Arizona State Univ, Sch Media, Tempe, AZ 85287 USA; [Turaga, Pavan] Arizona State Univ, Sch Engn, Tempe, AZ 85287 USA; [Turaga, Pavan] Arizona State Univ, Sch Elect Engn, Tempe, AZ 85287 USA; [Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA	AT&T; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe; University System of Maryland; University of Maryland College Park	Gopalan, R (corresponding author), AT&T Labs Res, Video & Multimedia Dept, Middletown, NJ 07748 USA.	raghuram@research.att.com; taheri@cs.umd.edu; pturaga@asu.edu; rama@umiacs.umd.edu	Turaga, Pavan/W-6186-2019; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012	Turaga, Pavan/0000-0002-5263-5943	MURI from US Office of Naval Research [N00014-08-1-0638]	MURI from US Office of Naval Research	This work was partially supported by a MURI Grant N00014-08-1-0638 from the US Office of Naval Research. This work was performed while Raghuraman Gopalan was with the University of Maryland.	Absil PA, 2004, ACTA APPL MATH, V80, P199, DOI 10.1023/B:ACAP.0000013855.14971.91; Agrawal A, 2009, PROC CVPR IEEE, P2066, DOI 10.1109/CVPRW.2009.5206685; Ahonen T., 2008 19 INT C PATT R, P1; Begelfor E., 2006, 2006 IEEE COMPUTER S, V2, P2087, DOI DOI 10.1109/CVPR.2006.50; Chakrabarti A, 2010, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2010.5539954; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Flusser J, 2003, IEEE T PATTERN ANAL, V25, P234, DOI 10.1109/TPAMI.2003.1177154; Flusser J, 1998, IEEE T PATTERN ANAL, V20, P590, DOI 10.1109/34.683773; Flusser J, 2000, J MATH IMAGING VIS, V13, P101, DOI 10.1023/A:1026519929823; Flusser J., 1996, THEORETICAL FDN COMP, P37; Gallivan KA, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P315; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; Hansen P.C., 2006, DEBLURRING IMAGES MA; Hu H, 2006, IEEE IMAGE PROC, P617, DOI 10.1109/ICIP.2006.312411; Hunt Bobby Ray, 1977, PRENTICE HALL SIGNAL; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Lui YM, 2008, LECT NOTES COMPUT SC, V5303, P44, DOI 10.1007/978-3-540-88688-4_4; Nishiyama M, 2011, IEEE T PATTERN ANAL, V33, P838, DOI 10.1109/TPAMI.2010.203; Nishiyama M, 2009, PROC CVPR IEEE, P1115, DOI 10.1109/CVPRW.2009.5206750; Ojansivu V, 2008, LECT NOTES COMPUT SC, V5112, P527, DOI 10.1007/978-3-540-69812-8_52; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Stainvas I, 2000, INT C PATT RECOG, P805, DOI 10.1109/ICPR.2000.906198; Suk T, 2003, PATTERN RECOGN, V36, P2895, DOI 10.1016/S0031-3203(03)00187-0; Tikhonov A.N., 1977, SOLUTIONS ILLPOSED P; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; WONG YC, 1967, P NATL ACAD SCI USA, V57, P589, DOI 10.1073/pnas.57.3.589; Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673	34	47	48	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1220	1226		10.1109/TPAMI.2012.15	http://dx.doi.org/10.1109/TPAMI.2012.15			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22231594				2022-12-18	WOS:000302916600014
J	Kimmel, R; Zhang, CP; Bronstein, AM; Bronstein, MM				Kimmel, Ron; Zhang, Cuiping; Bronstein, Alexander M.; Bronstein, Michael M.			Are MSER Features Really Interesting?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MSER; feature detector; affine invariance; stable region; correspondence	RECOGNITION	Detection and description of affine-invariant features is a cornerstone component in numerous computer vision applications. In this note, we analyze the notion of maximally stable extremal regions (MSERs) through the prism of the curvature scale space, and conclude that in its original definition, MSER prefers regular (round) regions. Arguing that interesting features in natural images usually have irregular shapes, we propose alternative definitions of MSER which are free of this bias, yet maintain their invariance properties.	[Kimmel, Ron] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel; [Zhang, Cuiping] CMART Syst Inc, Santa Clara, CA 95050 USA; [Bronstein, Alexander M.] Tel Aviv Univ, Sch Elect Engn, Fac Engn, IL-69978 Tel Aviv, Israel; [Bronstein, Michael M.] Univ Svizzera Italiana, Inst Computat Sci, Fac Informat, CH-6900 Lugano, Switzerland	Technion Israel Institute of Technology; Tel Aviv University; Universita della Svizzera Italiana	Kimmel, R (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	ron@cs.technion.ac.il; cuiping.zhang@gmail.com; bron@eng.tau.ac.il; michael.bronstein@usi.ch			European Commission [267414]; Swiss High-Performance and High-Productivity Computing (HP2C)	European Commission(European CommissionEuropean Commission Joint Research Centre); Swiss High-Performance and High-Productivity Computing (HP2C)	This research was supported by the European Commission's FP7-ERC program, grant agreement no. 267414. Michael M. Bronstein is supported by the Swiss High-Performance and High-Productivity Computing (HP2C) grant.	ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127; BRUCKSTEIN AM, 1993, CVGIP-IMAG UNDERSTAN, V58, P49, DOI 10.1006/ciun.1993.1031; Bruckstein AM, 1998, PATTERN RECOGN, V31, P181, DOI 10.1016/S0031-3203(97)00018-6; Cao F., 2008, THEORY SHAPE IDENTIF; Desolneux A, 2001, J MATH IMAGING VIS, V14, P271, DOI 10.1023/A:1011290230196; FORSSEN P, 2007, P IEEE INT C COMP VI; Fua P., 1990, Machine Vision and Applications, V3, P45, DOI 10.1007/BF01211451; GAGE M, 1986, J DIFFER GEOM, V23, P69; GRAYSON MA, 1987, J DIFFER GEOM, V26, P285; GUICHARD F, 2001, IPAM GBM TUTORIAL; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; KIMIA BB, 1990, THESIS MCGILL U; Kimmel R, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P37; KIMMEL R, 2009, 200909 CIS TECHN; KIMMEL R, 2004, NUMERICAL GEOMETRY I; KIMMEL R, 1996, P INT C PATT REC; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Obdrzalek S., 2006, CATEGORY LEVEL OBJEC, P85; Olver P. J., 1995, EQUIVALENCE INVARIAN, DOI DOI 10.1017/CBO9780511609565; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Romeny B.H, 1994, GEOMETRIC DRIVEN DIF; SAPIRO G, 1993, THESIS TECHNION ISRA; Sivic J, 2003, P IEEE INT C COMP VI; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Yu GS, 2009, INT CONF ACOUST SPEE, P1597, DOI 10.1109/ICASSP.2009.4959904	28	47	53	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2316	2320		10.1109/TPAMI.2011.133	http://dx.doi.org/10.1109/TPAMI.2011.133			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM	21709304				2022-12-18	WOS:000294910000015
J	Tabia, H; Daoudi, M; Vandeborre, JP; Colot, O				Tabia, Hedi; Daoudi, Mohamed; Vandeborre, Jean-Philippe; Colot, Olivier			A New 3D-Matching Method of Nonrigid and Partially Similar Models Using Curve Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D-shape matching; curves analysis; belief functions; feature points		The 3D-shape matching problem plays a crucial role in many applications, such as indexing or modeling, by example. Here, we present a novel approach to matching 3D objects in the presence of nonrigid transformation and partially similar models. In this paper, we use the representation of surfaces by 3D curves extracted around feature points. Indeed, surfaces are represented with a collection of closed curves, and tools from shape analysis of curves are applied to analyze and to compare curves. The belief functions are used to define a global distance between 3D objects. The experimental results obtained on the TOSCA and the SHREC07 data sets show that the system performs efficiently in retrieving similar 3D models.	[Tabia, Hedi; Colot, Olivier] Univ Lille 1, LAGIS FRE CNRS 3303, F-59653 Villeneuve Dascq, France; [Daoudi, Mohamed; Vandeborre, Jean-Philippe] TELECOM Lille 1, F-59653 Villeneuve Dascq, France; [Daoudi, Mohamed; Vandeborre, Jean-Philippe] Univ Lille 1, Inst TELECOM, LIFL UMR CNRS 8022, F-59653 Villeneuve Dascq, France	Universite de Lille - ISITE; Universite de Lille; Universite de Lille - ISITE; Universite de Lille; Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; IMT Atlantique; Universite de Lille - ISITE; Universite de Lille	Tabia, H (corresponding author), Univ Lille 1, LAGIS FRE CNRS 3303, Cite Sci, F-59653 Villeneuve Dascq, France.	hedi.tabia@telecom-lille1.eu; mohamed.daoudi@telecom-lille1.eu; vandeborre@telecom-lille1.eu; Olivier.Colot@univ-lille1.fr	Daoudi, Mohammed/H-5935-2013; COLOT, Olivier/C-7776-2017	Daoudi, Mohammed/0000-0003-4219-7860; COLOT, Olivier/0000-0003-1428-1678	Contrat de Projet Etat-Region (CPER) Region Nord-Pas-de-Calais Ambient Intelligence;  [ANR-07-SESU-004]	Contrat de Projet Etat-Region (CPER) Region Nord-Pas-de-Calais Ambient Intelligence(Region Hauts-de-France); 	This work was partially supported by the project ANR-07-SESU-004 and the Contrat de Projet Etat-Region (CPER) Region Nord-Pas-de-Calais Ambient Intelligence.	Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359; ANTINI G, 2005, P IEEE INT C MULT EX; AOUADA D, 2008, P IEEE CS C COMP VIS; Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296; Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6; Bronstein AM, 2009, INT J COMPUT VISION, V84, P163, DOI 10.1007/s11263-008-0147-3; Cole-McLaughlin K., 2003, P 19 ANN S COMP GEOM, P344; Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45; Gil A, 2010, MACH VISION APPL, V21, P905, DOI 10.1007/s00138-009-0195-x; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; Jahanbin S, 2008, P 2 IEEE INT C BIOM; Joshi SH, 2007, LECT NOTES COMPUT SC, V4679, P387; Katz S., 2005, VISUAL COMPUT, V25, P865; Klassen E, 2006, LECT NOTES COMPUT SC, V3951, P95; Laurent Y., 1998, SIAM J APPL MATH, V58, P565; LI X, 2006, P IEEE INT C SHAP MO; LIU Y, 2006, P IEEE CS C COMP VIS; Marini S., 2007, P IEEE SHAP MOD INT, P13; Michor PW, 2006, J EUR MATH SOC, V8, P1, DOI 10.4171/JEMS/37; Mortara M, 2002, SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P245, DOI 10.1109/SMI.2002.1003552; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Samir C, 2009, INT J COMPUT VISION, V82, P80, DOI 10.1007/s11263-008-0187-8; Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Tierny J, 2009, COMPUT GRAPH FORUM, V28, P41, DOI 10.1111/j.1467-8659.2008.01190.x; Vranic D., 2004, THESIS U LEIPZIG; Yezzi A, 2005, IEEE I CONF COMP VIS, P913	28	47	48	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					852	858		10.1109/TPAMI.2010.202	http://dx.doi.org/10.1109/TPAMI.2010.202			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	21079272	Green Submitted			2022-12-18	WOS:000287370400016
J	Yuan, QA; Thangali, A; Ablavsky, V; Sclaroff, S				Yuan, Quan; Thangali, Ashwin; Ablavsky, Vitaly; Sclaroff, Stan			Learning a Family of Detectors via Multiplicative Kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; object detection; object tracking; pose estimation; kernel methods	FACE; RECOGNITION; OBJECTS	Object detection is challenging when the object class exhibits large within-class variations. In this work, we show that foreground-background classification (detection) and within-class classification of the foreground class (pose estimation) can be jointly learned in a multiplicative form of two kernel functions. Model training is accomplished via standard SVM learning. When the foreground object masks are provided in training, the detectors can also produce object segmentations. A tracking-by-detection framework to recover foreground state in video sequences is also proposed with our model. The advantages of our method are demonstrated on tasks of object detection, view angle estimation, and tracking. Our approach compares favorably to existing methods on hand and vehicle detection tasks. Quantitative tracking results are given on sequences of moving vehicles and human faces.	[Yuan, Quan] Sony Elect Inc, US Res Ctr, San Jose, CA 95112 USA; [Thangali, Ashwin; Ablavsky, Vitaly; Sclaroff, Stan] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA	Boston University	Yuan, QA (corresponding author), Sony Elect Inc, US Res Ctr, 1730 N 1 St, San Jose, CA 95112 USA.	quan.yuan@am.sony.com; tvashwin@cs.bu.edu; ablavsky@cs.bu.edu; sclaroff@cs.bu.edu	yuan, quan/GZM-5597-2022	Ablavsky, Vitaly/0000-0003-2703-7666	US National Science Foundation (NSF) [IIS-0705749, IIS-0713168]	US National Science Foundation (NSF)(National Science Foundation (NSF))	This paper reports work that was supported in part by the US National Science Foundation (NSF) under grants IIS-0705749 and IIS-0713168.	Agarwal A., 2004, P IEEE C COMP VIS PA; Andriluka M., 2008, P IEEE C COMP VIS PA; ATHITSOS V, 2003, P IEEE C COMP VIS PA; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BISSACCO A, 2007, P IEEE C COMP VIS PA; Bissacco A., 2006, ADV NEURAL INFORM PR; Blaschko M.B., 2008, P EUR C COMP VIS; BORENSTEIN E, 2002, P EUR C COMP VIS; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Crasborn Onno, 2004, ECHO DATA SET SIGN L; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, HISTOGRAMS ORIENTED; Damoulas T, 2009, PATTERN RECOGN LETT, V30, P46, DOI 10.1016/j.patrec.2008.08.016; Enzweiler M., 2008, P IEEE C COMP VIS PA; Everingham M., 2006, MACHINE LEARNING CHA; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; GAVRILA DM, 2000, P EUR C COMP VIS; GROSS R, 2008, P IEEE INT C FAC GES; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011; Ioffe S, 2001, INT J COMPUT VISION, V43, P45, DOI 10.1023/A:1011179004708; IONESCU C, 2009, P IEEE C COMP VIS PA; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Joachims T., 1999, ADV KERNEL METHODS S; Leibe B., 2007, P IEEE C COMP VIS PA; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Li S., 2001, P IEEE INT C COMP VI; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73; MARSZALEK M, 2007, P VIS REC CHALL WORK; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; NEIDLE C, 2003, SLLRP SIGNSTREAM DAT; NEVATIA R., 2007, P IEEE INT C COMP VI; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; OIKONOMOPOULOS A, 2006, P WORKSH VIS HUM COM; Okuma K., 2004, P EUR C COMP VIS; ONG E, 2004, P IEEE INT C FAC GES; Osadchy R., 2004, ADV NEURAL INFORM PR; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Pentland A., 1994, IEEE C COMP VIS PATT; Platt J., 1999, ADV LARGE MARGIN CLA; RAMANAN D, 2005, P IEEE C COMP VIS PA; Rifkin R, 2004, J MACH LEARN RES, V5, P101; ROSALES R, 2002, ADV NEURAL INFORM PR; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Russell B., 2005, LABELME DATABASE WEB; SCHIELE B., 2006, P IEEE C COMP VIS PA; Shakhnarovich G., 2003, P IEEE INT C COMP VI; Shi J., 1997, P IEEE C COMP VIS PA; Sidenbladh H., 2000, P EUR C COMP VIS; Sigal L., 2004, P IEEE C COMP VIS PA; SMINCHISESCU C, 2006, P IEEE C COMP VIS PA; STENGER B, 2003, P IEEE INT C COMP VI; TON P. H. S., 2005, P IEEE C COMP VIS PA; Torralba A., 2004, P IEEE C COMP VIS PA; VARMA M, 2007, P IEEE INT C COMP VI; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P., 2003, P IEEE C COMP VIS PA; Wang L., 2007, P AS C COMP VIS; WU B., 2007, P IEEE C COMP VIS PA; YUAN Q, 2007, P IEEE C COMP VIS PA; ZHU L, 2007, ADV NEURAL INFORM PR	63	47	52	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					514	530		10.1109/TPAMI.2010.117	http://dx.doi.org/10.1109/TPAMI.2010.117			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	20548107	Green Submitted			2022-12-18	WOS:000286204700007
J	Cootes, TF; Twining, CJ; Petrovic, VS; Babalola, KO; Taylor, CJ				Cootes, Timothy F.; Twining, Carole J.; Petrovic, Vladimir S.; Babalola, Kolawole O.; Taylor, Christopher J.			Computing Accurate Correspondences across Groups of Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonrigid registration; correspondence problem; appearance models	ACTIVE APPEARANCE MODELS; AUTOMATIC CONSTRUCTION; NONRIGID REGISTRATION; BRAIN; MAXIMIZATION	Groupwise image registration algorithms seek to establish dense correspondences between sets of images. Typically, they involve iteratively improving the registration between each image and an evolving mean. A variety of methods have been proposed, which differ in their choice of objective function, representation of deformation field, and optimization methods. Given the complexity of the task, the final accuracy is significantly affected by the choices made for each component. Here, we present a groupwise registration algorithm which can take advantage of the statistics of both the image intensities and the range of shapes across the group to achieve accurate matching. By testing on large sets of images (in both 2D and 3D), we explore the effects of using different image representations and different statistical shape constraints. We demonstrate that careful choice of such representations can lead to significant improvements in overall performance.	[Cootes, Timothy F.; Twining, Carole J.; Petrovic, Vladimir S.; Babalola, Kolawole O.; Taylor, Christopher J.] Univ Manchester, Imaging Sci & Biomed Engn Res Grp, Manchester M13 9PT, Lancs, England	University of Manchester	Cootes, TF (corresponding author), Univ Manchester, Imaging Sci & Biomed Engn Res Grp, Manchester M13 9PT, Lancs, England.	t.cootes@manchester.ac.uk; carole.twining@manchester.ac.uk; vladimir.petrovic@manchester.ac.uk; kola.babalola@manchester.ac.uk; chris.taylor@manchester.ac.uk	Twining, Carole J/F-7423-2012; Taylor, Christopher J/A-3909-2009	Taylor, Christopher J/0000-0001-7867-9533; Cootes, Timothy/0000-0002-2695-9063; Babalola, Kola/0000-0003-1384-8433	EPSRC [GR/N14248/01, GR/S82503/01]; UK Medical Research Council [D2025/31]; EPSRC [DT/F003072/1, EP/F027044/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [GR/N14248/01, GR/S82503/01, EP/F027044/1, DT/F003072/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); UK Medical Research Council(UK Research & Innovation (UKRI)Medical Research Council UK (MRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors would like to thank David Kennedy of the Center for Morphometric Analysis at MGH for providing the fully annotated brain images. This research was supported by the MIAS IRC project, EPSRC Grant No. GR/N14248/01, UK Medical Research Council Grant No. D2025/31 ("From Medical Images and Signals to Clinical Information"), and also by the IBIM project, EPSRC grant No. GR/S82503/01 ("Integrated Brain Image Modeling").	Baker S, 2004, IEEE T PATTERN ANAL, V26, P1380, DOI 10.1109/TPAMI.2004.77; BALCI SK, 2007, P MICCAI STAT REG WO, P23; Collins DL, 1995, HUM BRAIN MAPP, V3, P190, DOI 10.1002/hbm.460030304; Cootes TF, 2008, IMAGE VISION COMPUT, V26, P326, DOI 10.1016/j.imavis.2006.12.005; Cootes TF, 2004, LECT NOTES COMPUT SC, V2034, P316; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COOTES TF, 2005, P BRIT MACH VIS C, V2, P879; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Davies RH, 2002, IEEE T MED IMAGING, V21, P525, DOI 10.1109/TMI.2002.1009388; DAVIES RH, 2002, P ECCV, V3, P3; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Dryden IL, 1998, STAT ANAL SHAPE; Duchesne S, 2002, NEUROIMAGE, V17, P515, DOI 10.1006/nimg.2002.1188; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; FILIPEK PA, 1994, CEREB CORTEX, V4, P344, DOI 10.1093/cercor/4.4.344; Frangi AF, 2002, IEEE T MED IMAGING, V21, P1151, DOI 10.1109/TMI.2002.804426; Gaens T, 1998, LECT NOTES COMPUT SC, V1496, P1099, DOI 10.1007/BFb0056299; Guimond A, 1998, LECT NOTES COMPUT SC, V1496, P631, DOI 10.1007/BFb0056249; Hajnal JV, 2001, MED IMAGE REGISTRATI; Jones MJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P683, DOI 10.1109/ICCV.1998.710791; Jones MJ, 1998, INT J COMPUT VISION, V29, P107, DOI 10.1023/A:1008074226832; Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068; KOKKINOS I, 2007, P IEEE INT C COMP VI; Langs G, 2007, LECT NOTES COMPUT SC, V4791, P968; Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34; Lorenzen P, 2005, LECT NOTES COMPUT SC, V3750, P411, DOI 10.1007/11566489_51; Lotjonen J, 2001, LECT NOTES COMPUTER, P541; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; MAINTZ J, 1998, IEEE ENG MED BIOL, V2, P1; Marsland S, 2003, LECT NOTES COMPUT SC, V2879, P771; Marsland S, 2008, IMAGE VISION COMPUT, V26, P333, DOI 10.1016/j.imavis.2006.12.009; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; Nishida M, 2006, NEUROIMAGE, V32, P1041, DOI 10.1016/j.neuroimage.2006.05.020; Ponce J., 2006, CATEGORY LEVEL OBJEC; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; Rueckert D, 2003, IEEE T MED IMAGING, V22, P1014, DOI 10.1109/TMI.2003.815865; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x; Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4; Twining CJ, 2004, INT C PATT RECOG, P704, DOI 10.1109/ICPR.2004.1334626; Vetter T, 1997, PROC CVPR IEEE, P40, DOI 10.1109/CVPR.1997.609295; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wang F, 2008, IEEE T PATTERN ANAL, V30, P2011, DOI 10.1109/TPAMI.2007.70829; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	46	47	48	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					1994	2005		10.1109/TPAMI.2009.193	http://dx.doi.org/10.1109/TPAMI.2009.193			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20847389				2022-12-18	WOS:000281990900005
J	Zhu, GY; Zheng, YF; Doermann, D; Jaeger, S				Zhu, Guangyu; Zheng, Yefeng; Doermann, David; Jaeger, Stefan			Signature Detection and Matching for Document Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Document image analysis and retrieval; signature detection and segmentation; signature matching; structural saliency; deformable shape; measure of shape dissimilarity	NONRIGID SHAPES; VERIFICATION; RECOGNITION; REGISTRATION; CLASSIFICATION; IDENTIFICATION; ALGORITHMS; CURVES; AFFINE; TEXT	As one of the most pervasive methods of individual identification and document authentication, signatures present convincing evidence and provide an important form of indexing for effective document image processing and retrieval in a broad range of applications. However, detection and segmentation of free-form objects such as signatures from clustered background is currently an open document analysis problem. In this paper, we focus on two fundamental problems in signature-based document image retrieval. First, we propose a novel multiscale approach to jointly detecting and segmenting signatures from document images. Rather than focusing on local features that typically have large variations, our approach captures the structural saliency using a signature production model and computes the dynamic curvature of 2D contour fragments over multiple scales. This detection framework is general and computationally tractable. Second, we treat the problem of signature retrieval in the unconstrained setting of translation, scale, and rotation invariant nonrigid shape matching. We propose two novel measures of shape dissimilarity based on anisotropic scaling and registration residual error and present a supervised learning framework for combining complementary shape information from different dissimilarity metrics using LDA. We quantitatively study state-of-the-art shape representations, shape matching algorithms, measures of dissimilarity, and the use of multiple instances as query in document image retrieval. We further demonstrate our matching techniques in offline signature verification. Extensive experiments using large real-world collections of English and Arabic machine-printed and handwritten documents demonstrate the excellent performance of our approaches.	[Zhu, Guangyu; Doermann, David] Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA; [Zheng, Yefeng] Siemens Corp Res, Princeton, NJ 08540 USA; [Jaeger, Stefan] Chinese Acad Sci, MPG Partner Inst Computat Biol, Syst Bioinformat Grp, Shanghai 200031, Peoples R China	University System of Maryland; University of Maryland College Park; Siemens AG; Chinese Academy of Sciences; Shanghai Institutes for Biological Sciences, CAS; Max Planck Society	Zhu, GY (corresponding author), Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA.	zhugy@umiacs.umd.edu; yefeng.zheng@siemens.com; doermann@umd.edu; jaeger@picb.ac.cn	Zheng, Yefeng/ABG-7053-2020	Zheng, Yefeng/0000-0003-2195-2847	US Department of Defense [MDA-9040-2C-0406]; ARDA Challenge Grant on Complex Document Image Processing [4-31809]	US Department of Defense(United States Department of Defense); ARDA Challenge Grant on Complex Document Image Processing	This research is supported by the US Department of Defense under contract MDA-9040-2C-0406 and an ARDA Challenge Grant on Complex Document Image Processing 4-31809. Parts of this work have appeared in CVPR '07 [4] and ECCV '08 [66]. The authors would like to thank R. Sabourin for providing the offline signature database used in Section 6.5. They would also like to thank R. Chellappa, L. Davis, D. Jacobs, O. Frieder, and S. Srihari for useful discussions.	*ABBYY CORP, 2006, ABBYY FINEREADER SDK; Agam G., 2006, COMPLEX DOCUMENT IMA; Alter T, 1998, INT J COMPUT VISION, V27, P51, DOI 10.1023/A:1007953729443; [Anonymous], 2007, LEG TOB DOC LIB LTDL; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; Buckley Chris, 2000, P 23 ANN INT ACM SIG, P33, DOI 10.1145/345508.345543; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chen SY, 2005, PROC INT CONF DOC, P1280; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; DOERMANN DS, 1995, INT J COMPUT VISION, V15, P143, DOI 10.1007/BF01450853; Drouhard JP, 1996, PATTERN RECOGN, V29, P415, DOI 10.1016/0031-3203(95)00092-5; DYER CR, 1979, IEEE T PATTERN ANAL, V1, P88, DOI 10.1109/TPAMI.1979.4766880; ELDER J, 1993, VISION RES, V33, P981, DOI 10.1016/0042-6989(93)90080-G; Fang B, 2003, PATTERN RECOGN, V36, P91, DOI 10.1016/S0031-3203(02)00061-4; Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; GORMAN JW, 1988, IEEE T PATTERN ANAL, V10, P257, DOI 10.1109/34.3887; Guo JK, 2001, INT J PATTERN RECOGN, V15, P579, DOI 10.1142/S0218001401001088; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HOLLERBACH JM, 1978, THESIS MIT; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Kalera MK, 2004, INT J PATTERN RECOGN, V18, P1339, DOI 10.1142/S0218001404003630; Lamdan Y., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P335, DOI 10.1109/CVPR.1988.196257; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Lertbantanawong J, 2006, PROCEEDINGS OF THE 2006 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P414; Lewis D., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P665, DOI 10.1145/1148170.1148307; Li Y, 2008, IEEE T PATTERN ANAL, V30, P1313, DOI 10.1109/TPAMI.2007.70792; LIN CC, 1987, IEEE T PATTERN ANAL, V9, P686, DOI 10.1109/TPAMI.1987.4767963; LINDEBERG T, 1998, INT J COMPUT VISION, V30, P77; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220; Munich M. E., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P108, DOI 10.1109/ICCV.1999.791205; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Petrakis EGM, 2002, IEEE T PATTERN ANAL, V24, P1501, DOI 10.1109/TPAMI.2002.1046166; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Rath T. M., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P369, DOI 10.1145/1008992.1009056; Rath TM, 2003, PROC CVPR IEEE, P521; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Sabourin R., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P709, DOI 10.1142/S0218001494000383; Sabourin R, 1997, IEEE T PATTERN ANAL, V19, P976, DOI 10.1109/34.615447; SAINTMARC P, 1993, IEEE T PATTERN ANAL, V15, P1191, DOI 10.1109/34.244680; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shanker AP, 2007, PATTERN RECOGN LETT, V28, P1407, DOI 10.1016/j.patrec.2007.02.016; Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396; Shotton J, 2005, IEEE I CONF COMP VIS, P503; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Srihari SN, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P198, DOI 10.1109/DIAL.2006.17; TURKOWSKI K, 1990, GRAPHICS GEMS, V1, P147; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; VELKAMP R, 1999, UUCS199927; Wakahara T, 1998, IEEE T PATTERN ANAL, V20, P1332, DOI 10.1109/34.735806; WILLIAMS L, 1997, NEURAL COMPUT, V9, P849; Williams LR, 1999, INT J COMPUT VISION, V34, P81, DOI 10.1023/A:1008187804026; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949; ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81; Zheng YF, 2004, IEEE T PATTERN ANAL, V26, P337, DOI 10.1109/TPAMI.2004.1262324; Zhu G., 2007, P IEEE C COMP VIS PA, P1; Zhu GY, 2008, LECT NOTES COMPUT SC, V5304, P752	66	47	49	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					2015	2031		10.1109/TPAMI.2008.237	http://dx.doi.org/10.1109/TPAMI.2008.237			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	493VV	19762928				2022-12-18	WOS:000269767600007
J	Lu, SJ; Li, LL; Tan, CL				Lu, Shijian; Li, Linlin; Tan, Chew Lim			Document image retrieval through word shape coding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image retrieval; document image analysis; word shape coding	INFORMATION-RETRIEVAL; TEXT RETRIEVAL; SCRIPT	This paper presents a document retrieval technique that is capable of searching document images without optical character recognition (OCR). The proposed technique retrieves document images by a new word shape coding scheme, which captures the document content through annotating each word image by a word shape code. In particular, we annotate word images by using a set of topological shape features including character ascenders/descenders, character holes, and character water reservoirs. With the annotated word shape codes, document images can be retrieved by either query keywords or a query document image. Experimental results show that the proposed document image retrieval technique is fast, efficient, and tolerant to various types of document degradation.	[Lu, Shijian] Agcy Sci Technol & Res, Inst Infocomm Res, Singapore 119613, Singapore; [Li, Linlin; Tan, Chew Lim] Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 117543, Singapore	Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); National University of Singapore	Lu, SJ (corresponding author), Agcy Sci Technol & Res, Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	slu@i2r.a-star.edu.sg; lilinlin@comp.nus.edu.sg; tancl@comp.nus.edu.sg	Lu, Shijian/AAU-4831-2021	Lu, Shijian/0000-0002-6766-2506	Agency for Science, Technology, and Research (A*STAR), Singapore [0421010085]	Agency for Science, Technology, and Research (A*STAR), Singapore(Agency for Science Technology & Research (A*STAR))	This research is supported by the Agency for Science, Technology, and Research (A*STAR), Singapore, under Grant 0421010085.	BREUEL TM, 2005, P INT WORKSH DOC AN, P275; CHEN FR, 1995, P SOC PHOTO-OPT INS, V2422, P256, DOI 10.1117/12.205828; Khoubyari S., 1993, Proceedings. Second Annual Symposium on Document Analysis and Information Retrieval, P217; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; Lu SJ, 2008, PATTERN RECOGN, V41, P1799, DOI 10.1016/j.patcog.2007.10.017; Lu SJ, 2008, IEEE T PATTERN ANAL, V30, P14, DOI 10.1109/TPAMI.2007.1158; Lu Y, 2004, IEEE T KNOWL DATA EN, V16, P1398, DOI 10.1109/TKDE.2004.76; NAKAYAMA T, 1996, P INT C COMP LING CO, P818; NAKAYAMA T, 1994, P 4 C APPL NAT LANG, P22; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Salton G., 1983, INTRO MODERN INFORM; Smeaton AF, 1997, PROC INT CONF DOC, P974, DOI 10.1109/ICDAR.1997.620655; Spitz A. L., 1995, Shape, Structure and Pattern Recognition, P382; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; Tan CL, 2003, APPL INTELL, V18, P257, DOI 10.1023/A:1023245904128; Tan CL, 2002, IEEE T PATTERN ANAL, V24, P838, DOI 10.1109/TPAMI.2002.1008389; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P312, DOI 10.1109/34.368197; YANG Y, 1999, P 22 ANN INT ACM C R, V42	18	47	48	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					1913	1918		10.1109/TPAMI.2008.89	http://dx.doi.org/10.1109/TPAMI.2008.89			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787240				2022-12-18	WOS:000259110000005
J	He, YL; Tian, J; Li, L; Chen, H; Yang, X				He, YL; Tian, J; Li, L; Chen, H; Yang, X			Fingerprint matching based on global comprehensive similarity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprint identification; ridge-based nearest neighborhood among minutiae; relative feature; minutia-simplex	ENHANCEMENT	This paper introduces a novel algorithm based on global comprehensive similarity with three steps. To describe the Euclidean space- based relative features among minutiae, we first build a minutia- simplex that contains a pair of minutiae as well as their associated textures, with its transformation- variant and invariant relative features employed for the comprehensive similarity measurement and parameter estimation, respectively. By the second step, we use the ridge- based nearest neighborhood among minutiae to represent the ridge- based relative features among minutiae. With these ridge- based relative features, minutiae are grouped according to their affinity with a ridge. The Euclidean space- based and ridge- based relative features among minutiae reinforce each other in the representation of a fingerprint. Finally, we model the relationship between transformation and the comprehensive similarity between two fingerprints in terms of histogram for initial parameter estimation. Through these steps, our experiment shows that the method mentioned above is both effective and suitable for limited memory AFIS owing to its less than 1k byte template size.	Chinese Acad Sci, Ctr Biometr & Secur Res, Key Lab Complex Syst & Intelligence Sci, Inst Automat, Beijing 100080, Peoples R China; Microsoft Res Adv Technol Ctr, Beijing, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Microsoft	He, YL (corresponding author), Chinese Acad Sci, Ctr Biometr & Secur Res, Key Lab Complex Syst & Intelligence Sci, Inst Automat, POB 2728, Beijing 100080, Peoples R China.	yuliang.he@ia.ac.cn; tian@doctor.com; liang.li@ia.ac.cn; hongchen@microsoft.com; xin.yang@ia.ac.cn	Tian, Jie/H-1190-2011; Tian, Jie/M-5976-2013	Tian, Jie/0000-0003-0498-0432; 				Bazen AM, 2002, INT C PATT RECOG, P985, DOI 10.1109/ICPR.2002.1048471; Bhanu B, 2003, IEEE T PATTERN ANAL, V25, P616, DOI 10.1109/TPAMI.2003.1195995; CAPPELLI R, 2001, P 2 C ADV PATT REC; Chang JH, 2002, PATTERN RECOGN, V35, P1209, DOI 10.1016/S0031-3203(01)00121-2; CHEN H, 2003, P AVBPA, P327; Cheng JG, 2004, PATTERN RECOGN LETT, V25, P1273, DOI 10.1016/j.patrec.2004.04.005; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; He YL, 2003, PATTERN RECOGN LETT, V24, P1349, DOI 10.1016/S0167-8655(02)00376-8; Jain A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P282, DOI 10.1109/ICIP.2001.958106; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531; Jiang XD, 2000, INT C PATT RECOG, P1038, DOI 10.1109/ICPR.2000.906252; Jin ATB, 2004, IMAGE VISION COMPUT, V22, P503, DOI 10.1016/j.imavis.2003.12.002; Lee CJ, 2001, PATTERN RECOGN, V34, P2245, DOI 10.1016/S0031-3203(01)00029-2; Li S. Z., 2001, COMP SCI W; Luo XP, 2000, INT C PATT RECOG, P783, DOI 10.1109/ICPR.2000.903034; Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1; Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144; Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140; Prabhakar S., 2003, HDB FINGERPRINT RECO; Ross A, 2003, PATTERN RECOGN, V36, P1661, DOI 10.1016/S0031-3203(02)00349-7; Senior AW, 2001, IEICE T INF SYST, VE84D, P825; Sujan VA, 2002, PATTERN RECOGN LETT, V23, P609, DOI 10.1016/S0167-8655(01)00137-4; Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604; Toh KA, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P262, DOI 10.1109/ICIP.2001.958101; XIAO Q, 1991, PATTERN RECOGN, V24, P985, DOI 10.1016/0031-3203(91)90095-M; ZHANG TH, 2003, P 4 INT C AUD VID BA, P854	27	47	56	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					850	862		10.1109/TPAMI.2006.119	http://dx.doi.org/10.1109/TPAMI.2006.119			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724581	Green Submitted			2022-12-18	WOS:000236734400001
J	Moriyama, T; Kanade, T; Xiao, J; Cohn, JF				Moriyama, T; Kanade, T; Xiao, J; Cohn, JF			Meticulously detailed eye region model and its application to analysis of facial images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; facial image analysis; facial expression analysis; generative eye region model; motion tracking; texture modeling; gradient descent	FEATURE-EXTRACTION; AUTOMATIC-ANALYSIS; SYSTEM	We propose a system that is capable of detailed analysis of eye region images in terms of the position of the iris, degree of eyelid opening, and the shape, complexity, and texture of the eyelids. The system uses a generative eye region model that parameterizes the fine structure and motion of an eye. The structure parameters represent structural individuality of the eye, including the size and color of the iris, the width, boldness, and complexity of the eyelids, the width of the bulge below the eye, and the width of the illumination reflection on the bulge. The motion parameters represent movement of the eye, including the up-down position of the upper and lower eyelids and the 2D position of the iris. The system first registers the eye model to the input in a particular frame and individualizes it by adjusting the structure parameters. The system then tracks motion of the eye by estimating the motion parameters across the entire image sequence. Combined with image stabilization to compensate for appearance changes due to head motion, the system achieves accurate registration and motion recovery of eyes.	Keio Univ, Dept Sci & Technol, Kouhoku Ku, Kanagawa 2238522, Japan; Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; Epson Res & Dev Inc, Epson Palo Alto Lab, Palo Alto, CA 94304 USA; Univ Pittsburgh, Pittsburgh, PA 15260 USA	Keio University; Carnegie Mellon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Moriyama, T (corresponding author), Keio Univ, Dept Sci & Technol, Kouhoku Ku, 3-14-1 Hiyoshi, Kanagawa 2238522, Japan.	moriyama@ozawa.ics.keio.ac.jp; tk@cs.cmu.edu; xiaoj@erd.epson.com; jeffcohn@pitt.edu			NATIONAL INSTITUTE OF MENTAL HEALTH [R01MH051435] Funding Source: NIH RePORTER; NIMH NIH HHS [R01 MH051435, R01 MH51435, R01 MH051435-11] Funding Source: Medline	NATIONAL INSTITUTE OF MENTAL HEALTH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH)); NIMH NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH))		BLAKE A, 1992, ACTIVE VISION, P21; Chen H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P433, DOI 10.1109/ICCV.2001.937657; Choi SH, 2003, MED BIOL ENG COMPUT, V41, P146, DOI 10.1007/BF02344882; CHOW G, 1993, PATTERN RECOGN, V26, P1739, DOI 10.1016/0031-3203(93)90173-T; Deng JY, 1997, PATTERN RECOGN, V30, P403, DOI 10.1016/S0031-3203(96)00086-6; EKMAN P, 1994, WHAT FACE REVEALS; Ekman P., 2002, FACIAL ACTION CODING; EKMAN P, UNPUB EKMANHAGAR FAC; Fukuda K, 2001, INT J PSYCHOPHYSIOL, V40, P239, DOI 10.1016/S0167-8760(00)00192-6; Gokturk SB, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P287, DOI 10.1109/AFGR.2002.1004168; Gross R, 2001, P 3 WORKSH EMP EV ME; Herpers R, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P212, DOI 10.1109/AFGR.1996.557266; Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611; Kapoor A, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P195; KING I, 1997, P WORKSH 3D COMP VIS, P124; Lee SP, 2002, ACM T GRAPHIC, V21, P637; Lien JJJ, 2000, ROBOT AUTON SYST, V31, P131, DOI 10.1016/S0921-8890(99)00103-7; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Matsumoto Y, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P2127, DOI 10.1109/IROS.2000.895285; Moriyama T, 2002, INT C PATT RECOG, P78, DOI 10.1109/ICPR.2002.1047404; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2; RAVYSE I, 2000, P IEEE INT C PATT RE, V1, P5080; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; TIAN Y, 2000, P INT C MULT US INT, P143; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Wang JG, 2002, IEEE T SYST MAN CY B, V32, P332, DOI 10.1109/TSMCB.2002.999809; Xiao J, 2003, INT J IMAG SYST TECH, V13, P85, DOI 10.1002/ima.10048; XIE X, 1994, PATTERN RECOGN, V27, P791, DOI 10.1016/0031-3203(94)90164-3; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; Zhu J, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P131, DOI 10.1109/AFGR.2002.1004144	32	47	51	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					738	752		10.1109/TPAMI.2006.98	http://dx.doi.org/10.1109/TPAMI.2006.98			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640260	Green Submitted, Green Published, Green Accepted			2022-12-18	WOS:000235885700006
J	Yap, PT; Paramesran, R				Yap, PT; Paramesran, R			An efficient method for the computation of Legendre moments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						moments; feature representation	IMAGE-ANALYSIS	Legendre moments are continuous moments, hence, when applied to discrete-space images, numerical approximation is involved and error occurs. This paper proposes a method to compute the exact values of the moments by mathematically integrating the Legendre polynomials over the corresponding intervals of the image pixels. Experimental results show that the values obtained match those calculated theoretically, and the image reconstructed from these moments have lower error than that of the conventional methods for the same order. Although the same set of exact Legendre moments can be obtained indirectly from the set of geometric moments, the computation time taken is much longer than the proposed method.	Univ Malaya, Dept Elect Engn, Kuala Lumpur 50603, Malaysia	Universiti Malaya	Yap, PT (corresponding author), Univ Malaya, Dept Elect Engn, Kuala Lumpur 50603, Malaysia.	ptyap@time.net.my; ravee@um.edu.my	Yap, Pew-Thian/G-3292-2012; Paramesran, Raveendran/AAA-1895-2019	Paramesran, Raveendran/0000-0001-5093-7027				Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003; Erdelyi A., 1953, HIGHER TRANSCENDENTA; Haddadnia J, 2001, IEEE IMAGE PROC, P1018, DOI 10.1109/ICIP.2001.959221; KOEKOEK R, 1998, 9817 TU DELFT FAC TE, P46; Kreyszig E., 1988, ADV ENG MATH; Liao Simon Xinmeng, 1993, THESIS U MANITOBA WI; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809; MANDAL M, 1996, P INT C CONS EL JUN, P557; MUKUNDAN R, 1995, PATTERN RECOGN, V28, P1433, DOI 10.1016/0031-3203(95)00011-N; Mukundan R., 1998, MOMENT FUNCTIONS IMA; Qjidaa H, 1999, IEEE T PATTERN ANAL, V21, P1216, DOI 10.1109/34.809115; SHEN J, 1996, P ICPR 96 VIENN, P241; Shu HZ, 2000, PATTERN RECOGN, V33, P341, DOI 10.1016/S0031-3203(99)00044-8; Shu HZ, 2001, PATTERN RECOGN, V34, P1119, DOI 10.1016/S0031-3203(00)00049-2; Szeg G., 1939, ORTHOGONAL POLYNOMIA, V23; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; Zhou JD, 2002, PATTERN RECOGN, V35, P1143, DOI 10.1016/S0031-3203(01)00104-2	19	47	50	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1996	2002		10.1109/TPAMI.2005.232	http://dx.doi.org/10.1109/TPAMI.2005.232			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16355666				2022-12-18	WOS:000232532600014
J	Huijsmans, DP; Sebe, N				Huijsmans, DP; Sebe, N			How to complete performance graphs in content-based image retrieval: Add generality and normalize scope	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multimedia information systems; information retrieval; content-based image retrieval; performance evaluation	SYSTEM	The performance of a Content-Based Image Retrieval (CBIR) system, presented in the form of Precision-Recall or Precision-Scope graphs, offers an incomplete overview of the system under study: The influence of the irrelevant items ( embedding) is obscured. In this paper, we propose a comprehensive and well-normalized description of the ranking performance compared to the performance of an Ideal Retrieval System defined by ground-truth for a large number of predefined queries. We advocate normalization with respect to relevant class size and restriction to specific normalized scope values ( the number of retrieved items). We also propose new three and two-dimensional performance graphs for total recall studies in a range of embeddings.	Leiden Univ, Leiden Inst Adv Comp Sci, NL-2300 RA Leiden, Netherlands; Univ Amsterdam, Fac Sci, NL-1098 SJ Amsterdam, Netherlands	Leiden University; Leiden University - Excl LUMC; University of Amsterdam	Huijsmans, DP (corresponding author), Leiden Univ, Leiden Inst Adv Comp Sci, POB 9512, NL-2300 RA Leiden, Netherlands.	huijsman@liacs.nl; nicu@science.uva.nl	Huijsmans, Nies/C-6329-2009	Huijsmans, Nies/0000-0002-5594-7934; Sebe, Niculae/0000-0002-6597-7248				Baumgarten C, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P246, DOI 10.1145/312624.312685; Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596; GOKHALE DV, 1978, INFORMATION CONTINGE; Huijsmans DP, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P733; Huijsmans DP, 2001, PROC CVPR IEEE, P26; HUIJSMANS DP, 2000, P 4 INT C ADV VIS IN, P500; Muller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5; MULLER H, 2002, P INT C IM VID RETR, P38; Porkaew K, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P235, DOI 10.1145/319463.319613; RAGHAVAN VV, 1989, ACM T INFORM SYST, V7, P205, DOI 10.1145/65943.65945; ROBERTSO.SE, 1969, J DOC, V25, P93, DOI 10.1108/eb026466; Salton G., 1971, SMART RETRIEVAL SYST; SWETS JA, 1963, SCIENCE, V141, P245, DOI 10.1126/science.141.3577.245; TAGUESUTCLIFFE J, 1992, INFORM PROCESS MANAG, V28, P467, DOI 10.1016/0306-4573(92)90005-K; VANBEMMEL JH, 1997, HDB MED INFORMATICS; VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA; Vasconcelos N, 2000, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2000.855822; Voorhees Ellen M, 1999, P TEXT RETRIEVAL C; 2001, IEEE T CIRCUITS SYST, V11	19	47	52	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2005	27	2					245	251		10.1109/TPAMI.2005.30	http://dx.doi.org/10.1109/TPAMI.2005.30			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	879AR	15688561				2022-12-18	WOS:000225689300007
J	Carcassoni, M; Hancock, ER				Carcassoni, M; Hancock, ER			Correspondence matching with modal clusters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						point-pattern matching; spectral graph theory; robust statistics; hierarchy	EM ALGORITHM; CORNER DETECTION; SHAPE	The modal correspondence method of Shapiro and Brady aims to match point-sets by comparing the eigenvectors of a pairwise point proximity matrix. Although elegant by means of its matrix representation, the method is notoriously susceptible to differences in the relational structure of the point-sets under consideration. In this paper, we demonstrate how the method can be rendered robust to structural differences by adopting a hierarchical approach. To do this, we place the modal matching problem in a probabilistic setting in which the correspondences between pairwise clusters can be used to constrain the individual point correspondences. We demonstrate the utility of the method on a number of synthetic and real-world point-pattern matching problems.	Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England	University of York - UK	Carcassoni, M (corresponding author), Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England.	marco@cs.york.ac.uk; erh@cs.york.ac.uk	Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028				Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7; Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377; Chung FR, 1997, SPECTRAL GRAPH THEOR, V92; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602; LUO B, 1999, PATTERN RECOGN, P635; Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; Pilu M, 1997, PROC CVPR IEEE, P261, DOI 10.1109/CVPR.1997.609330; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Shokoufandeh A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P491, DOI 10.1109/CVPR.1999.784726; Sossa H., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P811, DOI 10.1109/CVPR.1992.223252; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; Wilson RC, 1998, COMPUT VIS IMAGE UND, V72, P21, DOI 10.1006/cviu.1997.0656	21	47	57	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1609	1615		10.1109/TPAMI.2003.1251153	http://dx.doi.org/10.1109/TPAMI.2003.1251153			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA		Green Published, Green Accepted			2022-12-18	WOS:000186765000010
J	Connell, SD; Jain, AK				Connell, SD; Jain, AK			Writer adaptation for online handwriting recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						online handwriting; writer-adaptation; writing style modeling; hidden Markov models; lexemes		Writer-adaptation is the process of converting a writer-independent handwriting recognition system, which models the characteristics of a large group of writers, into a writer-dependent system, which is tuned for a particular writer. This adaptation has the potential of greatly increasing recognition accuracies, provided adequate models can be constructed for a particular writer. The limited amount of data a writer is willing to provide during the training phase constrains the complexity of these models. We show how the appropriate use of writer-independent models is important for the adaptation process. Our approach to writer-adaptation makes use of writer-independent writing style models (called lexemes), to identify the styles present in a particular writer's training data. These models are then updated using the writer's data. Lexemes that are present in the writer's data, but for which an inadequate number of training examples is available, are replaced with the writer-independent models. We demonstrate the feasibility of this approach on both isolated handwritten character recognition and unconstrained word recognition tasks. Our results show an average reduction in error rate of 16.3 percent for lowercase characters as compared against representing each of the writer's character classes with a single model. In addition, an average error rate reduction of 9.2 percent is shown on handwritten words using only a small amount of data for adaptation.	Agilent Technol, Palo Alto, CA 95070 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Agilent Technologies; Michigan State University	Connell, SD (corresponding author), Agilent Technol, 3500 Deer Creek Rd,MS 25U-7A, Palo Alto, CA 95070 USA.	scott_connell@agilent.com; jain@cse.mus.edu						BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BEIGI HSM, 1994, IEEE IMAGE PROC, P169, DOI 10.1109/ICIP.1994.413297; BELLEGARDA EJ, 1993, P IWFHR 3 BUFF NEW Y, P225; Bercu S., 1993, P 3 INT WORKSH FRONT, P385; Chan KF, 1998, INT C PATT RECOG, P1508, DOI 10.1109/ICPR.1998.711993; Connell S., 2000, THESIS MICHIGAN STAT; Connell SD, 2001, PATTERN RECOGN, V34, P1, DOI 10.1016/S0031-3203(99)00197-1; Connell SD, 1998, INT C PATT RECOG, P182, DOI 10.1109/ICPR.1998.711110; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; GUYON I, 1991, PATTERN RECOGN, V24, P105, DOI 10.1016/0031-3203(91)90081-F; HU J, 1997, P IT IM PROC C FLOR, P647; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; LEGGETTER CJ, 1994, P INT C SPOK LANG PR, P451; Madhvanath S., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P911, DOI 10.1109/ICDAR.1995.602049; Manke S., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P403, DOI 10.1109/ICDAR.1995.599023; MANKE S, 1994, INT CONF ACOUST SPEE, P633; MOHIUDDIN KM, 1994, MACH INTELL PATT REC, V16, P437; NATHAN KS, 1993, P IEEE INT C AC SPEE, V5, P121; NATHAN KS, 1995, P ICASSP 1995 IEEE I, V4, P2619; PERRONE MP, 2000, P 7 INT WORKSH FONT; PLAMONDON R, 1989, IEEE T SYST MAN CYB, V19, P1060, DOI 10.1109/21.44021; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Prevost L, 1998, INT C PATT RECOG, P381, DOI 10.1109/ICPR.1998.711160; Rigoll G, 1998, INT C PATT RECOG, P1512, DOI 10.1109/ICPR.1998.711994; SCATTOLIN P, 1994, P VIS INT, P178; SCHENKEL M, 1994, INT CONF ACOUST SPEE, P637; SCHOMAKER LRB, 1993, P ICOHD 93 PAR, P19; Seni G, 1996, IEEE T PATTERN ANAL, V18, P757, DOI 10.1109/34.506798; SENIOR AW, 1996, P INT C ACOUSTICS SP, P3483; SUBRAHMONIA J, 1996, P ICASSP 96 ATL GEOR, V6, P3478; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; TAPPERT CC, 1984, P INT C PATT REC MON, P1004; Wakahara T, 1998, IEEE T PATTERN ANAL, V20, P1332, DOI 10.1109/34.735806; Yamasaki K, 1998, INT C PATT RECOG, P1150, DOI 10.1109/ICPR.1998.711899	35	47	49	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2002	24	3					329	346		10.1109/34.990135	http://dx.doi.org/10.1109/34.990135			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	524WM					2022-12-18	WOS:000174035900004
J	Marroquin, JL; Velasco, FA; Rivera, M; Nakamura, M				Marroquin, JL; Velasco, FA; Rivera, M; Nakamura, M			Gauss-Markov measure field models for low-level vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes methods; estimation theory; Gaussian distributions; image classification; image segmentation; Markov processes; probability; simulated annealing	IMAGES; RESTORATION	We present a class of models, derived from classical discrete Markov random fields, that may be used for the solution of ill-posed problems in image processing and in computational vision. They lead to reconstrucion algorithms that are flexible, computationally efficient, and biologically plausible. To illustrate their use, we present their application to the reconstruction of the dominant orientation and direction fields, to the classification of multiband images, and to image quantization and filtering.	Ctr Invest Matemat, Guanajuato 36000, Mexico; Univ Michoncana SNS, Morelia 58000, Michoacan, Mexico	CIMAT - Centro de Investigacion en Matematicas	Marroquin, JL (corresponding author), Ctr Invest Matemat, Apdo Postal 402, Guanajuato 36000, Mexico.			Rivera, Mariano/0000-0002-3211-2467				BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BHATTACHARJYA AK, 1994, IEEE T NEURAL NETWOR, V5, P83, DOI 10.1109/72.265963; Botello S, 1998, APPL OPTICS, V37, P7587, DOI 10.1364/AO.37.007587; Briggs W., 1987, MULTIGRID TUTORIAL; Chellapa R., 1993, MARKOV RANDOM FIELDS; Ersoy O., 1997, FOURIER RELATED TRAN; Fisher N.I., 1995, STAT ANAL CIRCULAR D; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GHIGLIA DC, 1994, J OPT SOC AM A, V11, P107, DOI 10.1364/JOSAA.11.000107; GOLLUB GH, 1990, MATRIX COMPUTATIONS; Granlund G.H., 1995, SIGNAL PROCESSING CO; HEITZ F, 1994, CVGIP-IMAG UNDERSTAN, V59, P125, DOI 10.1006/ciun.1994.1008; HIRIYANNAIAH HP, 1989, J OPT SOC AM A, V6, P1901, DOI 10.1364/JOSAA.6.001901; Horn B., 1986, ROBOT VISION, P1; KANDEL D, 1989, PHYS REV B, V40, P330, DOI 10.1103/PhysRevB.40.330; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; KASS M, 1987, P 1 INT C COMP VIS; KATSAGGELOS AK, 1991, IMAGE RESTORATION; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MARROQUIN JL, 1995, J OPT SOC AM A, V12, P2393, DOI 10.1364/JOSAA.12.002393; Marroquin JL, 1998, P SOC PHOTO-OPT INS, V3459, P238, DOI 10.1117/12.323803; MARROQUIN JL, 1998, J OPTICAL SOC AM, V15; MILLER MI, 1991, IEEE T NEURAL NETWOR, V2, P56, DOI 10.1109/72.80291; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Rao C. R, 1973, LINEAR STAT INFERENC; ROBB RA, 1989, IEEE T MED IMAGING, V8, P217, DOI 10.1109/42.34710; ROSYAM B, 1992, DIGIT SIGNAL PROCESS, V2, P48; Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299; ZHANG J, 1992, IEEE T SIGNAL PROCES, V40, P2570, DOI 10.1109/78.157297	31	47	50	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2001	23	4					337	348		10.1109/34.917570	http://dx.doi.org/10.1109/34.917570			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	421MJ					2022-12-18	WOS:000168067900001
J	Fischl, B; Schwartz, EL				Fischl, B; Schwartz, EL			Adaptive nonlocal filtering: A fast alternative to anisotropic diffusion for image enhancement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; diffusion; scale-space; anisotropic diffusion; nonlinear diffusion; filtering; permutation filter; nonlocal filter	EDGE-DETECTION; NEURAL DYNAMICS; PERCEPTION; FEATURES; SHAPE	Nonlinear anisotropic diffusion algorithms provide significant improvement in image enhancement as compared to linear filters. However, the excessive computational cost of solving nonlinear PDEs precludes their use in real-time vision applications. In the present paper, we show that two orders of magnitude speed improvement is provided by a new image filtering paradigm in which an adaptively determined vector field specifies nonlocal application points for an image filter.	Boston Univ, Dept Cognit & Neural Syst, Boston, MA 02215 USA; Massachusetts Gen Hosp, NMR Ctr, Charlestown, MA 02129 USA	Boston University; Harvard University; Massachusetts General Hospital	Fischl, B (corresponding author), Boston Univ, Dept Cognit & Neural Syst, 677 Beacon St, Boston, MA 02215 USA.	eric@thing4.bu.edu; fischl@cns.bu.edu						BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BLUM H, 1967, PERSPECT BIOL MED, V10, P381; BURBECK CA, 1995, VISION RES, V35, P1917, DOI 10.1016/0042-6989(94)00286-U; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012; COHEN MA, 1984, PERCEPT PSYCHOPHYS, V36, P428, DOI 10.3758/BF03207497; DANIELSSON PE, 1981, COMPUT VISION GRAPH, V17, P71, DOI 10.1016/S0146-664X(81)80010-X; ELFALLAH AI, 1994, P SOC PHOTO-OPT INS, V2182, P49, DOI 10.1117/12.171091; Fischl B, 1997, IEEE T PATTERN ANAL, V19, P342, DOI 10.1109/34.588012; FISCHL B, 1996, INT C PATT REC VIENN; FROME FS, 1972, TR198 U MAR COMP SCI; GROSSBERG S, 1985, PSYCHOL REV, V92, P173, DOI 10.1037/0033-295X.92.2.173; HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188; HUMMEL A, 1986, READINGS COMPUTER VI; KOVACS I, 1994, NATURE, V370, P644, DOI 10.1038/370644a0; LAMME VAF, 1995, J NEUROSCI, V15, P1605; LEE TS, 1996, NATURE; LEE TS, 1995, COMPUTATIONAL NEUROS; MALLADI R, 1995, P NATL ACAD SCI USA, V92, P7046, DOI 10.1073/pnas.92.15.7046; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NITZBERG M, 1992, IEEE T PATTERN ANAL, V14, P826, DOI 10.1109/34.149593; Nitzberg M., 1993, FILTERING SEGMENTATI; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Perona P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P16; ROJER AS, 1990, 10TH INT C PATT REC, V2, P278; Romeny B.M., 1994, GEOMETRY DRIVEN DIFF; Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P260; WEICKERT J, IN PRESS IEEE T IMAG; WEICKERT J, 1997, P 1997 IEEE INT C IM; WHITAKER RT, 1991, COMPUTER VISION GRAP, V57, P99; Witkin A.P., 1983, INT JOINT C ART INT, P1019	35	47	60	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					42	48		10.1109/34.745732	http://dx.doi.org/10.1109/34.745732			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ					2022-12-18	WOS:000078388900005
J	Chen, WG; Nandhakumar, N; Martin, WN				Chen, WG; Nandhakumar, N; Martin, WN			Image motion estimation from motion smear - A new computational model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion estimation; motion smear (blur); motion-from-smear		Motion smear is an important visual cue for motion perception by the human vision system (HVS). However, in image analysis research, exploiting motion smear has been largely ignored. Rather, motion smear is usually considered as a degradation of images that needs to be removed. In this paper, we establish a computational model that estimates image motion from motion smear information-''motion from smear.'' In many real situations, the shutter of the sensing camera must be kept open long enough to produce images of adequate signal-to-noise ratio (SNR), resulting in significant motion smear in images. We present a new motion blur model and an algorithm that enables unique estimation of image motion. A prototype sensor system that exploits the new motion blur model has been built to acquire data for ''motion-from-smear.'' Experimental results on images with both simulated smear and real smear, using our ''motion-from-smear'' algorithm as well as a conventional motion estimation technique, are provided. We also show that temporal aliasing does not affect ''motion-from-smear'' to the same degree as it does algorithms that use displacement as a cue. ''Motion-from-smear'' provides an additional tool for motion estimation and effectively complements the existing techniques when apparent motion smear is present.	UNIV VIRGINIA,DEPT ELECT ENGN,CHARLOTTESVILLE,VA 22903; UNIV VIRGINIA,DEPT COMP SCI,CHARLOTTESVILLE,VA 22903	University of Virginia; University of Virginia	Chen, WG (corresponding author), MICROSOFT CORP,1 MICROSOFT WAY,REDMOND,WA 98052, USA.							AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; AHO AC, 1993, J COMP PHYSIOL A, V172, P671; Andrews H.C., 1977, DIGITAL IMAGE RESTOR; BALLARD DH, 1986, BEHAV BRAIN SCI, V9, P67, DOI 10.1017/S0140525X00021555; BARLOW HB, 1958, J PHYSIOL-LONDON, V141, P337, DOI 10.1113/jphysiol.1958.sp005978; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BURR D, 1980, NATURE, V284, P164, DOI 10.1038/284164a0; Gonzalez R. C., 1987, DIGITAL IMAGE PROCES; Graham CH, 1935, AM J PHYSIOL, V113, P299, DOI 10.1152/ajplegacy.1935.113.2.299; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KARAYIANNIS NB, 1990, IEEE T ACOUST SPEECH, V38, P1155, DOI 10.1109/29.57544; KATSAGGELOS AK, 1991, DIGITAL IMAGE RESTOR, P143; KUO BC, 1980, DIGITAL CONTROL SYST; LARSEN L O, 1982, Amphibia-Reptilia, V2, P321; Ljung L., 1987, SYSTEM IDENTIFICATIO; MARTIN KE, 1993, ADV NEURAL INFORMATI; Pavlovic G, 1992, IEEE T IMAGE PROCESS, V1, P496, DOI 10.1109/83.199919; 1994, 1994 NEWPORT CATALOG; 1991, DIGITAL IMAGE RESTOR	19	47	51	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					412	425		10.1109/34.491622	http://dx.doi.org/10.1109/34.491622			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500006
J	Lakshmanan, S; Grimmer, D				Lakshmanan, S; Grimmer, D			A deformable template approach to detecting straight edges in radar images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						road boundary detection; millimeter-wave images; global shape models; log-normal densities; Metropolis algorithm		This paper addresses the problem of locating two straight and parallel road edges in images that are acquired from a stationary millimeter-wave radar platform positioned near ground-level. A fast, robust, and completely data-driven Bayesian solution to this problem is developed, and it has applications in automotive vision enhancement. The method employed in this paper makes use of a deformable template model of the expected road edges, a two-parameter lognormal model of the ground-level millimeter-wave (GLEM) radar imaging process, a maximum a posteriori (MAP) formulation of the straight edge detection problem, and a Monte Carlo algorithm to maximize the posterior density. Experimental results are presented by applying the method on GLEM radar images of actual roads. The performance of the method is assessed against ground truth for a variety of road scenes.	TRW CO INC,AUTOMOT ELECT GRP,FARMINGTON HILLS,MI 48335		Lakshmanan, S (corresponding author), UNIV MICHIGAN,DEPT ELECT & COMP ENGN,DEARBORN,MI 48128, USA.			Lakshmanan, Sridhar/0000-0001-7387-3943				Aitchison J, 1957, LOGNORMAL DISTRIBUTI; AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581; Chellappa R, 1993, MARKOV RANDOM FIELDS; CHOW YS, 1991, HANDS PATTERN THEORE; FARINA A, 1986, IEE PROC-F, V133, P39, DOI 10.1049/ip-f-1.1986.0009; KASTURI R, 1991, COMPUTER VISION PRIN; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; LAKSHMANAN S, 1995, P IEEE INT C AC SPEE; LEE JS, 1981, COMPUT VISION GRAPH, V17, P24, DOI 10.1016/S0146-664X(81)80005-6; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; SCHEER J, 1992, COHERENT RADAR PERFO; Skolnik M., 1980, INTRO RADAR SYSTEMS; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807	14	47	48	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					438	443		10.1109/34.491625	http://dx.doi.org/10.1109/34.491625			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500009
J	HUANG, Y; PALANIAPPAN, K; ZHUANG, XH; CAVANAUGH, JE				HUANG, Y; PALANIAPPAN, K; ZHUANG, XH; CAVANAUGH, JE			OPTIC FLOW-FIELD SEGMENTATION AND MOTION ESTIMATION USING A ROBUST GENETIC PARTITIONING ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MOTION ESTIMATION; OPTIC FLOW FIELD SEGMENTATION; LINEAR REGRESSION; ROBUST ESTIMATION; GENETIC ALGORITHM	RECOVERING 3-D MOTION; 3-DIMENSIONAL MOTION; SMOOTHNESS CONSTRAINTS; INHERENT AMBIGUITIES; COMPUTER VISION; OBJECTS; IMAGES; RECONSTRUCTION; SEQUENCES; SCENE	Optic flow motion analysis represents an important family of visual information processing techniques In computer vision, Segmenting an optic now field into coherent motion groups and estimating each underlying motion is a very challenging task when the optic flow field is projected from a scene of several independently moving objects, The problem is further complicated if the optic flow data are noisy and partially incorrect, In this paper, we present a novel framework for determining such optic flow fields by combining the conventional robust estimation with a modified, genetic algorithm. The baseline model used in the development is a linear optic flow motion algorithm [38] due to its computational simplicity, The statistical properties of the generalized linear regression (GLR) model are thoroughly explored and the sensitivity of the motion estimates toward data noise is quantitatively established. Conventional robust estimators are then incorporated into the linear regression model to suppress a small percentage of gross data errors or outliers. However, segmenting an optic flow field consisting of a large portion of incorrect data or multiple motion groups requires a very high robustness that is unattainable by the conventional robust estimators, To solve this problem, we propose a genetic partitioning algorithm that elegantly combines the robust estimation with the genetic algorithm by a bridging genetic operator called self-adaptation.	NASA, GODDARD SPACE FLIGHT CTR, ATMOSPHERES LAB, UNIV SPACE RES ASSOC, GREENBELT, MD 20771 USA; UNIV MISSOURI, DEPT ELECT & COMP ENGN, COLUMBIA, MO 65211 USA; UNIV MISSOURI, DEPT STAT, COLUMBIA, MO 65211 USA	National Aeronautics & Space Administration (NASA); NASA Goddard Space Flight Center; Universities Space Research Association (USRA); University of Missouri System; University of Missouri Columbia; University of Missouri System; University of Missouri Columbia	HUANG, Y (corresponding author), AT&T BELL LABS, MIDDLETOWN, NJ 07748 USA.		Palaniappan, Kannappan/A-3231-2008					ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; CHEN HH, 1990, IEEE T PATTERN ANAL, V12, P1002, DOI 10.1109/34.58872; DARRELL T, 1991, OCT IEEE WORKSH VIS, P173; Driessen J. N., 1991, Journal of Visual Communication and Image Representation, V2, P259, DOI 10.1016/1047-3203(91)90027-D; Fuller W. A., 2009, MEASUREMENT ERROR MO; Goldberg DE, 1989, GENETIC ALGORITHMS S; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; HOLLAND JH, 1975, P IEEE ANN ARBOR; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUANG TS, 1985, IEEE C COMPUTER VISI, P518; HUANG Y, 1995, IEEE T CIRCUIT SYSTE, V5; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; LIU Y, 1993, IEEE T PATTERN ANAL, V15, P802, DOI 10.1109/34.236249; LIU Y, 1990, SEQUENCE STEREO IMAG; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; Myers R. H, 1990, CLASSICAL MODERN REG, V2nd; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SNYDER MA, 1991, IEEE T PATTERN ANAL, V13, P1105, DOI 10.1109/34.103272; THOMPSON WB, 1980, IEEE T PATTERN ANAL, V2, P543, DOI 10.1109/TPAMI.1980.6447701; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; TZIRITAS G, 1989, SIGNAL PROCESS, V16, P53, DOI 10.1016/0165-1684(89)90113-8; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VERRI A, 1987, 1ST P INT C COMP VIS, P171; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; WENG J, 1989, 2ND P INT C COMP VIS, P64; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; YEN BL, 1983, COMPUT VISION GRAPH, V21, P21, DOI 10.1016/S0734-189X(83)80027-9; YOUNG GSJ, 1992, IEEE T PATTERN ANAL, V14, P995, DOI 10.1109/34.159903; ZHANG ZY, 1992, IEEE T PATTERN ANAL, V14, P1141, DOI 10.1109/34.177380; ZHUANG X, 1990, OCT P INT WORKSH ROB; ZHUANG XH, 1992, IEEE T PATTERN ANAL, V14, P19, DOI 10.1109/34.107011; ZHUANG XH, 1986, J OPT SOC AM A, V3, P1492, DOI 10.1364/JOSAA.3.001492; ZHUANG XH, 1988, COMPUT VISION GRAPH, V42, P334, DOI 10.1016/S0734-189X(88)80043-4; ZHUANG XH, 1994, IEEE T PATTERN ANAL, V16, P818, DOI 10.1109/34.308478	41	47	49	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1177	1190		10.1109/34.476510	http://dx.doi.org/10.1109/34.476510			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500005
J	NEY, H; ESSEN, U; KNESER, R				NEY, H; ESSEN, U; KNESER, R			ON THE ESTIMATION OF SMALL PROBABILITIES BY LEAVING-ONE-OUT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						STOCHASTIC LANGUAGE MODELING; LEAVING-ONE-OUT; ZERO-FREQUENCY PROBLEM; MAXIMUM LIKELIHOOD ESTIMATION; GENERALIZATION CAPABILITY	SPEECH RECOGNITION; LANGUAGE MODEL	In this paper, we apply the leaving-one-out concept to the estimation of 'small' probabilities, i.e., the case where the number of training samples is much smaller than the number of possible classes. After deriving the Turing-Good formula in this framework, we introduce several specific models in order to avoid the problems of the original Turing-Good formula These models are the constrained model, the absolute discounting model and the linear discounting model. These models are then applied to the problem of bigram-based stochastic language modeling. Experimental results are presented for a German and an English corpus.	PHILIPS GMBH,FORSCHUNGSLAB AACHEN,D-52066 AACHEN,GERMANY	Philips; Philips Research	NEY, H (corresponding author), UNIV AACHEN,RHEIN WESTFAL TH AACHEN,LEHRSTUHL INFORMAT 6,D-52056 AACHEN,GERMANY.							BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; Church K. W., 1991, Computer Speech and Language, V5, P19, DOI 10.1016/0885-2308(91)90016-J; Duda R.O., 1973, J ROYAL STAT SOC SER; Efron Bradley, 1982, JACKKNIFE BOOTSTRAP; JELINEK F, 1985, IMPACT PROCESSING TE; JOHANSSON S, 1985, COMPUT HUMANITIES, V19, P23, DOI 10.1007/BF02259615; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; KUGLER M, 1987, ESPRIT 291860 U BOCH; KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193; Lehmann E., 1983, THEORY POINT ESTIMAT; NADAS A, 1984, IEEE T ACOUST SPEECH, V32, P859, DOI 10.1109/TASSP.1984.1164378; NADAS A, 1985, IEEE T ACOUST SPEECH, V33, P1414, DOI 10.1109/TASSP.1985.1164728; STEINBISS V, 1990, APR P IEEE INT C AC, P57	16	47	47	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1202	1212		10.1109/34.476512	http://dx.doi.org/10.1109/34.476512			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500007
J	KUHN, R; DEMORI, R				KUHN, R; DEMORI, R			THE APPLICATION OF SEMANTIC CLASSIFICATION TREES TO NATURAL-LANGUAGE UNDERSTANDING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SPEECH UNDERSTANDING SEMANTIC CLASSIFICATION TREE; SCT; MACHINE LEARNING; NATURAL LANGUAGE; DECISION TREE		This article describes a new method for building a natural language understanding (NLU) system, in which the system's rules are learnt automatically from training data, The method has been applied to design of a speech understanding (SU) system, Designers of such systems rely increasingly on robust matchers to perform the task of extracting meaning from one or several word sequence hypotheses generated by a speech recognizer; a robust matcher processes semantically important Islands of words and constituents rather than attempting to parse the entire word sequence, We describe a new data structure, the Semantic Classification Tree (SCT), that learns semantic rules from training data and can be a building block;for robust matchers for NLU tasks, By reducing the need for handcoding and debugging a large number of rules, this approach facilitates rapid construction of an NLU system, In the case of an SU system, the rules learned by an SCT are highly resistant to errors by the speaker or by the speech recognizer because they depend on a small number of words in each utterance, Our work shows that semantic rules can be learned automatically from training data, yielding successful NLU for a realistic application.	MCGILL UNIV,SCH COMP SCI,MONTREAL,PQ H3A 2A7,CANADA; CTR RECH INFORMAT MONTREAL,MONTREAL,PQ H3A 2N4,CANADA	McGill University								Bahl Lalit R., 1990, READINGS SPEECH RECO, P507; BLACK E, 1993, 31ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P31; BLACK E, 1992, 1992 P DARPA SPEECH, P117; BLACK E, 1993, STATISTICALLY DRIVEN; CHOU PA, 1991, IEEE T PATTERN ANAL, V13, P340, DOI 10.1109/34.88569; CRAWFORD S, 1991, 8TH P INT WORKSH MAC; FU KS, 1986, IEEE T PATTERN ANAL, V8, P398, DOI 10.1109/TPAMI.1986.4767800; FU KS, 1986, IEEE T PATTERN ANAL, V8, P343, DOI 10.1109/TPAMI.1986.4767796; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; HIRSCHMAN L, 1992, 1992 P INT C SPOK LA, V2, P903; JACKSON E, 1991, 1991 P DARPA SPEECH, P190; Jelinek F., 1990, READINGS SPEECH RECO, P450, DOI [DOI 10.1016/B978-0-08-051584-7.50045-0, 10.1016/B978-0-08-051584-7.50045-0]; KUHN R, 1993, THESIS MCGILL U; KUHN R, 1993, APR P ICASSP 93, V2, P55; LING C, 1993, AUG IJCAI 93, V2, P1143; MILLER S, 1994, SPOKEN LANUGAGE SYST; MILLIEN E, 1993, EUROSPEECH 93, V2, P1331; Olshen R., 1984, CLASSIFICATION REGRE; PIERACCINI P, IN PRESS NEW ADV TRE; PIERACCINI R, 1991, 1991 P DARPA SPEECH, P121; PIERACCINI R, 1992, MAR P ICASSP 92; PRICE P, 1990, 1990  DARPA SPEECH N; RABINER LR, 1990, READINGS SPEECH RECO, P267; SENEFF S, 1992, 1992 P DARPA SPEECH, P299; Waibel Alexander, 1990, READINGS SPEECH RECO; WARD W, 1992, 1992 P DARPA SPEECH, P78; WARD W, 1993, P ICASSP 93 MINN, V2, P49; WARD W, 1991, 1991 P DARPA SPEECH, V101, P19; 1992, 1992 P DARPA SPEECH; 1991, 1991 P DARPA SPEECH; 1990, 1990 P DARPA SPEECH	31	47	67	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1995	17	5					449	460		10.1109/34.391397	http://dx.doi.org/10.1109/34.391397			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QW394					2022-12-18	WOS:A1995QW39400001
J	SHASHUA, A				SHASHUA, A			PROJECTIVE STRUCTURE FROM UNCALIBRATED IMAGES - STRUCTURE-FROM-MOTION AND RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						VISUAL RECOGNITION; 3-D RECONSTRUCTION FROM 2-D VIEWS; PROJECTIVE GEOMETRY; ALGEBRAIC AND GEOMETRIC INVARIANTS	3-D MOTION; OBJECTS; CALIBRATION; INVARIANTS	We address the problem of reconstructing 3-D space in a projective framework from two or more views, and the problem of artificially generating novel views of the scene from two given views (reprojection). We describe an invariance relation that provides a new description of structure, which we call projective depth, that is captured by a single equation relating image point correspondences across two or more views and the homographies of two arbitrary virtual planes. The framework is based on knowledge of correspondence of features across views, is linear and extremely simple, and the computations of structure readily extend to overdetermination using multiple views. Experimental results demonstrate a high degree of accuracy in both tasks: reconstruction and reprojection.	MIT,CTR BIOL COMP LEARNING,CAMBRIDGE,MA 02139; MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)								ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ALOIMONOS J, 1989, BIOL CYBERN, V60, P445, DOI 10.1007/BF00204700; Anandan P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P219; BARRETT EB, 1991, CVGIP-IMAG UNDERSTAN, V53, P46, DOI 10.1016/1049-9660(91)90004-9; BERGEN JR, 1990, HIERARCHICAL MOTION; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855; DEMEY S, 1992, OCT P BRIT MACH VIS; Dutta R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P106, DOI 10.1109/ICCV.1990.139504; FAIG W, 1975, PHOTOGRAMM ENG REM S, V41, P1479; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; GRIMSON WEL, 1993, AI1435 MIT ART INT L; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; HARTLEY RI, 1993, 2ND EUR WORKSH INV; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; LEE CH, 1988, P INT C COMP VIS TAM, P158; Lenz RK, 1987, IEEE T ROBOTIC AUTOM, P68; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lucas B D, 1981, P 7 INT JOINT C ARTI, P674; LUONG QT, 1993, DETERMINING FUNDAMEN; LUONG QT, 1993, CANONICAL REPRESENTA; MOHR R, 1992, RT84IMAG LIFIAIRIMAG; MUNDY J, 1992, P DARPA IM UND WORKS, P727; ROACH JW, 1979, IEEE T PATTERN ANAL, V1, P127, DOI 10.1109/TPAMI.1979.4766898; ROBERT L, 1993, P INT C COMP VIS BER, P540; SHASHUA A, 1992, MIT AITR1401 ART INT; SHASHUA A, 1994, MAY P EUR C COMP VIS; SHASHUA A, 1993, MIT AI1405 MEM; SHASHUA A, 1993, P INT C COMP VIS BER, P583; SHASHUA A, 1994, P IEEE C COMPUT VISI; SHASHUA A, 1992, AI1363 MIT ART INT L; SHASHUA A, 1993, 2ND P EUR WORKSH INV; SHASHUA A, 1991, AI1327 MIT ART INT L; TOMASI C, 1991, THESIS CARNEGIEMELLO; TOMASI C, 1991, IEEE WORKSH VIS MOT, P21; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; ULLMAN S, 1989, COGNITION, V32, P193, DOI 10.1016/0010-0277(89)90036-X; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ULLMAN S, 1989, MIT AI1052 MEM; ULLMAN S, 1986, MIT AI931 MEM; VERRI A, 1986, J OPT SOC AM A, V3, P297, DOI 10.1364/JOSAA.3.000297; WEINSHALL D, 1993, INT J COMPUT VISION, V10, P27, DOI 10.1007/BF01440845	46	47	66	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					778	790		10.1109/34.308472	http://dx.doi.org/10.1109/34.308472			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500002
J	JOSEPH, E; PAVLIDIS, T				JOSEPH, E; PAVLIDIS, T			BAR CODE WAVE-FORM RECOGNITION USING PEAK LOCATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BAR CODE RECOGNITION; WAVE-FORM RECOGNITION; PEAK DETECTION; PARAMETER ESTIMATION; DISTANCE CLASSIFICATION	HUMAN-VISION; EDGE; BLUR	Traditionally, zero crossings of the second derivative provide edge features for the classification of blurred waveforms. The accuracy of these edge features deteriorates in the case of severely blurred images. In this paper, a new feature is presented that is more resistant to the blurring process, the image, and waveform peaks. In addition, an estimate of the standard deviation sigma of the blurring kernel is used to perform minor deblurring of the waveform. Statistical pattern recognition is used to classify the peaks as bar code characters. The noise tolerance of this recognition algorithm is increased by using an adaptive, histogram-based technique to remove the noise. In a bar code environment that requires a misclassification rate of less than one in a million, the recognition algorithm showed a 43% performance improvement over current commercial bar code reading equipment.	SUNY STONY BROOK, DEPT COMP SCI, STONY BROOK, NY 11794 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	JOSEPH, E (corresponding author), SYMBOL TECHNOL INC, DEPT R&D, 116 WILBUR PL, BOHEMIA, NY 11716 USA.							BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BIEMOND J, 1990, P IEEE, V78, P856, DOI 10.1109/5.53403; BURR DC, 1989, VISION RES, V29, P419, DOI 10.1016/0042-6989(89)90006-0; CHEN JS, 1989, IEEE T PATTERN ANAL, V11, P191, DOI 10.1109/34.16714; CHENG Y, 1976, IEEE T PATTERN ANAL, V25, P725; CONCETTA M, P ROY SOC LOND B BIO, V235, P221; DEFIGUEIREDO R, 1990, IEEE T ACOUST SPEECH, V38, P328; HOROWITZ SL, 1975, COMMUN ACM, V18, P281, DOI 10.1145/360762.360810; HUMMEL RA, 1987, COMPUT VISION GRAPH, V38, P66, DOI 10.1016/S0734-189X(87)80153-6; JOSEPH E, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1-3, P129; JOSEPH E, 1992, THESIS STATE U NEW Y; MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4; Papoulis A., 2002, PROBABILITY RANDOM V; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PAVLIDIS T, 1990, IEEE COMPUTER    APR, P74; Rosenfeld A., 1982, DIGITAL PICTURE PROC; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; WANG TP, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1-3, P135; WATT RJ, 1983, VISION RES, V23, P1465, DOI 10.1016/0042-6989(83)90158-X; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]; ZALMAN G, 1991, J OPT SOC AM A, V8, P814, DOI 10.1364/JOSAA.8.000814	21	47	71	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					630	640		10.1109/34.295907	http://dx.doi.org/10.1109/34.295907			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200007
J	UMEYAMA, S				UMEYAMA, S			PARAMETERIZED POINT PATTERN-MATCHING AND ITS APPLICATION TO RECOGNITION OF OBJECT FAMILIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; PARAMETERIZED MODEL; POINT PATTERN MATCHING; SEARCH PROCEDURES; SHAPE MATCHING	LOCALIZATION; MODELS	This paper considers the problem of recognizing and localizing objects that can vary in parameterized ways. To achieve this goal, a concept of parameterized point pattern is introduced to model parameterized families of such objects, and a parameterized point pattern matching algorithm is proposed. A parameterized point pattern is a very flexible concept that can be used to model a large class of parameterized objects, such as a pair of scissors with rotating blades. The proposed matching algorithm is formulated as a tree search procedure, and it generates all maximum matchings satisfying a condition called delta-boundedness. Several pruning methods based on the condition of delta-boundedness and their efficient computing techniques are given. ne proposed matching algorithm is applied to a real shape matching problem in order to check the validity of the approach.			UMEYAMA, S (corresponding author), MINIST INT TRADE & IND,DIV INFORMAT SCI,ELECTROTECH LAB,IBARAKI,JAPAN.							ALT H, 1987, 3RD P ANN S COMP GEO, P308; BAIRD HS, 1985, MODEL BASED IMAGE MA; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; GASTON PC, 1984, IEEE T PATTERN ANAL, V6, P257, DOI 10.1109/TPAMI.1984.4767518; GOSHTASBY A, 1985, IEEE T SYST MAN CYB, V15, P631, DOI 10.1109/TSMC.1985.6313439; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GRIMSON WEL, 1987, 1ST P INT C COMP VIS, P93; KAHL DJ, 1980, IEEE T SYST MAN CYB, V10, P105; KITCHEN L, 1980, IEEE T SYST MAN CYB, V10, P96; OGAWA H, 1984, PATTERN RECOGN, V17, P569, DOI 10.1016/0031-3203(84)90055-4; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; WONG AKC, 1986, 8TH P INT C PATT REC, V1, P546	14	47	50	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					136	144		10.1109/34.192485	http://dx.doi.org/10.1109/34.192485			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KL910					2022-12-18	WOS:A1993KL91000004
J	HAMPSHIRE, JB; WAIBEL, A				HAMPSHIRE, JB; WAIBEL, A			THE META-PI NETWORK - BUILDING DISTRIBUTED KNOWLEDGE REPRESENTATIONS FOR ROBUST MULTISOURCE PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BAYESIAN DISCRIMINANT FUNCTION; CLASS-CONDITIONAL DENSITY; CONNECTIONISM; META-PI NETWORK; MIXTURE DENSITY; MULTISOURCE; PHONEME RECOGNITION; SPEECH RECOGNITION; TIME-DELAY NEURAL NETWORK (TDNN)	NEURAL NETWORKS; MARKOV-MODELS	We present a multinetwork connectionist classifier that forms distributed low-level knowledge representations for robust pattern recognition, given random feature vectors generated by multiple statistically distinct sources. The architecture comprises a number of source-dependent modules (i.e., each module is trained to classify patterns from one particular source) that are linked by a combinational superstructure. The superstructure adapts to the source being processed, integrating source-dependent classifications based on its internal assessment of the source model or combination of source models most likely to classify the input signal correctly. To train this combinational network, we have developed a new form of multiplicative connection, which we call the "Meta-Pi" connection; its function is closely aligned with predecessors described in [3], [29], and [31]. We illustrate how the Meta-Pi paradigm implements an adaptive Bayesian maximum a posteriori (MAP) classifier. We demonstrate its performance in the context of multispeaker phoneme recognition. In this task, the Meta-Pi superstructure combines speaker-dependent time-delay neural network (TDNN) modules to perform multispeaker /b, d, g/ phoneme recognition with speaker-dependent error rates (2 %). Finally, we apply the Meta-Pi architecture to a limited source-independent recognition task, illustrating its discrimination of a novel source. We demonstrate that it can adapt to the novel source (speaker), given five adaptation examples of each of the three phonemes; the resulting error rate of 7 % is approximately three times that of a typical source-dependent classifier. Longer term adaptation yields discrimination that is comparable with a speaker-dependent classifier of the novel source. We conclude with an assessment of our experimental results and their implications for larger real-world multisource and source-independent pattern recognition systems.	CARNEGIE MELLON UNIV,SCH COMP SCI,PITTSBURGH,PA 15213	Carnegie Mellon University	HAMPSHIRE, JB (corresponding author), CARNEGIE MELLON UNIV,DEPT ELECT & COMP ENGN,PITTSBURGH,PA 15213, USA.							BARRON A, 1988, S INTERFACE STATE CO; BOURLARD H, 1990, IEEE T PATTERN ANAL, V12, P1167, DOI 10.1109/34.62605; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; Duda R.O., 1973, J ROYAL STAT SOC SER; GISH H, 1990, 1990 IEEE P INT C AS, V3, P1361; HAMPSHIRE J, 1991, 1990 P CONN MOD SUMM, P159; Hampshire J B, 1990, IEEE Trans Neural Netw, V1, P216, DOI 10.1109/72.80233; HAMPSHIRE JB, 1989, CMUCS89166R CARN MEL; HASSELBLAD V, 1966, TECHNOMETRICS, V8, P431, DOI 10.2307/1266689; HIGHLEYMAN WH, 1962, AT&T TECH J, V41, P723, DOI 10.1002/j.1538-7305.1962.tb02426.x; Hinton G.E., 1990, MACHINE LEARNING PAR, P185; HON HW, 1990, COMMUNICATION    APR; HUANG XD, 1990, 1990 P IEEE AC SPE S, V2, P689; JACOBS R, 1988, 1988 CONN MOD SUMM S, P144; Jacobs R. A., 1991, NEURAL COMPUTATION, V3; JACOBS RA, 1990, COINS9027 U MASS DEP; KAMMERER BN, 1989, 1989 IEEE P INT JOIN, P243; LANG KJ, 1989, THESIS CARNEGIE MELL; LEE KF, 1988, CMUCS88148 CARN MELL; LEUNG HC, 1989, ADV NEURAL INFORMATI, V1, P206; LIPPMANN R, 1989, IEEE COMMUN MAG, V27; MALONEY P, 1989, 1989 P IEEE INT C NE, V1, P289; McClelland JL., 1987, PARALLEL DISTRIBUTED, DOI [10.7551/mitpress/5237.001.0001, DOI 10.7551/MITPRESS/5237.001.0001]; NOWLAN S, 1991, THESIS CARNEGIEMELLO; Nowlan S.J., 1990, ADV NEURAL INFORM PR, P574; NOWLAN SJ, 1990, CRGTR925 U TOR DEP C; O'Shaugnessy D, 1987, SPEECH COMMUNICATION; POLLACK JB, 1987, 9TH P ANN C COGN SCI, P391; POMERLEAU D, 1988, 1988 P IEEE INT C NE, P143; POMERLEAU D, 1987, CMUCS87165 CARN MELL; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; RTISCHEV D, 1989, THESIS MIT; Ruck D W, 1990, IEEE Trans Neural Netw, V1, P296, DOI 10.1109/72.80266; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SHOEMAKER PA, 1991, IEEE T NEURAL NETWOR, V2, P158, DOI 10.1109/72.80304; SPECHT D, 1988, 1988 P IEEE INT C NE, V1, P525; STERN RM, 1987, IEEE T ACOUST SPEECH, V35, P751, DOI 10.1109/TASSP.1987.1165203; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P1888, DOI 10.1109/29.45535; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Wan E A, 1990, IEEE Trans Neural Netw, V1, P303, DOI 10.1109/72.80269; WAN EA, 1991, 1990 P CONN MODE SUM, P159; WATROUS R, 1989, CRGTR895 U TOR DEP S	43	47	47	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1992	14	7					751	769		10.1109/34.142911	http://dx.doi.org/10.1109/34.142911			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JB675					2022-12-18	WOS:A1992JB67500004
J	LE, VB; LEE, DT				LE, VB; LEE, DT			OUT-OF-ROUNDNESS PROBLEM REVISITED	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FARTHEST NEIGHBOR VORONOI DIAGRAM; MAXIMUM INSCRIBED CENTER; MEDIAL AXIS; MINIMUM AREA DIFFERENCE CENTER; MINIMUM CIRCUMSCRIBED CENTER; MINIMUM RADIAL SEPARATION CENTER; NEAREST NEIGHBOR VORONOI DIAGRAM; ONE-CIRCLE APPROXIMATION CENTER	LINEAR-TIME ALGORITHMS	The out-of-roundness measurement of a circular profile undertakes different schemes depending on the type of center specified. The most common standard recommended by the American National Standards Institute (ANSI) is the minimum radial separation center. In this paper, we introduce another standard, called the minimum area difference center. Although the two centers are different in characteristics, the approach to finding both centers shares many commonalities. We present an O(n log n + k) time algorithm to compute the minimum radial separation center, and the minimum area difference center of a simple polygon G, where n is the number of vertices of G, and k is the number of intersection points of the medial axis (or the nearest neighbor Voronoi polygons of all skeleton region elements) and the farthest neighbor Voronoi diagram of G.	NORTHWESTERN UNIV,DEPT ELECT ENGN & COMP SCI,EVANSTON,IL 60208	Northwestern University	LE, VB (corresponding author), AT&T BELL LABS,2000 N NAPERVILLE RD,NAPERVILLE,IL 60566, USA.							AGGARWAL A, 1989, DISCRETE COMPUT GEOM, V4, P591, DOI 10.1007/BF02187749; Chazelle B., 1988, 29th Annual Symposium on Foundations of Computer Science (IEEE Cat. No.88CH2652-6), P590, DOI 10.1109/SFCS.1988.21975; DYER ME, 1984, SIAM J COMPUT, V13, P31, DOI 10.1137/0213003; EBARA H, UNPUB ROUNDNESS ALGO; LEE DT, 1982, IEEE T PATTERN ANAL, V4, P363, DOI 10.1109/TPAMI.1982.4767267; LEE DT, 1980, 8011FC04 NW U DEP EE; LEVY SJ, APPLIED GEOMETRIC TO; MAIRSON HG, 1987, JUL NATO C THEOR F C; MEGIDDO N, 1983, SIAM J COMPUT, V12, P759, DOI 10.1137/0212052; Shamos M.I., 1975, 16 ANN S FDN COMPUTE, P151; TOUISSANT GT, 1983, INT J COMPUT INF SCI, V12, P347; YAP CK, 1984, ONLOGN ALGORITHM VOR	12	47	51	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1991	13	3					217	223		10.1109/34.75510	http://dx.doi.org/10.1109/34.75510			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FG360					2022-12-18	WOS:A1991FG36000002
J	SHARIAT, H; PRICE, KE				SHARIAT, H; PRICE, KE			MOTION ESTIMATION WITH MORE THAN 2 FRAMES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,INST ROBOT & INTELLIGENT SYST,DEPT ELECT ENGN SYST,LOS ANGELES,CA 90089	University of Southern California								ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AGGARWAL JK, 1985, DEC P IM UND WKSHOP, P89; AGGARWAL JK, 1985, 3RD P IEEE WORKSH VI, P127; ASADA M, 1983, COMPUT VISION GRAPH, V21, P118, DOI 10.1016/S0734-189X(83)80031-0; BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; BOLLES RC, 1985, 3RD P IEEE WORKSH CO, P168; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; BROIDA TJ, 1985, JUN P IEEE C COMP VI, P82; BROIDA TJ, 1986, MAY P IEEE WORKSH MO, P95; BROIDA TJ, 1986, JUN P IEEE C COMP VI, P176; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; FANG JQ, 1984, COMPUT VISION GRAPH, V26, P183, DOI 10.1016/0734-189X(84)90182-8; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P633, DOI 10.1109/TPAMI.1981.4767164; HOFFMAN DD, 1982, BIOL CYBERN, V42, P195; LAWTON DT, 1980, 1ST P ANN NAT C ART; LEE CH, 1986, MAY P WORKSH MOT REP, P145; LIU YC, 1986, MAY P IEEE WORKSH MO, P47; MEDIONI G, 1985, DEC P IM UND WORKSH, P117; MEIRI AZ, 1980, IEEE T PATTERN ANAL, V2, P582, DOI 10.1109/TPAMI.1980.6447706; MITCHE A, 1985, JUN P IEEE C COMP VI, P504; MITICHE A, 1986, MAY P WORKSH MOT REP, P175; NAGEL HH, 1981, COMPUTER, V14, P29, DOI 10.1109/C-M.1981.220560; NAGEL HH, 1981, AUG P IEEE C PATT RE; NAGEL HH, 1981, AUG P INT JOINT C AR; OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; Shariat H., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P119; SHARIAT H, 1986, IRIS202 U SO CAL DEP; TSAI RY, 1981, IEEE T ACOUST SPEECH, V29, P1147, DOI 10.1109/TASSP.1981.1163710; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; TSAI RY, 1981, AUG P IEEE C PATT RE; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WEBB JA, 1982, ARTIF INTELL, V19, P107, DOI 10.1016/0004-3702(82)90023-6; Yasumoto Y., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P89; YEN BL, 1983, COMPUT VISION GRAPH, V21, P21, DOI 10.1016/S0734-189X(83)80027-9; ZHUANG X, 1985, JUN P IEEE C COMP VI, P686	37	47	52	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1990	12	5					417	434		10.1109/34.55102	http://dx.doi.org/10.1109/34.55102			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DA035					2022-12-18	WOS:A1990DA03500001
J	WILSON, R; SPANN, M				WILSON, R; SPANN, M			FINITE PROLATE SPHEROIDAL SEQUENCES AND THEIR APPLICATIONS .2. IMAGE FEATURE DESCRIPTION AND SEGMENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WILSON, R (corresponding author), UNIV WARWICK,DEPT COMP SCI,COVENTRY CV4 7AL,W MIDLANDS,ENGLAND.							Andrews H. C., 1972, INTRO MATH TECHNIQUE; Barlow H B, 1972, Perception, V1, P371, DOI 10.1068/p010371; BRODATZ P, 1956, TEXTURE PHOTOGRAPH A; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CAVANAGH P, 1978, PERCEPTION, V7, P167, DOI 10.1068/p070167; CHEN CH, 1982, NONLINEAR MAXIMUM EN; CHEN PE, 1981, IMAGE MODELING; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GRAHAM N, 1980, VISUAL CODING ADAPTA; GRANLUND GH, 1978, COMPUT VISION GRAPH, V8, P155, DOI 10.1016/0146-664X(78)90047-3; GRANLUND GH, 1983, FUNDAMENTALS COMPUTE; HARVEY LO, 1978, PERCEPT PSYCHOPHYS, V24, P534, DOI 10.3758/BF03198780; JACOBSON L, 1982, 6TH P INT C PATT REC, P542; JULESZ B, 1978, FORMAL THEORIES VISU; KNUTSSON H, 1982, THESIS LINKOEPING U; KNUTSSON H, 1980, P IEEE C PATTERN REC; LEVIALDI S, 1983, FUNDAMENTALS COMPUTE; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; Marr D., 1982, VISION; POLLEN DA, 1983, IEEE T SYST MAN CYB, V13, P907, DOI 10.1109/TSMC.1983.6313086; POLLEN DA, 1982, VISION RES, V22, P101, DOI 10.1016/0042-6989(82)90172-9; PRATT WK, 1978, IEEE T SYST MAN CYB, V8, P796, DOI 10.1109/TSMC.1978.4309867; SHANMUGAM KS, 1979, IEEE T PATTERN ANAL, V1, P37, DOI 10.1109/TPAMI.1979.4766874; SPANN M, 1985, PATTERN RECOGN, V18, P257, DOI 10.1016/0031-3203(85)90051-2; SPANN M, 1985, THESIS ASTON U; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; THOMSON DJ, 1982, P IEEE, V70, P1055, DOI 10.1109/PROC.1982.12433; VANGOOL L, 1985, COMPUT VISION GRAPH, V29, P336, DOI 10.1016/0734-189X(85)90130-6; WILSON R, 1985, P IEEE COMPINT MONTR; WILSON R, UNPUB UNCERTAINTY IN; WILSON R, 1984, 1ST P IM PROC S BIAR; WILSON R, 1984, P IEEE CSSP BANGALOR; WILSON R, 1984, IEEE T PATTERN ANAL, V6; WITKIN AP, 1984, P IEEE ICASSP 84 SAN	35	47	51	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					193	203		10.1109/34.3882	http://dx.doi.org/10.1109/34.3882			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M2974					2022-12-18	WOS:A1988M297400004
J	BOERNER, H; STRECKER, H				BOERNER, H; STRECKER, H			AUTOMATED X-RAY INSPECTION OF ALUMINUM CASTINGS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BOERNER, H (corresponding author), PHILIPS GMBH,FORSCHUNGSLAB HAMBURG,VOGT KOLLN STR 30,D-2000 HAMBURG 54,FED REP GER.			Boerner, Herbert/0000-0002-5128-4707				BARSCHDORF H, 1985, 65185 PHIL RES LAB I; BEAUDET PR, 1978, P 4 JOINT C PATT REC, P578; BLANZ WE, 1983, THESIS U STUTTGART S; Born M., 1975, PRINCIPLES OPTICS, VFifth; CANNY JJ, 1983, MIT AI TR720 TECH RE, P65; CLOSIER MJ, 1981, NDT INT          APR, P59; DAVIS LS, 1981, ARTIF INTELL, V17, P245, DOI 10.1016/0004-3702(81)90026-6; Decker H, 1983, PATTERN RECOGN LETT, V2, P125, DOI 10.1016/0167-8655(83)90048-X; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; FUKUNAGA K, 1972, ELECTRICAL SCI SERIE; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; HUMMEL RA, 1979, COMPUT VISION GRAPH, V9, P40, DOI 10.1016/0146-664X(79)90081-9; KLATTE R, 1985, 10TH P IMEKO PRAG; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; OLIVER DW, 1986, REV PROGR QUANTITA A, V5; REIMERS P, 1983, MATER EVAL, V41, P732; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; STRECKER H, 1983, SIGNAL PROCESS, V5, P423, DOI 10.1016/0165-1684(83)90005-1; STRECKER H, 1982, MATER EVAL, V40, P1050; STRECKER H, 1982, 6TH P INT C PATT REC, V1, P451; STRECKER H, 1985, FB43685 PHIL RES LAB; Teague M.R, 1980, J OPT SOC AM, V70; Wu R., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P92; Zenzo S., 1983, IMAGE VISION COMPUT, V1, P196; PHILIPS TECHNICAL MA; 1984, IPS IMAGE ANAL SYSTE	28	47	50	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1988	10	1					79	91		10.1109/34.3869	http://dx.doi.org/10.1109/34.3869			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	L4366					2022-12-18	WOS:A1988L436600008
J	RUTKOWSKI, L				RUTKOWSKI, L			ON BAYES RISK CONSISTENT PATTERN-RECOGNITION PROCEDURES IN A QUASI-STATIONARY ENVIRONMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											RUTKOWSKI, L (corresponding author), TECH UNIV CZESTOCHAWA,DEPT ELECT ENGN,CZESTOCHOWA,POLAND.							Alexits G., 1961, CONVERGENCE PROBLEMS; [Anonymous], [No title captured]; Bleuez J., 1979, REV ROUMAINE MATH PU, V24, P869; Cencov N. N., 1962, SOVIET MATH, V3, P1559; COVER TM, 1968 P HAW INT C SYS, P413; DEVROYE LP, 1980, Z WAHRSCHEINLICHKEIT, V51, P15, DOI 10.1007/BF00533813; GREBLICKI W, 1978, IEEE T SYST MAN CYB, V8, P809; GREBLICKI W, 1978, IEEE T INFORM THEORY, V24, P250, DOI 10.1109/TIT.1978.1055856; RUTKOWSKI L, 1980, IEEE T SYST MAN CYB, V10, P918; SCHWARTZ SC, 1967, ANN MATH STAT, V38, P1261, DOI 10.1214/aoms/1177698795; VANRYZIN J, 1966, SANKHYA            A, V28, P161; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; WOLVERTON CT, 1969, IEEE T INFORM THEORY, V15, P258, DOI 10.1109/TIT.1969.1054295	13	47	47	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					84	87		10.1109/TPAMI.1982.4767201	http://dx.doi.org/10.1109/TPAMI.1982.4767201			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21869009				2022-12-18	WOS:A1982MY53400015
J	DANKER, AJ; ROSENFELD, A				DANKER, AJ; ROSENFELD, A			BLOB DETECTION BY RELAXATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,CTR COMP SCI,COMP VISION LAB,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								CORNSWEET, 1970, VISUAL PERCEPTION; DANKER, 1980, PATTERN RECOGNITION, V12, P97; DAVIS LS, 1977, IEEE T COMPUT, V26, P1053, DOI 10.1109/TC.1977.1674746; EKLUNDH, 1978, TR701 U MAR COMP SCI; HAYES, 1979, THESIS U MARYLAND; MILGRAM, 1977, OCT P IM UND WORKSH, P104; MILGRAM, 1977, APR P IM UND WORKSH, P58; NAKAGAWA, 1978, IEEE T SYST MAN CYBE, V8, P899; PARIKH, 1978, IEEE T SYST MAN CYBE, V8, P736; PELEG, 1978, IEEE T SYST MAN CYBE, V8, P548; PELEG, 1980, IEEE T PATTERN ANAL, V2, P362; PELEG, 1978, TR694 U MAR COMP SCI; PELEG, 1979, COMPUT GRAPHICS IMAG, P235; PELEG S, 1979, COMMUN ACM, V22, P598, DOI 10.1145/359168.359174; ROSENFELD, 1977, JUN P IEEE C PATT RE, P14; ROSENFELD, 1978, DIGITAL PICTURE PROC; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; RUTKOWSKI, 1978, TR623 U MAR COMP SCI; SCHACHTER, 1977, IEEE T SYST MAN CYBE, V7, P813; SMITH, 1979, THESIS U MARYLAND; ZUCKER, 1976, 3RD P INT JOINT C PA, P852; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41	22	47	47	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					79	92		10.1109/TPAMI.1981.4767053	http://dx.doi.org/10.1109/TPAMI.1981.4767053			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LK116	21868921				2022-12-18	WOS:A1981LK11600009
J	POSTAIRE, JG; VASSEUR, CPA				POSTAIRE, JG; VASSEUR, CPA			AN APPROXIMATE SOLUTION TO NORMAL MIXTURE IDENTIFICATION WITH APPLICATION TO UNSUPERVISED PATTERN-CLASSIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV LILLE 1, CTR AUTOMAT, F-59650 VILLENEUVE DASCQ, FRANCE	Universite de Lille - ISITE; Universite de Lille	POSTAIRE, JG (corresponding author), UNIV RABAT, FAC SCI, ELECTR & ETUD SYST AUTOMAT LAB, RABAT, MOROCCO.							COOPER DB, 1964, INFORM CONTROL, V7, P416, DOI 10.1016/S0019-9958(64)90502-9; DALY RF, 1962, 20033 STANF U TECH R; DAY NE, 1969, BIOMETRIKA, V56, P463, DOI 10.1093/biomet/56.3.463; Duda R.O., 1973, J ROYAL STAT SOC SER; EGGLESTON HG, 1963, CAMBRIDGE TRACTS MAT; EIGEN DJ, 1974, IEEE T SYST MAN CYB, VSMC4, P284, DOI 10.1109/TSMC.1974.5409135; KAZAKOS D, 1977, IEEE T INFORM THEORY, V23, P203, DOI 10.1109/TIT.1977.1055693; MAKOV UE, 1977, IEEE T INFORM THEORY, V23, P761, DOI 10.1109/TIT.1977.1055801; MIZOGUCHI R, 1975, IEEE T COMPUT, V24, P979, DOI 10.1109/T-C.1975.224104; PATRICK EA, 1966, IEEE T INFORM THEORY, V12, P362, DOI 10.1109/TIT.1966.1053901; SPRAGINS J, 1966, IEEE T INFORM THEORY, V12, P223; TOU JT, 1974, PATTERN RECOGN, P119; VASSEUR C, 1979, SYST ANAL CONTR, V13, P171; YAKOWITZ SJ, 1970, IEEE T INFORM THEORY, V16, P330, DOI 10.1109/TIT.1970.1054442; YOUNG TY, 1970, IEEE T INFORM THEORY, V16, P258, DOI 10.1109/TIT.1970.1054454	15	47	47	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					163	179		10.1109/TPAMI.1981.4767074	http://dx.doi.org/10.1109/TPAMI.1981.4767074			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN968	21868931				2022-12-18	WOS:A1981MN96800006
J	EKLUNDH, JO; YAMAMOTO, H; ROSENFELD, A				EKLUNDH, JO; YAMAMOTO, H; ROSENFELD, A			RELAXATION METHOD FOR MULTISPECTRAL PIXEL CLASSIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									NATL AEROSPACE LAB,TOKYO,JAPAN; UNIV MARYLAND,CTR COMP SCI,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	EKLUNDH, JO (corresponding author), DEF RES INST,STOCKHOLM,SWEDEN.							DAVIS LS, 1978, IEEE T SYST MAN CYB, V8, P705; Duda R.O., 1973, J ROYAL STAT SOC SER; EKLUNDH J, 1978, TR662 U MAR COMP SCI; EKLUNDH JO, 1978, TR701 U MAR COMP SCI; OHLANDER R, 1976, THESIS CARNEGIE MELL; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Schacter B., 1976, SCENE SEGMENTATION C, P16	8	47	47	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	1					72	75		10.1109/TPAMI.1980.4766973	http://dx.doi.org/10.1109/TPAMI.1980.4766973			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD568	22499626				2022-12-18	WOS:A1980JD56800011
J	Pei, YT; Huang, YP; Zou, Q; Zhang, XY; Wang, S				Pei, Yanting; Huang, Yaping; Zou, Qi; Zhang, Xingyuan; Wang, Song			Effects of Image Degradation and Degradation Removal to CNN-Based Image Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Degradation; Cameras; Image resolution; Image recognition; Training; Computer vision; Deep learning; Image classification; image degradation; degradation removal; CNN	SUPERRESOLUTION	Just like many other topics in computer vision, image classification has achieved significant progress recently by using deep learning neural networks, especially the Convolutional Neural Networks (CNNs). Most of the existing works focused on classifying very clear natural images, evidenced by the widely used image databases, such as Caltech-256, PASCAL VOCs, and ImageNet. However, in many real applications, the acquired images may contain certain degradations that lead to various kinds of blurring, noise, and distortions. One important and interesting problem is the effect of such degradations to the performance of CNN-based image classification and whether degradation removal helps CNN-based image classification. More specifically, we wonder whether image classification performance drops with each kind of degradation, whether this drop can be avoided by including degraded images into training, and whether existing computer vision algorithms that attempt to remove such degradations can help improve the image classification performance. In this article, we empirically study those problems for nine kinds of degraded images-hazy images, motion-blurred images, fish-eye images, underwater images, low resolution images, salt-and-peppered images, images with white Gaussian noise, Gaussian-blurred images, and out-of-focus images. We expect this article can draw more interests from the community to study the classification of degraded images.	[Pei, Yanting; Huang, Yaping; Zou, Qi; Zhang, Xingyuan] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China; [Pei, Yanting; Huang, Yaping; Zou, Qi; Zhang, Xingyuan] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China; [Wang, Song] Univ South Carolina, Dept Comp Sci & Engn, Columbia, SC 29201 USA; [Wang, Song] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China	Beijing Jiaotong University; Beijing Jiaotong University; University of South Carolina System; University of South Carolina Columbia; Tianjin University	Huang, YP (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.; Huang, YP (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China.; Wang, S (corresponding author), Univ South Carolina, Dept Comp Sci & Engn, Columbia, SC 29201 USA.; Wang, S (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China.	yantingpei@bjtu.edu.cn; yphuang@bjtu.edu.cn; qzou@bjtu.edu.cn; 15112071@bjtu.edu.cn; songwang@cec.sc.edu		Wang, Song/0000-0003-4152-5295	Fundamental Research Funds for the Central Universities [2019JBZ104, 2016JBZ005]; National Natural Science Foundation of China [61906013, 51827813, 61672376, U1803264]	Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported, in part, by the Fundamental Research Funds for the Central Universities (2019JBZ104, 2016JBZ005), and National Natural Science Foundation of China (61906013, 51827813, 61672376, U1803264). The preliminary version of this work has been published in 2018 European Conference on Computer Vision [82].	Akkaynak D, 2017, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.2017.68; Al-amri S. S., 2010, ARXIV10044448; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Baek I, 2018, IEEE INT VEH SYM, P447; Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185; Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681; Chen Z, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010196; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Dong H., 2018, ARXIV 181109173; Durand T, 2017, PROC CVPR IEEE, P5957, DOI 10.1109/CVPR.2017.631; Everingham Mark, 2010, IJCV; Flusser J, 1996, IEEE T IMAGE PROCESS, V5, P533, DOI 10.1109/83.491327; Flusser J, 1998, IEEE T PATTERN ANAL, V20, P590, DOI 10.1109/34.683773; Flusser J, 2015, LECT NOTES COMPUT SC, V9256, P88, DOI 10.1007/978-3-319-23192-1_8; Fu B., 2018, MULTIMED TOOLS APPL, P1; Fu B, 2019, MULTIMED TOOLS APPL, V78, P12043, DOI 10.1007/s11042-018-6732-8; Fu HZ, 2012, IEEE T INF FOREN SEC, V7, P1301, DOI 10.1109/TIFS.2012.2195492; Gast J, 2016, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2016.204; Gopalan R., 2012, IEEE I CONF COMP VIS, V34, P1220; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Han W, 2018, PROC CVPR IEEE, P1654, DOI 10.1109/CVPR.2018.00178; Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hughes C, 2010, IEEE T PATTERN ANAL, V32, P2289, DOI 10.1109/TPAMI.2010.159; Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082; Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522; Kalalembang E, 2009, ICICI-BME: 2009 INTERNATIONAL CONFERENCE ON INSTRUMENTATION, COMMUNICATION, INFORMATION TECHNOLOGY, AND BIOMEDICAL ENGINEERING, P286; Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153; Karahan Samil, 2016, 2016 INT C BIOM SPEC, P1, DOI [10.1109/BIOSIG.2016.7736924, DOI 10.1109/BIOSIG.2016.7736924]; Krams O, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Lefkimmiatis S, 2018, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2018.00338; Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511; Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856; Liu D, 2019, IEEE T IMAGE PROCESS, V28, P4401, DOI 10.1109/TIP.2019.2908802; Liu RT, 2008, PROC CVPR IEEE, P954; Lu BY, 2019, PROC CVPR IEEE, P10217, DOI 10.1109/CVPR.2019.01047; Luchinin A., 2006, RUSSIAN ACAD SCI I A; Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155; Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82; Moller T, 2017, IEEE INT CONF COMP V, P2891, DOI 10.1109/ICCVW.2017.341; Moghaddam ME, 2007, PROCEEDINGS OF THE 5TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P278; Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35; Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180; Pei YT, 2018, LECT NOTES COMPUT SC, V11214, P697, DOI 10.1007/978-3-030-01249-6_42; Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835; Rajagopalan A.N., 2014, MOTION DEBLURRING AL; Ramakrishnan S, 2017, IEEE INT CONF COMP V, P2993, DOI 10.1109/ICCVW.2017.353; Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343; Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10; Sanchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504; Sharma V. K, 2018, INFORM COMMUNICATION, P443; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Tang C., 2019, PROC IEEECVF C COMPU, P2700; Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853; Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251; Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128; Wang N, 2017, OPT EXPRESS, V25, P22490, DOI 10.1364/OE.25.022490; Wang S, 2010, P IEEE C COMP VIS PA, P447; Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang ZH, 2016, PROCEEDINGS OF THE 4TH INTERNATIONAL WORKSHOP ON ENERGY HARVESTING AND ENERGY-NEUTRAL SENSING SYSTEMS (ENSSYS'16), P1, DOI 10.1145/2996884.2996885; Yair N, 2018, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2018.00334; Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123; Yu K, 2018, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2018.00259; Zhang J, 2017, PROC CVPR IEEE, P7016, DOI 10.1109/CVPR.2017.742; ZHANG K, 2017, PROC CVPR IEEE, P2808, DOI DOI 10.1109/CVPR.2017.300; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zhang ZW, 2013, IEEE T IMAGE PROCESS, V22, P3145, DOI 10.1109/TIP.2013.2259840; Zhang ZW, 2011, IEEE I CONF COMP VIS, P1770, DOI 10.1109/ICCV.2011.6126442; Zhao WD, 2019, PROC CVPR IEEE, P8897, DOI 10.1109/CVPR.2019.00911; Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191	81	46	47	10	83	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1239	1253		10.1109/TPAMI.2019.2950923	http://dx.doi.org/10.1109/TPAMI.2019.2950923			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31689183				2022-12-18	WOS:000626525300010
J	Meng, N; So, HKH; Sun, X; Lam, EY				Meng, Nan; So, Hayden K. -H.; Sun, Xing; Lam, Edmund Y.			High-Dimensional Dense Residual Convolutional Neural Network for Light Field Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image reconstruction; Convolution; Estimation; Image restoration; Feature extraction; Correlation; Light field super-resolution; 4-dimensional convolution; convolutional neural networks; deep learning	CAMERA; RESOLUTION	We consider the problem of high-dimensional light field reconstruction and develop a learning-based framework for spatial and angular super-resolution. Many current approaches either require disparity clues or restore the spatial and angular details separately. Such methods have difficulties with non-Lambertian surfaces or occlusions. In contrast, we formulate light field super-resolution (LFSR) as tensor restoration and develop a learning framework based on a two-stage restoration with 4-dimensional (4D) convolution. This allows our model to learn the features capturing the geometry information encoded in multiple adjacent views. Such geometric features vary near the occlusion regions and indicate the foreground object border. To train a feasible network, we propose a novel normalization operation based on a group of views in the feature maps, design a stage-wise loss function, and develop the multi-range training strategy to further improve the performance. Evaluations are conducted on a number of light field datasets including real-world scenes, synthetic data, and microscope light fields. The proposed method achieves superior performance and less execution time comparing with other state-of-the-art schemes.	[Meng, Nan; So, Hayden K. -H.; Lam, Edmund Y.] Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam, Hong Kong, Peoples R China; [Sun, Xing] Tencent, YouTu Lab, Shanghai 200233, Peoples R China	University of Hong Kong; Tencent	Lam, EY (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam, Hong Kong, Peoples R China.	nanmeng@eee.hku.hk; hso@eee.hku.hk; winfredsun@tencent.com; elam@eee.hku.hk	So, Hayden Kwok Hay/C-1585-2009; Meng, Nan/AAZ-1622-2020; Lam, Edmund Yin Mun/C-1853-2009	So, Hayden Kwok Hay/0000-0002-6514-0237; Meng, Nan/0000-0003-2821-7474; Lam, Edmund Yin Mun/0000-0001-6268-950X	Hong Kong Research Grants Council [17203217, 17201818, 104005009, 104005438]	Hong Kong Research Grants Council(Hong Kong Research Grants Council)	This work was supported in part by the Hong Kong Research Grants Council (17203217 and 17201818) and theUniversity of Hong Kong (104005009 and 104005438).	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168; Chan WS, 2007, MULTIDIM SYST SIGN P, V18, P83, DOI 10.1007/s11045-007-0022-3; Cheng Z., 2019, CVPR WORKSH; Farrugia RA, 2020, IEEE T PATTERN ANAL, V42, P1162, DOI 10.1109/TPAMI.2019.2893666; Farrugia RA, 2017, IEEE J-STSP, V11, P1058, DOI 10.1109/JSTSP.2017.2747127; Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595; Georgiev T, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3442712; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Gul MSK, 2018, IEEE T IMAGE PROCESS, V27, P2146, DOI 10.1109/TIP.2018.2794181; Gupta P., 2011, P 2011 INT C COMMUNI, P1, DOI 10.1109/ICCIndA.2011.6146669; Honauer K, 2017, LECT NOTES COMPUT SC, V10113, P19, DOI 10.1007/978-3-319-54187-7_2; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304; Lam EY, 2015, J OPT SOC AM A, V32, P2021, DOI 10.1364/JOSAA.32.002021; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Levoy M, 2006, ACM T GRAPHIC, V25, P924, DOI 10.1145/1141911.1141976; Liang CK, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2665075; Lim J, 2009, IEEE IMAGE PROC, P1173; Lin X, 2015, BIOMED OPT EXPRESS, V6, P3179, DOI 10.1364/BOE.6.003179; Maas A. L., 2013, P ICML; Mitra K., 2012, P IEEECVF C COMPUTER, P22; Mousnier A., 2015, ARXIV150301903; Ng, 2005, LIGHT FIELD PHOTOGRA; Pearson J, 2013, IEEE T IMAGE PROCESS, V22, P3405, DOI 10.1109/TIP.2013.2268939; Rerabek M., 2016, P 8 INT C QUAL MULTI; Rossi M, 2018, IEEE T IMAGE PROCESS, V27, P4207, DOI 10.1109/TIP.2018.2828983; Sam G., 2016, TRAINING INVESTIGATI; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Shin C, 2018, PROC CVPR IEEE, P4748, DOI 10.1109/CVPR.2018.00499; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Srinivasan PP, 2017, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2017.246; Sun X, 2016, IEEE IJCNN, P367, DOI 10.1109/IJCNN.2016.7727222; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Vagharshakyan S, 2018, IEEE T PATTERN ANAL, V40, P133, DOI 10.1109/TPAMI.2017.2653101; Wang TC, 2016, IEEE T PATTERN ANAL, V38, P2170, DOI 10.1109/TPAMI.2016.2515615; Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398; Wang YL, 2018, IEEE T IMAGE PROCESS, V27, P4274, DOI 10.1109/TIP.2018.2834819; Wanner S., 2013, VISION MODELING VISU, P225, DOI DOI 10.2312/PE.VMV.VMV13.225-226; Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147; Wanner S, 2012, LECT NOTES COMPUT SC, V7576, P608, DOI 10.1007/978-3-642-33715-4_44; Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259; Wu GC, 2019, IEEE T PATTERN ANAL, V41, P1681, DOI 10.1109/TPAMI.2018.2845393; Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178; Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126; Yeung HWF, 2018, LECT NOTES COMPUT SC, V11210, P138, DOI 10.1007/978-3-030-01231-1_9; Yoon Y, 2017, IEEE SIGNAL PROC LET, V24, P848, DOI 10.1109/LSP.2017.2669333; Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17; Zhang FL, 2017, IEEE T VIS COMPUT GR, V23, P1561, DOI 10.1109/TVCG.2016.2532329; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zhang ZT, 2015, PROC CVPR IEEE, P3800, DOI 10.1109/CVPR.2015.7299004; Ziegler M, 2017, 2017 3DTV CONFERENCE: THE TRUE VISION - CAPTURE, TRANSMISSION AND DISPLAY OF 3D VIDEO (3DTV-CON)	61	46	47	13	64	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					873	886		10.1109/TPAMI.2019.2945027	http://dx.doi.org/10.1109/TPAMI.2019.2945027			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31581075	Green Submitted			2022-12-18	WOS:000616309900009
J	Yang, JF; Liang, J; Wang, K; Rosin, PL; Yang, MH				Yang, Jufeng; Liang, Jie; Wang, Kai; Rosin, Paul L.; Yang, Ming-Hsuan			Subspace Clustering via Good Neighbors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering algorithms; Sparse matrices; Correlation; Clustering methods; Optimization; Minimization; Matching pursuit algorithms; Spectral-based subspace clustering; post-processing; good neighbors; sparsity; graph connectivity	SEGMENTATION; ROBUST	Finding the informative subspaces of high-dimensional datasets is at the core of numerous applications in computer vision, where spectral-based subspace clustering is arguably the most widely studied method due to its strong empirical performance. Such algorithms first compute an affinity matrix to construct a self-representation for each sample using other samples as a dictionary. Sparsity and connectivity of the self-representation play important roles in effective subspace clustering. However, simultaneous optimization of both factors is difficult due to their conflicting nature, and most existing methods are designed to address only one factor. In this paper, we propose a post-processing technique to optimize both sparsity and connectivity by finding good neighbors. Good neighbors induce key connections among samples within a subspace and not only have large affinity coefficients but are also strongly connected to each other. We reassign the coefficients of the good neighbors and eliminate other entries to generate a new coefficient matrix. We show that the few good neighbors can effectively recover the subspace, and the proposed post-processing step of finding good neighbors is complementary to most existing subspace clustering algorithms. Experiments on five benchmark datasets show that the proposed algorithm performs favorably against the state-of-the-art methods with negligible additional computation cost.	[Yang, Jufeng; Liang, Jie; Wang, Kai] Nankai Univ, Coll Comp Sci, Tianjin 300350, Peoples R China; [Rosin, Paul L.] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95344 USA	Nankai University; Cardiff University; University of California System; University of California Merced	Yang, MH (corresponding author), Univ Calif Merced, Sch Engn, Merced, CA 95344 USA.	yangjufeng@nankai.edu.cn; liang27jie@163.com; wangk@nankai.edu.cn; Paul.Rosin@cs.cf.ac.uk; mhyang@ucmerced.edu	Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Wang, Kai/0000-0001-5589-7060; Rosin, Paul/0000-0002-4965-3884; Liang, Jie/0000-0003-2822-5466	NSFC [61876094]; NSF CAREER [149783]; Natural Science Foundation of Tianjin, China [18JCYBJC15400, 18ZXZNGX00110]; Open Project Program of the National Laboratory of Pattern Recognition (NLPR); Fundamental Research Funds for the Central Universities	NSFC(National Natural Science Foundation of China (NSFC)); NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); Natural Science Foundation of Tianjin, China(Natural Science Foundation of Tianjin); Open Project Program of the National Laboratory of Pattern Recognition (NLPR); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported by the NSFC (NO. 61876094), NSF CAREER (NO.149783), Natural Science Foundation of Tianjin, China (NO. 18JCYBJC15400, 18ZXZNGX00110), the Open Project Program of the National Laboratory of Pattern Recognition (NLPR) and the Fundamental Research Funds for the Central Universities.	[Anonymous], 1998, 24 CVC U AUT BARC; [Anonymous], [No title captured]; [Anonymous], 2018, IEEE T CIRC SYST VID, DOI DOI 10.1109/TCSVT.2017.2706264; [Anonymous], 2001, SPRINGE SER STAT N; Dyer EL, 2013, J MACH LEARN RES, V14, P2487; Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Feng JS, 2014, PROC CVPR IEEE, P3818, DOI 10.1109/CVPR.2014.482; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Guo Y, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083644; Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775; Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484; Ji P, 2015, IEEE I CONF COMP VIS, P4687, DOI 10.1109/ICCV.2015.532; Kim E, 2016, IEEE T IMAGE PROCESS, V25, P4245, DOI 10.1109/TIP.2016.2588321; Lai HJ, 2014, LECT NOTES COMPUT SC, V8690, P617, DOI 10.1007/978-3-319-10605-2_40; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee M, 2015, PROC CVPR IEEE, P1648, DOI 10.1109/CVPR.2015.7298773; Li CG, 2016, IEEE T SIGNAL PROCES, V64, P6557, DOI 10.1109/TSP.2016.2613070; Li CG, 2015, PROC CVPR IEEE, P277, DOI 10.1109/CVPR.2015.7298624; Li ZW, 2016, PROC CVPR IEEE, P5347, DOI 10.1109/CVPR.2016.577; Liang J, 2018, LECT NOTES COMPUT SC, V11215, P726, DOI 10.1007/978-3-030-01252-6_43; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2016, IEEE T PATTERN ANAL, V38, P417, DOI 10.1109/TPAMI.2015.2453969; Liu ZL, 2013, 2013 INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND VISUALIZATION (ICVRV 2013), P64, DOI 10.1109/ICVRV.2013.71; Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26; Lu CY, 2019, IEEE T PATTERN ANAL, V41, P487, DOI 10.1109/TPAMI.2018.2794348; Lu CY, 2013, IEEE I CONF COMP VIS, P1345, DOI 10.1109/ICCV.2013.170; Nasihatkon B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2137, DOI 10.1109/CVPR.2011.5995679; Nene S. A., 1996, COLUMBIA OBJECT IMAG; Peng C, 2017, PROC CVPR IEEE, P682, DOI 10.1109/CVPR.2017.80; Peng X, 2017, IEEE T CYBERNETICS, V47, P1053, DOI 10.1109/TCYB.2016.2536752; Peng X, 2015, AAAI CONF ARTIF INTE, P3827; Purkait P, 2017, IEEE T PATTERN ANAL, V39, P1697, DOI 10.1109/TPAMI.2016.2614980; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shin W, 2014, INT CONF DIGIT INFO, P275, DOI 10.1109/DICTAP.2014.6821695; Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010; Tierney S, 2014, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2014.134; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006; Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; XIAO SJ, 2015, PROC CVPR IEEE, P4612; Xu J, 2015, COMPUT VIS IMAGE UND, V138, P25, DOI 10.1016/j.cviu.2015.04.003; Yang JF, 2018, AAAI CONF ARTIF INTE, P4358; Yang JF, 2018, IEEE T IMAGE PROCESS, V27, P5288, DOI 10.1109/TIP.2018.2845136; Yang YZ, 2016, LECT NOTES COMPUT SC, V9906, P731, DOI 10.1007/978-3-319-46475-6_45; Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360; You C., 2018, P EUR C COMP VIS, P67; You C, 2017, PROC CVPR IEEE, P4323, DOI 10.1109/CVPR.2017.460; You C, 2016, PROC CVPR IEEE, P3918, DOI 10.1109/CVPR.2016.425; You C, 2016, PROC CVPR IEEE, P3928, DOI 10.1109/CVPR.2016.426; Zhang DW, 2019, INT J COMPUT VISION, V127, P363, DOI 10.1007/s11263-018-1112-4	53	46	48	4	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1537	1544		10.1109/TPAMI.2019.2913863	http://dx.doi.org/10.1109/TPAMI.2019.2913863			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	31056488	Green Accepted			2022-12-18	WOS:000535615700019
J	Qi, YK; Zhang, SP; Qin, L; Huang, QM; Yao, HX; Lim, J; Yang, MH				Qi, Yuankai; Zhang, Shengping; Qin, Lei; Huang, Qingming; Yao, Hongxun; Lim, Jongwoo; Yang, Ming-Hsuan			Hedging Deep Features for Visual Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; convolutional neural network; adaptive hedge; Siamese network	OBJECT TRACKING	Convolutional Neural Networks (CNNs) have been applied to visual tracking with demonstrated success in recent years. Most CNN-based trackers utilize hierarchical features extracted from a certain layer to represent the target. However, features from a certain layer are not always effective for distinguishing the target object from the backgrounds especially in the presence of complicated interfering factors (e.g., heavy occlusion, background clutter, illumination variation, and shape deformation). In this work, we propose a CNN-based tracking algorithm which hedges deep features from different CNN layers to better distinguish target objects and background clutters. Correlation filters are applied to feature maps of each CNN layer to construct a weak tracker, and all weak trackers are hedged into a strong one. For robust visual tracking, we propose a hedge method to adaptively determine weights of weak classifiers by considering both the difference between the historical as well as instantaneous performance, and the difference among all weak trackers over time. In addition, we design a Siamese network to define the loss of each weak tracker for the proposed hedge method. Extensive experiments on large benchmark datasets demonstrate the effectiveness of the proposed algorithm against the state-of-the-art tracking methods.	[Qi, Yuankai; Huang, Qingming; Yao, Hongxun] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China; [Zhang, Shengping] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Shandong, Peoples R China; [Qin, Lei; Huang, Qingming] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China; [Huang, Qingming] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 100049, Peoples R China; [Lim, Jongwoo] Hanyang Univ, Dept Comp Sci, Seoul 133791, South Korea; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95344 USA	Harbin Institute of Technology; Harbin Institute of Technology; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Hanyang University; University of California System; University of California Merced	Huang, QM (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.; Zhang, SP (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Shandong, Peoples R China.; Huang, QM (corresponding author), Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China.; Huang, QM (corresponding author), Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 100049, Peoples R China.	yk.qi@hit.edu.cn; s.zhang@hit.edu.cn; qinlei@ict.ac.cn; qmhuang@jdl.ac.cn; h.yao@hit.edu.cn; jlim@hanyang.ac.kr; mhyang@ucmerced.edu	Yang, Ming-Hsuan/T-9533-2019; Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; 	National Natural Science Foundation of China [61620106009, 61332016, U1636214, 61650202, 61672188, 61572465, 61390510, 61732007, 61472103, 61772158, U1711265]; Key Research Program of Frontier Sciences, CAS [QYZDJ-SSW-SYS013]; NRF - Ministry of Science, ICT Korea [NRF-2017R1A2B4011928, NRF-2017M3C4A7069369]; NSF CAREER [1149783]; Young Excellent Talent Program of Harbin Institute of Technology	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Research Program of Frontier Sciences, CAS; NRF - Ministry of Science, ICT Korea(National Research Foundation of Korea); NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); Young Excellent Talent Program of Harbin Institute of Technology	This work was supported in part by National Natural Science Foundation of China: 61620106009, 61332016, U1636214, 61650202, 61672188, 61572465, 61390510, 61732007, 61472103, 61772158, U1711265; in part by Key Research Program of Frontier Sciences, CAS: QYZDJ-SSW-SYS013; in part by the NRF grant funded by Ministry of Science, ICT Korea: NRF-2017R1A2B4011928 and NRF-2017M3C4A7069369; in part by the NSF CAREER Grant 1149783, and gifts from Adobe, Verisk, and Nvidia. S. Zhang was also supported by the Young Excellent Talent Program of Harbin Institute of Technology.	Adam A., 2006, IEEE C COMP VIS PATT; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Bai QX, 2013, IEEE I CONF COMP VIS, P2040, DOI 10.1109/ICCV.2013.255; Bailer C, 2014, LECT NOTES COMPUT SC, V8695, P170, DOI 10.1007/978-3-319-10584-0_12; Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667; Bischof H., 2006, BMVC, P47; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; Chaudhuri K., 2009, ADV NEURAL INFORM PR; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Danelljan Martin, 2014, BRIT MACH VIS C NOTT; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286; Figueroa PJ, 2006, COMPUT VIS IMAGE UND, V101, P122, DOI 10.1016/j.cviu.2005.07.006; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gidaris  S., 2015, P IEEE INT C COMP VI, P1904; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Glorot X., 2010, PROC MACH LEARN RES, P249; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79; Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14; Kristan M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P98, DOI 10.1109/ICCVW.2013.20; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595; NAM H, 2016, PROC CVPR IEEE, P4293, DOI DOI 10.1109/CVPR.2016.465; Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466; SCHNEIDERMAN H, 1994, IEEE T ROBOTIC AUTOM, V10, P769, DOI 10.1109/70.338531; Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230; Song  X., 2013, ACM T INTEL SYST TEC, V4; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158; Tian G, 2009, LECT NOTES COMPUT SC, V5552, P1145, DOI 10.1007/978-3-642-01510-6_130; Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531; Vojir T, 2016, COMPUT VIS IMAGE UND, V153, P109, DOI 10.1016/j.cviu.2016.05.007; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; Wang N, 2013, ADV NEURAL INFORM PR, DOI DOI 10.5555/2999611.2999702; Wang NY, 2014, PR MACH LEARN RES, V32, P1107; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Yang J., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P140, DOI 10.1145/274644.274666; Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13; Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882	51	46	47	0	76	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1116	1130		10.1109/TPAMI.2018.2828817	http://dx.doi.org/10.1109/TPAMI.2018.2828817			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993908				2022-12-18	WOS:000463607400007
J	Rubino, C; Crocco, M; Del Bue, A				Rubino, Cosimo; Crocco, Marco; Del Bue, Alessio			3D Object Localisation from Multi-View Image Detections	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-view geometry; 3D localisation; object detection; conics optimisation	POSE ESTIMATION; VISION; SINGLE	In this work we present a novel approach to recover objects 3D position and occupancy in a generic scene using only 2D object detections from multiple view images. The method reformulates the problem as the estimation of a quadric (ellipsoid) in 3D given a set of 2D ellipses fitted to the object detection bounding boxes in multiple views. We show that a closed-form solution exists in the dual-space using a minimum of three views while a solution with two views is possible through the use of non-linear optimisation and object constraints on the size of the object shape. In order to make the solution robust toward inaccurate bounding boxes, a likely occurrence in object detection methods, we introduce a data preconditioning technique and a non-linear refinement of the closed form solution based on implicit subspace constraints. Results on synthetic tests and on different real datasets, involving challenging scenarios, demonstrate the applicability and potential of our method in several realistic scenarios.	[Rubino, Cosimo; Crocco, Marco; Del Bue, Alessio] Ist Italiano Tecnol, Visual Geometry & Modelling VGM Lab, Via Morego 30, I-16163 Genoa, Italy	Istituto Italiano di Tecnologia - IIT	Crocco, M (corresponding author), Ist Italiano Tecnol, Visual Geometry & Modelling VGM Lab, Via Morego 30, I-16163 Genoa, Italy.	Cosimo.Rubino@iit.it; Marco.Crocco@iit.it; alessio.delbue@iit.it	Rubino, Cosimo/AAD-7590-2020					Aldoma A, 2014, IEEE INT C INT ROBOT, P5016, DOI 10.1109/IROS.2014.6943275; [Anonymous], 2014, TANGO PROJECT; Ayoub AB., 1993, MATH MAG, V66, P322, DOI DOI 10.1080/0025570X.1993.11996157; Bao S. Y., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2025, DOI 10.1109/CVPR.2011.5995462; Bao SY, 2013, PROC CVPR IEEE, P1264, DOI 10.1109/CVPR.2013.167; Bao SY, 2012, LECT NOTES COMPUT SC, V7572, P86, DOI 10.1007/978-3-642-33718-5_7; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; Choi W, 2010, LECT NOTES COMPUT SC, V6314, P553, DOI 10.1007/978-3-642-15561-1_40; Crocco M, 2016, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2016.449; Cross G, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P25, DOI 10.1109/ICCV.1998.710697; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dame A, 2013, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2013.170; Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237; Divvala SK, 2012, LECT NOTES COMPUT SC, V7585, P31, DOI 10.1007/978-3-642-33885-4_4; Farenzena Michela, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1489, DOI 10.1109/ICCVW.2009.5457435; Farenzena M., 2006, P INT C COMP VIS PAT, P1185; Farenzena M., 2008, P ACM SIGCOMM, P1; Fidler S., 2012, P ADV NEURAL INFORM, P611; Fioraio N, 2013, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2013.202; Fusiello A, 2004, IEEE T PATTERN ANAL, V26, P1633, DOI 10.1109/TPAMI.2004.125; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Geiger A., 2011, ADV NEURAL INFORM PR, VVol. 24, P1467; Geiger A, 2014, IEEE T PATTERN ANAL, V36, P1012, DOI 10.1109/TPAMI.2013.185; Glasner D, 2011, IEEE I CONF COMP VIS, P1275, DOI 10.1109/ICCV.2011.6126379; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; Hartley R., 2003, MULTIPLE VIEW GEOMET; Henderson H.V., 1979, CANADIAN J STATISTIC, V7, P65; Hinterstoisser Stefan, 2012, P AS C COMP VIS, P2, DOI DOI 10.1007/978-3-642-37331-2_42; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807; Kato T., 2012, SHORT INTRO PERTURBA; Liebelt J, 2010, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2010.5539836; Ma S. D., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P344, DOI 10.1109/ICPR.1996.546046; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Ozuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633; Ohn-Bar E, 2014, IEEE COMPUT SOC CONF, P179, DOI 10.1109/CVPRW.2014.32; Pepik B, 2012, LECT NOTES COMPUT SC, V7577, P356, DOI 10.1007/978-3-642-33783-3_26; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1; Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178; Savarese S, 2008, LECT NOTES COMPUT SC, V5304, P602, DOI 10.1007/978-3-540-88690-7_45; Savarese S, 2007, IEEE I CONF COMP VIS, P1245; Torki M, 2011, IEEE I CONF COMP VIS, P2603, DOI 10.1109/ICCV.2011.6126549; Vicente S, 2014, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2014.13; Xiao JX, 2008, LECT NOTES COMPUT SC, V5304, P725, DOI 10.1007/978-3-540-88690-7_54; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zia MZ, 2013, IEEE T PATTERN ANAL, V35, P2608, DOI 10.1109/TPAMI.2013.87; Zia MZ, 2015, INT J COMPUT VISION, V112, P188, DOI 10.1007/s11263-014-0780-y; Zia MZ, 2014, PROC CVPR IEEE, P3678, DOI 10.1109/CVPR.2014.470	50	46	48	4	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1281	1294		10.1109/TPAMI.2017.2701373	http://dx.doi.org/10.1109/TPAMI.2017.2701373			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28489531				2022-12-18	WOS:000431524700001
J	Elhayek, A; de Aguiar, E; Jain, A; Thompson, J; Pishchulin, L; Andriluka, M; Bregler, C; Schiele, B; Theobalt, C				Elhayek, A.; de Aguiar, E.; Jain, A.; Thompson, J.; Pishchulin, L.; Andriluka, M.; Bregler, C.; Schiele, B.; Theobalt, C.			MARCOnI-ConvNet-Based MARker-Less Motion Capture in Outdoor and Indoor Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion capture; marker-less motion capture; multi-model dataset; convolutional neural networks	PICTORIAL STRUCTURES; TRACKING PEOPLE; POSE	Marker-less motion capture has seen great progress, but most state-of-the-art approaches fail to reliably track articulated human body motion with a very low number of cameras, let alone when applied in outdoor scenes with general background. In this paper, we propose a method for accurate marker-less capture of articulated skeleton motion of several subjects in general scenes, indoors and outdoors, even from input filmed with as few as two cameras. The new algorithm combines the strengths of a discriminative image-based joint detection method with a model-based generative motion tracking algorithm through an unified pose optimization energy. The discriminative part-based pose detection method is implemented using Convolutional Networks ( ConvNet) and estimates unary potentials for each joint of a kinematic skeleton model. These unary potentials serve as the basis of a probabilistic extraction of pose constraints for tracking by using weighted sampling from a pose posterior that is guided by the model. In the final energy, we combine these constraints with an appearance-based model-to-image similarity term. Poses can be computed very efficiently using iterative local optimization, since joint detection with a trained ConvNet is fast, and since our formulation yields a combined pose estimation energy with analytic derivatives. In combination, this enables to track full articulated joint angles at state-of-the-art accuracy and temporal stability with a very low number of cameras. Our method is efficient and lends itself to implementation on parallel computing hardware, such as GPUs. We test our method extensively and show its advantages over related work on many indoor and outdoor data sets captured by ourselves, as well as data sets made available to the community by other research labs. The availability of good evaluation data sets is paramount for scientific progress, and many existing test data sets focus on controlled indoor settings, do not feature much variety in the scenes, and often lack a large corpus of data with ground truth annotation. We therefore further contribute with a new extensive test data set called MPI-MARCOnI for indoor and outdoor marker-less motion capture that features 12 scenes of varying complexity and varying camera count, and that features ground truth reference data from different modalities, ranging from manual joint annotations to marker-based motion capture results. Our new method is tested on these data, and the data set will be made available to the community.	[Elhayek, A.] MPI Informat, Graph Vis & Video Grp, Saarland, Germany; [de Aguiar, E.; Pishchulin, L.; Theobalt, C.] MPI Informat, Saarland, Germany; [Schiele, B.] MPI Informat, Comp Vis & Multimodal Comp Dept, Saarland, Germany; [Andriluka, M.] Stanford Univ, Stanford, CA 94305 USA; [Jain, A.] NYU, New York, NY 10003 USA; [Thompson, J.; Bregler, C.] Google, Mountain View, CA USA	Max Planck Society; Max Planck Society; Max Planck Society; Stanford University; New York University; Google Incorporated	Elhayek, A (corresponding author), MPI Informat, Graph Vis & Video Grp, Saarland, Germany.	ahmedelhayek84@gmail.com; edilson.de.aguiar@gmail.com; ajain@nyu.edu; tompson@cimsnyu.edu; leonid.pishchulin@gmail.com; andriluka@mpii.de; chris.bregler@gmail.com; schiele@mpii.de; theobalt@mpii.de	El_hayek, Ahmed/AAT-6860-2021	Theobalt, Christian/0000-0001-6104-6625				Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; Amin S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.45; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Baak A, 2011, IEEE I CONF COMP VIS, P1092, DOI 10.1109/ICCV.2011.6126356; Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Bray M, 2007, COMPUT VIS IMAGE UND, V106, P116, DOI 10.1016/j.cviu.2005.09.013; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; Bregler C., 2014, ICLR; Brox T, 2010, IEEE T PATTERN ANAL, V32, P402, DOI 10.1109/TPAMI.2009.32; Buehler Patrick, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2961, DOI 10.1109/CVPRW.2009.5206523; Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464; Chen X., 2014, P 27 ANN C NEURAL IN, P1736, DOI DOI 10.1109/CVPR.2018.00742; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Elhayek A, 2015, COMPUT GRAPH FORUM, V34, P86, DOI 10.1111/cgf.12519; Elhayek A, 2015, PROC CVPR IEEE, P3810, DOI 10.1109/CVPR.2015.7299005; Elhayek A, 2012, PROC CVPR IEEE, P1870, DOI 10.1109/CVPR.2012.6247886; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Freeman W T, 1995, P INT WORKSH AUT FAC, P296; Gall J, 2008, PROC CVPR IEEE, P1681; Gall J, 2010, INT J COMPUT VISION, V87, P75, DOI 10.1007/s11263-008-0173-1; GANAPATHI V, 2010, PROC CVPR IEEE, P755, DOI DOI 10.1109/CVPR.2010.5540141; Gkioxari G, 2013, PROC CVPR IEEE, P3342, DOI 10.1109/CVPR.2013.429; Grauman K, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P641; Hasler N, 2009, PROC CVPR IEEE, P224, DOI 10.1109/CVPRW.2009.5206859; Jain A, 2015, LECT NOTES COMPUT SC, V9004, P302, DOI 10.1007/978-3-319-16808-1_21; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee CS, 2010, INT J COMPUT VISION, V87, P118, DOI 10.1007/s11263-009-0266-5; Li R, 2010, INT J COMPUT VISION, V87, P170, DOI 10.1007/s11263-009-0283-4; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Mori G, 2002, LECT NOTES COMPUT SC, V2352, P666; Nair V, 2010, P 27 INT C MACHINE L, P807; Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433; Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82; Plankers R, 2001, COMPUT VIS IMAGE UND, V81, P285, DOI 10.1006/cviu.2000.0891; Pons-Moll G, 2011, IEEE I CONF COMP VIS, P1243, DOI 10.1109/ICCV.2011.6126375; Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016; Ramanan D, 2005, PROC CVPR IEEE, P271; Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801; Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179; Shiratori T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964926; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Sigal L, 2012, INT J COMPUT VISION, V98, P15, DOI 10.1007/s11263-011-0493-4; Sridhar S, 2015, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2015.7298941; Sridhar S, 2013, IEEE I CONF COMP VIS, P2456, DOI 10.1109/ICCV.2013.305; Stoll C, 2011, IEEE I CONF COMP VIS, P951, DOI 10.1109/ICCV.2011.6126338; Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664; Tompson J., 2014, NIPS, P1799; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Tzionas D, 2014, LECT NOTES COMPUT SC, V8753, P277, DOI 10.1007/978-3-319-11752-2_22; Wei XL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366207; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741	62	46	47	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					501	514		10.1109/TPAMI.2016.2557779	http://dx.doi.org/10.1109/TPAMI.2016.2557779			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	27116731				2022-12-18	WOS:000395555100007
J	Tao, MW; Srinivasan, PP; Hadap, S; Rusinkiewicz, S; Malik, J; Ramamoorthi, R				Tao, Michael W.; Srinivasan, Pratul P.; Hadap, Sunil; Rusinkiewicz, Szymon; Malik, Jitendra; Ramamoorthi, Ravi			Shape Estimation from Shading, Defocus, and Correspondence Using Light-Field Angular Coherence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Light fields; 3D reconstruction; specular-free image; reflection components separation; depth cues; shape from shading	PHOTOMETRIC-STEREO; DEPTH	Light-field cameras are quickly becoming commodity items, with consumer and industrial applications. They capture many nearby views simultaneously using a single image with a micro-lens array, thereby providing a wealth of cues for depth recovery: defocus, correspondence, and shading. In particular, apart from conventional image shading, one can refocus images after acquisition, and shift one's viewpoint within the sub-apertures of the main lens, effectively obtaining multiple views. We present a principled algorithm for dense depth estimation that combines defocus and correspondence metrics. We then extend our analysis to the additional cue of shading, using it to refine fine details in the shape. By exploiting an all-in-focus image, in which pixels are expected to exhibit angular coherence, we define an optimization framework that integrates photo consistency, depth consistency, and shading consistency. We show that combining all three sources of information: defocus, correspondence, and shading, outperforms state-ofthe-art light-field depth estimation algorithms in multiple scenarios.	[Tao, Michael W.; Srinivasan, Pratul P.; Malik, Jitendra] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA; [Hadap, Sunil] Adobe, San Jose, CA 95110 USA; [Rusinkiewicz, Szymon] Princeton Univ, Dept Comp Sci, Princeton, NJ 08540 USA; [Ramamoorthi, Ravi] Univ Calif San Diego, CSE Dept, La Jolla, CA 92093 USA	University of California System; University of California Berkeley; Adobe Systems Inc.; Princeton University; University of California System; University of California San Diego	Tao, MW (corresponding author), Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA.	mtao@eecs.berkeley.edu; pratul@eecs.berkeley.edu; hadap@adobe.com; smr@cs.princeton.edu; malik@eecs.berkeley.edu; ravir@cs.ucsd.edu		Rusinkiewicz, Szymon/0000-0002-4253-2588	NSF Fellowship [DGE 1106400]; NSF [IIS-1012147, IIS-1421435]; ONR [N00014-09-1-0741, N00014-14-1-0332, N00014-15-1-2013]; Adobe; Nokia; Samsung (GRO); Google; Sony; Draper	NSF Fellowship(National Science Foundation (NSF)); NSF(National Science Foundation (NSF)); ONR(Office of Naval Research); Adobe; Nokia(Nokia Corporation); Samsung (GRO)(Samsung); Google(Google Incorporated); Sony; Draper	We thank Jong-Chyi Su for generating the synthetic images and comparisons, Weilun Sun for assisting with point cloud processing, HaeGon Jeon for generating comparison images, and Sean Arietta for setting up the 3D printer. We thank the reviewers for their careful reading and many suggestions on the paper. We acknowledge the financial support from NSF Fellowship DGE 1106400; NSF Grants IIS-1012147 and IIS-1421435; ONR grants N00014-09-1-0741, N00014-14-1-0332, and N00014-15-1-2013; funding from Adobe, Nokia, Samsung (GRO), Google (Research Award); and support by Sony and Draper to the UC San Diego Center for Visual Computing.	ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783; Barron JT, 2013, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2013.10; Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Basri R, 2001, PROC CVPR IEEE, P374; Bermano AH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2546276; Berthold K.P., 1970, TECHNICAL REPORT, P2; Bolles R., 1997, INT J COMPUT VISION, V1, P7; Chadraker M. K., 2014, P IEEE C COMP VIS PA, P2523; Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197; Chen QF, 2013, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2013.37; Criminisi A, 2005, COMPUT VIS IMAGE UND, V97, P51, DOI 10.1016/j.cviu.2004.06.001; Debevec P., 2012, P 25 ANN C COMP GRAP, P189; Durou K.-D., 2008, COMPUT VIS IMAGE UND; Fanello SR, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601223; Goldluecke B, 2013, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2013.134; Hasinoff SW, 2006, LECT NOTES COMPUT SC, V3951, P620; Heber Stefan, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P66, DOI 10.1007/978-3-642-40395-8_6; Heber S, 2014, LECT NOTES COMPUT SC, V8694, P751; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46; Janoch A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1168, DOI 10.1109/ICCVW.2011.6130382; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Johnson M. K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2553, DOI 10.1109/CVPR.2011.5995510; Kamal MH, 2015, LECT NOTES COMPUT SC, V8932, P350, DOI 10.1007/978-3-319-14612-6_26; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Kim C., 2013, ACM T GRAPHIC, V73, P1; KLARQUIST WN, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P374, DOI 10.1109/IROS.1995.525912; LEE KM, 1993, IEEE T PATTERN ANAL, V15, P815, DOI 10.1109/34.236247; Levin A, 2010, LECT NOTES COMPUT SC, V6311, P214, DOI 10.1007/978-3-642-15549-9_16; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Li JG, 2010, PROC CVPR IEEE, P2769, DOI 10.1109/CVPR.2010.5540004; Liang C.-K., 2008, ACM SIGGRAPH; LIU TY, 1992, IMAGE VISION COMPUT, V10, P46, DOI 10.1016/0262-8856(92)90083-F; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Min DB, 2013, IEEE T PATTERN ANAL, V35, P2539, DOI 10.1109/TPAMI.2013.15; Ng, 2005, LIGHT FIELD PHOTOGRA; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; Perwass C., 2012, SPIE ELECT IMAG, V8291, P8; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Sabater N., 2014, P ECCV WORKSH LIGHT, P548; Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977; Schechner YY, 2000, INT J COMPUT VISION, V39, P141, DOI 10.1023/A:1008175127327; Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526; SUBBARAO M, 1994, INT J COMPUT VISION, V13, P271, DOI 10.1007/BF02028349; Subbarao M., 1998, SPIE 3 DIMENSIONAL I, P14; Suwajanakorn S., 2012, P IEEE C COMP VIS PA; Suwajanakorn S, 2014, LECT NOTES COMPUT SC, V8692, P796, DOI 10.1007/978-3-319-10593-2_52; Tao M., 2014, P 10 EUR C COMP VIS, P673; Tao MW, 2016, IEEE T PATTERN ANAL, V38, P1155, DOI 10.1109/TPAMI.2015.2477811; Tao MW, 2015, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2015.7298804; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Vaish V, 2006, P 2006 IEEE COMP SOC, V2, P2331, DOI DOI 10.1109/CVPR.2006.244; van Doorn AJ, 2011, J VISION, V11, DOI 10.1167/11.3.21; Wang T.-C., 2015, P INT C COMP VIS; Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398; Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656; Watanabe M, 1998, INT J COMPUT VISION, V27, P203, DOI 10.1023/A:1007905828438; WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu C., 2014, P SIGGRAPH AS, V33; Yu Z, 2013, IEEE I CONF COMP VIS, P2792, DOI 10.1109/ICCV.2013.347; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhao Q, 2012, IEEE T PATTERN ANAL, V34, P1437, DOI 10.1109/TPAMI.2012.77	65	46	52	1	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					546	560		10.1109/TPAMI.2016.2554121	http://dx.doi.org/10.1109/TPAMI.2016.2554121			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	27101598	hybrid			2022-12-18	WOS:000395555100010
J	Kulkarni, K; Turaga, P				Kulkarni, Kuldeep; Turaga, Pavan			Reconstruction-Free Action Inference from Compressive Imagers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Compressive sensing; reconstruction-free; action recognition	ACTION RECOGNITION; CORRELATION FILTERS; LOCALIZATION; HISTOGRAMS; MODELS	Persistent surveillance from camera networks, such as at parking lots, UAVs, etc., often results in large amounts of video data, resulting in significant challenges for inference in terms of storage, communication and computation. Compressive cameras have emerged as a potential solution to deal with the data deluge issues in such applications. However, inference tasks such as action recognition require high quality features which implies reconstructing the original video data. Much work in compressive sensing (CS) theory is geared towards solving the reconstruction problem, where state-of-the-art methods are computationally intensive and provide low-quality results at high compression rates. Thus, reconstruction-free methods for inference are much desired. In this paper, we propose reconstruction-free methods for action recognition from compressive cameras at high compression ratios of 100 and above. Recognizing actions directly from CS measurements requires features which are mostly nonlinear and thus not easily applicable. This leads us to search for such properties that are preserved in compressive measurements. To this end, we propose the use of spatio-temporal smashed filters, which are compressive domain versions of pixel-domain matched filters. We conduct experiments on publicly available databases and show that one can obtain recognition rates that are comparable to the oracle method in uncompressed setup, even for high compression ratios.	[Kulkarni, Kuldeep; Turaga, Pavan] Arizona State Univ, Sch Arts Media & Engn, Tempe, AZ 85281 USA; [Kulkarni, Kuldeep; Turaga, Pavan] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA	Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe	Kulkarni, K; Turaga, P (corresponding author), Arizona State Univ, Sch Arts Media & Engn, Tempe, AZ 85281 USA.; Kulkarni, K; Turaga, P (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.	kkulkar1@asu.edu; pturaga@asu.edu	Turaga, Pavan/W-6186-2019	Turaga, Pavan/0000-0002-5263-5943	ONR [N00014-12-1-0124, Z868302]	ONR(Office of Naval Research)	This work was supported by ONR Grant N00014-12-1-0124 sub award Z868302. The authors would like to thank H. Braun for their useful suggestions and comments.	Achlioptas D., 2001, P ACM SIGMOD SIGACT, P274, DOI DOI 10.1145/375551.375608; Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Ali S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2608, DOI 10.1109/ICPR.2010.639; Blank M, 2005, IEEE I CONF COMP VIS, P1395; BRACEWELL RN, 1993, ELECTRON LETT, V29, P304, DOI 10.1049/el:19930207; Calderbank Robert, 2009, PREPRINT; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Cevher V, 2008, LECT NOTES COMPUT SC, V5303, P155, DOI 10.1007/978-3-540-88688-4_12; Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Davenport M, 2007, COMPUTAT IMAG 5, V6498, P142; Derpanis KG, 2010, PROC CVPR IEEE, P1990, DOI 10.1109/CVPR.2010.5539874; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Hennings-Yeomans PH, 2007, IEEE T INF FOREN SEC, V2, P613, DOI 10.1109/TIFS.2007.902039; Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332; Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330; Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31; Johnson W.B., 1982, C MOD AN PROB NEW HA; Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68; Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167; Klaser A., 2008, P BRIT MACH VIS C; Kliper-Gross O, 2012, LECT NOTES COMPUT SC, V7577, P256, DOI 10.1007/978-3-642-33783-3_19; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Kulkarni K, 2012, IEEE IMAGE PROC, P1417, DOI 10.1109/ICIP.2012.6467135; Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472; Needell D, 2010, COMMUN ACM, V53, P93, DOI 10.1145/1859204.1859229; Ozer B, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P61, DOI 10.1109/HUMO.2000.897372; Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Sankaranarayanan A. C., 2012, P IEEE INT C COMP PH, P1, DOI DOI 10.1109/ICCPHOT.2012.6215212; Sankaranarayanan AC, 2010, LECT NOTES COMPUT SC, V6311, P129, DOI 10.1007/978-3-642-15549-9_10; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156; Shechtman E, 2005, PROC CVPR IEEE, P405; Shi F, 2013, PROC CVPR IEEE, P2595, DOI 10.1109/CVPR.2013.335; Sims SRF, 2004, OPT ENG, V43, P1705, DOI 10.1117/1.1767195; Thirumalai V, 2013, J VIS COMMUN IMAGE R, V24, P649, DOI 10.1016/j.jvcir.2011.12.004; Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341; Wakin MB, 2006, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2006.312577; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Yeo CH, 2008, IEEE T CIRC SYST VID, V18, P1006, DOI 10.1109/TCSVT.2008.927112; Zhu XX, 2007, LECT NOTES COMPUT SC, V4642, P77	43	46	47	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					772	784		10.1109/TPAMI.2015.2469288	http://dx.doi.org/10.1109/TPAMI.2015.2469288			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26353363	Green Submitted			2022-12-18	WOS:000372549700013
J	Huang, D; Cabral, R; De la Torre, F				Huang, Dong; Cabral, Ricardo; De la Torre, Fernando			Robust Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robust methods; errors in variables; intra-sample outliers; missing data	FACE RECOGNITION; DISCRIMINANT-ANALYSIS; FRAMEWORK	Discriminative methods (e.g., kernel regression, SVM) have been extensively used to solve problems such as object recognition, image alignment and pose estimation from images. These methods typically map image features (X) to continuous (e.g., pose) or discrete (e.g., object category) values. A major drawback of existing discriminative methods is that samples are directly projected onto a subspace and hence fail to account for outliers common in realistic training sets due to occlusion, specular reflections or noise. It is important to notice that existing discriminative approaches assume the input variables X to be noise free. Thus, discriminative methods experience significant performance degradation when gross outliers are present. Despite its obvious importance, the problem of robust discriminative learning has been relatively unexplored in computer vision. This paper develops the theory of robust regression (RR) and presents an effective convex approach that uses recent advances on rank minimization. The framework applies to a variety of problems in computer vision including robust linear discriminant analysis, regression with missing data, and multi-label classification. Several synthetic and real examples with applications to head pose estimation from images, image and video classification and facial attribute classification with missing data are used to illustrate the benefits of RR.	[Huang, Dong; Cabral, Ricardo; De la Torre, Fernando] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Huang, D; Cabral, R; De la Torre, F (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	dghuang@andrew.cmu.edu; rscabral@cs.cmu.edu; ftorre@cs.cmu.edu			Portuguese Foundation for Science and Technology through CMU-Portugal program [FCT/CMU/P11]	Portuguese Foundation for Science and Technology through CMU-Portugal program	The second author was supported by the Portuguese Foundation for Science and Technology through the CMU-Portugal program under the project FCT/CMU/P11. The authors would like to thank Francisco Vicente for the assistance with the experiment on the TRECVID 2011 Dataset.	Adcock RJ, 1878, ANALYST, V5, P53, DOI DOI 10.2307/2635758; [Anonymous], 2004, EMERGING TOPICS COMP; Cabral R., 2011, P ADV NEUR INF PROC, P1185; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528; Choi S., 1997, J COMPUT VISION, V24, P271, DOI DOI 10.1023/A:1007927408552; CHORK CY, 1992, J GEOCHEM EXPLOR, V43, P191, DOI 10.1016/0375-6742(92)90105-H; Croux C, 2001, CAN J STAT, V29, P473, DOI 10.2307/3316042; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184; Fidler S, 2006, IEEE T PATTERN ANAL, V28, P337, DOI 10.1109/TPAMI.2006.46; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gillard J. W., 2005, METHOD MOMENTS ESTIM; Gillard J.W., 2006, HIST OVERVIEW LINEAR; GOLUB GH, 1980, SIAM J NUMER ANAL, V17, P883, DOI 10.1137/0717073; Gross R., 2007, TR0708 CMU ROB I; Hawkins DM, 1997, J AM STAT ASSOC, V92, P136, DOI 10.2307/2291457; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; He XM, 2000, J MULTIVARIATE ANAL, V72, P151, DOI 10.1006/jmva.1999.1857; Huang D, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995683; Huber P., 1981, ROBUST STAT; Huffel S., 1991, TOTAL LEAST SQUARES; Jia HJ, 2009, PROC CVPR IEEE, P136, DOI 10.1109/CVPRW.2009.5206862; Ke QF, 2005, PROC CVPR IEEE, P739; Kim S. J., 2005, P NEUR INF PROC SYST, P659; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Kummell CH, 1879, ANALYST, V6, P97, DOI DOI 10.2307/2635646; Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830; Li FX, 2012, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2012.6247956; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Lindley D. V., 1947, J ROY STAT SOC, V9, P218, DOI DOI 10.2307/2984115; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Marlin B. M., 2008, THESIS U TORONTO TOR; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Matei BC, 2006, IEEE T PATTERN ANAL, V28, P1537, DOI 10.1109/TPAMI.2006.205; PLACKETT RL, 1950, BIOMETRIKA, V37, P149, DOI 10.1093/biomet/37.1-2.149; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; Rousseeuw PJ, 2003, ROBUST REGRESSION OU; Sermanet P., 2014, P INT C LEARN REPR, P16; Snoek C.G., 2006, P 14 ANN ACM INT C M, P421, DOI DOI 10.1145/1180639.1180727; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Wald A, 1940, ANN MATH STAT, V11, P284, DOI 10.1214/aoms/1177731868; Wang H, 2010, LECT NOTES COMPUT SC, V6316, P126, DOI 10.1007/978-3-642-15567-3_10; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhang Yu., 2010, P ADV NEURAL INFORM, P2568; Zhang ZD, 2011, IEEE I CONF COMP VIS, P1347, DOI 10.1109/ICCV.2011.6126388	50	46	47	0	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					363	375		10.1109/TPAMI.2015.2448091	http://dx.doi.org/10.1109/TPAMI.2015.2448091			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761740				2022-12-18	WOS:000369989600013
J	Su, ZY; Wang, YL; Shi, R; Zeng, W; Sun, J; Luo, F; Gu, XF				Su, Zhengyu; Wang, Yalin; Shi, Rui; Zeng, Wei; Sun, Jian; Luo, Feng; Gu, Xianfeng			Optimal Mass Transport for Shape Matching and Comparison	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimal mass transport; shape representation; surface matching; shape space	REGISTRATION; ALGORITHMS; MANIFOLDS; METRICS; SPACE	Surface based 3D shape analysis plays a fundamental role in computer vision and medical imaging. This work proposes to use optimal mass transport map for shape matching and comparison, focusing on two important applications including surface registration and shape space. The computation of the optimal mass transport map is based on Monge-Brenier theory, in comparison to the conventional method based on Monge-Kantorovich theory, this method significantly improves the efficiency by reducing computational complexity from O(n(2)) to O(n). For surface registration problem, one commonly used approach is to use conformal map to convert the shapes into some canonical space. Although conformal mappings have small angle distortions, they may introduce large area distortions which are likely to cause numerical instability thus resulting failures of shape analysis. This work proposes to compose the conformal map with the optimal mass transport map to get the unique area-preserving map, which is intrinsic to the Riemannian metric, unique, and diffeomorphic. For shape space study, this work introduces a novel Riemannian framework, Conformal Wasserstein Shape Space, by combing conformal geometry and optimal mass transport theory. In our work, all metric surfaces with the disk topology are mapped to the unit planar disk by a conformal mapping, which pushes the area element on the surface to a probability measure on the disk. The optimal mass transport provides a map from the shape space of all topological disks with metrics to the Wasserstein space of the disk and the pullback Wasserstein metric equips the shape space with a Riemannian metric. We validate our work by numerous experiments and comparisons with prior approaches and the experimental results demonstrate the efficiency and efficacy of our proposed approach.	[Su, Zhengyu; Shi, Rui; Gu, Xianfeng] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA; [Wang, Yalin] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85281 USA; [Zeng, Wei] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA; [Sun, Jian] Tsinghua Univ, Ctr Math Sci, Beijing 100084, Peoples R China; [Luo, Feng] Rutgers State Univ, Dept Math, New Brunswick, NJ 08901 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; Arizona State University; Arizona State University-Tempe; State University System of Florida; Florida International University; Tsinghua University; Rutgers State University New Brunswick	Su, ZY (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.	zhsu@cs.stonybrook.edu; ylwang@asu.edu; rshi@cs.stonybrook.edu; wzeng@cs.fiu.edu; sunjian0813@gmail.com; fluo@math.rutgers.edu; gu@cs.stonybrook.edu	Zeng, Wei/J-6474-2014	Wang, Yalin/0000-0002-6241-735X; Gu, Xianfeng/0000-0001-8226-5851	NSF [DMS-1418255, DMS-1221339, DMS-1413417, IIS-1421165]; AFOSR [FA9550-10-1-0294]; NSFC [61328206]; NIH [R21AG043760]; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [U54EB020403] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON AGING [R21AG043760] Funding Source: NIH RePORTER	NSF(National Science Foundation (NSF)); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); NSFC(National Natural Science Foundation of China (NSFC)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL INSTITUTE ON AGING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	This work was partially supported by NSF DMS-1418255, NSF DMS-1221339, NSF DMS-1413417, NSF IIS-1421165, AFOSR FA9550-10-1-0294, NSFC 61328206, NIH R21AG043760. Z. Su is the corresponding author of the article.	Angenent S, 1999, LECT NOTES COMPUT SC, V1679, P271; [Anonymous], 2005, CONVEX POLYHEDRA; Bauer M., 2010, ARXIV10093616; Bauer M, 2012, SIAM J IMAGING SCI, V5, P244, DOI 10.1137/100807983; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Bonnotte Nicolas, 2012, ARXIV12051099, P1; Boyer DM, 2011, P NATL ACAD SCI USA, V108, P18221, DOI 10.1073/pnas.1112822108; BRENIER Y, 1991, COMMUN PUR APPL MATH, V44, P375, DOI 10.1002/cpa.3160440402; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Bronstein Michael M, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1065, DOI 10.1109/TPAMI.2010.210; de Goes F., 2012, SIGGRAPH ASIA, V31; de Goes F, 2011, COMPUT GRAPH FORUM, V30, P1593, DOI 10.1111/j.1467-8659.2011.02033.x; Dominitz A, 2010, IEEE T VIS COMPUT GR, V16, P419, DOI 10.1109/TVCG.2009.64; Dongmei Zhang, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P524, DOI 10.1109/CVPR.1999.784731; Ekman P., 2002, FACIAL ACTION CODING; Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396; Gu X.D., 2008, COMPUTATIONAL CONFOR; Gu XF, 2004, IEEE T MED IMAGING, V23, P949, DOI 10.1109/TMI.2004.831226; Gu Xianfeng, 2013, ARXIV13094175; Gu XD, 2011, COMPUT METH FUNCT TH, V11, P747; Gupta S, 2010, INT J COMPUT VISION, V90, P331, DOI 10.1007/s11263-010-0360-8; Haker S, 2004, INT J COMPUT VISION, V60, P225, DOI 10.1023/B:VISI.0000036836.66311.97; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; Holland D, 2009, P NATL ACAD SCI USA, V106, P20954, DOI 10.1073/pnas.0906053106; Hurdal MK, 2009, NEUROIMAGE, V45, pS86, DOI 10.1016/j.neuroimage.2008.10.045; Jermyn IH, 2012, LECT NOTES COMPUT SC, V7576, P804, DOI 10.1007/978-3-642-33715-4_58; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; KANTOROVICH L. V., 2006, J MATH SCI-U TOKYO, V133, P1383, DOI [DOI 10.1007/S10958-006-0050-9, 10.1007/s10958-006-0050-9]; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Koehl P, 2014, IEEE T PATTERN ANAL, V36, P466, DOI 10.1109/TPAMI.2013.139; Kurtek S, 2013, COMPUT GRAPH FORUM, V32, P429, DOI 10.1111/cgf.12063; Kurtek S, 2012, IEEE T PATTERN ANAL, V34, P1717, DOI 10.1109/TPAMI.2011.233; Lipman Y., 2009, ACM T GRAPHIC, V28, P3; Lombaert H, 2013, IEEE T PATTERN ANAL, V35, P2143, DOI 10.1109/TPAMI.2012.276; Luo F, 2013, ARXIV13025472; Lvy B., 2002, P SIGGRAPH; Merigot Q, 2011, COMPUT GRAPH FORUM, V30, P1583, DOI 10.1111/j.1467-8659.2011.02032.x; Pantazis D, 2010, NEUROIMAGE, V49, P2479, DOI 10.1016/j.neuroimage.2009.09.027; rachev s.t., 1998, PROB APPL S, VII, DOI 10.1007/b98894; Rehman TU, 2009, MED IMAGE ANAL, V13, P931, DOI 10.1016/j.media.2008.10.008; Schoen R., 1997, P C LECT NOT GEOM TO, VII; SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506; Sharon E, 2004, PROC CVPR IEEE, P350; Shi J, 2013, NEUROIMAGE, V78, P111, DOI 10.1016/j.neuroimage.2013.04.018; Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184; Srivastava A, 2009, IEEE T PATTERN ANAL, V31, P1616, DOI 10.1109/TPAMI.2008.223; Styner M, 2005, P NATL ACAD SCI USA, V102, P4872, DOI 10.1073/pnas.0501117102; Su ZY, 2013, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2013.290; THOMPSON PM, 2002, COMPUTING VISUALIZAT, V5, P1; Villani C., 2003, TOPICS OPTIMAL TRANS; Wang Y., 2008, INT J COMPUT VIS, V76; Wang YL, 2012, IEEE T MED IMAGING, V31, P251, DOI 10.1109/TMI.2011.2168233; Xu Zheng, 2008, FLY ASH, V3, P17; Younes L, 2008, REND LINCEI-MAT APPL, V19, P25; Younes L, 2012, IMAGE VISION COMPUT, V30, P389, DOI 10.1016/j.imavis.2011.09.009; Zeng W, 2010, IEEE T PATTERN ANAL, V32, P662, DOI 10.1109/TPAMI.2009.201; Zhao X, 2013, IEEE T VIS COMPUT GR, V19, P2838, DOI 10.1109/TVCG.2013.135; Zhong JD, 2010, NEUROIMAGE, V49, P355, DOI 10.1016/j.neuroimage.2009.08.026; Zhu L, 2003, LECT NOTES COMPUT SC, V2879, P277	64	46	47	2	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2246	2259		10.1109/TPAMI.2015.2408346	http://dx.doi.org/10.1109/TPAMI.2015.2408346			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440265	Green Accepted			2022-12-18	WOS:000362411000008
J	Carreira, J; Caseiro, R; Batista, J; Sminchisescu, C				Carreira, Joao; Caseiro, Rui; Batista, Jorge; Sminchisescu, Cristian			Free-Form Region Description with Second-Order Pooling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Recognition; image descriptors; second-order statistics; segmentation; regression; pooling; differential geometry	RIEMANNIAN FRAMEWORK; RECOGNITION; CLASSIFICATION; FEATURES; SCALE; SEGMENTATION; CONTOURS; TEXTURE; KERNEL; SHAPES	Semantic segmentation and object detection are nowadays dominated by methods operating on regions obtained as a result of a bottom-up grouping process (segmentation) but use feature extractors developed for recognition on fixed-form (e.g. rectangular) patches, with full images as a special case. This is most likely suboptimal. In this paper we focus on feature extraction and description over free-form regions and study the relationship with their fixed-form counterparts. Our main contributions are novel pooling techniques that capture the second-order statistics of local descriptors inside such free-form regions. We introduce second-order generalizations of average and max-pooling that together with appropriate non-linearities, derived from the mathematical structure of their embedding space, lead to state-of-the-art recognition performance in semantic segmentation experiments without any type of local feature coding. In contrast, we show that codebook-based local feature coding is more important when feature extraction is constrained to operate over regions that include both foreground and large portions of the background, as typical in image classification settings, whereas for high-accuracy localization setups, second-order pooling over free-form regions produces results superior to those of the winning systems in the contemporary semantic segmentation challenges, with models that are much faster in both training and testing.	[Carreira, Joao] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA; [Carreira, Joao; Caseiro, Rui; Batista, Jorge] Univ Coimbra, Inst Syst & Robot, Coimbra, Portugal; [Sminchisescu, Cristian] Lund Univ, Dept Math, Fac Engn, Lund, Sweden; [Sminchisescu, Cristian] Romanian Acad, Inst Math, Bucharest, Romania	University of California System; University of California Berkeley; Universidade de Coimbra; Lund University; Institute of Mathematics of the Romanian Academy; Romanian Academy of Sciences; University of Bucharest	Carreira, J (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.	carreira@eecs.berkeley.edu; ruicaseiro@isr.uc.pt; batista@isr.uc.pt; cristian.sminchisescu@math.lth.se	Batista, Jorge/A-4196-2011	Batista, Jorge/0000-0003-2387-5961	FCT [SFRH/BPD/84194/2012, SFRH/BD74152/2010, PTDC/EEA-CRO/122812/2010]; CNCS-UEFISCDI [CT-ERC-2012-1, PCE-2011-3-0438]	FCT(Portuguese Foundation for Science and TechnologyEuropean Commission); CNCS-UEFISCDI(Consiliul National al Cercetarii Stiintifice (CNCS)Unitatea Executiva pentru Finantarea Invatamantului Superior, a Cercetarii, Dezvoltarii si Inovarii (UEFISCDI))	The authors would like to thank the support, in part, by the FCT under fellowships SFRH/BPD/84194/2012, SFRH/BD74152/2010 and project PTDC/EEA-CRO/122812/2010 and CNCS-UEFISCDI under CT-ERC-2012-1, PCE-2011-3-0438. J. Carreira and C. Sminchisescu. are the corresponding authors.	Arbelaez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077; Arbelaez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707; Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996; Belongie S., 2000, P ADV NEUR INF PROC, P509; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Boix X, 2012, INT J COMPUT VISION, V96, P83, DOI 10.1007/s11263-011-0449-8; Boureau Y.L., 2010, P 27 INT C MACH LEAR, P111; Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555; Caputo B., 2010, ELECT LETT COMPUT VI, V8, P15, DOI DOI 10.5565/rev/elcvia.350; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Carreira J, 2012, INT J COMPUT VISION, V98, P243, DOI 10.1007/s11263-011-0507-2; Caseiro R, 2011, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2011.6126218; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Davies PI, 2003, SIAM J MATRIX ANAL A, V25, P464, DOI 10.1137/S0895479802410815; do Carmo M. P., 1992, RIEMANNIAN GEOMETRY; Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445; Everingham M., 2012, PASCAL VISUAL OBJECT; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Farquhar J., 2005, IMPROVING BAG KEYPOI; Fei-Fei L., 2007, COMPUTER VISION IMAG, P178; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; Fidler S, 2013, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2013.423; Fulkerson B., 2009, IEEE I CONF COMP VIS, P670, DOI [10.1109/ICCV.2009.5459175, DOI 10.1109/ICCV.2009.5459175]; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727; Hariharan B, 2012, LECT NOTES COMPUT SC, V7575, P459, DOI 10.1007/978-3-642-33765-9_33; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Ion A., 2011, P ADV NEUR INF PROC, P40; Ion A, 2014, INT J COMPUT VISION, V107, P40, DOI 10.1007/s11263-013-0663-7; Joachims T., 2006, P 12 ACM SIGKDD INT, V06, P217, DOI DOI 10.1145/1150402.1150429; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Koniusz P, 2011, IEEE IMAGE PROC, P661; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Ladicky L, 2010, LECT NOTES COMPUT SC, V6314, P424, DOI 10.1007/978-3-642-15561-1_31; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Li FX, 2013, PROC CVPR IEEE, P3302, DOI 10.1109/CVPR.2013.424; Li ZY, 2013, IEEE I CONF COMP VIS, P2136, DOI 10.1109/ICCV.2013.454; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maire M, 2011, IEEE I CONF COMP VIS, P2142, DOI 10.1109/ICCV.2011.6126490; Malisiewicz Tomasz, 2008, P IEEE C COMP VIS PA, P1; Nakayama H, 2010, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2010.5539921; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Picard D, 2011, IEEE IMAGE PROC, P669, DOI 10.1109/ICIP.2011.6116641; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Sanchez J, 2012, PATTERN RECOGN LETT, V33, P2216, DOI 10.1016/j.patrec.2012.07.019; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sminchisescu C, 2009, NEURIPS, P135; Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z; Tuytelaars T, 2011, IEEE I CONF COMP VIS, P1824, DOI 10.1109/ICCV.2011.6126449; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Xia W, 2013, IEEE I CONF COMP VIS, P2176, DOI 10.1109/ICCV.2013.271; Yadollahpour P, 2013, PROC CVPR IEEE, P1923, DOI 10.1109/CVPR.2013.251	68	46	47	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1177	1189		10.1109/TPAMI.2014.2361137	http://dx.doi.org/10.1109/TPAMI.2014.2361137			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357341				2022-12-18	WOS:000354377100005
J	Zhou, N; Fan, JP				Zhou, Ning; Fan, Jianping			Jointly Learning Visually Correlated Dictionaries for Large-Scale Visual Recognition Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Joint dictionary learning; common visual atoms; category-specific visual atoms; visual tree; large-scale visual recognition	IMAGE; CLASSIFICATION	Learning discriminative dictionaries for image content representation plays a critical role in visual recognition. In this paper, we present a joint dictionary learning (JDL) algorithm which exploits the inter-category visual correlations to learn more discriminative dictionaries. Given a group of visually correlated categories, JDL simultaneously learns one common dictionary and multiple category-specific dictionaries to explicitly separate the shared visual atoms from the category-specific ones. The problem of JDL is formulated as a joint optimization with a discrimination promotion term according to the Fisher discrimination criterion. A visual tree method is developed to cluster a large number of categories into a set of disjoint groups, so that each of them contains a reasonable number of visually correlated categories. The process of image category clustering helps JDL to learn better dictionaries for classification by ensuring that the categories in the same group are of strong visual correlations. Also, it makes JDL to be computationally affordable in large-scale applications. Three classification schemes are adopted to make full use of the dictionaries learned by JDL for visual content representation in the task of image categorization. The effectiveness of the proposed algorithms has been evaluated using two image databases containing 17 and 1,000 categories, respectively.	[Zhou, Ning; Fan, Jianping] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA	University of North Carolina; University of North Carolina Charlotte	Zhou, N (corresponding author), Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.	nzhou@uncc.edu; jfan@uncc.edu			National Science Foundation of China [61272285]; Doctoral Program of Higher Education of China [20126101110022]; National High-Technology Program of China (863 Program) [2014AA012301]; Program for Changjiang Scholars and Innovative Research Team in University [IRT13090]	National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Doctoral Program of Higher Education of China(Specialized Research Fund for the Doctoral Program of Higher Education (SRFDP)); National High-Technology Program of China (863 Program)(National High Technology Research and Development Program of China); Program for Changjiang Scholars and Innovative Research Team in University(Program for Changjiang Scholars & Innovative Research Team in University (PCSIRT))	The authors would like to thank the reviewers for their insightful comments and suggestions which helped to make this paper more readable. This research is partly supported by National Science Foundation of China under Grant 61272285, Doctoral Program of Higher Education of China (Grant No. 20126101110022), National High-Technology Program of China (863 Program, Grant No.2014AA012301), and Program for Changjiang Scholars and Innovative Research Team in University (No. IRT13090).	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Aly M., 2011, P INT C IM PROC SEPT; [Anonymous], 2011, P NIPS; Barthe E, 2009, POLICE PRACT RES, V10, P255, DOI 10.1080/15614260802381067; Bengio Samy, 2010, ADV NEURAL INFORM PR, V1, P163, DOI [10.5555/2997189.2997208, DOI 10.5555/2997189.2997208]; Bergamo A, 2012, PROC CVPR IEEE, P3085, DOI 10.1109/CVPR.2012.6248040; Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319; BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963; Bousquet O., 2008, ADV NEURAL INFORM PR, P161, DOI DOI 10.7751/mitpress/8996.003.0015; Chiang C.-K., 2011, P IEEE C COMP VIS; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6; Deng Jia, 2011, ADV NEURAL INFORM PR, V1, P567, DOI [10.5555/2986459.2986523, DOI 10.5555/2986459.2986523]; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Engan K, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P1, DOI 10.1109/ISCAS.1999.779928; Fan JP, 2008, IEEE T IMAGE PROCESS, V17, P407, DOI 10.1109/TIP.2008.916999; Fan JP, 2012, IEEE T MULTIMEDIA, V14, P1414, DOI 10.1109/TMM.2012.2197604; Fan JP, 2011, IEEE T IMAGE PROCESS, V20, P837, DOI 10.1109/TIP.2010.2073476; Fan JP, 2005, PATTERN RECOGN, V38, P865, DOI 10.1016/j.patcog.2004.07.011; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Griffin Gregory, 2008, P IEEE C COMP VIS PA, DOI [10.1109/CVPR.2008.4587410, DOI 10.1109/CVPR.2008.4587410]; Huang K., 2007, ADV NEURAL INFORM PR, V19, P609; Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lee H, 2016, ADV NEURAL INFORM PR, V19; Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2008, P IEEE C COMP VIS PA; Mairal J., 2008, ADV NEURAL INFORM PR, P1033; Mairal J, 2008, LECT NOTES COMPUT SC, V5304, P43, DOI 10.1007/978-3-540-88690-7_4; Marszalek M, 2008, LECT NOTES COMPUT SC, V5305, P479, DOI 10.1007/978-3-540-88693-8_35; Ng AY, 2002, ADV NEUR IN, V14, P849; Nilsback M.-E., 2008, P IND C COMP VIS GRA; Perronnin F, 2012, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2012.6248090; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964; Sanchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504; Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang A. Y., 2010, ARXIV E PRINTS; Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yang L., 2008, P IEEE C COMP VIS PA; Yang M., 2011, P IEEE INT C COMP VI; Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967; Zelnik-Manor Lihi, 2005, P ADV NEUR INF PROC, P1601; Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]; Zhang ST, 2012, MED IMAGE ANAL, V16, P1385, DOI 10.1016/j.media.2012.07.007; Zhang W., 2009, ICML, P156; Zhou N, 2012, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR.2012.6248091; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11	59	46	48	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					715	730		10.1109/TPAMI.2013.189	http://dx.doi.org/10.1109/TPAMI.2013.189			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353195				2022-12-18	WOS:000334109000007
J	El Shafey, L; McCool, C; Wallace, R; Marcel, S				El Shafey, Laurent; McCool, Chris; Wallace, Roy; Marcel, Sebastien			A Scalable Formulation of Probabilistic Linear Discriminant Analysis: Applied to Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						PLDA; probablistic model; expectation maximization; face verification		In this paper, we present a scalable and exact solution for probabilistic linear discriminant analysis (PLDA). PLDA is a probabilistic model that has been shown to provide state-of-the-art performance for both face and speaker recognition. However, it has one major drawback: At training time estimating the latent variables requires the inversion and storage of a matrix whose size grows quadratically with the number of samples for the identity (class). To date, two approaches have been taken to deal with this problem, to 1) use an exact solution that calculates this large matrix and is obviously not scalable with the number of samples or 2) derive a variational approximation to the problem. We present a scalable derivation which is theoretically equivalent to the previous nonscalable solution and thus obviates the need for a variational approximation. Experimentally, we demonstrate the efficacy of our approach in two ways. First, on labeled faces in the wild, we illustrate the equivalence of our scalable implementation with previously published work. Second, on the large Multi-PIE database, we illustrate the gain in performance when using more training samples per identity (class), which is made possible by the proposed scalable formulation of PLDA.	[El Shafey, Laurent; McCool, Chris; Wallace, Roy; Marcel, Sebastien] Idiap Res Inst, CH-1920 Martigny, Switzerland; [El Shafey, Laurent] Ecole Polytech Fed Lausanne, CH-1920 Martigny, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	El Shafey, L (corresponding author), Idiap Res Inst, POB 592,Rue Marconi 19, CH-1920 Martigny, Switzerland.	laurent.el-shafey@idiap.ch; christopher.mccool@idiap.ch; roy.wallace@idiap.ch; sebastien.marcel@idiap.ch		Marcel, Sebastien/0000-0002-2497-9140; McCool, Chris/0000-0002-0577-1299	European Community [238803, 257289]	European Community(European Commission)	The research leading to these results has received funding from the European Community's Seventh Framework Programme (FP7) under grant agreements 238803 (BBfor2) and 257289 (TABULA RASA).	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Bailly-Bailliere E, 2003, LECT NOTES COMPUT SC, V2688, P625; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Guillaumin Matthieu, 2009, P INT C COMP VIS; Huang Gary B., 2007, 0749 U MASS; Kisku DR, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P63, DOI 10.1109/AUTOID.2007.380594; Li P., 2010, ADV FACE IMAGE ANAL; Li P, 2012, IEEE T PATTERN ANAL, V34, P144, DOI 10.1109/TPAMI.2011.104; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Prince SJD, 2007, IEEE I CONF COMP VIS, P1751; Tan X, 2007, P 3 INT C AN MOD FAC; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; [No title captured]	14	46	48	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1788	1794		10.1109/TPAMI.2013.38	http://dx.doi.org/10.1109/TPAMI.2013.38			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23682003	Green Submitted			2022-12-18	WOS:000319060600019
J	Zhang, XY; Liu, CL				Zhang, Xu-Yao; Liu, Cheng-Lin			Writer Adaptation with Style Transfer Mapping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Writer adaptation; style transfer mapping; handwriting recognition	ONLINE; RECOGNITION; CLASSIFICATION	Adapting a writer-independent classifier toward the unique handwriting style of a particular writer has the potential to significantly increase accuracy for personalized handwriting recognition. This paper proposes a novel framework of style transfer mapping (STM) for writer adaptation. The STM is a writer-specific class-independent feature transformation which has a closed-form solution. After style transfer mapping, the data of different writers are projected onto a style-free space, where the writer-independent classifier needs no change to classify the transformed data and can achieve significantly higher accuracy. The framework of STM can be combined with different types of classifiers for supervised, unsupervised, and semi-supervised adaptation, where writer-specific data can be either labeled or unlabeled and need not cover all classes. In this paper, we combine STM with the state-of-the-art classifiers for large-category Chinese handwriting recognition: learning vector quantization (LVQ) and modified quadratic discriminant function (MQDF). Experiments on the online Chinese handwriting database CASIA-OLHWDB demonstrate that STM-based adaptation is very efficient and effective in improving classification accuracy. Semi-supervised adaptation achieves the best performance, while unsupervised adaptation is even better than supervised adaptation. On handwritten text data, semi-supervised adaptation achieves error reduction rates 31.95 and 25.00 percent by LVQ and MQDF, respectively.	[Zhang, Xu-Yao; Liu, Cheng-Lin] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Zhang, XY (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.	xyz@nlpr.ia.ac.cn; liucl@nlpr.ia.ac.cn			National Basic Research Program of China (973 Program) [2012CB316302]; National Natural Science Foundation of China (NSFC) [60825301, 60933010]; Chinese Academy of Sciences [XDA06030300]	National Basic Research Program of China (973 Program)(National Basic Research Program of China); National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Chinese Academy of Sciences(Chinese Academy of Sciences)	This work was supported in part by the National Basic Research Program of China (973 Program) Grant 2012CB316302, the National Natural Science Foundation of China (NSFC) Grants 60825301 and 60933010, and the Strategic Priority Research Program of the Chinese Academy of Sciences (Grant XDA06030300).	Aksela M, 2007, PATTERN RECOGN LETT, V28, P136, DOI 10.1016/j.patrec.2006.06.016; Arora A, 2011, PROC INT CONF DOC, P1105, DOI 10.1109/ICDAR.2011.223; Ball G., 2008, P INT C FRONT HANDWR, P529; Ball Gregory R., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P26, DOI 10.1109/ICDAR.2009.249; Bishop, 1995, NEURAL NETWORKS PATT; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Brakensiek A., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P486, DOI 10.1109/ICDAR.2001.953837; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chellapilla K., 2006, P INT WORKSH FRONT H, P423; Connell SD, 2002, IEEE T PATTERN ANAL, V24, P329, DOI 10.1109/34.990135; Ding K., 2009, P INT C DOC AN REC, P531; Frinken Volkmar, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P31, DOI 10.1109/ICDAR.2009.18; Frinken V, 2011, PROC INT CONF DOC, P314, DOI 10.1109/ICDAR.2011.71; Haddad L, 2011, PROC INT CONF DOC, P284, DOI 10.1109/ICDAR.2011.65; Huaigu Cao, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1091, DOI 10.1109/ICDAR.2009.77; Huang GB, 2012, J MACH LEARN RES, V13, P363; Jin LW, 2010, NEUROCOMPUTING, V73, P1614, DOI 10.1016/j.neucom.2009.11.039; Jin XB, 2010, PATTERN RECOGN, V43, P2428, DOI 10.1016/j.patcog.2010.01.013; Kai Ding, 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P559, DOI 10.1109/ICFHR.2010.92; KELLY M. G., 1999, P 5 ACM SIGKDD INT C, P367, DOI DOI 10.1145/312129.312285; Kienzle W., 2006, P 23 INT C MACH LEAR, P457, DOI DOI 10.1145/1143844.1143902; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LaViola JJ, 2007, IEEE T PATTERN ANAL, V29, P1917, DOI 10.1109/TPAMI.2007.1109; LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010; Liu C.-L., 2006, P 10 IWFHR, P217; Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17; Liu CL, 2004, IEEE T NEURAL NETWOR, V15, P430, DOI 10.1109/TNN.2004.824263; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Long T, 2008, PATTERN RECOGN, V41, P2916, DOI 10.1016/j.patcog.2008.02.009; Matic N., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P187, DOI 10.1109/ICDAR.1993.395752; Mouchere H, 2007, INT J PATTERN RECOGN, V21, P99, DOI 10.1142/S0218001407005326; NAGY G, 1966, IEEE T INFORM THEORY, V12, P215, DOI 10.1109/TIT.1966.1053864; Nosary A, 2004, PATTERN RECOGN, V37, P385, DOI 10.1016/S0031-3203(03)00185-7; Oudot L., 2005, ELECT LETT COMPUTER, V5, P87; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Platt JC, 1997, ADV NEUR IN, V9, P765; Platt JC, 2000, ADV NEUR IN, P61; Rodriguez-Serrano JA, 2010, PATTERN RECOGN LETT, V31, P742, DOI 10.1016/j.patrec.2010.01.007; Sarkar P, 2005, IEEE T PATTERN ANAL, V27, P88, DOI 10.1109/TPAMI.2005.18; Sato A, 1996, ADV NEUR IN, V8, P423; Szummer M., 2006, P INT WORKSH FRONT H; Takebe H, 2002, LECT NOTES COMPUT SC, V2423, P134; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; Tewari Naveen Chandra, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P86, DOI 10.1109/ICDAR.2009.212; Vajda S, 2011, PROC INT CONF DOC, P259, DOI 10.1109/ICDAR.2011.60; Veeramachaneni S, 2005, IEEE T PATTERN ANAL, V27, P14, DOI 10.1109/TPAMI.2005.19; Veeramachaneni S., 2003, INT J DOC ANAL RECOG, V6, P154; Veeramachaneni S, 2007, IEEE T PATTERN ANAL, V29, P1280, DOI 10.1109/TPAMI.2007.1030; Vinciarelli A, 2002, PATTERN RECOGN LETT, V23, P905, DOI 10.1016/S0167-8655(02)00021-1; Vuori V., 2002, ADAPTIVE METHODS ONL; Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264; Wang YQ, 2009, PATTERN RECOGN, V42, P3296, DOI 10.1016/j.patcog.2008.10.022; Xiu PP, 2012, IEEE T PATTERN ANAL, V34, P2467, DOI 10.1109/TPAMI.2012.50; Zhang X.Y., 2011, IJCAI P INT JOINT C, V22, P1621; Zhang XY, 2011, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2011.5995661; Zhibin Huang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P91, DOI 10.1109/ICDAR.2009.28; Zhou Yan, 2000, P 17 INT C MACHINE L, P327	61	46	49	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1773	1787		10.1109/TPAMI.2012.239	http://dx.doi.org/10.1109/TPAMI.2012.239			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23682002				2022-12-18	WOS:000319060600018
J	Kwon, J; Lee, KM				Kwon, Junseok; Lee, Kyoung Mu			Wang-Landau Monte Carlo-Based Tracking Methods for Abrupt Motions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object tracking; abrupt motion; Wang-Landau method; density-of-states; N-fold way; Markov Chain Monte Carlo		We propose a novel tracking algorithm based on the Wang-Landau Monte Carlo (WLMC) sampling method for dealing with abrupt motions efficiently. Abrupt motions cause conventional tracking methods to fail because they violate the motion smoothness constraint. To address this problem, we introduce the Wang-Landau sampling method and integrate it into a Markov Chain Monte Carlo (MCMC)-based tracking framework. By employing the novel density-of-states term estimated by the Wang-Landau sampling method into the acceptance ratio of MCMC, our WLMC-based tracking method alleviates the motion smoothness constraint and robustly tracks the abrupt motions. Meanwhile, the marginal likelihood term of the acceptance ratio preserves the accuracy in tracking smooth motions. The method is then extended to obtain good performance in terms of scalability, even on a high-dimensional state space. Hence, it covers drastic changes in not only position but also scale of a target. To achieve this, we modify our method by combining it with the N-fold way algorithm and present the N-Fold Wang-Landau (NFWL)-based tracking method. The N-fold way algorithm helps estimate the density-of-states with a smaller number of samples. Experimental results demonstrate that our approach efficiently samples the states of the target, even in a whole state space, without loss of time, and tracks the target accurately and robustly when position and scale are changing severely.	[Kwon, Junseok; Lee, Kyoung Mu] Seoul Natl Univ, Automat & Syst Res Inst, Dept Elect Engn & Comp Sci, Comp Vis Lab, Seoul 151744, South Korea	Seoul National University (SNU)	Kwon, J (corresponding author), Seoul Natl Univ, Automat & Syst Res Inst, Dept Elect Engn & Comp Sci, Comp Vis Lab, 1 Gwanak Ro, Seoul 151744, South Korea.	s98parad@gmail.com; kyoungmu@snu.ac.kr	Lee, Kyoung Mu/AAC-4063-2020	Lee, Kyoung Mu/0000-0001-7210-1036; kwon, junseok/0000-0001-9526-7549	NRF Grant of MEST [314-2008-1-D00377]	NRF Grant of MEST(Ministry of Education, Science & Technology (MEST), Republic of Korea)	This work was partly supported by NRF Grant of MEST (314-2008-1-D00377).	Adam A., 2006, P IEEE C COMP VIS CO; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B., 2009, P IEEE C COMP VIS PA; Belardinelli RE, 2007, J CHEM PHYS, V127, DOI 10.1063/1.2803061; BERG BA, 1991, PHYS LETT B, V267, P249, DOI 10.1016/0370-2693(91)91256-U; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D., 2000, P IEEE C COMP VIS CO; Grabner H., 2006, 2006 IEEE COMP SOC C, P260; Han B, 2005, P 10 IEEE INT C COMP; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Hua G., 2004, P IEEE C COMP VIS CO; Isard M., 1998, P EUR C COMP VIS; Isard M., 2001, P 8 IEEE INT C COMP; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kwon J., 2009, P IEEE C COMP VIS CO; Kwon J., 2009, P IEEE C COMP VIS PA; Kwon J., 2008, P EUR C COMP VIS; Kwon J., 2010, P IEEE C COMP VIS CO; Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170; Li W., 2009, P 16 IEEE INT C IM P; Li Y., 2007, P IEEE C COMP VIS CO; Ling H., 2006, P IEEE C COMP VIS CO; Little J.J., 2006, P EUR C COMP VIS; MacCormick J., 1999, P 7 IEEE INT C COMP; Perez P., 2002, P EUR C COMP VIS; Philomin V., 2000, P EUR C COMP VIS; Roberts GO, 1997, ANN APPL PROBAB, V7, P110, DOI 10.1214/aoap/1034625254; Roberts GO, 2009, J COMPUT GRAPH STAT, V18, P349, DOI 10.1198/jcgs.2009.06134; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Schulz BJ, 2002, INT J MOD PHYS C, V13, P477, DOI 10.1142/S0129183102003243; Smith K., 2005, P IEEE C COMP VIS CO; Yang M., 2005, P IEEE C COMP VIS CO; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zhao T., 2004, P IEEE C COMP VIS CO; Zhou X., 2010, P IEEE C COMP VIS CO	38	46	56	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					1011	1024		10.1109/TPAMI.2012.161	http://dx.doi.org/10.1109/TPAMI.2012.161			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22848132	Green Submitted			2022-12-18	WOS:000314931000018
J	Sahillioglu, Y; Yemez, Y				Sahillioglu, Yusuf; Yemez, Yucel			Minimum-Distortion Isometric Shape Correspondence Using EM Algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D isometric shape correspondence; multidimensional scaling; spectral embedding; isometric distortion; greedy optimization; bipartite perfect matching; EM algorithm		We present a purely isometric method that establishes 3D correspondence between two (nearly) isometric shapes. Our method evenly samples high-curvature vertices from the given mesh representations, and then seeks an injective mapping from one vertex set to the other that minimizes the isometric distortion. We formulate the problem of shape correspondence as combinatorial optimization over the domain of all possible mappings, which then reduces in a probabilistic setting to a log-likelihood maximization problem that we solve via the Expectation-Maximization (EM) algorithm. The EM algorithm is initialized in the spectral domain by transforming the sampled vertices via classical Multidimensional Scaling (MDS). Minimization of the isometric distortion, and hence maximization of the log-likelihood function, is then achieved in the original 3D euclidean space, for each iteration of the EM algorithm, in two steps: by first using bipartite perfect matching, and then a greedy optimization algorithm. The optimal mapping obtained at convergence can be one-to-one or many-to-one upon choice. We demonstrate the performance of our method on various isometric (or nearly isometric) pairs of shapes for some of which the ground-truth correspondence is available.	[Sahillioglu, Yusuf; Yemez, Yucel] Koc Univ, Dept Comp Engn, TR-34450 Istanbul, Turkey	Koc University	Sahillioglu, Y (corresponding author), Koc Univ, Dept Comp Engn, TR-34450 Istanbul, Turkey.	ysahillioglu@ku.edu.tr; yyemez@ku.edu.tr		Sahillioglu, Yusuf/0000-0002-7997-4232	TUBITAK [EEEAG-109E274]	TUBITAK(Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK))	This work has been supported by TUBITAK under the project EEEAG-109E274.	Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575; Anguelov D., 2004, ADV NEURAL INFORM PR, P33; Au OKC, 2010, COMPUT GRAPH FORUM, V29, P645, DOI 10.1111/j.1467-8659.2009.01634.x; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Carcassoni M, 2003, IEEE T PATTERN ANAL, V25, P1609, DOI 10.1109/TPAMI.2003.1251153; Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; Funkhouser T., 2006, P S GEOM PROC; GOWER JC, 1966, BIOMETRIKA, V53, P325, DOI 10.2307/2333639; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; HUANG Q, 2008, COMPUT GRAPH FORUM, P1149; Jain V, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P118; Kim V.G., 2010, COMPUT GRAPH FORUM, V29, P1555; Kim VG, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964974; Kolmogorov V, 2009, MATH PROGRAM COMPUT, V1, P43, DOI 10.1007/s12532-009-0002-8; Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378; Liu R., 2006, P 24 INT C ADV COMP; Mateus D., 2008, PROC CVPR IEEE, P1, DOI DOI 10.1109/CVPR.2008.4587538; MEYER M, 2002, P INT WORKSH VIS MAT; Munsell BC, 2008, IEEE T PATTERN ANAL, V30, P2023, DOI 10.1109/TPAMI.2007.70841; Ovsjanikov M., 2007, COMPUT GRAPH FORUM, V27, P1341; Ovsjanikov M, 2010, COMPUT GRAPH FORUM, V29, P1555, DOI 10.1111/j.1467-8659.2010.01764.x; Peyre G, 2003, P VLSM 03, P33; Sahillioglu Y, 2011, COMPUT GRAPH FORUM, V30, P1461, DOI 10.1111/j.1467-8659.2011.02020.x; Sahillioglu Y, 2010, PROC CVPR IEEE, P453, DOI 10.1109/CVPR.2010.5540178; Sand P., 2003, P INT C COMP GRAPH I; Sharma A, 2010, P WORKSH NONR SHAP A; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; TEVS A., 2009, P IEEE C COMP VIS PA; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x; Wang C., 2011, P 3 INT C SCAL SPAC; Weber O, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409626; Wuhrer S., 2009, P INT C 3D DIG IM MO; Zaharescu Andrei, 2009, P IEEE C COMP VIS PA; Zeng Y., 2010, P IEEE C COMP VIS PA; Zhang H, 2008, COMPUT GRAPH FORUM, V27, P1431, DOI 10.1111/j.1467-8659.2008.01283.x	45	46	52	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2012	34	11					2203	2215		10.1109/TPAMI.2012.26	http://dx.doi.org/10.1109/TPAMI.2012.26			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	005MR	22248632	Green Submitted			2022-12-18	WOS:000308755000012
J	Del Bue, A; Xavier, J; Agapito, L; Paladini, M				Del Bue, Alessio; Xavier, Joao; Agapito, Lourdes; Paladini, Marco			Bilinear Modeling via Augmented Lagrange Multipliers (BALM)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bilinear optimization; augmented Lagrangian; SfM; photometric stereo; image registration	STRUCTURE-FROM-MOTION; MISSING DATA; FACTORIZATION; SHAPE; OPTIMIZATION; ALGORITHM; MATRIX	This paper presents a unified approach to solve different bilinear factorization problems in computer vision in the presence of missing data in the measurements. The problem is formulated as a constrained optimization where one of the factors must lie on a specific manifold. To achieve this, we introduce an equivalent reformulation of the bilinear factorization problem that decouples the core bilinear aspect from the manifold specificity. We then tackle the resulting constrained optimization problem via Augmented Lagrange Multipliers. The strength and the novelty of our approach is that this framework can seamlessly handle different computer vision problems. The algorithm is such that only a projector onto the manifold constraint is needed. We present experiments and results for some popular factorization problems in computer vision such as rigid, non-rigid, and articulated Structure from Motion, photometric stereo, and 2D-3D non-rigid registration.	[Del Bue, Alessio] Ist Italiano Tecnol IIT, PAVIS Dept, I-16163 Genoa, Italy; [Xavier, Joao] Univ Tecn Lisboa, Inst Syst & Robot ISR, Inst Super Tecn IST, P-1049001 Lisbon, Portugal; [Agapito, Lourdes; Paladini, Marco] Queen Mary Univ London, Sch Elect Engn & Comp Sci EECS, London E1 4NS, England	Istituto Italiano di Tecnologia - IIT; Universidade de Lisboa; Instituto Superior Tecnico; University of London; Queen Mary University London	Del Bue, A (corresponding author), Ist Italiano Tecnol IIT, PAVIS Dept, Via Morego 30, I-16163 Genoa, Italy.	alessio.delbue@iit.it; jxavier@isr.ist.utl.pt; lourdes.agapito@eecs.qmul.ac.uk; marco.paladini@eecs.qmul.ac.uk	Xavier, João/R-4294-2016	Xavier, João/0000-0002-9669-8532; Del Bue, Alessio/0000-0002-2262-4872	European Research Council under the European Community [204871-HUMANIS]; FCT [CMU-PT/SIA/0026/2009]; ISR/IST	European Research Council under the European Community(European Research Council (ERC)); FCT(Portuguese Foundation for Science and TechnologyEuropean Commission); ISR/IST(European Commission)	This research has received funding from the European Research Council under the European Community's Seventh Framework Programme (FP7/2007-2013) ERC Starting Grant agreement 204871-HUMANIS. The work of J. Xavier was partially supported by FCT grant CMU-PT/SIA/0026/2009 and by ISR/IST plurianual funding 9POSC program, FEDER). The authors thank J. Buenaposada for providing an implementation of [1] and M. Chandraker for sharing the Branch & Bound implementation of [10]. They gratefully acknowledge R. Proietti for the hardware support in the large scale 3D reconstruction experiments. The box and head data for the articulated test were given by P. Tresadern. The data for the Casa da Musica 3D reconstruction were provided by M. Marques and J. Costeira.	Aanaes H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8; Abboud B, 2005, IEE P-VIS IMAGE SIGN, V152, P327, DOI 10.1049/ip-vis:20045060; AKHTER I, 2008, P NEUR INF PROC SYST; [Anonymous], 2006, P ADV NEUR INF PROC; Bascle B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P323, DOI 10.1109/ICCV.1998.710738; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Bertsekas D.P., 2019, REINFORCEMENT LEARNI; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Buchanan AM, 2005, PROC CVPR IEEE, P316; Chang MMJ, 2008, CVPR, P1, DOI [10.1002/9780470727010.CH1, DOI 10.1109/ARSO.2008.4653593.]; Chen P, 2004, IEEE T PATTERN ANAL, V26, P1051, DOI 10.1109/TPAMI.2004.52; Chen P, 2008, INT J COMPUT VISION, V80, P125, DOI 10.1007/s11263-008-0135-7; Chuang E, 2005, ACM T GRAPHIC, V24, P331, DOI 10.1145/1061347.1061355; Cole F. H., 2002, THESIS HARVARD COLL; Conn AR, 1996, SIAM J OPTIMIZ, V6, P674, DOI 10.1137/S1052623493251463; Cuzzolin F., 2006, P 2006 IEEE COMP SOC, V2, P1701; Del Bue A, 2007, IMAGE VISION COMPUT, V25, P297, DOI 10.1016/j.imavis.2005.10.004; Del Bue A, 2010, LECT NOTES COMPUT SC, V6314, P283; Elgammal A., 2004, P IEEE C COMP VIS PA, V1; Ferreira R., 2009, P 20 BRIT MACH VIS C; Gonzalez-Mora J, 2007, IEEE I CONF COMP VIS, P2776; Guerreiro RFC, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P105; Guignard Monique, 2003, TOP, V11, P151, DOI DOI 10.1007/BF02579036; HARTLEY R, 2003, P AUSTR JAP ADV WORK; Hestenes M. R., 1969, Journal of Optimization Theory and Applications, V4, P303, DOI 10.1007/BF00927673; Jacobs DW, 2001, COMPUT VIS IMAGE UND, V82, P57, DOI 10.1006/cviu.2001.0906; Julia C, 2008, LECT NOTES COMPUT SC, V5112, P315, DOI 10.1007/978-3-540-69812-8_31; Lin Z., 2009, UILUENG092215; Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527; Mai F, 2010, J SIGNAL PROCESS SYS, V61, P181, DOI 10.1007/s11265-009-0414-8; Marques M, 2009, COMPUT VIS IMAGE UND, V113, P261, DOI 10.1016/j.cviu.2008.09.004; Okatani T, 2007, INT J COMPUT VISION, V72, P329, DOI 10.1007/s11263-006-9785-5; OLSEN S, 2007, P BRIT MACH VIS C; Paladini M, 2012, INT J COMPUT VISION, V96, P252, DOI 10.1007/s11263-011-0468-5; Schlick M., 1938, PHILOS PAPERS; Shaji A., 2008, 19 INT C PATT REC, P1, DOI [10.1109/ICPR.2008.4761367., DOI 10.1109/ICPR.2008.4761367]; Shin D, 2008, PATTERN RECOGN LETT, V29, P49, DOI 10.1016/j.patrec.2007.08.013; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TORRESANI L, 2001, P IEEE C COMP VIS PA; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; TRESADERN P, 2005, COMP VIS PATT REC 20, V2, P1110; Wang G, 2008, PATTERN RECOGN LETT, V29, P72, DOI 10.1016/j.patrec.2007.09.004; Wiberg T, 1976, P 2 S COMP STAT, P229; Xavier J., 2012, CONVERGENCE ANAL BAL; Yan JY, 2008, IEEE T PATTERN ANAL, V30, P865, DOI 10.1109/TPAMI.2007.70739	47	46	48	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1496	1508		10.1109/TPAMI.2011.238	http://dx.doi.org/10.1109/TPAMI.2011.238			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22156102	Green Submitted			2022-12-18	WOS:000305188500004
J	Browne, RP; McNicholas, PD; Sparling, MD				Browne, Ryan P.; McNicholas, Paul D.; Sparling, Matthew D.			Model-Based Learning Using a Mixture of Mixtures of Gaussian and Uniform Distributions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Statistical computing; multivariate statistics	DISCRIMINANT-ANALYSIS; LIKELIHOOD; CLASSIFICATION	We introduce a mixture model whereby each mixture component is itself a mixture of a multivariate Gaussian distribution and a multivariate uniform distribution. Although this model could be used for model-based clustering (model-based unsupervised learning) or model-based classification (model-based semi-supervised learning), we focus on the more general model-based classification framework. In this setting, we fit our mixture models to data where some of the observations have known group memberships and the goal is to predict the memberships of observations with unknown labels. We also present a density estimation example. A generalized expectation-maximization algorithm is used to estimate the parameters and thereby give classifications in this mixture of mixtures model. To simplify the model and the associated parameter estimation, we suggest holding some parameters fixed-this leads to the introduction of more parsimonious models. A simulation study is performed to illustrate how the model allows for bursts of probability and locally higher tails. Two further simulation studies illustrate how the model performs on data simulated from multivariate Gaussian distributions and on data from multivariate t-distributions. This novel approach is also applied to real data and the performance of our approach under the various restrictions is discussed.	[Browne, Ryan P.; McNicholas, Paul D.; Sparling, Matthew D.] Univ Guelph, Dept Math & Stat, Guelph, ON N1G 2W1, Canada	University of Guelph	Browne, RP (corresponding author), Univ Guelph, Dept Math & Stat, Guelph, ON N1G 2W1, Canada.	rbrowne@uoguelph.ca; paul.mcnicholas@uoguelph.ca; msparlin@uoguelph.ca		Browne, Ryan/0000-0003-4543-0218; McNicholas, Paul/0000-0002-2482-523X	Natural Sciences and Engineering Research Council of Canada; Compusense Inc.; Ontario Centres of Excellence; University Research Chair in Computational Statistics at the University of Guelph; Canada Foundation for Innovation; Ontario Ministry for Research and Innovation	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR); Compusense Inc.; Ontario Centres of Excellence; University Research Chair in Computational Statistics at the University of Guelph; Canada Foundation for Innovation(Canada Foundation for InnovationCGIAR); Ontario Ministry for Research and Innovation(Ministry of Research and Innovation, Ontario)	This work was supported by a Discovery Grant and a Collaborative Research and Development Grant from the Natural Sciences and Engineering Research Council of Canada, by a grant-in-aid from Compusense Inc., by a Collaborative Research Grant from the Ontario Centres of Excellence, and by the University Research Chair in Computational Statistics at the University of Guelph. Equipment used in this work was purchased with support from the Canada Foundation for Innovation's Leaders Opportunity Fund and from the Ontario Ministry for Research and Innovation's Small Infrastructure Fund.	Aitken AC, 1926, P R SOC EDINB, V46, P289, DOI DOI 10.1017/S0370164600022070; Andrews JL, 2011, STAT COMPUT, V21, P361, DOI 10.1007/s11222-010-9175-2; Andrews JL, 2011, COMPUT STAT DATA AN, V55, P520, DOI 10.1016/j.csda.2010.05.019; [Anonymous], 2010, R LANG ENV STAT COMP; Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189; BOHNING D, 1994, ANN I STAT MATH, V46, P373, DOI 10.1007/BF01720593; Bouchard G, 2006, IEEE T PATTERN ANAL, V28, P544, DOI 10.1109/TPAMI.2006.82; Bouveyron C, 2007, COMPUT STAT DATA AN, V52, P502, DOI 10.1016/j.csda.2007.02.009; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Di Zio M, 2007, COMPUT STAT DATA AN, V51, P2573, DOI 10.1016/j.csda.2006.01.001; FORINA M, 1986, VITIS, V25, P189; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Hurley CB, 2004, J COMPUT GRAPH STAT, V13, P788, DOI 10.1198/106186004X12425; McLachlan GJ, 2007, COMPUT STAT DATA AN, V51, P5327, DOI 10.1016/j.csda.2006.09.015; McLachlan G. J., 2008, EM ALGORITHM EXTENSI; McNicholas PD, 2010, COMPUT STAT DATA AN, V54, P711, DOI 10.1016/j.csda.2009.02.011; McNicholas PD, 2010, BIOINFORMATICS, V26, P2705, DOI 10.1093/bioinformatics/btq498; McNicholas PD, 2010, J STAT PLAN INFER, V140, P1175, DOI 10.1016/j.jspi.2009.11.006; Meila M, 2007, J MULTIVARIATE ANAL, V98, P873, DOI 10.1016/j.jmva.2006.11.013; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Steinley D, 2004, PSYCHOL METHODS, V9, P386, DOI 10.1037/1082-989X.9.3.386; [No title captured]; [No title captured]	27	46	46	3	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2012	34	4					814	817		10.1109/TPAMI.2011.199	http://dx.doi.org/10.1109/TPAMI.2011.199			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	896PO	22383342				2022-12-18	WOS:000300581700014
J	Muhammad, MS; Choi, TS				Muhammad, Mannan Saeed; Choi, Tae-Sun			Sampling for Shape from Focus in Optical Microscopy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sampling step size; shape from focus; 3D shape recovery; optical microscopy; curve fitting	3-DIMENSIONAL SHAPE; IMAGE FOCUS; DEPTH MAP; RECOVERY	Shape from focus (SFF), which relies on image focus as a cue within sequenced images, represents a passive technique in recovering object shapes in scenes. Although numerous methods have been recently proposed, less attention has been paid to particular factors affecting them. In regard to SFF, one such critical factor impacting system application is the total number of images. A large data set requires a huge amount of computation power, whereas decreasing the number of images causes shape reconstruction to be crude and erroneous. The total number of images is inversely proportional to interframe distance or sampling step size. In this paper, interframe distance (or sampling step size) criteria for SFF systems have been formulated. In particular, light ray focusing is approximated by the use of a Gaussian beam followed by the formulation of a sampling expression using Nyquist sampling. Consequently, a fitting function for focus curves is also obtained. Experiments are performed on simulated and real objects to validate the proposed schemes.	[Muhammad, Mannan Saeed; Choi, Tae-Sun] Gwangju Inst Sci & Technol, Signal & Image Proc Lab, Sch Mechatron, Kwangju 500712, South Korea	Gwangju Institute of Science & Technology (GIST)	Muhammad, MS (corresponding author), Gwangju Inst Sci & Technol, Signal & Image Proc Lab, Sch Mechatron, 261 Cheomdan Gwagiro Oryong Dong, Kwangju 500712, South Korea.	mannan@gist.ac.kr; tschoi@gist.ac.kr	Muhammad, Mannan Saeed/G-5115-2015	Muhammad, Mannan Saeed/0000-0002-3036-4660; Choi, Tae-Sun/0000-0001-7496-2438	National Research Foundation of Korea (NRF); Ministry of Education, Science, and Technology [2010-0008312]	National Research Foundation of Korea (NRF)(National Research Foundation of Korea); Ministry of Education, Science, and Technology(Ministry of Education, Science & Technology (MEST), Republic of Korea)	This work is supported by the Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education, Science, and Technology (2010-0008312).	Ahmad MB, 2007, IEEE T CONSUM ELECTR, V53, P1, DOI 10.1109/TCE.2007.339492; Ahrent E., 2008, IMAGING MICROSCOPY, V10, P58; Asif M, 2001, IEEE T IMAGE PROCESS, V10, P1670, DOI 10.1109/83.967395; Born M., 1980, PRINCIPLES OPTICS, P180; Choi TS, 2000, OPT ENG, V39, P1321, DOI 10.1117/1.602498; Conrad J., 2006, DEPTH FIELD DEPTH; DeGroot M.H., 1980, PROBABILITY STAT; Geusebroek JM, 2000, CYTOMETRY, V39, P1; Kariya T, 2004, GEN LEAST SQUARES; Levoy M., 2010, DIGITAL PHOTOGRAPHY; Lin SC, 2009, J CHIN SOC MECH ENG, V30, P39; Mahmood MT, 2010, OPT LETT, V35, P1272, DOI 10.1364/OL.35.001272; Mahmood MT, 2008, MICROSC RES TECHNIQ, V71, P897, DOI 10.1002/jemt.20635; Malik AS, 2008, PATTERN RECOGN, V41, P2200, DOI 10.1016/j.patcog.2007.12.014; Malik AS, 2007, PATTERN RECOGN, V40, P154, DOI 10.1016/j.patcog.2006.05.032; Mennucci A., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P550, DOI 10.1109/ICIAP.1999.797653; Muhammad MS, 2010, MICROSC RES TECHNIQ, V73, P140, DOI 10.1002/jemt.20765; Muhammad MS, 2009, MICROSC RES TECHNIQ, V72, P703, DOI 10.1002/jemt.20768; Nayar S. K., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P218, DOI 10.1109/ROBOT.1990.125976; NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479; Piller H., 1977, MICROSCOPE PHOTOMETR; Pradeep KS, 2007, IEEE T IMAGE PROCESS, V16, P1920, DOI 10.1109/TIP.2007.899188; RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263; Rost F., 2000, PHOTOGRAPHY MICROSCO; Sahay RR, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P243; Saleh B. E. A., 2007, FUNDAMENTALS PHOTONI; Shim SO, 2009, IEEE IMAGE PROC, P3777, DOI 10.1109/ICIP.2009.5414336; Shim SO, 2009, MICROSC RES TECHNIQ, V72, P362, DOI 10.1002/jemt.20662; Siegman A. E., 1986, LASERS; Spring K.R., 2009, OLYMPUS MICROSCOPY R; SUBBARAO M, 1995, IEEE T PATTERN ANAL, V17, P266, DOI 10.1109/34.368191; SUBBARAO M, 1993, OPT ENG, V32, P2824, DOI 10.1117/12.147706; SUBBARAO M, 1994, MACH VISION APPL, V7, P277, DOI 10.1007/BF01213418; Sun Y, 2004, MICROSC RES TECHNIQ, V65, P139, DOI 10.1002/jemt.20118; Tenenbaum J.M., 1970, THESIS STANFORD U; Wu Q, 2008, MICROSCOPE IMAGE PROCESSING, P1; Xie H., 2004, MICROSC RES TECHNIQ, V70, P987; Xiong Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P68, DOI 10.1109/CVPR.1993.340977; Young I. T., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P493	39	46	50	5	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					564	573		10.1109/TPAMI.2011.144	http://dx.doi.org/10.1109/TPAMI.2011.144			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21768654				2022-12-18	WOS:000299381600011
J	Nishiyama, M; Hadid, A; Takeshima, H; Shotton, J; Kozakaya, T; Yamaguchi, O				Nishiyama, Masashi; Hadid, Abdenour; Takeshima, Hidenori; Shotton, Jamie; Kozakaya, Tatsuo; Yamaguchi, Osamu			Facial Deblur Inference Using Subspace Analysis for Recognition of Blurred Faces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; inference; point spread function; deblur	IDENTIFICATION	This paper proposes a novel method for recognizing faces degraded by blur using deblurring of facial images. The main issue is how to infer a Point Spread Function (PSF) representing the process of blur on faces. Inferring a PSF from a single facial image is an ill-posed problem. Our method uses learned prior information derived from a training set of blurred faces to make the problem more tractable. We construct a feature space such that blurred faces degraded by the same PSF are similar to one another. We learn statistical models that represent prior knowledge of predefined PSF sets in this feature space. A query image of unknown blur is compared with each model and the closest one is selected for PSF inference. The query image is deblurred using the PSF corresponding to that model and is thus ready for recognition. Experiments on a large face database (FERET) artificially degraded by focus or motion blur show that our method substantially improves the recognition performance compared to existing methods. We also demonstrate improved performance on real blurred images on the FRGC 1.0 face database. Furthermore, we show and explain how combining the proposed facial deblur inference with the local phase quantization (LPQ) method can further enhance the performance.	[Nishiyama, Masashi; Takeshima, Hidenori; Kozakaya, Tatsuo] Toshiba Co Ltd, Corp Res & Dev Ctr, Saiwai Ku, Kawasaki, Kanagawa 2128582, Japan; [Hadid, Abdenour] Univ Oulu, Elect & Informat Engn Dept, Machine Vis Grp, FIN-90014 Oulu, Finland; [Shotton, Jamie] Microsoft Res Cambridge, Cambridge CB3 0FB, England; [Yamaguchi, Osamu] Toshiba Co Ltd, Power & Ind Syst R&D Ctr, Fuchu, Tokyo 838511, Japan	Toshiba Corporation; University of Oulu; Microsoft; Toshiba Corporation	Nishiyama, M (corresponding author), Toshiba Co Ltd, Corp Res & Dev Ctr, Saiwai Ku, 1 Komukaitoshiba Cho, Kawasaki, Kanagawa 2128582, Japan.	masashi1@m.ieice.org; hadid@ee.oulu.fi; hidenori.takeshima@toshiba.co.jp; jamieshotton@gmail.com; tatsuo.kozakaya@toshiba.co.jp; osamu1.yamaguchi@toshiba.co.jp		Takeshima, Hidenori/0000-0002-2557-8533				Ahonen T., 2008 19 INT C PATT R, P1; Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Ancuti C, 2009, COMPUT GRAPH FORUM, V28, P619, DOI 10.1111/j.1467-8659.2009.01402.x; Bourlai T., 2009, P IEEE INT C BIOM ID; Campisi P., 2007, BLIND IMAGE DECONVOL; CANNON M, 1976, IEEE T ACOUST SPEECH, V24, P58, DOI 10.1109/TASSP.1976.1162770; Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187; CHANG MM, 1991, IEEE T SIGNAL PROCES, V39, P2323, DOI 10.1109/78.91207; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; GENNERY DB, 1973, J OPT SOC AM, V63, P1571, DOI 10.1364/JOSA.63.001571; Gonzalez Rafael C., 2007, DIGITAL IMAGE PROCES; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hu H, 2006, IEEE IMAGE PROC, P617, DOI 10.1109/ICIP.2006.312411; Jia J., 2007, IEEE C COMP VIS PATT, P1; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; Li S.Z., 2005, HDB FACE RECOGNITION; Mita T, 2008, IEEE T PATTERN ANAL, V30, P1257, DOI 10.1109/TPAMI.2007.70767; Nishiyama M, 2009, PROC CVPR IEEE, P1115, DOI 10.1109/CVPRW.2009.5206750; OJA E, 1983, SUBSPACE METHODS PAT; Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Rooms F., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P210; Savakis AE, 1993, IEEE T IMAGE PROCESS, V2, P141, DOI 10.1109/83.217219; Savvides M, 2004, INT C PATT RECOG, P810; Stainvas I, 2000, INT C PATT RECOG, P805, DOI 10.1109/ICPR.2000.906198; Tong HH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P17, DOI 10.1109/ICME.2004.1394114; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WATANABE S, 1973, P INT JOINT C PATT R, P25; Yitzhaky Y, 1997, GRAPH MODEL IM PROC, V59, P310, DOI 10.1006/gmip.1997.0435; Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452	33	46	48	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					838	845		10.1109/TPAMI.2010.203	http://dx.doi.org/10.1109/TPAMI.2010.203			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	21079280				2022-12-18	WOS:000287370400014
J	Gay-Bellile, V; Bartoli, A; Sayd, P				Gay-Bellile, Vincent; Bartoli, Adrien; Sayd, Patrick			Direct Estimation of Nonrigid Registrations with Image-Based Self-Occlusion Reasoning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonrigid registration; self-occlusion; direct method; image retexturing	WARPS	The registration problem for images of a deforming surface has been well studied. External occlusions are usually well handled. In 2D image-based registration, self-occlusions are more challenging. Consequently, the surface is usually assumed to be only slightly self-occluding. This paper is about image-based nonrigid registration with self-occlusion reasoning. A specific framework explicitly modeling self-occlusions is proposed. It is combined with an intensity-based, "direct" data term for registration. Self-occlusions are detected as shrinkage areas in the 2D warp. Experimental results on several challenging data sets show that our approach successfully registers images with self-occlusions while effectively detecting the self-occluded regions.	[Gay-Bellile, Vincent; Sayd, Patrick] CEA Saclay, F-91191 Gif Sur Yvette, France; [Gay-Bellile, Vincent; Bartoli, Adrien] CNRS, UMR 6602, LASMEA, F-63177 Clermont Ferrand, France	CEA; UDICE-French Research Universities; Universite Paris Saclay; Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS); Universite Clermont Auvergne (UCA)	Gay-Bellile, V (corresponding author), CEA Saclay, Batiment 528,PC 94, F-91191 Gif Sur Yvette, France.	vincentgaybellile@hotmail.fr; Adrien.Bartoli@gmail.com; Patrick.Sayd@cea.fr						Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; BAKER S, 2003, CMURIT0301; BARTOLI A, 2006, P BRIT MACH VIS C; BARTOLI A, 2004, P BRIT MACH VIS C; Bartoli A, 2008, J MATH IMAGING VIS, V31, P133, DOI 10.1007/s10851-007-0062-1; BENHIMANE S, 2004, P INT C INT ROB SYST; Bergen J.R., 1992, P EUR C COMP VIS; Besse F, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.132; BLACK MJ, 1991, P INT C COMP VIS PAT; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BREGLER C, 2000, P INT C COMP VIS PAT; COOTES TF, 2004, P EUR C COMP VIS; GAYBELLILE V, 2007, P BRIT MACH VIS C; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171; Ilic S, 2007, INT J COMPUT VISION, V72, P159, DOI 10.1007/s11263-006-8595-0; Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001; LIM J, 2005, P INT C COMP VIS PAT; LIN WC, 2006, P EUR C COMP VIS; MALIS E, 2007, P INT C INT ROB SYST; Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9; PIZARRO D, 2007, P SCAND C IM AN; PIZARRO D, 2008, P INT C COMP VIS PAT; PRASAD M, 2006, P INT C COMP VIS PAT; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; SALZMANN M, 2005, P BRIT MACH VIS C; SILVEIRA G, 2007, P INT C COMP VIS PAT; WHITE R, 2006, P EUR C COMP VIS	30	46	48	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					87	104		10.1109/TPAMI.2008.265	http://dx.doi.org/10.1109/TPAMI.2008.265			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926901				2022-12-18	WOS:000271826700008
J	Djioua, M; Plamondon, R				Djioua, Moussa; Plamondon, Rejean			A New Algorithm and System for the Characterization of Handwriting Strokes with Delta-Lognormal Parameters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern recognition; kinematic theory; rapid movement; Delta-Lognormal model; lognormal function; parameter extraction; motor control; nonlinear regression; optimization; curve-fitting	RAPID HUMAN MOVEMENTS; KINEMATIC THEORY; MODEL; REPRESENTATION; ACCELERATION; COORDINATION; PROFILES; VELOCITY; TIME	In this paper, we present a new analytical method for estimating the parameters of Delta-Lognormal functions and characterizing handwriting strokes. According to the Kinematic Theory of rapid human movements, these parameters contain information on both the motor commands and the timing properties of a neuromuscular system. The new algorithm, called XZERO, exploits relationships between the zero crossings of the first and second time derivatives of a lognormal function and its four basic parameters. The methodology is described and then evaluated under various testing conditions. The new tool allows a greater variety of stroke patterns to be processed automatically. Furthermore, for the first time, the extraction accuracy is quantified empirically, taking advantage of the exponential relationships that link the dispersion of the extraction errors with its signal-to-noise ratio. A new extraction system which combines this algorithm with two other previously published methods is also described and evaluated. This system provides researchers involved in various domains of pattern analysis and artificial intelligence with new tools for the basic study of single strokes as primitives for understanding rapid human movements.	[Djioua, Moussa; Plamondon, Rejean] Ecole Polytech, Lab Scribens, Dept Genie Elect, Montreal, PQ H3C 3A7, Canada	Universite de Montreal; Polytechnique Montreal	Djioua, M (corresponding author), Ecole Polytech, Lab Scribens, Dept Genie Elect, POB 6079,Stn Ctr Ville, Montreal, PQ H3C 3A7, Canada.	moussa.djioua@polymtl.ca; rejean.plamondon@polymtl.ca	Plamondon, Réjean/O-3214-2015	Plamondon, Réjean/0000-0002-4903-7539	NSERC [RGPIN-915]	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	This research was supported by grant RGPIN-915 from the NSERC to Rejean Plamondon.	Alimi AM, 1996, HANDWRITING AND DRAWING RESEARCH, P127; BIZZI E, 1980, TUTORIALS MOTOR CONT; BULLOCK D, 1990, BIOL CYBERN, V70, P15; CARTER MC, 1984, J NEUROPHYSIOL, V52, P787, DOI 10.1152/jn.1984.52.5.787; Chang SH, 2005, PERCEPT MOTOR SKILL, V101, P631, DOI 10.2466/PMS.101.6.631-647; COHEN AC, 1980, J AM STAT ASSOC, V75, P399, DOI 10.2307/2287466; CORCOS DM, 1990, J NEUROPHYSIOL, V64, P1033, DOI 10.1152/jn.1990.64.3.1033; Crow EL, 1988, LOGNORMAL DISTRIBUTI; DESANTIS A, 2005, P 12 BIENN C INT GRA, V12, P168; Djioua M., 2007, THESIS ECOLE POLYTEC; DJIOUA M, 2007, P 13 C INT GRAPH SOC, V13, P19; Djioua M, 2007, INT J PATTERN RECOGN, V21, P21, DOI 10.1142/S0218001407005284; EDELMAN S, 1987, BIOL CYBERN, V57, P25, DOI 10.1007/BF00318713; ENDERLE JD, 1987, IEEE T BIO-MED ENG, V34, P43, DOI 10.1109/TBME.1987.326014; FELDMAN AG, 1986, J MOTOR BEHAV, V18, P17; Feng C, 2002, INT C PATT RECOG, P52, DOI 10.1109/ICPR.2002.1047398; FLASH T, 1985, J NEUROSCI, V5, P1688, DOI 10.1523/jneurosci.05-07-01688.1985; Gangadhar G, 2007, INT J DOC ANAL RECOG, V10, P69, DOI 10.1007/s10032-007-0046-0; GEORGOPOULOS AP, 1981, J NEUROPHYSIOL, V46, P725, DOI 10.1152/jn.1981.46.4.725; GERKEN A, 1991, PHARMACOPSYCHIATRY, V24, P132, DOI 10.1055/s-2007-1014456; GIELEN CCAM, 1985, J MOTOR BEHAV, V17, P421; GISZTER SF, 1993, J NEUROSCI, V13, P467; GLENAT S, 2005, P 12 BIENN C INT GRA, V12, P49; GUENTHER F, 1992, NEURAL NETWORKS, V5, P531; GUERFALI W, 1996, THESIS ECOLE POLYTEC; Guerfali W., 1995, RES COMPUTER ROBOT V, P217; Guest RM, 2002, PATTERN ANAL APPL, V5, P261, DOI 10.1007/s100440200023; Harris CM, 1998, NATURE, V394, P780, DOI 10.1038/29528; HILTON O, 1993, CRC SERIES FORENSIC; HOLLERBACH JM, 1981, BIOL CYBERN, V39, P139, DOI 10.1007/BF00336740; LACQUANITI F, 1983, ACTA PSYCHOL, V54, P115, DOI 10.1016/0001-6918(83)90027-6; LANGE KW, 2005, P 12 BIENN C INT GRA, V12, P276; LECLERC F, 1996, THESIS ECOLE POLYTEC; LIKFORMANSULEM L, 2008, P 11 INT C FRONT HAN, V11, P70; LONGSTAFF MG, 2005, P 12 BIENN C INT GRA, V12, P305; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; MEYER DE, 1982, PSYCHOL REV, V89, P449, DOI 10.1037/0033-295X.89.5.449; MORASSO P, 1981, EXP BRAIN RES, V42, P223; MUSSAIVALDI FA, 1994, P NATL ACAD SCI USA, V91, P7534, DOI 10.1073/pnas.91.16.7534; NAGASAKI H, 1989, EXP BRAIN RES, V74, P319; NEILSON PD, 1993, PSYCHOL RES-PSYCH FO, V55, P99, DOI 10.1007/BF00419640; NIHEI Y, 1985, TOKOHU PSYCHOL FOLIA, V43, P127; OREILLY C, 2008, P 11 INT C FRONT HAN, V11, P216; Paine RW, 2004, NEURAL NETWORKS, V17, P1291, DOI 10.1016/j.neunet.2004.08.005; PHILLIPS JG, 2007, P 13 BIENN C INT GRA, V13, P83; PLAMONDON R, 1995, BIOL CYBERN, V72, P295, DOI 10.1007/BF00202785; PLAMONDON R, 1995, BIOL CYBERN, V72, P309, DOI 10.1007/BF00202786; Plamondon R, 1998, BIOL CYBERN, V78, P119, DOI 10.1007/s004220050419; Plamondon R, 2003, BIOL CYBERN, V89, P126, DOI 10.1007/s00422-003-0407-9; Plamondon Rejean, 2007, Frontiers of Computer Science in China, V1, P106, DOI 10.1007/s11704-007-0009-0; PLAMONDON R, 1993, BIOL CYBERN, V69, P119, DOI 10.1007/BF00226195; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Plamondon R., 1999, ENCY ELECT ELECT ENG, V15, P123; Plamondon R, 2006, HUM MOVEMENT SCI, V25, P586, DOI 10.1016/j.humov.2006.07.004; Potkonjak Veljko, 2005, INT J HUM ROBOT, V2.01, P105; Rohrer B, 2002, J NEUROSCI, V22, P8297; Rosenblum S, 2008, HUM MOVEMENT SCI, V27, P200, DOI 10.1016/j.humov.2008.02.011; RUSU A, 2007, P 13 BIENN C INT GRA, V13, P14; Schenk Thomas, 2004, J Hand Ther, V17, P349, DOI 10.1197/j.jht.2004.04.005; SCHOMAKER LRB, 1991, THESIS NIJMEGEN U; Schroter A, 2003, DEMENT GERIATR COGN, V15, P132, DOI 10.1159/000068484; Simner ML, 1996, HANDWRITING AND DRAWING RESEARCH, P197; SIMNER ML, 2000, J FORENSIC DOCUMENT, V13, P1; SOECHTING JF, 1981, J NEUROSCI, V1, P710, DOI 10.1523/JNEUROSCI.01-07-00710.1981; TEULINGS HL, 1991, HUM MOVEMENT SCI, V10, P315, DOI 10.1016/0167-9457(91)90010-U; Thoroughman KA, 2000, NATURE, V407, P742, DOI 10.1038/35037588; Tucha O, 2004, PSYCHOPHARMACOLOGY, V173, P49, DOI 10.1007/s00213-003-1690-9; TUCHA O, 2005, P 12 BIENN C INT GRA, V12, P237; UNO Y, 1989, BIOL CYBERN, V61, P89, DOI 10.1007/BF00204593; VARGA T, 2005, P 12 C INT GRAPH SOC, V12, P206; Viviani P., 1980, TUTORIALS MOTOR BEHA, P525; WANN J, 1991, DEV GRAPHIC SKILLS S; WISE ME, 1966, STAT NEERL, V20, P119; Woch A, 2004, MOTOR CONTROL, V8, P547, DOI 10.1123/mcj.8.4.547; WOCH A, 2007, P 13 BIENN C INT GRA, V13, P56	75	46	47	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					2060	2072		10.1109/TPAMI.2008.264	http://dx.doi.org/10.1109/TPAMI.2008.264			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	493VV	19762931				2022-12-18	WOS:000269767600010
J	Zimmermann, K; Matas, J; Svoboda, T				Zimmermann, Karel; Matas, Jiri; Svoboda, Tomas			Tracking by an Optimal Sequence of Linear Predictors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image processing and computer vision; scene analysis; tracking		We propose a learning approach to tracking explicitly minimizing the computational complexity of the tracking process subject to user-defined probability of failure (loss-of-lock) and precision. The tracker is formed by a Number of Sequences of Learned Linear Predictors (NoSLLiP). Robustness of NoSLLiP is achieved by modeling the object as a collection of local motion predictors-object motion is estimated by the outlier-tolerant RANSAC algorithm from local predictions. The efficiency of the NoSLLiP tracker stems 1) from the simplicity of the local predictors and 2) from the fact that all design decisions, the number of local predictors used by the tracker, their computational complexity (i.e., the number of observations the prediction is based on), locations as well as the number of RANSAC iterations, are all subject to the optimization (learning) process. All time-consuming operations are performed during the learning stage-tracking is reduced to only a few hundred integer multiplications in each step. On PC with 1xK8 3200+, a predictor evaluation requires about 30 mu s. The proposed approach is verified on publicly available sequences with approximately 12,000 frames with ground truth. Experiments demonstrate superiority in frame rates and robustness with respect to the SIFT detector, Lucas-Kanade tracker, and other trackers.	[Zimmermann, Karel; Matas, Jiri; Svoboda, Tomas] Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Prague 12135 2, Czech Republic	Czech Technical University Prague	Zimmermann, K (corresponding author), Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Karlovo Namesti 13, Prague 12135 2, Czech Republic.	karel.zimmermann@esat.kuleuven.be; matas@cmp.felk.cvut.cz; svoboda@cmp.felk.cvut.cz	Svoboda, Tomas/H-1627-2012; Zimmermann, Karel/G-7963-2014; Zimmermann, Karel/AAF-1596-2021; , Matas/AAW-3282-2020	Svoboda, Tomas/0000-0002-7184-1785; Zimmermann, Karel/0000-0002-8898-4512; 	Czech Academy of Sciences [1ET101210407]; Czech Ministry of Education [1M0567]; EC [FP6-IST-027787]; Grant Agency of Czech Republic [102/07/1317]	Czech Academy of Sciences(Czech Academy of Sciences); Czech Ministry of Education(Ministry of Education, Youth & Sports - Czech Republic); EC(European CommissionEuropean Commission Joint Research Centre); Grant Agency of Czech Republic(Grant Agency of the Czech Republic)	Karel Zimmermann was supported by the Czech Academy of Sciences under Project 1ET101210407. Tomas Svoboda was supported by the Czech Ministry of Education under Project 1M0567 and in part by EC Project FP6-IST-027787 DIRAC. Jiri Matas was supported by the Grant Agency of Czech Republic under Project 102/07/1317. This work was done while Karel Zimmermann was with the Czech Technical University.	Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; BENHIMANE S, 2007, P IEEE C COMP VIS PA; Bissacco A., 2007, 2007 IEEE C COMP VIS, P1, DOI [10.1109/CVPR.2007.383129, DOI 10.1109/CVPR.2007.383129]; Bollobas B., 1998, MODERN GRAPH THEORY; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; CRISTINACCE D, 2006, P 17 BRIT MACH VIS C, P929; DRUCKER H, 1996, ADV NEURAL INFORM PR, V9, P156; GRABNER H, 2006, P IEEE C COMP VIS PA, V1, P260, DOI DOI 10.1109/CVPR.2006.215; Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326; Herbert Bay, 2006, P 9 EUR C COMP VIS M; Jurie F., 2002, P BRIT MACHINE VISIO, V2002, P123, DOI [10.5244/C.16.10, DOI 10.5244/C.16.10]; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; OZUYSAL M, 2006, P EUR C COMP VIS, P592; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Smola A, 1998, TUTORIAL SUPPORT VEC; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167; ZHOU SK, 2005, P 10 IEEE INT C COMP, V1, P541, DOI DOI 10.1109/ICCV.2005.117; ZIMMERMANN K, 2008, THESIS CZECH TU	25	46	55	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					677	692		10.1109/TPAMI.2008.119	http://dx.doi.org/10.1109/TPAMI.2008.119			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407WX	19229083	Green Submitted			2022-12-18	WOS:000263396100008
J	Xu, ZJ; Chen, H; Zhu, SC; Luo, JB				Xu, Zijian; Chen, Hong; Zhu, Song-Chun; Luo, Jiebo			A hierarchical compositional model for face representation and sketching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face sketch; hierarchical; grammar model	RECOGNITION	This paper presents a hierarchical-compositional model of human faces, as a three-layer AND-OR graph to account for the structural variabilities over multiple resolutions. In the AND-OR graph, an AND-node represents a decomposition of certain graphical structure, which expands to a set of OR-nodes with associated relations; an OR-node serves as a switch variable pointing to alternative AND-nodes. Faces are then represented hierarchically: The first layer treats each face as a whole, the second layer refines the local facial parts jointly as a set of individual templates, and the third layer further divides the face into 15 zones and models detail facial features such as eye corners, marks, or wrinkles. Transitions between the layers are realized by measuring the minimum description length (MDL) given the complexity of an input face image. Diverse face representations are formed by drawing from dictionaries of global faces, parts, and skin detail features. A sketch captures the most informative part of a face in a much more concise and potentially robust representation. However, generating good facial sketches is extremely challenging because of the rich facial details and large structural variations, especially in the high-resolution images. The representing power of our generative model is demonstrated by reconstructing high-resolution face images and generating the cartoon facial sketches. Our model is useful for a wide variety of applications, including recognition, nonphotorealisitc rendering, superresolution, and low-bit rate face coding.	[Xu, Zijian] Moodys Corp, San Francisco, CA 94111 USA; [Chen, Hong] Brion Technol Inc, Santa Clara, CA 95054 USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Luo, Jiebo] Eastman Kodak Co, Kodak Res Labs, Rochester, NY 14650 USA	University of California System; University of California Los Angeles; Eastman Kodak	Xu, ZJ (corresponding author), Moodys Corp, Wall St Analyt,1 Front St,Suite 1900, San Francisco, CA 94111 USA.	zjxu@stat.ucla.edu; chenh@brion.com; sczhu@stat.ucla.edu; jiebo.luo@kodak.com	Luo, Jiebo/AAI-7549-2020	Luo, Jiebo/0000-0002-4516-9729				Abney SP, 1997, COMPUT LINGUIST, V23, P597; Baker S., 2000, P IEEE INT C AUT FAC; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BRUCE V, 1992, APPL COGNITIVE PSYCH, V6, P619, DOI 10.1002/acp.2350060705; CHEN H, 2001, P IEEE INT C COMP VI; CHEN H, 2006, P IEEE INT C COMP VI; COOTES TF, 2001, P IEEE INT C COMP VI; DAVIES RH, 2001, P BRIT MACH VIS C; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; GUO C, 2003, P IEEE INT C COMP VI; Hallinan P. W., 1999, 2 3 DIMENSIONAL PATT; Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0; HUA G, 2004, P IEEE INT C COMP VI; Jones MJ, 1998, INT J COMPUT VISION, V29, P107, DOI 10.1023/A:1008074226832; KANADE T, 1973, COMPUTER RECOGNITION; KOSHIMIZU H, 1999, P IEEE INT C SYST MA, V6, P294; LIANG L, 2006, P IEEE INT C COMP VI; Lindeberg T., 1994, SCALE SPACE THEORY C; LIU C, 2001, P IEEE INT C COMP VI; LIU C, 2002, P EUR C COMP VIS, P687; Martinez A., 1998, 24 CVC, P24; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Pearl J., 1984, INTELLIGENT SEARCH S; PENTLAND A, 1994, P IEEE INT C COMP VI; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; REKERS J, 1995, PARSING ALGORITHM CO; TANG X, 2003, P IEEE INT C COMP VI; TIAN Y, 2001, IEEE T PAMI, V23, P229; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; ULLMAN S, 2000, P BRIT MACH VIS C; Viola P. A., 2001, P IEEE INT C COMP VI; WEBER M, 2000, P IEEE INT C COMP VI; XIAO J, 2004, P IEEE INT C COMP VI; XU Z, 2007, P IEEE INT C COMP VI; XU ZJ, 2006, P INT C PATT REC; XU ZJ, 2005, P IEEE INT C COMP VI; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; YAO ZY, 2007, P INT WORKSH EN MIN; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; ZHAO W, 2000, 948 UMDC; Zhu S.-C., 2007, FDN TRENDS COMPUTER; Zhu XD, 1998, TAIWAN J MATH, V2, P1; [No title captured]	44	46	49	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					955	969		10.1109/TPAMI.2008.50	http://dx.doi.org/10.1109/TPAMI.2008.50			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421103	Green Submitted			2022-12-18	WOS:000254872500003
J	Dowson, N; Bowden, R				Dowson, Nicholas; Bowden, Richard			Mutual information for Lucas-Kanade tracking (MILK): An inverse compositional formulation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mutual information; registration; Newton optimization; tracking		Mutual Information (MI) is popular for registration via function optimization. This work proposes an inverse compositional formulation of MI for Levenberg-Marquardt optimization. This yields a constant Hessian, which may be precomputed. Speed improvements of 15 percent were obtained, with convergence accuracies similar those of the standard formulation.	Siemens Mol Imaging, Oxford OX1 2EP, England; Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	Siemens AG; University of Surrey	Dowson, N (corresponding author), Siemens Mol Imaging, 28-36 Hythe Bridge St, Oxford OX1 2EP, England.	nicholas.dowson@siemens.com; r.bowden@surrey.ac.uk	Dowson, Nicholas D H/B-7621-2017; Dowson, Nicholas/A-7537-2011; Bowden, Richard/AAF-8283-2019	Dowson, Nicholas D H/0000-0003-4694-5459; Dowson, Nicholas/0000-0003-4694-5459; Bowden, Richard/0000-0003-3285-8020				Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; BRENT RP, 1971, COMPUT J, V14, P422, DOI 10.1093/comjnl/14.4.422; Brooks R, 2006, INT C PATT RECOG, P1200; COLLIGNON A, 1995, COMP IMAG VIS, V3, P263; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403; Dowson N, 2006, LECT NOTES COMPUT SC, V3951, P365; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Maes F, 1999, Med Image Anal, V3, P373, DOI 10.1016/S1361-8415(99)80030-9; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; SHUM HY, 2000, INT J COMPUT VISION, V36, P63; Studholme C, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P27; Thevenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976; UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220; VIOLA P, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P16, DOI 10.1109/ICCV.1995.466930	20	46	47	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					180	185		10.1109/TPAMI.2007.70757	http://dx.doi.org/10.1109/TPAMI.2007.70757			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000334	Green Submitted			2022-12-18	WOS:000250843500015
J	Zhu, LJ; Zhou, ZT; Hu, DW				Zhu, Liangjia; Zhou, Zongtan; Hu, Dewen			Globally consistent reconstruction of ripped-up documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						reconstruction of ripped-up documents; compatibility; global consistency; gradient projection; relaxation	JIGSAW PUZZLES; RELAXATION; CURVES; SHAPE	One of the most crucial steps for automatically reconstructing ripped-up documents is to find a globally consistent solution from the ambiguous candidate matches. However, little work has been done so far to solve this problem in a general computational framework without using application-specific features. In this paper, we propose a global approach for reconstructing ripped-up documents by first finding candidate matches from document fragments using curve matching and then disambiguating these candidates through a relaxation process to reconstruct the original document. The candidate disambiguation problem is formulated in a relaxation scheme in which the definition of compatibility between neighboring matches is proposed, and global consistency is defined as the global criterion. Initially, global match confidences are assigned to each of the candidate matches. After that, the overall local relationships among neighboring matches are evaluated by computing their global consistency. Then, these confidences are iteratively updated using the gradient projection method to maximize the criterion. This leads to a globally consistent solution and, thus, provides a sound document reconstruction. The overall performance of our approach in several practical experiments is illustrated. The results indicate that the reconstruction of ripped-up documents up to 50 pieces is possibly accomplished automatically.	Natl Univ Def Technol, Coll Mechatron & Automat, Dept Automat Control, Robot Lab, Changsha 410073, Hunan, Peoples R China	National University of Defense Technology - China	Zhu, LJ (corresponding author), Natl Univ Def Technol, Coll Mechatron & Automat, Dept Automat Control, Robot Lab, Changsha 410073, Hunan, Peoples R China.	ljzhu@nudt.edu.cn; ztzhou@nudt.edu.cn; dwhu@nudt.edu.cn	Hu, Dewen/D-1978-2015; Hu, Dewen/AAN-8511-2020					Amigoni F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P581; ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509; Ballard D.H., 1982, COMPUTER VISION; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; BURDEA GC, 1989, IEEE T ROBOTIC AUTOM, V5, P752, DOI 10.1109/70.88097; Calabi E, 1998, INT J COMPUT VISION, V26, P107, DOI 10.1023/A:1007992709392; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; De Smet P, 2003, P SOC PHOTO-OPT INS, V5108, P189, DOI 10.1117/12.501078; Faber P, 2003, IEEE T PATTERN ANAL, V25, P1021, DOI 10.1109/TPAMI.2003.1217606; FABER P, 2001, EDIINFRR0057 U ED; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; FREEMAN H, 1964, IEEE T COMPUT, VEC13, P118, DOI 10.1109/PGEC.1964.263781; Goldsmith T.H., 1974, PHYSL INSECTA, VII, P165, DOI [10.1016/B978-0-12-591602-8.50012-6, DOI 10.1016/B978-0-12-591602-8.50012-6]; HILDITCH CJ, 1969, MACH INTELL, V4, P403; Hori K., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P440, DOI 10.1109/CVPR.1999.784718; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Kanoh M, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P478, DOI 10.1109/ICIAP.2001.957055; Kong WX, 2001, PROC CVPR IEEE, P583; LAM L, 1988, PATTERN RECOGN, V21, P19, DOI 10.1016/0031-3203(88)90068-4; Leitao HCD, 2002, IEEE T PATTERN ANAL, V24, P1239, DOI 10.1109/TPAMI.2002.1033215; LEVY M, 1988, P 9 INT C PATT REC R, P208; MATAS J, 1995, P INT C IM AN PROC, P13; McBride J.C., 2003, P 2003 C COMP VIS PA, P1; PAAIOANNOU G, 2002, IEEE T PATTERN ANAL, V24, P114; PAJDLA T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P390, DOI 10.1109/ICCV.1995.466913; Papaodysseus C, 2002, IEEE T SIGNAL PROCES, V50, P1277, DOI 10.1109/TSP.2002.1003053; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; Solana C, 2005, SIBGRAPI 2005: XVIII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, CONFERENCE PROCEEDINGS, P163; Ucoluk G, 1999, COMPUT GRAPH-UK, V23, P573, DOI 10.1016/S0097-8493(99)00075-8; UKOVICH A, 2004, P IEEE INT S SIGNAL, P18; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P810, DOI 10.1109/34.400572; Wolfson H., 1988, Annals of Operations Research, V12, P51, DOI 10.1007/BF02186360; WOLFSON HJ, 1990, IEEE T PATTERN ANAL, V12, P483, DOI 10.1109/34.55108; Yao FH, 2003, PATTERN RECOGN LETT, V24, P1819, DOI 10.1016/S0167-8655(03)00006-0; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	36	46	50	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					1	13		10.1109/TPAMI.2007.1163	http://dx.doi.org/10.1109/TPAMI.2007.1163			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000320				2022-12-18	WOS:000250843500001
J	Ying, XH; Zha, HB				Ying, Xianghua; Zha, Hongbin			Geometric interpretations of the relation between the image of the absolute conic and sphere images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						camera calibration; geometric interpretation; sphere image; image of the absolute conic; double-contact theorem	CAMERA CALIBRATION	A spherical object has been introduced into camera calibration for several years through utilizing the properties of an image conic, which is the projection of the occluding contour of a sphere in the perspective image. However, in literature, only an algebraic interpretation was presented for the relation between the image of the absolute conic and sphere images. In this paper, we propose two geometric interpretations of this relation and two novel camera calibration methods using sphere images are derived from these geometric interpretations.	Peking Univ, Natl Lab Machine Percept, Beijing 100871, Peoples R China	Peking University	Ying, XH (corresponding author), Peking Univ, Natl Lab Machine Percept, Beijing 100871, Peoples R China.	xhying@cis.pku.edu.cn; zha@cis.pku.edu.cn						Agrawal M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P782; BEARDSLEY P, 1992, LECT NOTES COMPUT SC, V588, P312; Daniilidis K, 1996, PROC CVPR IEEE, P708, DOI 10.1109/CVPR.1996.517150; Daucher N., 1994, P 3 EUR C COMP VIS, P449; Evelyn CJA, 1974, 7 CIRCLES THEOREM OT; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; HARTLEY RI, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P908; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; KANATANI K, 1993, CVGIP-IMAG UNDERSTAN, V58, P286, DOI 10.1006/ciun.1993.1043; Kim JS, 2005, IEEE T PATTERN ANAL, V27, P637, DOI 10.1109/TPAMI.2005.80; MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171; PENNA MA, 1991, IEEE T PATTERN ANAL, V13, P1240, DOI 10.1109/34.107007; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; Sturm P., 1999, P IEEE C COMP VIS PA, P432, DOI DOI 10.1109/CVPR.1999.786974; Teramoto H., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P499; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Ying XH, 2004, IEEE T PATTERN ANAL, V26, P1260, DOI 10.1109/TPAMI.2004.79; Zhang WG, 1999, APPL MATH MECH-ENGL, V20, P666	20	46	51	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					2031	2036		10.1109/TPAMI.2006.245	http://dx.doi.org/10.1109/TPAMI.2006.245			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108376				2022-12-18	WOS:000241195700012
J	Kirishima, T; Sato, K; Chihara, K				Kirishima, T; Sato, K; Chihara, K			Real-time gesture recognition by learning and selective control of visual interest points	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						gesture recognition; selective control; visual interest points; Gaussian density feature; real-time interaction	IMAGE CLASSIFICATION; FACE RECOGNITION; TRACKING; FUSION; MOTION; ATTENTION; STRATEGY; FEATURES; MODELS; TREES	For the real-time recognition of unspecified gestures by an arbitrary person, a comprehensive framework is presented that addresses two important problems in gesture recognition systems: selective attention and processing frame rate. To address the first problem, we propose the Quadruple Visual Interest Point Strategy. No assumptions are made with regard to scale or rotation of visual features, which are computed from dynamically changing regions of interest in a given image sequence. In this paper, each of the visual features is referred to as a visual interest point, to which a probability density function is assigned, and the selection is carried out. To address the second problem, we developed a selective control method to equip the recognition system with self-load monitoring and controlling functionality. Through evaluation experiments, we show that our approach provides robust recognition with respect to such factors as type of clothing, type of gesture, extent of motion trajectories, and individual differences in motion characteristics. In order to indicate the real-time performance and utility aspects of our approach, a gesture video system is developed that demonstrates full video-rate interaction with displayed image objects.	Nara Natl Coll Technol, Dept Elect Engn, Yamato Koriyama, Nara 6391080, Japan; Osaka Univ, Grad Sch Engn Sci, Dept Syst Innovat, Div Syst Sci & Appl Informat, Toyonaka, Osaka 5608531, Japan; Nara Inst Sci & Technol, Grad Sch Informat Sci, Ikoma, Nara 6300101, Japan	Osaka University; Nara Institute of Science & Technology	Kirishima, T (corresponding author), Nara Natl Coll Technol, Dept Elect Engn, 22 Yata Cho, Yamato Koriyama, Nara 6391080, Japan.	tosiyu-k@elec.nara-k.ac.jp; sato@sys.es.osaka-u.ac.jp; chihara@is.naist.jp						Backer G, 2001, IEEE T PATTERN ANAL, V23, P1415, DOI 10.1109/34.977565; Bharadwaj P, 2002, IEEE T PATTERN ANAL, V24, P1394, DOI 10.1109/TPAMI.2002.1039210; Bicego M, 2004, IEEE T PATTERN ANAL, V26, P281, DOI 10.1109/TPAMI.2004.1262200; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bressan M, 2003, IEEE T PATTERN ANAL, V25, P1312, DOI 10.1109/TPAMI.2003.1233904; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855; DARRELL T, 1995, P INT WORKSH AUT FAC, P135; Deng HW, 2004, IEEE T PATTERN ANAL, V26, P951, DOI 10.1109/TPAMI.2004.30; Denzler J, 2002, IEEE T PATTERN ANAL, V24, P145, DOI 10.1109/34.982896; DIORINOS M, 1996, P INT C VIRT SYST MU, P183; Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620; EKMAN P, 1995, P INT WORKSHOP AUTOM, P7; Freeman W T, 1995, P INT WORKSH AUT FAC, P296; Huang T. S., 1995, P INT WORKSH AUT FAC, P73; HUNTER E, 1995, P INT WORKSH AUT FAC, P290; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Kirishima T, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P579, DOI 10.1109/AFGR.1998.671010; KIRISHIMA T, 1996, P INT C VIRTUAL  SEP, P433; KIRISHIMA T, 1998, IEICE D 2 T D, V81, P785; KIRISHIMA T, 2001, IEICE D2 T D, V84, P2398; Kittler J, 2003, IEEE T PATTERN ANAL, V25, P110, DOI 10.1109/TPAMI.2003.1159950; Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809; Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601; MACKENZIE IS, 1993, P ACM C HUM FACT COM, P488; Maggioni C., 1995, P INT WORKSH AUT FAC, P166; MASE K, 1996, P INT C VIRTUAL  SEP, P107; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; QUEK F, 1994, P VIRT REAL SOFTW TE, P17; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; Raudys S, 2003, IEEE T PATTERN ANAL, V25, P1178, DOI 10.1109/TPAMI.2003.1227993; Salah AA, 2002, IEEE T PATTERN ANAL, V24, P420, DOI 10.1109/34.990146; So RHY, 1996, IEEE T SYST MAN CY A, V26, P445, DOI 10.1109/3468.508823; Song Y, 2003, IEEE T PATTERN ANAL, V25, P814, DOI 10.1109/TPAMI.2003.1206511; Storkey AJ, 2003, IEEE T PATTERN ANAL, V25, P859, DOI 10.1109/TPAMI.2003.1206515; Tagare HD, 2001, IEEE T PATTERN ANAL, V23, P490, DOI 10.1109/34.922707; THWAITES H, 1996, P INT C VIRTUAL  SEP, P19; Titsias MK, 2003, IEEE T PATTERN ANAL, V25, P924, DOI 10.1109/TPAMI.2003.1206521; Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568; Vega IR, 2003, IEEE T PATTERN ANAL, V25, P1323, DOI 10.1109/TPAMI.2003.1233906; Wiles CS, 2001, IEEE T PATTERN ANAL, V23, P1391, DOI 10.1109/34.977563; WILSON AD, 1995, P INT WORKSH AUT FAC, P129; Windridge D, 2003, IEEE T PATTERN ANAL, V25, P343, DOI 10.1109/TPAMI.2003.1182097; YAMAMOTO J, 1994, IEICE D, V77, P1311; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803; Yeung DS, 2002, IEEE T PATTERN ANAL, V24, P556, DOI 10.1109/34.993562	46	46	55	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					351	364		10.1109/TPAMI.2005.61	http://dx.doi.org/10.1109/TPAMI.2005.61			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747791				2022-12-18	WOS:000226300200005
J	Guest, E; Berry, E; Baldock, RA; Fidrich, M; Smith, MA				Guest, E; Berry, E; Baldock, RA; Fidrich, M; Smith, MA			Robust point correspondence applied to two and three-dimensional image registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image registration; iterative closest point; surface matching; point correspondence; image warping; image matching; serial sections; reconstruction		Accurate and robust correspondence calculations are very important in many medical and biological applications. Often, the correspondence calculation forms part of a rigid registration algorithm, but accurate correspondences are especially important for elastic registration algorithms and for quantifying changes over time. In this paper, a new correspondence calculation algorithm, CSM (Correspondence by Sensitivity to Movement), is described. A robust corresponding point is calculated by determining the sensitivity of a correspondence to movement of the point being matched. If the correspondence is reliable, a perturbation in the position of this point should not result in a large movement of the correspondence. A measure of reliability is also calculated. This correspondence calculation method is independent of the registration transformation and has been incorporated into both a 2D elastic registration algorithm for warping serial sections and a 3D rigid registration algorithm for registering pre and postoperative facial range scans. These applications use different methods for calculating the registration transformation and accurate rigid and elastic alignment of images has been achieved with the CSM method. It is expected that this method will be applicable to many different applications and that good results would be achieved if it were to be inserted into other methods for calculating a registration transformation from correspondences.	Leeds Metropolitan Univ, Sch Comp, Leeds LS6 3QS, W Yorkshire, England; Univ Leeds, Ctr Med Imaging Res, Leeds, W Yorkshire, England; Univ Leeds, Acad Unit Med Phys, Leeds, W Yorkshire, England; Western Gen Hosp, MRC, Human Genet Unit, Edinburgh EH4 2XU, Midlothian, Scotland; Attila Jozsef Univ, Res Grp Artificial Intelligence, Szeged, Hungary	Leeds Beckett University; University of Leeds; University of Leeds; University of Leeds; University of Edinburgh; Szeged University	Guest, E (corresponding author), Leeds Metropolitan Univ, Sch Comp, Beckett Pk Campus, Leeds LS6 3QS, W Yorkshire, England.	e.guest@lmu.ac.uk; e.berry@leeds.ac.uk; richard@hgu.mrc.ac.uk; fidrich@cc.u-szeged.hu; m.a.smith@leeds.ac.uk		Baldock, Richard/0000-0003-0332-6877; Fidrich, Marta/0000-0001-6160-6928				ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; Brett AD, 1999, LECT NOTES COMPUT SC, V1613, P376; Chui H, 1999, LECT NOTES COMPUT SC, V1613, P168; Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998; GOSHTASBY A, 1992, IEEE T MED IMAGING, V11, P507, DOI 10.1109/42.192686; Guest E., 1995, Bioimaging, V3, P154, DOI 10.1002/1361-6374(199512)3:4<154::AID-BIO2>3.3.CO;2-D; GUEST E, 1994, THESIS U EDINBURGH; HIBBARD LS, 1986, COMPUT BIOL MED, V16, P411, DOI 10.1016/0010-4825(86)90065-X; IBRAHIM W, 1999, IEEE T MED IMAGING, V17, P957; Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P234, DOI 10.1109/IM.1997.603871; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Koenderink J., 1990, SOLID SHAPE; Lester H, 1999, PATTERN RECOGN, V32, P129, DOI 10.1016/S0031-3203(98)00095-8; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; Pito R, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P85, DOI 10.1109/IM.1997.603852; REES DWA, 1990, MECH SOLIDS STRUCTUR; ROMENY BMT, 1991, LECT NOTES COMPUT SC, V511, P239, DOI 10.1007/BFb0033757; Subsol G, 1998, Med Image Anal, V2, P37, DOI 10.1016/S1361-8415(01)80027-X; TRUCCO E, 1995, IEEE T PATTERN ANAL, V17, P177, DOI 10.1109/34.368172; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; VERBEEK FJ, 1995, THESIS TU DELFT; ZHANG D, 1999, P 2 INT C 3D DIG IM, P209; ZHANG YJ, 1991, CYTOMETRY, V12, P308, DOI 10.1002/cyto.990120404	26	46	50	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2001	23	2					165	179		10.1109/34.908967	http://dx.doi.org/10.1109/34.908967			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	401NJ		Green Accepted			2022-12-18	WOS:000166933500006
J	Wada, T; Matsuyama, T				Wada, T; Matsuyama, T			Multiobject behavior recognition by event driven selective attention method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						behavior recognition; HMM; nondeterministic finite automata; selective attention mechanism; toke propagation; multiviewpoint image	NETWORKS; GESTURE	Recognizing multiple object behaviors from nonsegmented image sequences is a difficult problem because most of the motion recognition methods proposed so far share the limitation of the single-object assumption. Based on existing methods, the problem can be solved only by bottom-up image sequence segmentation followed by sequence classification. This straightforward approach totally depends on bottom-up segmentation which is easily affected by occlusions and outliers. This paper presents a completely novel approach for this task without using bottom-up segmentation. Our approach is based on assumption generation and verification, i.e., feasible assumptions about the present behaviors consistent with the input image and behavior models are dynamically generated and verified by finding their supporting evidence in input images. This can be realized by an architecture called the selective attention model, which consists of a state-dependent event detector and an event sequence analyzer. The former detects image variation (event) in a limited image region (focusing region), which is not affected by occlusions and outliers. The latter analyzes sequences of detected events and activates all feasible states representing assumptions about multiobject behaviors. In this architecture, event detection can be regarded as a verification process of generated assumptions because each focusing region is determined by the corresponding assumption. This architecture is sound since all feasible assumptions are generated. However, these redundant assumptions imply ambiguity of the recognition result. Hence, we further extend the system by introducing 1) colored-token propagation to discriminate different objects in state space and 2) integration of multiviewpoint image sequences to disambiguate the single-view recognition results. Extensive experiments of human behavior recognition in real world environments demonstrate the soundness and robustness of our architecture.	Kyoto Univ, Grad Sch Informat, Dept Intelligence Sci & Technol, Kyoto 6068501, Japan	Kyoto University	Wada, T (corresponding author), Kyoto Univ, Grad Sch Informat, Dept Intelligence Sci & Technol, Kyoto 6068501, Japan.	twada@i.kyoto-u.ac.jp; tm@i.kyoto-u.ac.jp						Akaike H., 1973, 2 INT S INFORM THEOR, P267, DOI DOI 10.1007/978-1-4612-1694-0_15; Bobick AF, 1998, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1998.698609; Brand M, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P94, DOI 10.1109/AFGR.1996.557249; BREGLER C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P494, DOI 10.1109/ICCV.1995.466899; DEKLEER J, 1986, ARTIF INTELL, V28, P127, DOI 10.1016/0004-3702(86)90080-9; GHAHRAMANI Z, 1995, 9502 MIT COMP COGN S; HOPCROFT JE, 1979, INTRO AUTOMATA THEOR, pCH2; JORDAN MI, 1996, 9606 MIT COMP COGN S; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MEIER U, 1999, P INT C MULT INT; RABINER L, 1988, IEEE ACOUSTIC SPEECH, P4; RAND M, 1997, P COMPUTER VISION PA, P994; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SAUL LK, 1995, ADV NEURAL INFORMATI, V7; Starner T., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P265, DOI 10.1109/ISCV.1995.477012; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; TOYAMA K, 1999, INT C COMP VIS, P255, DOI DOI 10.1109/ICCV.1999.791228; WADA T, 1996, P ICPR96, VA, P718; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; WILSON A, 1995, 337 MIT MED LAB PERC; Wilson AD, 1998, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.1998.698708; YAMATO J, 1992, P COMPUTER VISION PA, P664; Yang MH, 1998, PROC CVPR IEEE, P892, DOI 10.1109/CVPR.1998.698710	23	46	48	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2000	22	8					873	887		10.1109/34.868687	http://dx.doi.org/10.1109/34.868687			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	354GN					2022-12-18	WOS:000089321500012
J	Tsap, LV; Goldgof, DB; Sarkar, S				Tsap, LV; Goldgof, DB; Sarkar, S			Nonrigid motion analysis based on dynamic refinement of finite element models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						physically-based vision; deformable models; nonrigid motion analysis; biomedical applications; finite element analysis	INTERFACE; IMAGES	In this paper, we propose new algorithms for accurate nonrigid motion tracking. Given an initial model representing general knowledge of the object, a set of sparse correspondences, and incomplete or missing information about geometry or material properties, we can recover dense motion vectors using finite element models. The method is based on the iterative analysis of the differences between the actual and predicted behavior. Large differences indicate that an object's properties are not captured properly by the model describing it. Feedback from the images during the motion allows the refinement of the model by minimizing the error between the expected and true position of the object's points. These errors are due to flaws in the model parameter estimation such as geometry and material properties. Unknown parameters are recovered using an iterative descent search for the best nonlinear finite element model that approximates nonrigid motion of the given object. During this search process, we not only estimate material properties. but also infer dense point correspondences from our initial set of sparse correspondences. Thus, during tracking, the model is refined which, in turn, improves tracking quality. As a result, we obtain a more precise description of nonrigid motion. Experimental results demonstrate the success of the proposed algorithm. The method was applied to man-made elastic materials and human skin to recover unknown elasticity. to complex 3D objects to find details of their geometry, and to a hand motion analysis application. Our work demonstrates the possibility of accurate quantitative analysis of nonrigid motion in range image sequences with objects consisting of multiple materials and 3D volumes.	Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94551 USA; Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	United States Department of Energy (DOE); Lawrence Livermore National Laboratory; State University System of Florida; University of South Florida	Tsap, LV (corresponding author), Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94551 USA.	tsap1@llnl.gov; goldgof@bigpine.csee.usf.edu; sarkar@bigpine.csee.usf.edu	Sarkar, Sudeep/A-8213-2009; Goldgof, Dmitry/ABF-1366-2020; Sarkar, Sudeep/ABD-7629-2021	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207				Aggarwal JK, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P90, DOI 10.1109/NAMW.1997.609859; Alexander R.M., 1992, HUMAN MACHINE; Basu S, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P46, DOI 10.1109/NAMW.1997.609851; Brauer JR, 1993, WHAT EVERY ENG SHOUL; BRIDGEMAN GB, 1979, BRIDGEMANS COMPLETE; BURNETT DS, 1988, FINITE ELEMENT ANAL; Davis MH, 1997, IEEE T MED IMAGING, V16, P317, DOI 10.1109/42.585766; DECARLO D, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P834, DOI 10.1109/ICCV.1995.466851; Delingette H., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P152, DOI 10.1109/MNRAO.1994.346242; Fung Y., 1993, BIOMECHANICS MECH PR, DOI 10.1007/978-1-4757-2257-4; HUANG WC, 1993, P AS C COMP VIS OS J, P256; Hughes TJR, 1984, THEORETICAL FDN LARG; Kita Y, 1996, IEEE T PATTERN ANAL, V18, P1150, DOI 10.1109/34.546253; KUCH JJ, 1995, VISION BASED HAND MO, P666; LARRABEE WF, 1986, LARYNGOSCOPE, V96, P399; MAENO T, 1996, P 10 C EUR C BIOM, P3122; Metaxas D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P337, DOI 10.1109/CVPR.1991.139712; METAXAS D, 1993, SPIE, V2031, P160; Nastar C, 1996, IEEE T PATTERN ANAL, V18, P1067, DOI 10.1109/34.544076; Neuenschwander W., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P828, DOI 10.1109/ICCV.1995.466852; OOMENS CWJ, 1985, THESIS TH TWENTE NET; Press WH, 1988, NUMERICAL RECIPES C; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; REHG JM, 1994, P EUR C COMP VIS, V2, P35; Sclaroff S., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P158, DOI 10.1109/MNRAO.1994.346241; SilverThorn MB, 1996, J REHABIL RES DEV, V33, P253; *SWANS AN SYST INC, 1996, ANSYS US MAN REV 5 3; TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, P580; THACKER JG, 1976, THESIS U VIRGINIA; TODD BA, 1994, J REHABIL RES DEV, V31, P111; Tsap LV, 1998, IEEE T MED IMAGING, V17, P620, DOI 10.1109/42.730406; Tsap LV, 1999, IMAGE VISION COMPUT, V17, P997, DOI 10.1016/S0262-8856(98)00185-1; Tsap LV, 1998, COMPUT VIS IMAGE UND, V69, P330, DOI 10.1006/cviu.1998.0663; VANNAH WM, 1993, J REHABIL RES DEV, V30, P205; WEISS JA, 1995, P 2 WORLD C BIOM AMS, P149; Young A., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P399, DOI 10.1109/CVPR.1992.223158; ZHANG M, 1995, MED ENG PHYS, V17, P559, DOI 10.1016/1350-4533(95)00002-5	37	46	51	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2000	22	5					526	543		10.1109/34.857007	http://dx.doi.org/10.1109/34.857007			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	337FV					2022-12-18	WOS:000088347500008
J	Tang, CK; Medioni, G				Tang, CK; Medioni, G			Inference of integrated surface, curve, and junction descriptions from sparse 3D data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation and feature extraction; integrated shape description; surface orientation discontinuity; surface and curve extremality		We are interested in descriptions of 3D data sets, as obtained from stereo or a 3D digitizer. We therefore consider as input a sparse set of points, possibly associated with certain orientation information. In this paper, we address the problem of inferring integrated high-level descriptions such as surfaces, So curves, and junctions from a sparse point set. While the method proposed by Guy and Medioni provides excellent results for smooth structures, it only detects surface orientation discontinuities but does not localize them. For precise localization, we propose a noniterative cooperative algorithm in which surfaces, curves, and junctions work together: Initial estimates are computed based on the work by Guy and Medioni, where each point in the given sparse and possibly noisy point set is convolved with a predefined vector mask to produce dense saliency maps. These maps serve as input to our novel extremal surface and curve algorithms for initial surface and curve extraction. These initial features are refined and integrated by using excitatory and inhibitory fields. Consequently, intersecting surfaces (resp. curves) are fused precisely at their intersection curves (resp. junctions). Results on several synthetic as well as real data sets are presented.	Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA	University of Southern California	Tang, CK (corresponding author), Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.	chitang@iris.usc.edu; medioni@iris.usc.edu						Blake A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P62; Boissonnat J. D., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P830; Boult T. E., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P68; Cormen T., INTRO ALGORITHMS; FUA P, 1992, P EUR C COMP VIS SAN, P676; Guy G, 1997, IEEE T PATTERN ANAL, V19, P1265, DOI 10.1109/34.632985; Han S, 1996, IEEE VISUAL, P295, DOI 10.1109/VISUAL.1996.568122; Hilton A, 1998, COMPUT VIS IMAGE UND, V69, P273, DOI 10.1006/cviu.1998.0664; Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Lee MS, 1998, PROC CVPR IEEE, P346, DOI 10.1109/CVPR.1998.698629; LIAO C, 1994, CAD94 WORKSH PITTSB; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Nielson G. M., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P83, DOI 10.1109/VISUAL.1991.175782; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; ROTH G, GRAPHICS INTERFACE 9, P173; Szeliski R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P82, DOI 10.1109/CVPR.1993.340975; Tang CK, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P818, DOI 10.1109/ICCV.1998.710812; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; Terzopoulos D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P70, DOI 10.1109/CVPR.1991.139663; Thirion JP, 1996, GRAPH MODEL IM PROC, V58, P503, DOI 10.1006/gmip.1996.0042; Vasilescu M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P829, DOI 10.1109/CVPR.1992.223247; Wheeler MD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P917, DOI 10.1109/ICCV.1998.710826	25	46	48	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1998	20	11					1206	1223		10.1109/34.730555	http://dx.doi.org/10.1109/34.730555			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	138TX					2022-12-18	WOS:000076990100007
J	WHEELER, MD; IKEUCHI, K				WHEELER, MD; IKEUCHI, K			SENSOR MODELING, PROBABILISTIC HYPOTHESIS GENERATION, AND ROBUST LOCALIZATION FOR OBJECT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; 3D OBJECT RECOGNITION; PROBABILISTIC RECOGNITION; MARKOV RANDOM FIELDS; ROBUST POSE ESTIMATION	3-D OBJECTS; REPRESENTATION; IMAGE	In an effort to make object recognition efficient and accurate enough for real applications, we have developed three probabilistic techniques-sensor modeling, probabilistic hypothesis generation, and robust localization-which form the basis of a promising paradigm for object recognition. Our techniques effectively exploit prior knowledge to reduce the number of hypotheses that must be tested during recognition. Our recognition approach utilizes statistical constraints on the matches between image and model features. These statistical constraints are computed using a model of the entire sensing process-resulting in more realistic and tighter constraints on matches. The candidate hypotheses are pruned by probabilistic constraint satisfaction to select likely matches based on the image evidence and prior statistical constraints. The resulting hypotheses are ordered most-likely first for verification, thus minimizing unnecessary verifications. The reliability of the verification decision is significantly increased by the use of a robust localization algorithm. Our localization algorithm reliably locates objects despite partial occlusion and significant errors in initial location estimates. We have implemented these techniques in a system that recognizes polyhedral objects in range images. Our results demonstrate accurate recognition while greatly limiting the number of verifications.	CARNEGIE MELLON UNIV,SCH COMP SCI,INST ROBOT,PITTSBURGH,PA 15213	Carnegie Mellon University	WHEELER, MD (corresponding author), CARNEGIE MELLON UNIV,SCH COMP SCI,DEPT COMP SCI,PITTSBURGH,PA 15213, USA.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; BENARIE J, 1990, IEEE T PATTERN ANAL, V12, P760, DOI 10.1109/34.57667; BESI PJ, 1992, IEEE T PATTERN ANAL, V14, P239; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; BOLLE RM, 1992, IEEE T PATT ANAL MAC, V14; BOLLE RM, 1986, IEEE T PATT ANAL MAC, V8; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; Breuel T. M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P445, DOI 10.1109/CVPR.1992.223152; Burns J. B., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P328, DOI 10.1109/CVPR.1992.223255; CAMPS OI, 1991, IEEE WORKSHOP DIRECT, P11; CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995; COOPER P, 1989, THESIS U ROCHESTER; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P1066, DOI 10.1109/34.99239; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; FUJIWARA Y, 1991, CMURITR9116 CARN MEL; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GRIMSON WEL, 1991, MIT1250 TECH REP; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; IKEUCHI K, 1987, INT J COMPUT VISION, V1, P145, DOI 10.1007/BF00123163; IKEUCHI K, 1991, IEEE T ROBOTIC AUTOM, V7, P771, DOI 10.1109/70.105386; KASS M, 1987, INT J COMPUTER VISIO, V2, P322; KRIEGMAN D, 1989, DARPA IUS WORKSHOP, P461; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; PRESS WH, 1991, NUMERICAL RECIPES C; WELLS WM, 1992, THESIS MIT; WHEELER MD, 1994, 2ND P CAD BAS VIS WO, P46	29	46	47	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1995	17	3					252	265		10.1109/34.368190	http://dx.doi.org/10.1109/34.368190			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QM090					2022-12-18	WOS:A1995QM09000003
J	SMITH, SJ; BOURGOIN, MO; SIMS, K; VOORHEES, HL				SMITH, SJ; BOURGOIN, MO; SIMS, K; VOORHEES, HL			HANDWRITTEN CHARACTER CLASSIFICATION USING NEAREST-NEIGHBOR IN LARGE DATABASES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							DISTANCE	We show that systems built on a simple statistical technique and a large training database can be automatically optimized to produce classification accuracies of 99% in the domain of handwritten digits. It is also shown that the performance of these systems scale consistently with the size of the training database, where the error rate is cut by more than half for every tenfold increase in the size of the training set from 10 to 100,000 examples. Three distance metrics for the standard Nearest Neighbor classification system are investigated: a simple Hamming distance metric, a pixel distance metric, and a metric based on the extraction of penstroke features. Systems employing these metrics were trained and tested on a standard, publicly available, database of nearly 225,000 digits provided by the National Institute of Standards and Technology. Additionally, a confidence metric is both introduced by the authors and also discovered and optimized by the system. The new confidence measure proves to be superior to the commonly used Nearest Neighbor distance.	TASC,READING,MA 01867		SMITH, SJ (corresponding author), THINKING MACHINES CORP,245 1ST ST,CAMBRIDGE,MA 02142, USA.							AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AHMED P, 1987, INT J PATTERN RECOGN; ATKESON C, 1986, MIT942 AI LAB TECH R; BORGEFORS G, 1990, SIGNAL PROCESS, V21, P61, DOI 10.1016/0165-1684(90)90027-V; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; CHURCH K, 1986, UNPUB STOCHASTIC PAR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DASRATHY B, 1990, NEAREST NEIGHBOR PAT; Garris M.D., NIST SPECIAL DATABAS; HINTON G, 1992, ADV NEURAL INFORMATI, V4; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; KELLY J, 1991, 12TH P INT JOINT C A; KELLY J, 1991, 4TH P INT C GEN ALG; MASAND B, 1993, APR AIAA SPR S CAS B; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; SMITH S, 1992, SUPERCOMPUTING S 92, P377; Stanfill C., 1986, Communications of the ACM, V29, P1213, DOI 10.1145/7902.7906; WIDROW B, 1973, PATTERN RECOGN, V5, P175, DOI 10.1016/0031-3203(73)90042-3; WILKINDON RA, 1992, NISTIR4912 NAT I STA	22	46	51	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					915	919		10.1109/34.310689	http://dx.doi.org/10.1109/34.310689			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802					2022-12-18	WOS:A1994PE80200009
J	FISCHLER, MA; WOLF, HC				FISCHLER, MA; WOLF, HC			LOCATING PERCEPTUALLY SALIENT POINTS ON PLANAR CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; SALIENT POINTS; CRITICAL POINTS; CURVE PARTITIONING; CURVE SEGMENTATION; CURVE DESCRIPTION	DIGITAL CURVES; SHAPE	This paper describes the underlying ideas and algorithmic details of a computer program that performs at a human level of competence for a significant subset of the curve partitioning task. It extends and rounds out the technique and philosophical approach originally presented in a 1986 paper by Fischler and Bolles. In particular, it provides a unified strategy for selecting and dealing with interactions between salient points, even when these points are salient at different scales of resolution. Experimental results are presented involving on the order of 1000 real and synthetically generated images.	SAN JOSE STATE UNIV,SAN JOSE,CA 95192; STANFORD UNIV,STANFORD,CA 94305; UNIV CALIF BERKELEY,BERKELEY,CA 94720	California State University System; San Jose State University; Stanford University; University of California System; University of California Berkeley	FISCHLER, MA (corresponding author), SRI INT,MENLO PK,CA 94025, USA.							ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; BENGTSSON A, 1991, IEEE T PATTERN ANAL, V13, P85, DOI 10.1109/34.67634; CLINE AK, 1974, COMMUN ACM, V17, P218, DOI 10.1145/360924.360971; DAVIS LS, 1977, IEEE T COMPUT, V26, P236, DOI 10.1109/TC.1977.1674812; DRESCHLER L, 1981, 7TH P INT JOINT C AR, P692; Fischler M., 1987, READINGS COMPUTER VI, P204; FISCHLER MA, 1980, COMPUT VISION GRAPH, V13, P334, DOI 10.1016/0146-664X(80)90032-5; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; FISCHLER MA, 1983, JUN P IEEE CVPR 83, P351; Hilbert D., 1952, GEOMETRY IMAGINATION; HOFFMAN DD, 1982, P AAAI, P5; IMAI H, 1986, COMPUT VISION GRAPH, V36, P31, DOI 10.1016/S0734-189X(86)80027-5; Lowe D. G., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P558, DOI 10.1109/CCV.1988.590036; MEHROTRA R, 1990, PATTERN RECOGN, V23, P1223, DOI 10.1016/0031-3203(90)90118-5; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; RANGARAJAN K, 1988, 2ND P ICCV TAMP; RICHARDS W, 1986, J OPT SOC AM A, V3, P1483, DOI 10.1364/JOSAA.3.001483; RICHARDS W, 1986, HUMAN MACHINE VISION, V2, P207; ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; Witkin AP, 1983, 8 INT JOINT C ART IN, P1019; WUESCHER DM, 1991, IEEE T PATTERN ANAL, V13, P41, DOI 10.1109/34.67629	24	46	47	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1994	16	2					113	129		10.1109/34.273737	http://dx.doi.org/10.1109/34.273737			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NA631					2022-12-18	WOS:A1994NA63100001
J	COHEN, FS; WANG, JY				COHEN, FS; WANG, JY			MODELING IMAGE CURVES USING INVARIANT 3-D OBJECT CURVE MODELS - A PATH TO 3-D RECOGNITION AND SHAPE ESTIMATION FROM IMAGE CONTOURS .1.	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AFFINE INVARIANCE; AFFINE INVARIANT CURVE MATCHING; B-SPLINES; BAYESIAN SELECTION; CONTROL POINTS; IMAGE CONTOURS; MMSE ESTIMATION; ORDER OF THE B-SPLINE	REPRESENTATION	These twin papers are concerned with the problems of 3-D object recognition and Shape estimation from image curves using a 3-D object curve model that is invariant to affine transformation onto the image space, and a binocular stereo imaging system. The objects of interest here are the ones that have markings (e.g., characters, letters, special drawings and symbols, etc.) on their surfaces. The 3-D curves on the object are modeled as B-splines, which are characterized by a set of parameters (the control points) from which the 3-D curve can be totally generated. The B-splines are invariant under affine transformations. That means that the affine projected object curve onto the image space is a B-spline whose control points are related to the object control points through the affine transformation. Part I presented here deals with issues relating to the curve modeling process. In particular, we address the problems of estimating the control points from the data curve, and of deciding on the ''best'' order B-spline and the ''best'' number of control points to be used to model the image or object curve(s). A minimum mean-square error (mmse) estimation technique which is invariant to affine transformations is presented as a noniterative, simple, and fast approach for control point estimation. The ''best'' B-spline is decided upon using a Bayesian selection rule. Finally, we present a matching algorithm that allocates a sample curve to one of p prototype curves when the sample curve is an a priori unknown affine transformation of one of the prototype curves stored in the data base. The approach is tried on a variety of images of real objects.	CHUNG CHENG INST TECHNOL,DEPT INFORMAT SCI,TAYUAN,TAIWAN		COHEN, FS (corresponding author), DREXEL UNIV,DEPT ELECT & COMP ENGN,PHILADELPHIA,PA 19104, USA.		Rohlf, F J/A-8710-2008					ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BESL PJ, 1989, ANAL INTERPRETATION; BOLLE RM, 1984, IEEE T PATTERN ANAL, V6; Cohen F. S., 1992, Proceedings. IEEE Workshop on Applications of Computer Vision (Cat. No.92TH0446-5), P213, DOI 10.1109/ACV.1992.240308; COHEN FS, 1991, CVGIP-GRAPH MODEL IM, V53, P501, DOI 10.1016/1049-9652(91)90001-Z; COOPER DB, 1974, IEEE T INFORM THEORY, V12; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; Duda R.O., 1973, J ROYAL STAT SOC SER; Faux ID, 1979, COMPUTATIONAL GEOMET; Gordon WJ., 1974, COMPUT AIDED GEOM D, P95, DOI [10.1016/B978-0-12-079050-0.50011-4, DOI 10.1016/B978-0-12-079050-0.50011-4]; HUANG Z, 1993, P 93 SPIE C  APPLICA, V9; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; KAYSHAP R, 1982, IEEE T PATTERN ANAL, V4; KEREN D, 1992, P DARPA IMAGE UNDERS; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PAGLIERONI DW, 1988, COMPUT VISION GRAPH, V42, P87, DOI 10.1016/0734-189X(88)90144-2; PAVLIDIS T, 1975, IEEE T SYST MAN CYB, V5, P610, DOI 10.1109/TSMC.1975.4309402; Persoon Eric, 1986, IEEE T PATTERN ANAL; PHILBRICK O, 1968, PICTORIAL PATTERN RE, P395; PRESS WH, 1988, NUMERICAL RECIPESA C; Rogers D.F., 1990, MATH ELEMENTS COMPUT, Vsecond; Rosenfeld A., 1982, DIGITAL PICTURE PROC; SAGHRI JA, 1981, IEEE T PATTERN ANAL, V3, P533, DOI 10.1109/TPAMI.1981.4767146; SCHOENBERG IJ, 1946, Q APPL MATH, V4, P112, DOI 10.1090/qam/16705; SCHOENBERG IJ, 1946, Q APPL MATH, V4, P45, DOI 10.1090/qam/15914; WANG JY, 1991, THESIS DREXEL U PHIL; ZACKS S, 1981, PARAMETRIC STATISTIC; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	29	46	56	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1994	16	1					1	12		10.1109/34.273721	http://dx.doi.org/10.1109/34.273721			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MV733					2022-12-18	WOS:A1994MV73300001
J	FARAGO, A; LINDER, T; LUGOSI, G				FARAGO, A; LINDER, T; LUGOSI, G			FAST NEAREST-NEIGHBOR SEARCH IN DISSIMILARITY SPACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						AVERAGE COMPLEXITY; DISSIMILARITY SPACES; FAST NEAREST-NEIGHBOR SEARCH; PATTERN RECOGNITION; PROBABILISTIC ANALYSIS OF ALGORITHMS	ALGORITHM	A fast nearest-neighbor algorithm is presented. It works in general spaces where the known cell (bucketing) techniques cannot be implemented for various reasons, such as the absence of coordinate structure and/or high dimensionality. The central idea has already appeared several times in the literature with extensive computer simulation results. This paper provides an exact probabilistic analysis or this family of algorithms, proving its O(1) asymptotic average complexity measured in the number of dissimilarity calculations.			FARAGO, A (corresponding author), TECH UNIV BUDAPEST,H-1521 BUDAPEST,HUNGARY.			Lugosi, Gabor/0000-0003-1614-5901				BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; Berge C., 1973, GRAPHS HYPERGRAPHS; Dobkin D., 1976, SIAM Journal on Computing, V5, P181, DOI 10.1137/0205015; FARAGO A, 1988, HIRADASTECHNIKA, V49; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; LINDER T, 1990, JAN IEEE INT S INF T; MOTOISHI K, 1990, JAN IEEE INT S INF T; SETHI IK, 1981, IEEE T SYST MAN CYB, V11, P245; VIDAL E, 1988, IEEE T ACOUST SPEECH, V36, P651, DOI 10.1109/29.1575; VIDAL E, 1988, RECENT ADV SPEECH UN; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, P145, DOI 10.1016/0167-8655(86)90013-9; Wheeden R. L., 1977, MEASURE INTEGRAL; [No title captured]	13	46	52	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					957	962		10.1109/34.232083	http://dx.doi.org/10.1109/34.232083			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600011
J	DEMICHELI, E; TORRE, V; URAS, S				DEMICHELI, E; TORRE, V; URAS, S			THE ACCURACY OF THE COMPUTATION OF OPTICAL-FLOW AND OF THE RECOVERY OF MOTION PARAMETERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							SEQUENCES; IMAGE; FIELD	In this paper, the accuracy and the dependence on parameters of a general scheme for the analysis of time-varying image sequences is presented. The approach, which is based on a modification of a recently proposed technique for the computation of optical How (Verri et al. [43]), is able to produce vector fields from which it is possible to recover 3-D motion parameters such as time-to-collision and angular velocity. The numerical stability of the computed optical flow and the dependence of the recovery of 3-D motion parameters on spatial and temporal filtering is investigated. By considering optical flows computed on subsampled images or along single scanlines, it is also possible to recover 3-D motion parameters from reduced optical flows. An adequate estimate of time-to-collision can be obtained from sequences of images with spatial resolution reduced to 128 x 128 pixels or from sequences of single scanlines passing near the focus of expansion. The use of Kalman filtering increases the accuracy and the robustness of the estimation of motion parameters. The proposed approach seems to be able to provide not only a theoretical background but also practical tools that are adequate for the analysis of time-varying image sequences.	UNIV GENOA, DIPARTIMENTO FIS, I-16126 GENOA, ITALY; THREE M ITALIA SPA, FERRANIA, ITALY	University of Genoa	DEMICHELI, E (corresponding author), CNR, IST CIBERNET & BIOFIS, GENOA, ITALY.			De Micheli, Enrico/0000-0002-8058-045X				AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; BLACK MJ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P33; BOUTHEMY P, 1990, KINEMATIC DYNAMIC IS, P223; Bucy R.S., 1968, FILTERING STOCHASTIC; BULTHOFF HH, 1987, J OPT SOC AM A, V4; Burt P. J., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P269; CAMPANI M, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P22; DEMICHELI E, 1989, P NATO ARW NEUROCOMP; DEMICHELI E, 1990, 1ST P EUR C COMP VIS; DICKMANNS ED, 1990, IEEE T SYST MAN CYB, V20, P1273, DOI 10.1109/21.61200; FAUGERAS OD, 1987, 1ST P INT C COMP VIS, P25; FENMENA CL, 1979, COMPUT GRAPH IMAGE P, P301; FRANCOIS E, 1990, IMAGE VISION COMPUT, V8, P279, DOI 10.1016/0262-8856(90)80004-D; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; HARRIS C, 1990, 1ST P EUR C COMP VIS; HEITZ F, 1990, IRISA561 TECH REP; Hildreth E., 1984, MEASUREMENT VISUAL M; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Kalman R.E., 1969, TOPICS MATH SYSTEMS; KOENDERINK JJ, 1986, VISION RES, V26, P161, DOI 10.1016/0042-6989(86)90078-7; KOENDERINK JJ, 1977, KIBERNETICS; Lanczos C., 1996, LINEAR DIFFERENTIAL; LITTLE J, 1989, P IEEE WORKSHOP VISU; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LOWE DG, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P436; MITICHE A, 1987, PATT RECOGN, V20; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1984, 1 P C IM TRAIT SYNTH, P545; NAGEL HH, 1990, 1ST P EUR C COMP VIS; NELSON RC, 1989, IEEE T PATTERN ANAL, V11, P1102, DOI 10.1109/34.42840; REICHART W, 1988, NATURWISSENSCHAFTEN; ROACH JW, 1979, IEEE T PATTERN ANAL, V1, P127, DOI 10.1109/TPAMI.1979.4766898; SCHUNCK BG, 1988, IMAGE FLOW FUNDAMENT; Tikhonov A.N., 1977, SOLUTION ILL POSED P; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; TSAI RY, 1982, R921 U ILLINOIS URBA; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; VERRI A, 1989, J OPT SOC AM A, V6, P698, DOI 10.1364/JOSAA.6.000698; VERRI A, 1990, J OPT SOC AM A, V7, P912, DOI 10.1364/JOSAA.7.000912; VERRI A, 1989, 5TH P ALV VIS C; WAXMAN A, 1987, ADV COMPUTER VIS; YAMAMOTO M, 1989, IEEE T PATTERN ANAL, V11, P528, DOI 10.1109/34.24785; ZHUANG XH, 1986, J OPT SOC AM A, V3, P1492, DOI 10.1364/JOSAA.3.001492	46	46	46	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					434	447		10.1109/34.211464	http://dx.doi.org/10.1109/34.211464			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470					2022-12-18	WOS:A1993LB47000002
J	NOMURA, Y; SAGARA, M; NARUSE, H; IDE, A				NOMURA, Y; SAGARA, M; NARUSE, H; IDE, A			SIMPLE CALIBRATION ALGORITHM FOR HIGH-DISTORTION-LENS CAMERA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CAMERA CALIBRATION; HIGH ACCURACY; IMAGE DISTORTION; INTRINSIC PARAMETERS; MODEL FITTING; 3-D MEASUREMENT		This paper presents a simple and useful calibration method for a TV camera with a high-distortion lens. The parameters to be calibrated are effective focal length, one-pixel width on an image plane, image distortion center, and distortion coefficient. A simple-pattern calibration chart composed of parallel straight lines is introduced as a reference for calibration. An ordinary 2-D model fitting is decomposed into two 1-D model fittings on the column and row of a frame buffer across the image distortion center by ingeniously utilizing the point symmetry characteristic of image distortion. Some parameters with a calibration chart are eliminated by setting up a calibration chart precisely and by utilizing negligibly low distortion near the image distortion center. Thus, the number of unknown parameters to be calibrated is drastically decreased, enabling simple and useful calibration. Furthermore, effectiveness of the proposed calibration method is confirmed by experimentation.	NIPPON TELEGRAPH & TELEPHONE CORP,SAKAI BRANCH,SAKAI,JAPAN; NIPPON TELEGRAPH & TELEPHONE CORP,TRANSMISS SYST LABS,TOKAI,IBARAKI,JAPAN	Nippon Telegraph & Telephone Corporation; Nippon Telegraph & Telephone Corporation	NOMURA, Y (corresponding author), NAGOYA UNIV,DEPT INFORMAT ENGN,NAGOYA,AICHI 464,JAPAN.							LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781; Naruse H., 1987, Systems and Computers in Japan, V18, P1, DOI 10.1002/scj.4690181201; NOMURA Y, 1988, T ASME, V110, P92; PAUL RP, 1983, ROBOT MANIPULATORS, P45; Tsai R.Y., 1986, P IEEE C COMP VIS PA, P364	5	46	67	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1992	14	11					1095	1099		10.1109/34.166624	http://dx.doi.org/10.1109/34.166624			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JX370					2022-12-18	WOS:A1992JX37000004
J	BURGER, W; BHANU, B				BURGER, W; BHANU, B			ESTIMATING 3-D EGOMOTION FROM PERSPECTIVE IMAGE SEQUENCES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									HONEYWELL INC,CTR SYST & RES,SIGNAL & IMAGE PROC GRP,MINNEAPOLIS,MN 55418; HONEYWELL INC,CTR SYST & RES,SCENE DYNAM PROGRAM,MINNEAPOLIS,MN 55418	Honeywell; Honeywell				Bhanu, Bir/0000-0001-8971-6416				ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ANANDAN P, 1984, SPIE INTELL ROBOTS C, V521, P184; Bandopadhay A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P498; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BHANU B, 1989, MAY P DARPA IM UND W; BHANU B, 1987, DARPA DACA7686C0017; BHANU B, 1988, APR P DARPA IM UND W, P289; BHARWANI S, 1986, MAY P WORKSH MOT REP, P73; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; Burger W., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P736, DOI 10.1109/CVPR.1988.196316; BURGER W, 1987, 10TH P INT JOINT C A; BURGHARD W, 1989, KRIMINALISTIK, P563; FANG JQ, 1984, IEEE T PATTERN ANAL, V6, P545, DOI 10.1109/TPAMI.1984.4767569; FAUGERAS OD, 1987, 1ST P INT C COMP VIS, P25; HARALICK RM, 1980, COMPUT VISION GRAPH, V13, P191, DOI 10.1016/0146-664X(80)90046-5; JERIAN C, 1984, IEEE T PATTERN ANAL, V6, P523, DOI 10.1109/TPAMI.1984.4767558; KIM J, 1987, 87SRC38 HON SYST RES; LAWTON DT, 1983, COMPUT VISION GRAPH, V22, P114; LEE DN, 1980, PHILOS T R SOC B, V290, P169, DOI 10.1098/rstb.1980.0089; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Moravec H., 1977, P 5 INT JOINT C ART, VVolume 1, P584; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; REGAN D, 1979, SCI AM           JUL, P131; RIEGER JH, 1985, J OPT SOC AM A, V2, P354, DOI 10.1364/JOSAA.2.000354; RIEGER JH, 1983, J OPT SOC AM, V73, P339, DOI 10.1364/JOSA.73.000339; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; Schunck B. G., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P560; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VERRI A, 1987, P DARPA IMAGE UNDERS, P825; WENG J, 1987, 1ST P INT C COMP VIS, P703	33	46	73	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1040	1058		10.1109/34.61704	http://dx.doi.org/10.1109/34.61704			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700002
J	HANSEN, C; HENDERSON, TC				HANSEN, C; HENDERSON, TC			CAGD-BASED COMPUTER VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											HANSEN, C (corresponding author), UNIV UTAH,DEPT COMP SCI,SALT LAKE CITY,UT 84112, USA.							BAUMGART B, 1974, AIM249 STANF U DEP C; BHANU B, 1987, COMPUTER, V20, P19, DOI 10.1109/MC.1987.1663657; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; BRADY M, 1985, 2ND P INT S ROB RES, P45; HANSEN C, 1986, UUCS86113 U UT DEP C; HANSEN CD, 1988, THESIS U UTAH SALT L; HO CC, 1987, THESIS U UTAH SALT L; IKEUCHI K, 1987, P DARPA IMAGE UNDERS, P321; KENT EW, 1986, APR IEEE INT C ROB A, P1634; KNOLL TF, 1986, IEEE T ROBOTIC AUTOM, V2, P3, DOI 10.1109/JRA.1986.1087031; KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595; PLANTINGA H, 1987, CSTR683 U WISC MAD D; [No title captured]	14	46	46	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1181	1193		10.1109/34.42856	http://dx.doi.org/10.1109/34.42856			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796					2022-12-18	WOS:A1989AW79600005
J	DEMICHELI, E; CAPRILE, B; OTTONELLO, P; TORRE, V				DEMICHELI, E; CAPRILE, B; OTTONELLO, P; TORRE, V			LOCALIZATION AND NOISE IN EDGE-DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											DEMICHELI, E (corresponding author), DEPT PHYS,VIA DODECANESO 33,I-16146 GENOA,ITALY.			caprile, bruno giovanni/0000-0002-1459-9953; De Micheli, Enrico/0000-0002-8058-045X				ABRAHAM R, 1967, TRANSVERSAL MAPPINGS; BASANO L, UNPUB POWER 2 FIR FI; BERTERO M, 1988, P IEEE; BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; CANNY JF, 1983, MIT720 TECH REP; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; DEMICHELI E, 1986, 3 P INT C IM AN P RA; DERICHE R, 1987, INT J COMPUT VISION; FRIEDEN BR, 1971, PROGR OPTICS, V9, P312; HARALICK RM, 1980, COMPUT VISION GRAPH, V12, P60, DOI 10.1016/0146-664X(80)90004-0; HARALICK RM, 1982, SPIE P ROBOT VISION; HARALICK RM, 1981, P PATTERN RECOG IMAG, P285; HERSHKOWITZ A, 1980, MIT183 AI MEM; HILDRETH EC, 1980, MIT579 AI MEM; HORN BKP, 1972, MIT285 AI MEM; LUNSCHER WHH, 1983, IEEE T PATTERN ANAL, V6, P678; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; SHANMUGAM KS, 1979, IEEE T PATTERN ANAL, V1, P37, DOI 10.1109/TPAMI.1979.4766874; SLEPIAN D, 1965, J MATH PHYS CAMB, V44, P99, DOI 10.1002/sapm196544199; Thom R., 1954, COMMENT MATH HELV, V28, P17, DOI DOI 10.1007/BF02566923; Tikhonov A., 1977, SOLUTIONS ILL POSED; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769	23	46	46	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1989	11	10					1106	1117		10.1109/34.42841	http://dx.doi.org/10.1109/34.42841			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR689					2022-12-18	WOS:A1989AR68900008
J	JERNIGAN, ME; DASTOUS, F				JERNIGAN, ME; DASTOUS, F			ENTROPY-BASED TEXTURE ANALYSIS IN THE SPATIAL-FREQUENCY DOMAIN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											JERNIGAN, ME (corresponding author), UNIV WATERLOO, DEPT SYST DESIGN, WATERLOO N2L 3G1, ONTARIO, CANADA.							BRODATZ P, 1968, TEXTURES PHOTOGRAPHI; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008; Duda R., 1973, PATTERN CLASSIFICATI, p[114, 221]; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HARVEY LO, 1979, OCT P INT C CYB SOC, P449; SPITZBERG R, 1975, VISION RES, V15, P837, DOI 10.1016/0042-6989(75)90263-1; SUTTON RN, 1972, IEEE T COMPUT, VC 21, P667, DOI 10.1109/T-C.1972.223572; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777	8	46	48	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	2					237	243		10.1109/TPAMI.1984.4767507	http://dx.doi.org/10.1109/TPAMI.1984.4767507			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SF591	21869187				2022-12-18	WOS:A1984SF59100010
J	SUGIHARA, K				SUGIHARA, K			A NECESSARY AND SUFFICIENT CONDITION FOR A PICTURE TO REPRESENT A POLYHEDRAL SCENE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SUGIHARA, K (corresponding author), NAGOYA UNIV,FAC ENGN,DEPT INFORMAT SCI,NAGOYA,AICHI 464,JAPAN.							CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; COWAN TM, 1977, PERCEPTION, V6, P41, DOI 10.1068/p060041; COWAN TM, 1974, J MATH PSYCHOL, V11, P190, DOI 10.1016/0022-2496(74)90018-2; DRAPER SW, 1981, ARTIF INTELL, V17, P461, DOI 10.1016/0004-3702(81)90032-1; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; HUFFMAN DA, 1977, MACH INTELL, V8, P493; Huffman David, 1977, MACHINE INTELLIGENCE, V8, P475; KANADE T, 1980, ARTIF INTELL, V13, P279, DOI 10.1016/0004-3702(80)90004-1; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; SHAPIRA R, 1979, COMMUN ACM, V22, P368, DOI 10.1145/359114.359129; SHAPIRA R, 1984, IEEE T PATTERN ANAL, V6, P122, DOI 10.1109/TPAMI.1984.4767487; SUGIHARA K, 1984, ARTIF INTELL, V23, P59, DOI 10.1016/0004-3702(84)90005-5; SUGIHARA K, 1978, COMPUT VISION GRAPH, V8, P382, DOI 10.1016/0146-664X(78)90064-3; SUGIHARA K, 1982, IEEE T PATTERN ANAL, V4, P458, DOI 10.1109/TPAMI.1982.4767289; SUGIHARA K, UNPUB DISCRETE APPL; TEROUANNE E, 1980, J MATH PSYCHOL, V22, P24, DOI 10.1016/0022-2496(80)90045-0; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; WHITELEY W, 1979, STRUCTURAL TOPOLOGY, V1, P46; Whiteley W., 1982, STRUCT TOPOL, V7, P13	19	46	49	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					578	586		10.1109/TPAMI.1984.4767571	http://dx.doi.org/10.1109/TPAMI.1984.4767571			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	TM813	21869226				2022-12-18	WOS:A1984TM81300003
J	Sun, DQ; Yang, XD; Liu, MY; Kautz, J				Sun, Deqing; Yang, Xiaodong; Liu, Ming-Yu; Kautz, Jan			Models Matter, So Does Training: An Empirical Study of CNNs for Optical Flow Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optical flow; pyramid; warping; cost volume; and convolutional neural network (CNN)		We investigate two crucial and closely-related aspects of CNNs for optical flow estimation: models and training. First, we design a compact but effective CNN model, called PWC-Net, according to simple and well-established principles: pyramidal processing, warping, and cost volume processing. PWC-Net is 17 times smaller in size, 2 times faster in inference, and 11 percent more accurate on Sintel final than the recent FlowNet2 model. It is the winning entry in the optical flow competition of the robust vision challenge. Next, we experimentally analyze the sources of our performance gains. In particular, we use the same training procedure for PWC-Net to retrain FlowNetC, a sub-network of FlowNet2. The retrained FlowNetC is 56 percent more accurate on Sintel final than the previously trained one and even 5 percent more accurate than the FlowNet2 model. We further improve the training procedure and increase the accuracy of PWC-Net on Sintel by 10 percent and on KITTI 2012 and 2015 by 20 percent. Our newly trained model parameters and training protocols are available on https://github.com/NVlabs/PWC-Net.	[Sun, Deqing; Kautz, Jan] NVIDIA, Westford, MA 01886 USA; [Yang, Xiaodong; Liu, Ming-Yu] NVIDIA, Santa Clara, CA 95050 USA	Nvidia Corporation	Sun, DQ (corresponding author), NVIDIA, Westford, MA 01886 USA.	deqings@nvidia.com; xiaodongy@nvidia.com; mingyul@nvidia.com; jkautz@nvidia.com						ADELSON EH, 1982, NATURE, V300, P523, DOI 10.1038/300523a0; [Anonymous], [No title captured]; [Anonymous], 2018, TROUBLING TRENDS MAC; [Anonymous], [No title captured]; [Anonymous], 2018, IEEE CVF C COMP VIS; [Anonymous], 2016, P AS C COMP VIS; Bai M, 2016, LECT NOTES COMPUT SC, V9910, P154, DOI 10.1007/978-3-319-46466-4_10; Bailer C, 2017, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2017.290; Bailer C, 2015, IEEE I CONF COMP VIS, P4015, DOI 10.1109/ICCV.2015.457; Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen QF, 2016, PROC CVPR IEEE, P4706, DOI 10.1109/CVPR.2016.509; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Fan LJ, 2018, PROC CVPR IEEE, P6016, DOI 10.1109/CVPR.2018.00630; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Gadot D, 2016, PROC CVPR IEEE, P4236, DOI 10.1109/CVPR.2016.459; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156; Hu YL, 2016, PROC CVPR IEEE, P5704, DOI 10.1109/CVPR.2016.615; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936; Hur J, 2017, IEEE I CONF COMP VIS, P312, DOI 10.1109/ICCV.2017.42; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jaderberg M, 2015, ADV NEUR IN, V28; Jegou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156; Jia Y., 2014, P 22 ACM INT C MULT, P675; Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938; Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lai WS, 2017, ADV NEUR IN, V30; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li YP, 2008, LECT NOTES COMPUT SC, V5303, P379; Liu C, 2008, PROC CVPR IEEE, P3911; Long GC, 2016, LECT NOTES COMPUT SC, V9910, P434, DOI 10.1007/978-3-319-46466-4_26; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Memisevic Roland, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383036; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Ranjan A, 2019, IEEE I CONF COMP VIS, P2404, DOI 10.1109/ICCV.2019.00249; Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291; Ren ZL, 2017, INT CONF 3D VISION, P225, DOI 10.1109/3DV.2017.00034; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Roth S, 2007, INT J COMPUT VISION, V74, P33, DOI 10.1007/s11263-006-0016-x; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Simoncelli E. P., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P310, DOI 10.1109/CVPR.1991.139707; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Sun DQ, 2008, LECT NOTES COMPUT SC, V5304, P83; Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489; Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2; Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175; Weiss Y, 2002, NAT NEUROSCI, V5, P598, DOI 10.1038/nn858; Werlberger M., 2009, BMVC, V1, P1, DOI DOI 10.5244/C.23.108; Wulff J, 2017, PROC CVPR IEEE, P6911, DOI 10.1109/CVPR.2017.731; Wulff J, 2015, PROC CVPR IEEE, P120, DOI 10.1109/CVPR.2015.7298607; Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211; Xu J, 2017, PROC CVPR IEEE, P5807, DOI 10.1109/CVPR.2017.615; Yang YC, 2017, PROC CVPR IEEE, P3767, DOI 10.1109/CVPR.2017.401; Yu FP, 2016, PROCEEDINGS OF 2016 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES, AND DEVICE APPLICATIONS (SPAWDA), P1, DOI 10.1109/SPAWDA.2016.7829944; Yu JJ, 2016, LECT NOTES COMPUT SC, V9915, P3, DOI 10.1007/978-3-319-49409-8_1; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zbontar J, 2016, J MACH LEARN RES, V17; Zweig S, 2017, PROC CVPR IEEE, P6363, DOI 10.1109/CVPR.2017.674	77	45	47	2	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1408	1423		10.1109/TPAMI.2019.2894353	http://dx.doi.org/10.1109/TPAMI.2019.2894353			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30676944	Green Submitted			2022-12-18	WOS:000535615700009
J	Lin, GS; Liu, FY; Milan, A; Shen, CH; Reid, I				Lin, Guosheng; Liu, Fayao; Milan, Anton; Shen, Chunhua; Reid, Ian			RefineNet: Multi-Path Refinement Networks for Dense Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Estimation; Image segmentation; Task analysis; Convolution; Training; Visualization; Convolutional neural network; semantic segmentation; object parsing; human parsing; scene parsing; depth estimation; dense prediction		Recently, very deep convolutional neural networks (CNNs) have shown outstanding performance in object recognition and have also been the first choice for dense prediction problems such as semantic segmentation and depth estimation. However, repeated subsampling operations like pooling or convolution striding in deep CNNs lead to a significant decrease in the initial image resolution. Here, we present RefineNet, a generic multi-path refinement network that explicitly exploits all the information available along the down-sampling process to enable high-resolution prediction using long-range residual connections. In this way, the deeper layers that capture high-level semantic features can be directly refined using fine-grained features from earlier convolutions. The individual components of RefineNet employ residual connections following the identity mapping mindset, which allows for effective end-to-end training. Further, we introduce chained residual pooling, which captures rich background context in an efficient manner. We carry out comprehensive experiments on semantic segmentation which is a dense classification problem and achieve good performance on seven public datasets. We further apply our method for depth estimation and demonstrate the effectiveness of our method on dense regression problems.	[Lin, Guosheng] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore; [Liu, Fayao] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Milan, Anton] Amazon Core ML, Berlin, Germany; [Shen, Chunhua; Reid, Ian] Univ Adelaide, Sch Comp Sci, ARC Ctr Excellence Robot Vis, Adelaide, SA 5005, Australia	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Adelaide; Australian Centre for Robotic Vision; University of Adelaide	Liu, FY (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	gslin@ntu.edu.sg; fayaoliu@gmail.com; milan@gmail.com; chunhua.shen@adelaide.edu.au; ian.reid@adelaide.edu.au	; Lin, Guosheng/Q-4024-2017	Reid, Ian/0000-0001-7790-6423; Lin, Guosheng/0000-0002-0329-7458	Australian Research Council through the Australian Centre for Robotic Vision [CE140100016]; ARC [FT120100969, FL130100102]; NTU start-up grant; MOE Tier-1 grant [2017-T1-002091-02]	Australian Research Council through the Australian Centre for Robotic Vision(Australian Research Council); ARC(Australian Research Council); NTU start-up grant(Nanyang Technological University); MOE Tier-1 grant(Ministry of Education, Singapore)	This research was supported by the Australian Research Council through the Australian Centre for Robotic Vision (CE140100016). C. Shen's participation was supported by an ARC Future Fellowship (FT120100969). I. Reid's participation was supported by an ARC Laureate Fellowship (FL130100102). G. Lin's participation was partly supported by a NTU start-up grant and a MOE Tier-1 grant (2017-T1-002091-02). We would like to thank NVIDIA for GPU donation.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], ECCV; [Anonymous], P EUR C COMPUT VIS; [Anonymous], P EUR C COMPUT VIS; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Chandra S, 2016, LECT NOTES COMPUT SC, V9911, P402, DOI 10.1007/978-3-319-46478-7_25; Chen L.-C., 2014, ARXIV14127062CSCV, P1; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191; Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Eigen D, 2014, ADV NEUR IN, V27; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835; Kendall A., 2015, CORR; Kim S, 2016, LECT NOTES COMPUT SC, V9912, P143, DOI 10.1007/978-3-319-46484-8_9; Koltun V, 2012, NIPS, P109; Krahenbuhl P, 2015, PROC CVPR IEEE, P1574, DOI 10.1109/CVPR.2015.7298765; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Liang XD, 2016, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2016.347; Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152; Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Pinheiro P. O. O., 2015, ADV NEURAL INFORM PR, V28, P1990; Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Roy A, 2016, PROC CVPR IEEE, P5506, DOI 10.1109/CVPR.2016.594; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897; Yu F., 2016, ABS151107122 CORR; Zagoruyko S., 2016, CORR; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zhou B., 2016, CORR	60	45	46	8	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1228	1242		10.1109/TPAMI.2019.2893630	http://dx.doi.org/10.1109/TPAMI.2019.2893630			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30668461	Green Published			2022-12-18	WOS:000523685800016
J	Yao, QM; Kwok, JT; Wang, TF; Liu, TY				Yao, Quanming; Kwok, James T.; Wang, Taifeng; Liu, Tie-Yan			Large-Scale Low-Rank Matrix Learning with Nonconvex Regularizers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Low-rank matrix learning; nonconvex regularization; proximal algorithm; parallel algorithm; matrix completion	THRESHOLDING ALGORITHM; VARIABLE SELECTION; SINGULAR-VALUES; COMPLETION; FACTORIZATION; RELAXATION	Low-rank modeling has many important applications in computer vision and machine learning. While the matrix rank is often approximated by the convex nuclear norm, the use of nonconvex low-rank regularizers has demonstrated better empirical performance. However, the resulting optimization problem is much more challenging. Recent state-of-the-art requires an expensive full SVD in each iteration. In this paper, we show that for many commonly-used nonconvex low-rank regularizers, the singular values obtained from the proximal operator can be automatically threshold. This allows the proximal operator to be efficiently approximated by the power method. We then develop a fast proximal algorithm and its accelerated variant with inexact proximal step. It can be guaranteed that the squared distance between consecutive iterates converges at a rate of O(1/T), where T is the number of iterations. Furthermore, we show the proposed algorithm can be parallelized, and the resultant algorithm achieves nearly linear speedup w.r.t. the number of threads. Extensive experiments are performed on matrix completion and robust principal component analysis. Significant speedup over the state-of-the-art is observed.	[Yao, Quanming] 4Paradigm Inc, Beijing 100089, Peoples R China; [Kwok, James T.] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Clear Water Bay, Hong Kong, Peoples R China; [Wang, Taifeng] Microsoft Res Asia, Machine Learning Grp, Beijing 100010, Peoples R China; [Liu, Tie-Yan] Microsoft Res Asia, Beijing 100010, Peoples R China	Hong Kong University of Science & Technology; Microsoft; Microsoft Research Asia; Microsoft; Microsoft Research Asia	Yao, QM (corresponding author), 4Paradigm Inc, Beijing 100089, Peoples R China.	yaoquanming@4Paradigm.com; jamesklkse@ust.hk; taifengw@microsoft.com; tyliu@microsoft.com	Yao, Quanming/Y-6095-2019	Yao, Quanming/0000-0001-8944-8618	Research Grants Council of the Hong Kong Special Administrative Region [614513]; Microsoft Research Asia; 4Paradigm	Research Grants Council of the Hong Kong Special Administrative Region(Hong Kong Research Grants Council); Microsoft Research Asia(Microsoft); 4Paradigm	This research was supported in part by the Research Grants Council of the Hong Kong Special Administrative Region (Grant 614513), Microsoft Research Asi aand 4Paradigm.	Attouch H, 2013, MATH PROGRAM, V137, P91, DOI 10.1007/s10107-011-0484-9; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; Bertsekas DP., 2002, INTRO PROBABILITY; Bolte J, 2010, T AM MATH SOC, V362, P3319, DOI 10.1090/S0002-9947-09-05048-X; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Dieci L, 1999, SIAM J MATRIX ANAL A, V20, P800, DOI 10.1137/S0895479897330182; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Gong SQ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT RAIL TRANSPORTATION (ICIRT), P37, DOI 10.1109/ICIRT.2013.6696264; Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5; Gui H, 2016, PR MACH LEARN RES, V48; Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806; HIRIARTURRUTY JB, 1985, LECT NOTES ECON MATH, V256, P37; Hsieh CJ, 2014, PR MACH LEARN RES, V32; Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271; Ji S., 2009, P 26 ANN INT C MACH, P457, DOI DOI 10.1145/1553374.1553434; Larsen R. M., 1998, PB357 DAIMI AARH U D; Lewis A, 2005, SET-VALUED ANAL, V13, P243, DOI 10.1007/s11228-004-7198-6; Li HY, 2015, INT CONF SOFTW ENG, P379, DOI 10.1109/ICSESS.2015.7339079; Li W, 2018, IEEE T PATTERN ANAL, V40, P1114, DOI 10.1109/TPAMI.2017.2704624; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Lu CY, 2015, AAAI CONF ARTIF INTE, P1805; Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P829, DOI 10.1109/TIP.2015.2511584; Mazumder R, 2010, J MACH LEARN RES, V11, P2287; Oh TH, 2018, IEEE T PATTERN ANAL, V40, P376, DOI 10.1109/TPAMI.2017.2677440; Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956; Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003; RAO CR, 1979, J MULTIVARIATE ANAL, V9, P362, DOI 10.1016/0047-259X(79)90094-0; Schmidt M., 2011, ADV NEURAL INFORM PR, P1458; Sun Q, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P311; Toh KC, 2010, PAC J OPTIM, V6, P615; Wang Z, 2015, SIAM J SCI COMPUT, V37, pA488, DOI 10.1137/130934271; Wen ZW, 2012, MATH PROGRAM COMPUT, V4, P333, DOI 10.1007/s12532-012-0044-1; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Xiao SJ, 2016, IEEE T NEUR NET LEAR, V27, P2268, DOI 10.1109/TNNLS.2015.2472284; XIAO SJ, 2015, PROC CVPR IEEE, P4612; Yao QM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4002; Yao QM, 2015, IEEE DATA MINING, P539, DOI 10.1109/ICDM.2015.9; Yu HF, 2012, IEEE DATA MINING, P765, DOI 10.1109/ICDM.2012.168; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729; Zhang T, 2010, J MACH LEARN RES, V11, P1081; Zhang Xinhua, 2012, ADV NEURAL INFORM PR, P2906	50	45	45	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2628	2643		10.1109/TPAMI.2018.2858249	http://dx.doi.org/10.1109/TPAMI.2018.2858249			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30040624	Green Submitted			2022-12-18	WOS:000489838200007
J	Sangineto, E; Nabi, M; Culibrk, D; Sebe, N				Sangineto, Enver; Nabi, Moin; Culibrk, Dubravko; Sebe, Nicu			Self Paced Deep Learning for Weakly Supervised Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weakly supervised learning; object detection; self-paced learning; curriculum learning; deep learning; training protocol	LOCALIZATION	In a weakly-supervised scenario object detectors need to be trained using image-level annotation alone. Since bounding-box-level ground truth is not available, most of the solutions proposed so far are based on an iterative, Multiple Instance Learning framework in which the current classifier is used to select the highest-confidence boxes in each image, which are treated as pseudo-ground truth in the next training iteration. However, the errors of an immature classifier can make the process drift, usually introducing many of false positives in the training dataset. To alleviate this problem, we propose in this paper a training protocol based on the self-paced learning paradigm. The main idea is to iteratively select a subset of images and boxes that are the most reliable, and use them for training. While in the past few years similar strategies have been adopted for SVMs and other classifiers, we are the first showing that a self-paced approach can be used with deep-network-based classifiers in an end-to-end training pipeline. The method we propose is built on the fully-supervised Fast-RCNN architecture and can be applied to similar architectures which represent the input image as a bag of boxes. We show state-of-the-art results on Pascal VOC 2007, Pascal VOC 2010 and ILSVRC 2013. On ILSVRC 2013 our results based on a low-capacity AlexNet network outperform even those weakly-supervised approaches which are based on much higher-capacity networks.	[Sangineto, Enver; Nabi, Moin; Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci DISI, I-38122 Trento, TN, Italy; [Nabi, Moin] SAP SE, D-10178 Berlin, Germany; [Culibrk, Dubravko] Univ Novi Sad, Dept Ind Engn & Management, Novi Sad 21101, Serbia	University of Trento; University of Novi Sad	Sangineto, E (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci DISI, I-38122 Trento, TN, Italy.	enver.sangineto@unitn.it; m.nabi@sap.com; dculibrk@uns.ac.rs; sebe@disi.unitn.it	Sangineto, Enver/AAS-9542-2020	Sebe, Niculae/0000-0002-6597-7248; Sangineto, Enver/0000-0002-5187-4133; Nabi, Moin/0000-0001-7559-9888; Culibrk, Dubravko/0000-0003-3417-1687				Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bazzani Loris, 2016, P IEEE WINT C APPL C, P1; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bilen H, 2014, P BRIT MACH VIS C, P112; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen XL, 2015, IEEE I CONF COMP VIS, P1431, DOI 10.1109/ICCV.2015.168; Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231; Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309; Everingham M., PASCAL VISUAL OBJECT; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Hoai M, 2014, PATTERN RECOGN, V47, P1523, DOI 10.1016/j.patcog.2013.09.028; Hoffman J, 2015, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2015.7298906; Hoffman Judy, 2014, NIPS; Jiang L, 2014, ADV NEUR IN, V27; Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22; Khosla A, 2012, LECT NOTES COMPUT SC, V7572, P158, DOI 10.1007/978-3-642-33718-5_12; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Lapedriza Agata, 2013, ARXIV13116510; Lee YJ, 2011, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2011.5995523; Liang XD, 2015, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2015.120; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; OQUAB M, 2015, PROC CVPR IEEE, P685, DOI DOI 10.1109/CVPR.2015.7298668; PENTINA A, 2015, PROC CVPR IEEE, P5492, DOI [DOI 10.1109/CVPR.2015.7299188, 10.1109/CVPR.2015.7299188]; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sangineto E, 2014, LECT NOTES COMPUT SC, V8691, P456, DOI 10.1007/978-3-319-10578-9_30; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shi MJ, 2016, LECT NOTES COMPUT SC, V9909, P105, DOI 10.1007/978-3-319-46454-1_7; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Song H. O., 2014, P INT C MACH LEARN; Song HO., 2014, ADV NEURAL INFORM PR, V2, P1637; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308; Teh E. W., 2016, P BRIT MACH VIS C; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang C, 2015, IEEE T IMAGE PROCESS, V24, P1371, DOI 10.1109/TIP.2015.2396361; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Zaremba W, 2014, CORR; Zhang D., 2016, PROC INT JOINT C ART, P3538	45	45	46	2	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					712	725		10.1109/TPAMI.2018.2804907	http://dx.doi.org/10.1109/TPAMI.2018.2804907			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29993478	Green Submitted			2022-12-18	WOS:000458168800014
J	Jeon, HG; Park, J; Choe, G; Park, J; Bok, Y; Tai, YW; Kweon, IS				Jeon, Hae-Gon; Park, Jaesik; Choe, Gyeongmin; Park, Jinsun; Bok, Yunsu; Tai, Yu-Wing; Kweon, In So			Depth from a Light Field Image with Learning-Based Matching Costs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational photography; light field imaging; depth estimation; 3D reconstruction; aberration correction	CALIBRATION	One of the core applications of light field imaging is depth estimation. To acquire a depth map, existing approaches apply a single photo-consistency measure to an entire light field. However, this is not an optimal choice because of the non-uniform light field degradations produced by limitations in the hardware design. In this paper, we introduce a pipeline that automatically determines the best configuration for photo-consistency measure, which leads to the most reliable depth label from the light field. We analyzed the practical factors affecting degradation in lenslet light field cameras, and designed a learning based framework that can retrieve the best cost measure and optimal depth label. To enhance the reliability of our method, we augmented an existing light field benchmark to simulate realistic source dependent noise, aberrations, and vignetting artifacts. The augmented dataset was used for the training and validation of the proposed approach. Our method was competitive with several state-of-the-art methods for the benchmark and real-world light field datasets.	[Jeon, Hae-Gon; Choe, Gyeongmin; Park, Jinsun; Kweon, In So] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea; [Park, Jaesik] Intel Labs, Santa Clara, CA 95054 USA; [Bok, Yunsu] Elect & Telecommun Res Inst, Daejeon 305350, South Korea; [Tai, Yu-Wing] Tencent, Shenzhen 518057, Peoples R China	Korea Advanced Institute of Science & Technology (KAIST); Intel Corporation; Electronics & Telecommunications Research Institute - Korea (ETRI); Tencent	Jeon, HG (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.	hgjeon@rcv.kaist.ac.kr; jaesik.park@intel.com; gmchoe@rcv.kaist.ac.kr; jspark88@rcv.kaist.ac.kr; ysbok@etri.re.kr; yuwing@gmail.com; iskweon77@kaist.ac.kr	Park, Jinsun/ABG-3042-2021; Jeon, Hae-Gon/W-5908-2019; Tai, Yuwing/C-2047-2011	Park, Jinsun/0000-0002-2296-819X; Jeon, Hae-Gon/0000-0003-1105-1666; Tai, Yuwing/0000-0002-3148-0380; PARK, JAESIK/0000-0001-5541-409X	Technology Innovation Program - Ministry of Trade, Industry AMP; Energy (MOTIE, Korea) [2017-10069072]; Institute for Information AMP; communications Technology Promotion - Korea government (MSIT) [2017-0-01780]; Technology Innovation Program - Ministry of Trade, Industry AMP; Energy (MI, Korea) [10048320]; National Research Foundation of Korea (NRF) - Ministry of Education [NRF-2015034617]	Technology Innovation Program - Ministry of Trade, Industry AMP; Energy (MOTIE, Korea)(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea); Institute for Information AMP; communications Technology Promotion - Korea government (MSIT)(Ministry of Science & ICT (MSIT), Republic of Korea); Technology Innovation Program - Ministry of Trade, Industry AMP; Energy (MI, Korea); National Research Foundation of Korea (NRF) - Ministry of Education(National Research Foundation of KoreaMinistry of Education (MOE), Republic of Korea)	This work was supported by the Technology Innovation Program (No. 2017-10069072) funded By the Ministry of Trade, Industry & Energy (MOTIE, Korea), by Institute for Information & communications Technology Promotion (No. 2017-0-01780) grant funded by the Korea government (MSIT),, and by the Technology Innovation Program (No. 10048320) funded by the Ministry of Trade, Industry & Energy (MI, Korea). Hae-Gon Jeon was partially supported by Global Ph.D. Fellowship Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (NRF-2015034617).	[Anonymous], 2016, LYTRO ILLUM FEATURES; Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168; Bok Y, 2017, IEEE T PATTERN ANAL, V39, P287, DOI 10.1109/TPAMI.2016.2541145; Bok Y, 2014, LECT NOTES COMPUT SC, V8694, P47, DOI 10.1007/978-3-319-10599-4_4; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197; Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137; Dansereau DG, 2013, PROC SPIE, V8657, DOI 10.1117/12.2002239; Fanello SR, 2016, PROC CVPR IEEE, P5441, DOI 10.1109/CVPR.2016.587; Georgiev T, 2010, COMPUT GRAPH FORUM, V29, P1955, DOI 10.1111/j.1467-8659.2010.01662.x; Goldluecke B, 2013, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2013.134; Heber S, 2014, LECT NOTES COMPUT SC, V8694, P751; Hirschmuller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221; Hirschmuller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407; Hwang Y, 2012, IEEE T PATTERN ANAL, V34, P1329, DOI 10.1109/TPAMI.2011.224; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Johannsen O., 2013, LECT NOTES COMPUTER, P302, DOI [DOI 10.1007/978-3-642-44964-2_15, 10.1007/ 978-3-642-44964-2_15]; Johannsen O, 2016, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2016.355; Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153; Kim C., 2013, ACM T GRAPHIC, V73, P1; Klaus A, 2006, INT C PATT RECOG, P15; Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10; Liang CK, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2665075; LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614; Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13; Mei Xing, 2011, IEEE INT C COMP VIS, P467, DOI DOI 10.1109/ICCVW.2011.6130280; Mitra K., 2012, P IEEECVF C COMPUTER, P22; Ng, 2005, LIGHT FIELD PHOTOGRA; Ng R., 2006, P INT OPT DES C, P1; Park MG, 2015, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2015.7298605; Poggi M, 2016, INT CONF 3D VISION, P138, DOI 10.1109/3DV.2016.22; Raytrix, 2012, 3D LIGHT FIELD CAM T; Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372; Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1339, DOI 10.1109/TPAMI.2007.1151; Shannon CE, 1998, P IEEE, V86, P447, DOI 10.1109/JPROC.1998.659497; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Spyropoulos A, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P73, DOI 10.1109/3DV.2015.16; Tang H., 2013, COMP PHOT ICCP 2013, P1; Tao MW, 2017, IEEE T PATTERN ANAL, V39, P546, DOI 10.1109/TPAMI.2016.2554121; Tao MW, 2016, IEEE T PATTERN ANAL, V38, P1155, DOI 10.1109/TPAMI.2015.2477811; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Venkataraman K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508390; Wang TC, 2016, PROC CVPR IEEE, P5451, DOI 10.1109/CVPR.2016.588; Wang TC, 2016, IEEE T PATTERN ANAL, V38, P2170, DOI 10.1109/TPAMI.2016.2515615; Wanner S., 2013, VISION MODELING VISU, P225, DOI DOI 10.2312/PE.VMV.VMV13.225-226; Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147; Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259; Williem, 2016, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2016.476; Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49; Yu Z, 2013, IEEE I CONF COMP VIS, P2792, DOI 10.1109/ICCV.2013.347; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345; Zbontar J, 2016, J MACH LEARN RES, V17; Zhang S, 2016, COMPUT VIS IMAGE UND, V145, P148, DOI 10.1016/j.cviu.2015.12.007	53	45	53	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					297	310		10.1109/TPAMI.2018.2794979	http://dx.doi.org/10.1109/TPAMI.2018.2794979			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29994179				2022-12-18	WOS:000456150600003
J	Chatterjee, A; Govindu, VM				Chatterjee, Avishek; Govindu, Venu Madhav			Robust Relative Rotation Averaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Relative rotation averaging; structure from motion; 3D rotation group; SO(3); iteratively reweighted least squares; Quasi-Newton optimization; Gauss-Newton optimization		This paper addresses the problem of robust and efficient relative rotation averaging in the context of large-scale Structure from Motion. Relative rotation averaging finds global or absolute rotations for a set of cameras from a set of observed relative rotations between pairs of cameras. We propose a generalized framework of relative rotation averaging that can use different robust loss functions and jointly optimizes for all the unknown camera rotations. Our method uses a quasi-Newton optimization which results in an efficient iteratively reweighted least squares (IRLS) formulation that works in the Lie algebra of the 3D rotation group. We demonstrate the performance of our approach on a number of large-scale data sets. We show that our method outperforms existing methods in the literature both in terms of speed and accuracy.	[Chatterjee, Avishek] Indian Inst Sci, Bangalore 560012, Karnataka, India; [Govindu, Venu Madhav] Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India	Indian Institute of Science (IISC) - Bangalore; Indian Institute of Science (IISC) - Bangalore	Chatterjee, A (corresponding author), Indian Inst Sci, Bangalore 560012, Karnataka, India.	avishek@ee.iisc.ernet.in; venu@ee.iisc.ernet.in							0	45	46	6	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					958	972		10.1109/TPAMI.2017.2693984	http://dx.doi.org/10.1109/TPAMI.2017.2693984			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28422652				2022-12-18	WOS:000426687100014
J	Zhou, Q; Zhao, Q				Zhou, Qiang; Zhao, Qi			Flexible Clustered Multi-Task Learning by Learning Representative Tasks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustered multi-task learning; representative task; group sparsity	MULTIPLE TASKS; REGRESSION; ALGORITHM	Multi-task learning (MTL) methods have shown promising performance by learning multiple relevant tasks simultaneously, which exploits to share useful information across relevant tasks. Among various MTL methods, clustered multi-task learning (CMTL) assumes that all tasks can be clustered into groups and attempts to learn the underlying cluster structure from the training data. In this paper, we present a new approach for CMTL, called flexible clustered multi-task (FCMTL), in which the cluster structure is learned by identifying representative tasks. The new approach allows an arbitrary task to be described by multiple representative tasks, effectively soft-assigning a task to multiple clusters with different weights. Unlike existing counterpart, the proposed approach is more flexible in that (a) it does not require clusters to be disjoint, (b) tasks within one particular cluster do not have to share information to the same extent, and (c) the number of clusters is automatically inferred from data. Computationally, the proposed approach is formulated as a row-sparsity pursuit problem. We validate the proposed FCMTL on both synthetic and real-world data sets, and empirical results demonstrate that it outperforms many existing MTL methods.	[Zhou, Qiang; Zhao, Qi] Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117583, Singapore	National University of Singapore	Zhou, Q; Zhao, Q (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117583, Singapore.	zhouqiang@u.nus.edu; eleqiz@nus.edu.sg			Defense Innovative Research Programme [9014100596]	Defense Innovative Research Programme	The authors would like to thank Dr. Leon Wenliang Zhong for providing the implementation of [60]. They also thank the anonymous reviewers and associate editor for their constructive suggestions. The research was supported by the Defense Innovative Research Programme (No. 9014100596). Q. Zhao is the corresponding author.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], 2007, J MACHINE LEARNING R; [Anonymous], 2010, CALIFORNIA I TECHNOL; [Anonymous], 2012, P INT C MACH LEARN; Argyriou A., 2007, P 20 ANN C NEUR INF, P41, DOI DOI 10.1007/S10994-007-5040-8; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Bakker B, 2004, J MACH LEARN RES, V4, P83, DOI 10.1162/153244304322765658; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Boyd S, 2004, CONVEX OPTIMIZATION; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; CHEN J., 2010, P 16 ACM SIGKDD INT, P1179; Chen J., 2011, PROC 17 ACM SIGKDD I, P42; Chen JH, 2013, IEEE T PATTERN ANAL, V35, P1025, DOI 10.1109/TPAMI.2012.189; Chen X., 2011, UAI, P105; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dinuzzo F, 2013, NEUROCOMPUTING, V118, P119, DOI 10.1016/j.neucom.2013.02.024; Dinuzzo F, 2011, IEEE T NEURAL NETWOR, V22, P290, DOI 10.1109/TNN.2010.2095882; Elhamifar E., 2012, ADV NEURAL INFORM PR, P19; Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; Gong P, 2012, NIPS, V25, P1997; Gong Pinghua, 2012, KDD, V2012, P895; Gong PH, 2013, J MACH LEARN RES, V14, P2979; Jacob L, 2008, ARXIV PREPRINT ARXIV; Jacob L., 2009, P 26 INT C MACH LEAR, P433, DOI DOI 10.1145/1553374.1553431; Jacob L, 2008, BIOINFORMATICS, V24, P358, DOI 10.1093/bioinformatics/btm611; Jalali A., 2010, ADV NEURAL INF PROCE, V23, P964; Kang Z., 2011, P INT C MACH LEARN, V2, P4; Kato T, 2010, IEEE T KNOWL DATA EN, V22, P957, DOI 10.1109/TKDE.2009.142; Keerthi SS, 2003, NEURAL COMPUT, V15, P487, DOI 10.1162/089976603762553013; Kim S., 2010, P 27 INT C MACH LEAR, P543; Kumar A., 2012, INT C MACH LEARN; Lee S., 2010, PROC INT C NEURAL IN, P1306; Liu J, 2009, SIMUL: 2009 FIRST INTERNATIONAL CONFERENCE ON ADVANCES IN SYSTEM SIMULATION, P1, DOI 10.1109/SIMUL.2009.24; Nesterov Y, 2013, MATH PROGRAM, V140, P125, DOI 10.1007/s10107-012-0629-5; Passos A., 2012, P INT C MACH LEARN, P1103; Pillonetto G, 2010, IEEE T PATTERN ANAL, V32, P193, DOI 10.1109/TPAMI.2008.297; Quadrianto N., 2010, PROC 23 INT C NEURAL, P1957; Rakotomamonjy A, 2011, IEEE T NEURAL NETWOR, V22, P1307, DOI 10.1109/TNN.2011.2157521; Romera-Paredes B., 2012, J MACHINE LEARNING, V22, P951; Romera-Paredes B., 2013, P 30 INT C MACHINE L, P1444; Schwaighofer A., 2004, NIPS 04 P 17 INT C N, P1209; Solnon M, 2012, J MACH LEARN RES, V13, P2773; Sra S, 2012, OPTIMIZATION FOR MACHINE LEARNING, P1; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Williams, 2007, NEURAL INFORM PROCES, P153, DOI DOI 10.5555/2981562.2981582; Xue Y, 2007, J MACH LEARN RES, V8, P35; Yang Xiaolin, 2009, ADV NEURAL INFORM PR, P2151; Yeung D.-Y., 2013, P 23 INT JOINT C ART, P1917; Yu K., 2005, P 22 INT C MACH LEAR, P1012, DOI DOI 10.1145/1102351.1102479; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhang Y., 2010, PROC INT C NEURAL IN, P2559; Zhang Y, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 6, P733; Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975; Zhong L. W., 2011, P 28 INT C MACH LEAR, P9; Zhou J., 2011, P 17 ACM SIGKDD INT, P814, DOI [10.1145/2020408.2020549, DOI 10.1145/2020408.2020549]; Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702	62	45	47	3	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					266	278		10.1109/TPAMI.2015.2452911	http://dx.doi.org/10.1109/TPAMI.2015.2452911			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761733				2022-12-18	WOS:000369989600006
J	Chakraborty, S; Balasubramanian, V; Sun, Q; Panchanathan, S; Ye, JP				Chakraborty, Shayok; Balasubramanian, Vineeth; Sun, Qian; Panchanathan, Sethuraman; Ye, Jieping			Active Batch Selection via Convex Relaxations with Guaranteed Solution Bounds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Batch mode active learning; optimization	QUERY; FACE	Active learning techniques have gained popularity to reduce human effort in labeling data instances for inducing a classifier. When faced with large amounts of unlabeled data, such algorithms automatically identify the exemplar instances for manual annotation. More recently, there have been attempts towards a batch mode form of active learning, where a batch of data points is simultaneously selected from an unlabeled set. In this paper, we propose two novel batch mode active learning (BMAL) algorithms: BatchRank and BatchRand. We first formulate the batch selection task as an NP-hard optimization problem; we then propose two convex relaxations, one based on linear programming and the other based on semi-definite programming to solve the batch selection problem. Finally, a deterministic bound is derived on the solution quality for the first relaxation and a probabilistic bound for the second. To the best of our knowledge, this is the first research effort to derive mathematical guarantees on the solution quality of the BMAL problem. Our extensive empirical studies on 15 binary, multi-class and multi-label challenging datasets corroborate that the proposed algorithms perform at par with the state-of-the-art techniques, deliver high quality solutions and are robust to real-world issues like label noise and class imbalance.	[Chakraborty, Shayok] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA; [Balasubramanian, Vineeth] Indian Inst Technol, Dept Comp Sci & Engn, Hyderabad, Andhra Pradesh, India; [Sun, Qian; Ye, Jieping] Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85281 USA; [Panchanathan, Sethuraman] Arizona State Univ, Ctr Cognit Ubiquitous Comp CUbiC, Tempe, AZ 85281 USA	Carnegie Mellon University; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Hyderabad; Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe	Chakraborty, S (corresponding author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.	shayokc@andrew.cmu.edu; vineethnb@iith.ac.in; qian.sun@asu.edu; panch@asu.edu; jieping.ye@asu.edu	Balasubramanian, Vineeth N/AAQ-7695-2020	Balasubramanian, Vineeth N/0000-0003-2656-0375	Div Of Information & Intelligent Systems [1116360] Funding Source: National Science Foundation	Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))		Balasubramanian Vineeth, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1378, DOI 10.1109/ICCVW.2009.5457449; Balcan MF, 2010, MACH LEARN, V80, P111, DOI 10.1007/s10994-010-5174-y; Baram Y, 2004, J MACH LEARN RES, V5, P255; Beygelzimer A., 2009, P 26 ANN INT C MACH, P49; Bilgic M., 2010, P 27 INT C MACHINE L, P79; Brinker K, 2006, STUD CLASS DATA ANAL, P206, DOI 10.1007/3-540-31314-1_24; Brinker K., 2003, ICML, P59; Chakraborty S., 2012, J PATTERN RECOG, V46, P497; Chakraborty Shayok, 2011, P 19 ACM INT C MULT, P1413; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295; Ekenel H. K., 2007, P IEEE C COMP VIS PA, P1; El Kaliouby R, 2004, IEEE SYS MAN CYBERN, P682; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Guo Y, 2010, ADV NEURAL INFORM PR, P802; Guo YH, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P823; Guo Yuhong, 2007, ADV NEURAL INFORM PR, P593; Hanneke S., 2007, P 24 INT C MACH LEAR, P353, DOI [10.1145/1273496.1273541, DOI 10.1145/1273496.1273541]; Harpale A, 2010, ICML; Ho SS, 2008, IEEE T PATTERN ANAL, V30, P1557, DOI 10.1109/TPAMI.2007.70811; Hoi S. C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587350; Hoi SCH, 2006, P 15 INT C WORLD WID, P633, DOI [10.1145/1135777.1135870, DOI 10.1145/1135777.1135870]; Hoi SCH, 2006, P 23 INT C MACH LEAR, V148, P417, DOI [10.1145/1143844.1143897, DOI 10.1145/1143844.1143897]; Hoi SCH, 2009, IEEE T KNOWL DATA EN, V21, P1233, DOI 10.1109/TKDE.2009.60; Huang SJ, 2014, IEEE T PATTERN ANAL, V36, P1936, DOI 10.1109/TPAMI.2014.2307881; Kachites McCallum A., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P350; Kukar M, 2003, ARTIF INTELL MED, V29, P81, DOI 10.1016/S0933-3657(03)00043-5; Liere R., 1997, AAAI IAAI, P591; Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011; Marcel S, 2010, LECT NOTES COMPUT SC, V6388, P210, DOI 10.1007/978-3-642-17711-8_22; Monteleoni C., 2007, P 2007 IEEE C COMP V, P1; Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424; Sanderson C., 2008, BIOMETRIC PERSON REC; Schohn G., 2000, P 17 INT C MACH LEAR, P839; Settles B., 2010, 648 U WISC MASD COMP; Singh M., 2009, UCDCSI200901; Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243; Tong S., 2001, PROC ACM INT C MULTI, V9, P107; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Xu Z, 2003, LECT NOTES COMPUT SC, V2633, P393; Yuan XT, 2013, J MACH LEARN RES, V14, P899; Zhang M.L., 2010, KDD, P999	42	45	49	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					1945	1958		10.1109/TPAMI.2015.2389848	http://dx.doi.org/10.1109/TPAMI.2015.2389848			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26353181				2022-12-18	WOS:000360813400001
J	Kwon, Y; Kim, KI; Tompkin, J; Kim, JH; Theobalt, C				Kwon, Younghee; Kim, Kwang In; Tompkin, James; Kim, Jin Hyung; Theobalt, Christian			Efficient Learning of Image Super-Resolution and Compression Artifact Removal with Semi-Local Gaussian Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image enhancement; super-resolution; image compression; Gaussian process; regression	RECONSTRUCTION; LIMITS; DCT	Improving the quality of degraded images is a key problem in image processing, but the breadth of the problem leads to domain-specific approaches for tasks such as super-resolution and compression artifact removal. Recent approaches have shown that a general approach is possible by learning application-specific models from examples; however, learning models sophisticated enough to generate high-quality images is computationally expensive, and so specific per-application or per-dataset models are impractical. To solve this problem, we present an efficient semi-local approximation scheme to large-scale Gaussian processes. This allows efficient learning of task-specific image enhancements from example images without reducing quality. As such, our algorithm can be easily customized to specific applications and datasets, and we show the efficiency and effectiveness of our approach across five domains: single-image super-resolution for scene, human face, and text images, and artifact removal in JPEG- and JPEG 2000-encoded images.	[Kwon, Younghee] Google Inc, Mountain View, CA 94043 USA; [Kim, Kwang In] Univ Lancaster, Sch Comp & Commun, Lancaster LA1 4WA, England; [Tompkin, James] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Kim, Jin Hyung] Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea; [Theobalt, Christian] Max Planck Inst Informat, D-66123 Saarbrucken, Germany	Google Incorporated; Lancaster University; Harvard University; Korea Advanced Institute of Science & Technology (KAIST); Max Planck Society	Kwon, Y (corresponding author), Google, Mountain View, CA USA.	youngheek@google.com; k.kim@lancaster.ac.uk; jtompkin@seas.harvard.edu; jkim@kaist.ac.kr; theobalt@mpi-inf.mpg.de	Kim, Jin Hyung/C-1923-2011	Theobalt, Christian/0000-0001-6104-6625				Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Bishop C.M, 2006, PATTERN RECOGN; Bourlard H., 1993, CONNECTIONIST SPEECH; Cawley GC, 2006, LECT NOTES ARTIF INT, V3944, P56; Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043; CHAUDHURI S, 2001, SUPER RESOLUTION IMA; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; Gehler P. V., 2005, ADV NEURAL INFORM PR, P419; He H, 2011, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2011.5995713; Herbrich R., 2003, ADV NEURAL INFORM PR, P625; Kwon Y, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.14; Laparra V, 2010, J MACH LEARN RES, V11, P873; Lee K, 2005, IEEE T IMAGE PROCESS, V14, P36, DOI 10.1109/TIP.2004.838699; Li X, 2005, IEEE T CIRC SYST VID, V15, P108, DOI 10.1109/TCSVT.2004.836743; Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081; Liu P. J., 2007, THESIS U TORONTO TOR; Nosratinia A, 2003, IEEE SIGNAL PROC LET, V10, P296, DOI 10.1109/LSP.2003.817179; Nosratinia A, 2001, J VLSI SIG PROCESS S, V27, P69, DOI 10.1023/A:1008167430544; Pickup LC, 2004, ADV NEUR IN, V16, P1587; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Qiu GP, 2000, IEEE T CIRC SYST VID, V10, P1450, DOI 10.1109/76.889048; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Raik E., 1967, USSR COMP MATH MATH, V7, P1, DOI DOI 10.1016/0041-5553(67)90113-9; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Seeger M.W., 2003, INT WORKSHOP ARTIFIC, VR4, P254; SILVERMAN BW, 1984, ANN STAT, V12, P898, DOI 10.1214/aos/1176346710; Snelson Edward, 2006, ADV NEURAL INFORM PR, V3; Snelson Edward, 2007, P 11 INT C ARTIFICIA, P524; Sollich P., 2005, ADV NEURAL INFORM PR, P1313; Sun DQ, 2007, IEEE T IMAGE PROCESS, V16, P2743, DOI 10.1109/TIP.2007.904969; Tappen Marshall F, 2003, P 3 INT WORKSH STAT, P1; Tipping M.E., 2003, ADV NEURAL INFORM PR, V15, P1303; Tschumperle D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87; Walder C., 2008, ICML, P1112; Wang T., 2008, OPTICAL ENG, V47; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; YANG YY, 1995, IEEE T IMAGE PROCESS, V4, P896, DOI 10.1109/83.392332; Zhai GT, 2009, J VIS COMMUN IMAGE R, V20, P595, DOI 10.1016/j.jvcir.2009.06.004	43	45	46	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1792	1805		10.1109/TPAMI.2015.2389797	http://dx.doi.org/10.1109/TPAMI.2015.2389797			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353127	Green Submitted			2022-12-18	WOS:000359216600005
J	Mac Aodha, O; Humayun, A; Pollefeys, M; Brostow, GJ				Mac Aodha, Oisin; Humayun, Ahmad; Pollefeys, Marc; Brostow, Gabriel J.			Learning a Confidence Measure for Optical Flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optical flow; confidence measure; Random Forest; synthetic data; algorithm selection	ALGORITHM	We present a supervised learning-based method to estimate a per-pixel confidence for optical flow vectors. Regions of low texture and pixels close to occlusion boundaries are known to be difficult for optical flow algorithms. Using a spatiotemporal feature vector, we estimate if a flow algorithm is likely to fail in a given region. Our method is not restricted to any specific class of flow algorithm and does not make any scene specific assumptions. By automatically learning this confidence, we can combine the output of several computed flow fields from different algorithms to select the best performing algorithm per pixel. Our optical flow confidence measure allows one to achieve better overall results by discarding the most troublesome pixels. We illustrate the effectiveness of our method on four different optical flow algorithms over a variety of real and synthetic sequences. For algorithm selection, we achieve the top overall results on a large test set, and at times even surpass the results of the best algorithm among the candidates.	[Mac Aodha, Oisin; Brostow, Gabriel J.] UCL, Dept Comp Sci, London WC1E 6BT, England; [Humayun, Ahmad] Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA; [Pollefeys, Marc] Swiss Fed Inst Technol, Comp Vis & Geometry Lab, Dept Comp Sci, CH-8092 Zurich, Switzerland	University of London; University College London; University System of Georgia; Georgia Institute of Technology; Swiss Federal Institutes of Technology Domain; ETH Zurich	Mac Aodha, O (corresponding author), UCL, Dept Comp Sci, Gower St, London WC1E 6BT, England.	o.macaodha@cs.ucl.ac.uk; ahumayun@cc.gatech.edu; marc.pollefeys@inf.ethz.ch; G.Brostow@cs.ucl.ac.uk	Brostow, Gabriel/S-1464-2019; Pollefeys, Marc/I-7607-2013	Brostow, Gabriel/0000-0001-8472-3828; 	National University of Ireland; Microsoft Innovation Cluster for Embedded Software	National University of Ireland; Microsoft Innovation Cluster for Embedded Software(Microsoft)	Funding for this research was provided by the National University of Ireland Travelling Studentship in the Sciences and the Microsoft Innovation Cluster for Embedded Software. Project page: http://visual.cs.ucl.ac.uk/pubs/flowConfidence.	Alt N., 2010, P IEEE C COMP VIS PA; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; BainbridgeSmith A, 1996, ELECTRON LETT, V32, P882, DOI 10.1049/el:19960574; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; Barron J.L., 1992, TR299 U W ONT DEP CO; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43; Bruhn A, 2006, COMP IMAG VIS, P283; Cech J., 2011, P IEEE C COMP VIS PA; Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1561/0600000035, 10.1501/0000000035]; Farhadi Ali, 2009, CVPR; Gehrig SK, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Gong ML, 2006, INT J COMPUT VISION, V68, P319, DOI 10.1007/s11263-006-5099-x; Gould S., 2009, P IEEE INT C COMP VI; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46; Humayun A., 2011, P IEEE C COMP VIS PA; JAHNE B, 1999, HDB COMPUTER VISION, V2; Kaneva B., 2011, P IEEE INT C COMP VI; Kondermann C., 2008, P EUR C COMP VIS; Kondermann C, 2007, LECT NOTES COMPUT SC, V4713, P132; Kybic J, 2011, COMPUT VIS IMAGE UND, V115, P1449, DOI 10.1016/j.cviu.2011.06.008; Lempitsky V, 2008, PROC CVPR IEEE, P3184; Levin A., 2004, P ACM SIGGRAPH; Li B., 2011, P IEEE C COMP VIS PA; Liu C., 2008, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Mac Aodha O., 2010, P IEEE C COMP VIS PA; Mac Aodha O., 2012, P EUR C COMP VIS; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; McCane B, 2001, COMPUT VIS IMAGE UND, V84, P126, DOI 10.1006/cviu.2001.0930; Meister S., 2011, P 14 ITG C EL MED TE; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Otte M., 1994, P EUR C COMP VIS; Peng B., 2008, P BRIT MACH VIS C, P161; Raykar V.C., 2009, P INT C MACH LEARN; Reynolds M., 2011, P IEEE C COMP VIS PA; Roth S, 2007, INT J COMPUT VISION, V74, P33, DOI 10.1007/s11263-006-0016-x; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Simoncelli E., 1991, P IEEE C COMP VIS PA; Stenger B., 2009, P IEEE C COMP VIS PA; Sun D., 2008, P EUR C COMP VIS; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; Wedel A., 2009, P IEEE INT C COMP VI; Werlberger M., 2009, P BRIT MACH VIS C; Woodford O., 2006, P BRIT MACH VIS C; Yong X, 2005, PATTERN RECOGN LETT, V26, P1059, DOI 10.1016/j.patrec.2004.09.049; Zach C, 2007, IEEE I CONF COMP VIS, P1213; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420; Zimmer H., 2009, P 7 INT C EN MIN MET	55	45	46	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1107	1120		10.1109/TPAMI.2012.171	http://dx.doi.org/10.1109/TPAMI.2012.171			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	22868652				2022-12-18	WOS:000316126800007
J	Lhuillier, M				Lhuillier, Maxime			Incremental Fusion of Structure-from-Motion and GPS Using Constrained Bundle Adjustments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Local bundle adjustment; structure-from-motion; fusion; low cost GPS		Two problems occur when bundle adjustment (BA) is applied on long image sequences: large calculation time and drift (or error accumulation). In recent work, the calculation time is reduced by local BAs applied in an incremental scheme. The drift may be reduced by fusion of GPS and Structure-from-Motion. An existing fusion method is BA minimizing a weighted sum of image and GPS errors. This paper introduces two constrained BAs for fusion which enforce an upper bound for the reprojection error. These BAs are alternatives to the existing fusion BA which does not guarantee a small reprojection error and requires a weight as input. Then, the three fusion BAs are integrated in an incremental Structure-from-Motion method based on local BA. Last, we will compare the fusion results on long monocular image sequences and low cost GPS.	UMR 6602 UBP CNRS IFMA, Inst Pascal Ex Lasmea, F-63171 Aubiere, France	Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS); Universite Clermont Auvergne (UCA)	Lhuillier, M (corresponding author), UMR 6602 UBP CNRS IFMA, Inst Pascal Ex Lasmea, Campus Univ Cezeaux, F-63171 Aubiere, France.	Maxime.Lhuillier@free.fr						Agarwal S., 2010, P EUR C COMP VIS; Bard Y., 1974, NONLINEAR PARAMETER; Ellum C., 2006, INT ARCH PHOTOGRAMME, VXXXV; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Kume H., 2010, P INT C PATT REC; Lhuillier M., 2011, P IEEE C COMP VIS PA; Lothe P., 2009, P IEEE C COMP VIS PA; McGlone J. C., 2004, MANUAL PHOTOGRAMMETR, VFifth; Michot J., 2010, P INT S 3D DAT PROC; Mouragnon E, 2009, IMAGE VISION COMPUT, V27, P1178, DOI 10.1016/j.imavis.2008.11.006; PRESS WH, 1999, NUMERICAL RECIPIES C; Triggs B., 2000, P INT WORKSH VIS ALG; Wu C., 2011, P IEEE C COMP VIS PA	13	45	48	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2489	2495		10.1109/TPAMI.2012.157	http://dx.doi.org/10.1109/TPAMI.2012.157			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22848131				2022-12-18	WOS:000309913700016
J	Peyre, G				Peyre, Gabriel			Texture Synthesis with Grouplets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Texture; grouplets; texture synthesis; inpainting	FIELD ANALYSIS; IMAGE; DIFFUSION; SPARSITY; MODEL; FLOW	This paper proposes a new method to synthesize and inpaint geometric textures. The texture model is composed of a geometric layer that drives the computation of a new grouplet transform. The geometry is an orientation flow that follows the patterns of the texture to analyze or synthesize. The grouplet transform extends the original construction of Mallat [1] and is adapted to the modeling of natural textures. Each grouplet atoms is an elongated stroke located along the geometric flow. These atoms exhibit a wide range of lengths and widths, which is important to match the variety of structures present in natural images. Statistical modeling and sparsity optimization over these grouplet coefficients enable the synthesis of texture patterns along the flow. This paper explores texture inpainting and texture synthesis, which both require the joint optimization of the geometric flow and the grouplet coefficients.	[Peyre, Gabriel] Univ Paris 09, CNRS, F-75775 Paris 16, France; [Peyre, Gabriel] Univ Paris 09, CEREMADE, F-75775 Paris 16, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; PSL Research University Paris; Universite Paris-Dauphine; Universite Paris Cite; UDICE-French Research Universities; PSL Research University Paris; Universite Paris-Dauphine	Peyre, G (corresponding author), Univ Paris 09, CNRS, Pl Marechal De Lattre De Tassigny, F-75775 Paris 16, France.	gabriel.peyre@ceremade.dauphine.fr	Peyré, Gabriel/P-2438-2015	Peyré, Gabriel/0000-0002-4477-0387				Almeida MP, 1997, J MATH IMAGING VIS, V7, P241, DOI 10.1023/A:1008278411855; Ashikhmin M., 2001, P 2001 S INT 3D GRAP, P217, DOI DOI 10.1145/364338.364405; Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036; Bar-Joseph Z, 2001, IEEE T VIS COMPUT GR, V7, P120, DOI 10.1109/2945.928165; BARGTEIL A. W., 2006, P ACM SIGGRAPH EUR S, P345; Ben-Shahar O, 2003, IEEE T PATTERN ANAL, V25, P401, DOI 10.1109/TPAMI.2003.1190568; Bergen J.R., 1991, COMPUTATIONAL MODELS, P253; Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972; BONET JD, 1997, P SIGGRAPH 97, P361; Bridson R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239497; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Cabral B., 1993, P 20 ANN C COMP GRAP, P263, DOI DOI 10.1145/166117.166151>; Candes EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116; Cappelli R, 2007, IEEE T PATTERN ANAL, V29, P1489, DOI 10.1109/TPAMI.2007.1087; Chen H, 2006, IEEE T PATTERN ANAL, V28, P1025, DOI 10.1109/TPAMI.2006.131; Cook RL, 2005, ACM T GRAPHIC, V24, P803, DOI 10.1145/1073204.1073264; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Demanet L, 2007, APPL COMPUT HARMON A, V23, P368, DOI 10.1016/j.acha.2007.03.003; Diewald U, 2000, IEEE T VIS COMPUT GR, V6, P139, DOI 10.1109/2945.856995; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005; Fadili M. J., 2007, COMPUTER J; FARGE M, 2006, ENCY MATH PHYS, P408; Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039; Gonzales R, 1993, DIGITAL IMAGE PROCES; Heeger D.J., 1995, P 22 ANN C COMP GRAP, P229, DOI DOI 10.1145/218380.218446; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jos Stam, 1995, P 22 ANN C COMP GRAP, P129, DOI [10.1145/218380.218430, DOI 10.1145/218380.218430]; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; Kim T, 2008, P IEEE 14 AS PAC C C, P1, DOI DOI 10.1145/1544012.1544069; Kothe U, 2003, LECT NOTES COMPUT SC, V2781, P25; Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Kwatra V, 2007, IEEE T VIS COMPUT GR, V13, P939, DOI 10.1109/TVCG.2007.1044; Lamorlette A, 2002, ACM T GRAPHIC, V21, P729, DOI 10.1145/566570.566644; Le Pennec E, 2005, MULTISCALE MODEL SIM, V4, P992, DOI 10.1137/040619454; Lefebvre S, 2005, ACM T GRAPHIC, V24, P777, DOI 10.1145/1073204.1073261; Lefebvre S, 2006, ACM T GRAPHIC, V25, P541, DOI 10.1145/1141911.1141921; Lewis J.-P., 1984, Computers & Graphics, V18, P245; Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787; MALLAT S, 2008, APPL COMPUTATIONAL H; Mallat S., 1999, WAVELET TOUR SIGNAL; Mallat S, 2008, COMMUN PUR APPL MATH, V61, P1173; Malley JO, 2007, ENG J AISC, V44, P3; Masnou S, 2002, IEEE T IMAGE PROCESS, V11, P68, DOI 10.1109/83.982815; Meyer FG, 1997, APPL COMPUT HARMON A, V4, P147, DOI 10.1006/acha.1997.0208; Neyret F., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P147; Paget R, 1998, IEEE T IMAGE PROCESS, V7, P925, DOI 10.1109/83.679446; Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247; PEYRE G, 2008, COMPUTER VISION IMAG; Peyre G., 2007, BEST BASIS COMPRESSE; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908; SHU CF, 1994, IEEE T PATTERN ANAL, V16, P946, DOI 10.1109/34.310692; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548; Tricoche X, 2004, MATH VISUAL, P275; Tschumperle D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87; van Wijk JJ, 2002, ACM T GRAPHIC, V21, P745, DOI 10.1145/566570.566646; Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009; Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131; WITKIN A, 1991, COMP GRAPH, V25, P299, DOI 10.1145/127719.122750; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	67	45	49	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					733	746		10.1109/TPAMI.2009.54	http://dx.doi.org/10.1109/TPAMI.2009.54			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224127	Green Submitted			2022-12-18	WOS:000274548800013
J	Mita, T; Kaneko, T; Stenger, B; Hori, O				Mita, Takeshi; Kaneko, Toshimitsu; Stenger, Bjorn; Hori, Osamu			Discriminative feature co-occurrence selection for object detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object detection; co-occurrence; boosting; feature selection		This paper describes an object detection framework that learns the discriminative co-occurrence of multiple features. Feature co-occurrences are automatically found by Sequential Forward Selection at each stage of the boosting process. The selected feature co-occurrences are capable of extracting structural similarities of target objects leading to better performance. The proposed method is a generalization of the framework proposed by Viola and Jones, where each weak classifier depends only on a single feature. Experimental results obtained using four object detectors for finding faces and three different hand poses, respectively, show that detectors trained with the proposed algorithm yield consistently higher detection rates than those based on their framework while using the same number of features.	[Mita, Takeshi; Kaneko, Toshimitsu] Toshiba Co Ltd, Ctr Corp Res & Dev, Multimedia Lab, Saiwai Ku, Kawasaki, Kanagawa 2128582, Japan; [Stenger, Bjorn] Toshiba Res Europe Ltd, Comp Vis Grp, Cambridge CB4 0GZ, England; [Hori, Osamu] Toshiba Co Ltd, Principal Off, Technol Planning Div, Minato Ku, Tokyo 1058001, Japan	Toshiba Corporation; Toshiba Corporation; Toshiba Corporation	Mita, T (corresponding author), Toshiba Co Ltd, Ctr Corp Res & Dev, Multimedia Lab, Saiwai Ku, 1 Komukai Toshiba Cho, Kawasaki, Kanagawa 2128582, Japan.	takeshi.mita@toshiba.co.jp; toshimitsu.kaneko@toshiba.co.jp; bjorn.stenger@crl.toshiba.co.uk; osamu.hori@toshiba.co.jp						Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J., 1998, ADDITIVE LOGISTIC RE; Georghiades A. S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P277, DOI 10.1109/AFGR.2000.840647; Hadid A, 2004, PROC CVPR IEEE, P797; HEISELE B, 2000, AI MEMO, V1687; Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kolsch M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P614, DOI 10.1109/AFGR.2004.1301601; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Lienhart R, 2002, IEEE IMAGE PROC, P900; Liu C, 2003, PROC CVPR IEEE, P587; Messer K., 1999, P 2 C AUD VID BAS BI; NARENDRA P, 1977, IEEE T COMPUT, V26, P917, DOI 10.1109/TC.1977.1674939; Ong EJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P889; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Samaria F., 1994, P 2 IEEE WORKSH APPL; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; Sim T., 2002, P 5 INT C AUT FAC GE; Stearns S. D., 1976, 3rd International Joint Conference on Pattern Recognition, P71; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Torralba A., 2004, P COMP VIS PATT REC; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; Zhang D, 2004, INT C PATT RECOG, P411, DOI 10.1109/ICPR.2004.1334238	32	45	49	3	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1257	1269		10.1109/TPAMI.2007.70767	http://dx.doi.org/10.1109/TPAMI.2007.70767			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550907				2022-12-18	WOS:000256294100011
J	Bloy, GJ				Bloy, Greg J.			Blind camera fingerprinting and image clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering algorithms; forensics; image processing; pattern recognition; machine learning		Previous studies have shown how to "fingerprint" a digital camera given a set of images known to come from the camera. A clustering technique is proposed to construct such fingerprints from a mixed set of images, enabling identification of each image's source camera without any prior knowledge of source.	Aerosp Corp, Chantilly, VA 20151 USA	Aerospace Corporation - USA	Bloy, GJ (corresponding author), Aerosp Corp, 15049 Conf Ctr Dr,CH3-240, Chantilly, VA 20151 USA.	greg.j.bloy@aero.org						GERADTS ZJ, 2001, P SPIE EN TECHN LAW, V4232; Kundu S, 1999, PATTERN RECOGN, V32, P1149, DOI 10.1016/S0031-3203(98)00143-5; Lukas J, 2005, PROC SPIE, V5685, P249, DOI 10.1117/12.587105; LUKAS J, 2005, P I C IM PROC; Lukas J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602	5	45	47	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					532	U1		10.1109/TPAMI.2007.1183	http://dx.doi.org/10.1109/TPAMI.2007.1183			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195445				2022-12-18	WOS:000252286100013
J	Miyazaki, D; Ikeuchi, K				Miyazaki, Daisuke; Ikeuchi, Katsushi			Shape estimation of transparent objects by using inverse polarization ray tracing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						polarization; raytracing; shape-from-X; transparency; Mueller calculus	SURFACE ORIENTATIONS	Few methods have been proposed to measure three-dimensional shapes of transparent objects such as those made of glass and acrylic. In this paper, we propose a novel method for estimating the surface shapes of transparent objects by analyzing the polarization state of the light. Existing methods do not fully consider the reflection, refraction, and transmission of the light occurring inside a transparent object. We employ a polarization raytracing method to compute both the path of the light and its polarization state. Polarization raytracing is a combination of conventional raytracing, which calculates the trajectory of light rays, and Mueller calculus, which calculates the polarization state of the light. First, we set an initial value of the shape of the transparent object. Then, by changing the shape, the method minimizes the difference between the input polarization data and the rendered polarization data calculated by polarization raytracing. Finally, after the iterative computation is converged, the shape of the object is obtained. We also evaluate the method by measuring some real transparent objects.	Univ Tokyo, Inst Ind Sci, Dept 3, Ikeuchi Lab, Tokyo 1538505, Japan	University of Tokyo	Miyazaki, D (corresponding author), Univ Tokyo, Inst Ind Sci, Dept 3, Ikeuchi Lab, 4-6-1 Komaba, Tokyo 1538505, Japan.	miyazaki@cvl.iis.u-tokyo.ac.jp; ki@cvl.iis.u-tokyo.ac.jp						[Anonymous], 1992, NUMERICAL RECIPES C; ATKINSON GA, 2006, P IEEE COMP SOC C CO, P495; Atkinson GA, 2006, IEEE T IMAGE PROCESS, V15, P1653, DOI 10.1109/TIP.2006.871114; Ben-Ezra M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1025; Born M., 1959, PRINCIPLE OPTICS, P803; CHIPMAN RA, 1995, OPT ENG, V34, P1636, DOI 10.1117/12.202061; COURANT R, 1953, MEHTODS MATH PHYS; Guy S, 2004, ACM T GRAPHIC, V23, P231, DOI 10.1145/1015706.1015708; Hata S., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P684, DOI 10.1109/ICPR.1996.547652; HECHT E, 2002, OPTICS, P693; Horn B. K. P., 1986, ROBOT VISION, P509; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; IKEUCHI K, 1984, P INT C PATT REC, P736; Koshikawa K., 1987, Advanced Robotics, V2, P137, DOI 10.1163/156855387X00129; Kutulakos KN, 2005, IEEE I CONF COMP VIS, P1448; Miyazaki D, 2002, J OPT SOC AM A, V19, P687, DOI 10.1364/JOSAA.19.000687; Miyazaki D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P982; Miyazaki D, 2004, IEEE T PATTERN ANAL, V26, P73, DOI 10.1109/TPAMI.2004.1261080; Morris NJW, 2005, IEEE I CONF COMP VIS, P1573; MURASE H, 1992, IEEE T PATTERN ANAL, V14, P1045, DOI 10.1109/34.159906; Rahmann S, 2001, PROC CVPR IEEE, P149; Saito M, 1999, J OPT SOC AM A, V16, P2286, DOI 10.1364/JOSAA.16.002286; Schechner YY, 2000, J OPT SOC AM A, V17, P276, DOI 10.1364/JOSAA.17.000276; Tannenbaum D.C., 1994, P INT WORKSH APPL RO, P221; WILKIE A, 2001, P 12 EUR WORKSH REND, P197; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; WOLFF LB, 1990, IEEE COMPUT GRAPH, V10, P44, DOI 10.1109/38.62695	28	45	49	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					2018	2029		10.1109/TPAMI.2007.1117	http://dx.doi.org/10.1109/TPAMI.2007.1117			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848781				2022-12-18	WOS:000249343900011
J	Matei, BC; Meer, P				Matei, Bogdan C.; Meer, Peter			Estimation of nonlinear errors-in-variables models for computer vision applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonlinear least squares; heteroscedastic regression; camera calibration; 3D rigid motion; uncalibrated vision	TRANSFORMATIONS	In an errors-in-variables (EIV) model, all the measurements are corrupted by noise. The class of EIV models with constraints separable into the product of two nonlinear functions, one solely in the variables and one solely in the parameters, is general enough to represent most computer vision problems. We show that the estimation of such nonlinear EIV models can be reduced to iteratively estimating a linear model having point dependent, i.e., heteroscedastic, noise process. Particular cases of the proposed heteroscedastic errors-in-variables (HEIV) estimator are related to other techniques described in the vision literature: the Sampson method, renormalization, and the fundamental numerical scheme. In a wide variety of tasks, the HEIV estimator exhibits the same, or superior, performance as these techniques and has a weaker dependence on the quality of the initial solution than the Levenberg-Marquardt method, the standard approach toward estimating nonlinear models.	Sarnoff Corp, Vis Technol Lab, Princeton, NJ 08540 USA; Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA	Sarnoff Corporation; Rutgers State University New Brunswick	Matei, BC (corresponding author), Sarnoff Corp, Vis Technol Lab, 201 Washington Rd, Princeton, NJ 08540 USA.	bmatei@sarnoff.com; meer@caip.ruters.edu						ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; BREWER JW, 1978, IEEE T CIRCUITS SYST, V25, P772, DOI 10.1109/TCS.1978.1084534; Bride J, 2001, PROC CVPR IEEE, P984; Chen HF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P878, DOI 10.1109/ICCV.2003.1238441; Chojnacki W, 2004, IMAGE VISION COMPUT, V22, P85, DOI 10.1016/S0262-8856(03)00140-9; Chojnacki W, 2004, IEEE T PATTERN ANAL, V26, P264, DOI 10.1109/TPAMI.2004.1262197; Chojnacki W, 2001, J MATH IMAGING VIS, V14, P21, DOI 10.1023/A:1008355213497; Chojnacki W, 2000, IEEE T PATTERN ANAL, V22, P1294, DOI 10.1109/34.888714; EDELMAN A, 1997, SIAM J MATRIX ANAL A, V20, P217; Eggert DW, 1997, MACH VISION APPL, V9, P272, DOI 10.1007/s001380050048; FORSTNER W, 2001, FESTSCHRIFT ANLASSLI, P69; Fuller W. A., 2009, MEASUREMENT ERROR MO; GEORGESCU B, 2002, P EUR C COP VIS, V2, P294; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GRAHAM A, E HORWOOD SERIES MAT; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; Kanatani K, 2001, IEEE T INFORM THEORY, V47, P2017, DOI 10.1109/18.930934; Kanatani K., 1993, GEOMETRIC COMPUTATIO; Kanatani K., 1996, STAT OPTIMIZATION GE; KOENDERINK J, 1998, INT J COMPUT VISION, V23, P303; Leedan Y, 2000, INT J COMPUT VISION, V37, P127, DOI 10.1023/A:1008185619375; Ma Y, 2001, INT J COMPUT VISION, V44, P219, DOI 10.1023/A:1012276232049; Matei B., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P339, DOI 10.1109/CVPR.1999.786961; MATEI B, 2000, P COMP VIS PATT REC, V22, P18; MATEI B, 1998, EMPIRICAL EVALUATION, P72; MATEI B, 2001, THESIS RUTGERS U; MATEI B, 2001, P 8 INT C COMP VIS, V2, P578; MATEI B, 2000, P 15 INT C PATT REC, V3, P802; Morris DD, 2001, PROC CVPR IEEE, P343; NESTARES O, 2003, P IEEE INT C IM PROC; OHTA N, 1998, P EUR C COMP VIS ECC, P175; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; Stewart GW, 1997, SIAM PROC S, P3; Subbarao R, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P70; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; TRUCCO E, 1998, INTRO TECHNIQUES 3 D; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; Van Huffel S., 1991, TOTAL LEAST SQUARES; VANDENHENGEL A, 2002, P 13 BRIT MACH VIS C, P468; VANHUFFEL S, 1989, SIAM J MATRIX ANAL A, V10, P294; ZAMAR RH, 1989, BIOMETRIKA, V76, P149, DOI 10.2307/2336379; ZHANG Z, 1995, IMAGE MATCHING SOFTW	44	45	51	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2006	28	10					1537	1552		10.1109/TPAMI.2006.205	http://dx.doi.org/10.1109/TPAMI.2006.205			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	071ME	16986538				2022-12-18	WOS:000239605500001
J	Yip, AM; Ding, C; Chan, TF				Yip, AM; Ding, C; Chan, TF			Dynamic cluster formation using level set methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dynamic clustering; level set methods; cluster intensity functions; kernel density estimation; cluster contours; partial differential equations	ALGORITHMS	Density- based clustering has the advantages for 1) allowing arbitrary shape of cluster and 2) not requiring the number of clusters as input. However, when clusters touch each other, both the cluster centers and cluster boundaries ( as the peaks and valleys of the density distribution) become fuzzy and difficult to determine. We introduce the notion of cluster intensity function ( CIF) which captures the important characteristics of clusters. When clusters are well- separated, CIFs are similar to density functions. But, when clusters become closed to each other, CIFs still clearly reveal cluster centers, cluster boundaries, and degree of membership of each data point to the cluster that it belongs. Clustering through bump hunting and valley seeking based on these functions are more robust than that based on density functions obtained by kernel density estimation, which are often oscillatory or oversmoothed. These problems of kernel density estimation are resolved using Level Set Methods and related techniques. Comparisons with two existing density- based methods, valley seeking and DBSCAN, are presented which illustrate the advantages of our approach.	Natl Univ Singapore, Dept Math, Singapore 117543, Singapore; Univ Calif Berkeley, Lawrence Berkeley Lab, Computat Res Div, Berkeley, CA 94720 USA; Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90095 USA	National University of Singapore; United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; University of California System; University of California Berkeley; University of California System; University of California Los Angeles	Yip, AM (corresponding author), Natl Univ Singapore, Dept Math, 2,Sci Dr 2, Singapore 117543, Singapore.	matymha@nus.edu.sg; chqding@lbl.gov; chan@college.ucla.edu	Yip, Andy/C-9025-2011; Yip, Andy/GQQ-5041-2022; Chan, Tony F/A-4166-2013	Chan, Tony F/0000-0001-6196-2068	NATIONAL INSTITUTE OF MENTAL HEALTH [P20MH065166] Funding Source: NIH RePORTER; NIMH NIH HHS [P20 MH65166] Funding Source: Medline	NATIONAL INSTITUTE OF MENTAL HEALTH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH)); NIMH NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH))		Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49; Banerjee A, 2004, SIAM PROC S, P234; Ben-Hur A., 2002, Journal of Machine Learning Research, V2, P125, DOI 10.1162/15324430260185565; Berkhin P., 2002, SURVEY CLUSTERING DA; Bungartz HJ, 2004, ACT NUMERIC, V13, P147, DOI 10.1017/S0962492904000182; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Ding C, 2005, LECT NOTES ARTIF INT, V3721, P71; Ding CHQ, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P107, DOI 10.1109/ICDM.2001.989507; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Ertoz L, 2003, SIAM PROC S, P47; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Garcke J, 2003, LECT NOTES COMPUT SC, V2659, P683; Garcke J, 2001, COMPUTING, V67, P225, DOI 10.1007/s006070170007; GARCKE J, 2001, P 7 ACM SIGKDD INT C, P87; Han J, 2001, DATA MINING CONCEPTS, DOI 10.1016/C2009-0-61819-5; Hansen P, 1997, MATH PROGRAM, V79, P191, DOI 10.1007/BF02614317; Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P58; Jain A. K., 1988, FUNDAMENTALS DIGITAL; Jolliffe J. T., 2002, PRINCIPAL COMPONENT; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; Kaufman L., 2009, FINDING GROUPS DATA; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; McLachlan G.J., 2001, FINITE MIXTURE MODEL; NG RT, 1994, P 20 INT C VER LARG, P144; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osher S, 2003, LEVEL SET METHODS DY; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Prabhakar S, 1998, PROC INT CONF DATA, P94, DOI 10.1109/ICDE.1998.655763; SAIN SR, 1994, J AM STAT ASSOC, V89, P807, DOI 10.2307/2290906; Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419; Sapiro G., 2001, GEOMETRIC PARTIAL DI; Sethian J. A., 1999, LEVEL SET METHODS FA; Sharan R, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P307; Sheikholeslami G, 2000, VLDB J, V8, P289, DOI 10.1007/s007780050009; Spellman PT, 1998, MOL BIOL CELL, V9, P3273, DOI 10.1091/mbc.9.12.3273; Tsai YHR, 2003, SIAM J NUMER ANAL, V41, P673, DOI 10.1137/S0036142901396533; Wang W, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P186; Zenger C., 1991, PARALLEL ALGORITHMS, V31; Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167	42	45	46	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					877	889		10.1109/TPAMI.2006.117	http://dx.doi.org/10.1109/TPAMI.2006.117			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724583				2022-12-18	WOS:000236734400003
J	Ji, SH; Krishnapuram, B; Carin, L				Ji, SH; Krishnapuram, B; Carin, L			Variational Bayes for continuous hidden Markov models and its application to active learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						variational Bayes (VB); continuous hidden Markov models (CHMMs); active learning (AL); query by committee (QBC); maximum expected information gain (MEIG); error-reduction-based active learning		In this paper, we present a varitional Bayes (VB) framework for learning continuous hidden Markov models (CHMMs), and we examine the VB framework within active learning. Unlike a maximum likelihood or maximum a posteriori training procedure, which yield a point estimate of the CHMM parameters, VB-based training yields an estimate of the full posterior of the model parameters. This is particularly important for small training sets since it gives a measure of confidence in the accuracy of the learned model. This is utilized within the context of active learning, for which we acquire labels for those feature vectors for which knowledge of the associated label would be most informative for reducing model-parameter uncertainty. Three active learning algorithms are considered in this paper: 1) query by committee (QBC), with the goal of selecting data for labeling that minimize the classification variance, 2) a maximum expected information gain method that seeks to label data with the goal of reducing the entropy of the model parameters, and 3) an error-reduction-based procedure that attempts to minimize classification error over the test data. The experimental results are presented for synthetic and measured data. We demonstrate that all of these active learning methods can significantly reduce the amount of required labeling, compared to random selection of samples for labeling.	Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA; Siemens Med Solut USA Inc, Comp Aided Diag & Therapy Grp, Malvern, PA 19355 USA	Duke University; Siemens AG	Ji, SH (corresponding author), Duke Univ, Dept Elect & Comp Engn, Box 90291, Durham, NC 27708 USA.	shji@ee.duke.edu; balaji.krishnapuram@siemens.com; lcarin@ee.duke.edu		Carin, Lawrence/0000-0001-6277-7948				Attias H., 2000, P ANN C NEUR INF PRO; Bishop C.M., 2000, 16 C UNCERTAINTY ART, P46; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; ENGELSON SA, 1999, J ARTIFICIAL INTELLI, P335; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; FREY BJ, 2003, IEEE T PATTERN ANAL; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Geman S, 1992, NEURAL COMPUTATION; Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310; MacKay D.J.C., 1997, BOOK ENSEMBLE LEARNI; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; McCallumzy A.K., 1998, ICML, V98, P359; MINKA TP, 2001, USING LOWER BOUNDS A; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Roy Nicholas, 2001, ICML, P894; Runkle PR, 1999, IEEE T SIGNAL PROCES, V47, P2035, DOI 10.1109/78.771050; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P287, DOI 10.1145/130385.130417; SPALL JC, 2003, IEEE CONTROL SYS APR; Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243	23	45	46	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					522	532		10.1109/TPAMI.2006.85	http://dx.doi.org/10.1109/TPAMI.2006.85			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	011FK	16566502				2022-12-18	WOS:000235253300003
J	Pedreira, CE				Pedreira, CE			Learning vector quantization with training data selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						learning vector quantization LVQ; pattern classification; clustering; data selection; neural networks	MULTISURFACE METHOD; PATTERN SEPARATION; DIAGNOSIS	In this paper, we propose a method that selects a subset of the training data points to update LVQ prototypes. The main goal is to conduct the prototypes to converge at a more convenient location, diminishing misclassification errors. The method selects an update set composed by a subset of points considered to be at the risk of being captured by another class prototype. We associate the proposed methodology to a weighted norm, instead of the Euclidean, in order to establish different levels of relevance for the input attributes. The technique was implemented on a controlled experiment and on Web available data sets.	Univ Fed Rio de Janeiro, Rio De Janeiro, Brazil	Universidade Federal do Rio de Janeiro	Pedreira, CE (corresponding author), Univ Fed Rio de Janeiro, Rio De Janeiro, Brazil.	carlosp@centroin.com.br	Pedreira, Carlos/I-5629-2013	Pedreira, Carlos/0000-0002-9312-4023				[Anonymous], 1998, NEURAL NETWORKS COMP; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Berzal F, 2003, DATA KNOWL ENG, V44, P31, DOI 10.1016/S0169-023X(02)00062-9; Bottou L, 2004, LECT NOTES ARTIF INT, V3176, P146; Crammer K., 2002, P 15 ANN C NEUR INF; DETRANO R, 1989, AM J CARDIOL, V64, P304, DOI 10.1016/0002-9149(89)90524-9; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GERSHO A, 1979, IEEE T INFORM THEORY, V25, P373, DOI 10.1109/TIT.1979.1056067; Girolami M., 1999, SELF ORGANISING NEUR; Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5; HARMON NH, 1967, MODERN FACTOR ANAL; JONSON RA, 1998, APPL MULTIVARIABLE S; KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1988, P IEEE INT C NEUR NE; Kohonen T, 2001, SELF ORGANIZING MAPS; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; MANGASARIAN OL, 1968, IEEE T INFORM THEORY, V14, P801, DOI 10.1109/TIT.1968.1054229; OJA E, 1995, HDB BRAIN THEORY NEU, P753; Olshen R., 1984, CLASSIFICATION REGRE; QIN AK, 2005, PATTERN RECOGNITION; SATO AS, 1995, ADV NEURAL INFORMATI, V7, P423; Seo S, 2003, NEURAL COMPUT, V15, P1589, DOI 10.1162/089976603321891819; Setiono R, 1997, IEEE T NEURAL NETWOR, V8, P654, DOI 10.1109/72.572104; Vakil-Baghmisheh MT, 2003, PATTERN RECOGN, V36, P1901, DOI 10.1016/S0031-3203(02)00291-1; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; ZADOR PL, 1982, IEEE T INFORM THEORY, V28, P139, DOI 10.1109/TIT.1982.1056490	30	45	45	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2006	28	1					157	162		10.1109/TPAMI.2006.14	http://dx.doi.org/10.1109/TPAMI.2006.14			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	982OR	16402629				2022-12-18	WOS:000233172000015
J	Koerich, AL; Sabourin, R; Suen, CY				Koerich, AL; Sabourin, R; Suen, CY			Recognition and verification of unconstrained handwritten words	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						word hypothesis rejection; classifier combination; large vocabulary; handwriting recognition; neural networks	CHARACTER-RECOGNITION; SYSTEM; FUSION	This paper presents a novel approach for the verification of the word hypotheses generated by a large vocabulary, offline handwritten word recognition system. Given a word image, the recognition system produces a ranked list of the N-best recognition hypotheses consisting of text transcripts, segmentation boundaries of the word hypotheses into characters, and recognition scores. The verification consists of an estimation of the probability of each segment representing a known class of character. Then, character probabilities are combined to produce word confidence scores which are further integrated with the recognition scores produced by the recognition system. The N-best recognition hypothesis list is reranked based on such composite scores. In the end, rejection rules are invoked to either accept the best recognition hypothesis of such a list or to reject the input word image. The use of the verification approach has improved the word recognition rate as well as the reliability of the recognition system, while not causing significant delays in the recognition process. Our approach is described in detail and the experimental results on a large database of unconstrained handwritten words extracted from postal envelopes are presented.	Pontificial Catholic Univ Parana, PUCPR, Postgrad Program Appl Informat, BR-80215901 Curitiba, Parana, Brazil; Ecole Technol Super, Dept Genie Prod Automatisee, Montreal, PQ H3C 1K3, Canada; Concordia Univ, Ctr Pattern Recognit & Machine Intelligence, CENPARMI, Montreal, PQ H3G 1M8, Canada	Pontificia Universidade Catolica do Parana; University of Quebec; Ecole de Technologie Superieure - Canada; Concordia University - Canada	Koerich, AL (corresponding author), Pontificial Catholic Univ Parana, PUCPR, Postgrad Program Appl Informat, R Imaculada Conceicao 1155, BR-80215901 Curitiba, Parana, Brazil.	alekoe@computer.org; robert.sabourin@etsmtl.ca; suen@cenparmi.concordia.ca	Koerich, Alessandro Lameiras/F-7246-2012; Koerich, Alessandro Lameiras/O-7746-2019; Sabourin, Robert/J-7642-2012	Koerich, Alessandro Lameiras/0000-0001-5879-7014; Sabourin, Robert/0000-0002-9098-1011				Arica N, 2002, IEEE T PATTERN ANAL, V24, P801, DOI 10.1109/TPAMI.2002.1008386; Arica N, 2001, IEEE T SYST MAN CY C, V31, P216, DOI 10.1109/5326.941845; Britto A.  Jr., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P396, DOI 10.1109/ICDAR.2001.953820; Carbonnel S, 2003, PROC INT CONF DOC, P477; CHO SJ, 2000, P 7 INT WORKSH FRONT, P219; CORDELLA LP, 2000, P 1 INT WORKSH MULT, P330; DUPLANTIER M, 1998, INTERFACES VISUALISA; El-Yacoubi A, 1999, IEEE T PATTERN ANAL, V21, P752, DOI 10.1109/34.784288; FAROUZ C, 1999, THESIS U NANTES NANT; Gader PD, 1996, PATTERN RECOGN LETT, V17, P577, DOI 10.1016/0167-8655(96)00021-9; Gloger JM, 1997, PROC INT CONF DOC, P556, DOI 10.1109/ICDAR.1997.620562; Gorski N, 1997, PROC INT CONF DOC, P1092, DOI 10.1109/ICDAR.1997.620677; Grandidier F, 2003, PROC INT CONF DOC, P1252; GRANDIDIER F, 2000, ANAL ENSEMBLE CONFUS; Guillevic D., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P11, DOI 10.1109/ICDAR.1995.598933; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Koerich A. L., 2003, International Journal on Document Analysis and Recognition, V6, P126, DOI 10.1007/s10032-003-0113-0; Koerich A. L., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P660, DOI 10.1109/ICDAR.2001.953872; Koerich AL, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P479, DOI 10.1109/IWFHR.2004.88; Koerich AL, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P232, DOI 10.1109/IWFHR.2004.42; Koerich AL, 2003, PATTERN ANAL APPL, V6, P97, DOI 10.1007/s10044-002-0169-3; Koerich AL, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P99, DOI 10.1109/IWFHR.2002.1030893; Koerich AL, 2002, INT CONF ACOUST SPEE, P3537; KOERICH AL, 2002, THESIS U QUEBEC MONT; Madhvanath S, 1999, IEEE T PATTERN ANAL, V21, P1344, DOI 10.1109/34.817412; MARAKUTAT S, 2002, P 8 INT WORKSH FRONT, P24; Oliveira LS, 2001, PROC INT CONF DOC, P389, DOI 10.1109/ICDAR.2001.953819; Pitrelli JF, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P30, DOI 10.1109/IWFHR.2002.1030880; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Powalka RK, 1997, PATTERN RECOGN, V30, P421, DOI 10.1016/S0031-3203(96)00093-3; Schurmann J, 1996, PATTERN CLASSIFICATI; Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887; SRIHARI S, 2000, P 1 INT WORKSH MULT, P45; Steinherz T., 1999, International Journal on Document Analysis and Recognition, V2, P90, DOI 10.1007/s100320050040; Stolcke Andreas, 1997, 5 EUR C SPEECH COMM; Suen CY, 2000, LECT NOTES COMPUT SC, V1857, P52; TAKAHASHI H, 1993, P 2 INT C DOC AN REC, P585; Verma B, 2001, PATTERN RECOGN LETT, V22, P991, DOI 10.1016/S0167-8655(01)00046-0; Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14; Yaeger L, 1997, ADV NEUR IN, V9, P807; Zavaliagkos G, 1994, IEEE T SPEECH AUDI P, V2, P151, DOI 10.1109/89.260358	41	45	51	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1509	1522		10.1109/TPAMI.2005.207	http://dx.doi.org/10.1109/TPAMI.2005.207			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	953OM	16237988				2022-12-18	WOS:000231086700001
J	Zhang, T; Freedman, D				Zhang, T; Freedman, D			Improving performance of distribution tracking through background mismatch	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active contours; density matching; level set method; tracking; PDEs	GEODESIC ACTIVE CONTOURS	This paper proposes a new density matching method based on background mismatching for tracking of nonrigid moving objects. The new tracking method extends the idea behind the original density-matching tracker [7], which tracks an object by finding a contour in which the photometric density sampled from the enclosed region most closely matches a model density. This method can be quite sensitive to the initial curve placements and model density. The new method eliminates these sensitivities by adding a second term to the optimization: The mismatch between the model density and the density sampled from the background. By maximizing this term, the tracking algorithm becomes significantly more robust in practice. Furthermore, we show the enhanced ability of the algorithm to deal with target objects which possess smooth or diffuse boundaries. The tracker is in the form of a partial differential equation, and is implemented using the level-set framework. Experiments on synthesized images and real video sequences show our proposed methods are effective and robust; the results are compared with several existing methods.	Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Zhang, T (corresponding author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.	zhangt3@cs.rpi.edu; freedman@cs.rpi.edu						Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; CHEN YQ, 2001, P IEEE INT C COMP VI; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P281, DOI 10.1109/TPAMI.2003.1177159; FREEDMAN D, 2004, IN PRESS IEEE T IMAG; HUTTENLOCHER DP, 1993, P 4 INT C COMP VIS, P93; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; KASS M, 1987, P INT C COMP VIS JUN; Mansouri AR, 2002, IEEE T PATTERN ANAL, V24, P947, DOI 10.1109/TPAMI.2002.1017621; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; PARAGIOS N, 1999, P INT C COMPUTER VIS, V2, P688; RAO BSY, 1993, INT J ROBOT RES, V12, P20, DOI 10.1177/027836499301200102; Sethian J. A., 1999, LEVEL SET METHODS FA; Terzopoulos D., 1992, ACTIVE VISION, P3; TOYAMA K, 2001, P INT C COMPUTER VIS; TSAI A, 2000, P IEEE COMP SOC C CO, V1, P119; XU G, 1993, P INT C COMPUTER MAY; YEZZI A, 1999, P INT C IM PROC, V2, P1; Yezzi A.  Jr., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P898, DOI 10.1109/ICCV.1999.790317; Yuille A. L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P104, DOI 10.1109/CVPR.1989.37836	23	45	52	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2005	27	2					282	287		10.1109/TPAMI.2005.31	http://dx.doi.org/10.1109/TPAMI.2005.31			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	879AR	15688566				2022-12-18	WOS:000225689300012
J	Jia, JY; Tang, CK				Jia, JY; Tang, CK			Tensor voting for image correction by global and local intensity alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image correction and recovery; color transfer; replacement functions; applications		This paper presents a voting method to perform image correction by global and local intensity alignment. The key to our modeless approach is the estimation of global and local replacement functions by reducing the complex estimation problem to the robust 2D tensor voting in the corresponding voting spaces. No complicated model for replacement function ( curve) is assumed. Subject to the monotonic constraint only, we vote for an optimal replacement function by propagating the curve smoothness constraint using a dense tensor field. Our method effectively infers missing curve segments and rejects image outliers. Applications using our tensor voting approach are proposed and described. The first application consists of image mosaicking of static scenes, where the voted replacement functions are used in our iterative registration algorithm for computing the best warping matrix. In the presence of occlusion, our replacement function can be employed to construct a visually acceptable mosaic by detecting occlusion which has large and piecewise constant color. Furthermore, by the simultaneous consideration of color matches and spatial constraints in the voting space, we perform image intensity compensation and high contrast image correction using our voting framework, when only two defective input images are given.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Hong Kong University of Science & Technology	Jia, JY (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	leojia@cs.ust.hk; cktang@cs.ust.hk	Jia, Jiaya/I-3251-2012					BENEZRA M, 2003, COMPUTER VISION PATT; BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247; Chellappa R, 1993, MARKOV RANDOM FIELDS; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; DAVIS J, 1998, COMPUTER VISION PATT; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; Edirisinghe A, 2001, PHOTOGRAMM ENG REM S, V67, P915; FABIAN R, 1991, CVGIP GRAPHICAL MODE; GOOCH M, 2001, IEEE COMPUT GRAPH, P34; GROSSBERG MD, 2002, P EUR C COMP VIS MAY; HASLER D, 2001, P SPIE; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; JIA J, 2003, P INT C COMP VIS; JIA J, 2004, P EUR C COMP VIS; Kundur D, 1998, IEEE T SIGNAL PROCES, V46, P375, DOI 10.1109/78.655423; LEVY Y, 2002, OPTICAL ENG; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; MANN S, 2001, COMPUTER VISION PATT; Medioni G., 2000, COMPUTATIONAL FRAMEW; MESSINA G, 2003, P IEEE INT C MULT EX; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; Schechner YY, 2002, IEEE T PATTERN ANAL, V24, P1334, DOI 10.1109/TPAMI.2002.1039205; SHIRLEY P, 2002, P SIGGRAPH, P267; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677; SZELISKI R, 1997, P SIGGRAPH, P251; TSIN Y, 2001, P INT C COMP VIS JUL; Uyttendaele M., 2001, COMPUTER VISION PATT; Yitzhaky Y, 1998, J OPT SOC AM A, V15, P1512, DOI 10.1364/JOSAA.15.001512; ZHU Z, 2001, P INT C COMP VIS JUL	32	45	50	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2005	27	1					36	50		10.1109/TPAMI.2005.20	http://dx.doi.org/10.1109/TPAMI.2005.20			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	870BE	15628267	Green Submitted			2022-12-18	WOS:000225028200005
J	Fusiello, A; Benedetti, A; Farenzena, M; Busti, A				Fusiello, A; Benedetti, A; Farenzena, M; Busti, A			Globally convergent autocalibration using interval analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing and computer vision; camera calibration; modeling from video; interval arithmetic; 3D/stereo scene analysis; self-calibration	EUCLIDEAN RECONSTRUCTION; KRUPPAS EQUATIONS; SELF-CALIBRATION; CAMERA; CORRESPONDENCES; MATRIX; MOTION	We address the problem of autocalibration of a moving camera with unknown constant intrinsic parameters. Existing autocalibration techniques use numerical optimization algorithms whose convergence to the correct result cannot be guaranteed, in general. To address this problem, we have developed a method where an interval branch-and-bound method is employed for numerical minimization. Thanks to the properties of Interval Analysis this method converges to the global solution with mathematical certainty and arbitrary accuracy and the only input information it requires from the user are a set of point correspondences and a search interval. The cost function is based on the Huang-Faugeras constraint of the essential matrix. A recently proposed interval extension based on Bernstein polynomial forms has been investigated to speed up the search for the solution. Finally, experimental results are presented.	Univ Verona, Dipartimento Informat, I-37134 Verona, Italy; KLA Tencor, Milpitas, CA 95035 USA	University of Verona; KLA Corporation	Fusiello, A (corresponding author), Univ Verona, Dipartimento Informat, I-37134 Verona, Italy.	fusiello@sci.univr.it; Arrigo.Benedetti@kla-tencor.com; farenzen@sci.univr.it; busti@cad.it	Fusiello, Andrea/GOJ-9893-2022; Fusiello, Andrea/A-3162-2016	Fusiello, Andrea/0000-0003-2963-0316; Fusiello, Andrea/0000-0003-2963-0316				Beardsley PA, 1997, INT J COMPUT VISION, V23, P235, DOI 10.1023/A:1007923216416; Bougnoux S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P790, DOI 10.1109/ICCV.1998.710808; DU KS, 1994, J GLOBAL OPTIM, V5, P253, DOI 10.1007/BF01096455; Fusiello A, 2000, IMAGE VISION COMPUT, V18, P555, DOI 10.1016/S0262-8856(99)00065-7; FUSIELLO A, 2003, RR092003 U VER DIP I; HANSEN E, 1992, GLOBAL OPTIMIZATION; HARTLEY R, 1992, P 2 EUR C COMP VIS, P579; HARTLEY R, 1999, P IEEE INT C COMP VI; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P133, DOI 10.1109/34.574792; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362; Heyden A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P339, DOI 10.1109/ICPR.1996.546045; HEYDEN A, 1998, P AS C COMP VIS; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368; Kearfott RB., 1996, RIGOROUS GLOBAL SEAR, DOI [10.1007/978-1-4757-2495-0, DOI 10.1007/978-1-4757-2495-0]; LOURAKIS MI, 2000, P AS C COMP VIS TAIP, V1, P403; Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991; Luong QT, 1996, COMPUT VIS IMAGE UND, V64, P193, DOI 10.1006/cviu.1996.0055; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; Makino K., 2003, INT J PURE APPL MATH, V6, P239; MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171; Mendonca P. R. S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P500, DOI 10.1109/CVPR.1999.786984; Moore R. E., 1996, METHOD APPL INTERVAL; Nataray PSV, 2002, J GLOBAL OPTIM, V24, P417, DOI 10.1023/A:1021296315884; Neumaier A., 2003, Reliable Computing, V9, P43, DOI 10.1023/A:1023061927787; NEUMAIER A, 2001, INTRO NUMERICAL ANAL; OLIENSIS J, 1999, P IEEE INT C COMP VI; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; Pollefeys M, 1997, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.1997.609357; PONCE J, 2002, P SMILE 2000 WORKSH, V2018, P52; Rogers D.F., 1990, MATH ELEMENTS COMPUT, Vsecond; Roth G, 2002, INT C PATT RECOG, P312, DOI 10.1109/ICPR.2002.1048302; Sturm P, 2000, IEEE T PATTERN ANAL, V22, P1199, DOI 10.1109/34.879804; STURM P, 2001, PROC CVPR IEEE, P145; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; UESHIBA T, 1998, P 5 ECCV, V1, P296; ZELLER C, 1996, 2793 INRIA; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	40	45	48	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1633	1638		10.1109/TPAMI.2004.125	http://dx.doi.org/10.1109/TPAMI.2004.125			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	861AO	15573823				2022-12-18	WOS:000224388700008
J	Peng, J; Heisterkamp, DR; Dai, HK				Peng, J; Heisterkamp, DR; Dai, HK			Adaptive quasiconformal kernel nearest neighbor classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; nearest neighbors; quasiconformal mapping; kernel methods; feature space		Nearest neighbor classification assumes locally constant class conditional probabilities. This assumption becomes invalid in high dimensions due to the curse-of-dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. We propose an adaptive nearest neighbor classification method to try to minimize bias. We use quasiconformal transformed kernels to compute neighborhoods over which the class probabilities tend to be more homogeneous. As a result, better classification performance can be expected. The efficacy of our method is validated and compared against other competing techniques using a variety of data sets.	Tulane Univ, Dept Elect Engn & Comp Sci, New Orleans, LA 70118 USA; Oklahoma State Univ, Dept Comp Sci, Stillwater, OK 74078 USA	Tulane University; Oklahoma State University System; Oklahoma State University - Stillwater	Peng, J (corresponding author), Tulane Univ, Dept Elect Engn & Comp Sci, New Orleans, LA 70118 USA.	jp@eecs.tulane.edu; doug@cs.okstate.edu; dai@cs.okstate.edu						Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; [Anonymous], 1997, CONFORMAL INVARIANTS; Bellman R., 1961, ADAPTIVE CONTROL PRO; Blair D. E., 2000, INVERSION THEORY CON; Cristianini N., 2000, INTRO SUPPORT VECTOR; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R.O., 1973, J ROYAL STAT SOC SER; Friedman J. H., 1994, FLEXIBLE METRIC NEAR; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Heisterkamp DR, 2001, PROC CVPR IEEE, P388; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; Peng J, 2001, PROC CVPR IEEE, P58; Scholkopf B., 1999, ADV KERNEL METHODS S; Schomerus H, 2000, EUR PHYS J D, V10, P5, DOI 10.1007/s100530050520; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; TONG S, 2000, P AAAI; Vapnik VN, 1998, ADAPTIVE LEARNING SY	19	45	48	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2004	26	5					656	661		10.1109/TPAMI.2004.1273978	http://dx.doi.org/10.1109/TPAMI.2004.1273978			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EY	15460287				2022-12-18	WOS:000220756400011
J	Liu, JZ; Lee, YT; Cham, WK				Liu, JZ; Lee, YT; Cham, WK			Identifying faces in a 2D line drawing representing a manifold object	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D models; face identification; geometry; graphs; line drawings; manifolds	WIRE FRAMES; 3D OBJECT; RECONSTRUCTION; IDENTIFICATION; MODELS; SHAPE	A straightforward way to illustrate a 3D model is to use a line drawing. Faces in a 2D line drawing provide important information for reconstructing its 3D geometry. Manifold objects belong to a class of common solids and most solid systems are based on manifold geometry. In this paper, a new method is proposed for finding faces from single 2D line drawings representing manifolds. The face identification is formulated based on a property of manifolds: each edge of a manifold is shared exactly by two faces. The two main steps in our method are 1) searching for cycles from a line drawing and 2) searching for faces from the cycles. In order to speed up the face identification procedure, a number of properties, most of which relate to planar manifold geometry in line drawings, are presented to identify most of the cycles that are or are not real faces in a drawing, thus reducing the number of unknown cycles in the second searching. Schemes to deal with manifolds with curved faces and manifolds each represented by two or more disjoint graphs are also proposed. The experimental results show that our method can handle manifolds previous methods can handle, as well as those they cannot.	Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China; Nanyang Technol Univ, Sch Mech & Prod Engn, Singapore 2263, Singapore	Chinese University of Hong Kong; Chinese University of Hong Kong; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Liu, JZ (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China.	jzliu@ee.cuhk.edu.hk; wkcham@ee.cuhk.edu.hk; mytlee@ntu.edu.sg	Lee, Yong Tsui/A-1373-2011	Lee, Yong Tsui/0000-0003-1285-4217				Ablameyko S, 1999, COMPUT CONTROL ENG J, V10, P277, DOI 10.1049/cce:19990606; AGARWAL SC, 1992, COMPUT AIDED DESIGN, V24, P123, DOI 10.1016/0010-4485(92)90032-6; Bagali S., 1995, Proceedings. Third Symposium on Solid Modeling and Applications, P339, DOI 10.1145/218013.218083; Chartrand G., 1993, APPL ALGORITHMIC GRA; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; Cooper MC, 2001, INT J COMPUT VISION, V43, P75, DOI 10.1023/A:1011166601983; COOPER MC, 1993, IMAGE VISION COMPUT, V11, P82, DOI 10.1016/0262-8856(93)90074-Q; Courter S. M., 1986, Computer Graphics, V20, P171, DOI 10.1145/15886.15905; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; DUTTON RD, 1983, COMPUT GRAPH, V7, P143, DOI 10.1016/0097-8493(83)90004-3; GANTER MA, 1983, COMPUTER MECH ENG, V2, P40; Hanrahan P. M., 1982, Computer Graphics, V16, P77, DOI 10.1145/965145.801265; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HOJNICKI JS, 1988, COMPUTERS MECH E MAR, P19; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; Kuo MH, 1998, COMPUT AIDED DESIGN, V30, P517, DOI 10.1016/S0010-4485(98)00006-2; LaCourse D.E., 1995, HDB SOLID MODELING; LECLERC YG, 1992, INT J COMPUT VISION, V9, P113, DOI 10.1007/BF00129683; LEQUETTE R, 1988, COMPUT AIDED DESIGN, V20, P171, DOI 10.1016/0010-4485(88)90273-4; Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X; Liu JZ, 2001, IEEE T PATTERN ANAL, V23, P1106; LYSAK D, 1991, THESIS PENNSYLVANIA; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; Mantyla M., 1988, INTRODUCTION; MARILL T, 1991, INT J COMPUT VISION, V6, P147, DOI 10.1007/BF00128154; MARKOWSKY G, 1980, IBM J RES DEV, V24, P582, DOI 10.1147/rd.245.0582; Mateti P., 1976, SIAM Journal on Computing, V5, P90, DOI 10.1137/0205007; REINGOLD EM, 1977, COMBINATORIAL ALGORI; Sedgewick R., 1990, ALGORITHMS C; Shimshoni I, 1997, COMPUT VIS IMAGE UND, V65, P296, DOI 10.1006/cviu.1996.0569; Shpitalni M, 1996, IEEE T PATTERN ANAL, V18, P1000, DOI 10.1109/34.541409; SUGIHARA K, 1984, ARTIF INTELL, V23, P59, DOI 10.1016/0004-3702(84)90005-5; SUGIHARA K, 1984, IEEE T PATTERN ANAL, V6, P578, DOI 10.1109/TPAMI.1984.4767571; THOMASSEN C, 1989, J ALGORITHM, V10, P568, DOI 10.1016/0196-6774(89)90006-0; Turner A, 2000, COMPUT GRAPH-UK, V24, P869, DOI 10.1016/S0097-8493(00)00089-3; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19	36	45	51	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1579	1593		10.1109/TPAMI.2002.1114850	http://dx.doi.org/10.1109/TPAMI.2002.1114850			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	618YA		Green Submitted			2022-12-18	WOS:000179444600003
J	Oliensis, J				Oliensis, J			Exact two-image structure from motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure from motion; two-image structure from motion; least-squares error; triangulation; ambiguity; spherical retina; coplanarity; Sampson error; local minima	LOCAL AMBIGUITIES; ALGORITHMS	For two-image structure from motion, we present a simple, exact expression for a least-squares image-reprojection error for finite motion that depends only on the motion. Optimal estimates of the structure and motion can be computed by minimizing this expression just over the motion parameters. Also, we present a solution to the triangulation problem: an exact, explicit expression for the optimal structure estimate given the motion. We identify a new ambiguity in recovering the structure for known motion. We study the exact error's properties experimentally and demonstrate that it often has several local minima for forward or backward motion estimates. Our experiments also show that the "reflected" local minimum of Oliensis and Soatto et al. occurs for large translational motions. Our exact results assume that the camera is calibrated and use a least-squares image-reprojection error that applies most naturally to a spherical imaging surface. We approximately extend our approach to the standard least-squares error in the image plane and uncalibrated cameras. We present an improved version of the Sampson error which gives better results experimentally.	NEC Res Inst, Princeton, NJ 08540 USA	NEC Corporation	Oliensis, J (corresponding author), NEC Res Inst, 4 Independence Way, Princeton, NJ 08540 USA.	oliensis@research.nj.nec.com						Chiuso A, 2000, INT J COMPUT VISION, V39, P195, DOI 10.1023/A:1026563712076; Dutta R., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P159, DOI 10.1109/CVPR.1989.37844; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; HARTLEY RI, 1993, P 2 EUR US WORKSH IN, P187; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; JEPSON AD, 1993, SPATIAL VISION IN HUMANS AND ROBOTS, P39; Kanatani K., 1993, GEOMETRIC COMPUTATIO; Kumar R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P365, DOI 10.1109/ICCV.1990.139552; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; NISTER D, 2001, THESIS KTH; Oliensis J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P737, DOI 10.1109/ICCV.1999.790295; Oliensis J, 2000, IEEE T PATTERN ANAL, V22, P685, DOI 10.1109/34.865186; Oliensis J, 1999, INT J COMPUT VISION, V34, P163, DOI 10.1023/A:1008139920864; Oliensis J, 2001, IEEE T PATTERN ANAL, V23, P546, DOI 10.1109/34.927457; OLIENSIS J, 2001, EXACT 2 IMAGE STRUCT; OLIENSIS J, 2001, ERROR SURFACE STRUCT; Soatto S, 1998, PROC CVPR IEEE, P282, DOI 10.1109/CVPR.1998.698621; SOATTO S, 1997, OPTIMAL SUBOPTIMAL S; Srinivasan S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P528, DOI 10.1109/ICCV.1999.791268; Srinivasan S, 2000, INT J COMPUT VISION, V37, P203, DOI 10.1023/A:1008111923880; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; TRIGGS B, 1999, P WORKSH VIS ALG; VIDAL R, 2001, P INT C COMP VIS, V1, P34; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; Zhang ZY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P772, DOI 10.1109/ICCV.1998.710805; Zhang ZY, 1998, IEEE T PATTERN ANAL, V20, P717, DOI 10.1109/34.689302	29	45	46	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1618	1633		10.1109/TPAMI.2002.1114853	http://dx.doi.org/10.1109/TPAMI.2002.1114853			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	618YA					2022-12-18	WOS:000179444600006
J	Malis, E; Cipolla, R				Malis, E; Cipolla, R			Camera self-calibration from unknown planar structures enforcing the multiview constraints between collineations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						self-calibration; multiple views; planes; collineation; nonlinear constraints	PROJECTIVE STRUCTURE; RECONSTRUCTION	In this paper, we describe an efficient method to impose the constraints existing between the collineations between images which can be computed from a sequence of views of a planar structure. These constraints are usually not taken into account by multiview techniques in order not to increase the computational complexity of the algorithms. However, imposing the constraints is very useful since it allows a reduction of geometric errors in the reprojected features and provides a consistent set of collineations which can be used for several applications such as mosaicing, reconstruction, and self-calibration. In order to show the validity of our approach, this paper focus on self-calibration from unknown planar structures proposing a method exploiting the consistent set of collineations. Our method can deal with an arbitrary number of views and an arbitrary number of planes and varying camera internal parameters. However, for simplicity, this papers will only discuss the case with one plane in several views. The results obtained with synthetic and real data are very accurate and stable even when using only few images.	INRIA, F-06902 Sophia Antipolis, France; Univ Cambridge, Cambridge CB2 1PZ, England	Inria; University of Cambridge	Malis, E (corresponding author), INRIA, 2004,Route Lucioles, F-06902 Sophia Antipolis, France.	ezio.malis@sophia.inria.fr	Arandjelović, Ognjen/V-5255-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla, Roberto/0000-0002-8999-2151				ABDELAZIZ YI, 1971, P ASP UI S CLOS RANG, P1; Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285; Faugeras O. D., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P15; HARTLEY R, 1994, P 3 EUR C COMP VIS, P471; HARTLEY RI, 1992, LECT NOTES COMPUT SC, V588, P579; Hartley RI, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P469, DOI 10.1109/ICCV.1998.710760; HARTLEY RI, 1994, LNCS SERIES, V825, P237; Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5; Heyden A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P339, DOI 10.1109/ICPR.1996.546045; Malis E, 2000, INT C PATT RECOG, P85, DOI 10.1109/ICPR.2000.905281; MALIS E, 2000, P EUR C COMP VIS, V2, P610; MALIS E, 2001, CAMERA SELF CALIBRAT; MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171; Mendelsohn J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P581, DOI 10.1109/CVPR.1999.784974; Mendonca P. R. S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P500, DOI 10.1109/CVPR.1999.786984; Moons T, 1996, IEEE T PATTERN ANAL, V18, P77, DOI 10.1109/34.476015; Pollefeys M, 1999, IEEE T PATTERN ANAL, V21, P707, DOI 10.1109/34.784285; Sturm P., 1999, P IEEE C COMP VIS PA, P432, DOI DOI 10.1109/CVPR.1999.786974; Szeliski R., 1998, 3D Structure from Multiple Images of Large-Scale Environments. European Workshop, SMILE'98. Proceedings, P171; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; Triggs B, 1996, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.1996.517170; TRIGGS B, 1998, P 5 EUR C COMP VIS, P89; ZELNIKMANOR L, 1999, P IEEE INT C COMP VI, V1, P710; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; [No title captured]	26	45	55	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2002	24	9					1268	1272		10.1109/TPAMI.2002.1033217	http://dx.doi.org/10.1109/TPAMI.2002.1033217			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	587KW		Green Submitted			2022-12-18	WOS:000177640500009
J	Song, JQ; Su, F; Tai, CL; Cai, SJ				Song, JQ; Su, F; Tai, CL; Cai, SJ			An object-oriented progressive-simplification-based vectorization system for engineering drawings: Model, algorithm, and performance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						vectorization; raster-to-vector; engineering drawing; object-oriented model and algorithm; graphics recognition; performance evaluation	UNDERSTANDING SYSTEM; ARC SEGMENTATION; LINE; IMAGES	Existing vectorization systems for engineering drawings usually take a two-phase workflow: convert a raster image to raw vectors and recognize graphic objects from the raw vectors. The first phase usually separates a ground truth graphic object that intersects or touches other graphic objects into several parts, thus, the second phase faces the difficulty of searching for and merging raw vectors belonging to the same object. These operations slow down vectorization and degrade the recognition quality. Imitating the way humans read engineering drawings, we propose an efficient one-phase object-oriented vectorization model that recognizes each class of graphic objects from their natural characteristics. Each ground truth graphic object is recognized directly in its entirety at the pixel level. The raster image is progressively simplified by erasing recognized graphic objects to eliminate their interference with subsequent recognition. To evaluate the performance of the proposed model, we present experimental results on real-life drawings and quantitative analysis using third party protocols. The evaluation results show significant improvement in speed and recognition rate.	Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China; Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Nanjing University; Hong Kong University of Science & Technology	Song, JQ (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.	songjq@ieee.org; suf@graphics.nju.edu.cn; taicl@cs.ust.hk; sjcai@netra.nju.edu.cn						AMIR I, 1990, COMPUT VISION GRAPH, V49, P398, DOI 10.1016/0734-189X(90)90112-9; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Chhabra AK, 1998, LECT NOTES COMPUT SC, V1389, P390; Chiang JY, 1998, PATTERN RECOGN, V31, P1541, DOI 10.1016/S0031-3203(97)00157-X; CLEMENT TP, 1981, PATTERN RECOGN, V14, P43, DOI 10.1016/0031-3203(81)90044-3; DATTA A, 1994, PATTERN RECOGN, V27, P1181, DOI 10.1016/0031-3203(94)90004-3; DenHartog JE, 1996, COMPUT VIS IMAGE UND, V63, P105, DOI 10.1006/cviu.1996.0007; Dori D, 1999, IEEE T PATTERN ANAL, V21, P202, DOI 10.1109/34.754586; Dori D, 1997, ADV ENG SOFTW, V28, P11, DOI 10.1016/S0965-9978(96)00035-X; DORI D, 1995, IEEE T PATTERN ANAL, V17, P1057, DOI 10.1109/34.473231; Dori D, 1999, IEEE T SYST MAN CY A, V29, P411, DOI 10.1109/3468.769761; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; HORI O, 1993, P INT DOC AN REC, P272; Janssen RDT, 1997, COMPUT VIS IMAGE UND, V65, P38, DOI 10.1006/cviu.1996.0484; Liu WY, 1998, LECT NOTES COMPUT SC, V1389, P9; Liu WY, 1997, MACH VISION APPL, V9, P240, DOI 10.1007/s001380050045; Liu WY, 1998, LECT NOTES COMPUT SC, V1389, P359; Liu WY, 1998, IEEE T PATTERN ANAL, V20, P424, DOI 10.1109/34.677280; Liu WY, 1998, COMPUT VIS IMAGE UND, V70, P420, DOI 10.1006/cviu.1998.0683; MOURA L, 1991, COMPUT PHYS COMMUN, V64, P57, DOI 10.1016/0010-4655(91)90049-Q; ROSEN S, 1995, CHINESE EDUC SOC, V28, P3, DOI 10.2753/CED1061-193228053; SONG J, 2000, P IEEE C COMP VIS PA, V2, P383; Song JQ, 2000, PATTERN ANAL APPL, V3, P142, DOI 10.1007/s100440070019; Tan Jianrong, 1994, Chinese Journal of Computers, V17, P561; Tombre K, 1998, LECT NOTES COMPUT SC, V1389, P257; WEI Y, 1990, P IEEE INT S GEOSC R, V2, P1190; ZOU R, 1997, J SOFTWARE S, V8, P404	28	45	53	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2002	24	8					1048	1060		10.1109/TPAMI.2002.1023802	http://dx.doi.org/10.1109/TPAMI.2002.1023802			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	578JY					2022-12-18	WOS:000177115100004
J	Ayala, G; Domingo, J				Ayala, G; Domingo, J			Spatial size distributions: Applications to shape and texture analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture analysis; shape analysis; size distribution; granulometry; geometric covariogram; spatial size distribution	CLASSIFICATION	This paper proposes new descriptors for binary and gray-scale images based on newly defined spatial size distributions (SSD). The main idea consists of combining a granulometric analysis of the image with a comparison between the geometric covariograms for binary images or the auto-correlation function for gray-scale images of the original image and its granulometric transformation; the usual granulometric size distribution then arises as a particular case of this formulation. Examples are given to show that in those cases in which a finer description of the image is required, the more complex descriptors generated from the SSD could be advantageously used. It is also shown that the new descriptors are probability distributions so their intuitive interpretation and properties can be appropriately studied from the probabilistic point of view. The usefulness of these descriptors in shape analysis is illustrated by some synthetic examples and their use in texture analysis is studied by doing an experiment of texture classification on a standard texture database. A comparison is perfomed among various cases of the SSD and several former methods for texture classification in terms of percentages of correct classification and the number of features used.	Univ Valencia, Dept Estadist & Invest Operat, E-46100 Burjassot, Spain; Univ Valencia, Dept Informat, E-46100 Burjassot, Spain	University of Valencia; University of Valencia	Ayala, G (corresponding author), Univ Valencia, Dept Estadist & Invest Operat, Dr Moliner 50, E-46100 Burjassot, Spain.	guillermo.ayala@uv.es; juan.domingo@uv.es	Domingo, Juan/AAA-2379-2019; Domingo, Juan/E-9709-2018; Ayala, Guillermo/A-8077-2008; Ayala, Guillermo/N-5766-2019	Domingo, Juan/0000-0003-4728-6256; Domingo, Juan/0000-0003-4728-6256; Ayala, Guillermo/0000-0002-6231-2865; Ayala, Guillermo/0000-0002-6231-2865				Asano A., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P209, DOI 10.1109/ICIAP.1999.797596; Aubert A, 2000, PATTERN RECOGN, V33, P1083, DOI 10.1016/S0031-3203(99)00166-1; Ayala G, 2001, PATTERN RECOGN, V34, P1219, DOI 10.1016/S0031-3203(00)00074-1; Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796; Baheerathan S, 1999, PATTERN RECOGN, V32, P605, DOI 10.1016/S0031-3203(98)00122-8; Billingsley P., 1995, WILEY SERIES PROBABI, V3rd; CHAUDHURI BB, 1993, IEE PROC-E, V140, P233, DOI 10.1049/ip-e.1993.0034; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; CHEN YD, 1994, OPT ENG, V33, P2713, DOI 10.1117/12.173552; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008; de Ves E, 1999, INT J COMPUT VISION, V34, P5, DOI 10.1023/A:1008164518969; Dougherty E. R., 1992, Journal of Mathematical Imaging and Vision, V1, P7, DOI 10.1007/BF00135222; DOUGHERTY ER, 1992, PATTERN RECOGN, V25, P1181, DOI 10.1016/0031-3203(92)90020-J; DOUGHERTY ER, 1989, P INT GEOSC REM SENS; DUBUF JMH, 1990, PATTERN RECOGN, V23, P291, DOI 10.1016/0031-3203(90)90017-F; FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594; Garcia P, 1999, COMPUT VIS IMAGE UND, V74, P227, DOI 10.1006/cviu.1999.0760; GARCIA P, 1999, THESIS JAUME I CASTE; Garcia-Sevilla P, 1999, IEEE T IMAGE PROCESS, V8, P1457, DOI 10.1109/83.791973; GHOSH P, 1998, P INT S COMP GRAPH I; Goutsias J., 2000, HDB MED IMAGING, V2, P175; GOUTSIAS J, 1997, RANDOM SETS THEORY A; Kaplan LM, 1999, IEEE T IMAGE PROCESS, V8, P1572, DOI 10.1109/83.799885; Karu K, 1996, PATTERN RECOGN, V29, P1437, DOI 10.1016/0031-3203(96)00004-0; KRZANOWSKI WJ, 1995, KENDALLS LIB STAT, V2; Lee YG, 1998, NEUROCOMPUTING, V20, P115, DOI 10.1016/S0925-2312(97)00095-7; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Matheron G., 1975, RANDOM SETS INTEGRAL; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Sabourin R, 1997, IEEE T PATTERN ANAL, V19, P976, DOI 10.1109/34.615447; Sand F, 1998, PATTERN RECOGN, V31, P53, DOI 10.1016/S0031-3203(97)00022-8; Seber G. A. F., 1984, MULTIVARIATE OBSERVA; Serra J., 1982, IMAGE ANAL MATH MORP; Sivakumar K, 1999, IEEE T PATTERN ANAL, V21, P99, DOI 10.1109/34.748817; Sivakumar K, 1997, J ELECTRON IMAGING, V6, P31, DOI 10.1117/12.261931; SIVAKUMAR K, 1997, RANDOM SETS THEORY A, P47; Smith G, 1997, PATTERN RECOGN LETT, V18, P1495, DOI 10.1016/S0167-8655(97)00132-3; Stoyan D., 1994, METHODS GEOMETRICAL; Tuceryan M., 1998, HDB PATTERN RECOGNIT, DOI [10.1142/9789814343138, DOI 10.1142/9789814343138]; VINCENT L, 1999, STOCHASTIC GEOMETRY, pCH6	41	45	49	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2001	23	12					1430	1442		10.1109/34.977566	http://dx.doi.org/10.1109/34.977566			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	500NY					2022-12-18	WOS:000172634700008
J	Chen, HC; Schatz, B; Ng, T; Martinez, J; Kirchhoff, A; Lin, CT				Chen, HC; Schatz, B; Ng, T; Martinez, J; Kirchhoff, A; Lin, CT			A parallel computing approach to creating engineering concept spaces for semantic retrieval: The Illinois Digital Library Initiative project	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						semantic retrieval; concept space; concept association; parallel computing; digital library	INFORMATION-RETRIEVAL; DOCUMENT-RETRIEVAL; CONNECTION MACHINE; NEURAL NETWORKS; SYSTEMS; SEARCH; PERFORMANCE; DATABASES; DESIGN; MODEL	This research presents preliminary results generated from the semantic retrieval research component of the illinois Digital Library Initiative (DLI) project. Using a variation of the automatic thesaurus generation techniques, to which we refer as the concept space approach, we aimed to create graphs of domain-specific concepts (terms) and their weighted co-occurrence relationships for all major engineering domains. Merging these concept spaces and providing traversal paths across:different concept spaces could potentially help alleviate the vocabulary (difference) problem evident in large-scale information retrieval. We have experimented previously with such a technique for a smaller molecular biology domain (Worm Community System, with 10+ MBs of document collection) with encouraging results. In order to address the scalability issue related to large-scale information retrieval and analysis for the current Illinois DLI project, we recently conducted experiments using the concept space approach on parallel supercomputers. Our test collection included 2+ GBs of computer science and electrical engineering abstracts extracted from the INSPEC database. The concept space approach called for extensive textual and statistical analysis (a form of knowledge discovery) based on automatic indexing and cooccurrence analysis algorithms, both previously tested in the biology domain. Initial testing results using a 512-node CM-5 and a 16-processor SGI Power Challenge were promising. Power Challenge was later selected to create a comprehensive computer engineering concept space of about 270,000 terms and 4,000,000+ links using 24.5 hours of CPU time. Our system evaluation involving 12 knowledgeable subjects revealed that the automatically-created computer engineering concept space generated significantly higher concept recall than the human-generated INSPEC computer engineering thesaurus. However, the INSPEC was more precise than the automatic concept space. Our current work mainly involves creating concept spaces for other major engineering domains and developing robust graph matching and traversal algorithms for cross-domain, concept-based retrieval. Future work also will include generating individualized concept spaces for assisting user-specific concept-based information retrieval.	UNIV ILLINOIS,NATL CTR SUPERCOMP APPLICAT,BECKMAN INST,URBANA,IL 61801; UNIV ARIZONA,SCI & ENGN LIB,TUCSON,AZ 85712; UNIV ARIZONA,DEPT LIB & INFORMAT STUDIES,TUCSON,AZ 85712	University of Illinois System; University of Illinois Urbana-Champaign; University of Arizona; University of Arizona	Chen, HC (corresponding author), UNIV ARIZONA,KARL ELLER GRAD SCH MANAGEMENT,MIS DEPT,MCCLELLAND HALL,TUCSON,AZ 85721, USA.							AHLSWEDE T, 1988, INT J LEXICOGR, V1, P214; Anderson John R., 1985, COGNITIVE PSYCHOL IT; ANDERSON JR, 1985, INFORMATION BEHAV, V1; BATES MJ, 1986, J AM SOC INFORM SCI, V37, P357; BELKIN NJ, 1982, J DOC, V38, P61, DOI 10.1108/eb026722; Card SK, 1983, PSYCHOL HUMAN COMPUT; CHEN H, 1995, J AM SOC INFORM SCI, V46, P348, DOI 10.1002/(SICI)1097-4571(199506)46:5<348::AID-ASI6>3.0.CO;2-1; CHEN H, IN PRESS J AM SOC IN; CHEN H, 1987, 6TH P NAT C ART INT, P285; CHEN HC, 1991, INFORM PROCESS MANAG, V27, P405, DOI 10.1016/0306-4573(91)90060-Y; CHEN HC, 1993, IEEE EXPERT, V8, P25, DOI 10.1109/64.207426; CHEN HC, 1992, IEEE T SYST MAN CYB, V22, P885, DOI 10.1109/21.179830; CHEN HC, 1995, J AM SOC INFORM SCI, V46, P194, DOI 10.1002/(SICI)1097-4571(199504)46:3<194::AID-ASI4>3.0.CO;2-S; CHEN HC, 1995, J AM SOC INFORM SCI, V46, P175, DOI 10.1002/(SICI)1097-4571(199504)46:3<175::AID-ASI3>3.0.CO;2-U; COUVREUR TR, 1994, J AM SOC INFORM SCI, V45, P443, DOI 10.1002/(SICI)1097-4571(199408)45:7<443::AID-ASI1>3.0.CO;2-O; CROFT WB, 1990, 13TH P INT C RES DEV, P349; CROUCH CJ, 1992, P 15 ANN INT ACM SIG, P77; DOYLE LB, 1962, AM DOC, V13, P378, DOI 10.1002/asi.5090130404; DUMAIS ST, 1994, P 2 TEXT RETR C TREC, P105; Fox E. A., 1988, Second Conference on Applied Natural Language Processing, P101; FRIEDER O, 1991, 14TH P ACM SIGIR, P230; FURNAS GW, 1987, COMMUN ACM, V30, P964, DOI 10.1145/32206.32212; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; KIM YW, 1990, J DOC, V46, P113, DOI 10.1108/eb026857; Lancaster F. W., 1986, VOCABULARY CONTROL I; LESK ME, 1969, AM DOC, V20, P27, DOI 10.1002/asi.4630200106; Lindberg D. A. B., 1990, Fourteenth Annual Symposium on Computer Applications in Medical Care. Standards in Medical Informatics. A Conference of the American Medical Informatics Association, P121; MARON ME, 1960, J ACM, V7, P216, DOI 10.1145/321033.321035; ODDY RN, 1991, INFORM PROCESS MANAG, V27, P317, DOI 10.1016/0306-4573(91)90087-3; PEAT HJ, 1991, J AM SOC INFORM SCI, V42, P378, DOI 10.1002/(SICI)1097-4571(199106)42:5<378::AID-ASI8>3.0.CO;2-8; POOL R, 1995, SCIENCE, V269, P1359, DOI 10.1126/science.269.5229.1359; RASMUSSEN E, 1992, INFORMATION RETRIEVA; RASMUSSEN EM, 1991, INFORM PROCESS MANAG, V27, P255, DOI 10.1016/0306-4573(91)90083-X; SALTON G, 1988, COMMUN ACM, V31, P202, DOI 10.1145/42372.42380; Salton G., 1989, AUTOMATIC TEXT PROCE; SCHATZ BR, 1994, SCIENCE, V265, P895, DOI 10.1126/science.265.5174.895; STANFILL C, 1991, INFORM PROCESS MANAG, V27, P285, DOI 10.1016/0306-4573(91)90085-Z; STILES HE, 1961, J ACM, V8, P271, DOI 10.1145/321062.321074; THOMBORSON CD, 1993, COMMUN ACM, V36, P41, DOI 10.1145/163359.163363; WAH BW, 1993, IEEE T KNOWL DATA EN, V5, P138, DOI 10.1109/69.204098; YANG J, 1993, P 2 ANN S DOC AN INF, P271	41	45	53	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1996	18	8					771	782		10.1109/34.531798	http://dx.doi.org/10.1109/34.531798			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	VE318					2022-12-18	WOS:A1996VE31800002
J	Healey, G; Jain, H				Healey, G; Jain, H			Retrieving multispectral satellite images using physics-based invariant representations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image database; image retrieval; color constancy; satellite images; color; machine vision; texture; computer vision; recognition	RECOGNITION	We present a set of algorithms and a search strategy for the robust content-based retrieval of multispectral satellite images. Since the property of interest in these images is usually the physical characteristics of ground cover, we use representations and methods that are invariant to illumination and atmospheric conditions. The representations and algorithms are derived for this application from a physical model for the formation of multispectral satellite images. The use of several representations and algorithms is necessary to interpret the diversity of physical and geometric structure in these images. Algorithms are used that exploit multispectral distributions, multispectral spatial structure, and labeled classes. The performance of the system is demonstrated on a large set of multispectral satellite images taken over different areas of the United States under different illumination and atmospheric conditions.			Healey, G (corresponding author), UNIV CALIF IRVINE, DEPT ELECT & COMP ENGN, IRVINE, CA 92717 USA.							BACH JR, 1993, IEEE T KNOWL DATA EN, V5, P619, DOI 10.1109/69.234774; BELL TE, 1995, IEEE SPECTRUM    MAR, P24; COHEN J, 1964, PSYCHON SCI, V1, P369, DOI 10.3758/BF03342963; GATES D, 1965, APPL OPTICS, V4; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; HEALEY G, 1995, J OPT SOC AM A, V12, P1877, DOI 10.1364/JOSAA.12.001877; HEALEY G, 1994, J OPT SOC AM A, V11, P3003, DOI 10.1364/JOSAA.11.003003; KONDEPUDY R, 1994, J OPT SOC AM A, V11, P3037, DOI 10.1364/JOSAA.11.003037; MALONEY LT, 1986, J OPT SOC AM A, V3, P1673, DOI 10.1364/JOSAA.3.001673; PARKKINEN JPS, 1989, J OPT SOC AM A, V6, P318, DOI 10.1364/JOSAA.6.000318; Pentland A., 1994, SPIE STORAGE RETRIEV, P34; PETKOVIC D, 1994, J INTELLIGENT INFORM; PICARD RW, 1995, MULTIMEDIA SYST, V3, P3, DOI 10.1007/BF01236575; Slater D, 1996, IEEE T PATTERN ANAL, V18, P206, DOI 10.1109/34.481544; Smoliar S. W., 1994, IEEE Multimedia, V1, P62, DOI 10.1109/93.311653; TAUBIN G, 1992, ARTIF INT, P375; WOODHAM RJ, 1987, IEEE T GEOSCI REMOTE, V25, P258, DOI 10.1109/TGRS.1987.289798	17	45	46	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1996	18	8					842	848		10.1109/34.531804	http://dx.doi.org/10.1109/34.531804			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VE318					2022-12-18	WOS:A1996VE31800008
J	Parodi, P; Piccioli, G				Parodi, P; Piccioli, G			3D shape reconstruction by using vanishing points	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						reconstruction of 3D shape; vanishing point; line drawing; incidence structure; spatial structure; labeling; realizability	PERSPECTIVE IMAGES; INDOOR; SCENES	This paper investigates the quantitative reconstruction of the 3D structure of a scene from a line drawing, by using the geometrical constraints provided by the location of vanishing points. The additional information on vanishing points allows the design of an algorithm which has several advantages with respect to the usual approach based on a reduction to Linear Programming (Sugihara, 1982). These advantages range from a lower computational complexity to error tolerance and exact reconstruction of the 3D-geometry of the objects. These features make the algorithm a useful tool for the quantitative analysis of real-world images, which is useful for several tasks from scene understanding to automatic vehicle guidance.			Parodi, P (corresponding author), UNIV GENOA,DEPT PHYS,VIA DODECANESO 33,I-16146 GENOA,ITALY.							BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; BRILLAULTOMAHONY B, 1991, CVGIP-IMAG UNDERSTAN, V54, P289, DOI 10.1016/1049-9660(91)90069-2; CAMPANI M, 1993, P INT VEH S TOK JAP, P107; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P199; Caprile B., 1990, INT J COMPUTER VISIO; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; DENDRIS N, 1994, UNPUB PARALLEL ALGOR; DOBKIN D, 1979, INFORMATION PROCESSI, V9, P96; GATTI M, 1992, 2 INT WORKSH ROB COM, P401; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; Jaja J, 1992, INTRO PARALLEL ALGOR; KADONO K, 1991, P IEEE WORKSH DIR AU, P186; KANADE T, 1980, ARTIF INTELL, V13, P279, DOI 10.1016/0004-3702(80)90004-1; KANADE T, 1993, ARTIF INTELL, V59, P95, DOI 10.1016/0004-3702(93)90175-B; Karp R.M., 1990, HDB THEORETICAL COMP, P869; KIROUSIS LM, 1988, J COMPUT SYST SCI, V37, P14, DOI 10.1016/0022-0000(88)90043-8; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; MAGEE MJ, 1984, COMPUT VISION GRAPH, V26, P256, DOI 10.1016/0734-189X(84)90188-9; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; Nakatani H., 1981, Transactions of the Institute of Electronics and Communication Engineers of Japan, Section E (English), VE64, P357; PARODI A, 1993, AS C COMP VIS ACCV 9, P446; PARODI P, 1994, ARTIF INTELL, V70, P239, DOI 10.1016/0004-3702(94)90107-4; PARODI P, IN PRESS INT J COMPU; QUAN L, 1989, PATTERN RECOGN LETT, V9, P279, DOI 10.1016/0167-8655(89)90006-8; STRAFORINI M, 1993, IMAGE VISION COMPUT, V11, P91, DOI 10.1016/0262-8856(93)90075-R; STRAFORINI M, 1992, IEEE T PATTERN ANAL, V14, P298, DOI 10.1109/34.121797; SUGIHARA K, 1984, IEEE T PATTERN ANAL, V6, P578, DOI 10.1109/TPAMI.1984.4767571; WALTZ D, 1971, ARTIF INTELL, V2, P79	29	45	45	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1996	18	2					211	217		10.1109/34.481545	http://dx.doi.org/10.1109/34.481545			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TV669					2022-12-18	WOS:A1996TV66900011
J	ULUPINAR, F; NEVATIA, R				ULUPINAR, F; NEVATIA, R			SHAPE FROM CONTOUR - STRAIGHT HOMOGENEOUS GENERALIZED CYLINDERS AND CONSTANT CROSS-SECTION GENERALIZED CYLINDERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SHAPE FROM CONTOUR; STRAIGHT HOMOGENEOUS GENERALIZED CONES; CONSTANT CROSS SECTION GENERALIZED CONES; SYMMETRY ANALYSIS; SHAPE CONSTRAINTS	SURFACES	We analyze the properties of Straight Homogeneous Generalized Cylinders (SHGCs) and Constant Cross Section Generalized Cylinders (CGCs), and derive the types of symmetries that the limb boundaries and cross sections of these objects produce on the image plane. The constraints on the 3D shape of the objects are formulated based on the symmetries and from the geometry of the projection models. Finally, the methods that recover the 3D shape from the image of their contours are discussed and recovered surfaces are shown for sample objects.	UNIV SO CALIF,SCH ENGN,INST ROBOT & INTELLIGENT SYST,LOS ANGELES,CA 90089	University of Southern California	ULUPINAR, F (corresponding author), ADV COMP SYST CO,TECH STAFF,3000 S ROBERTSON BLVD,LOS ANGELES,CA 90034, USA.							BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BINFORD TO, 1971, DEC IEEE C SYST CONT; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; GROSS A, 1990, P IMAGE UNDERSTANDIN, P573; HORAUD R, 1988, ARTIF INTELL, V37, P333, DOI 10.1016/0004-3702(88)90059-8; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; Kanade T., 1983, HUMAN MACHINE VISION, P237; KASHIPATI R, 1988, THESIS U SO CALIF; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; MOHAN R, 1989, JUN P IEEE C COMP VI, P333; NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; PONCE J, 1987, INT J COMPUT VISION, V1, P195, DOI 10.1007/BF00127820; SAINTMARC P, 1990, 1ST EUR C COMP VIS A, P64; SHAFER SA, 1983, COMPUT VISION GRAPH, V24, P182, DOI 10.1016/0734-189X(83)90042-7; SHAFER SA, 1983, CS83131 CARN MELL U; SHAFER SA, 1983, CS083105 CARN MELL U; STEVENS KA, 1981, ARTIF INTELL, V17, P47, DOI 10.1016/0004-3702(81)90020-5; ULUPINAR F, 1993, IEEE T PATTERN ANAL, V15, P3, DOI 10.1109/34.184771; ULUPINAR F, 1991, P COMPUTER VISION PA; ULUPINAR F, 1990, 3RD P ICCV; ULUPINAR F, 1990, 10TH P INT C PATT RE, P147; WEISS I, 1988, COMPUT VISION GRAPH, V41, P80, DOI 10.1016/0734-189X(88)90118-1; XU G, 1987, 1ST P ICCV LOND, P716; Zerroug M., 1993, P DARPA IM UND WORKS, P905	29	45	48	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					120	135		10.1109/34.368175	http://dx.doi.org/10.1109/34.368175			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825					2022-12-18	WOS:A1995QE82500003
J	DUNCAN, JH; CHOU, TC				DUNCAN, JH; CHOU, TC			ON THE DETECTION OF MOTION AND THE COMPUTATION OF OPTICAL-FLOW	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MOTION DETECTION; OPTICAL FLOW; TEMPORALLY VARYING IMAGE SEQUENCES		A method for the detection of motion in image sequences is presented. In this method, the intensity history at each pixel is convolved with the second derivative in time of a temporal Gaussian smoothing function. The zero crossings in a single frame of the resulting function indicate the positions of moving edges. Intensity changes in time due to illumination effects do not produce zero crossings; thus, they are not interpreted as motion by the present method. It is also shown that the spatial and temporal derivatives of this function can be used to compute the component of the optical flow that is normal to the zero-crossing contours. This computation is also insensitive to nonconvective temporal and spatial variations in the image intensity that are caused by illumination effects.	UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	DUNCAN, JH (corresponding author), UNIV MARYLAND,DEPT MECH ENGN,COLLEGE PK,MD 20742, USA.		Duncan, James H/FVY-7148-2022	Duncan, James H/0000-0003-3740-9881				Buxton B. F., 1984, Image and Vision Computing, V2, P59, DOI 10.1016/0262-8856(84)90001-5; BUXTON BF, 1983, PROC R SOC SER B-BIO, V218, P27, DOI 10.1098/rspb.1983.0024; Duncan J. H., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P374, DOI 10.1109/CCV.1988.590014; DUNCAN JH, 1988, CARTR362 U MARYL CEN; HAYNES SM, 1983, COMPUT VISION GRAPH, V21, P345, DOI 10.1016/S0734-189X(83)80048-6; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JAIN AR, 1979, IEEE T PATTERN ANAL, V1, P206; JAIN R, 1979, COMPUT VISION GRAPH, V11, P13, DOI 10.1016/0146-664X(79)90074-1; MARR D, 1981, PROC R SOC SER B-BIO, V211, P151, DOI 10.1098/rspb.1981.0001; NG EW, 1969, J RES NBS B MATH SCI, V73, P1, DOI 10.6028/jres.073B.001; WAXMAN AM, 1987, LSRTR4 BOST U COLL E	11	45	49	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1992	14	3					346	352		10.1109/34.120329	http://dx.doi.org/10.1109/34.120329			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HF732					2022-12-18	WOS:A1992HF73200004
J	ZHUANG, XH; WANG, T; ZHANG, P				ZHUANG, XH; WANG, T; ZHANG, P			A HIGHLY ROBUST ESTIMATOR THROUGH PARTIALLY LIKELIHOOD FUNCTION MODELING AND ITS APPLICATION IN COMPUTER VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AUTOMATIC THRESHOLDING; CONTAMINATED GAUSSIAN MIXTURES; CONTAMINATED GAUSSIANS; GENERAL REGRESSION; HIGHLY ROBUST ESTIMATOR; MULTIPLE RIGID MOTION SEGMENTATION AND ESTIMATION; PARTIAL MODELING	3-DIMENSIONAL MOTION; MOVING-OBJECTS; ALGORITHM	This article presents a highly robust estimator, known as the MF estimator for general regression, where "MF" represents an abbreviation of "model fitting." In this paper, we explain that high robustness becomes possible through partially but completely modeling the unknown log likelihood function. The partial modeling takes place by taking the Bayesian statistical decision rule and a number of important heuristics altogether into consideration while maximizing the log likelihood function. Application topics include the automatic selection of multiple thresholds, the single rigid motion estimation or the multiple rigid motion segmentation, and estimation from two perspective views. We believe that the proposed MF estimator will pave a solid road towards solving many robust estimation problems that demand an estimator that is either highly robust or capable of handling contaminated Gaussian mixture models.	ZHEJIANG UNIV, DEPT COMP SCI & ENGN, COMP VIS LAB, HANGZHOU, PEOPLES R CHINA; UNIV WASHINGTON, DEPT ELECT ENGN, SEATTLE, WA 98195 USA	Zhejiang University; University of Washington; University of Washington Seattle	ZHUANG, XH (corresponding author), UNIV MISSOURI, DEPT ELECT & COMP ENGN, COLUMBIA, MO 65201 USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ALOIMONOS J, 1986, JUN P IEEE C COMP VI, P510; [Anonymous], 1959, PHOTOGRAMM REC; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GEMAN S, 1984, NOV IEEE T PATT ANAL, V6; HARALICK RM, 1986, COMPUT VISION GRAPH, V36, P372, DOI 10.1016/0734-189X(86)90082-4; HARALICK RM, 1989, IEEE T SYST MAN  AUG; HINTON GE, 1983, P IEEE C COMPUT VISI; HUANG TS, 1989, MACHINE VISION INSPE; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; Li G., 1985, EXPLORING DATA TABLE, P281; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ZHUANG X, 1989, COMPUT VISION GRAPH, V46, P175, DOI 10.1016/0734-189X(89)90167-9; ZHUANG X, 1988, IEEE J ROBOTICS AUTO, V4; ZHUANG XH, 1986, J OPT SOC AM A, V3, P1492, DOI 10.1364/JOSAA.3.001492	23	45	49	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1992	14	1					19	35		10.1109/34.107011	http://dx.doi.org/10.1109/34.107011			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GV942					2022-12-18	WOS:A1992GV94200002
J	Li, MS; Chen, SH; Chen, X; Zhang, Y; Wang, YF; Tian, Q				Li, Maosen; Chen, Siheng; Chen, Xu; Zhang, Ya; Wang, Yanfeng; Tian, Qi			Symbiotic Graph Neural Networks for 3D Skeleton-Based Human Action Recognition and Motion Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Three-dimensional displays; Magnetic heads; Joints; Convolution; Task analysis; Symbiosis; 3D skeleton-based action recognition; motion prediction; multiscale graph convolution networks; graph inference		3D skeleton-based action recognition and motion prediction are two essential problems of human activity understanding. In many previous works: 1) they studied two tasks separately, neglecting internal correlations; and 2) they did not capture sufficient relations inside the body. To address these issues, we propose a symbiotic model to handle two tasks jointly; and we propose two scales of graphs to explicitly capture relations among body-joints and body-parts. Together, we propose symbiotic graph neural networks, which contain a backbone, an action-recognition head, and a motion-prediction head. Two heads are trained jointly and enhance each other. For the backbone, we propose multi-branch multiscale graph convolution networks to extract spatial and temporal features. The multiscale graph convolution networks are based on joint-scale and part-scale graphs. The joint-scale graphs contain actional graphs, capturing action-based relations, and structural graphs, capturing physical constraints. The part-scale graphs integrate body-joints to form specific parts, representing high-level relations. Moreover, dual bone-based graphs and networks are proposed to learn complementary features. We conduct extensive experiments for skeleton-based action recognition and motion prediction with four datasets, NTU-RGB+D, Kinetics, Human3.6M, and CMU Mocap. Experiments show that our symbiotic graph neural networks achieve better performances on both tasks compared to the state-of-the-art methods.	[Li, Maosen; Chen, Siheng; Chen, Xu; Zhang, Ya; Wang, Yanfeng] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai, Peoples R China; [Li, Maosen; Chen, Siheng; Chen, Xu; Zhang, Ya; Wang, Yanfeng] Shanghai Jiao Tong Univ, Shanghai Key Lab Multimedia Proc & Transmiss, Shanghai, Peoples R China; [Tian, Qi] Huawei Cloud & Al, Shenzhen 518129, Peoples R China; [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA	Shanghai Jiao Tong University; Shanghai Jiao Tong University; University of Texas System; University of Texas at San Antonio (UTSA)	Li, MS (corresponding author), Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai, Peoples R China.; Li, MS (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Lab Multimedia Proc & Transmiss, Shanghai, Peoples R China.	maosen_li@sjtu.edu.cn; sihengc@sjtu.edu.cn; xuchen2016@sjtu.edu.cn; ya_zhang@sjtu.edu.cn; wangyanfeng@sjtu.edu.cn; wywqtian@gmail.com		Chen, Xu/0000-0001-5299-7074; cui, Xingchao/0000-0002-1103-0702; Li, Mingdian/0000-0002-4507-3233; Chen, Si-Wei/0000-0001-8713-7664	National Key Research and Development Program of China [2019YFB1804304]; SHEITC [2018-RGZN-02046]; 111 plan [BP0719010]; STCSM [18DZ2270700]; State Key Laboratory of UHD Video and Audio Production and Presentation	National Key Research and Development Program of China; SHEITC; 111 plan; STCSM(Science & Technology Commission of Shanghai Municipality (STCSM)); State Key Laboratory of UHD Video and Audio Production and Presentation	This work was supported by the National Key Research and Development Program of China (No. 2019YFB1804304), SHEITC (No. 2018-RGZN-02046), 111 plan (No. BP0719010), and STCSM (No. 18DZ2270700), and State Key Laboratory of UHD Video and Audio Production and Presentation. Parts of this paper appear in [1]. This work was done when S. Chen was working at Mitsubishi Electric Research Laboratories (MERL).	Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Chen SH, 2018, IEEE T SIGNAL PROCES, V66, P666, DOI 10.1109/TSP.2017.2771730; Chiu HK, 2019, IEEE WINT CONF APPL, P1423, DOI 10.1109/WACV.2019.00156; Cho K, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P122; Defferrard M, 2016, ADV NEUR IN, V29; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494; Gao X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P601, DOI 10.1145/3343031.3351170; Gaur U, 2011, IEEE I CONF COMP VIS, P2595, DOI 10.1109/ICCV.2011.6126548; Ghosh P, 2017, INT CONF 3D VISION, P458, DOI 10.1109/3DV.2017.00059; Gopalakrishnan A, 2019, PROC CVPR IEEE, P12108, DOI 10.1109/CVPR.2019.01239; Gui LY, 2018, LECT NOTES COMPUT SC, V11212, P441, DOI 10.1007/978-3-030-01237-3_27; Gui LY, 2018, LECT NOTES COMPUT SC, V11208, P823, DOI 10.1007/978-3-030-01225-0_48; Gui LY, 2018, IEEE INT C INT ROBOT, P562, DOI 10.1109/IROS.2018.8594452; Guo X, 2019, AAAI CONF ARTIF INTE, P2580; Hamilton WL, 2017, ADV NEUR IN, V30; Hu G, 2019, IEEE INT CON MULTI, P1216, DOI 10.1109/ICME.2019.00212; Huang DA, 2014, LECT NOTES COMPUT SC, V8695, P489, DOI 10.1007/978-3-319-10584-0_32; Huang ZW, 2017, PROC CVPR IEEE, P1243, DOI 10.1109/CVPR.2017.137; Hussein Mohamed E, 2013, 23 INT JOINT C ART I; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573; Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207; Kipf T. N., 2017, INT C LEARN REPR, DOI [DOI 10.1109/ICDM.2008.17, DOI 10.1109/ICDM.2019.00070]; Kundu JN, 2019, AAAI CONF ARTIF INTE, P8553; Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115; Lehrmann AM, 2014, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2014.171; Li B, 2019, AAAI CONF ARTIF INTE, P8561; Li C, 2018, IEEE INT CONF SENS, P1, DOI 10.1109/TFUZZ.2018.2878200; Li C, 2018, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2018.00548; Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371; Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030; Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497; Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154; Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007; Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76; Pavlovic V, 2001, PROC INT C NEURAL IN, P942; Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115; Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810; Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230; Shi YG, 2018, LECT NOTES COMPUT SC, V11214, P305, DOI 10.1007/978-3-030-01249-6_19; Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132; Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7; Song YF, 2019, IEEE IMAGE PROC, P1, DOI 10.1109/ICIP.2019.8802917; Sui YL, 2013, INT SYM CODE GENER, P1; Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558; Thakkar K., 2018, ARXIV180904983; Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275; Walker J, 2017, IEEE I CONF COMP VIS, P3352, DOI 10.1109/ICCV.2017.361; Wang D., 2018, P EUR C COMP VIS, P451; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wen YH, 2019, AAAI CONF ARTIF INTE, P8989; Weng JW, 2017, PROC CVPR IEEE, P445, DOI 10.1109/CVPR.2017.55; Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351; Xue Tianfan, 2016, ADV NEURAL INFORM PR, P2; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444; Zhang XK, 2020, IEEE T NEUR NET LEAR, V31, P3047, DOI 10.1109/TNNLS.2019.2935173	65	44	44	65	97	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3316	3333		10.1109/TPAMI.2021.3053765	http://dx.doi.org/10.1109/TPAMI.2021.3053765			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33481706	Green Submitted			2022-12-18	WOS:000803117500038
J	Yi, P; Wang, ZY; Jiang, K; Jiang, JJ; Lu, T; Ma, JY				Yi, Peng; Wang, Zhongyuan; Jiang, Kui; Jiang, Junjun; Lu, Tao; Ma, Jiayi			A Progressive Fusion Generative Adversarial Network for Realistic and Consistent Video Super-Resolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Convolution; Three-dimensional displays; Image reconstruction; Gallium nitride; Neural networks; Generative adversarial networks; Convolutional neural network; video super-resolution; spatio-temporal correlation; progressive fusion; generative adversarial network	IMAGE SUPERRESOLUTION	How to effectively fuse temporal information from consecutive frames remains to be a non-trivial problem in video super-resolution (SR), since most existing fusion strategies (direct fusion, slow fusion, or 3D convolution) either fail to make full use of temporal information or cost too much calculation. To this end, we propose a novel progressive fusion network for video SR, in which frames are processed in a way of progressive separation and fusion for the thorough utilization of spatio-temporal information. We particularly incorporate multi-scale structure and hybrid convolutions into the network to capture a wide range of dependencies. We further propose a non-local operation to extract long-range spatio-temporal correlations directly, taking place of traditional motion estimation and motion compensation (ME&MC). This design relieves the complicated ME&MC algorithms, but enjoys better performance than various ME&MC schemes. Finally, we improve generative adversarial training for video SR to avoid temporal artifacts such as flickering and ghosting. In particular, we propose a frame variation loss with a single-sequence training method to generate more realistic and temporally consistent videos. Extensive experiments on public datasets show the superiority of our method over state-of-the-art methods in terms of performance and complexity. Our code is available at https://github.com/psychopa4/MSHPFNL.	[Yi, Peng; Wang, Zhongyuan; Jiang, Kui] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan 430072, Peoples R China; [Jiang, Junjun] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China; [Jiang, Junjun] Peng Cheng Lab, Shenzhen 518066, Peoples R China; [Lu, Tao] Wuhan Inst Technol, Sch Comp Sci & Engn, Wuhan 430205, Peoples R China; [Ma, Jiayi] Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China	Wuhan University; Harbin Institute of Technology; Peng Cheng Laboratory; Wuhan Institute of Technology; Wuhan University	Wang, ZY (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan 430072, Peoples R China.	yipeng@whu.edu.cn; wzy_hope@163.com; kuijiang@whu.edu.cn; junjun0595@163.com; lutxyl@gmail.com; jyma2010@gmail.com		Jiang, Kui/0000-0002-4055-7503	National Key RD Project [2016YFE0202300]; National Natural Science Foundation of China [61671332, U1903214, U1736206, 62071339, 62072350, 62072347, 61971165, 61773295]; Hubei Province Technological Innovation Major Project [2019AAA049, 2019AAA045]	National Key RD Project; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Hubei Province Technological Innovation Major Project	This work was supported by the National Key R&D Project (2016YFE0202300), National Natural Science Foundation of China (61671332, U1903214, U1736206, 62071339, 62072350, 62072347, 61971165, and 61773295), and Hubei Province Technological Innovation Major Project (2019AAA049, and 2019AAA045).	Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bao WB, 2021, IEEE T PATTERN ANAL, V43, P933, DOI 10.1109/TPAMI.2019.2941941; Belekos SP, 2010, IEEE T IMAGE PROCESS, V19, P1451, DOI 10.1109/TIP.2010.2042115; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669; Haris M, 2019, PROC CVPR IEEE, P3892, DOI 10.1109/CVPR.2019.00402; Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Huang Gao, 2018, ICLR; Huang Y., 2015, P ADV NEURAL INFORM, V28, P235; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Isobe Takashi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8005, DOI 10.1109/CVPR42600.2020.00803; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jiang K, 2019, IEEE T GEOSCI REMOTE, V57, P5799, DOI 10.1109/TGRS.2019.2902431; Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Jolicoeur-Martineau A., 2019, 7 INT C LEARN REPR I; Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kingma D.P, P 3 INT C LEARNING R; Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837; Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li DY, 2017, IEEE T COMPUT IMAG, V3, P749, DOI 10.1109/TCI.2017.2671360; Liao RJ, 2015, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2015.68; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Liu D, 2017, IEEE I CONF COMP VIS, P2526, DOI 10.1109/ICCV.2017.274; Liu XM, 2011, IEEE T IMAGE PROCESS, V20, P3455, DOI 10.1109/TIP.2011.2150234; Lucas A, 2019, IEEE T IMAGE PROCESS, V28, P3312, DOI 10.1109/TIP.2019.2895768; Ma JY, 2020, IEEE T IND ELECTRON, V67, P5687, DOI 10.1109/TIE.2019.2934071; Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590; Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693; Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467; Shao ZF, 2019, IEEE J-STARS, V12, P2663, DOI 10.1109/JSTARS.2019.2925456; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479; Tian YP, 2020, PROC CVPR IEEE, P3357, DOI 10.1109/CVPR42600.2020.00342; Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149; Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514; Vaswani A., 2017, ADV NEURAL INFORM PR, V30; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002; Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang ZY, 2019, IEEE T IMAGE PROCESS, V28, P2530, DOI 10.1109/TIP.2018.2887017; Xingjian S., 2015, ADV NEURAL INFORM PR, P802, DOI DOI 10.1007/978-3-319-21233-3_6; Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yi P, 2019, IEEE I CONF COMP VIS, P3106, DOI 10.1109/ICCV.2019.00320; Yi P, 2020, IEEE T CIRC SYST VID, V30, P2503, DOI 10.1109/TCSVT.2019.2925844; Yu F., MULTISCALE CONTEXT A; Yu X, 2020, IEEE T PATTERN ANAL, V42, P2926, DOI 10.1109/TPAMI.2019.2916881; Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344; Zhang WL, 2019, IEEE I CONF COMP VIS, P3096, DOI 10.1109/ICCV.2019.00319; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zhang Yulun, 2018, P EUROPEAN C COMPUTE, P286; Zhang Yulun, 2019, ARXIV190310082; Zhang ZD, 2019, IEEE T IMAGE PROCESS, V28, P1625, DOI 10.1109/TIP.2018.2877483; Zhou LG, 2019, IEEE T NEUR NET LEAR, V30, P3275, DOI 10.1109/TNNLS.2018.2890550	70	44	44	20	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2264	2280		10.1109/TPAMI.2020.3042298	http://dx.doi.org/10.1109/TPAMI.2020.3042298			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33270559				2022-12-18	WOS:000792921400006
J	Lu, XK; Wang, WG; Shen, JB; Crandall, D; Luo, JB				Lu, Xiankai; Wang, Wenguan; Shen, Jianbing; Crandall, David; Luo, Jiebo			Zero-Shot Video Object Segmentation With Co-Attention Siamese Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Correlation; Object segmentation; Motion segmentation; Computational modeling; Visualization; Inference algorithms; Zero-shot video object segmentation; differentiable co-attention mechanism; siamese network		We introduce a novel network, called CO-attention siamese network (COSNet), to address the zero-shot video object segmentation task in a holistic fashion. We exploit the inherent correlation among video frames and incorporate a global co-attention mechanism to further improve the state-of-the-art deep learning based solutions that primarily focus on learning discriminative foreground representations over appearance and motion in short-term temporal segments. The co-attention layers in COSNet provide efficient and competent stages for capturing global correlations and scene context by jointly computing and appending co-attention responses into a joint feature space. COSNet is a unified and end-to-end trainable framework where different co-attention variants can be derived for capturing diverse properties of the learned joint feature space. We train COSNet with pairs (or groups) of video frames, and this naturally augments training data and allows increased learning capacity. During the segmentation stage, the co-attention model encodes useful information by processing multiple reference frames together, which is leveraged to infer the frequently reappearing and salient foreground objects better. Our extensive experiments over three large benchmarks demonstrate that COSNet outperforms the current alternatives by a large margin. Our implementations are available at https://github.com/carrierlxk/COSNet.	[Lu, Xiankai] Shangdong Univ, Sch Software, Jinan 250100, Peoples R China; [Wang, Wenguan] Swiss Fed Inst Technol, CH-8092 Zrich, Switzerland; [Shen, Jianbing] Univ Macau, Dept Comp & Informat Sci, State Key Lab Internet Things Smart City, Macau, Peoples R China; [Crandall, David] Indiana Univ, Bloomington, IN 47405 USA; [Luo, Jiebo] Univ Rochester, Dept Comp Scienece, Rochester, NY 14627 USA	Shandong University; University of Macau; Indiana University System; Indiana University Bloomington; University of Rochester	Wang, WG (corresponding author), Swiss Fed Inst Technol, CH-8092 Zrich, Switzerland.	carrierlxk@gmail.com; wenguanwang.ai@gmail.com; shenjianbingcg@gmail.com; djcran@indiana.edu; jiebo.luo@gmail.com		Luo, Jiebo/0000-0002-4516-9729; Shen, Jianbing/0000-0002-4109-8353	CCF-Baidu Open Fund; Zhejiang Lab's Open Fund [2019KD0AB04]	CCF-Baidu Open Fund; Zhejiang Lab's Open Fund	The authors would like to thank the reviewers and editors for their time and valuable comments on this work. This work was supported by the CCF-Baidu Open Fund and Zhejiang Lab's Open Fund (No. 2019KD0AB04). A preliminary version of this work has appeared in CVPR 2019 [1].	Bahdanau Dzmitry, 2015, NEURAL MACHINE TRANS; Bao LC, 2018, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2018.00626; Brock A., 2017, P INT C LEARN REPR; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565; Chang J, 2013, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2013.267; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667; Chen TL, 2018, LECT NOTES COMPUT SC, V11214, P527, DOI 10.1007/978-3-030-01249-6_32; Cheng JC, 2018, PROC CVPR IEEE, P7415, DOI 10.1109/CVPR.2018.00774; Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Denil M, 2012, NEURAL COMPUT, V24, P2151, DOI 10.1162/NECO_a_00312; Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637; Faktor A., 2014, P BMVC, V2, P8; Fan QN, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818105; Fang HS, 2018, LECT NOTES COMPUT SC, V11214, P52, DOI 10.1007/978-3-030-01249-6_4; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883; Fu HZ, 2014, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2014.405; Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893; Gu YC, 2020, AAAI CONF ARTIF INTE, V34, P10869; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hu YT, 2018, LECT NOTES COMPUT SC, V11212, P56, DOI 10.1007/978-3-030-01237-3_4; Hu YT, 2018, LECT NOTES COMPUT SC, V11205, P813, DOI 10.1007/978-3-030-01246-5_48; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Jaderberg M, 2015, ADV NEUR IN, V28; Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228; Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336; Jang WD, 2016, PROC CVPR IEEE, P696, DOI 10.1109/CVPR.2016.82; Jetley Saumya, 2018, INT C LEARN REPR; Jia K, 2017, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2017.425; Keuper M, 2015, IEEE I CONF COMP VIS, P3271, DOI 10.1109/ICCV.2015.374; Koh YJ, 2018, LECT NOTES COMPUT SC, V11218, P537, DOI 10.1007/978-3-030-01264-9_32; Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784; Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471; Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342; Li HF, 2019, IEEE I CONF COMP VIS, P7273, DOI 10.1109/ICCV.2019.00737; Li SY, 2018, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2018.00683; Li SY, 2018, LECT NOTES COMPUT SC, V11207, P215, DOI 10.1007/978-3-030-01219-9_13; Lu JS, 2016, ADV NEUR IN, V29; Lu X., 2020, ECCV; Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374; Lu Xiankai, 2020, CVPR; Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418; Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372; Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Rodr~iguez P., 2017, P INT C LEARN REPR; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saxe Andrew M, 2013, ARXIV13126120; Siam M., 2020, P 29 INT JOINT C ART; Siam M, 2019, IEEE INT CONF ROBOT, P50, DOI 10.1109/ICRA.2019.8794254; Sinclair D., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P366, DOI 10.1109/ICCV.1993.378191; Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44; Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410; Taylor B, 2015, PROC CVPR IEEE, P4268, DOI 10.1109/CVPR.2015.7299055; Tokmakov P, 2019, INT J COMPUT VISION, V127, P282, DOI 10.1007/s11263-018-1122-2; Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480; Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64; Tsai YH, 2016, LECT NOTES COMPUT SC, V9908, P760, DOI 10.1007/978-3-319-46493-0_46; Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423; Vaswani A, 2017, ADV NEUR IN, V30; Wang WG, 2020, IEEE T PATTERN ANAL, V42, P1913, DOI 10.1109/TPAMI.2019.2905607; Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417; Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933; Wang WG, 2021, IEEE T PATTERN ANAL, V43, P2413, DOI 10.1109/TPAMI.2020.2966453; Wang WG, 2019, IEEE T PATTERN ANAL, V41, P985, DOI 10.1109/TPAMI.2018.2819173; Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612; Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941; Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wu Q, 2018, PROC CVPR IEEE, P6106, DOI 10.1109/CVPR.2018.00639; Xiao HX, 2018, PROC CVPR IEEE, P1140, DOI 10.1109/CVPR.2018.00125; Xiong C, 2017, 5 INT C LEARN REPR I; Xu CL, 2012, PROC CVPR IEEE, P1202, DOI 10.1109/CVPR.2012.6247802; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680; Yoon JS, 2017, IEEE I CONF COMP VIS, P2186, DOI 10.1109/ICCV.2017.238; You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87; Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515; Zheng ZL, 2019, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2019.00683	93	44	44	25	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2228	2242		10.1109/TPAMI.2020.3040258	http://dx.doi.org/10.1109/TPAMI.2020.3040258			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33232224				2022-12-18	WOS:000764815300041
J	Li, CY; Guo, CL; Loy, CC				Li, Chongyi; Guo, Chunle; Loy, Chen Change			Learning to Enhance Low-Light Image via Zero-Reference Deep Curve Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Lighting; Estimation; Training; Image enhancement; Image color analysis; Dynamic range; Task analysis; Computational photography; low-light image enhancement; curve estimation; zero-reference learning	QUALITY ASSESSMENT	This paper presents a novel method, Zero-Reference Deep Curve Estimation (Zero-DCE), which formulates light enhancement as a task of image-specific curve estimation with a deep network. Our method trains a lightweight deep network, DCE-Net, to estimate pixel-wise and high-order curves for dynamic range adjustment of a given image. The curve estimation is specially designed, considering pixel value range, monotonicity, and differentiability. Zero-DCE is appealing in its relaxed assumption on reference images, i.e., it does not require any paired or even unpaired data during training. This is achieved through a set of carefully formulated non-reference loss functions, which implicitly measure the enhancement quality and drive the learning of the network. Despite its simplicity, we show that it generalizes well to diverse lighting conditions. Our method is efficient as image enhancement can be achieved by an intuitive and simple nonlinear curve mapping. We further present an accelerated and light version of Zero-DCE, called Zero-DCE++, that takes advantage of a tiny network with just 10K parameters. Zero-DCE++ has a fast inference speed (1000/11 FPS on a single GPU/CPU for an image of size 1200x900x3) while keeping the enhancement performance of Zero-DCE. Extensive experiments on various benchmarks demonstrate the advantages of our method over state-of-the-art methods qualitatively and quantitatively. Furthermore, the potential benefits of our method to face detection in the dark are discussed. The source code is made publicly available at https://li-chongyi.github.io/Proj_Zero-DCE++.html.	[Li, Chongyi; Loy, Chen Change] Nanyang Technol Univ NTU, S Lab, Singapore 639798, Singapore; [Guo, Chunle] Nankai Univ, Coll Comp Sci, Tianjin 300071, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nankai University	Loy, CC (corresponding author), Nanyang Technol Univ NTU, S Lab, Singapore 639798, Singapore.	chongyi.li@ntu.edu.sg; guochunle@nankai.edu.cn; ccloy@ntu.edu.sg			A*STAR; SingaporeMOE AcRF Tier 1 [2018-T1-002-056]; NTU SUG; CAAI-Huawei MindSpore Open Fund	A*STAR(Agency for Science Technology & Research (A*STAR)); SingaporeMOE AcRF Tier 1(Ministry of Education, Singapore); NTU SUG(Nanyang Technological University); CAAI-Huawei MindSpore Open Fund	This research was conducted in collaboration with SenseTime. This work was supported by theA*STAR through the Industry Alignment Fund - Industry Collaboration Projects Grant. This work was also supported in part by SingaporeMOE AcRF Tier 1 (2018-T1-002-056) and NTU SUG. The work of Chunle Guo was supported by the CAAI-Huawei MindSpore Open Fund. Chongyi Li and Chunle Guo contributed equally to this work.	Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Bychkovsky V, 2011, PROC CVPR IEEE, P97; Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218; Chen C, 2019, IEEE I CONF COMP VIS, P3184, DOI 10.1109/ICCV.2019.00328; Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347; Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067; Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170; Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304; Gu SH, 2020, IEEE T PATTERN ANAL, V42, P2437, DOI 10.1109/TPAMI.2019.2961672; Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185; Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450; Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378; Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280; Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059; Lee C, 2012, IEEE IMAGE PROC, P965, DOI 10.1109/ICIP.2012.6467022; Li CY, 2020, IEEE T MULTIMEDIA, V22, P704, DOI 10.1109/TMM.2019.2933334; Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241; Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010; Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520; Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539; Liu J., 2018, P BRIT MECH VIS C, P1; Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008; Lv J. W. Feifan, 2018, BR MACH VIS C; Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009; Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920; Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x; Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17; Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726; Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804; Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835; Ren H., 2021, IEEE WINT CONF APPL, V34, P1049, DOI DOI 10.1109/WACV48630.2021.00005; Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412; Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534; Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701; Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235; Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596; Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313; Yang WH, 2020, IEEE T IMAGE PROCESS, V29, P5737, DOI 10.1109/TIP.2020.2981922; Yuan L, 2012, LECT NOTES COMPUT SC, V7575, P771, DOI 10.1007/978-3-642-33765-9_55; Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	49	44	45	22	49	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 3	2021	44	8					4225	4238		10.1109/TPAMI.2021.3063604	http://dx.doi.org/10.1109/TPAMI.2021.3063604			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6IC	33656989	Green Submitted			2022-12-18	WOS:000820523200001
J	Hu, XW; Fu, CW; Zhu, L; Qin, J; Heng, PA				Hu, Xiaowei; Fu, Chi-Wing; Zhu, Lei; Qin, Jing; Heng, Pheng-Ann			Direction-Aware Spatial Context Features for Shadow Detection and Removal	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Image color analysis; Training; Semantics; Benchmark testing; Recurrent neural networks; Shadow detection; shadow removal; spatial context features; deep neural network	INTRINSIC IMAGE DECOMPOSITION	Shadow detection and shadow removal are fundamental and challenging tasks, requiring an understanding of the global image semantics. This paper presents a novel deep neural network design for shadow detection and removal by analyzing the spatial image context in a direction-aware manner. To achieve this, we first formulate the direction-aware attention mechanism in a spatial recurrent neural network (RNN) by introducing attention weights when aggregating spatial context features in the RNN. By learning these weights through training, we can recover direction-aware spatial context (DSC) for detecting and removing shadows. This design is developed into the DSC module and embedded in a convolutional neural network (CNN) to learn the DSC features at different levels. Moreover, we design a weighted cross entropy loss to make effective the training for shadow detection and further adopt the network for shadow removal by using a euclidean loss function and formulating a color transfer function to address the color and luminosity inconsistencies in the training pairs. We employed two shadow detection benchmark datasets and two shadow removal benchmark datasets, and performed various experiments to evaluate our method. Experimental results show that our method performs favorably against the state-of-the-art methods for both shadow detection and shadow removal.	[Hu, Xiaowei; Fu, Chi-Wing; Zhu, Lei; Heng, Pheng-Ann] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China; [Qin, Jing] Hong Kong Polytech Univ, Sch Nursing, Ctr Smart Hlth, Hong Kong, Peoples R China; [Fu, Chi-Wing; Heng, Pheng-Ann] Chinese Acad Sci, Shenzhen Inst Adv Technol, Guangdong Prov Key Lab Comp Vis & Virtual Real Te, Shenzhen 518055, Peoples R China	Chinese University of Hong Kong; Hong Kong Polytechnic University; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS	Fu, CW; Zhu, L (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.	xwhu@cse.cuhk.edu.hk; philip.chiwing.fu@gmail.com; lzhu@cse.cuhk.edu.hk; harry.qin@polyu.edu.hk; pheng@cse.cuhk.edu.hk	Qin, Jing/J-9807-2016	Qin, Jing/0000-0002-7059-0929; Zhu, Lei/0000-0003-3871-663X; Heng, Pheng Ann/0000-0003-3055-5034; Hu, Xiaowei/0000-0002-5708-7018; Fu, Chi Wing/0000-0002-5238-593X	National Basic Program of China, 973 Program [2015CB351706]; Shenzhen Science and Technology Program [JCYJ20170413162617606]; Hong Kong Research Grants Council [CUHK 14225616, PolyU 152035/17E, CUHK 14203416]; Hong Kong Ph.D. Fellowship	National Basic Program of China, 973 Program(National Basic Research Program of China); Shenzhen Science and Technology Program; Hong Kong Research Grants Council(Hong Kong Research Grants Council); Hong Kong Ph.D. Fellowship	This work was supported by the National Basic Program of China, 973 Program (Project no. 2015CB351706), the Shenzhen Science and Technology Program (Project no. JCYJ20170413162617606), and the Hong Kong Research Grants Council (Project no. CUHK 14225616, PolyU 152035/17E, & CUHK 14203416). Xiaowei Hu is funded by the Hong Kong Ph.D. Fellowship. We thank reviewers for their valuable comments, Michael S. Brown for his discussion, and Tomas F. Yago Vicente, Minh Hoai Nguyen, Vn Nguyen, Moein Shakeri, Jiandong Tian and Jifeng Wang for sharing their results and evaluation code with us. A preliminary version of this work was accepted for presentation in CVPR 2018 [1]. The source code is publicly available at https://xwhu.github.io/.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2016, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2015.2462355; Baba M., P ACM SIGGRAPH; Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314; Bell S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601206; Bousseau A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618476; Chen QF, 2013, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2013.37; Cheng LC, 2018, PROC CVPR IEEE, P656, DOI 10.1109/CVPR.2018.00075; Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18; Finlayson GD, 2002, LECT NOTES COMPUT SC, V2353, P823; Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z; Gong H., 2014, BMVC, P1, DOI 10.5244/c.28.36; Gryka M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2732407; Guo Ruiqi, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P2956, DOI 10.1109/TPAMI.2012.214; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoiem D, 2011, CVPR 2011, P2033, DOI DOI 10.1109/CVPR.2011.5995725; Hosseinzadeh S, 2018, IEEE INT C INT ROBOT, P3124, DOI 10.1109/IROS.2018.8594050; Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778; Huang X, 2011, IEEE I CONF COMP VIS, P898, DOI 10.1109/ICCV.2011.6126331; Jia Y., 2014, P 22 ACM INT C MULT, P675; Junejo IN, 2008, LECT NOTES COMPUT SC, V5302, P318, DOI 10.1007/978-3-540-88682-2_25; Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191; Khan SH, 2014, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2014.249; Kim S, 2016, LECT NOTES COMPUT SC, V9912, P143, DOI 10.1007/978-3-319-46484-8_9; King DB, 2015, ACS SYM SER, V1214, P1; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lalonde JF, 2010, LECT NOTES COMPUT SC, V6312, P322, DOI 10.1007/978-3-642-15552-9_24; Lalonde JF, 2009, IEEE I CONF COMP VIS, P183, DOI 10.1109/ICCV.2009.5459163; Le Q. V., 2015, CORR; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Lettry L, 2018, IEEE WINT CONF APPL, P1359, DOI 10.1109/WACV.2018.00153; Liu F, 2008, LECT NOTES COMPUT SC, V5305, P437; Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51; Narihira T, 2015, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2015.342; Okabe T, 2009, IEEE I CONF COMP VIS, P1693, DOI 10.1109/ICCV.2009.5459381; Panagopoulos A, 2011, PROC CVPR IEEE, P673, DOI 10.1109/CVPR.2011.5995585; Qu LQ, 2017, PROC CVPR IEEE, P2308, DOI 10.1109/CVPR.2017.248; Salvador E., 2004, COMPUT VIS IMAGE UND, V95, P238, DOI DOI 10.1016/j.cviu.2004.03.008; Santhanam V., 2017, IEEE C COMPUT VIS PA, P5609; Shen L, 2008, PROC CVPR IEEE, P2479; Shen L, 2015, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2015.7298818; Shen L, 2011, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2011.5995738; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Tian JD, 2016, PATTERN RECOGN, V51, P85, DOI 10.1016/j.patcog.2015.09.006; Vicente TFY, 2018, IEEE T PATTERN ANAL, V40, P682, DOI 10.1109/TPAMI.2017.2691703; Vicente TFY, 2016, PROC CVPR IEEE, P3783, DOI 10.1109/CVPR.2016.411; Vicente TFY, 2015, IEEE I CONF COMP VIS, P3388, DOI 10.1109/ICCV.2015.387; Vincente TFY, 2016, LECT NOTES COMPUT SC, V9910, P816, DOI 10.1007/978-3-319-46466-4_49; Nguyen V, 2017, IEEE I CONF COMP VIS, P4520, DOI 10.1109/ICCV.2017.483; Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192; Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433; Wu TP, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243982; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Yang QX, 2012, IEEE T IMAGE PROCESS, V21, P4361, DOI 10.1109/TIP.2012.2208976; Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao Q, 2012, IEEE T PATTERN ANAL, V34, P1437, DOI 10.1109/TPAMI.2012.77; Zhu JJ, 2010, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.2010.5540209	63	44	48	6	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2795	2808		10.1109/TPAMI.2019.2919616	http://dx.doi.org/10.1109/TPAMI.2019.2919616			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NX0AD	31150337	Green Submitted			2022-12-18	WOS:000575381000005
J	Li, CS; Wang, XF; Dong, WS; Yan, JC; Liu, QS; Zha, HY				Li, Changsheng; Wang, Xiangfeng; Dong, Weishan; Yan, Junchi; Liu, Qingshan; Zha, Hongyuan			Joint Active Learning with Feature Selection via CUR Matrix Decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active learning; feature selection; matrix factorization		This paper presents an unsupervised learning approach for simultaneous sample and feature selection, which is in contrast to existing works which mainly tackle these two problems separately. In fact the two tasks are often interleaved with each other: noisy and high-dimensional features will bring adverse effect on sample selection, while informative or representative samples will be beneficial to feature selection. Specifically, we propose a framework to jointly conduct active learning and feature selection based on the CUR matrix decomposition. From the data reconstruction perspective, both the selected samples and features can best approximate the original dataset respectively, such that the selected samples characterized by the features are highly representative. In particular, our method runs in one-shot without the procedure of iterative sample selection for progressive labeling. Thus, our model is especially suitable when there are few labeled samples or even in the absence of supervision, which is a particular challenge for existing methods. As the joint learning problem is NP-hard, the proposed formulation involves a convex but non-smooth optimization problem. We solve it efficiently by an iterative algorithm, and prove its global convergence. Experimental results on publicly available datasets corroborate the efficacy of our method compared with the state-of-the-art.	[Li, Changsheng] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China; [Li, Changsheng] Univ Elect Sci & Technol China, Big Data Res Ctr, Chengdu 611731, Sichuan, Peoples R China; [Li, Changsheng] Youe Data Inc, AI Res Lab, Beijing 100170, Peoples R China; [Wang, Xiangfeng] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai Key Lab Trustworthy Comp, Shanghai 200241, Peoples R China; [Dong, Weishan] Baidu Search, Beijing 100085, Peoples R China; [Yan, Junchi] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200000, Peoples R China; [Liu, Qingshan] Nanjing Univ Informat Sci & Technol, Sch Informat & Control, B DAT Lab, Nanjing 210044, Jiangsu, Peoples R China; [Zha, Hongyuan] Georgia Inst Technol, Sch Computat Sci & Engn, Atlanta, GA 30332 USA	University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; East China Normal University; Shanghai Jiao Tong University; Nanjing University of Information Science & Technology; University System of Georgia; Georgia Institute of Technology	Li, CS (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.; Li, CS (corresponding author), Univ Elect Sci & Technol China, Big Data Res Ctr, Chengdu 611731, Sichuan, Peoples R China.	lichangsheng@uestc.edu.cn; xfwang@sei.ecnu.edu.cn; dongweishan@baidu.com; yanjunchi@sjtu.edu.cn; qsliu@nuist.edu.cn; zha@cc.gatech.edu	Liu, Qing/GWC-9222-2022; liu, qingqing/HHD-0360-2022	Yan, Junchi/0000-0001-9639-7679	National Natural Science Foundation of China [61532009, 11501210, 61602176]; Key Program of Shanghai Science and Technology Commission [15JC1401700]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Program of Shanghai Science and Technology Commission	The authors are thankful to Lance Warren Feagan with IBM Research - China, who helps editing and revising to improve the writing of this paper. Part of the work was done when the first author worked in IBM Research -China. This work was partially supported by National Natural Science Foundation of China Grant No. 61532009, 11501210, 61602176. It also was partially supported by the Key Program of Shanghai Science and Technology Commission Grant No. 15JC1401700.	Bilgic M., 2012, SIAM INT C DATA MINI, P696; Boutsidis C, 2017, SIAM J COMPUT, V46, P543, DOI 10.1137/140977898; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Cai D, 2012, IEEE T KNOWL DATA EN, V24, P707, DOI 10.1109/TKDE.2011.104; Chattopadhyay R, 2012, P 10 ACM SIGKDD INT, P741; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295; De Rosa R, 2017, PATTERN RECOGN LETT, V99, P48, DOI 10.1016/j.patrec.2017.03.005; Drineas P, 2008, SIAM J MATRIX ANAL A, V30, P844, DOI 10.1137/07070471X; Elhamifar E, 2013, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2013.33; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1; He BS, 2015, NUMER MATH, V130, P567, DOI 10.1007/s00211-014-0673-6; He BS, 2012, SIAM J NUMER ANAL, V50, P700, DOI 10.1137/110836936; He BS, 2002, MATH PROGRAM, V92, P103, DOI 10.1007/s101070100280; He X., 2005, P ADV NEUR INF PROC, P507; He XF, 2011, IEEE T PATTERN ANAL, V33, P2013, DOI 10.1109/TPAMI.2011.44; Hemant J., 2011, UALR0602; Hu Y., 2013, INT JOINT C ART INT, P1415; Huang SJ, 2014, IEEE T PATTERN ANAL, V36, P1936, DOI 10.1109/TPAMI.2014.2307881; Jain P, 2009, PROC CVPR IEEE, P762, DOI 10.1109/CVPRW.2009.5206651; Joshi Ajay J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2372, DOI 10.1109/CVPRW.2009.5206627; Kong X., 2011, P 17 ACM SIGKDD INT, P654, DOI [10.1145/2020408.2020511, DOI 10.1145/2020408.2020511]; Leng J., 2010, P COMP EL ENG, P166; Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3; Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625; Li L., 2012, P 18 ACM SIGKDD INT, P1086, DOI DOI 10.1145/2339530.2339701]; Liang L, 2014, PROC CVPR IEEE, P208, DOI 10.1109/CVPR.2014.34; Lin Z., 2009, UILUENG092215 EL COM; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Mahoney MW, 2009, P NATL ACAD SCI USA, V106, P697, DOI [10.1073/pnas.0803205105, 10.1073/pnas.0803205106]; Nie F., 2008, P 23 AAAI C ART INT, P671; Nie F., 2013, P INT JO C ART INT, P1; Nie FP, 2016, AAAI CONF ARTIF INTE, P1302; Pippa E, 2016, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES FOR AGEING WELL AND E-HEALTH (ICT4AWE), P88, DOI 10.5220/0005912200880095; Qi G.-J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587383; Raghavan H, 2006, J MACH LEARN RES, V7, P1655; Roffo G, 2015, IEEE I CONF COMP VIS, P4202, DOI 10.1109/ICCV.2015.478; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Roy Nicholas, 2001, P 18 INT C MACH LEAR, P441; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300; Vijayanarasimhan S, 2014, INT J COMPUT VISION, V108, P97, DOI 10.1007/s11263-014-0721-9; Vijayanarasimhan S, 2010, PROC CVPR IEEE, P3035, DOI 10.1109/CVPR.2010.5540055; Wang JG, 2011, IEEE T IMAGE PROCESS, V20, P2049, DOI 10.1109/TIP.2011.2106794; Wang SS, 2013, J MACH LEARN RES, V14, P2729; Wang Z., 2013, P 19 ACM SIGKDD INT, P158; Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421; Yang Y., 2011, P 22 INT JOINT C ART, P1589, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-267; Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x; Yeung D.-Y., 2013, P 23 INT JOINT C ART, P1917; Yu K, 2006, P 23 INT C MACH LEAR, ppp1081; Zhang LJ, 2011, IEEE T PATTERN ANAL, V33, P2026, DOI 10.1109/TPAMI.2011.20; Zhang XY, 2015, IEEE T NEUR NET LEAR, V26, P3034, DOI 10.1109/TNNLS.2015.2401595; Zheng Z., 2007, P 24 INT C MACH LEAR, P1151, DOI DOI 10.1145/1273496.1273641	53	44	44	0	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1382	1396		10.1109/TPAMI.2018.2840980	http://dx.doi.org/10.1109/TPAMI.2018.2840980			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29993711	Green Submitted			2022-12-18	WOS:000467037000008
J	Gligorijevic, V; Panagakis, Y; Zafeiriou, S				Gligorijevic, Vladimir; Panagakis, Yannis; Zafeiriou, Stefanos			Non-Negative Matrix Factorizations for Multiplex Network Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiplex networks; non-negative matrix factorization; community detection; network integration	COMMUNITY STRUCTURE; FUNCTIONAL MODULES; MULTILAYER GRAPHS; ALGORITHMS	Networks have been a general tool for representing, analyzing, and modeling relational data arising in several domains. One of the most important aspect of network analysis is community detection or network clustering. Until recently, the major focus have been on discovering community structure in single (i.e., monoplex) networks. However, with the advent of relational data with multiple modalities, multiplex networks, i.e., networks composed of multiple layers representing different aspects of relations, have emerged. Consequently, community detection in multiplex network, i.e., detecting clusters of nodes shared by all layers, has become a new challenge. In this paper, we propose Network Fusion for Composite Community Extraction (NF-CCE), a new class of algorithms, based on four different non-negative matrix factorization models, capable of extracting composite communities in multiplex networks. Each algorithm works in two steps: first, it finds a non-negative, low-dimensional feature representation of each network layer; then, it fuses the feature representation of layers into a common non-negative, low-dimensional feature representation via collective factorization. The composite clusters are extracted from the common feature representation. We demonstrate the superior performance of our algorithms over the state-of-the-art methods on various types of multiplex networks, including biological, social, economic, citation, phone communication, and brain multiplex networks.	[Gligorijevic, Vladimir; Panagakis, Yannis; Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, London SW7 2AZ, England; [Gligorijevic, Vladimir] Simons Fdn, Flatiron Inst, New York, NY 10010 USA; [Panagakis, Yannis] Middlesex Univ London, Dept Comp Sci, London NW4 4BT, England	Imperial College London; Middlesex University	Gligorijevic, V (corresponding author), Imperial Coll London, Dept Comp, London SW7 2AZ, England.; Gligorijevic, V (corresponding author), Simons Fdn, Flatiron Inst, New York, NY 10010 USA.	vgligorijevic@flatironinstitute.org; i.panagakis@imperial.ac.uk; s.zafeiriou@imperial.ac.uk	Panagakis, Yannis/AAZ-8090-2020	Panagakis, Ioannis/0000-0003-0153-5210; Gligorijevic, Vladimir/0000-0002-5165-0973				Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; [Anonymous], 2014, P 5 ACM C BIOINF COM; [Anonymous], 2010, NETWORKS INTRO, DOI DOI 10.1093/ACPROF:OSO/9780199206650.001.0001; Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556; Berlingerio M, 2011, 2011 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2011), P490, DOI 10.1109/ASONAM.2011.104; Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008; Boccaletti S, 2006, PHYS REP, V424, P175, DOI 10.1016/j.physrep.2005.10.009; Boyd S, 2004, CONVEX OPTIMIZATION; Chen JC, 2006, BIOINFORMATICS, V22, P2283, DOI 10.1093/bioinformatics/btl370; Cheng W, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P320; Condon A, 2001, RANDOM STRUCT ALGOR, V18, P116, DOI 10.1002/1098-2418(200103)18:2<116::AID-RSA1001>3.0.CO;2-2; De Domenico M, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms7864; Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277; Ding Chris, 2006, P 12 ACM SIGKDD INT, V2006, P126; Dong XW, 2014, IEEE T SIGNAL PROCES, V62, P905, DOI 10.1109/TSP.2013.2295553; Dong XW, 2012, IEEE T SIGNAL PROCES, V60, P5820, DOI 10.1109/TSP.2012.2212886; Duch J, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.027104; Everett M., 1998, CONNECTIONS, V21, P49; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Gauvin L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086028; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Harshman R.A., 1970, MULTIMODAL FACTOR AN; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; HOLLAND PW, 1983, SOC NETWORKS, V5, P109, DOI 10.1016/0378-8733(83)90021-7; Jutla I.S., 2011, GEN LOUVAIN METHOD C; Kim J, 2015, SIGMOD REC, V44, P37, DOI 10.1145/2854006.2854013; Kivela M, 2014, J COMPLEX NETW, V2, P203, DOI 10.1093/comnet/cnu016; Kuang D., 2012, PROC 2012 SIAM INT C, P106, DOI DOI 10.1137/1.9781611972825.10; Lee DD, 2001, ADV NEUR IN, V13, P556; Leskovec J., 2010, P 19 INT C WORLD WID, P631; Mitrovic M, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.026123; Mostafavi S, 2010, BIOINFORMATICS, V26, P1759, DOI 10.1093/bioinformatics/btq262; Mucha PJ, 2010, SCIENCE, V328, P876, DOI 10.1126/science.1184819; Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103; Newman MEJ, 2004, PHYS REV E, V70, DOI [10.1103/PhysRevE.70.056131, 10.1103/PhysRevE.69.026113]; Nicosia V, 2013, PHYS REV LETT, V111, DOI 10.1103/PhysRevLett.111.058701; Panagakis Y, 2010, IEEE T AUDIO SPEECH, V18, P576, DOI 10.1109/TASL.2009.2036813; Papalexakis EE, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P899; Pereira-Leal JB, 2004, PROTEINS, V54, P49, DOI 10.1002/prot.10505; Rodriguez MA, 2010, J INFORMETR, V4, P29, DOI 10.1016/j.joi.2009.06.004; Schaeffer SE, 2007, COMPUT SCI REV, V1, P27, DOI 10.1016/j.cosrev.2007.05.001; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shih YK, 2012, BIOINFORMATICS, V28, pI473, DOI 10.1093/bioinformatics/bts370; Snijders TAB, 2006, SOCIOL METHODOL, V36, P99, DOI 10.1111/j.1467-9531.2006.00176.x; Strogatz SH, 2001, NATURE, V410, P268, DOI 10.1038/35065725; Tang L, 2009, IEEE DATA MINING, P503, DOI 10.1109/ICDM.2009.20; Tropp JA, 2012, FOUND COMPUT MATH, V12, P389, DOI 10.1007/s10208-011-9099-z; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang B, 2014, NAT METHODS, V11, P333, DOI [10.1038/NMETH.2810, 10.1038/nmeth.2810]; Wang F, 2011, DATA MIN KNOWL DISC, V22, P493, DOI 10.1007/s10618-010-0181-y; West D. B., 2001, INTRO GRAPH THEORY, V2; WHITE JG, 1986, PHILOS T R SOC B, V314, P1, DOI 10.1098/rstb.1986.0056; Yang ZR, 2010, IEEE T NEURAL NETWOR, V21, P734, DOI 10.1109/TNN.2010.2041361; Zhang SQ, 2015, IEEE ACM T COMPUT BI, V12, P1146, DOI 10.1109/TCBB.2015.2396073; Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6	59	44	47	5	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					928	940		10.1109/TPAMI.2018.2821146	http://dx.doi.org/10.1109/TPAMI.2018.2821146			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29993651	Green Submitted			2022-12-18	WOS:000460583500011
J	Masi, I; Chang, FJ; Choi, J; Harel, S; Kim, J; Kim, K; Leksut, J; Rawls, S; Wu, Y; Hassner, T; AbdAlmageed, W; Medioni, G; Morency, LP; Natarajan, P; Nevatia, R				Masi, Iacopo; Chang, Feng-Ju; Choi, Jongmoo; Harel, Shai; Kim, Jungyeon; Kim, Kanggeon; Leksut, Jatuporn; Rawls, Stephen; Wu, Yue; Hassner, Tal; AbdAlmageed, Wael; Medioni, Gerard; Morency, Louis-Philippe; Natarajan, Prem; Nevatia, Ram			Learning Pose-Aware Models for Pose-Invariant Face Recognition in the Wild	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; CNN; pose-aware		We propose a method designed to push the frontiers of unconstrained face recognition in the wild with an emphasis on extreme out-of-plane pose variations. Existing methods either expect a single model to learn pose invariance by training on massive amounts of data or else normalize images by aligning faces to a single frontal pose. Contrary to these, our method is designed to explicitly tackle pose variations. Our proposed Pose-Aware Models (PAM) process a face image using several pose-specific, deep convolutional neural networks (CNN). 3D rendering is used to synthesize multiple face poses from input images to both train these models and to provide additional robustness to pose variations at test time. Our paper presents an extensive analysis of the IARPA Janus Benchmark A (IJB-A), evaluating the effects that landmark detection accuracy, CNN layer selection, and pose model selection all have on the performance of the recognition pipeline. It further provides comparative evaluations on IJB-A and the PIPA dataset. These tests show that our approach outperforms existing methods, even surprisingly matching the accuracy of methods that were specifically fine-tuned to the target dataset. Parts of this work previously appeared in [1] and [2].	[Masi, Iacopo; Chang, Feng-Ju; Choi, Jongmoo; Kim, Jungyeon; Kim, Kanggeon; Leksut, Jatuporn; Medioni, Gerard; Nevatia, Ram] Univ Southern Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90007 USA; [Rawls, Stephen; Wu, Yue; Hassner, Tal; AbdAlmageed, Wael; Natarajan, Prem] Univ Southern Calif, Inst Informat Sci, Los Angeles, CA 90007 USA; [Harel, Shai; Hassner, Tal] Open Univ Israel, IL-4353701 Raanana, Israel; [Morency, Louis-Philippe] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	University of Southern California; University of Southern California; Open University Israel; Carnegie Mellon University	Masi, I (corresponding author), Univ Southern Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90007 USA.	iacopoma@usc.edu; fengjuch@usc.edu; jongmooc@usc.edu; shaih82@gmail.com; jungyeon@usc.edu; kanggeon.kim@usc.edu; leksut@usc.edu; srawls@isi.edu; yue_wu@isi.edu; hassner@isi.edu; wamageed@isi.edu; medioni@usc.edu; morency@cs.cmu.edu; pnataraj@isi.edu; nevatia@usc.edu		Chang, Feng-Ju/0000-0003-2405-3118; Wu, Yue/0000-0003-0126-3614; Kim, KangGeon/0000-0001-9467-2323	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA [2014-14071600010]	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA	This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA 2014-14071600010. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purpose notwithstanding any copyright annotation thereon. Moreover, we gratefully acknowledge USC HPC for hyper-computing and the support of NVIDIA Corporation for their donation of an NVIDIA Titan X.I.M. is the lead author; F.C., J.C., S.H., J.K., K.K., J.L., S.R., and Y.W. in alphabetical order; T.H. is the lead senior author; all remaining senior authors appear next in alphabetical order.	Abdalmageed W., 2016, CORR, P1, DOI DOI 10.1109/WACV.2016.7477555; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Ashraf AB, 2008, PROC CVPR IEEE, P3208; Asthana A, 2011, IEEE I CONF COMP VIS, P937, DOI 10.1109/ICCV.2011.6126336; Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54; Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980; Chen J., 2015, UNCONSTRAINED FACE V; Chen JC, 2016, IEEE WINT CONF APPL; Chen YC, 2012, LECT NOTES COMPUT SC, V7577, P766, DOI 10.1007/978-3-642-33783-3_55; Chowdhury Animesh R., 2016, 2016 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2016.7534285; Crispell D. E., 2016, PROC IEEE APPL IMAGE; Crosswhite N, 2017, IEEE INT CONF AUTOMA, P1, DOI 10.1109/FG.2017.11; Ferrari C, 2017, IEEE COMPUT SOC CONF, P583, DOI 10.1109/CVPRW.2017.86; Ferrari C, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P509, DOI 10.1109/3DV.2015.63; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; HASSNER T, 2015, PROC CVPR IEEE, P4295, DOI DOI 10.1109/CVPR.2015.7299058; Hassner T., 2016, P IEEE C COMP VIS PA, P59; Hassner T, 2013, IEEE I CONF COMP VIS, P3607, DOI 10.1109/ICCV.2013.448; Heo J., 2011, TPAMI, V34, P2341; Huang Gary B., 2007, 0749 U MASS, P7; ju Chang F., 2017, P 7 IEEE INT WORKSH, P11599; Kanade T, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P954; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; Kim K., 2016, P BRIT MACH VIS C; KLARE BF, 2015, PROC CVPR IEEE, P1931, DOI DOI 10.1109/CVPR.2015.7298803; Klontz JC, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS); Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li AN, 2009, PROC CVPR IEEE, P605, DOI 10.1109/CVPRW.2009.5206659; Li HX, 2016, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2016.145; Lu C, 2015, AAAI CONF ARTIF INTE, P3811; Masi I, 2017, IEEE INT CONF AUTOMA, P604, DOI 10.1109/FG.2017.76; Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523; Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35; Masi I, 2014, INT C PATT RECOG, P4477, DOI 10.1109/ICPR.2014.766; Masi I, 2013, IEEE COMPUT SOC CONF, P775, DOI 10.1109/CVPRW.2013.116; Parkhi Omkar M., 2015, BRIT MACH VIS C; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Prabhu U, 2011, IEEE T PATTERN ANAL, V33, P1952, DOI 10.1109/TPAMI.2011.123; Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114; Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163; Wang D., 2015, FACE SEARCH SCALE 80; Wolf L., 2011, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2011.5995566; Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230; Wolf L, 2009, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2009.5459323; Wu Y, 2018, IEEE T PATTERN ANAL, V40, P3067, DOI 10.1109/TPAMI.2017.2787130; Yi D., 2014, LEARNING FACE REPRES, V1411, P7923; Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454; Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667; Yin Q., 2015, NAIVE DEEP FACE RECO; YOSINSKI J, 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.1109/IJCNN.2016.7727519; Zhang Mengjie, 2014, EUROGRAPHICS STATE A, V1, P2, DOI [10.2312/egst.20141042, DOI 10.2312/EGST.20141042]; Zhang N, 2015, PROC CVPR IEEE, P4804, DOI 10.1109/CVPR.2015.7299113; Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7; Zhu Z., 2014, RECOVER CANONICAL VI; Zhu Z., 2014, NIPS, P217	65	44	44	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					379	393		10.1109/TPAMI.2018.2792452	http://dx.doi.org/10.1109/TPAMI.2018.2792452			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29994497				2022-12-18	WOS:000456150600009
J	Huang, ZW; Wang, RP; Shan, SG; Van Gool, L; Chen, XL				Huang, Zhiwu; Wang, Ruiping; Shan, Shiguang; Van Gool, Luc; Chen, Xilin			Cross Euclidean-to-Riemannian Metric Learning with Application to Face Recognition from Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Riemannian manifold; video-based face recognition; cross Euclidean-to-Riemannian metric learning	SET; CLASSIFICATION; MANIFOLD; POINT	Riemannian manifolds have been widely employed for video representations in visual classification tasks including video-based face recognition. The success mainly derives from learning a discriminant Riemannian metric which encodes the non-linear geometry of the underlying Riemannian manifolds. In this paper, we propose a novel metric learning framework to learn a distance metric across a Euclidean space and a Riemannian manifold to fuse average appearance and pattern variation of faces within one video. The proposed metric learning framework can handle three typical tasks of video-based face recognition: Video-to-Still, Still-to-Video and Video-to-Video settings. To accomplish this new framework, by exploiting typical Riemannian geometries for kernel embedding, we map the source Euclidean space and Riemannian manifold into a common Euclidean subspace, each through a corresponding high-dimensional Reproducing Kernel Hilbert Space (RKHS). With this mapping, the problem of learning a cross-view metric between the two source heterogeneous spaces can be converted to learning a single-view Euclidean distance metric in the target common Euclidean space. By learning information on heterogeneous data with the shared label, the discriminant metric in the common space improves face recognition from videos. Extensive experiments on four challenging video face databases demonstrate that the proposed framework has a clear advantage over the state-of-the-art methods in the three classical video-based face recognition scenarios.	[Huang, Zhiwu; Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland; [Van Gool, Luc] Katholieke Univ Leuven, VIS Lab, B-3000 Leuven, Belgium; [Wang, Ruiping; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Shan, Shiguang] CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing, Peoples R China	Swiss Federal Institutes of Technology Domain; ETH Zurich; KU Leuven; Chinese Academy of Sciences; Institute of Computing Technology, CAS	Shan, SG (corresponding author), CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing, Peoples R China.	zhiwu.huang@vision.ee.ethz.ch; wangruiping@ict.ac.cn; sgshan@ict.ac.cn; vangool@vision.ee.ethz.ch; xlchenj@ict.ac.cn		Huang, Zhiwu/0000-0002-7385-079X; Shan, Shiguang/0000-0002-8348-392X	973 Program [2015CB351802]; Natural Science Foundation of China [61390511, 61379083, 61650202, 61402443, 61672496]; Frontier Science Key Research Project CAS [QYZDJ-SSW-JSC009]; Youth Innovation Promotion Association CAS [2015085]	973 Program(National Basic Research Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Frontier Science Key Research Project CAS; Youth Innovation Promotion Association CAS	This work has been carried out mainly at the Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS), where Z. Huang pursued the PhD degree. It is partially supported by 973 Program under contract No. 2015CB351802, Natural Science Foundation of China under contract Nos. 61390511, 61379083, 61650202, 61402443, 61672496, Frontier Science Key Research Project CAS No. QYZDJ-SSW-JSC009 and Youth Innovation Promotion Association CAS No. 2015085.	Amari S., 2000, METHODS INFORM GEOME; Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996; Beveridge J. R., 2013, P 6 INT C BIOMETRICS, P1; Beveridge JR, 2015, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2015.7163156; Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Cevikalp H., 2010, PROC CVPR IEEE, P2567, DOI DOI 10.1109/CVPR.2010.5539965; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hamm J., 2009, ADV NEURAL INFORM PR, P601; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564; Harandi MT, 2014, LECT NOTES COMPUT SC, V8690, P17, DOI 10.1007/978-3-319-10605-2_2; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635; Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500; Huang ZW, 2015, PR MACH LEARN RES, V37, P720; Huang ZW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493448; Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609; Huang ZW, 2014, PROC CVPR IEEE, P1677, DOI 10.1109/CVPR.2014.217; Huang ZW, 2015, PATTERN RECOGN, V48, P3113, DOI 10.1016/j.patcog.2015.03.011; Jayasumana S, 2015, IEEE T PATTERN ANAL, V37, P2464, DOI 10.1109/TPAMI.2015.2414422; Jayasumana S, 2013, 2013 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES & APPLICATIONS (DICTA), P463; Jung SK, 2012, BIOMETRIKA, V99, P551, DOI 10.1093/biomet/ass022; Kim M, 2008, PROC CVPR IEEE, P1787; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Li PH, 2013, IEEE I CONF COMP VIS, P1601, DOI 10.1109/ICCV.2013.202; Liu Mengyi, 2014, P INT C MULTIMODAL I, P494, DOI DOI 10.1145/2663204.2666274; Lovric M, 2000, J MULTIVARIATE ANAL, V74, P36, DOI 10.1006/jmva.1999.1853; Lu JW, 2013, IEEE I CONF COMP VIS, P329, DOI 10.1109/ICCV.2013.48; McFee B, 2011, J MACH LEARN RES, V12, P491; Parkhi Omkar M., 2015, BRIT MACH VIS C; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Quadrianto N., 2011, P 28 INT C MACHINE L; Quang M. H., 2014, ADV NEURAL INFORM PR, P388; Salakhutdinov R, 2005, NEURAL INF PROCESS S, P513; Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sharma A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247923; Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350; Sra S., 2012, ADV NEURAL INFORM PR, P144; Sugiyama M, 2007, J MACH LEARN RES, V8, P1027; Sun Y., 2015, ARXIV PREPRINT ARXIV; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tosato D, 2010, LECT NOTES COMPUT SC, V6312, P378, DOI 10.1007/978-3-642-15552-9_28; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Vemulapalli R, 2013, PROC CVPR IEEE, P1782, DOI 10.1109/CVPR.2013.233; Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965; Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850; Wang W, 2015, PROC CVPR IEEE, P3395, DOI 10.1109/CVPR.2015.7298816; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wold H., 1985, ENCY STAT SCI, DOI DOI 10.1002/0471667196; Wolf L., 2011, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2011.5995566; Xu CY, 2015, IEEE T CIRC SYST VID, V25, P1576, DOI 10.1109/TCSVT.2015.2392472; Zhai X., 2013, P AAAI C ART INT AAA; Zhu PF, 2013, IEEE I CONF COMP VIS, P2664, DOI 10.1109/ICCV.2013.331	60	44	44	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2827	2840		10.1109/TPAMI.2017.2776154	http://dx.doi.org/10.1109/TPAMI.2017.2776154			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29990185	Green Published, Green Accepted, Green Submitted			2022-12-18	WOS:000449355500003
J	Wu, Y; Hassner, T; Kim, K; Medioni, G; Natarajan, P				Wu, Yue; Hassner, Tal; Kim, Kanggeon; Medioni, Gerard; Natarajan, Prem			Facial Landmark Detection with Tweaked Convolutional Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face and gesture recognition; Neural nets	REPRESENTATION	This paper concerns the problem of facial landmark detection. We provide a unique new analysis of the features produced at intermediate layers of a convolutional neural network (CNN) trained to regress facial landmark coordinates. This analysis shows that while being processed by the CNN, face images can be partitioned in an unsupervised manner into subsets containing faces in similar poses (i.e., 3D views) and facial properties (e.g., presence or absence of eye-wear). Based on this finding, we describe a novel CNN architecture, specialized to regress the facial landmark coordinates of faces in specific poses and appearances. To address the shortage of training data, particularly in extreme profile poses, we additionally present data augmentation techniques designed to provide sufficient training examples for each of these specialized sub-networks. The proposed Tweaked CNN (TCNN) architecture is shown to outperform existing landmark detection methods in an extensive battery of tests on the AFW, ALFW, and 300W benchmarks. Finally, to promote reproducibility of our results, we make code and trained models publicly available through our project webpage.	[Wu, Yue; Hassner, Tal; Natarajan, Prem] USC, Informat Sci Inst, Marina Del Rey, CA 90292 USA; [Kim, Kanggeon; Medioni, Gerard] USC, Inst Robot & Intelligent Syst, Marina Del Rey, CA 90292 USA	University of Southern California; University of Southern California	Hassner, T (corresponding author), USC, Informat Sci Inst, Marina Del Rey, CA 90292 USA.	yue_wu@isi.edu; hassner@isi.edu; kanggeon.kim@usc.edu; medioni@usc.edu; pnataraj@isi.edu		Kim, KangGeon/0000-0001-9467-2323	Office of the Director of National Intelligence (ODNI); Intelligence Advanced Research Projects Activity (IARPA) [2014-14071600010]	Office of the Director of National Intelligence (ODNI); Intelligence Advanced Research Projects Activity (IARPA)	This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA 2014-14071600010. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purpose notwithstanding any copyright annotation thereon. Yue Wu and Tal Hassner contributed equally to this work.	Abdalmageed W., 2016, CORR, P1, DOI DOI 10.1109/WACV.2016.7477555; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442; Aubry M, 2015, IEEE I CONF COMP VIS, P2875, DOI 10.1109/ICCV.2015.329; Baltrusaitis T, 2014, LECT NOTES COMPUT SC, V8692, P593, DOI 10.1007/978-3-319-10593-2_39; Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54; Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23; Bishop CM, 2006, PATTERN RECOGNITION; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204; Cao X., 2014, INT J COMPUT VISION, V107; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; Demirkus M, 2015, COMPUT VIS IMAGE UND, V136, P128, DOI 10.1016/j.cviu.2015.03.005; Ding XY, 2013, IEEE I CONF COMP VIS, P2400, DOI 10.1109/ICCV.2013.298; Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646; Ghiasi G, 2014, PROC CVPR IEEE, P1899, DOI 10.1109/CVPR.2014.306; Hartley R., 2003, MULTIPLE VIEW GEOMET; HASSNER T, 2015, PROC CVPR IEEE, P4295, DOI DOI 10.1109/CVPR.2015.7299058; Hassner T, 2016, IEEE COMPUT SOC CONF, P127, DOI 10.1109/CVPRW.2016.23; Hassner T, 2013, IEEE I CONF COMP VIS, P3607, DOI 10.1109/ICCV.2013.448; Huang GB, 2007, 07 UMASS TR; ju Chang F., 2017, P IEEE INT C COMP VI; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; King DE, 2009, J MACH LEARN RES, V10, P1755; Kingma D.P, P 3 INT C LEARNING R; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352; LIANG Z, 2015, ARXIV150703409; Masi I., 2016, P EUR C COMPUT VIS; Masi I, 2017, IEEE INT CONF AUTOMA, P604, DOI 10.1109/FG.2017.76; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yang H, 2015, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2015.7299100; Yang H, 2015, CHEM ENG SCI, V130, P1, DOI 10.1016/j.ces.2015.03.006; YOSINSKI J, 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.1109/IJCNN.2016.7727519; Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244; Zadeh Amir, 2016, ARXIV161108657; Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1; Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	51	44	46	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					3067	3074		10.1109/TPAMI.2017.2787130	http://dx.doi.org/10.1109/TPAMI.2017.2787130			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL		Green Submitted			2022-12-18	WOS:000449355500021
J	Li, NY; Ye, JW; Ji, Y; Ling, HB; Yu, JY				Li, Nianyi; Ye, Jinwei; Ji, Yu; Ling, Haibin; Yu, Jingyi			Saliency Detection on Light Field	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Saliency detection; light field; Lytro; focus stack	OBJECT DETECTION	Existing saliency detection approaches use images as inputs and are sensitive to foreground/background similarities, complex background textures, and occlusions. We explore the problem of using light fields as input for saliency detection. Our technique is enabled by the availability of commercial plenoptic cameras that capture the light field of a scene in a single shot. We show that the unique refocusing capability of light fields provides useful focusness, depths, and objectness cues. We further develop a new saliency detection algorithm tailored for light fields. To validate our approach, we acquire a light field database of a range of indoor and outdoor scenes and generate the ground truth saliency map. Experiments show that our saliency detection scheme can robustly handle challenging scenarios such as similar foreground and background, cluttered background, complex occlusions, etc., and achieve high accuracy and robustness.	[Li, Nianyi; Ye, Jinwei; Ji, Yu; Yu, Jingyi] Univ Delaware, Newark, DE 19716 USA; [Ling, Haibin] Temple Univ, Philadelphia, PA 19122 USA	University of Delaware; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Li, NY (corresponding author), Univ Delaware, Newark, DE 19716 USA.	nianyi@eecis.udel.edu; jye@eecis.udel.edu; yuji@eecis.udel.edu; hbling@temple.edu; yuji@eecis.udel.edu			National Science Foundation [IIS-1218156]	National Science Foundation(National Science Foundation (NSF))	This research is supported by National Science Foundation Grant IIS-1218156. Jingyi Yu is the corresponding author.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; [Anonymous], 2006, NIPS; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309; Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Ciptadi A, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.112; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98; Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676; Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2006, VIS COGN, V14, P959, DOI 10.1080/13506280500195672; Kim C, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024224; Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8; Levoy M, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.270; Li F., 2013, ADV MECH ENG, V2013, P1, DOI DOI 10.1007/S00122-013-2049-1; Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Mai L, 2013, PROC CVPR IEEE, P1131, DOI 10.1109/CVPR.2013.150; Maki A, 2000, COMPUT VIS IMAGE UND, V78, P351, DOI 10.1006/cviu.2000.0840; Ng R., 2005, COMPUT SCI TECH REP, V2, P1; Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708; Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615; Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758; Suh B, 2003, P 16 ANN ACM S USER, P95, DOI [10.1145/964696.964707, DOI 10.1145/964696.964707]; Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240; Wanner S, 2013, PROC CVPR IEEE, P1011, DOI 10.1109/CVPR.2013.135; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Ye JW, 2014, VISUAL COMPUT, V30, P93, DOI 10.1007/s00371-013-0786-4; Zhai Y., 2006, VISUAL ATTENTION DET	44	44	47	5	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1605	1616		10.1109/TPAMI.2016.2610425	http://dx.doi.org/10.1109/TPAMI.2016.2610425			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	27654139	hybrid			2022-12-18	WOS:000404606300009
J	Li, PH; Wang, QL; Zeng, H; Zhang, L				Li, Peihua; Wang, Qilong; Zeng, Hui; Zhang, Lei			Local Log-Euclidean Multivariate Gaussian Descriptor and Its Application to Image Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image descriptors; space of Gaussians; Lie group; image classification	REPRESENTATION; DISTANCE; SCALE	This paper presents a novel image descriptor to effectively characterize the local, high-order image statistics. Our work is inspired by the Diffusion Tensor Imaging and the structure tensor method (or covariance descriptor), and motivated by popular distribution-based descriptors such as SIFT and HoG. Our idea is to associate one pixel with a multivariate Gaussian distribution estimated in the neighborhood. The challenge lies in that the space of Gaussians is not a linear space but a Riemannian manifold. We show, for the first time to our knowledge, that the space of Gaussians can be equipped with a Lie group structure by defining a multiplication operation on this manifold, and that it is isomorphic to a subgroup of the upper triangular matrix group. Furthermore, we propose methods to embed this matrix group in the linear space, which enables us to handle Gaussians with Euclidean operations rather than complicated Riemannian operations. The resulting descriptor, called Local Log-Euclidean Multivariate Gaussian (L(2)EMG) descriptor, works well with low-dimensional and high-dimensional raw features. Moreover, our descriptor is a continuous function of features without quantization, which can model the first-and second-order statistics. Extensive experiments were conducted to evaluate thoroughly L(2)EMG, and the results showed that L(2)EMG is very competitive with state-of-the-art descriptors in image classification.	[Li, Peihua; Wang, Qilong; Zeng, Hui] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian, Peoples R China; [Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China	Dalian University of Technology; Hong Kong Polytechnic University	Li, PH (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian, Peoples R China.	peihuali@dlut.edu.cn; qlwang@mail.dlut.edu.cn; zenghui118@mail.dlut.edu.cn; cslzhang@comp.polyu.edu.hk		Zeng, Hui/0000-0001-6862-6964; Zhang, Lei/0000-0002-2078-4215	National Natural Science Foundation of China [61471082]; Hong Kong RGC GRF grant [PolyU 5313/13E]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Hong Kong RGC GRF grant	This work was supported by the National Natural Science Foundation of China (61471082), and the Hong Kong RGC GRF grant (PolyU 5313/13E).	Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996; Baker A., 2002, MATRIX GROUPS INTRO; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91; CALVO M, 1990, J MULTIVARIATE ANAL, V35, P223, DOI 10.1016/0047-259X(90)90026-E; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155; Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Davies PI, 2003, SIAM J MATRIX ANAL A, V25, P464, DOI 10.1137/S0895479802410815; Donahue J, 2014, PR MACH LEARN RES, V32; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Feng Tang, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2631, DOI 10.1109/CVPRW.2009.5206550; Freeman W T, 1995, P INT WORKSH AUT FAC, P296; Gallier J. H., 2013, CORR; Griffin G., 2007, 120 CAL I TECHN; Gupta R, 2008, LECT NOTES COMPUT SC, V5303, P265, DOI 10.1007/978-3-540-88688-4_20; Hall B. C., 2003, LIE GROUPS LIE ALGEB, V222; HIGHAM NJ, 1986, SIAM J SCI STAT COMP, V7, P1160, DOI 10.1137/0907079; Horn RA, 1999, MATRIX ANAL; Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Ke Y, 2004, PROC CVPR IEEE, P506; Kincaid D, 2002, NUMERICAL ANAL MATH; Knutsson H., 1989, Proceedings of 6th Scandinavian Conference on Image Analysis, P244; Kobayashi T, 2014, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2014.413; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Le Bihan D, 2001, J MAGN RESON IMAGING, V13, P534, DOI 10.1002/jmri.1076; Li PH, 2013, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2013.212; Li PH, 2012, LECT NOTES COMPUT SC, V7574, P469, DOI 10.1007/978-3-642-33712-3_34; Li QN, 2013, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2013.115; Liyu Gong, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2366, DOI 10.1109/CVPRW.2009.5206506; Lopez-Valcarce R, 2001, IEEE T CIRCUITS-II, V48, P213, DOI 10.1109/82.917793; Lovric M, 2000, J MULTIVARIATE ANAL, V74, P36, DOI 10.1006/jmva.1999.1853; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma B., 2014, P AS C COMP VIS, P505; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Nakayama H, 2010, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2010.5539921; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Peng XJ, 2014, LECT NOTES COMPUT SC, V8691, P660, DOI 10.1007/978-3-319-10578-9_43; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Pratt WK, 2007, DIGITAL IMAGE PROCES, Vxix; Rao C.R., 1945, BULL CALCUTTA MATH S, V37, P81, DOI DOI 10.1007/978-1-4612-0919-5_15; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Serra G., 2013, P ACM INT C MULT, P709; Sharan L, 2010, J VISION, V9, P784; Sharan L, 2013, INT J COMPUT VISION, V103, P348, DOI 10.1007/s11263-013-0609-0; Sharma G, 2012, LECT NOTES COMPUT SC, V7578, P1, DOI 10.1007/978-3-642-33786-4_1; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; SKOVGAARD LT, 1984, SCAND J STAT, V11, P211; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Weichert J., 2006, VISUALIZATION IMAGE; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yuan JS, 2011, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2011.5995476; Zheng YB, 2012, LECT NOTES COMPUT SC, V7576, P172, DOI 10.1007/978-3-642-33715-4_13	67	44	47	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					803	817		10.1109/TPAMI.2016.2560816	http://dx.doi.org/10.1109/TPAMI.2016.2560816			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	28113542				2022-12-18	WOS:000397717600015
J	Lombaert, H; Grady, L; Polimeni, JR; Cheriet, F				Lombaert, Herve; Grady, Leo; Polimeni, Jonathan R.; Cheriet, Farida			FOCUSR: Feature Oriented Correspondence Using Spectral Regularization-A Method for Precise Surface Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Registration; surface fitting; spectral methods; graph theory	SHAPE-ANALYSIS; REGISTRATION; ALGORITHM; FRAMEWORK	Existing methods for surface matching are limited by the tradeoff between precision and computational efficiency. Here, we present an improved algorithm for dense vertex-to-vertex correspondence that uses direct matching of features defined on a surface and improves it by using spectral correspondence as a regularization. This algorithm has the speed of both feature matching and spectral matching while exhibiting greatly improved precision (distance errors of 1.4 percent). The method, FOCUSR, incorporates implicitly such additional features to calculate the correspondence and relies on the smoothness of the lowest-frequency harmonics of a graph Laplacian to spatially regularize the features. In its simplest form, FOCUSR is an improved spectral correspondence method that nonrigidly deforms spectral embeddings. We provide here a full realization of spectral correspondence where virtually any feature can be used as an additional information using weights on graph edges, but also on graph nodes and as extra embedded coordinates. As an example, the full power of FOCUSR is demonstrated in a real-case scenario with the challenging task of brain surface matching across several individuals. Our results show that combining features and regularizing them in a spectral embedding greatly improves the matching precision (to a submillimeter level) while performing at much greater speed than existing methods.	[Lombaert, Herve] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H2J 2K9, Canada; [Grady, Leo] HeartFlow Inc, R&D, Redwood City, CA USA; [Polimeni, Jonathan R.] Harvard Univ, Massachusetts Gen Hosp, Athinoula A Martinos Ctr Biomed Imaging, Sch Med,Dept Radiol, Charlestown, MA USA; [Cheriet, Farida] Ecole Polytech Montreal, Dept Comp Engn, Montreal, PQ, Canada	McGill University; Harvard University; Massachusetts General Hospital; Universite de Montreal; Polytechnique Montreal	Lombaert, H (corresponding author), McGill Univ, Ctr Intelligent Machines, 4239 Rue St Denis, Montreal, PQ H2J 2K9, Canada.		Polimeni, Jonathan R/P-1395-2014	Polimeni, Jonathan R/0000-0002-1348-1179	Alexander Graham Bell Canada Graduate Scholarships of the Natural Sciences and Engineering Research Council of Canada (NSERC); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [K01EB011498] Funding Source: NIH RePORTER	Alexander Graham Bell Canada Graduate Scholarships of the Natural Sciences and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	The authors would especially like to thank Bruce Fischl and Martin Reuter for their helpful comments, the anonymous reviewers for their valuable comments and suggestions, Gareth Funka-Lea for supporting this project, as well as the financial support from the Alexander Graham Bell Canada Graduate Scholarships of the Natural Sciences and Engineering Research Council of Canada (NSERC).	Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Anguelov D., 2004, ADV NEURAL INFORM PR, P33; Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396; Audette MA, 2000, MED IMAGE ANAL, V4, P201, DOI 10.1016/S1361-8415(00)00014-1; Bach F.R., 2004, P ADV NEUR INF PROC; Bengio Y., 2004, P ADV NEUR INF PROC; BESL PJ, 1988, P IEEE, V76, P936, DOI 10.1109/5.5966; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bronstein AM, 2007, IEEE T VIS COMPUT GR, V13, P902, DOI 10.1109/TVCG.2007.1041; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Cagniart C, 2010, LECT NOTES COMPUT SC, V6314, P326, DOI 10.1007/978-3-642-15561-1_24; Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7; Castellani U, 2011, IEEE T PATTERN ANAL, V33, P2555, DOI 10.1109/TPAMI.2011.85; Chan T., 1995, CSL9415 PARC; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Cohen-Steiner D, 2003, P 19 ANN S COMP GEOM, P312, DOI DOI 10.1145/777792.777839; Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576; Dubrovina A, 2011, ADV DATA SCI ADAPT, V3, P203, DOI 10.1142/S1793536911000829; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4; Fischl B, 2004, CEREB CORTEX, V14, P11, DOI 10.1093/cercor/bhg087; Fischl B, 2000, P NATL ACAD SCI USA, V97, P11050, DOI 10.1073/pnas.200033797; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Grady L.J., 2010, DISCRETE CALCULUS AP; Gu XF, 2004, IEEE T MED IMAGING, V23, P949, DOI 10.1109/TMI.2004.831226; Haehnel D., 2003, P INT C ART INT IJCA, V3, P915; Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806; Hinds OP, 2008, NEUROIMAGE, V39, P1585, DOI 10.1016/j.neuroimage.2007.10.033; Jain V, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P118; Kimmel R., 2010, P INT S 3D DAT PROC; Lin M. H., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P648, DOI 10.1109/ICCV.1999.791286; Lipman Y., 2009, P ACM SIGGRAPH; Lipman Y., 2011, P ACM SIGGRAPH; Liu R, 2009, COMPUT GRAPH FORUM, V28, P397, DOI 10.1111/j.1467-8659.2009.01379.x; Lohmann G, 2008, CEREB CORTEX, V18, P1415, DOI 10.1093/cercor/bhm174; Lombaert H., 2011, P 22 INT C INF PROC, P660; Mateus D., 2008, PROC CVPR IEEE, P1, DOI DOI 10.1109/CVPR.2008.4587538; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Niethammer M, 2007, LECT NOTES COMPUT SC, V4791, P850; Ovsjanikov M, 2010, COMPUT GRAPH FORUM, V29, P1555, DOI 10.1111/j.1467-8659.2010.01764.x; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; Qiu AQ, 2006, IEEE T MED IMAGING, V25, P1296, DOI 10.1109/TMI.2006.882143; Reuter M, 2010, INT J COMPUT VISION, V89, P287, DOI 10.1007/s11263-009-0278-1; Reuter M, 2009, COMPUT AIDED DESIGN, V41, P739, DOI 10.1016/j.cad.2009.02.007; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Schreiner J, 2004, ACM T GRAPHIC, V23, P870, DOI 10.1145/1015706.1015812; SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Sharma A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2481, DOI 10.1109/CVPR.2011.5995455; Shelton CR, 2000, INT J COMPUT VISION, V38, P75, DOI 10.1023/A:1008170818506; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shi YG, 2010, LECT NOTES COMPUT SC, V6363, P49; Shi YG, 2009, LECT NOTES COMPUT SC, V5762, P208; Shokoufandeh A, 2005, IEEE T PATTERN ANAL, V27, P1125, DOI 10.1109/TPAMI.2005.142; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Sprengel R, 1997, P IEEE EMBS, V18, P1190, DOI 10.1109/IEMBS.1996.652767; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x; Tevs A, 2009, PROC CVPR IEEE, P1185, DOI 10.1109/CVPRW.2009.5206775; Tung T, 2010, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2010.5539806; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x; Varanasi K, 2008, LECT NOTES COMPUT SC, V5303, P30, DOI 10.1007/978-3-540-88688-4_3; von Lavante E., 2010, P EUR WORKSH 3DOR; Wuhrer Stefanie, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1574, DOI 10.1109/ICCVW.2009.5457426; Yeo BTT, 2010, IEEE T MED IMAGING, V29, P1424, DOI 10.1109/TMI.2010.2049497; Zeng W, 2012, GRAPH MODELS, V74, P121, DOI 10.1016/j.gmod.2012.03.009; Zeng W, 2010, IEEE T PATTERN ANAL, V32, P662, DOI 10.1109/TPAMI.2009.201; Zhang H, 2008, COMPUT GRAPH FORUM, V27, P1431, DOI 10.1111/j.1467-8659.2008.01283.x; Zhang H, 2010, COMPUT GRAPH FORUM, V29, P1865, DOI 10.1111/j.1467-8659.2010.01655.x; Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81	74	44	45	1	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2143	2160		10.1109/TPAMI.2012.276	http://dx.doi.org/10.1109/TPAMI.2012.276			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868776	Green Accepted			2022-12-18	WOS:000322029000008
J	Lucey, S; Navarathna, R; Ashraf, AB; Sridharan, S				Lucey, Simon; Navarathna, Rajitha; Ashraf, Ahmed Bilal; Sridharan, Sridha			Fourier Lucas-Kanade Algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Lucas & Kanade (LK); Fourier domain; illumination invariance; active appearance model (AAM)	ACTIVE APPEARANCE MODELS; FACE RECOGNITION; TRACKING; ILLUMINATION	In this paper, we propose a framework for both gradient descent image and object alignment in the Fourier domain. Our method centers upon the classical Lucas & Kanade (LK) algorithm where we represent the source and template/ model in the complex 2D Fourier domain rather than in the spatial 2D domain. We refer to our approach as the Fourier LK (FLK) algorithm. The FLK formulation is advantageous when one preprocesses the source image and template/ model with a bank of filters (e. g., oriented edges, Gabor, etc.) as 1) it can handle substantial illumination variations, 2) the inefficient preprocessing filter bank step can be subsumed within the FLK algorithm as a sparse diagonal weighting matrix, 3) unlike traditional LK, the computational cost is invariant to the number of filters and as a result is far more efficient, and 4) this approach can be extended to the Inverse Compositional (IC) form of the LK algorithm where nearly all steps (including Fourier transform and filter bank preprocessing) can be precomputed, leading to an extremely efficient and robust approach to gradient descent image matching. Further, these computational savings translate to nonrigid object alignment tasks that are considered extensions of the LK algorithm, such as those found in Active Appearance Models (AAMs).	[Lucey, Simon] CSIRO, Brisbane, Qld 4069, Australia; [Navarathna, Rajitha; Sridharan, Sridha] Queensland Univ Technol, Speech Audio Image & Video Technol Lab, Brisbane, Qld 4001, Australia; [Ashraf, Ahmed Bilal] Univ Penn, Sch Med, Computat Breast Imaging Grp, Philadelphia, PA 19104 USA	Commonwealth Scientific & Industrial Research Organisation (CSIRO); Queensland University of Technology (QUT); University of Pennsylvania	Lucey, S (corresponding author), CSIRO, Brisbane, Qld 4069, Australia.	simon.lucey@csiro.au; r.navarathna@qut.edu.au; Ahmed.Ashraf@uphs.upenn.edu; s.sridharan@qut.edu.au	Lucey, Simon/HDO-1716-2022	Sridharan, Sridha/0000-0003-4316-9001	Australian Research Council [FT0991969]	Australian Research Council(Australian Research Council)	Dr. Simon Lucey is the recipient of an Australian Research Council Future Fellowship (project number FT0991969).	Ashraf AB, 2010, PROC CVPR IEEE, P2480, DOI 10.1109/CVPR.2010.5539948; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; BAKER S, 2001, P IEEE C COMP VIS PA; BAKER S, 2003, CMURITR0301; Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55; Bartlett MS, 2005, PROC CVPR IEEE, P568; BELHUMEUR P, 1996, P IEEE C COMP VIS PA; Black M., 1998, INT J COMPUT VISION, V36, P101; Cohn J.F., 2010, IEEE SIGNAL PROCESSI, V27; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Dowson N, 2008, IEEE T PATTERN ANAL, V30, P180, DOI 10.1109/TPAMI.2007.70757; Evangelidis GD, 2008, IEEE T PATTERN ANAL, V30, P1858, DOI 10.1109/TPAMI.2008.113; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; Gross R, 2003, LECT NOTES COMPUT SC, V2688, P10; Gross Ralph, 2008, P IEEE INT C AUT FAC; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Lee B., 2004, PROC 8 INT C SPOKEN, P2489; Li ZF, 2009, IEEE T PATTERN ANAL, V31, P755, DOI 10.1109/TPAMI.2008.174; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; LIU X, [No title captured]; Lucas BD, 1981, P INT JOINT C ART IN, V3, P674; Lucey S., 2008, P IEEE C COMP VIS PA; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Navarathna R., 2011, P IEEE INT C COMP VI; Nawab S.H., 1996, SIGNALS SYSTEMS, V2; NGUYEN MH, 2008, P IEEE C COMP VIS PA; Theobald BJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P149; Tzimiropoulos G., 2011, P IEEE INT C COMP VI; Wiskott C., 1997, IEEE T PATTERN ANAL, V19, P775	31	44	48	0	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1383	1396		10.1109/TPAMI.2012.220	http://dx.doi.org/10.1109/TPAMI.2012.220			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599053	Green Submitted			2022-12-18	WOS:000317857900009
J	Basri, R; Hassner, T; Zelnik-Manor, L				Basri, Ronen; Hassner, Tal; Zelnik-Manor, Lihi			Approximate Nearest Subspace Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Approximate nearest neighbor search techniques; subspace representations	FACE RECOGNITION; ILLUMINATION; NEIGHBOR; MOTION; SHAPE	Subspaces offer convenient means of representing information in many pattern recognition, machine vision, and statistical learning applications. Contrary to the growing popularity of subspace representations, the problem of efficiently searching through large subspace databases has received little attention in the past. In this paper, we present a general solution to the problem of Approximate Nearest Subspace search. Our solution uniformly handles cases where the queries are points or subspaces, where query and database elements differ in dimensionality, and where the database contains subspaces of different dimensions. To this end, we present a simple mapping from subspaces to points, thus reducing the problem to the well-studied Approximate Nearest Neighbor problem on points. We provide theoretical proofs of correctness and error bounds of our construction and demonstrate its capabilities on synthetic and real data. Our experiments indicate that an approximate nearest subspace can be located significantly faster than the nearest subspace, with little loss of accuracy.	[Basri, Ronen] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel; [Hassner, Tal] Open Univ Israel, Div Comp Sci, IL-43107 Raanana, Israel; [Zelnik-Manor, Lihi] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	Weizmann Institute of Science; Open University Israel; Technion Israel Institute of Technology	Basri, R (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, Ziskind Bldg,Room 227, IL-76100 Rehovot, Israel.	ronen.basri@weizmann.ac.il; hassner@openu.ac.il; lihi@ee.technion.ac.il			Moross Foundation;  [IRG-208529]	Moross Foundation; 	The research of Lihi Zelnik-Manor is supported by Marie Curie IRG-208529. The vision group at the Weizmann Institute is supported in part by the Moross Foundation. This research was performed partly while Ronen Basri was at the Toyota Technological Institute at Chicago. This manuscript contains results that have previously appeared in the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2007) [5] and the Proceedings of the International Workshop on Subspace Methods at the IEEE International Conference on Computer Vision (ICCV) (2009) [6]. Author names in alphabetical order due to equal contribution.	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Andoni A, 2009, PROCEEDINGS OF THE TWENTIETH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P293; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; BASRI R, 2007, P IEEE C COMP VIS PA; BASRI R, 2009, P IEEE INT WORKSH SU; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BOIMAN O, 2006, P NEURAL INFORM PROC, V19, P177; Borenstein E, 2004, LECT NOTES COMPUT SC, V3023, P315; Brand M, 2001, PROC CVPR IEEE, P456; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Charikar M, 2002, LECT NOTES COMPUT SC, V2380, P451; Datar M., 2004, P 20 ANN S COMP GEOM, P253; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Fei-Fei L., 2005, 2005 IEEE COMP SOC C; Fitzgibbon AW, 2003, PROC CVPR IEEE, P26; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; HASSNER T, 2006, P PATCH WORKSH IEEE; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Indyk P, 2007, ACM T ALGORITHMS, V3, DOI 10.1145/1273340.1273347; IRANI M, 2000, P 6 EUR C COMP VIS J, V1, P539; Johnson W. B., 1984, CONT MATH, V26, P189, DOI DOI 10.1090/CONM/026/737400; Liu T., 2004, NIPS 2004, P825; Magen A., 2002, Randomization and Approximation Techniques in Computer Science. 6th International Workshop, RANDOM 2002. Proceedings (Lecture Notes in Computer Science Vol.2483), P239; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448; Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119; SIMARD P, 1998, NEURAL NETWORKS TRIC, P227; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2001, PROC CVPR IEEE, P493; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968; Yianilos PN, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P361; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]	39	44	45	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					266	278		10.1109/TPAMI.2010.110	http://dx.doi.org/10.1109/TPAMI.2010.110			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	20513927				2022-12-18	WOS:000285313200005
J	Gorczowski, K; Styner, M; Jeong, JY; Marron, JS; Piven, J; Hazlett, HC; Pizer, SM; Gerig, G				Gorczowski, Kevin; Styner, Martin; Jeong, Ja Yeon; Marron, J. S.; Piven, Joseph; Hazlett, Heather Cody; Pizer, Stephen M.; Gerig, Guido			Multi-Object Analysis of Volume, Pose, and Shape Using Statistical Discrimination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape; size and shape; shape analysis	CAUDATE-NUCLEUS; SEGMENTATION; LEVEL; MRI; SCHIZOPHRENIA; HIPPOCAMPUS	One goal of statistical shape analysis is the discrimination between two populations of objects. Whereas traditional shape analysis was mostly concerned with single objects, analysis of multi-object complexes presents new challenges related to alignment and pose. In this paper, we present a methodology for discriminant analysis of multiple objects represented by sampled medial manifolds. Non-euclidean metrics that describe geodesic distances between sets of sampled representations are used for alignment and discrimination. Our choice of discriminant method is the distance-weighted discriminant because of its generalization ability in high-dimensional, low sample size settings. Using an unbiased, soft discrimination score, we associate a statistical hypothesis test with the discrimination results. We explore the effectiveness of different choices of features as input to the discriminant analysis, using measures like volume, pose, shape, and the combination of pose and shape. Our method is applied to a longitudinal pediatric autism study with 10 subcortical brain structures in a population of 70 subjects. It is shown that the choices of type of global alignment and of intrinsic versus extrinsic shape features, the latter being sensitive to relative pose, are crucial factors for group discrimination and also for explaining the nature of shape change in terms of the application domain.	[Gorczowski, Kevin; Styner, Martin; Jeong, Ja Yeon; Pizer, Stephen M.] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA; [Styner, Martin; Piven, Joseph; Hazlett, Heather Cody] Univ N Carolina, Dept Psychiat, Chapel Hill, NC 27599 USA; [Marron, J. S.] Univ N Carolina, Dept Stat & Operat Res, Chapel Hill, NC 27599 USA; [Gerig, Guido] Univ Utah, Sci Comp & Imaging Inst SCI, Salt Lake City, UT 84112 USA	University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill; Utah System of Higher Education; University of Utah	Gorczowski, K (corresponding author), Univ N Carolina, Dept Comp Sci, CB 3175, Chapel Hill, NC 27599 USA.	kgorcz@unc.edu; styner@cs.unc.edu; jjeong@email.unc.edu; marron@email.unc.edu; jpiven@med.unc.edu; hcody@med.unc.edu; smp@cs.unc.edu; gerig@sci.utah.edu	Styner, Martin/AAS-9949-2020	Styner, Martin/0000-0002-8747-5118; Gerig, Guido/0000-0002-9547-6233	NIH NIBIB [P01 EB002779]; NIH Conte Center [MH064065]; UNC Neurodevelopmental Research Core NDRC; NIH [RO1 MH61696]; NIMH [MH64580]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENT [P30HD003110] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [P01EB002779] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF MENTAL HEALTH [P50MH064065, R01MH061696, R01MH064580] Funding Source: NIH RePORTER	NIH NIBIB(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NIH Conte Center(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); UNC Neurodevelopmental Research Core NDRC; NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NIMH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH)); EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENT(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child Health & Human Development (NICHD)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL INSTITUTE OF MENTAL HEALTH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH))	This research is supported by the NIH NIBIB grant P01 EB002779, the NIH Conte Center MH064065, and the UNC Neurodevelopmental Research Core NDRC. The MRI images of infants and expert manual segmentations are funded by NIH RO1 MH61696 and NIMH MH64580.	BOOKSTEIN F, 1996, P WORKSH MATH METH B; BOSSA MN, 2006, P 2006 IEEE C COMP V, P59; Bouix S, 2005, NEUROIMAGE, V25, P1077, DOI 10.1016/j.neuroimage.2004.12.051; Csernansky JG, 1998, P NATL ACAD SCI USA, V95, P11406, DOI 10.1073/pnas.95.19.11406; Dager SR, 2007, AM J NEURORADIOL, V28, P672; Davatzikos C, 1996, J COMPUT ASSIST TOMO, V20, P88, DOI 10.1097/00004728-199601000-00017; Dryden I., 1998, STAT SHAPE ANAL; Dryden I.L., 1993, INDIAN J STAT A, P460; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; Gerig G., 2001, P MICCAI, V2208, P24, DOI DOI 10.1007/3-540-45468-3_4; Golland P, 2005, MED IMAGE ANAL, V9, P69, DOI 10.1016/j.media.2004.07.003; GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x; Hazlett HC, 2006, BIOL PSYCHIAT, V59, P1, DOI 10.1016/j.biopsych.2005.06.015; Juranek J, 2006, J CHILD NEUROL, V21, P1051, DOI 10.1177/7010.2006.00237; Keefe RSE, 2006, BIOL PSYCHIAT, V59, P97, DOI 10.1016/j.biopsych.2005.06.022; Kelemen A, 1999, IEEE T MED IMAGING, V18, P828, DOI 10.1109/42.811260; Langen M, 2007, BIOL PSYCHIAT, V62, P262, DOI 10.1016/j.biopsych.2006.09.040; Levitt JJ, 2002, AM J PSYCHIAT, V159, P1190, DOI 10.1176/appi.ajp.159.7.1190; Litvin A, 2005, LECT NOTES COMPUT SC, V3565, P345; Marron JS, 2007, J AM STAT ASSOC, V102, P1267, DOI 10.1198/016214507000001120; McCarley RW, 1999, BIOL PSYCHIAT, V45, P1099, DOI 10.1016/S0006-3223(99)00018-9; Munson J, 2006, ARCH GEN PSYCHIAT, V63, P686, DOI 10.1001/archpsyc.63.6.686; Pizer SM, 2005, MED PHYS, V32, P1335, DOI 10.1118/1.1869872; Pizer SM, 2003, INT J COMPUT VISION, V55, P85, DOI 10.1023/A:1026313132218; Pizer SM, 1999, IEEE T MED IMAGING, V18, P851, DOI 10.1109/42.811263; Sen SK, 2008, I S BIOMED IMAGING, P1195, DOI 10.1109/ISBI.2008.4541216; Small C.G., 1996, STAT THEORY SHAPE; STAIB LH, 1996, IEEE T MED IMAGING, V15, P1; Styner M, 2005, P NATL ACAD SCI USA, V102, P4872, DOI 10.1073/pnas.0501117102; Styner M, 2004, MED IMAGE ANAL, V8, P197, DOI 10.1016/j.media.2004.06.004; Styner M, 2003, MED IMAGE ANAL, V7, P207, DOI 10.1016/S1361-8415(02)00110-X; Styner M, 2006, LECT NOTES COMPUT SC, V4091, P1; Thompson PM, 2000, NATURE, V404, P190, DOI 10.1038/35004593; THOMPSON PM, 2000, BRAIN MAPPING DISORD; THOMSON D, 1942, GROWTH FORM; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355; Yushkevich P., 2001, Information Processing in Medical Imaging. 17th International Conference, IPMI 2001. Proceedings (Lecture Notes in Computer Science Vol.2082), P402	39	44	44	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					652	661		10.1109/TPAMI.2009.92	http://dx.doi.org/10.1109/TPAMI.2009.92			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224121	Green Accepted, Green Submitted			2022-12-18	WOS:000274548800007
J	Kumar, MP; Torr, PHS; Zisserman, A				Kumar, M. Pawan; Torr, P. H. S.; Zisserman, A.			OBJCUT: Efficient Segmentation Using Top-Down and Bottom-Up Cues	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object category specific segmentation; conditional random fields; generalized EM; graph cuts		We present a probabilistic method for segmenting instances of a particular object category within an image. Our approach overcomes the deficiencies of previous segmentation techniques based on traditional grid conditional random fields (CRF), namely that 1) they require the user to provide seed pixels for the foreground and the background and 2) they provide a poor prior for specific shapes due to the small neighborhood size of grid CRF. Specifically, we automatically obtain the pose of the object in a given image instead of relying on manual interaction. Furthermore, we employ a probabilistic model which includes shape potentials for the object to incorporate top-down information that is global across the image, in addition to the grid clique potentials which provide the bottom-up information used in previous approaches. The shape potentials are provided by the pose of the object obtained using an object category model. We represent articulated object categories using a novel layered pictorial structures model. Nonarticulated object categories are modeled using a set of exemplars. These object category models have the advantage that they can handle large intraclass shape, appearance, and spatial variation. We develop an efficient method, OBJCUT, to obtain segmentations using our probabilistic framework. Novel aspects of this method include: 1) efficient algorithms for sampling the object category models of our choice and 2) the observation that a sampling-based approximation of the expected log-likelihood of the model can be increased by a single graph cut. Results are presented on several articulated (e. g., animals) and nonarticulated (e. g., fruits) object categories. We provide a favorable comparison of our method with the state of the art in object category specific image segmentation, specifically the methods of Leibe and Schiele and Schoenemann and Cremers.	[Kumar, M. Pawan] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Zisserman, A.] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England; [Torr, P. H. S.] Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England	Stanford University; University of Oxford; Oxford Brookes University	Kumar, MP (corresponding author), Stanford Univ, Dept Comp Sci, Serra Mall, Stanford, CA 94305 USA.	pawan@cs.stanford.edu; philiptorr@brookes.ox.ac.uk; az@robots.ox.ac.uk			EU; EPSRC [EP/C006631/1(P)]; Royal Society; Wolfson Foundation; Microsoft Research; Royal Academy of Engineering; EU [228180]	EU(European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Royal Society(Royal Society of London); Wolfson Foundation; Microsoft Research(Microsoft); Royal Academy of Engineering(Royal Academy of Engineering - UK); EU(European Commission)	M. Pawan Kumar was funded by the EU CLASS project and by the EPSRC grant EP/C006631/1(P). Philip H. S. Torr is in receipt of the Royal Society Wolfson Research Merit Award and would like to acknowledge support from the Royal Society and Wolfson Foundation. Andrew Zisserman thanks Microsoft Research, the Royal Academy of Engineering, and the EU under ERC grant VisRec no. 228180 for support. This work was performed while M. Pawan Kumar was at the University of Oxford.	Agarwal A., 2004, P EUR C COMP VIS, V3, P54; BLAKE A, 2004, P ECCV, V1, P428; BORENSTEIN E, 2002, P EUR C COMP VIS ECC, V2, P109; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Coughlan J, 1998, PROC CVPR IEEE, P747, DOI 10.1109/CVPR.1998.698687; Cremers D, 2006, INT J COMPUT VISION, V66, P67, DOI 10.1007/s11263-005-3676-z; Felzenszwalb PF, 2003, PROC CVPR IEEE, P102; Felzenszwalb PF, 2000, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.2000.854739; FELZENSZWALB PF, 2003, P ADV NEUR INF PROC; Fergus R, 2003, PROC CVPR IEEE, P264; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Freedman D, 2005, PROC CVPR IEEE, P755; GAVRILA DM, 2000, P EUR C COMP VIS, P37; Gelman A, 2013, BAYESIAN DATA ANAL, P16; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Goldstein J, 2005, LECT NOTES ARTIF INT, V3635, P137, DOI 10.1007/11559887_9; HAMMER PL, 1965, OPER RES, V13, P388; Huang R, 2004, PROC CVPR IEEE, P739; KOHLI P, 2007, P IEEE C COMP VIS PA; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kumar MP, 2008, INT J COMPUT VISION, V76, P301, DOI 10.1007/s11263-007-0064-x; Kumar MP, 2005, PROC CVPR IEEE, P18; Kumar P.M., 2004, P BRIT MACH VIS C, P789; Lafferty J., 2001, CONDITIONAL RANDOM F; LEIBE B, 2003, P BRIT MACH VIS C, V2, P264; LEVIN A, 2006, P EUR C COMP VIS, V4, P581; Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560; OPELT A, 2006, P IEEE C COMP VIS PA, V1, P3; PRASAD M, 2006, P IND C COMP VIS GRA; Ramanan D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P338; RAMANAN D, 2007, P IEEE C COMP VIS PA; RIHAN J, 2006, P IND C COMP VIS GRA; ROTHER C, 2004, P ACM SIGGRAPH, P309; Schoenemann T., 2007, P IEEE INT C COMP VI; SCHOENEMANN T, 2008, P IEEE C COMP VIS PA; Shotton J, 2005, IEEE I CONF COMP VIS, P503; SHOTTON J, 2006, P EUR C COMP VIS, V1, P1, DOI DOI 10.1007/11744023_; STENGER B, 2004, P INT WORKSH HUM COM, P105; Thayananthan A, 2003, PROC CVPR IEEE, P127; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Toyama K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P50, DOI 10.1109/ICCV.2001.937599; Varma M, 2003, PROC CVPR IEEE, P691; Winn J, 2005, IEEE I CONF COMP VIS, P756; Winn J., 2006, CVPR; YEDIDIA J, 2001, TR200116 MERL	46	44	48	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2010	32	3					530	545		10.1109/TPAMI.2009.16	http://dx.doi.org/10.1109/TPAMI.2009.16			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	543WG	20075476				2022-12-18	WOS:000273609600010
J	Leichter, I; Lindenbaum, M; Rivlin, E				Leichter, Ido; Lindenbaum, Michael; Rivlin, Ehud			Tracking by Affine Kernel Transformations Using Color and Boundary Cues	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; kernel-based tracking	VISUAL TRACKING	Kernel-based trackers aggregate image features within the support of a kernel (a mask) independently of their spatial structure. These trackers spatially fit the kernel (usually in location and in scale) such that a function of the aggregate is optimized. We propose a kernel-based visual tracker that exploits the constancy of color and the presence of color edges along the target boundary. The tracker estimates the best affinity of a spatially aligned pair of kernels, one of which is color related and the other of which is object boundary related. In a sense, this work extends previous kernel-based trackers by incorporating the object boundary cue into the tracking process and by allowing the kernels to be affinely transformed instead of only translated and isotropically scaled. These two extensions make for more precise target localization. A more accurately localized target also facilitates safer updating of its reference color model, further enhancing the tracker's robustness. The improved tracking is demonstrated for several challenging image sequences.	[Leichter, Ido; Lindenbaum, Michael; Rivlin, Ehud] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Leichter, I (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	idol@cs.technion.ac.il; mic@cs.technion.ac.il; ehudr@cs.technion.ac.il						BERGEN JR, 1992, P EUR C COMP VIS, P237; Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614; BRADSKI G, 1983, INTEL TECHNOLOGY J Q, V2; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Collins RT, 2003, PROC CVPR IEEE, P234; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Elgammal A, 2003, PROC CVPR IEEE, P781; Fan ZM, 2005, PROC CVPR IEEE, P502; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hager GD, 2004, PROC CVPR IEEE, P790; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; LEICHTER I, 2007, P 11 IEEE INT C COMP; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; MCKENNA S, 1997, P BRIT MACH VIS C, P140; McKenna SJ, 1999, IMAGE VISION COMPUT, V17, P225, DOI 10.1016/S0262-8856(98)00104-8; OKUMA K, 2004, P EUR C COMP VIS, P28; Peng NS, 2005, PATTERN RECOGN LETT, V26, P605, DOI 10.1016/j.patrec.2004.08.023; Perez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Wu Y, 2004, INT J COMPUT VISION, V58, P55, DOI 10.1023/B:VISI.0000016147.97880.cd; Yang C, 2005, PROC CVPR IEEE, P176; Yang CJ, 2005, IEEE I CONF COMP VIS, P212; Zhang HH, 2005, PROC CVPR IEEE, P293	26	44	51	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					164	171		10.1109/TPAMI.2008.194	http://dx.doi.org/10.1109/TPAMI.2008.194			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029554				2022-12-18	WOS:000260889700014
J	Sukno, FM; Ordas, S; Butakoff, C; Cruz, S; Frangi, AF				Sukno, Federico M.; Ordas, Sebastian; Butakoff, Constantine; Cruz, Santiago; Frangi, Alejandro F.			Active shape models with invariant optimal features: Application to facial analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face and gesture recognition; feature evaluation and selection; invariants; shape model; statistical image analysis	RECOGNITION; SEGMENTATION; IMAGES	This work is framed in the field of statistical face analysis. In particular, the problem of accurate segmentation of prominent features of the face in frontal view images is addressed. We propose a method that generalizes linear Active Shape Models (ASMs), which have already been used for this task. The technique is built upon the development of a nonlinear intensity model, incorporating a reduced set of differential invariant features as local image descriptors. These features are invariant to rigid transformations, and a subset of them is chosen by Sequential Feature Selection for each landmark and resolution level. The new approach overcomes the unimodality and Gaussianity assumptions of classical ASMs regarding the distribution of the intensity values across the training set. Our methodology has demonstrated a significant improvement in segmentation precision as compared to the linear ASM and Optimal Features ASM ( a nonlinear extension of the pioneer algorithm) in the tests performed on AR, XM2VTS, and EQUINOX databases.	Pompeu Fabra Univ, Dept Technol, Barcelona 08003, Spain; Univ Zaragoza, Aragon Inst Engn Res, Zaragoza 50018, Spain	Pompeu Fabra University; University of Zaragoza	Sukno, FM (corresponding author), Pompeu Fabra Univ, Dept Technol, Passeig Circumvallacio 8, Barcelona 08003, Spain.	federico.sukno@upf.edu; sebastian.ordas@upf.edu; constantine.butakoff@upf.edu; cruzll@unizar.es; alejandro.frangi@upf.edu	Butakoff, Constantine/E-8644-2016; Sukno, Federico/AAM-4440-2021; Frangi, Alejandro F/C-6500-2008; Butakoff, Constantine/A-1904-2009	Butakoff, Constantine/0000-0002-8526-5045; Sukno, Federico/0000-0002-2029-1576; Frangi, Alejandro F/0000-0002-2675-528X; Butakoff, Constantine/0000-0002-8526-5045				AIZENBERG I, 2002, SPIE P IM PROC ALG S, P460; Aizenberg I., 2000, MULTIVALUED UNIVERSA; ALPAYDIN E, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P29, DOI 10.1109/ICPR.1992.201715; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Bengio S., 2004, SPEAK LANG REC WORKS, P237; Bolle RM, 2004, COMPUT VIS IMAGE UND, V93, P1, DOI 10.1016/j.cviu.2003.08.002; Cootes T. F., 2000, STAT MODELS APPEARAN; COOTES TF, 1999, P BRIT MACH VIS C, V1, P173; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Cristinacce D, 2004, P 6 IEEE INT C AUT F; Demirel H, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P277, DOI 10.1109/AFGR.1996.557277; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; FLORACK L, 2001, THESIS UTRECHT U UTR; Huber P., 1981, ROBUST STAT; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231; Li K. P., 1998, P IEEE INT C AC SPEE, V1, P595; Liew AWC, 2003, IEEE T FUZZY SYST, V11, P542, DOI 10.1109/TFUZZ.2003.814843; Martinez A.M., 1998, AR FACE DATABASE TEC; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; MESSER K, 2003, P 4 INT C AUD VID BA; NORDSTOM MM, 2004, IMM FACE DATABASE AN; Perlibakas V, 2004, PATTERN RECOGN LETT, V25, P711, DOI 10.1016/j.patrec.2004.01.011; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Scott IM, 2003, LECT NOTES COMPUT SC, V2732, P258; Selinger A., 2002, 0201 EQ CORP; Sukno F, 2005, LECT NOTES COMPUT SC, V3546, P365; SUKNO F, 2005, P SPIE BIOM TECHN HU, V2, P152; TAMMINEN T, 2004, P BRIT MACH VIS C; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121; WALKER KN, 1997, P BRIT MACHINE VISIO, V1, P540; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; [No title captured]	36	44	49	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1105	1117		10.1109/TPAMI.2007.1041	http://dx.doi.org/10.1109/TPAMI.2007.1041			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496371				2022-12-18	WOS:000246395300001
J	Pattichis, MS; Bovik, AC				Pattichis, Marios S.; Bovik, Alan C.			Analyzing image structure by multidimensional frequency modulation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						theory and models; image processing and computer vision; image models	2-DIMENSIONAL FRINGE PATTERNS; NATURAL DEMODULATION; PHASE; SEPARATION; AMPLITUDE; SIGNAL	We develop a mathematical framework for quantifying and understanding multidimensional frequency modulations in digital images. We begin with the widely accepted definition of the instantaneous frequency vector ( IF) as the gradient of the phase and define the instantaneous frequency gradient tensor ( IFGT) as the tensor of component derivatives of the IF vector. Frequency modulation bounds are derived and interpreted in terms of the eigendecomposition of the IFGT. Using the IFGT, we derive the ordinary differential equations ( ODEs) that describe image flowlines. We study the diagonalization of the ODEs of multidimensional frequency modulation on the IFGT eigenvector coordinate system and suggest that separable transforms can be computed along these coordinates. We illustrate these new methods of image pattern analysis on textured and fingerprint images. We envision that this work will find value in applications involving the analysis of image textures that are nonstationary yet exhibit local regularity. Examples of such textures abound in nature.	Univ New Mexico, Dept Elect Engn & Comp Engn, Albuquerque, NM 87131 USA; Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA	University of New Mexico; University of Texas System; University of Texas Austin	Pattichis, MS (corresponding author), Univ New Mexico, Dept Elect Engn & Comp Engn, MSC01 1100,ECE Bldg,Room 229A, Albuquerque, NM 87131 USA.	pattichis@ece.unm.edu; bovik@ece.utexas.edu	Pattichis, Marios/ABG-8325-2021; Bovik, Alan/B-6717-2012	Pattichis, Marios/0000-0002-1574-1827; Bovik, Alan/0000-0001-6067-710X				Acton ST, 2001, IEEE T IMAGE PROCESS, V10, P885, DOI 10.1109/83.923285; Aris R., 1962, VECTORS TENSORS BASI; Baxter R. A., 1999, Proceedings of the 1999 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics. WASPAA'99 (Cat. No.99TH8452), P227, DOI 10.1109/ASPAA.1999.810891; Bellman R E, 1995, INTRO MATRIX ANAL; BOGACKI P, 1989, APPL MATH LETT, V2, P1; BOVIK AC, 1992, IEEE T INFORM THEORY, V38, P691, DOI 10.1109/18.119731; Bovik AC, 1997, IEEE T SIGNAL PROCES, V45, P867, DOI 10.1109/78.564175; BOVIK AC, 1993, IEEE T SIGNAL PROCES, V41, P3245, DOI 10.1109/78.258071; Boyce W.E., 2012, ELEMENTARY DIFFERENT, V10th; Bulow T, 2001, IEEE T SIGNAL PROCES, V49, P2844, DOI 10.1109/78.960432; DIMITRADIAS D, 2003, P EUR C SPEECH COMM; DIMITRADIAS D, 2001, P IEEE C AC SPEECH S; Dormand J.R., 1980, J COMPUT APPL MATH, V6, P19, DOI [10.1016/0771-050X(80)90013-3, DOI 10.1016/0771-050X(80)90013-3]; Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520; FELSBERG M, 2005, P SCAL SPAC C; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; Girolami G, 2002, MEAS SCI TECHNOL, V13, P909, DOI 10.1088/0957-0233/13/6/312; Guillemin V., 2010, DIFFERENTIAL TOPOLOG, V370; HAHN SL, 2002, 3 WARS U TECHN I RAD; Havlicek JP, 2000, IEEE T IMAGE PROCESS, V9, P227, DOI 10.1109/83.821736; HAVLICEK JP, 1996, THESIS U TEXAS AUSTI; HAVLICEK JP, 2003, P 37 IEEE AS C SIGN; KAISER JF, 1990, INT CONF ACOUST SPEE, P381, DOI 10.1109/ICASSP.1990.115702; KNUTSSON H, 1994, IEEE IMAGE PROC, P36, DOI 10.1109/ICIP.1994.413270; KOENDERINK JJ, 1993, SPIE, V2031, P2; Kothe U, 2005, LECT NOTES COMPUT SC, V3459, P179; Larkin KG, 2005, OPT EXPRESS, V13, P8097, DOI 10.1364/OPEX.13.008097; Larkin KG, 2001, J OPT SOC AM A, V18, P1862, DOI 10.1364/JOSAA.18.001862; Larkin KG, 2001, J OPT SOC AM A, V18, P1871, DOI 10.1364/JOSAA.18.001871; MARAGOS P, 1993, IEEE T SIGNAL PROCES, V41, P3024, DOI 10.1109/78.277799; MARAGOS P, 1995, J OPT SOC AM A, V12, P1867, DOI 10.1364/JOSAA.12.001867; MARAGOS P, 1993, IEEE T SIGNAL PROCES, V41, P1532, DOI 10.1109/78.212729; Marsden J., 2003, VECTOR CALCULUS, P1; Morelande MR, 2002, IEEE T SIGNAL PROCES, V50, P578, DOI 10.1109/78.984741; Morse M., 1969, CRITICAL POINT THEOR; NACKMAN LR, 1984, IEEE T PATTERN ANAL, V6, P442, DOI 10.1109/TPAMI.1984.4767549; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; Pai WC, 2000, IEEE T SIGNAL PROCES, V48, P2300, DOI 10.1109/78.852011; Pattichis MS, 2001, IEEE T IMAGE PROCESS, V10, P951, DOI 10.1109/83.923291; Pattichis MS, 2000, IEEE T MED IMAGING, V19, P1253, DOI 10.1109/42.897818; PENROSE R, 1979, ANN HUM GENET, V42, P435, DOI 10.1111/j.1469-1809.1979.tb00677.x; Ray N, 2001, IEEE IMAGE PROC, P78, DOI 10.1109/ICIP.2001.958957; Rodriguez PV, 2003, P ANN INT IEEE EMBS, V25, P1176, DOI 10.1109/IEMBS.2003.1279459; Santhanam B, 2004, IEEE SIGNAL PROC LET, V11, P341, DOI 10.1109/LSP.2003.822902; Santhanam B, 2000, IEEE T COMMUN, V48, P473, DOI 10.1109/26.837050; Shampine LF, 1997, SIAM J SCI COMPUT, V18, P1, DOI 10.1137/S1064827594276424; STEGER C, 1999, P 7 ICCV, V2, P884; Strang G., 1988, LINEAR ALGEBRA APPL, V3rd; SUPER BJ, 1995, IEEE T PATTERN ANAL, V17, P333, DOI 10.1109/34.385983; YAP T, 2001, P 35 AS C SIGN SYST, V2, P1156	50	44	44	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					753	766		10.1109/TPAMI.2007.1051	http://dx.doi.org/10.1109/TPAMI.2007.1051			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356197	Green Submitted			2022-12-18	WOS:000244855700001
J	Foulonneau, A; Charbonnier, P; Heitz, F				Foulonneau, Alban; Charbonnier, Pierre; Heitz, Fabrice			Affine-invariant geometric shape priors for region-based active contours	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; active contours; region-based approach; Legendre moments; shape constraint; shape derivative; affine invariance	IMAGE; SEGMENTATION	We present a new way of constraining the evolution of a region- based active contour with respect to a reference shape. Minimizing a shape prior, defined as a distance between shape descriptors based on the Legendre moments of the characteristic function, leads to a geometric flow that can be used with benefits in a two- class segmentation application. The shape model includes intrinsic invariance with regard to pose and affine deformations.	Lab Reg Ponts & Chaussees Strasbourg, F-67035 Strasbourg, France; Univ Strasbourg 1, CNRS, UMR 7005, Lab Sci Image Informat & Teledetect, F-67400 Illkirch Graffenstaden, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universites de Strasbourg Etablissements Associes; Universite de Strasbourg	Foulonneau, A (corresponding author), Lab Reg Ponts & Chaussees Strasbourg, 11 Rue Jean Mentelin,BP 9, F-67035 Strasbourg, France.	alban.foulonneau@equipement.gouv.fr; pierre.charbonnier@equipement.gouv.fr; fabrice.heitz@ensps.u-strasbg.fr	HEITZ, Fabrice/R-4100-2017; Charbonnier, Pierre/H-4037-2016	HEITZ, Fabrice/0000-0002-3004-0957; Charbonnier, Pierre/0000-0002-9374-5647				Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Cremers D, 2004, LECT NOTES COMPUT SC, V3175, P36; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; Foulonneau A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P413; FOULONNEAU A, 2005, RRAF012005; Grenander U., 1991, HANDS PATTERN THEORE; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; MCINERNEY T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P840, DOI 10.1109/ICCV.1995.466850; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PEI SC, 1995, IMAGE VISION COMPUT, V13, P711, DOI 10.1016/0262-8856(95)98753-G; Precioso F, 2002, EURASIP J APPL SIG P, V2002, P555, DOI 10.1155/S1110865702203121; RIKLINRAVIV T, 2004, P ECCV, P50; ROUSSON M, 2002, P EUR C COMP VIS, P78; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355	18	44	44	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1352	1357		10.1109/TPAMI.2006.154	http://dx.doi.org/10.1109/TPAMI.2006.154			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886870				2022-12-18	WOS:000238162400016
J	Narasimhan, SG; Nayar, SK				Narasimhan, SG; Nayar, SK			Enhancing resolution along multiple imaging dimensions using assorted pixels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image formation; multisampling; dynamic range; color; resolution; interpolation; structural models; learning; Bayer pattern		Multisampled imaging is a general framework for using pixels on an image detector to simultaneously sample multiple dimensions of imaging ( space, time, spectrum, brightness, polarization, etc.). The mosaic of red, green, and blue spectral filters found in most solid-state color cameras is one example of multisampled imaging. We briefly describe how multisampling can be used to explore other dimensions of imaging. Once such an image is captured, smooth reconstructions along the individual dimensions can be obtained using standard interpolation algorithms. Typically, this results in a substantial reduction of resolution ( and, hence, image quality). One can extract significantly greater resolution in each dimension by noting that the light fields associated with real scenes have enormous redundancies within them, causing different dimensions to be highly correlated. Hence, multisampled images can be better interpolated using local structural models that are learned offline from a diverse set of training images. The specific type of structural models we use are based on polynomial functions of measured image intensities. They are very effective as well as computationally efficient. We demonstrate the benefits of structural interpolation using three specific applications. These are 1) traditional color imaging with a mosaic of color filters, 2) high dynamic range monochrome imaging using a mosaic of exposure filters, and 3) high dynamic range color imaging using a mosaic of overlapping color and exposure filters.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Carnegie Mellon University; Columbia University	Narasimhan, SG (corresponding author), Carnegie Mellon Univ, Inst Robot, NSH 3211,5000 Forbes Ave, Pittsburgh, PA 15213 USA.	srinivas@cs.cmu.edu; nayar@cs.columbia.edu						Baker S, 2000, PROC CVPR IEEE, P372, DOI 10.1109/CVPR.2000.854852; Bayer B. E., 1976, U.S. Patent, Patent No. [3,971,065, 3971065, 3 971 065]; BENEZRA M, 2000, P IEEE INT C COMP VI; Bracewell R, 1986, PENTAGRAM NOTATION C, V2nd, P192; BRAINARD DH, 1994, P IS T 47 ANN M ROCH, P375; Cok David R., 1987, US Patent, Patent No. [4,642,678, 4642678]; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; DILLON PLP, 1978, IEEE T ELECTRON DEV, V25, P97, DOI 10.1109/T-ED.1978.19045; DILLON PLP, 1977, Patent No. 4047203; FREED LA, 1988, NATL GEOGR RES, V4, P395; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Ginosar R, 1992, United States Patent, Patent No. 5144442; Hamilton John, 1997, U.S. Patent, Patent No. [5,629,734, 5629734]; KNOP K, 1985, IEEE T ELECT DEVICES, V32; Laroche C. A., 1994, US Patent, Patent No. [5,373,322, 5373322]; MANABE D, 1983, P IEEE CUSTOM INTEGR, P451; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857; PARULSKI KA, 1985, IEEE T ELECT DEVICES, V32; RAMANATH R, 2002, J ELECT IMAGING, V11; SCHECHNER YY, 2001, P INT C COMP VIS; Tappen Marshall F, 2003, P 3 INT WORKSH STAT, P1; WOBER MA, 1995, Patent No. 5475769	24	44	59	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					518	530		10.1109/TPAMI.2005.76	http://dx.doi.org/10.1109/TPAMI.2005.76			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794158				2022-12-18	WOS:000226845700004
J	Tan, KH; Hua, H; Ahuja, N				Tan, KH; Hua, H; Ahuja, N			Multiview panoramic cameras using mirror pyramids	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							STEREO	A mirror pyramid consists of a set of planar mirror faces arranged around an axis of symmetry and inclined to form a pyramid. By strategically positioning a number of conventional cameras around a mirror pyramid, the viewpoints of the cameras' mirror images can be located at a single point within the pyramid and their optical axes pointed in different directions to effectively form a virtual camera with a panoramic field of view. Mirror pyramid-based panoramic cameras have a number of attractive properties, including single-viewpoint imaging, high resolution, and video rate capture. It is also possible to place multiple viewpoints within a single mirror pyramid, yielding compact designs for simultaneous multiview panoramic video rate imaging. Nalwa [4] first described some of the basic ideas behind mirror pyramid cameras. In this paper, we analyze the general class of multiview panoramic cameras, provide a method for designing these cameras, and present experimental results using a prototype we have developed to validate single-pyramid multiview designs. We first give a description of mirror pyramid cameras, including the imaging geometry, and investigate the relationship between the placement of viewpoints within the pyramid and the cameras' field of view (FOV), using simulations to illustrate the concepts. A method for maximizing sensor utilization in a mirror pyramid-based multiview panoramic camera is also presented. Images acquired using the experimental prototype for two viewpoints are shown.	Univ Illinois, Beckman Inst Adv Sci & Technol, Comp Vision & Robot Lab, Urbana, IL 61801 USA; Univ Arizona, Ctr Opt Sci, Tucson, AZ 85721 USA	University of Illinois System; University of Illinois Urbana-Champaign; University of Arizona	Tan, KH (corresponding author), Univ Illinois, Beckman Inst Adv Sci & Technol, Comp Vision & Robot Lab, 405 N Mathews Ave, Urbana, IL 61801 USA.	tankh@vision.ai.uiuc.edu; ahuja@vision.ai.uiuc.edu; hhua@optics.arizona.edu		Tan, Kar Han/0000-0001-9294-2932; Hua, Hong/0000-0002-7255-610X				AGGARWAL M, 2000, P INT C PATT REC; Aggarwal M., 2001, P IEEE INT C COMP VI; ANDERSON PI, 1995, ADV IMAGING, V10, P48; BENOSMAN R, 2001, PANORAMIC VISION; CASTANO A, 1998, P WORKSH COMP VIS VI; Chahl JS, 1997, APPL OPTICS, V36, P8275, DOI 10.1364/AO.36.008275; Chahl JS, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P104, DOI 10.1109/OMNVIS.2000.853815; COORG S, 1998, P IEEE COMP SOC C CO; Hicks RA, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P97, DOI 10.1109/OMNVIS.2000.853813; HICKS RA, 1999, P WORKSH PERC MOB AG; HUA H, 2001, P IEEE COMP SOC C CO; ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792; KAWANISHI T, 1998, P INT C PATT REC; Krishnan A, 1996, INT J COMPUT VISION, V20, P169, DOI 10.1007/BF00208718; KRISHNAN A, 1996, P IEEE COMP SOC C CO; KRISHNAN A, 1993, P NATL C ART INT; MIYAMOTO K, 1964, J OPT SOC AM, V54, P1060, DOI 10.1364/JOSA.54.001060; NALWA V, 1996, TRUE OMNIDIRECTIONAL; NALWA VS, 2001, Patent No. 6219090; NALWA VS, 2000, Patent No. 6141145; Nayar S., 1997, P IEEE COMP SOC C CO; NAYAR SK, 2000, P IEEE COMP SOC C CO; NAYAR SK, 1999, P IEEE COMP SOC C CO; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; PELEG S, 1997, P IEEE COMP SOC C CO; Shum H.-Y., 1997, MSRTR9723 MICR RES; SWAMINTHAN R, 2000, IEEE T PATTERN ANAL, V22; TAN KH, 2002, P IEEE WORKSH OMN VI; YAMAZAWA K, 1993, P INT C INT ROB SYST; ZHANG Z, 1998, MSRTR9871 MICR RES; ZHU Z, 2000, P WORKSH OMN VIS; ZIMMERMAN S, 1992, P IEEE AIAA DIG AV S; [No title captured]	33	44	51	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					941	946		10.1109/TPAMI.2004.33	http://dx.doi.org/10.1109/TPAMI.2004.33			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579952				2022-12-18	WOS:000221323900011
J	Bors, AG; Hancock, ER; Wilson, RC				Bors, AG; Hancock, ER; Wilson, RC			Terrain analysis using radar shape-from-shading	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						synthetic aperture radar imagining; shape-from-shading; terrain surface reconstruction; maximum a posteriori probability estimation; robust statistics	EDGE-DETECTION; SAR; TOPOGRAPHY; IMAGERY	This paper develops a maximum a posteriori (MAP) probability estimation framework for shape-from-shading (SFS) from synthetic aperture radar (SAR) images. The aim is to use this method to reconstruct surface topography from a single radar image of relatively complex terrain. Our MAP framework makes explicit how the recovery of local surface orientation depends on the whereabouts of terrain edge features and the available radar reflectance information. To apply the resulting process to real world radar data, we require probabilistic models for the appearance of terrain features and the relationship between the orientation of surface normals and the radar reflectance. We show that the SAR data can be modeled using a Rayleigh-Bessel distribution and use this distribution to develop a maximum likelihood algorithm for detecting and labeling terrain edge features. Moreover, we show how robust statistics can be used to estimate the characteristic parameters of this distribution. We also develop an empirical model for the SAR reflectance function. Using the reflectance model, we perform Lambertian correction so that a conventional SFS algorithm can be applied to the radar data. The initial surface normal direction is constrained to point in the direction of the nearest ridge or ravine feature. Each surface normal must fall within a conical envelope whose axis is in the direction of the radar illuminant. The extent of the envelope depends on the corrected radar reflectance and the variance of the radar signal statistics. We explore various ways of smoothing the field of surface normals using robust statistics. Finally, we show how to reconstruct the terrain surface from the smoothed field of surface normal vectors. The proposed algorithm is applied to various SAR data sets containing relatively complex terrain structure.	Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England	University of York - UK	Bors, AG (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.	Adrian.Bors@cs.york.ac.uk; erh@cs.york.ac.uk; wilson@cs.york.ac.uk	Hancock, Edwin R/C-6071-2008; Hancock, Edwin/N-7548-2019; Bors, Adrian/T-3618-2019	Hancock, Edwin R/0000-0003-4496-2028; Hancock, Edwin/0000-0003-4496-2028; Bors, Adrian/0000-0001-7838-0021				ABRAMOWITZ M, 1972, HDB MATH; [Anonymous], 1990, NONLINEAR DIGITAL FI; ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807; BAYER T, 1991, IEEE T GEOSCI REMOTE, V29, P451, DOI 10.1109/36.79436; Beauchemin M, 1998, IEEE T GEOSCI REMOTE, V36, P1826, DOI 10.1109/36.718650; Bichsel M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P459, DOI 10.1109/CVPR.1992.223150; BOLTER R, 1998, P MACH VIS ADV IM PR, P160; BOLTER R, 1996, INT ARCH PHOTOGRAMM, V21, P20; Bors AG, 1996, IEEE T NEURAL NETWOR, V7, P1351, DOI 10.1109/72.548164; Bors AG, 2000, PROC CVPR IEEE, P262, DOI 10.1109/CVPR.2000.855828; BORS AG, 2002, P IEEE INT C IM PROC, V2, P477; BOVIK AC, 1988, IEEE T ACOUST SPEECH, V36, P1618, DOI 10.1109/29.7550; Carrara W., 1995, SPOTLIGHT SYNTHETIC; Caves R, 1998, IEEE T IMAGE PROCESS, V7, P1534, DOI 10.1109/83.725361; Chellappa R, 1993, MARKOV RANDOM FIELDS; Chorowicz J, 1998, REMOTE SENS ENVIRON, V64, P221, DOI 10.1016/S0034-4257(98)00011-X; Czerwinski RN, 1998, IEEE T IMAGE PROCESS, V7, P1700, DOI 10.1109/83.730381; Datcu M, 1998, IEEE T GEOSCI REMOTE, V36, P1431, DOI 10.1109/36.718847; Dupuis P, 1994, ANN APPL PROBAB, V4, P287, DOI 10.1214/aoap/1177005063; EVANS AN, 1994, IEEE IMAGE PROC, P466, DOI 10.1109/ICIP.1994.413357; FJORTOFT R, 1997, P IEEE INT C AC SPEE, V4, P2761; FRANKOT RT, 1990, ARTIF INTELL, V43, P271, DOI 10.1016/0004-3702(90)90076-C; Fua P, 1998, INT J COMPUT VISION, V26, P215, DOI 10.1023/A:1007905112118; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GHILGLIA DC, 1998, 2 DIMENSIONAL PHASE; GOERING DJ, 1995, IEEE T GEOSCI REMOTE, V33, P185, DOI 10.1109/36.368210; GUINDON B, 1990, IEEE T GEOSCI REMOTE, V28, P654; HAGFORS T, 1991, RADIO SCI, V26, P403, DOI 10.1029/91RS00108; Haldemann AFC, 1999, J GEOPHYS RES-PLANET, V104, P24075, DOI 10.1029/1999JE900023; Hancock E. R., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P196, DOI 10.1109/CVPR.1991.139687; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; Huber PJ, 1981, ROBUST STAT; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Kassam S. A., 1988, SIGNAL DETECTION NON; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P47, DOI 10.1006/cviu.1995.1040; KIMMEL R, 1995, INT J COMPUT VISION, V16, P107, DOI 10.1007/BF01539551; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; LOHMAN G, 1998, VOLUMETRIC IMAGE ANA; LOPES A, 1993, INT J REMOTE SENS, V14, P1735, DOI 10.1080/01431169308953999; Oliver CJ, 1996, IEE P-RADAR SON NAV, V143, P31, DOI 10.1049/ip-rsn:19960219; Ostrov DN, 1999, IEEE T GEOSCI REMOTE, V37, P335, DOI 10.1109/36.739066; Papoulis A., 2002, PROBABILITY RANDOM V; PAQUERAULT S, 1996, P INT GEOSC REM SENS, V1, P503; Press WH., 2002, NUMERICAL RECIPES C, V2; SEBER GAF, 1986, MULTIVARIATE OBSERVA; SERA J, 1982, IMAGE ANAL MATH MORP; Skolnik M., 1990, RADAR HDB; THOMAS J, 1991, PHOTOGRAMM ENG REM S, V57, P51; TORREAO JRA, 1995, MACH VISION APPL, V8, P163, DOI 10.1007/BF01215811; TOUZI R, 1988, IEEE T GEOSCI REMOTE, V26, P764, DOI 10.1109/36.7708; Ulaby F.T., 1981, MICROWAVE REMOTE SEN, V1; WILDEY RL, 1984, SCIENCE, V224, P153, DOI 10.1126/science.224.4645.153; Wilson RC, 2000, COMPUT VIS IMAGE UND, V77, P25, DOI 10.1006/cviu.1999.0810; Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658; ZITO RR, 1988, COMPUT VISION GRAPH, V43, P281, DOI 10.1016/0734-189X(88)90084-9; 1992, J GEOPHYSICAL RES PL, V97	58	44	47	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2003	25	8					974	992		10.1109/TPAMI.2003.1217602	http://dx.doi.org/10.1109/TPAMI.2003.1217602			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	702XJ		Green Accepted, Green Submitted			2022-12-18	WOS:000184249800004
J	Clarkson, MJ; Rueckert, D; Hill, DLG; Hawkes, DJ				Clarkson, MJ; Rueckert, D; Hill, DLG; Hawkes, DJ			Using photo-consistency to register 2D optical images of the human face to a 3D surface model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						2D-3D registration; similarity measures; photo-consistency; pose estimation; extrinsic parameter calibration	POSE ESTIMATION; CAMERA CALIBRATION; REGISTRATION; POINT; LINE; 2-D	In this paper, we propose a novel method to register two or more optical images to a 3D surface model. The potential applications of such a registration method could be in medicine; for example, in image guided interventions, surveillance and identification, industrial inspection, computer assisted manufacture, computer assisted maintenance, or telemanipulation in remote or hostile environments. Registration is performed by optimizing a similarity measure with respect to the transformation parameters. We propose a novel similarity measure based on "photo-consistency." For each surface point, the similarity measure computes how consistent the corresponding optical image information in each view is with a lighting model. The relative pose of the optical images must be known. We validate the system using data from an optical-based surface reconstruction system and surfaces derived from magnetic resonance (MR) images of the human face. We test the accuracy and robustness of the system with respect to the number of video images, video image noise, errors in surface location and area, and complexity of the matched surfaces. We demonstrate the algorithm working on 10 further optical-based reconstructions of the human head and skin surfaces derived from MR images of the heads of five volunteers. Matching four optical images to a surface model produced a 3D error of between 1.45 and 1.59 mm, at a success rate of 100 percent, where the initial misregistration was up to 16 mm or degrees from the registration position.	Kings Coll London, Guys Hosp, Div Radiol Sci & Med Engn, London SE1 9RT, England; Univ London Imperial Coll Sci Technol & Med, Visual Informat Proc Dept Comp, London SW7 2BZ, England; Kings Coll London, Guys Hosp, Div Radiol Sci & Med Engn, London SE1 9RT, England	Guy's & St Thomas' NHS Foundation Trust; University of London; King's College London; Imperial College London; Guy's & St Thomas' NHS Foundation Trust; University of London; King's College London		clarkson_matthew@yahoo.co.uk; dr@doc.ic.ac.uk; derek.hill@kcl.ac.uk; david.hawkes@kcl.ac.uk	Rueckert, Daniel/C-4393-2008; Clarkson, Matthew/C-1512-2008	Clarkson, Matthew/0000-0002-5565-1252; Rueckert, Daniel/0000-0002-5683-5889; Hill, Derek/0000-0003-1970-1432				Agouris P, 1996, PHOTOGRAMM ENG REM S, V62, P703; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; CLARKSON M, 2000, THESIS U LONDON UK; Clarkson MJ, 2000, PROC SPIE, V3979, P342, DOI 10.1117/12.387696; Clarkson MJ, 1999, PROC SPIE, V3661, P14, DOI 10.1117/12.348487; CLARKSON MJ, 1999, P MICCAI, P579; Colchester A C, 1996, Med Image Anal, V1, P73, DOI 10.1016/S1361-8415(96)80006-5; DEMENTHON D, 1992, IEEE T PATTERN ANAL, V14, P1100, DOI 10.1109/34.166625; Edwards PJ, 2000, IEEE T MED IMAGING, V19, P1082, DOI 10.1109/42.896784; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Foley James D., 1990, COMPUTER GRAPHICS; Fua P, 2000, INT J COMPUT VISION, V38, P153, DOI 10.1023/A:1008105802790; Fua P, 1997, INT J COMPUT VISION, V24, P19, DOI 10.1023/A:1007918123901; Grimson WEL, 1999, SCI AM, V280, P62; Grimson WEL, 1996, IEEE T MED IMAGING, V15, P129, DOI 10.1109/42.491415; GRIMSON WEL, 1998, P INT C MED IM COMP, P63; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; Kollnig H, 1997, INT J COMPUT VISION, V23, P283, DOI 10.1023/A:1007927317325; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375; LEVENTON ME, 1997, P IM UND WORKSH; LIU YC, 1990, IEEE T PATTERN ANAL, V12, P28, DOI 10.1109/34.41381; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Penney GP, 1998, IEEE T MED IMAGING, V17, P586, DOI 10.1109/42.730403; PHONG TQ, 1995, INT J COMPUT VISION, V15, P225, DOI 10.1007/BF01451742; Powell MW, 2000, PROC CVPR IEEE, P263, DOI 10.1109/CVPR.2000.854804; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Robert L, 1996, COMPUT VIS IMAGE UND, V63, P314, DOI 10.1006/cviu.1996.0021; Schroeder W., 2010, VISUALIZATION TOOLKI, V4th ed.; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918	34	44	46	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2001	23	11					1266	1280		10.1109/34.969117	http://dx.doi.org/10.1109/34.969117			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	491KV					2022-12-18	WOS:000172108300005
J	Lee, SW; Ryu, DS				Lee, SW; Ryu, DS			Parameter-free geometric document layout analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						geometric document layout analysis; parameter-free method; periodicity estimation; multiscale analysis; page segmentation	SEGMENTATION	Automatic transformation of paper documents into electronic documents requires geometric document layout analysis at the first stage. However, variations in character font sizes, text line spacing, and document layout structures have made it difficult to design a general-purpose document layout analysis algorithm for many years. The use of some parameters has therefore been unavoidable in previous methods. In this paper, we propose a parameter-free method for segmenting the document images into maximal homogeneous regions and identifying them as texts, images, tables, and ruling lines. A pyramidal quadtree structure is constructed for multiscale analysis and a periodicity measure is suggested to find a periodical attribute of text regions for page segmentation. To obtain robust page segmentation results, a confirmation procedure using texture analysis is applied to only ambiguous regions. Based on the proposed periodicity measure, multiscale analysis, and confirmation procedure, we could develop a robust method for geometric document layout analysis independent of character font sizes, text line spacing, and document layout structures. The proposed method was experimented with the document database from the University of Washington and the MediaTeam Document Database. The results of these tests have shown that the proposed method provides more accurate results than the previous ones.	Korea Univ, Ctr Artificial Vis Res, Seongbuk Ku, Seoul 136701, South Korea; Hyundai Informat Technol Co Ltd, Yongin 449910, Kyunggi Do, South Korea	Korea University	Lee, SW (corresponding author), Korea Univ, Ctr Artificial Vis Res, Seongbuk Ku, Anam Dong, Seoul 136701, South Korea.	swlee@image.korea.ac.kr; ryu75@shinbiro.com	Lee, Seong-Whan/C-7928-2012					Antonacopoulos A, 1998, COMPUT VIS IMAGE UND, V70, P350, DOI 10.1006/cviu.1998.0691; *CAER CORP, 1998, OMN PRO WIND 95 98 N; Cheng H, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P610, DOI 10.1109/ICIP.1998.723575; Drivas D., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P610, DOI 10.1109/ICDAR.1995.601970; Etemad K, 1997, IEEE T PATTERN ANAL, V19, P92, DOI 10.1109/34.566817; Gatos B, 1997, PATTERN RECOGN, V30, P1505, DOI 10.1016/S0031-3203(96)00157-4; HA J, 1995, P 3 INT C DOC AN REC, P952; *HAPSAN COMP INC, 1999, ARM PROF WIND 95 98; HARALICK RM, 1994, P IEEE COMP SOC C CO, V8, P385; Jain A. K., 1992, Machine Vision and Applications, V5, P169, DOI 10.1007/BF02626996; Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886; Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X; LEBOURGEOIS F, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P272, DOI 10.1109/ICPR.1992.201771; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Phillips I. T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P478, DOI 10.1109/ICDAR.1993.395691; Sauvola J., 1999, CD ROM COLLECTION DO; Simon A, 1997, IEEE T PATTERN ANAL, V19, P273, DOI 10.1109/34.584106; Tang YY, 1997, IEEE T PATTERN ANAL, V19, P921, DOI 10.1109/34.608296	18	44	53	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2001	23	11					1240	1256						17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	491KV					2022-12-18	WOS:000172108300003
J	Liu, K; Huang, YS; Suen, CY				Liu, K; Huang, YS; Suen, CY			Identification of fork points on the skeletons of handwritten Chinese characters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						thinning; skeleton; segmentation; stroke extraction; character recognition; handwritten Chinese character	THINNING ALGORITHM; RECOGNITION	This paper describes techniques for stroke extraction used in the recognition of handwritten Chinese characters. A new set of feature points is proposed for the analysis of skeleton images. Based on a geometrical graph, a novel criterion is proposed for the identification of fork points in a skeleton image which correspond to joint points in the original character image. Experimental results indicate that the proposed method correctly determines the fork points, and is effective in unifying the joint points.	Concordia Univ, Ctr Pattern Recognit & Machine Intelligence, Montreal, PQ H3G 1M8, Canada; CCL ITRI, Hsinchu 310, Taiwan	Concordia University - Canada; Industrial Technology Research Institute - Taiwan	Liu, K (corresponding author), Concordia Univ, Ctr Pattern Recognit & Machine Intelligence, Suite GM-606,1455 de maisonneuve Blvd W, Montreal, PQ H3G 1M8, Canada.							Abuhaiba ISI, 1996, PATTERN RECOGN, V29, P1161, DOI 10.1016/0031-3203(95)00142-5; CHANG HD, 1993, PATTERN RECOGN, V26, P711, DOI 10.1016/0031-3203(93)90123-E; CHENG FH, 1993, PATTERN RECOGN, V26, P579, DOI 10.1016/0031-3203(93)90112-A; DOERMANN D, 1993, P INT WORKSH FRONT H, P41; HILDEBRANDT TH, 1993, PATTERN RECOGN, V26, P205, DOI 10.1016/0031-3203(93)90030-Z; Hong-De Chang, 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P1223, DOI 10.1142/S0218001494000619; HUANG JS, 1993, HDB PATTERN RECOGNIT, P595; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; LEE HJ, 1992, PATTERN RECOGN, V25, P543, DOI 10.1016/0031-3203(92)90052-K; LIAO CW, 1990, PATTERN RECOGN, V23, P475, DOI 10.1016/0031-3203(90)90068-V; LIN JY, 1995, PATTERN RECOGN, V28, P493, DOI 10.1016/0031-3203(94)00122-3; LIU K, 1996, THINNING BASED FEATU; LU SW, 1991, PATTERN RECOGN, V24, P617, DOI 10.1016/0031-3203(91)90029-5; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; PAVLIDIS T, 1986, COMPUT VISION GRAPH, V35, P111, DOI 10.1016/0734-189X(86)90128-3; TSENG LY, 1992, PATTERN RECOGN, V25, P1445, DOI 10.1016/0031-3203(92)90119-4; WANG PSP, 1989, IEEE T COMPUT, V38, P741, DOI 10.1109/12.24276; YAMAMA H, 1984, P 7 INT JOINT C PATT, P389	18	44	54	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1999	21	10					1095	1100		10.1109/34.799914	http://dx.doi.org/10.1109/34.799914			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	248DB					2022-12-18	WOS:000083259100011
J	Kim, WY; Kim, YS				Kim, WY; Kim, YS			Robust rotation angle estimator	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						rotation angle; zernike moment; phase; principal axes	INVARIANT IMAGE RECOGNITION; MOMENTS	The conventional method of estimating the rotation angle of a pattern using the principal axes is not suitable for circular symmetric patterns since eigenvalues are similar in both directions. In this paper, a new and robust method of estimating a rotation angle using the phase information of Zernike moments is presented. The experimental results show that the proposed method estimates the rotation angle of the circular symmetric patterns more accurately than the principal axes method, even in the presence of noise.	Hanyang Univ, Dept Elect Engn, Seoul 133791, South Korea	Hanyang University	Kim, WY (corresponding author), Hanyang Univ, Dept Elect Engn, Seoul 133791, South Korea.							GOSE E, 1996, PATTERN RECOGN, P155; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; KHOTANZAD A, 1990, PATTERN RECOGN, V23, P1089, DOI 10.1016/0031-3203(90)90005-6; Kim W. Y., 1994, P IEEE INT C COMP VI, P391; KIM WY, 1997, J ELECT ENG INFORMAT, V2; PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1908, IEEE T PATTERN ANAL, V10; TSAI WH, 1991, PATTERN RECOGN, V24, P95, DOI 10.1016/0031-3203(91)90080-O	9	44	48	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1999	21	8					768	773		10.1109/34.784290	http://dx.doi.org/10.1109/34.784290			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	225YF					2022-12-18	WOS:000081993000008
J	Hung, YS; Ho, HT				Hung, YS; Ho, HT			A Kalman filter approach to direct depth estimation incorporating surface structure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						depth-from-motion; Kalman filter; gradient method; surface structure; image sequence	MOTION	The problem of depth-from-motion using a monocular image sequence is considered. A pixel-based model is developed for direct depth estimation within a Kalman filtering framework. A method is proposed for incorporating local surface structure into the Kalman filter. Experimental results are provided to illustrate the effect of structural information on depth estimation.	Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam Rd, Hong Kong, Peoples R China	University of Hong Kong	Hung, YS (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam Rd, Hong Kong, Peoples R China.	yshung@eee.hku.hk	Hung, Yeung Sam/C-1852-2009					ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333; ALOIMONOS Y, 1994, INT J COMPUT VISION, V13, P33, DOI 10.1007/BF01420794; BELANGER PR, 1974, AUTOMATICA, V10, P267, DOI 10.1016/0005-1098(74)90037-5; Heel J., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P1142, DOI 10.1109/ROBOT.1990.126150; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; HUANG LQ, 1994, IMAGE VISION COMPUT, V12, P435, DOI 10.1016/0262-8856(94)90027-2; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; SANDINI G, 1990, IEEE T PATTERN ANAL, V12, P13, DOI 10.1109/34.41380; SINCLAIR D, 1994, INT J COMPUT VISION, V13, P57, DOI 10.1007/BF01420795; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WAXMAN AM, 1987, INT J COMPUT VISION, V1, P239, DOI 10.1007/BF00127823; Weng J., 1993, MOTION STRUCTURE IMA; XIONG YL, 1995, INT S COMP VIS COR G, P1; ZHUANG H, 1994, ROBOTICS AUTONOMOUS, V13, P87	18	44	47	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1999	21	6					570	575		10.1109/34.771330	http://dx.doi.org/10.1109/34.771330			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	205KD		Green Published, Green Submitted			2022-12-18	WOS:000080819100009
J	Beveridge, JR; Riseman, EM				Beveridge, JR; Riseman, EM			How easy is matching 2D line models using local search?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; optimal model matching; line segment models; run-time performance characterization; random-starts local search	OBJECT RECOGNITION	Local search is a well established and highly effective method for solving complex combinatorial optimization problems. Here, local search is adapted to solve difficult geometric matching problems. Matching is posed as the problem of finding the optimal many-to-many correspondence mapping between a line segment model and image line segments. Image data is assumed to be fragmented, noisy, and cluttered. The algorithms presented have been used for robot navigation, photo interpretation, and scene understanding. This paper explores how local search performs as model complexity increases, image clutter increases, and additional model instances are added to the image data. Expected run-times to find optimal matches with 95 percent confidence are determined for 48 distinct problems involving six models. Nonlinear regression is used to estimate run-time growth as a function of problem size. Both polynomial and exponential growth models are fit to the run-time data. For problems with random clutter, the polynomial model fits better and growth is comparable to that for tree search. Far problems involving symmetric models and multiple model instances, where tree search is exponential, the polynomial growth model is superior to the exponential growth model for one search; algorithm and comparable for another.	UNIV MASSACHUSETTS, DEPT COMP SCI, AMHERST, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Beveridge, JR (corresponding author), COLORADO STATE UNIV, DEPT COMP SCI, FT COLLINS, CO 80523 USA.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; BAIRD HS, 1985, MODEL BASED IMAGE MA; Beveridge J. R., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P18, DOI 10.1109/ICPR.1990.118058; Beveridge J. R., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P533, DOI 10.1109/ISCV.1995.477056; BEVERIDGE JR, 1995, COMPUT VIS IMAGE UND, V61, P351, DOI 10.1006/cviu.1995.1028; BEVERIDGE JR, 1993, THESIS U MASSACHUSET; BEVERIDGE JR, 1989, P IM UND WORKSH LOS, P815; BEVERIDGE JR, 1991, SPIE MILESTONE SERIE; BEVERIDGE JR, 1996, P IM UND WORKSH LOS, P683; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; CASS TA, 1992, P IMAGE UNDERSTANDIN, P693; Collins R. T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P240, DOI 10.1109/CVPR.1993.340983; COLLINS RT, 1993, P DARPA IM UND WORKS, P197; DAVIS LS, 1982, PATTERN RECOGN, V15, P277, DOI 10.1016/0031-3203(82)90030-9; DEVORE JL, 1982, NONLINEAR MULTIPLE R, P459; DRAPER B, 1993, THESIS U MASSACHUSET; Eric W., 1990, OBJECT RECOGNITION C; FENNEMA C, 1990, IEEE T SYST MAN CYB, V20, P1352, DOI 10.1109/21.61206; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GRIMSON WEL, 1994, INT J COMPUT VISION, V13, P7, DOI 10.1007/BF01420793; GRIMSON WEL, 1990, ARTIF INTELL, V44, P121, DOI 10.1016/0004-3702(90)90100-E; JOHNSON DS, 1988, J COMPUT SYST SCI, V37, P79, DOI 10.1016/0022-0000(88)90046-3; Kernighan B. W., 1970, Bell System Technical Journal, V49, P291; KUMAR R, 1994, P CVGIP IM UND, V11; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; LIN S, 1973, OPER RES, V21, P498, DOI 10.1287/opre.21.2.498; LOADER C, 1995, THESIS U W AUSTR; Noble B, 1969, APPL LINEAR ALGEBRA; Olson C. F., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P449, DOI 10.1109/ISCV.1995.477043; OLSON CF, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P251, DOI 10.1109/CVPR.1994.323837; PAPADIMITRIOU CH, 1982, COMBINATORIAL OPTIMI, P454; POPE AR, 1994, MODEL BASED OBJECT R; POPE AR, 1993, INT C COMP VIS, P296; RAMESH V, 1995, THESIS U WASHINGTON; RISEMAN EM, 1997, VISUAL NAVIGATION BI, P317; Roberts L, 1965, MACHINE PERCEPTION 3; ROTH G, 1993, CVGIP-IMAG UNDERSTAN, V58, P1, DOI 10.1006/ciun.1993.1028; STEIN F, 1992, P IM UND WORKSH SAN, P667; Stevens MR, 1997, IEEE T IMAGE PROCESS, V6, P126, DOI 10.1109/83.552102; TOVEY CA, 1985, SIAM J ALGEBRA DISCR, V6, P384, DOI 10.1137/0606040; Well W. M.  III, 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P486, DOI 10.1109/CVPR.1991.139740; Whitley D., 1995, Journal of Heuristics, V1, P77, DOI 10.1007/BF02430367	44	44	45	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1997	19	6					564	579		10.1109/34.601245	http://dx.doi.org/10.1109/34.601245			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XG302		Green Submitted			2022-12-18	WOS:A1997XG30200002
J	Gardner, WF; Lawton, DT				Gardner, WF; Lawton, DT			Interactive model-based vehicle tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						vehicle tracking; model-based; interactive; local translation	MOTION; OBJECT	This paper describes an interactive model-based vision system for vehicle tracking. A human specifies a limited amount of information in the form of object models, which establish a context for autonomous interpretation of scenes containing moving vehicles. Results are presented from several image sequences shot with handheld uncalibrated cameras.	MICROSOFT CORP,REDMOND,WA 98052	Microsoft	Gardner, WF (corresponding author), K2T INC,1 S LINDEN ST,DUQUESNE,PA 15110, USA.							AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101; DICKMANNS ED, 1990, IEEE T SYST MAN CYB, V20, P1273, DOI 10.1109/21.61200; DICKMANNS ED, 1992, IEEE T PATTERN ANAL, V14, P199, DOI 10.1109/34.121789; Elmenreich W., 2002, P IEEE INT C ROB AUT, V502; GARDNER WF, 1995, GITGVU9533 GEORG I T; GENNERY DB, 1992, INT J COMPUT VISION, V7, P243, DOI 10.1007/BF00126395; KOLLER D, 1992, P 2 EUR C COMP VIS S, P437; KOLLER D, 1991, JUN IEEE C COMP VIS, P90; KRIEGMAN DJ, 1989, IEEE T ROBOTIC AUTOM, V5, P792, DOI 10.1109/70.88100; LAWTON DT, 1993, P DARPA IMAGE UNDERS, P697; LIU Y, 1993, IEEE T PATTERN ANAL, V15, P802, DOI 10.1109/34.236249; MATTHIES L, 1987, CMUCS87185 CARN MELL; SCHICK J, 1991, OCT P IEEE WORKSH VI, P256; WU JJ, 1989, INT J COMPUT VISION, V2, P373, DOI 10.1007/BF00133556; ZHANG ZY, 1992, INT J COMPUT VISION, V7, P211, DOI 10.1007/BF00126394	15	44	46	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1996	18	11					1115	1121		10.1109/34.544082	http://dx.doi.org/10.1109/34.544082			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VU159		Green Submitted			2022-12-18	WOS:A1996VU15900008
J	Chaumette, F; Boukir, S; Bouthemy, P; Juvin, D				Chaumette, F; Boukir, S; Bouthemy, P; Juvin, D			Structure from controlled motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; robotics; active vision; structure from motion; vision-based control	LINE CORRESPONDENCES; VISION; SHAPE; DEPTH	This paper deals with the recovery of 3D information using a single mobile camera in the context of active vision. First, we propose a general revisited formulation of the structure-from-known-motion issue. Within the same formalism, we handle various kinds of 3D geometrical primitives such as points, lines, cylinders, spheres, etc. We also aim at minimizing effects of the different measurement errors which are involved in such a process. More precisely, we mathematically determine optimal camera configurations and motions which lead to a robust and accurate estimation of the 3D structure parameters. We apply the visual servoing approach to perform these camera motions using a control law in closed-loop with respect to visual data. Real-time experiments dealing with 3D structure estimation of points and cylinders are reported. They demonstrate that this active vision strategy can very significantly improve the estimation accuracy.	L3I, F-17042 LA ROCHELLE 1, FRANCE; CEA, LETI DEIN, F-91191 GIF SUR YVETTE, FRANCE	CEA; UDICE-French Research Universities; Universite Paris Saclay	Chaumette, F (corresponding author), INST RECH INFORMAT & SYST ALEATOIRES, INST NATL RECH INFORMAT & AUTOMAT RENNES, CAMPUS BEAULIEU, F-35042 RENNES, FRANCE.		Francois, Chaumette/AAH-1481-2021	Francois, Chaumette/0000-0002-1238-4385; Boukir, Samia/0000-0002-0907-081X				ABBOTT L, 1990, P 3 ICCV OS JAP DEC, P489; ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ALOIMONOS J, 1987, 1ST P INT C COMP VIS, P35; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; Bandopadhay A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P498; BOUKIR S, 1993, P 8 SCAND C IM AN TR, V1, P113; BOUKIR S, 1993, 1074 IRISA U RENN 1; BROWN C, 1992, P 11 ICPR HAG NETH A, V1, P21; CHAUMETTE F, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P347, DOI 10.1109/CVPR.1994.323850; CHIEN CH, 1989, IEEE T PATTERN ANAL, V11, P372, DOI 10.1109/34.19034; Crowley J. L., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P109, DOI 10.1142/S0218001493000078; DANIILIDIS K, 1990, P 1 ECCV ANT FRANC A, P199; ESPIAU B, 1992, IEEE T ROBOTIC AUTOM, V8, P313, DOI 10.1109/70.143350; ESPIAU B, 1987, IEEE INT C ROB AUT R, V3, P1436; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; HASHIMOTO K, 1993, WORLD SCI SERIES ROB, V7; Herve J.-Y., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P10, DOI 10.1109/CVPR.1992.223234; HORN BKP, 1987, ROBOT VISION; HUANG L, 1991, P IEEE WORKSH VIS MO, P196; LI S, 1991, P IEEE WORKSH VIS MO; MARCHAND E, 1995, IEEE INT WORKSH VIS, P10; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; Milios E., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P51, DOI 10.1142/S0218001493000042; MITICHE A, 1989, PATTERN RECOGN, V22, P299, DOI 10.1016/0031-3203(89)90077-0; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; OLIENSIS J, 1991, IEEE WORKSH VIS MOT, P8; PAHLAVAN K, 1992, CVGIP-IMAG UNDERSTAN, V56, P41, DOI 10.1016/1049-9660(92)90084-G; RIVES P, 1989, P IEEE WORKSH INT 3D; SAFAEERAD R, 1992, IEEE T ROBOTIC AUTOM, V8, P624, DOI 10.1109/70.163786; SANDINI G, 1990, IEEE T PATTERN ANAL, V12, P13, DOI 10.1109/34.41380; Sandini G., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P39; SHASHUA A, 1993, P INT C COMP VIS BER, P583; THOMPSON WB, 1993, IEEE T PATTERN ANAL, V15, P162, DOI 10.1109/34.192488; TISTARELLI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P108, DOI 10.1016/1049-9660(92)90089-L; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; VERNON D, 1990, IEEE T ROBOTIC AUTOM, V6, P509, DOI 10.1109/70.62040; VIALA M, 1992, P SPIE INT ROB VIS C; VIEVILLE T, 1992, PROCEEDINGS OF THE 1992 IEEE INTERNATIONAL SYMPOSIUM ON INTELLIGENT CONTROL, P348, DOI 10.1109/ISIC.1992.225114; WAXMAN AM, 1987, INT J COMPUT VISION, V1, P239, DOI 10.1007/BF00127823; WEISS LE, 1987, IEEE T ROBOTIC AUTOM, V3, P404, DOI 10.1109/JRA.1987.1087115; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P318, DOI 10.1109/34.120327	42	44	47	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1996	18	5					492	504		10.1109/34.494639	http://dx.doi.org/10.1109/34.494639			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL691					2022-12-18	WOS:A1996UL69100002
J	Moons, T; VanGool, L; Proesmans, M; Pauwels, E				Moons, T; VanGool, L; Proesmans, M; Pauwels, E			Affine reconstruction from perspective image pairs with a relative object-camera translation in between	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						affine reconstruction; camera translation; stereo; shape-from-motion; repeated structure; perspective projection		A method is described to recover the three-dimensional affine structure of a scene consisting of at least five points identified in two perspective views with a relative object-camera translation in between. When compared to the results for arbitrary stereo views, a more detailed reconstruction is possible using less information. The method presented only assumes that the two images are obtained by Identical cameras, but no knowledge about the intrinsic parameters of the camera(s) or about the performed translation is assumed, By the same method, affine 3D reconstruction from a single view can be achieved for parallel structures. In that case, four points suffice for affine reconstruction.			Moons, T (corresponding author), KATHOLIEKE UNIV LEUVEN, DEPT ELECT ENGN, MACHINE INTELLIGENCE & IMAGING RES GRP, B-3001 LOUVAIN, BELGIUM.							ARMSTRONG M, 1994, 5TH P BRIT MACH VIS; BEARDSLEY PA, 1994, COMPUTER VISION ECCV; BOUFAMA B, 1994, COMPUTER VISION ECCV; FAUGERAS OD, 1992, 2 EUR C COMP VIS ECC, P563; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; Hartley R. I., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P237; Kanatani K., 1993, GEOMETRIC COMPUTATIO; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; MAYBANK S, 1990, P ECCV 90, P177; MOHR R, 1993, JUN P C COMP VIS PAT, P543; Moons T., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P297; MOONS T, 1994, KULESATM129420 KATH; PROESMANS M, 1994, COMPUTER VISION ECCV; QUAN L, 1993, 4TH P BRIT MACH VIS, P659; ROTHWELL CA, 1993, P IEEE INT C COMPUTE, P573; Semple J., 1979, ALGEBRAIC PROJECTIVE; SHASHUA A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P483, DOI 10.1109/CVPR.1994.323870	17	44	46	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					77	83		10.1109/34.476015	http://dx.doi.org/10.1109/34.476015			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500011
J	BOYER, KL; MIRZA, MJ; GANGULY, G				BOYER, KL; MIRZA, MJ; GANGULY, G			THE ROBUST SEQUENTIAL ESTIMATOR - A GENERAL-APPROACH AND ITS APPLICATION TO SURFACE ORGANIZATION IN RANGE DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RANGE DATA; SEGMENTATION; ROBUST ESTIMATORS; PERCEPTUAL ORGANIZATION; SURFACE PARAMETERIZATION; SEQUENTIAL ESTIMATORS	COMPUTER VISION; PARAMETER-ESTIMATION; IMAGES	We present an autonomous, statistically robust, sequential function approximation approach to simultaneous parameterization and organization of (possibly partially occluded) surfaces in noisy, outlier-ridden (not Gaussian), functional range data. At the core of this approach is the Robust Sequential Estimator, a robust extension to the method of sequential least squares. Unlike most existing surface characterization techniques, our method generates complete surface hypotheses in parameter space. Given a noisy depth map of an unknown 3-D scence, the algorithm first selects appropriate seed points representing possible surfaces. For each nonredundant seed it chooses the best approximating model from a given set of competing models using a modified Akaike Information Criterion. With this best model, each surface is expanded from its seed over the entire image, and this step is repeated for all seeds. Those points which appear to be outliers with respect to the model in growth are not included in the (possibly disconnected) surface. Point regions are deleted from each newly grown surface in the prune stage. Noise, outliers, or coincidental surface alignment may cause some points to appear to belong to more than one surface. These ambiguities are resolved by a weighted voting scheme within a 5 x 5 decision window centered around the ambiguous point. The isolated point regions left after the resolve stage are removed and any missing points in the data are filled by the surface having a majority consensus in an 8-neighborhood.			BOYER, KL (corresponding author), OHIO STATE UNIV,DEPT ELECT ENGN,SIGNAL ANAL & MACHINE PERCEPT LAB,2015 NEIL AVE,COLUMBUS,OH 43210, USA.							Akaike H., 1973, 2 INT S INFORM THEOR, P267, DOI DOI 10.1007/978-1-4612-1694-0_15; Andrews D F, 1972, ROBUST ESTIMATES LOC; BEATON AE, 1974, TECHNOMETRICS, V16, P147, DOI 10.2307/1267936; BESL PJ, 1986, COMPUT VISION GRAPH, V33, P33, DOI 10.1016/0734-189X(86)90220-3; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BESL PJ, 1988, 1988 P INT C COMP VI; BOLES RC, 1982, INT J ROBOT RES, V1, P57; BOULT T, 1990, IEEE T ROBOTIC AUTOM, P232; Box G. E. P., 1987, EMPIRICAL MODEL BUIL; BOZDOGAN H, 1987, PSYCHOMETRIKA, V52, P345, DOI 10.1007/BF02294361; BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5; FAN T, 1986, JUN P IEEE C COMP VI, P86; FAN T, 1987, 1987 P DARPA IM UND, P351; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; Fisher R.B., 1989, SURFACES OBJECTS COM, V7; FORSTNER W, 1987, COMPUT VISION GRAPH, V40, P273, DOI 10.1016/S0734-189X(87)80144-5; GOODALL C, 1983, UNDERSTANDING ROBUST, P339; HARALICK RM, 1986, COMPUT VISION GRAPH, V36, P372, DOI 10.1016/0734-189X(86)90082-4; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; HSIA TC, 1976, SYSTEM IDENTIFICATIO; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; JAIN AK, 1993, MARKOV RANDOM FIELD, P543; KOCH MW, 1987, IEEE T PATTERN ANAL, V9, P483, DOI 10.1109/TPAMI.1987.4767936; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; MIRZA MJ, 1993, IEEE T ROBOTIC AUTOM, V9, P75, DOI 10.1109/70.210797; MIRZA MJ, 1992, 1992 P IEEE C COMP V, P366; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; Shirai Y, 1987, 3 DIMENSIONAL COMPUT	28	44	48	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1994	16	10					987	1001		10.1109/34.329010	http://dx.doi.org/10.1109/34.329010			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PM827					2022-12-18	WOS:A1994PM82700003
J	VENKATESWAR, V; CHELLAPPA, R				VENKATESWAR, V; CHELLAPPA, R			EXTRACTION OF STRAIGHT-LINES IN AERIAL IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						STRAIGHT LINE EXTRACTION; CONNECTED COMPONENTS; EDGE DETECTION; FEATURE EXTRACTION	HOUGH TRANSFORM; EDGE-DETECTION	A straight-line extractor that produces line descriptions from aerial images is described. The input to the line extractor is in the form of an edge image, where the contrast and direction of each edge pixel is specified. The system scans the edge image left to right and top to bottom (LRTB) and assigns a line label for each scanned edge pixel, thereby generating a label image. At the end of this process, each edge pixel has a line label associated with it, and edge pixels that belong to the same line will be assigned the same line label. In addition, with each line label, a record that stores the end points, the average contrast, and the pixel support of the line is generated. The label image is used as a spatial index to further link fragmented lines. We also describe techniques to eliminate many of the physically insignificant lines, given that the domain of interpretation is aerial images dominated by man-made objects.	UNIV MARYLAND,DEPT ENGN,COLL PK,MD 20742; UNIV MARYLAND,CTR AUTOMAT RES,COLL PK,MD 20742	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park	VENKATESWAR, V (corresponding author), TEXAS INSTRUMENTS INC,CTR SEMICOND PROC & DESIGN,DALLAS,TX 75243, USA.		Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020					BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; HERMAN M, 1986, ARTIF INTELL, V30, P289, DOI 10.1016/0004-3702(86)90002-0; HUERTAS A, 1988, COMPUT VISION GRAPH, V41, P131, DOI 10.1016/0734-189X(88)90016-3; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MCKEOWN DM, 1985, IEEE T PATTERN ANAL, V7, P570, DOI 10.1109/TPAMI.1985.4767704; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; SHAPIRO SD, 1978, PATTERN RECOGN, V10, P129, DOI 10.1016/0031-3203(78)90022-5; Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010; VENKATESWAR V, 1991, CARTR556 U MAR CTR A; VENKATESWAR V, 1991, OCT P IEEE WORKSH VI, P280; VENKATESWAR V, 1991, CARTR567 U MAR CTR A; VENKATESWAR V, 1991, CARTR557 U MAR CTR A; VENKATESWAR V, 1990, P 10 INT C PATT REC, V1, P204; ZHOU YT, 1989, IEEE T PATTERN ANAL, V11, P84, DOI 10.1109/34.23115	19	44	65	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1992	14	11					1111	1114		10.1109/34.166627	http://dx.doi.org/10.1109/34.166627			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JX370					2022-12-18	WOS:A1992JX37000007
J	TAN, HL; GELFAND, SB; DELP, EJ				TAN, HL; GELFAND, SB; DELP, EJ			A COST MINIMIZATION APPROACH TO EDGE-DETECTION USING SIMULATED ANNEALING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COST MINIMIZATION; EDGE DETECTION; EDGE MODELING; LOW-LEVEL VISION; SEGMENTATION; SIMULATED ANNEALING	OPTIMIZATION; CONVERGENCE; RELAXATION	In this paper, we cast edge detection as a problem in cost minimization. This is achieved by the formulation of a cost function that evaluates the quality of edge configurations. The function is a linear sum of weighted cost factors. The cost factors capture desirable characteristics of edges such as accuracy in localization, thinness, and continuity. Edges are detected by finding the edge configurations that minimize the cost function. We give a mathematical description of edges and analyze the cost function in terms of the characteristics of the edges in minimum cost configurations. Through the analysis, we provide guidelines on the choice of weights to achieve certain characteristics of the detected edges. The cost function is minimized by the stimulated annealing method. We present a novel set of strategies for generating candidate states and devise a suitable temperature schedule. Experimental results, which verify the usefulness of our cost minimization approach to edge detection, are given.	PURDUE UNIV,SCH ELECT ENGN,COMP VIS & IMAGE PROC LAB,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	TAN, HL (corresponding author), KODAK RES LABS,CTR IMAGE ELECTR,ROCHESTER,NY 14650, USA.		Delp, Edward J/C-3616-2013	Delp, Edward J/0000-0002-2909-7323				ASHKAR GP, 1978, COMPUT VISION GRAPH, V7, P331, DOI 10.1016/S0146-664X(78)80002-1; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CARNEVALI P, 1985, IBM J RES DEV, V29, P569, DOI 10.1147/rd.296.0569; DELP EJ, 1985, IEEE T SYST MAN CYB, V15, P144, DOI 10.1109/TSMC.1985.6313403; DICKEY FM, 1977, APPL OPTICS, V16, P145, DOI 10.1364/AO.16.000145; EICHEL PH, 1988, IEEE T MED IMAGING, V7, P313, DOI 10.1109/42.14514; EICHEL PH, 1985, JUN P IEEE COMP VIS, P14; ELGAMAL AA, 1987, IEEE T INFORM THEORY, V33, P116, DOI 10.1109/TIT.1987.1057277; GELFAND SB, 1985, 24TH P C DEC CONTR F, P779; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GIDAS B, 1985, J STAT PHYS, V39, P73, DOI 10.1007/BF01007975; GIDAS B, 1989, IEEE T PATTERN ANAL, V11, P164, DOI 10.1109/34.16712; HAJEK B, 1988, MATH OPER RES, V13, P311, DOI 10.1287/moor.13.2.311; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KITCHEN L, 1981, IEEE T SYST MAN CYB, V11, P597, DOI 10.1109/TSMC.1981.4308758; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION; MARROQUIN J, 1985, THESIS MIT; MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004; MITRA D, 1986, ADV APPL PROBAB, V18, P747, DOI 10.2307/1427186; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; PELI T, 1982, COMPUT VISION GRAPH, V20, P1, DOI 10.1016/0146-664X(82)90070-3; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; ROSENFELD A, 1981, IMAGE MODELING; SCHACHTER A, 1977, IEEE T SYST MAN CYB, V7, P813; Skiscim C. C., 1983, 1983 Winter Simulation Conference Proceedings, P523; TAN DHL, 1989, JUN P IEEE COMP VIS, P86; TAN HL, 1988, THESIS PURDUE U W LA; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769	36	44	49	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1992	14	1					3	18		10.1109/34.107010	http://dx.doi.org/10.1109/34.107010			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GV942					2022-12-18	WOS:A1992GV94200001
J	LI, XB				LI, XB			PARALLEL ALGORITHMS FOR HIERARCHICAL-CLUSTERING AND CLUSTER VALIDITY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											LI, XB (corresponding author), UNIV ALBERTA,DEPT COMP SCI,EDMONTON T6G 2H1,ALBERTA,CANADA.							BATCHER KE, 1977, IEEE T COMPUT, V26, P174, DOI 10.1109/TC.1977.5009297; DEKEL E, 1981, SIAM J COMPUT, V10, P657, DOI 10.1137/0210049; DUBES R, 1980, ADV COMPUT, V19, P113; FANG ZX, 1987, IEEE T PATTERN ANAL, V9, P835, DOI 10.1109/TPAMI.1987.4767990; HWANG K, 1984, COMPUTER ARCHITECTUR; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; LI X, 1989, PARALLEL COMPUT, V11, P275, DOI 10.1016/0167-8191(89)90036-7; LI X, 1988, 8821 U ALB DEP COMP; LI XB, 1989, PATTERN RECOGN, V22, P397, DOI 10.1016/0031-3203(89)90049-6; NI LM, 1985, IEEE T PATTERN ANAL, V7, P80, DOI 10.1109/TPAMI.1985.4767620; WU C, 1981, IEEE T COMPUT, V30, P324, DOI 10.1109/TC.1981.1675790	11	44	47	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1088	1092		10.1109/34.61708	http://dx.doi.org/10.1109/34.61708			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700006
J	DILL, AR; LEVINE, MD				DILL, AR; LEVINE, MD			MULTIPLE RESOLUTION SKELETONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MCGILL UNIV,MCGILL RES CTR INTELLIGENT MACHINES,COMP VIS & ROBOT LAB,MONTREAL H3A 2A7,QUEBEC,CANADA; MCGILL UNIV,FAC MED,MONTREAL H3A 2A7,QUEBEC,CANADA; MCGILL UNIV,FAC DENT,MONTREAL H3A 2A7,QUEBEC,CANADA	McGill University; McGill University; McGill University								ARCELLI C, 1981, COMPUT VISION GRAPH, V17, P130, DOI 10.1016/0146-664X(81)90021-6; ASADA H, 1984, MIT758 ART INT LAB M; BABAUD J, 1983, 20 FLAIR REP; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BLUM H, 1964, P S MODELS PERCEPTIO; BRADY M, 1984, MIT757 ART INT LAB M; CHEUNG ATW, 1982, J RETICULOENDOTH SOC, V31, P193; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DILL AR, 1985, P GRAPHICS INTERFACE, P389; Dyer C. R., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P333; FENG HYF, 1975, IEEE T COMPUT, VC 24, P636, DOI 10.1109/T-C.1975.224276; FISCHLER MA, 1983, 8TH P IJCAI, P1014; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; GALLUS G, 1970, PHYS MED BIOL, V15, P435, DOI 10.1088/0031-9155/15/3/004; GRINNELL F, 1982, J CELL SCI, V58, P95; Hilditch C.J., 1969, MACH INTELL, P403; HUMMEL RA, 1984, 111 NEW YORK U TECH; Levine M., 1985, VISION MAN MACHINE; LEVINE MD, 1983, COMPUT VISION GRAPH, V21, P58, DOI 10.1016/S0734-189X(83)80029-2; MACKWORTH AK, 1984, 5TH P CAN SOC COMP S, P114; MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486; NOBLE PB, 1986, COMPUTER ASSISTED AN; PAVLIDIS T, 1980, COMPUT VISION GRAPH, V13, P142, DOI 10.1016/S0146-664X(80)80037-2; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; Witkin AP, 1983, 8 INT JOINT C ART IN, P1019; YUILLE AL, 1983, MIT722 ART INT LAB M; 1983, WEBSTERS 9TH NEW COL	30	44	46	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1987	9	4					495	504		10.1109/TPAMI.1987.4767937	http://dx.doi.org/10.1109/TPAMI.1987.4767937			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H9088	21869407				2022-12-18	WOS:A1987H908800003
J	Zhang, DW; Han, JW; Cheng, G; Yang, MH				Zhang, Dingwen; Han, Junwei; Cheng, Gong; Yang, Ming-Hsuan			Weakly Supervised Object Localization and Detection: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Location awareness; Annotations; Training; Task analysis; Detectors; Supervised learning; Computer vision; Weakly supervised learning; object localization; object detection	TARGET DETECTION; DEEP; IMAGES; MODELS	As an emerging and challenging problem in the computer vision community, weakly supervised object localization and detection plays an important role for developing new generation computer vision systems and has received significant attention in the past decade. As methods have been proposed, a comprehensive survey of these topics is of great importance. In this work, we review (1) classic models, (2) approaches with feature representations from off-the-shelf deep networks, (3) approaches solely based on deep learning, and (4) publicly available datasets and standard evaluation metrics that are widely used in this field. We also discuss the key challenges in this field, development history of this field, advantages/disadvantages of the methods in each category, the relationships between methods in different categories, applications of the weakly supervised object localization and detection methods, and potential future directions to further promote the development of this research field.	[Zhang, Dingwen; Han, Junwei; Cheng, Gong] Northwestern Polytech Univ, Sch Automat, Brain & Artificial Intelligence Lab, Xian 710072, Shaanxi, Peoples R China; [Yang, Ming-Hsuan] Univ Calif Merced, EECS, Merced, CA 95344 USA	Northwestern Polytechnical University; University of California System; University of California Merced	Han, JW (corresponding author), Northwestern Polytech Univ, Sch Automat, Brain & Artificial Intelligence Lab, Xian 710072, Shaanxi, Peoples R China.	zdw@xidian.edu.cn; junweihan2010@gmail.com; gclieng@nwpu.edu.cn; mhyang@ucmerced.edu			National Key R&D Program of China [2017YFB1002201]; National Science Foundation of China [61876140, 61773301]; NSF CAREER [1149783]	National Key R&D Program of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD))	This work was supported in part by the National Key R&D Program of China under Grant 2017YFB1002201 and in part by the National Science Foundation of China under Grants 61876140 and 61773301. The work of Ming-Hsuan Yang was supported in part by the NSF CAREER under Grant 1149783.	Alexander Kolesnikov, 2016, Arxiv, DOI arXiv:1605.05538; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2007, PASCAL VISUAL OBJECT; Arun A, 2019, PROC CVPR IEEE, P9424, DOI 10.1109/CVPR.2019.00966; B.S. Manjunath, 2017, Arxiv, DOI arXiv:1708.01723; Bazzani L, 2016, IEEE WINT CONF APPL, DOI 10.1109/wacv.2016.7477688; Bency AJ, 2016, LECT NOTES COMPUT SC, V9905, P714, DOI 10.1007/978-3-319-46448-0_43; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bilen H, 2014, P BMVC 2014, P1997; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711; Blaschko M., 2010, ADV NEURAL INFORM PR; Bontempi D, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101688; Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286; Cao LJ, 2017, PATTERN RECOGN, V64, P417, DOI 10.1016/j.patcog.2016.10.033; Chanda O., 2017, PROC BRIT MACH VIS C; Chen GB, 2017, ADV NEUR IN, V30; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen XL, 2015, IEEE I CONF COMP VIS, P1431, DOI 10.1109/ICCV.2015.168; Chen-Lin Zhang, 2017, Arxiv, DOI arXiv:1705.02758; Cheng G, 2020, IEEE T IMAGE PROCESS, V29, P5794, DOI 10.1109/TIP.2020.2987161; Hsu CY, 2021, Arxiv, DOI arXiv:2103.04009; Choe J, 2020, PROC CVPR IEEE, P3130, DOI 10.1109/CVPR42600.2020.00320; Choe J, 2019, PROC CVPR IEEE, P2214, DOI 10.1109/CVPR.2019.00232; Cholakkal H, 2016, PROC CVPR IEEE, P5278, DOI 10.1109/CVPR.2016.570; Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231; Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309; Crandall DJ, 2006, LECT NOTES COMPUT SC, V3951, P16; Cristian Sminchisescu, 2014, Arxiv, DOI arXiv:1412.0100; Crowley EJ, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.39; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Deselaers T, 2010, LECT NOTES COMPUT SC, V6314, P452, DOI 10.1007/978-3-642-15561-1_33; Deyu Meng, 2017, Arxiv, DOI arXiv:1703.01290; Diba A, 2019, IEEE COMPUT SOC CONF, P601, DOI 10.1109/CVPRW.2019.00086; Diba A, 2017, PROC CVPR IEEE, P5131, DOI 10.1109/CVPR.2017.545; Dit-Yan Yeung, 2019, Arxiv, DOI arXiv:1905.08586; Huh D, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), P263, DOI 10.1109/ICAIIC.2019.8668987; Dong XY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P279, DOI 10.1145/3123266.3123455; Durand T, 2017, PROC CVPR IEEE, P5957, DOI 10.1109/CVPR.2017.631; Durand T, 2016, PROC CVPR IEEE, P4743, DOI 10.1109/CVPR.2016.513; Eric Tzeng, 2013, Arxiv, DOI arXiv:1310.1531; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264; Fan Ma, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P420, DOI 10.1007/978-3-030-58548-8_25; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Feng XX, 2021, IEEE T GEOSCI REMOTE, V59, P6946, DOI 10.1109/TGRS.2020.3030990; Feng XX, 2020, IEEE T GEOSCI REMOTE, V58, P8002, DOI 10.1109/TGRS.2020.2985989; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; Florian Dubost, 2020, Arxiv, DOI arXiv:1906.01891; Galleguillos C, 2008, LECT NOTES COMPUT SC, V5302, P193, DOI 10.1007/978-3-540-88682-2_16; Gao MF, 2018, LECT NOTES COMPUT SC, V11205, P155, DOI 10.1007/978-3-030-01246-5_10; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Gao W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2866, DOI 10.1109/ICCV48922.2021.00288; Gao Y, 2019, IEEE I CONF COMP VIS, P9833, DOI 10.1109/ICCV.2019.00993; Ge WF, 2018, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2018.00139; Girshick R., 2014, PROC IEEE C COMPUT V; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Gondal WM, 2017, IEEE IMAGE PROC, P2069; Gonthier N, 2019, LECT NOTES COMPUT SC, V11130, P692, DOI 10.1007/978-3-030-11012-3_53; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gudi A., 2017, PROC BRIT MACH VIS C; Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hariharan B, 2012, LECT NOTES COMPUT SC, V7575, P459, DOI 10.1007/978-3-642-33765-9_33; Hoai M, 2014, PATTERN RECOGN, V47, P1523, DOI 10.1016/j.patcog.2013.09.028; Hoffman J, 2015, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2015.7298906; Hong WX, 2018, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2018.00145; Huang C, 2017, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2017.21; Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291; Huang SJ, 2019, IEEE T PATTERN ANAL, V41, P2614, DOI 10.1109/TPAMI.2018.2861732; Huang Z., 2020, P ADV NEUR INF PROC, V33, P16797; Hyun Oh Song, 2014, Arxiv, DOI arXiv:1403.1024; Hyunjung Shim, 2018, Arxiv, DOI arXiv:1802.07888; Inoue N, 2018, PROC CVPR IEEE, P5001, DOI 10.1109/CVPR.2018.00525; Ji ZHX, 2019, LECT NOTES COMPUT SC, V11766, P175, DOI 10.1007/978-3-030-32248-9_20; Jiajie Wang, 2018, Arxiv, DOI arXiv:1802.03531; Jiang PT, 2019, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2019.00216; Jie ZQ, 2016, ADV NEUR IN, V29; Jie ZQ, 2017, PROC CVPR IEEE, P4294, DOI 10.1109/CVPR.2017.457; Jinming Duan, 2020, Arxiv, DOI arXiv:2007.09727; Jost Tobias Springenberg, 2016, Arxiv, DOI arXiv:1511.06390; Kanezaki A., 2013, P 21 ACM INT C MULT, P605; Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22; Khan I., 2011, PROC 35 OAGMAAPR WOR; Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181; Kim D., 2019, ARXIV; Kosugi S, 2019, IEEE I CONF COMP VIS, P6063, DOI 10.1109/ICCV.2019.00616; Krapac J., 2015, PROC INT C COMPUT VI, P431; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Larochelle H., 2010, ADV NEURAL INFORM PR, P1243; Li C, 2015, P 2 INT WORKSHOP ENV, P9; Li GB, 2018, AAAI CONF ARTIF INTE, P7024; Li S., 2017, PROC BRIT MACH VIS C; Li Y, 2019, IEEE T PATTERN ANAL, V41, P639, DOI 10.1109/TPAMI.2018.2810288; Li YS, 2018, ISPRS J PHOTOGRAMM, V146, P182, DOI 10.1016/j.isprsjprs.2018.09.014; Liang XD, 2017, PROC CVPR IEEE, P4408, DOI 10.1109/CVPR.2017.469; Liang XD, 2015, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2015.120; Liu MX, 2020, IEEE T CYBERNETICS, V50, P3381, DOI 10.1109/TCYB.2019.2904186; Mai Jinjie, 2020, P IEEE CVF C COMP VI, P8766; Nguyen MH, 2009, IEEE I CONF COMP VIS, P1925, DOI 10.1109/ICCV.2009.5459426; Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706; Rahimi Amir, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P395, DOI 10.1007/978-3-030-58586-0_24; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren WQ, 2016, IEEE T PATTERN ANAL, V38, P405, DOI 10.1109/TPAMI.2015.2456908; Rochan M, 2015, PROC CVPR IEEE, P4315, DOI 10.1109/CVPR.2015.7299060; Rochan M, 2016, IMAGE VISION COMPUT, V56, P1, DOI 10.1016/j.imavis.2016.08.015; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sangheum Hwang, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P239, DOI 10.1007/978-3-319-46723-8_28; Sangineto E, 2019, IEEE T PATTERN ANAL, V41, P712, DOI 10.1109/TPAMI.2018.2804907; Schroeter J, 2019, PR MACH LEARN RES, V97; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Shaban A, 2019, IEEE I CONF COMP VIS, P5116, DOI 10.1109/ICCV.2019.00522; Shen Y, 2020, IEEE CVF C COMP VIS, P11326; Shen YH, 2018, PROC CVPR IEEE, P5764, DOI 10.1109/CVPR.2018.00604; Shen YH, 2019, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2019.00079; Shen YH, 2018, IEEE T NEUR NET LEAR, V29, P5960, DOI 10.1109/TNNLS.2018.2816021; Shi MJ, 2017, IEEE I CONF COMP VIS, P3401, DOI 10.1109/ICCV.2017.366; Shi MJ, 2016, LECT NOTES COMPUT SC, V9909, P105, DOI 10.1007/978-3-319-46454-1_7; Shi Z., 2017, ARXIV; Shi ZY, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.78; Shi ZY, 2015, IEEE T PATTERN ANAL, V37, P1959, DOI 10.1109/TPAMI.2015.2392769; Shi Z, 2013, IEEE I CONF COMP VIS, P2984, DOI 10.1109/ICCV.2013.371; Shou Z, 2018, LECT NOTES COMPUT SC, V11220, P162, DOI 10.1007/978-3-030-01270-0_10; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Sikka K, 2013, IEEE INT CONF AUTOMA; Singh KK, 2019, PROC CVPR IEEE, P9406, DOI 10.1109/CVPR.2019.00964; Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381; Singh KK, 2016, PROC CVPR IEEE, P3548, DOI 10.1109/CVPR.2016.386; Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416; Siva P, 2012, LECT NOTES COMPUT SC, V7574, P594, DOI 10.1007/978-3-642-33712-3_43; Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261; Song HO., 2014, ADV NEURAL INFORM PR, V2, P1637; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Sun C, 2016, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2016.379; Tang K, 2014, PROC CVPR IEEE, P1464, DOI 10.1109/CVPR.2014.190; Tang P, 2018, LECT NOTES COMPUT SC, V11215, P370, DOI 10.1007/978-3-030-01252-6_22; Tang P, 2020, IEEE T PATTERN ANAL, V42, P176, DOI 10.1109/TPAMI.2018.2876304; Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326; Tang P, 2017, PATTERN RECOGN, V71, P446, DOI 10.1016/j.patcog.2017.05.001; Tang YX, 2017, IEEE T MULTIMEDIA, V19, P393, DOI 10.1109/TMM.2016.2614862; Tang YX, 2014, IEEE IMAGE PROC, P4072, DOI 10.1109/ICIP.2014.7025827; Tao QY, 2019, IEEE T MULTIMEDIA, V21, P1135, DOI 10.1109/TMM.2018.2875597; Teh Eu Wern, 2016, BRIT MACH VIS C BMVC; Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780; Uijlings JRR, 2018, PROC CVPR IEEE, P1101, DOI 10.1109/CVPR.2018.00121; Wah C., 2011, TECH REP; Wan F, 2019, PROC CVPR IEEE, P2194, DOI 10.1109/CVPR.2019.00230; Wan F, 2018, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2018.00141; Wan F, 2016, IEEE IMAGE PROC, P3638, DOI 10.1109/ICIP.2016.7533038; Wan ZQ, 2017, IEEE IMAGE PROC, P4177; Wang C, 2014, IEEE IMAGE PROC, P4067, DOI 10.1109/ICIP.2014.7025826; Wang C, 2015, IEEE T IMAGE PROCESS, V24, P1371, DOI 10.1109/TIP.2015.2396361; Wang LT, 2017, IEEE T CYBERNETICS, V47, P1313, DOI 10.1109/TCYB.2017.2647965; Wang LT, 2014, IEEE IMAGE PROC, P1614, DOI 10.1109/ICIP.2014.7025323; Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678; Wang RZ, 2019, IEEE T MED IMAGING, V38, P1501, DOI 10.1109/TMI.2018.2885376; Wang S., 2012, P AS C COMP VIS, P796; Wang S, 2013, PROC CVPR IEEE, P3111, DOI 10.1109/CVPR.2013.400; Wang WH, 2013, IEEE WORK APP COMP, P331, DOI 10.1109/WACV.2013.6475037; Wang XG, 2018, PATTERN RECOGN, V74, P15, DOI 10.1016/j.patcog.2017.08.026; Wang XG, 2015, IEEE I CONF COMP VIS, P1224, DOI 10.1109/ICCV.2015.145; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wei XS, 2019, PATTERN RECOGN, V88, P113, DOI 10.1016/j.patcog.2018.10.022; Wei YC, 2018, LECT NOTES COMPUT SC, V11215, P454, DOI 10.1007/978-3-030-01252-6_27; Wilhelm T., 2017, PROC INT C DIGIT IMA, P1; Wonho Bae, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P618, DOI 10.1007/978-3-030-58555-6_37; Wu B., 2007, PROC IEEE C COMPUT V, P1, DOI 10.1109/cvpr.2007.383042; Wu JJ, 2015, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2015.7298968; Wu K, 2019, LECT NOTES COMPUT SC, V11766, P211, DOI 10.1007/978-3-030-32248-9_24; Xie Y, 2013, 2013 INFORMATION THEORY AND APPLICATIONS WORKSHOP (ITA); Xu BC, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P941, DOI 10.1145/3292500.3330830; Xu WJ, 2020, NEURAL PROCESS LETT, V51, P993, DOI 10.1007/s11063-019-10124-7; Xue HL, 2019, IEEE I CONF COMP VIS, P6588, DOI 10.1109/ICCV.2019.00669; Yang K, 2019, IEEE I CONF COMP VIS, P8371, DOI 10.1109/ICCV.2019.00846; Yang S, 2020, IEEE WINT CONF APPL, P2930, DOI 10.1109/WACV45572.2020.9093566; Yang ZH, 2019, PROC CVPR IEEE, P2912, DOI 10.1109/CVPR.2019.00303; Yao XW, 2021, IEEE T GEOSCI REMOTE, V59, P675, DOI 10.1109/TGRS.2020.2991407; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]; Yuanyi Zhong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P615, DOI 10.1007/978-3-030-58574-7_37; Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612; Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148; Yunhang Shen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P118, DOI 10.1007/978-3-030-58598-3_8; Zadrija V, 2018, COMPUT VIS IMAGE UND, V176, P9, DOI 10.1016/j.cviu.2018.10.004; Zadrija V, 2015, LECT NOTES COMPUT SC, V9358, P492, DOI 10.1007/978-3-319-24947-6_41; Zbou BL, 2015, PROC CVPR IEEE, P1492, DOI 10.1109/CVPR.2015.7298756; Zhang Chen-Lin, 2020, P IEEE CVF C COMP VI, P13460; Zhang DW, 2019, IEEE T CIRC SYST VID, V29, P3622, DOI 10.1109/TCSVT.2018.2884173; Zhang DW, 2019, INT J COMPUT VISION, V127, P363, DOI 10.1007/s11263-018-1112-4; Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P475, DOI 10.1109/TPAMI.2018.2881114; Zhang DW, 2017, PROC CVPR IEEE, P3587, DOI 10.1109/CVPR.2017.382; Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393; Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4; Zhang DW, 2015, IEEE GEOSCI REMOTE S, V12, P701, DOI 10.1109/LGRS.2014.2358994; Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P5553, DOI 10.1109/TGRS.2016.2569141; Zhang M, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102903; Zhang X., 2020, ECCV, P271; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhang XL, 2018, LECT NOTES COMPUT SC, V11216, P610, DOI 10.1007/978-3-030-01258-8_37; Zhang XP, 2018, LECT NOTES COMPUT SC, V11207, P248, DOI 10.1007/978-3-030-01219-9_15; Zhang XP, 2018, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR.2018.00448; Zhang Y., 2010, P BRIT MACH VIS C, P1; Zhang YL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3441, DOI 10.1145/3132747.3132768; Zhang YQ, 2018, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.2018.00103; Zhao L, 2005, IEEE I CONF COMP VIS, P454; Zhongzheng Ren, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10595, DOI 10.1109/CVPR42600.2020.01061; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou PC, 2016, MULTIDIM SYST SIGN P, V27, P925, DOI 10.1007/s11045-015-0370-3; Zhou PC, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P318, DOI 10.1109/BigMM.2015.13; Zhou Y., 2019, ARXIV; Zhu Y, 2017, IEEE I CONF COMP VIS, P1859, DOI 10.1109/ICCV.2017.204; Zhu Y, 2015, PROC CVPR IEEE, P4703, DOI 10.1109/CVPR.2015.7299102	217	43	43	44	62	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5866	5885		10.1109/TPAMI.2021.3074313	http://dx.doi.org/10.1109/TPAMI.2021.3074313			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33877967	Green Submitted			2022-12-18	WOS:000836666600094
J	Rocco, I; Arandjelovic, R; Sivic, J				Rocco, Ignacio; Arandjelovic, Relja; Sivic, Josef			Convolutional Neural Network Architecture for Geometric Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional neural network; geometric matching; image alignment; category-level matching	OBJECT; FEATURES; MODEL	We address the problem of determining correspondences between two images in agreement with a geometric model such as an affine, homography or thin-plate spline transformation, and estimating its parameters. The contributions of this work are three-fold. First, we propose a convolutional neural network architecture for geometric matching. The architecture is based on three main components that mimic the standard steps of feature extraction, matching and simultaneous inlier detection and model parameter estimation, while being trainable end-to-end. Second, we demonstrate that the network parameters can be trained from synthetically generated imagery without the need for manual annotation and that our matching layer significantly increases generalization capabilities to never seen before images. Finally, we show that the same model can perform both instance-level and category-level matching giving state-of-the-art results on the challenging PF, TSS and Caltech-101 datasets.	[Rocco, Ignacio; Sivic, Josef] PSL Res Univ, Ecole Normale Super, CNRS, INRIA,Dept Informat, F-75005 Paris, France; [Arandjelovic, Relja] DeepMind, London N1C 4AG, England; [Sivic, Josef] Czech Tech Univ, Czech Inst Informat Robot & Cybernet, Prague 616636, Czech Republic	Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Universite Paris Cite; Czech Technical University Prague	Rocco, I (corresponding author), PSL Res Univ, Ecole Normale Super, CNRS, INRIA,Dept Informat, F-75005 Paris, France.	ignacio.rocco@inria.fr; relja@google.com; josef.sivic@inria.fr	Rocco, Ignacio/AAH-5435-2019	Rocco, Ignacio/0000-0002-9638-0508	ERC grant LEAP [336845]; ANR project Semapolis [ANR-13-CORD-0003]; CIFAR Learning in Machines Brains program; European Regional Development Fund under the project IMPACT [CZ.02.1.01/0.0/0.0/15_003/0000468]	ERC grant LEAP; ANR project Semapolis(French National Research Agency (ANR)); CIFAR Learning in Machines Brains program; European Regional Development Fund under the project IMPACT	This work has been partly supported by ERC grant LEAP (no. 336845), ANR project Semapolis (ANR-13-CORD-0003), the Inria CityLab IPL, CIFAR Learning in Machines & Brains program and the European Regional Development Fund under the project IMPACT (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000468).	Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Altwaijry H, 2016, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2016.385; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Aubry M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591009; Azizpour H, 2016, IEEE T PATTERN ANAL, V38, P1790, DOI 10.1109/TPAMI.2015.2500224; Balntas V., 2016, 160105030 ARXIV; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Berg AC, 2005, PROC CVPR IEEE, P26; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; DeTone D., 2016, 160603798 ARXIV; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445; Everingham M., 2012, PASCAL VISUAL OBJECT; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forsyth D. A., 2002, COMPUTER VIS MODERN; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965; Ham B, 2018, IEEE T PATTERN ANAL, V40, P1711, DOI 10.1109/TPAMI.2017.2724510; Ham B, 2016, PROC CVPR IEEE, P3475, DOI 10.1109/CVPR.2016.378; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jahrer M., 2008, P COMP VIS WINT WORK, P39; Kanazawa A, 2016, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2016.354; Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lamdan Y., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P335, DOI 10.1109/CVPR.1988.196257; Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Long J. L., 2014, ADV NEURAL INFORM PR, V27, P1601; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9; Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374; Revaud J, 2016, INT J COMPUT VISION, V120, P300, DOI 10.1007/s11263-016-0908-3; Rocco I, 2018, PROC CVPR IEEE, P6917, DOI 10.1109/CVPR.2018.00723; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Taniai T, 2016, PROC CVPR IEEE, P4246, DOI 10.1109/CVPR.2016.460; Thewlis J., 2016, P BRIT MACH VIS C; Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175; Yancheshmeh FS, 2015, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2015.7298908; Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yu GS, 2011, IMAGE PROCESS ON LIN, V1, P11, DOI 10.5201/ipol.2011; ZAGORUYKO S, 2015, 2015 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2015.7299064; Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20; Zhou TH, 2015, PROC CVPR IEEE, P1191, DOI 10.1109/CVPR.2015.7298723; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	62	43	49	8	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2553	2567		10.1109/TPAMI.2018.2865351	http://dx.doi.org/10.1109/TPAMI.2018.2865351			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30106710	Green Submitted			2022-12-18	WOS:000489838200002
J	Oh, TH; Matsushita, Y; Tai, YW; Kweon, IS				Oh, Tae-Hyun; Matsushita, Yasuyuki; Tai, Yu-Wing; Kweon, In So			Fast Randomized Singular Value Thresholding for Low-Rank Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Singular value thresholding; rank minimization; nuclear norm minimization; robust principal component analysis; low-rank approximation	APPROXIMATION; ALGORITHMS; DECOMPOSITION; MINIMIZATION	Rank minimization can be converted into tractable surrogate problems, such as Nuclear Norm Minimization (NNM) and Weighted NNM (WNNM). The problems related to NNM, or WNNM, can be solved iteratively by applying a closed-form proximal operator, called Singular Value Thresholding (SVT), or Weighted SVT, but they suffer from high computational cost of Singular Value Decomposition (SVD) at each iteration. We propose a fast and accurate approximation method for SVT, that we call fast randomized SVT (FRSVT), with which we avoid direct computation of SVD. The key idea is to extract an approximate basis for the range of the matrix from its compressed matrix. Given the basis, we compute partial singular values of the original matrix from the small factored matrix. In addition, by developping a range propagation method, our method further speeds up the extraction of approximate basis at each iteration. Our theoretical analysis shows the relationship between the approximation bound of SVD and its effect to NNM via SVT. Along with the analysis, our empirical results quantitatively and qualitatively show that our approximation rarely harms the convergence of the host algorithms. We assess the efficiency and accuracy of the proposed method on various computer vision problems, e.g., subspace clustering, weather artifact removal, and simultaneous multi-image alignment and rectification.	[Oh, Tae-Hyun; Kweon, In So] Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon 34141, South Korea; [Matsushita, Yasuyuki] Osaka Univ, Suita, Osaka 5650871, Japan; [Tai, Yu-Wing] Tencent, Shanghai 518057, Peoples R China	Korea Advanced Institute of Science & Technology (KAIST); Osaka University; Tencent	Oh, TH (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon 34141, South Korea.	thoh.kaist.ac.kr@gmail.com; yasumat@ist.osaka-u.ac.jp; yuwing@gmail.com; iskweon77@kaist.ac.kr	Kweon, In So/C-2023-2011; Oh, Tae-Hyun/D-7854-2016	Oh, Tae-Hyun/0000-0003-0468-1571; Matsushita, Yasuyui/0000-0002-1935-4752	NRF of Korea - Korea government, MSIP [2010-0028680]; JSPS KAKENHI [JP16H01732]; Grants-in-Aid for Scientific Research [16H01732] Funding Source: KAKEN	NRF of Korea - Korea government, MSIP(National Research Foundation of Korea); JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); Grants-in-Aid for Scientific Research(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	The first and fourth authors were supported by the NRF of Korea grant funded by the Korea government, MSIP (No. 2010-0028680). The second author was partly supported by JSPS KAKENHI Grant Number JP16H01732. Tae-Hyun Oh is the corresponding author.	Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Cai JF, 2013, METHODS APPL ANAL, V20, P335, DOI 10.4310/MAA.2013.v20.n4.a2; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247; Drineas P, 2006, SIAM J COMPUT, V36, P158, DOI 10.1137/S0097539704442696; Eriksson A, 2012, IEEE T PATTERN ANAL, V34, P1681, DOI 10.1109/TPAMI.2012.116; GANESH A, 2009, 2009 3 IEEE INT, P213; Golub G. H., 2012, MATRIX COMPUTATIONS; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920; Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806; HIGHAM NJ, 1986, SIAM J SCI STAT COMP, V7, P1160, DOI 10.1137/0907079; Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271; Ji Shuiwang, 2009, INT C MACH LEARN ICM, DOI DOI 10.1145/1553374.1553434; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Lin Z., 2011, ARXIV11081548; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Lin Z, 2009, UILUENG092215 UIUC; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2012, NEURAL COMPUT, V24, P3371, DOI 10.1162/NECO_a_00369; Liu RS, 2014, NEUROCOMPUTING, V142, P529, DOI 10.1016/j.neucom.2014.03.046; Lu CY, 2014, PROC CVPR IEEE, P4130, DOI 10.1109/CVPR.2014.526; Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277; Ma SQ, 2011, MATH PROGRAM, V128, P321, DOI 10.1007/s10107-009-0306-5; Mahoney MW, 2011, FOUND TRENDS MACH LE, V3, P123, DOI 10.1561/2200000035; Mohan K, 2012, J MACH LEARN RES, V13, P3441; Oh T.-H., 2016, ADV NEURAL INFORM PR, P1390; Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956; Oh TH, 2015, PROC CVPR IEEE, P4484, DOI 10.1109/CVPR.2015.7299078; Oh TH, 2015, IEEE T PATTERN ANAL, V37, P1219, DOI 10.1109/TPAMI.2014.2361338; Oh TH, 2013, IEEE I CONF COMP VIS, P145, DOI 10.1109/ICCV.2013.25; Oh TH, 2013, IEEE IMAGE PROC, P790, DOI 10.1109/ICIP.2013.6738163; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; PIERRA G, 1984, MATH PROGRAM, V28, P96, DOI 10.1007/BF02612715; Sanderson C., 2016, J OPEN SOURCE SOFTWA, V1, P26, DOI [10.21105/joss.00026, DOI 10.21105/JOSS.00026]; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Wei S., 2010, MSRTR2010162; Wipf D., 2012, P 28 C UNC ART INT U, P914; Woolfe F, 2008, APPL COMPUT HARMON A, V25, P335, DOI 10.1016/j.acha.2007.12.002; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Yadong Mu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2609, DOI 10.1109/CVPR.2011.5995369; Zhang X., 2013, ADV NEURAL INF PROCE, V26, P1637; Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x; Zheng YQ, 2012, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2012.6247828	46	43	45	2	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					376	391		10.1109/TPAMI.2017.2677440	http://dx.doi.org/10.1109/TPAMI.2017.2677440			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28278459	Green Submitted			2022-12-18	WOS:000422706000009
J	Hane, C; Zach, C; Cohen, A; Pollefeys, M				Hane, Christian; Zach, Christopher; Cohen, Andrea; Pollefeys, Marc			Dense Semantic 3D Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Volumetric reconstruction; semantic labeling; convex formulation; multi-label segmentation; semantic 3D modeling		Both image segmentation and dense 3D modeling from images represent an intrinsically ill-posed problem. Strong regularizers are therefore required to constrain the solutions from being 'too noisy'. These priors generally yield overly smooth reconstructions and/or segmentations in certain regions while they fail to constrain the solution sufficiently in other areas. In this paper, we argue that image segmentation and dense 3D reconstruction contribute valuable information to each other's task. As a consequence, we propose a mathematical framework to formulate and solve a joint segmentation and dense reconstruction problem. On the one hand knowing about the semantic class of the geometry provides information about the likelihood of the surface direction. On the other hand the surface direction provides information about the likelihood of the semantic class. Experimental results on several data sets highlight the advantages of our joint formulation. We show how weakly observed surfaces are reconstructed more faithfully compared to a geometry only reconstruction. Thanks to the volumetric nature of our formulation we also infer surfaces which cannot be directly observed for example the surface between the ground and a building. Finally, our method returns a semantic segmentation which is consistent across the whole dataset.	[Hane, Christian] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA; [Zach, Christopher] Cambridge Res Lab Toshiba Res Europe, Cambridge CB4 0GZ, England; [Cohen, Andrea] Swiss Fed Inst Technol, Dept Comp Sci, CH-8092 Zurich, Switzerland; [Pollefeys, Marc] Swiss Fed Inst Technol, Dept Comp Sci, CH-8092 Zurich, Switzerland; [Pollefeys, Marc] Microsoft, Redmond, WA 98052 USA	University of California System; University of California Berkeley; Swiss Federal Institutes of Technology Domain; ETH Zurich; Swiss Federal Institutes of Technology Domain; ETH Zurich; Microsoft	Hane, C (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.	chaene@eecs.berkeley.edu; chzach@crl.toshiba.co.uk; andrea.cohen@inf.ethz.ch; marc.pollefeys@inf.ethz.ch	Pollefeys, Marc/I-7607-2013		4DVideo ERC under EC [210806]; V-Charge under EC [269916]; Swiss National Science Foundation [157101]	4DVideo ERC under EC; V-Charge under EC; Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	We would like to thank Lubor Ladicky for providing the output of his semantic classifier and Roland Angst for his help on the earlier version [13] of this paper. Furthermore, we gratefully acknowledge the support of the 4DVideo ERC starting grant #210806 and V-Charge grant #269916 both under the EC's FP7/2007-2013 and the Swiss National Science Foundation project # 157101.	Bao SY, 2013, PROC CVPR IEEE, P1264, DOI 10.1109/CVPR.2013.167; Blaha M., 2016, IEEE C COMP VIS PATT; Bleyer M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3081, DOI 10.1109/CVPR.2011.5995581; Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005; Chambolle A., 2008, 649 EC POL; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Cohen A, 2012, PROC CVPR IEEE, P1514, DOI 10.1109/CVPR.2012.6247841; Esedoglu S, 2004, COMMUN PUR APPL MATH, V57, P1609, DOI 10.1002/cpa.20045; Felzenszwalb PF, 2010, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2010.5540067; Gould S, 2010, STAIR VISION LIB; Hane C, 2014, PROC CVPR IEEE, P652, DOI 10.1109/CVPR.2014.89; Hane C, 2013, PROC CVPR IEEE, P97, DOI 10.1109/CVPR.2013.20; Hane C, 2011, IEEE INT C INT ROBOT, P1618, DOI 10.1109/IROS.2011.6048261; Hane Christian, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P57, DOI 10.1109/3DV.2014.77; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Jancosek M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3121, DOI 10.1109/CVPR.2011.5995693; Kim BS, 2013, IEEE I CONF COMP VIS, P1425, DOI 10.1109/ICCV.2013.180; Kolev K, 2010, LECT NOTES COMPUT SC, V6313, P538; Kundu A, 2014, LECT NOTES COMPUT SC, V8694, P703, DOI 10.1007/978-3-319-10599-4_45; Ladicky L., 2010, BMVC, P1; Ladicky L, 2014, LECT NOTES COMPUT SC, V8693, P468, DOI 10.1007/978-3-319-10602-1_31; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Ladicky Lubor, 2016, P IEEE C COMP VIS PA; Lellmann J, 2011, SIAM J IMAGING SCI, V4, P1049, DOI 10.1137/100805844; Lempitsky V., 2007, P IEEE C COMP VIS PA; Liu SB, 2011, PROC CVPR IEEE, P913, DOI 10.1109/CVPR.2011.5995334; Liu XQ, 2010, IEEE T PATTERN ANAL, V32, P1182, DOI 10.1109/TPAMI.2009.120; Melonakos J, 2008, IEEE T PATTERN ANAL, V30, P412, DOI 10.1109/TPAMI.2007.70713; Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374; Pock T, 2011, IEEE I CONF COMP VIS, P1762, DOI 10.1109/ICCV.2011.6126441; Pock T, 2009, PROC CVPR IEEE, P810, DOI 10.1109/CVPRW.2009.5206604; Quan L, 2007, INT J COMPUT VISION, V75, P135, DOI 10.1007/s11263-007-0044-1; Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y; Sayinov N, 2015, PROC CVPR IEEE, P5511, DOI 10.1109/CVPR.2015.7299190; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Strecha C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587706; Strekalovskiy E, 2011, IEEE I CONF COMP VIS, P2619, DOI 10.1109/ICCV.2011.6126551; Vineet V., 2015, P INT C ROB AUT; Zach C., 2007, P 11 IEEE INT C COMP, P1, DOI DOI 10.1109/ICCV.2007.4408983; Zach C., 2008, P INT S 3D DAT PROC, V1; Zach C, 2014, IEEE T PATTERN ANAL, V36, P157, DOI 10.1109/TPAMI.2013.105; Zach C, 2010, PROC CVPR IEEE, P1426, DOI 10.1109/CVPR.2010.5539801; Zach C, 2009, LECT NOTES COMPUT SC, V5748, P552, DOI 10.1007/978-3-642-03798-6_56; Zach C, 2009, PROC CVPR IEEE, P1911, DOI 10.1109/CVPRW.2009.5206565	45	43	44	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1730	1743		10.1109/TPAMI.2016.2613051	http://dx.doi.org/10.1109/TPAMI.2016.2613051			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	28113966				2022-12-18	WOS:000406840800003
J	Ramalingam, S; Sturm, P				Ramalingam, Srikumar; Sturm, Peter			A Unifying Model for Camera Calibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Camera calibration; generic imaging model; non-central; cata-dioptric; omni-directional	PERSPECTIVE; GEOMETRY; STEREO	This paper proposes a unified theory for calibrating a wide variety of cameramodels such as pinhole, fisheye, cata-dioptric, and multi-camera networks. Wemodel any camera as a set of image pixels and their associated camera rays in space. Every pixelmeasures the light traveling along a (half-) ray in 3-space, associated with that pixel. By this definition, calibration simply refers to the computation of the mapping between pixels and the associated 3D rays. Such amapping can be computed using images of calibration grids, which are objects with known 3D geometry, taken fromunknown positions. This general cameramodel allows to represent non-central cameras; we also consider two special subclasses, namely central and axial cameras. In a central camera, all rays intersect in a single point, whereas the rays are completely arbitrary in a non-central one. Axial cameras are an intermediate case: the camera rays intersect a single line. In thiswork, we show the theory for calibrating central, axial and non-centralmodels using calibration grids, which can be either three-dimensional or planar.	[Ramalingam, Srikumar] MERL, Cambridge, MA 02139 USA; [Sturm, Peter] Univ Grenoble Alpes, LJK, INRIA Grenoble Rhone Alpes, F-38400 St Martin Dheres, France	Communaute Universite Grenoble Alpes; UDICE-French Research Universities; Universite Grenoble Alpes (UGA)	Ramalingam, S (corresponding author), MERL, Cambridge, MA 02139 USA.	srikumar.ramalingam@gmail.com; peter.sturm@inria.fr						Adelson E., 1991, PLENOPTIC FUNCTION E; Agrawal A, 2012, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2012.6248073; Agrawal A, 2010, LECT NOTES COMPUT SC, V6313, P129; Aliaga DG, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P127, DOI 10.1109/ICCV.2001.937508; Baker S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P35, DOI 10.1109/ICCV.1998.710698; Bakstein H., 2001, COMPUTER VISION WINT, V2; Dunn A, 2007, P 11 INT C COMP VIS, P1; Dunne A K, 2007, P IAPR C MACH VIS AP, P114; Feldman D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P988; Geyer Christopher, 2000, LNCS, P445, DOI DOI 10.1007/3-540-45053-X_29; Gortler S.J., 1996, ACM T GRAPHIC, V23, P43, DOI DOI 10.1145/237170.237200; Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611; Grossmann E, 2008, LECT NOTES COMPUT SC, V5305, P228, DOI 10.1007/978-3-540-88693-8_17; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; Heung-Yeung Shum, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P22, DOI 10.1109/ICCV.1999.791193; Hicks RA, 2000, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2000.855867; Lee G. H., 2013, P IEEE INT C ROB AUT, P521; Lee GH, 2013, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2013.354; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Li HF, 2008, CURR MED RES OPIN, V24, P1, DOI [10.1185/030079908X253933, 10.1088/0256-307X/24/3/072]; Mei C, 2007, IEEE INT CONF ROBOT, P3945, DOI 10.1109/ROBOT.2007.364084; Micusik B., 2004, P AS C COMP VIS ACCV, P748; Miraldo P, 2014, IEEE INT CONF ROBOT, P2119, DOI 10.1109/ICRA.2014.6907150; Miraldo P, 2013, IEEE T PATTERN ANAL, V35, P2091, DOI 10.1109/TPAMI.2012.258; Miraldo P, 2011, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2011.6126511; Neumann J, 2003, PROC CVPR IEEE, P294; Nister D, 2004, PROC CVPR IEEE, P560; Nister D, 2005, IEEE I CONF COMP VIS, P120; Pajdla T, 2002, INT J COMPUT VISION, V47, P161, DOI 10.1023/A:1014593824520; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520; Ponce J, 2009, PROC CVPR IEEE, P1526, DOI 10.1109/CVPRW.2009.5206668; Ramalingam S, 2005, PROC CVPR IEEE, P1093; Ramalingam S., 2007, THESIS; Ramalingam S., 2004, OMNIVIS CONJUNCTION; Ramalingam S, 2006, COMPUT VIS IMAGE UND, V103, P218, DOI 10.1016/j.cviu.2006.06.006; Scaramuzza D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5695, DOI 10.1109/IROS.2006.282372; Seitz SM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937495; Shashua A, 2000, LECT NOTES COMPUT SC, V1842, P507; Sturm P, 2005, PROC CVPR IEEE, P206; Sturm P, 2004, LECT NOTES COMPUT SC, V3022, P1; Sturm P., 1999, P IEEE C COMP VIS PA, P432, DOI DOI 10.1109/CVPR.1999.786974; Sturm P., 2011, FDN TRENDS COMPUT GR, V61; Swaminathan R, 2003, PROC CVPR IEEE, P594; Tardif JP, 2009, IEEE T PATTERN ANAL, V31, P1552, DOI 10.1109/TPAMI.2008.202; Thirthala S., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision, P1539; Thirthala S, 2012, INT J COMPUT VISION, V96, P195, DOI 10.1007/s11263-011-0463-x; Wexler Y, 2003, PROC CVPR IEEE, P209; Wood D. N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P243, DOI 10.1145/258734.258859; Yu JY, 2004, LECT NOTES COMPUT SC, V3022, P14; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	51	43	48	6	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1309	1319		10.1109/TPAMI.2016.2592904	http://dx.doi.org/10.1109/TPAMI.2016.2592904			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27448339	Green Submitted			2022-12-18	WOS:000402744400003
J	Xu, XX; Li, W; Xu, D; Tsang, IW				Xu, Xinxing; Li, Wen; Xu, Dong; Tsang, Ivor W.			Co-Labeling for Multi-View Weakly Labeled Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-view learning; multi-instance learning; semi-supervised learning; relative outlier detection; weakly labeled learning		It is often expensive and time consuming to collect labeled training samples in many real-world applications. To reduce human effort on annotating training samples, many machine learning techniques (e.g., semi-supervised learning (SSL), multi-instance learning (MIL), etc.) have been studied to exploit weakly labeled training samples. Meanwhile, when the training data is represented with multiple types of features, many multi-view learning methods have shown that classifiers trained on different views can help each other to better utilize the unlabeled training samples for the SSL task. In this paper, we study a new learning problem called multi-view weakly labeled learning, in which we aim to develop a unified approach to learn robust classifiers by effectively utilizing different types of weakly labeled multi-view data from a broad range of tasks including SSL, MIL and relative outlier detection (ROD). We propose an effective approach called co-labeling to solve the multi-view weakly labeled learning problem. Specifically, we model the learning problem on each view as a weakly labeled learning problem, which aims to learn an optimal classifier from a set of pseudo-label vectors generated by using the classifiers trained from other views. Unlike traditional co-training approaches using a single pseudo-label vector for training each classifier, our co-labeling approach explores different strategies to utilize the predictions from different views, biases and iterations for generating the pseudo-label vectors, making our approach more robust for real-world applications. Moreover, to further improve the weakly labeled learning on each view, we also exploit the inherent group structure in the pseudo-label vectors generated from different strategies, which leads to a new multi-layer multiple kernel learning problem. Promising results for text-based image retrieval on the NUS-WIDE dataset as well as news classification and text categorization on several real-world multi-view datasets clearly demonstrate that our proposed co-labeling approach achieves state-of-the-art performance for various multi-view weakly labeled learning problems including multi-view SSL, multi-view MIL and multi-view ROD.	[Xu, Xinxing] Agcy Sci Technol & Res, IHPC, Singapore, Singapore; [Li, Wen] ETH, Comp Vis Lab, Zurich, Switzerland; [Xu, Dong] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia; [Tsang, Ivor W.] Univ Technol Sydney, Ctr Quantum Computat Intelligent Syst, Sydney, NSW 2006, Australia	Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC); Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Sydney; University of Technology Sydney	Xu, XX (corresponding author), Agcy Sci Technol & Res, IHPC, Singapore, Singapore.; Li, W (corresponding author), ETH, Comp Vis Lab, Zurich, Switzerland.; Xu, D (corresponding author), Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.; Tsang, IW (corresponding author), Univ Technol Sydney, Ctr Quantum Computat Intelligent Syst, Sydney, NSW 2006, Australia.	xuxinx@ihpc.a-star.edu.sg; liwen@vision.ee.ethz.ch; dong.xu@sydney.edu.au; ivor.tsang@gmail.com	Xu, Dong/A-3694-2011	Xu, Dong/0000-0003-2775-9730; Tsang, Ivor/0000-0001-8095-4637	Faculty of Engineering & Information Technologies, The University of Sydney, under the Faculty Research Cluster Program; Australian Research Council Future Fellowship [FT130100746]	Faculty of Engineering & Information Technologies, The University of Sydney, under the Faculty Research Cluster Program; Australian Research Council Future Fellowship(Australian Research Council)	This research was supported by funding from the Faculty of Engineering & Information Technologies, The University of Sydney, under the Faculty Research Cluster Program. This research was also partially supported by the Australian Research Council Future Fellowship FT130100746. Xinxing Xu and Wen Li contributed equally to this work.	Abney S, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P360; Amini M.R., 2009, ADV NEURAL INFORM PR, P28, DOI DOI 10.5555/2984093.2984097; Andrews S., 2002, NIPS, V2, P561; [Anonymous], 2011, P 28 INT C INT C MAC; Balcan M.-F., 2004, NIPS, P89; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Brefeld U., 2004, P INT C MACH LEARN; Bunescu R.C., 2007, P ICML, P105, DOI DOI 10.1145/1273496.1273510; Chen M, 2011, PROC 28 INT C MACHIN, P953; Chua T.-S., 2009, P ACM INT C IM VID R, P1, DOI 10.1145/1646396.1646452; Chun-Wei Seah, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P577, DOI 10.1109/ICDM.2011.73; Donahue J., 2014, ICML, P647; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Greene D., 2006, P 23 INT C MACHINE L, P377, DOI DOI 10.1145/1143844.1143892; Grtner T., 2002, P 19 INT C MACH LEAR, P179; Hido S, 2008, IEEE DATA MINING, P223, DOI 10.1109/ICDM.2008.49; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Joulin A., 2012, ARXIV12066413; Kanamori T, 2009, J MACH LEARN RES, V10, P1391; Kloft M, 2011, J MACH LEARN RES, V12, P953; Krishnapuram B., 2004, ADV NEURAL INFORM PR, P721; Kumar A., 2011, ADV NEURAL INFORM PR, P1413; Li M, 2007, IEEE T SYST MAN CY A, V37, P1088, DOI 10.1109/TSMCA.2007.904745; Li W, 2012, IEEE DATA MINING, P419, DOI 10.1109/ICDM.2012.78; Li W, 2011, IEEE I CONF COMP VIS, P2049, DOI 10.1109/ICCV.2011.6126478; Li Y, 2009, P INT C MACH LEARN, P633, DOI DOI 10.1145/1553374.1553456; Li Y.-F., 2009, P 12 INT C ART INT S, V5, P344; Li YF, 2013, J MACH LEARN RES, V14, P2151; Li YF, 2009, LECT NOTES ARTIF INT, V5782, P15; Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805; Rahmani R, 2006, P 23 INT C MACH LEAR, P705, DOI DOI 10.1145/1143844.1143933; Sindhwani V., 2008, INT C MACH LEARN, V307, P976, DOI DOI 10.1145/1390156.1390279; Sindhwani Vikas, 2005, P ICML WORKSH LEARN; Smola A., 2009, 12 INT C ART INT STA, V5, P536; Szafranski M, 2010, MACH LEARN, V79, P73, DOI 10.1007/s10994-009-5150-6; Wang W., 2010, PROC 27 INT C MACH L, P1135; Wang W., 2013, P AS C MACH LEARN CA, P467; Wang W, 2007, LECT NOTES ARTIF INT, V4701, P454; Xu L., 2004, ADV NEURAL INFORM PR; Xu XX, 2012, IEEE DATA MINING, P725, DOI 10.1109/ICDM.2012.105; Xu XX, 2013, IEEE T NEUR NET LEAR, V24, P749, DOI 10.1109/TNNLS.2012.2237183; Yu S., 2007, ADV NEURAL INFORM PR, P1665; Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186; Zhou Zhi-Hua, 2004, TECH REP; ZHU X, 2006, 1530 U WISC MAD DEP	47	43	48	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1113	1125		10.1109/TPAMI.2015.2476813	http://dx.doi.org/10.1109/TPAMI.2015.2476813			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26353366				2022-12-18	WOS:000375609000006
J	Zhou, WG; Yang, M; Wang, XY; Li, HQ; Lin, YQ; Tian, Q				Zhou, Wengang; Yang, Ming; Wang, Xiaoyu; Li, Houqiang; Lin, Yuanqing; Tian, Qi			Scalable Feature Matching by Dual Cascaded Scalar Quantization for Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Large scale image retrieval; codebook training-free; cascaded scalar quantization; dual resolution quantization	NEAREST-NEIGHBOR; SEARCH	In this paper, we investigate the problem of scalable visual feature matching in large-scale image search and propose a novel cascaded scalar quantization scheme in dual resolution. We formulate the visual feature matching as a range-based neighbor search problem and approach it by identifying hyper-cubes with a dual-resolution scalar quantization strategy. Specifically, for each dimension of the PCA-transformed feature, scalar quantization is performed at both coarse and fine resolutions. The scalar quantization results at the coarse resolution are cascaded over multiple dimensions to index an image database. The scalar quantization results over multiple dimensions at the fine resolution are concatenated into a binary super-vector and stored into the index list for efficient verification. The proposed cascaded scalar quantization (CSQ) method is free of the costly visual codebook training and thus is independent of any image descriptor training set. The index structure of the CSQ is flexible enough to accommodate new image features and scalable to index large-scale image database. We evaluate our approach on the public benchmark datasets for large-scale image retrieval. Experimental results demonstrate the competitive retrieval performance of the proposed method compared with several recent retrieval algorithms on feature quantization.	[Zhou, Wengang; Li, Houqiang] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Peoples R China; [Yang, Ming] Facebook Inc, Al Res, Menlo Pk, CA 94025 USA; [Wang, Xiaoyu] Snapchat Res Inc, Cupertino, CA 95014 USA; [Lin, Yuanqing] Amer Inc, NEC Labs, Cupertino, CA 95014 USA; [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Facebook Inc; NEC Corporation; University of Texas System; University of Texas at San Antonio (UTSA)	Zhou, WG (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Peoples R China.	zhwg@ustc.edu.cn; mingyang@fb.com; xiaoyu.wang@snapchat.com; lihq@ustc.edu.cn; ylin@nec-labs.com; qitian@cs.utsa.edu	Yang, Ming-Hsuan/AAE-7350-2019; Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Yang, Ming/0000-0003-1691-6817; Wang, Xiaoyu/0000-0002-6431-8822	973 Program [2015CB351803]; NSFC [61325009, 61390514, 61472378, 61429201]; Fundamental Research Funds for the Central Universities [WK2100060014, WK2100060011]; ARO [W911NF-12-1-0057]; NEC Laboratories of America	973 Program(National Basic Research Program of China); NSFC(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); ARO; NEC Laboratories of America	This work was supported in part to Prof. Houqiang Li by 973 Program under contract No. 2015CB351803, NSFC under contract No. 61325009 and No. 61390514, in part to Dr. Wengang Zhou by NSFC under contract No. 61472378 and the Fundamental Research Funds for the Central Universities under contract No. WK2100060014 and WK2100060011, and in part to Prof. Qi Tian by ARO grant W911NF-12-1-0057 and Faculty Research Awards by NEC Laboratories of America. This work was supported in part by NSFC under contract No. 61429201.	Aiger D, 2013, IEEE I CONF COMP VIS, P3471, DOI 10.1109/ICCV.2013.431; Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; BENTLEY JL, 1990, PROCEEDINGS OF THE SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P187, DOI 10.1145/98524.98564; Brandt J, 2010, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2010.5539852; Chu LY, 2013, IEEE T MULTIMEDIA, V15, P1982, DOI 10.1109/TMM.2013.2270455; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601; Chum Ondrej, 2008, BMVC, V810, P812, DOI DOI 10.5244/C.22.50; Datar M., 2004, P 20 ANN S COMP GEOM, P253; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Gros P., 2011, P 19 ACM INT C MULT, P1441; He JF, 2012, PROC CVPR IEEE, P3005, DOI 10.1109/CVPR.2012.6248030; Iwamura M, 2013, IEEE I CONF COMP VIS, P3535, DOI 10.1109/ICCV.2013.439; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jegou H, 2009, IEEE I CONF COMP VIS, P2357, DOI 10.1109/ICCV.2009.5459419; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Kuo Y., 2009, P 17 ACM INT C MULT, P65, DOI DOI 10.1145/1631272.1631284; Lepetit V, 2005, PROC CVPR IEEE, P775; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; Li F., 2009, P 1 ACM WORKSH LARG, P89; Liu Z., 2012, P 20 ACM INT C MULT, P199, DOI DOI 10.1145/2393347.2393380; Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P2047, DOI 10.1109/TIP.2014.2312283; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Qin Lv, 2007, P 33 VLDB2007, P950; Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sivic J., 2008, COMPUTER VISION PATT, P1, DOI 10.1109/CVPR.2008.4587635; Tian XM, 2015, IEEE T MULTIMEDIA, V17, P79, DOI 10.1109/TMM.2014.2368714; Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244; Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566; Xie LX, 2014, COMPUT VIS IMAGE UND, V124, P31, DOI 10.1016/j.cviu.2013.12.011; Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170; Zhang L., 2013, PROC 21 ACM INT C MU, P123, DOI DOI 10.1145/2502081.2502091; Zhang L, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2490823; Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210; Zhang SG, 2010, PROCEEDINGS OF THE ASME JOINT RAIL CONFERENCE, VOL 2, P501, DOI 10.1145/1873951.1874018; Zhang X, 2012, PROC CVPR IEEE, P2058, DOI 10.1109/CVPR.2012.6247910; Zheng L, 2014, PROC CVPR IEEE, P1963, DOI 10.1109/CVPR.2014.252; Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3604, DOI 10.1109/TIP.2014.2329182; Zhou W., 2012, ACM MULTIMEDIA; Zhou W., 2011, ACM MULTIMEDIA; Zhou W., 2010, P ACM INT C MULT, P511; Zhou WG, 2015, IEEE T IMAGE PROCESS, V24, P967, DOI 10.1109/TIP.2015.2389624; Zhou WG, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422960	56	43	44	1	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2016	38	1					159	171		10.1109/TPAMI.2015.2430329	http://dx.doi.org/10.1109/TPAMI.2015.2430329			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CY8OW	26656584				2022-12-18	WOS:000366669200012
J	Hong, BW; Soatto, S				Hong, Byung-Woo; Soatto, Stefano			Shape Matching Using Multiscale Integral Invariants	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape matching; shape descriptor; integral invariant; scale invariant; Wasserstein distance	FOURIER DESCRIPTORS; RECOGNITION; REPRESENTATION; SIGNATURES; SPACE; AREA	We present a shape descriptor based on integral kernels. Shape is represented in an implicit form and it is characterized by a series of isotropic kernels that provide desirable invariance properties. The shape features are characterized at multiple scales which form a signature that is a compact description of shape over a range of scales. The shape signature is designed to be invariant with respect to group transformations which include translation, rotation, scaling, and reflection. In addition, the integral kernels that characterize local shape geometry enable the shape signature to be robust with respect to undesirable perturbations while retaining discriminative power. Use of our shape signature is demonstrated for shape matching based on a number of synthetic and real examples.	[Hong, Byung-Woo] Chung Ang Univ, Dept Comp Sci, Seoul 156756, South Korea; [Soatto, Stefano] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	Chung Ang University; University of California System; University of California Los Angeles	Hong, BW (corresponding author), Chung Ang Univ, Dept Comp Sci, Seoul 156756, South Korea.	hong@cau.ac.kr; soatto@cs.ucla.edu		Hong, Byung-Woo/0000-0003-2752-3939	National Research Foundation of Korea Grant - Korean Government [NRF-2010-220-D00078, NRF-2011-0007898]; NGA [HM02101310004]; ARO [W911NF-11-1-0391]; ONR [N000141110863]	National Research Foundation of Korea Grant - Korean Government; NGA; ARO; ONR(Office of Naval Research)	This work was supported by the National Research Foundation of Korea Grant funded by the Korean Government NRF-2010-220-D00078, NRF-2011-0007898, and by NGA HM02101310004, ARO W911NF-11-1-0391, ONR N000141110863. The authors are grateful to the anonymous reviewers for their constructive comments. Byung-Woo Hong is the corresponding author	Alferez R, 1999, IEEE T PATTERN ANAL, V21, P505, DOI 10.1109/34.771318; ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Belongie S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P454, DOI 10.1109/ICCV.2001.937552; BENGTSSON A, 1991, IEEE T PATTERN ANAL, V13, P85, DOI 10.1109/34.67634; Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426; Boutin M, 2000, INT J COMPUT VISION, V40, P235, DOI 10.1023/A:1008139427340; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; BRUCKSTEIN AM, 1993, CVGIP-IMAG UNDERSTAN, V58, P49, DOI 10.1006/ciun.1993.1031; BRUCKSTEIN AM, 1992, INT J COMPUT VISION, V7, P271, DOI 10.1007/BF00126396; Calabi E, 1998, INT J COMPUT VISION, V26, P107, DOI 10.1023/A:1007992709392; Chazal F, 2009, COMPUT GRAPH FORUM, V28, P1393, DOI 10.1111/j.1467-8659.2009.01516.x; Chetverikov D, 1999, LECT NOTES COMPUT SC, V1689, P367; COHIGNAC T, 1994, INT C PATT RECOG, P164, DOI 10.1109/ICPR.1994.576250; COLE JB, 1991, PATTERN RECOGN LETT, V12, P519, DOI 10.1016/0167-8655(91)90091-Y; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; Dickson LE, 1914, ALGEBRAIC INVARIANTS; Dieudonne J. A., 1970, INVARIANT THEORY OLD; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; FORSYTH D, 1991, IMAGE VISION COMPUT, V9, P130, DOI 10.1016/0262-8856(91)90023-I; Gool LV, 1992, GEOMETRIC INVARIANCE, P193; Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286; Grace John Hilton, 1903, ALGEBRA INVARIANTS; Hann C. E., 2000, INT J COMPUT VISION, V40, P235; Hong B. -W, 2006, 2006 IE COMP SOC C C, V1, P833, DOI [10.1109/CVPR.2006.277, DOI 10.1109/CVPR.2006.277]; Hu M. K., 1961, IEEE T INFORM THEORY, V49, P179; Kanatani Kenichi, 1990, GROUP THEORETICAL ME, P4; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Lane E P, 1932, PROJECTIVE DIFFERENT; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Latto A., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P183; LEI G, 1990, IEEE T ROBOTIC AUTOM, V6, P432, DOI 10.1109/70.59368; Lenz R., 1990, GROUP THEORETICAL ME, V413; LEVENTON ME, 2000, PROC CVPR IEEE, P316, DOI DOI 10.1109/CVPR.2000.855835; Li S. Z., 1999, PROGR NEURAL NETWORK, V6, P203; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; Longin Jan Latecki, 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P617; Manay S, 2006, IEEE T PATTERN ANAL, V28, P1602, DOI 10.1109/TPAMI.2006.208; Miyatake T., 1983, Transactions of the Information Processing Society of Japan, V24, P64; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Mumford D., 1994, GEOMETRIC INVARIANT; Mundy J., 1992, GEOMETRIC INVARIANCE; NIELSEN L, 1991, CVGIP-IMAG UNDERSTAN, V54, P145, DOI 10.1016/1049-9660(91)90079-5; Olver P. J., 1995, EQUIVALENCE INVARIAN, DOI DOI 10.1017/CBO9780511609565; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PAJDLA T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P390, DOI 10.1109/ICCV.1995.466913; RACHEV ST, 1998, PROBABILITY ITS APPL; Raviv D., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2361, DOI 10.1109/CVPR.2011.5995486; Reiss T. H., 1993, RECOGNIZING PLANAR O, V676; Ruggeri MR, 2010, INT J COMPUT VISION, V89, P248, DOI 10.1007/s11263-009-0250-0; Saber E, 1997, J VIS COMMUN IMAGE R, V8, P3, DOI 10.1006/jvci.1997.0344; SAPIRO G, 1995, IEEE T PATTERN ANAL, V17, P67, DOI 10.1109/34.368150; SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591; Springer C. E., 1964, GEOMETRY ANAL PROJEC; Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0; Temlyakov A, 2010, PROC CVPR IEEE, P2289, DOI 10.1109/CVPR.2010.5539912; Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P910, DOI 10.1109/34.608294; van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x; Veltkamp RC, 2001, ADV PTRN RECOGNIT, P87; Verestoy J., 1997, MACHINE GRAPHICS VIS, V6, P225; WEISS I, 1993, IEEE T PATTERN ANAL, V15, P943, DOI 10.1109/34.232081; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1989, COMPUT VISION GRAPH, V45, P68, DOI 10.1016/0734-189X(89)90071-6; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	66	43	54	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					151	160		10.1109/TPAMI.2014.2342215	http://dx.doi.org/10.1109/TPAMI.2014.2342215			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353215				2022-12-18	WOS:000346970600013
J	Pillai, JK; Puertas, M; Chellappa, R				Pillai, Jaishanker K.; Puertas, Maria; Chellappa, Rama			Cross-Sensor Iris Recognition through Kernel Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sensor shift; cross-sensor matching; Kernel learning; adaptation; iris; biometrics	BIOMETRICS	Due to the increasing popularity of iris biometrics, new sensors are being developed for acquiring iris images and existing ones are being continuously upgraded. Re-enrolling users every time a new sensor is deployed is expensive and time-consuming, especially in applications with a large number of enrolled users. However, recent studies show that cross-sensor matching, where the test samples are verified using data enrolled with a different sensor, often lead to reduced performance. In this paper, we propose a machine learning technique to mitigate the cross-sensor performance degradation by adapting the iris samples from one sensor to another. We first present a novel optimization framework for learning transformations on iris biometrics. We then utilize this framework for sensor adaptation, by reducing the distance between samples of the same class, and increasing it between samples of different classes, irrespective of the sensors acquiring them. Extensive evaluations on iris data from multiple sensors demonstrate that the proposed method leads to improvement in cross-sensor recognition accuracy. Furthermore, since the proposed technique requires minimal changes to the iris recognition pipeline, it can easily be incorporated into existing iris recognition systems.	[Pillai, Jaishanker K.; Puertas, Maria; Chellappa, Rama] Univ Maryland, UMIACS, Dept Elect & Comp Engn, College Pk, MD 20742 USA; [Pillai, Jaishanker K.; Puertas, Maria; Chellappa, Rama] Univ Maryland, UMIACS, Ctr Automat Res, College Pk, MD 20742 USA; [Puertas, Maria] Univ Autonoma Madrid, ATVS Biometr Recognit Grp, Madrid, Spain	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; Autonomous University of Madrid	Pillai, JK (corresponding author), Univ Maryland, UMIACS, Dept Elect & Comp Engn, College Pk, MD 20742 USA.	jsp@umiacs.umd.edu; maria@umiacs.umd.edu; rama@umiacs.umd.edu	Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012		MURI from the US Office of Naval Research [N00014-12-1-0124]; FPI fellowship from the Universidad Autonoma de Madrid, Spain	MURI from the US Office of Naval Research; FPI fellowship from the Universidad Autonoma de Madrid, Spain	The work was supported by MURI from the US Office of Naval Research under Grant N00014-12-1-0124. The work of Maria Puertas was also supported by an FPI fellowship from the Universidad Autonoma de Madrid, Spain. J.K. Pillai and M. Puertas provided equal contributions to this paper.	Alonso-Fernandez F., 2006, PROC 9 INT C CONTROL, P1; Alonso-Fernandez F, 2010, IEEE T SYST MAN CY A, V40, P1168, DOI 10.1109/TSMCA.2010.2047498; Arora S.S., 2012, P IEEE INT C BIOM TH; Belkin M, 2002, ADV NEUR IN, V14, P585; Bishop C. M., 2006, J ELECT IMAG, V16, P140; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Bowyer Kevin W., 2009, Identity in the Information Society, V2, P327, DOI 10.1007/s12394-009-0037-z; Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005; Bowyer KW., 2013, HDB IRIS RECOGNITION, P15; Bregman L. M., 1967, COMP MATH MATH PHYS+, V7, P200, DOI DOI 10.1016/0041-5553(67)90040-7; Connaughton R., 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P90, DOI 10.1109/CVPRW.2011.5981814; Connaughton R, 2012, IEEE T INF FOREN SEC, V7, P919, DOI 10.1109/TIFS.2012.2190575; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Gonzalez-Barbosa E. A, 2011, P INT C HAND BAS BIO, P1; Hofmann T, 2008, ANN STAT, V36, P1171, DOI 10.1214/009053607000000677; Kulis B., 2006, P 23 INT C MACH LEAR, P505; Lee Y, 2009, PRINCIPLES TERAHERTZ, P1, DOI DOI 10.1007/978-0-387-09540-0_1; Lee Y., 2011, ROBUST IRIS RECOGNIT; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Matey JR, 2009, ADV PATTERN RECOGNIT, P23, DOI 10.1007/978-1-84882-385-3_2; Pan SJ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1187; Phillips PJ, 2000, COMPUTER, V33, P56, DOI 10.1109/2.820040; PRUSSING JE, 1986, J GUID CONTROL DYNAM, V9, P121, DOI 10.2514/3.20077; Ross A, 2004, LECT NOTES COMPUT SC, V3087, P134; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Sgroi A., 2012, P IEEE INT C BIOM TH; Van Nguyen H., 2012, P INT C AC SPEECH SI; Vishwanathan SVN, 2007, INT J COMPUT VISION, V73, P95, DOI 10.1007/s11263-006-9352-0; Weinberger K. Q., 2004, P 21 INT C MACH LEAR, P839	32	43	46	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					73	85		10.1109/TPAMI.2013.98	http://dx.doi.org/10.1109/TPAMI.2013.98			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231867				2022-12-18	WOS:000327965100007
J	Memisevic, R				Memisevic, Roland			Learning to Relate Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Learning image relations; spatiotemporal features; mapping units; energy models; complex cells	STEREO DISPARITY; ENERGY MODELS; COMPUTATION; EMERGENCE; NETWORK	A fundamental operation in many vision tasks, including motion understanding, stereopsis, visual odometry, or invariant recognition, is establishing correspondences between images or between images and data from other modalities. Recently, there has been increasing interest in learning to infer correspondences from data using relational, spatiotemporal, and bilinear variants of deep learning methods. These methods use multiplicative interactions between pixels or between features to represent correlation patterns across multiple images. In this paper, we review the recent work on relational feature learning, and we provide an analysis of the role that multiplicative interactions play in learning to encode relations. We also discuss how square-pooling and complex cell models can be viewed as a way to represent multiplicative interactions and thereby as a way to encode relations.	Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada	Universite de Montreal	Memisevic, R (corresponding author), Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada.	memisevr@iro.umontreal.ca			German Federal Ministry of Education and Research (BMBF) [01GQ0841]	German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF))	The author thanks Felix Bauer, Yoshua Bengio, Taco Cohen, Georgios Exarchakis, Geoffrey Hinton, Kishore Konda, Christoph von der Malsburg, Joshua Susskind and Christopher Zach for useful discussions and the reviewers for their useful suggestions. This work was supported in part by the German Federal Ministry of Education and Research (BMBF) in the project 01GQ0841 (BFNT Frankfurt).	ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; [Anonymous], [No title captured]; [Anonymous], 2011, AISTATS; Archie KA, 2000, NAT NEUROSCI, V3, P54, DOI 10.1038/71125; Bauer F., 2012, THESIS I INFORM; BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0; Bethge M., 2007, P SPIE HUMAN VISION, VXII, P1; Cadieu CF, 2012, NEURAL COMPUT, V24, P827, DOI 10.1162/NECO_a_00247; Courville A., 2011, P C ART INT STAT; Denil M, 2012, NEURAL COMPUT, V24, P2151, DOI 10.1162/NECO_a_00312; Fleet DJ, 1996, VISION RES, V36, P1839, DOI 10.1016/0042-6989(95)00313-4; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; GALLANT JL, 1993, SCIENCE, V259, P100, DOI 10.1126/science.8418487; GILES CL, 1987, APPL OPTICS, V26, P4972, DOI 10.1364/AO.26.004972; Gray RM, 2006, FOUND TRENDS COMMUN, V2, DOI 10.1561/0100000006; Grimes DB, 2005, NEURAL COMPUT, V17, P47, DOI 10.1162/0899766052530893; Hartley R., 2004, ROBOTICA; Hinton G., 2010, TECHNICAL REPORT; Hinton G.F., 1981, P 7 INT JOINT C ART, V2, P683; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOFSTADTER D, 1984, 755 AI MIT; Horn R.A., 2013, MATRIX ANAL, P321; Hoyer PO, 2002, VISION RES, V42, P1593, DOI 10.1016/S0042-6989(02)00017-2; Hyvarinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312; Hyvarinen A, 2000, LECT NOTES COMPUT SC, V1811, P535; Karklin Y., 2006, P ADV NEUR INF PROC, V18; Kohonen T., 1995, ICANN '95. International Conference on Artificial Neural Networks. Neuronimes '95 Scientific Conference, P3; Krizhevsky A., 2012, ADV NEURAL INFORM PR; Larochelle H., 2010, ADV NEURAL INFORM PR, P1243; Le QV, 2011, PROC CVPR IEEE; Manzagol P.-A., 2008, P 25 INT C MACH LEAR; Memisevic R., 2012, P INT C MACH LEARN J; Memisevic R., 2007, P IEEE C COMP VIS PA; Memisevic R., 2011, P IEEE INT C COMP VI; Memisevic R., 2008, THESIS U TORONTO; Memisevic R., 2010, P ADV NEUR INF PROC; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; OHZAWA I, 1990, SCIENCE, V249, P1037, DOI 10.1126/science.2396096; Olshausen B., 1994, THESIS CALIFORNIA I; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 2007, PROC SPIE, V6492, DOI 10.1117/12.715515; Plate T.A., 1991, P 12 INT JOINT C ART, P30; QIAN N, 1994, NEURAL COMPUT, V6, P390, DOI 10.1162/neco.1994.6.3.390; Ranzato M, 2010, P 13 INT C ART INT S; Ranzato M, 2010, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2010.5539962; Ross D. A., 2006, P 23 INT C MACH LEAR, P761; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P45, DOI [DOI 10.1016/B978-1-4832-1446-7.50010-8, 10.1016/B978-1-4832-1446-7.50010-8]; SANGER TD, 1988, BIOL CYBERN, V59, P405, DOI 10.1007/BF00336114; SMOLENSKY P, 1990, ARTIF INTELL, V46, P159, DOI 10.1016/0004-3702(90)90007-M; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Susskind J., 2011, P IEEE C COMP VIS PA P IEEE C COMP VIS PA; Sutskever Ilya, 2011, P 28 INT C MACH LEAR; Tang Y., 2012, P IEEE C COMP VIS PA; Taylor G, 2010, P EUR C COMP VIS; Taylor G. W., 2010, P IEEE C COMP VIS PA; Taylor Graham, 2009, P 26 ANN INT C MACH, DOI DOI 10.1145/1553374.1553505; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; Troje NF, 1996, VISION RES, V36, P1761, DOI 10.1016/0042-6989(95)00230-8; von der Malsburg C., 1994, MODELS NEURAL NETWOR, P95, DOI [10.1007/978-1-4612-4320-5_2, DOI 10.1007/978-1-4612-4320-5_2]; Wainwright MJ, 2000, ADV NEUR IN, V12, P855; Welling M., 2002, P ADV NEUR INF PROC; Zetzsche C, 2005, NETWORK-COMP NEURAL, V16, P191, DOI 10.1080/09548980500463982	65	43	48	0	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1829	1846		10.1109/TPAMI.2013.53	http://dx.doi.org/10.1109/TPAMI.2013.53			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23787339				2022-12-18	WOS:000320381400003
J	Jalba, AC; Kustra, J; Telea, AC				Jalba, Andrei C.; Kustra, Jacek; Telea, Alexandru C.			Surface and Curve Skeletonization of Large 3D Models on the GPU	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Medial axes; geodesics; skeleton regularization	ALGORITHM; SHAPE	We present a GPU-based framework for extracting surface and curve skeletons of 3D shapes represented as large polygonal meshes. We use an efficient parallel search strategy to compute point-cloud skeletons and their distance and feature transforms (FTs) with user-defined precision. We regularize skeletons by a new GPU-based geodesic tracing technique which is orders of magnitude faster and more accurate than comparable techniques. We reconstruct the input surface from skeleton clouds using a fast and accurate image-based method. We also show how to reconstruct the skeletal manifold structure as a polygon mesh and the curve skeleton as a polyline. Compared to recent skeletonization methods, our approach offers two orders of magnitude speed-up, high-precision, and low-memory footprints. We demonstrate our framework on several complex 3D models.	[Jalba, Andrei C.] Eindhoven Univ Technol, Dept Math & Comp Sci, POB 513, NL-5600 MB Eindhoven, Netherlands; [Kustra, Jacek] Philips Res, Eindhoven, Netherlands; [Telea, Alexandru C.] Univ Groningen, Johann Bernoulli Inst Math & Comp Sci, NL-9700 AK Groningen, Netherlands	Eindhoven University of Technology; Philips; Philips Research; University of Groningen	Jalba, AC (corresponding author), Eindhoven Univ Technol, Dept Math & Comp Sci, POB 513, NL-5600 MB Eindhoven, Netherlands.	A.C.Jalba@tue.nl; jacek.kustra@gmail.com; a.c.telea@rug.nl						Ahuja N, 1997, IEEE T PATTERN ANAL, V19, P169, DOI 10.1109/34.574801; Amenta N, 2002, INT J COMPUT GEOM AP, V12, P125, DOI 10.1142/S0218195902000773; AMENTA N, 2001, P SMA, P65; Aslan C, 2008, IEEE T PATTERN ANAL, V30, P2188, DOI 10.1109/TPAMI.2007.70842; Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769; Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59; Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351; Bouix S, 2005, MED IMAGE ANAL, V9, P209, DOI 10.1016/j.media.2004.06.026; Bouix S, 2006, MODEL SIMUL SCI ENG, P1; C AU O. K., 2008, P ACM SIGGRAPH, P441; CAO T., 2010, P ACM SIGGRAPH S INT, P134; Cayton L., 2010, P ADV DISTR MAN SYST, P192; Chang MC, 2009, COMPUT VIS IMAGE UND, V113, P1130, DOI 10.1016/j.cviu.2009.04.001; Chuang JH, 2000, IEEE T PATTERN ANAL, V22, P1241; Cornea N., 2007, IEEE T VIS COMPUT GR, V13, P87; Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0; Costa L. da F., 2001, SHAPE ANAL CLASSIFIC; Damon J, 2006, GEOM TOPOL, V10, P2385, DOI 10.2140/gt.2006.10.2385; Dey K., 2006, P S GEOMETRY PROCESS, V6, P143; Dey T., 2006, INT J COMPUTATIONAL, V35, P340; Dey TK, 2004, ALGORITHMICA, V38, P179, DOI 10.1007/s00453-003-1049-y; Dougherty R., 2007, MICROSC MICROANAL, V13, P1678, DOI [10.1017/s1431927607074430, DOI 10.1017/S1431927607074430]; Ebert D., 2002, P S DATA VISUALISATI, P251; Eisemann E., 2006, P 2006 S INT 3D GRAP, P71, DOI [10.1145/1111411.1111424, DOI 10.1145/1111411.1111424]; FOSKEY M., 2003, P SMA, p[135, 6, 8, 11]; Frey P., 2001, 0252 INRIA; Garcia V., 2008, P C VIS COMP GPU, P77; Ge YR, 1996, IEEE T PATTERN ANAL, V18, P1055, DOI 10.1109/34.544075; Giblin P, 2004, IEEE T PATTERN ANAL, V26, P238, DOI 10.1109/TPAMI.2004.1262192; Giesen J, 2009, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'09), P106, DOI 10.1145/1542362.1542388; Hassouna MS, 2009, IEEE T PATTERN ANAL, V31, P2257, DOI 10.1109/TPAMI.2008.271; Hesselink WH, 2008, IEEE T PATTERN ANAL, V30, P2204, DOI 10.1109/TPAMI.2008.21; Hotz I, 2000, IEEE VISUAL, P311, DOI 10.1109/VISUAL.2000.885710; Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P382, DOI 10.1006/cviu.1995.1062; Lambourne J., 2005, P INT C SHAP MOD APP, P107; LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013; Leymarie FF, 2007, IEEE T PATTERN ANAL, V29, P313, DOI 10.1109/TPAMI.2007.44; Li X., 2001, P 2001 S INT 3D GRAP, P35, DOI DOI 10.1145/364338.364343; Ma J, 2012, VISUAL COMPUT, V28, P7, DOI 10.1007/s00371-011-0594-7; Malandain G, 1998, IMAGE VISION COMPUT, V16, P317, DOI 10.1016/S0262-8856(97)00074-7; MeshLab, 2012, MESHLAB GEOM PROC SO; MIKLOS B, 2010, P ACM SIGGRAPH, P394; Ming W, 2001, IEEE VISUAL, P239, DOI 10.1109/VISUAL.2001.964517; Mortara M., 2004, P 9 ACM S SOL MOD AP, P339; Mount D., 2011, APPROXIMATE NEAREST; Nooruddin FS, 2003, IEEE T VIS COMPUT GR, V9, P191, DOI 10.1109/TVCG.2003.1196006; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; Palagyi K, 1999, LECT NOTES COMPUT SC, V1568, P325; Peyre G, 2005, PROG NONLINEAR DIFFE, V63, P157; Pizer SM, 2003, INT J COMPUT VISION, V55, P155, DOI 10.1023/A:1026135101267; Prohaska S, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P29, DOI 10.1109/VISUAL.2002.1183753; Pudney C, 1998, COMPUT VIS IMAGE UND, V72, P404, DOI 10.1006/cviu.1998.0680; Reniers D, 2008, IEEE T VIS COMPUT GR, V14, P355, DOI [10.1109/TVCG.2008.23, 10.1109/TC.2007.70786]; Reniers D, 2008, COMPUT GRAPH FORUM, V27, P1837, DOI 10.1111/j.1467-8659.2008.01330.x; Rumpf M., 2002, P S DAT VIS, p[151, 151]; Rusinkiewicz S., 2000, P ACM SIGGRAPH, P230; Schmies M., 2006, ACM SIGGRAPH 2006 CO, P30, DOI [DOI 10.1145/1185657.1185664, 10.1145/1185657.1185664]; Shaked D, 1998, COMPUT VIS IMAGE UND, V69, P156, DOI 10.1006/cviu.1997.0598; Shewchuk J. R., 1996, Applied Computational Geometry. Towards Geometric Engineering. FCRC'96 Workshop, WACG'96. Selected Papers, P203, DOI 10.1007/BFb0014497; Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653; Siddiqi K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P828, DOI 10.1109/ICCV.1999.790307; SIDDIQI K., 2009, MEDIAL REPRESENTATIO; Stolpner S., 2009, P IEEE 3DIM, P87; Stolpner S, 2011, COMPUT VIS IMAGE UND, V115, P695, DOI 10.1016/j.cviu.2010.10.014; Strzodka R, 2004, P EG IEEE TCVG S VIS, P221, DOI DOI 10.2312/VISSYM/VISSYM04/221-230; Sud A., 2006, THESIS; SUD A., 2005, P SPM, P103; Surazhsky V., 2005, P ACM SIGGRAPH, P130; TAGLIASACCHI A., 2009, P SIGGRAPH, P541; Telea A, 2011, LECT NOTES COMPUT SC, V6671, P393, DOI 10.1007/978-3-642-21569-8_34; van Dortmont MAMM, 2006, LECT NOTES COMPUT SC, V4245, P617; Verma V., 2009, P ACM GIS, P227; Wang J., 2007, P ACM S SOL MOD APPL, P139; Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079	76	43	45	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1495	1508		10.1109/TPAMI.2012.212	http://dx.doi.org/10.1109/TPAMI.2012.212			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599061	Green Submitted			2022-12-18	WOS:000317857900017
J	Derpanis, KG; Sizintsev, M; Cannons, KJ; Wildes, RP				Derpanis, Konstantinos G.; Sizintsev, Mikhail; Cannons, Kevin J.; Wildes, Richard P.			Action Spotting and Recognition Based on a Spatiotemporal Orientation Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action spotting; action recognition; action representation; human motion; visual spacetime; spatiotemporal orientation; template matching; real-time implementations	OBJECT; MODELS	This paper provides a unified framework for the interrelated topics of action spotting, the spatiotemporal detection and localization of human actions in video, and action recognition, the classification of a given video into one of several predefined categories. A novel compact local descriptor of video dynamics in the context of action spotting and recognition is introduced based on visual spacetime oriented energy measurements. This descriptor is efficiently computed directly from raw image intensity data and thereby forgoes the problems typically associated with flow-based features. Importantly: the descriptor allows for the comparison of the underlying dynamics of two spacetime video segments irrespective of spatial appearance, such as differences induced by clothing, and with robustness to clutter. An associated similarity measure is introduced that admits efficient exhaustive search for an action template, derived from a single exemplar video, across candidate video sequences. The general approach presented for action spotting and recognition is,amenable to efficient implementation, which is deemed critical for many important applications. For action spotting, details of a real-time GPU-based instantiation of the proposed approach are provided. Empirical evaluation of both action spotting and action recognition on challenging datasets suggests the efficacy of the proposed approach, with state-of-the-art performance documented on standard datasets.	[Derpanis, Konstantinos G.; Sizintsev, Mikhail; Cannons, Kevin J.; Wildes, Richard P.] York Univ, Dept Comp Sci & Engn, Toronto, ON M3J 1P3, Canada	York University - Canada	Derpanis, KG (corresponding author), York Univ, Dept Comp Sci & Engn, CSB 1003,4700 Keele St, Toronto, ON M3J 1P3, Canada.	kosta@cse.yorku.ca; sizints@cse.yorku.ca; kcannons@cse.yorku.ca; wildes@cse.yorku.ca			NSERC	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	Portions of this research were funded by an NSERC Discovery Grant to R. Wildes. The authors thank H. Seo and P. Milanfar for providing their cropped KTH templates, and T. Lian for helpful discussion.	ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Ali S., 2007, P 11 IEEE INT C COMP; Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284; Apostoloff N, 2005, PROC CVPR IEEE, P553; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bracewell R., 1999, FOURIER TRANSFORM IT, P46; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Chomat O., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P104, DOI 10.1109/CVPR.1999.784616; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Derpanis K., 2010, P IEEE C COMP VIS PA; Derpanis K., 2009, P IEEE C COMP VIS PA; Derpanis KG, 2005, IEEE IMAGE PROC, P2777; Derpanis KG, 2010, IEEE T PATTERN ANAL, V32, P1310, DOI 10.1109/TPAMI.2010.64; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Fanti C, 2005, PROC CVPR IEEE, P1166; Fathi A, 2008, PROC CVPR IEEE, P3064; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gilbert A, 2011, IEEE T PATTERN ANAL, V33, P883, DOI 10.1109/TPAMI.2010.144; Google, 2012, IM SEARCH; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Harris M., 2007, OPTIMIZING PARALLEL; HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568; Hu YX, 2009, IEEE I CONF COMP VIS, P128, DOI 10.1109/ICCV.2009.5459153; Jahne B., 2005, DIGITAL IMAGE PROCES; Jhuang H., 2007, P 11 IEEE INT C COMP; Liu Jiaomin, 2009, Proceedings of the 2009 Second International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2009), P15, DOI [10.1109/CVPRW.2009.5206744, 10.1109/ICINIS.2009.13]; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Ke Y., 2007, P 11 IEEE INT C COMP; Ke Y., 2007, P WVS; Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167; Klaser A., 2010, THESIS U GRENOBLE; Klaser Alexander, 2008, BMVC; Kobayashi T, 2009, PATTERN RECOGN LETT, V30, P212, DOI 10.1016/j.patrec.2008.09.006; Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lin Z, 2009, IEEE I CONF COMP VIS, P444; Liu J., 2008, P IEEE C COMP VIS PA; Marszaek M., 2009, CVPR, P2929, DOI DOI 10.1109/CVPR.2009.5206557; Matikainen P., 2008, P BRIT MACH VIS C; Mikolajczyk K., 2008, P IEEE C COMP VIS PA; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Ning HZ, 2009, IEEE T CIRC SYST VID, V19, P808, DOI 10.1109/TCSVT.2009.2017399; Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Ramanan D., 2003, P NEUR INF PROC SYST; Rapantzikos K., 2009, P IEEE C COMP VIS PA; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156; Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119; Sun J., 2009, P IEEE C COMP VIS PA; Sun XH, 2009, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2009.5204255; Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Wang Heng, 2009, BMVC, P1; Watson A., 1983, P MOT WORKSH, P1; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Wong S., 2007, P IEEE C COMP VIS PA; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201; Yeo CH, 2008, IEEE T CIRC SYST VID, V18, P1006, DOI 10.1109/TCSVT.2008.927112; Yilmaz A, 2008, COMPUT VIS IMAGE UND, V109, P335, DOI 10.1016/j.cviu.2007.09.006; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]; Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817, DOI 10.1007/978-3-540-88693-8_60	74	43	47	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					527	540		10.1109/TPAMI.2012.141	http://dx.doi.org/10.1109/TPAMI.2012.141			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	26353139	Green Submitted			2022-12-18	WOS:000314792900002
J	Tang, XO; Liu, K; Cui, JY; Wen, F; Wang, XG				Tang, Xiaoou; Liu, Ke; Cui, Jingyu; Wen, Fang; Wang, Xiaogang			IntentSearch: Capturing User Intention for One-Click Internet Image Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image search; intention; image reranking; adaptive similarity; keyword expansion	RELEVANCE FEEDBACK; RETRIEVAL	Web-scale image search engines (e. g., Google image search, Bing image search) mostly rely on surrounding text features. It is difficult for them to interpret users' search intention only by query keywords and this leads to ambiguous and noisy search results which are far from satisfactory. It is important to use visual information in order to solve the ambiguity in text-based image retrieval. In this paper, we propose a novel Internet image search approach. It only requires the user to click on one query image with minimum effort and images from a pool retrieved by text-based search are reranked based on both visual and textual content. Our key contribution is to capture the users' search intention from this one-click query image in four steps. 1) The query image is categorized into one of the predefined adaptive weight categories which reflect users' search intention at a coarse level. Inside each category, a specific weight schema is used to combine visual features adaptive to this kind of image to better rerank the text-based search result. 2) Based on the visual content of the query image selected by the user and through image clustering, query keywords are expanded to capture user intention. 3) Expanded keywords are used to enlarge the image pool to contain more relevant images. 4) Expanded keywords are also used to expand the query image to multiple positive visual examples from which new query specific visual and textual similarity metrics are learned to further improve content-based image reranking. All these steps are automatic, without extra effort from the user. This is critically important for any commercial web-based image search engine, where the user interface has to be extremely simple. Besides this key contribution, a set of visual features which are both effective and efficient in Internet image search are designed. Experimental evaluation shows that our approach significantly improves the precision of top-ranked images and also the user experience.	[Tang, Xiaoou; Liu, Ke] Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China; [Cui, Jingyu] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA; [Wen, Fang] Microsoft Res Asia, Beijing 100080, Peoples R China; [Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong; Stanford University; Microsoft; Microsoft Research Asia; Chinese University of Hong Kong	Tang, XO (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China.	xtang@ie.cuhk.edu.hk; liuke87@gmail.com; jycui@stanford.edu; fangwen@microsoft.com; xgwang@ee.cuhk.edu.hk	Wang, Xiaogang/L-4369-2014; snaith, melissa/E-8935-2012; Tang, Xiaoou/G-6509-2012	Wang, Xiaogang/0000-0002-9021-0954; 	Hong Kong SAR through RGC [416510]; Introduced Innovative R&D Team of Guangdong Province [201001D0104648280]	Hong Kong SAR through RGC; Introduced Innovative R&D Team of Guangdong Province	This work is partially supported by Hong Kong SAR through RGC project 416510 and by Guangdong Province through Introduced Innovative R&D Team of Guangdong Province 201001D0104648280.	Ah-Pine J, 2009, MULTIMED TOOLS APPL, V42, P31, DOI 10.1007/s11042-008-0246-8; [Anonymous], 2012, BING IM SEARCH; Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; BENHAIM N, 2006, P INT WORKSH SEM LEA; Cao Y., 2010, P IEEE INT C COMP VI; Chechik G, 2010, J MACH LEARN RES, V11, P1109; CHEN Y, 2001, P IEEE INT C IM PROC; Chum O., 2007, P IEEE INT C COMP VI; Cui J., 2008, P 16 ACM INT C MULT; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Deng J., 2011, P IEEE INT C COMP VI; FERGUS R, 2004, P EUR C COMP VIS; Freeman W., 1995, P INT WORKSH AUT FAC; Frome A., 2007, P IEEE INT C COMP VI; He J, 2004, P PAC RIM C MULT; Hsu WH, 2006, P 14 ANN ACM INT C M; Huang Y., 2011, P IEEE INT C COMP VI; Jarvelin K., 2000, J MACHINE LEARNING R, P41; Jing F., 2006, P 14 ANN ACM INT C M; Jing Y, 2008, P INT C WORLD WID WE; Jones K. Sparck, 1971, AUTOMATIC KEYWORD CL; Ke Y., 2006, P IEEE INT C COMP VI; Kim S., 2004, P 27 ANN INT ACM SIG; Krapac J., 2010, P IEEE INT C COMP VI; Lin Y., 2007, P IEEE INT C COMP VI; Liu S, 2004, P 27 ANN INT ACM SIG; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu Y, 2003, IEEE T MULTIMEDIA, V5, P339, DOI 10.1109/TMM.2003.813280; LUO B, 2003, P IS T SPIE EL IM IN; Luo W., 2011, P IEEE INT C COMP VI; Luo Y., 2008, P EUR C COMP VIS; Natsev AP, 2007, P 15 INT C MULT; Park G, 2003, P 2 INT C IM VID RET; Philbin J., 2010, P EUR C COMP VIS; QUACK T, 2004, P 12 ANN ACM INT C M; RUBNER Y, 1997, P ARPA IMAG UND WORK; Shen HY, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.221; Sivic J., 2003, P INT C COMP VIS; Smith J, 2003, P INT C MULT EXP; Tao D., 2004, P IEEE CS C COMP VIS; Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134; Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78; TONG S, 2001, P ACM MULT; Torralba A., 2003, P INT C COMP VIS; Triggs B, 2005, P IEEE INT C COMP VI; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; WANG C, 2006, P 8 ACM INT WORKSH M; Wu L., 2009, P INT C WORLD WID WE; Xiao R., 2007, P INT C COMP VIS; Yan R., 2003, P 11 ACM INT C MULT; YAN R, 2003, P INT C IM VID RETR; Zha Z., 2009, P 17 ACM INT C MULT; Zhang Y., 2011, P IEEE INT C COMP VI; Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3	55	43	54	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1342	1353		10.1109/TPAMI.2011.242	http://dx.doi.org/10.1109/TPAMI.2011.242			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22156100				2022-12-18	WOS:000304138300007
J	Gorisse, D; Cord, M; Precioso, F				Gorisse, David; Cord, Matthieu; Precioso, Frederic			Locality-Sensitive Hashing for Chi2 Distance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sublinear algorithm; approximate nearest neighbors; locality sensitive hashing; chi2 distance; image retrieval	NEAREST-NEIGHBOR; IMAGE	In the past 10 years, new powerful algorithms based on efficient data structures have been proposed to solve the problem of Nearest Neighbors search (or Approximate Nearest Neighbors search). If the Euclidean Locality Sensitive Hashing algorithm, which provides approximate nearest neighbors in a euclidean space with sublinear complexity, is probably the most popular, the euclidean metric does not always provide as accurate and as relevant results when considering similarity measure as the Earth-Mover Distance and chi(2) distances. In this paper, we present a new LSH scheme adapted to chi(2) distance for approximate nearest neighbors search in high-dimensional spaces. We define the specific hashing functions, we prove their local-sensitivity, and compare, through experiments, our method with the Euclidean Locality Sensitive Hashing algorithm in the context of image retrieval on real image databases. The results prove the relevance of such a new LSH scheme either providing far better accuracy in the context of image retrieval than euclidean scheme for an equivalent speed, or providing an equivalent accuracy but with a high gain in terms of processing speed.	[Gorisse, David] Yakaz Lab, F-75002 Paris, France; [Cord, Matthieu] UPMC Sorbonne Univ, LIP6, F-75005 Paris, France; [Precioso, Frederic] CNRS, Lab Informat Signaux & Syst Sophia Antipolis, UNS I3S UMR6070, Sophia Antipolis 6903, France	UDICE-French Research Universities; Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS)	Gorisse, D (corresponding author), Yakaz Lab, 34 Rue Clery, F-75002 Paris, France.	david@yakaz.com; matthieu.cord@lip6.fr; frederic.precioso@unice.fr						Andoni A, 2006, ANN IEEE SYMP FOUND, P459; CHANG EY, 2005, IEEE T MULTIMEDIA, V2; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Datar M., 2004, P ACM 20 ANN S COMP, P253; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; Georgescu B., 2003, P IEEE INT C COMP VI; Gorisse D., 2010, P 17 IEEE INT C IM P; Gorisse D., 2008, P 19 INT C PATT REC, P1873; Gosselin PH, 2008, COMPUT VIS IMAGE UND, V110, P403, DOI 10.1016/j.cviu.2007.09.018; Greenacre MJ, 2007, CORRES ANAL PRACTICE, V2nd; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; INDYK P, 2003, P INT WORKSH STAT CO; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Ke Y., 2004, ACM MULTIMEDIA, P869, DOI DOI 10.1145/1027527.1027729]; Lejsek H, 2009, IEEE T PATTERN ANAL, V31, P869, DOI 10.1109/TPAMI.2008.130; Muja M., 2009, P INT C COMP VIS THE; Qin Lv, 2007, P 33 VLDB2007, P950; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Samet H, 2006, MORGAN KAUFMANN SERI; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Weiss Y., 2008, P ADV NEUR INF PROC	21	43	43	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					402	409		10.1109/TPAMI.2011.193	http://dx.doi.org/10.1109/TPAMI.2011.193			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21968915				2022-12-18	WOS:000298105500016
J	Hua, G; Yang, MH; Learned-Miller, E; Ma, Y; Turk, M; Kriegman, DJ; Huang, TS				Hua, Gang; Yang, Ming-Hsuan; Learned-Miller, Erik; Ma, Yi; Turk, Matthew; Kriegman, David J.; Huang, Thomas S.			Introduction to the Special Section on Real-World Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Hua, Gang] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA; [Yang, Ming-Hsuan] Univ Calif, Dept Elect Engn & Comp Sci, Merced, CA 95344 USA; [Learned-Miller, Erik] Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA; [Ma, Yi] Microsoft Res Asia, Beijing, Peoples R China; [Turk, Matthew] Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA; [Kriegman, David J.] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 93093 USA; [Huang, Thomas S.] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA	International Business Machines (IBM); University of California System; University of California Merced; University of Massachusetts System; University of Massachusetts Amherst; Microsoft; Microsoft Research Asia; University of California System; University of California Santa Barbara; University of California System; University of California San Diego; University of Illinois System; University of Illinois Urbana-Champaign	Hua, G (corresponding author), IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA.	ganghua@gmail.com; mhyang@ucmerced.edu; elm@cs.umass.edu; mayi@microsoft.com; mturk@cs.ucsb.edu; kriegman@cs.ucsd.edu; huang@ifp.uiuc.edu	Yang, Ming-Hsuan/T-9533-2019; Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; 					0	43	46	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					1921	1924		10.1109/TPAMI.2011.182	http://dx.doi.org/10.1109/TPAMI.2011.182			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	26598769				2022-12-18	WOS:000293969000001
J	Sargin, ME; Yemez, Y; Erzin, E; Tekalp, AM				Sargin, Mehmet Emre; Yemez, Yuecel; Erzin, Engin; Tekalp, A. Murat			Analysis of head gesture and prosody patterns for prosody-driven head-gesture animation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multimedia information systems; speech analysis; face and gesture recognition; pattern analysis and recognition; animation		We propose a new two-stage framework for joint analysis of head gesture and speech prosody patterns of a speaker toward automatic realistic synthesis of head gestures from speech prosody. In the first stage analysis, we perform Hidden Markov Model (HMM)-based unsupervised temporal segmentation of head gesture and speech prosody features separately to determine elementary head gesture and speech prosody patterns, respectively, for a particular speaker. In the second stage, joint analysis of correlations between these elementary head gesture and prosody patterns is performed using Multistream HMMs to determine an audio-visual mapping model. The resulting audio-visual mapping model is then employed to synthesize natural head gestures from arbitrary input test speech given a head model for the speaker. In the synthesis stage, the audio-visual mapping model is used to predict a sequence of gesture patterns from the prosody pattern sequence computed for the input test speech. The Euler angles associated with each gesture pattern are then applied to animate the speaker head model. Objective and subjective evaluations indicate that the proposed synthesis by analysis scheme provides natural looking head gestures for the speaker with any input test speech, as well as in "prosody transplant" and "gesture transplant" scenarios.	[Sargin, Mehmet Emre] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA; [Yemez, Yuecel; Erzin, Engin; Tekalp, A. Murat] Koc Univ, Coll Engn, TR-34450 Istanbul, Turkey	University of California System; University of California Santa Barbara; Koc University	Sargin, ME (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.	msargin@ece.ucsb.edu; yyemez@ku.edu.tr; eerzin@ku.edu.tr; mtekalp@ku.edu.tr	Tekalp, Murat/AAW-1060-2020; Erzin, Engin/H-1716-2011	Erzin, Engin/0000-0002-2715-2368; Tekalp, Ahmet Murat/0000-0003-1465-8121				Aleksic PS, 2004, IEEE T CIRC SYST VID, V14, P682, DOI 10.1109/TCSVT.2004.826760; ANANTHAKRISHNAN S, 2005, P IEEE INT C AC SPEE, V1; Bengio Y, 1996, IEEE T NEURAL NETWOR, V7, P1231, DOI 10.1109/72.536317; Boersma P., 1993, IFA PROC, V17, P97; Bouguet J.-Y., 1999, PYRAMIDAL IMPLEMENTA; Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537; Bregler C., 2007, P ACM SIGGRAPH, P353; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; CHEN LS, 2001, J SAFETY ENV, V1, P21; Chuang E, 2005, ACM T GRAPHIC, V24, P331, DOI 10.1145/1061347.1061355; COLLOBERT R, 2002, IDIAP RES REPORT, V2, P46; Demirdjian D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P213, DOI 10.1109/ICCV.2001.937520; Deng  Z., 2004, P 2004 ACM SIGMM WOR, P24; FUA P, 1997, P 12 INT JOINT C ART, P1292; Graf HP, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P396, DOI 10.1109/AFGR.2002.1004186; Huang FJ, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P352, DOI 10.1109/MMSP.1998.738959; KURATATE T, 1999, P 6 EUR C SPEECH COM, P1279; Li Y, 2006, IEEE T MULTIMEDIA, V8, P542, DOI 10.1109/TMM.2006.870732; LIENHART R, 2002, P IEEE INT C IM PROC, V1, P900, DOI DOI 10.1109/ICIP.2002.1038171; Manton JH, 2002, IEEE T SIGNAL PROCES, V50, P635, DOI 10.1109/78.984753; *MOM INC, 2008, SPEECH DRIV TALK HEA; MORISHIMA S, 1989, P IEEE ICASSP GLASG, P1795; Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x; Naphade MR, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P13; Quek F., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P64, DOI 10.1109/RATFG.1999.799225; SARGIN ME, 2006, P INT C MULT EXP ICM; SHOEMAKE K, 1985, P 12 ANN C COMP GRAP, P245, DOI DOI 10.1145/325165.325242; Silverman K., 1992, P INT C SPOK LANG PR, P867; VALBONESI L, 2002, P EUR SIGN PROC C 20, V1, P75; Varshalovich D. A., 1988, QUANTUM THEORY ANGUL; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Xue JX, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P1165, DOI 10.1109/ICME.2006.262743; Yamamoto E, 1998, SPEECH COMMUN, V26, P105, DOI 10.1016/S0167-6393(98)00054-5	33	43	44	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1330	1345		10.1109/TPAMI.2007.70797	http://dx.doi.org/10.1109/TPAMI.2007.70797			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566489	Green Submitted			2022-12-18	WOS:000256679700002
J	Fan, LL; Wang, SG; Wang, HF; Guo, TD				Fan, Lingling; Wang, Shuguang; Wang, Hongfa; Guo, Tiande			Singular points detection based on zero-pole model in fingerprint images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						zero-pole model; Hough Transform (HT); orientation field; singular points	ORIENTATION FIELD; CLASSIFICATION; COMPUTATION	An algorithm is proposed, which combines Zero-pole Model and Hough Transform (HT) to detect singular points. Orientation of singular points is defined on the basis of the Zero-pole Model, which can further explain the practicability of Zero-pole Model. Contrary to orientation field generation, detection of singular points is simplified to determine the parameters of the Zero-pole Model. HT uses rather global information of fingerprint images to detect singular points. This makes our algorithm more robust to noise than methods that only use local information. As the Zero-pole Model may have a little warp from actual fingerprint orientation field, Poincare index is used to make position adjustment in neighborhood of the detected candidate singular points. Experimental results show that our algorithm performs well and fast enough for real-time application in database NIST-4.	[Fan, Lingling; Wang, Shuguang; Wang, Hongfa; Guo, Tiande] Chinese Acad Sci, Grad Univ, Sch Math Sci, Beijing, Peoples R China	Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Fan, LL (corresponding author), Chinese Acad Sci, Grad Univ, Sch Math Sci, Shijingshan Dist, Beijing, Peoples R China.	05fanlingling@mails.gucas.ac.cn; lu-cas.wang.gm@gmail.com; wanghongfa05@mails.gucas.ac.cn; tdguo@gucas.ac.cn						Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; Cappelli R, 2002, INT C PATT RECOG, P744, DOI 10.1109/ICPR.2002.1048096; Cappelli R, 2000, INT C PATT RECOG, P471, DOI 10.1109/ICPR.2000.903586; Chan KC, 2004, IEEE T CIRC SYST VID, V14, P95, DOI 10.1109/TCSVT.2003.818358; Galton Francis, 1892, FINGER PRINTS; Gonzalez R. C., 2003, DIGITAL IMAGE PROCES; Gu JW, 2004, PATTERN RECOGN, V37, P543, DOI 10.1016/S0031-3203(03)00178-X; Gu JW, 2003, PROC CVPR IEEE, P493; Henry E.R., 1990, CLASSIFICATION USES; Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; KAWAGOE M, 1984, PATTERN RECOGN, V17, P295, DOI 10.1016/0031-3203(84)90079-7; KOO WM, 2001, P INT C AUD VID BAS, P229; McLaughlin RA, 1998, PATTERN RECOGN LETT, V19, P299, DOI 10.1016/S0167-8655(98)00010-5; METHRE BM, 1993, MACH VISION APPL, V6, P124; Nilsson K, 2003, PATTERN RECOGN LETT, V24, P2135, DOI 10.1016/S0167-8655(03)00083-7; Nilsson K, 2002, INT C PATT RECOG, P395, DOI 10.1109/ICPR.2002.1047929; NILSSON K, 2002, P WORKSH BIOM AUTH, P39; Prabhakar S., 2003, HDB FINGERPRINT RECO; Qinzhi Zhang, 2004, Pattern Recognition, V37, P2233, DOI 10.1016/j.patcog.2003.12.020; Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800; RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3; SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I; SRINIVASAN VS, 1992, PATTERN RECOGN, V25, P139, DOI 10.1016/0031-3203(92)90096-2; Vizcaya PR, 1996, PATTERN RECOGN, V29, P1221, DOI 10.1016/0031-3203(95)00154-9; Zheng X., 2006, P INT C INT COMP, P593; Zhou J, 2004, PATTERN RECOGN, V37, P389, DOI 10.1016/S0031-3203(03)00186-9; Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608	28	43	46	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					929	940		10.1109/TPAMI.2008.31	http://dx.doi.org/10.1109/TPAMI.2008.31			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421101				2022-12-18	WOS:000254872500001
J	Kazhdan, M				Kazhdan, Michael			An approximate and efficient method for optimal rotation alignment of 3D models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						alignment; matching; retrieval; shape descriptors; signal processing		In many shape analysis applications, the ability to find the best rotation that aligns two models is an essential first step in the analysis process. In the past, methods for model alignment have either used normalization techniques, such as PCA alignment, or have performed an exhaustive search over the space of rotation to find the best optimal alignment. While normalization techniques have the advantage of efficiency, providing a quick method for registering two shapes, they are often imprecise and can give rise to poor alignments. Conversely, exhaustive search is guaranteed to provide the correct answer, but, even using efficient signal processing techniques, this type of approach can be prohibitively slow. In this paper, we present a new method for aligning two 3D shapes. We show that the method is markedly faster than existing approaches based on efficient signal processing and we provide registration results demonstrating that the alignments obtained using our method have a high degree of precision and are markedly better than those obtained using normalization.	Johns Hopkins Univ, Baltimore, MD 21218 USA	Johns Hopkins University	Kazhdan, M (corresponding author), Johns Hopkins Univ, 224 New Engn Bldg,3400 N Charles St, Baltimore, MD 21218 USA.	misha@cs.jhu.edu	Kazhdan, Michael M./A-3366-2010					Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207; DRISCOLL JR, 1994, ADV APPL MATH, V15, P202, DOI 10.1006/aama.1994.1008; Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775; Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279; Healy DM, 2003, J FOURIER ANAL APPL, V9, P341, DOI 10.1007/s00041-003-0018-9; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; KAZHDAN M, 2003, S GEOM PROC, P167; KAZHDAN M, 2004, P 2004 EUR ACM SIGGR, P116; Kovacs JA, 2002, ACTA CRYSTALLOGR D, V58, P1282, DOI 10.1107/S0907444902009794; Makadia A, 2004, INT C PATT RECOG, P590, DOI 10.1109/ICPR.2004.1334598; Makadia A, 2003, PROC CVPR IEEE, P217; Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386; Praun E, 2001, COMP GRAPH, P179, DOI 10.1145/383259.383277; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; Sharf A, 2004, ACM T GRAPHIC, V23, P878, DOI 10.1145/1015706.1015814; Shokoufandeh A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P491, DOI 10.1109/CVPR.1999.784726; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Vranic DV, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P757; Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774; [No title captured]	21	43	45	3	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1221	1229		10.1109/TPAMI.2007.1032	http://dx.doi.org/10.1109/TPAMI.2007.1032			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496379				2022-12-18	WOS:000246395300009
J	Stelldinger, P; Latecki, LJ; Siqueira, M				Stelldinger, Peer; Latecki, Longin Jan; Siqueira, Marcelo			Topological equivalence between a 3D object and the reconstruction of its digital image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						r-regular; topology; digitization; 3D; marching cubes; trilinear interpolation; well-composed		Digitization is not as easy as it looks. If one digitizes a 3D object even with a dense sampling grid, the reconstructed digital object may have topological distortions and, in general, there exists no upper bound for the Hausdorff distance. This explains why so far no algorithm has been known which guarantees topology preservation. However, as we will show, it is possible to repair the obtained digital image in a locally bounded way so that it is homeomorphic and close to the 3D object. The resulting digital object is always well-composed, which has nice implications for a lot of image analysis problems. Moreover, we will show that the surface of the original object is homeomorphic to the result of the marching cubes algorithm. This is really surprising since it means that the well-known topological problems of the marching cubes reconstruction simply do not occur for digital images of r-regular objects. Based on the trilinear interpolation, we also construct a smooth isosurface from the digital image that has the same topology as the original surface. Finally, we give a surprisingly simple topology preserving reconstruction method by using overlapping balls instead of cubical voxels. This is the first approach of digitizing 3D objects which guarantees topology preservation and gives an upper bound for the geometric distortion. Since the output can be chosen as a pure voxel presentation, a union of balls, a reconstruction by trilinear interpolation, a smooth isosurface, or the piecewise linear marching cubes surface, the results are directly applicable to a huge class of image analysis algorithms. Moreover, we show how one can efficiently estimate the volume and the surface area of 3D objects by looking at their digitizations. Measuring volume and surface area of digital objects are important problems in 3D image analysis. Good estimators should be multigrid convergent, i.e., the error goes to zero with increasing sampling density. We will show that every presented reconstruction method can be used for volume estimation and we will give a solution for the much more difficult problem of multigrid- convergent surface area estimation. Our solution is based on simple counting of voxels and we are the first to be able to give absolute bounds for the surface area.	Univ Hamburg, Cognist Syst Grp, D-22527 Hamburg, Germany; Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA; Univ Fed Mato Grosso do Sul, Dept Comp & Estatist, BR-79070900 Campo Grande, MS, Brazil	University of Hamburg; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; Universidade Federal de Mato Grosso do Sul	Stelldinger, P (corresponding author), Univ Hamburg, Cognist Syst Grp, Vogt Koelln Str 30, D-22527 Hamburg, Germany.	stelldinger@informatik.uni-hamburg.de; latecki@temple.edu; marcelo@dct.ufms.br	MA, Lei/I-4597-2014	Latecki, Longin Jan/0000-0002-5102-8244				Bailey DG, 2004, LECT NOTES COMPUT SC, V3322, P394; CHERNYAEV E, 1995, CN9517 CONS EUR RECH; CO CS, 2004, P JOINT EUR IEEE TCV, P273; Coeurjolly D, 2003, LECT NOTES COMPUT SC, V2616, P101; DURST MJ, 1988, P SIGGRAPH COMPUTER, V22, P243; FRANCIS LA, 1999, P 37 ANN SE REG C; KENMOCHI Y, 2001, P IS T SPIE C VIS GE, V4117, P100; Klette R, 2000, J MATH IMAGING VIS, V13, P173, DOI 10.1023/A:1011289414377; Klette R., 2004, DIGITAL GEOMETRY; KONG TY, 1990, PATTERN RECOGN LETT, V11, P231, DOI 10.1016/0167-8655(90)90060-F; KOTHE U, 2003, P DISCRETE GEOME NOV, P82; Latecki LJ, 1998, J MATH IMAGING VIS, V8, P131, DOI 10.1023/A:1008273227913; Latecki LJ, 1997, GRAPH MODEL IM PROC, V59, P164, DOI 10.1006/gmip.1997.0422; Lewiner T., 2003, Journal of Graphics Tools, V8, P1, DOI 10.1080/10867651.2003.10487582; Lopes A, 2003, IEEE T VIS COMPUT GR, V9, P16, DOI 10.1109/TVCG.2003.1175094; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Marr D., 1983, VISION; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; Nielson GM, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P489, DOI 10.1109/VISUAL.2004.28; NIELSON GM, 1991, VISUALIZATION 91, P83; Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293; Rosenfeld A, 1998, GRAPH MODEL IM PROC, V60, P24, DOI 10.1006/gmip.1997.0459; Serra J, 1982, IMAGE ANAL MATH MORP; SIQUEIRA M, 2005, P IS T SPIE C VIS GE, V13, P150; SLOBODA F, 2001, P DISCR GEOM COMP IM, P365; Stelldinger P, 2005, IMAGE VISION COMPUT, V23, P237, DOI 10.1016/j.imavis.2004.06.003; Stelldinger P, 2003, LECT NOTES COMPUT SC, V2781, P108; STELLDINGER P, 2006, P IEEE INT C IM AN; SUKUMAR N, 2003, P 6 INT ESAFORM C MA, P603; Tajine M, 2002, THEOR COMPUT SCI, V283, P243, DOI 10.1016/S0304-3975(01)00082-2; WESTOVER L, 1989, P CHAP HILL WORKSH V; Wilhelms J., 1990, Computer Graphics, V24, P79, DOI 10.1145/99308.99325	32	43	44	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					126	140		10.1109/TPAMI.2007.250604	http://dx.doi.org/10.1109/TPAMI.2007.250604			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108388	Green Submitted			2022-12-18	WOS:000241988300010
J	Zickler, T; Ramamoorthi, R; Enrique, S; Belhumeur, PN				Zickler, Todd; Ramamoorthi, Ravi; Enrique, Sebastian; Belhumeur, Peter N.			Reflectance sharing: Predicting appearance from a sparse set of images of a known shape	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						reflectance; BRDF; image synthesis; image-based rendering; radial basis functions	ILLUMINATION; COMPONENTS; MODELS; COLOR	Three- dimensional appearance models consisting of spatially varying reflectance functions defined on a known shape can be used in analysis- by- synthesis approaches to a number of visual tasks. The construction of these models requires the measurement of reflectance, and the problem of recovering spatially varying reflectance from images of known shape has drawn considerable interest. To date, existing methods rely on either: 1) low- dimensional ( e. g., parametric) reflectance models, or 2) large data sets involving thousands of images ( or more) per object. Appearance models based on the former have limited accuracy and generality since they require the selection of a specific reflectance model a priori, and while approaches based on the latter may be suitable for certain applications, they are generally too costly and cumbersome to be used for image analysis. We present an alternative approach that seeks to combine the benefits of existing methods by enabling the estimation of a nonparametric spatially varying reflectance function from a small number of images. We frame the problem as scattered- data interpolation in a mixed spatial and angular domain, and we present a theory demonstrating that the angular accuracy of a recovered reflectance function can be increased in exchange for a decrease in its spatial resolution. We also present a practical solution to this interpolation problem using a new representation of reflectance based on radial basis functions. This representation is evaluated experimentally by testing its ability to predict appearance under novel view and lighting conditions. Our results suggest that since reflectance typically varies slowly from point to point over much of an object's surface, we can often obtain a nonparametric reflectance function from a sparse set of images. In fact, in some cases, we can obtain reasonable results in the limiting case of only a single input image.	Harvard Univ, Div Engn & Appl Sci, Cambridge, MA 02138 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Harvard University; Columbia University	Zickler, T (corresponding author), Harvard Univ, Div Engn & Appl Sci, 33 Oxford St, Cambridge, MA 02138 USA.	zickler@eecs.harvard.edu; ravir@cs.columbia.edu; senrique@cs.columbia.edu; belhumeur@cs.columbia.edu						[Anonymous], 1992, ADV NUMERICAL ANAL 2; BEATSON G, 1995, LECT APPL MATH, V32, P77; BEATSON RK, 1992, COMPUT MATH APPL, V24, P7, DOI 10.1016/0898-1221(92)90167-G; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Boivin S, 2001, COMP GRAPH, P107, DOI 10.1145/383259.383270; BRACEWELL RN, 1993, ELECTRON LETT, V29, P304, DOI 10.1049/el:19930207; Buhmann MD:, 2003, CAMBRIDGE MONOGRAPHS, V12)., DOI 10.1017/CBO9780511543241; Cabral B, 1999, COMP GRAPH, P165, DOI 10.1145/311535.311553; CARR JC, 2001, P 28 ANN C COMP GRAP, P67, DOI DOI 10.1145/383259.383266; Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932; Cheng Y, 2002, BIOMACROMOLECULES, V3, P456, DOI 10.1021/bm0156227; CHRISTOUDIAS C, 2004, P EUR C COMP VIS, V4, P481; Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819; Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855; Dinh HQ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P606, DOI 10.1109/ICCV.2001.937682; DUCHON J, 1997, CONSTRUCTIVE THEORY, P85; Durand F, 2005, ACM T GRAPHIC, V24, P1115, DOI 10.1145/1073204.1073320; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Gu XF, 2002, ACM T GRAPHIC, V21, P355; Hara K, 2005, IEEE T PATTERN ANAL, V27, P493, DOI 10.1109/TPAMI.2005.82; HERTZMANN A, 2003, P IEEE C COMP VIS PA; Jaroszkiewicz R, 2003, PROC GRAPH INTERF, P1; Karner KF, 1996, COMPUT GRAPH FORUM, V15, pC119, DOI 10.1111/1467-8659.1530119; LAFORTUNE EPF, 1997, P SIGGRAPH, P117; LEE AWF, 1998, P SIGGRAPH 98, P95, DOI DOI 10.1145/280814.280828; LENSCH HPA, 2001, RENDERING TECHNIQUES; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Lu R, 1998, APPL OPTICS, V37, P5974, DOI 10.1364/AO.37.005974; Marschner S. R, 1998, THESIS CORNELL U; Marschner SR, 1999, SPRING EUROGRAP, P131; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; Matusik W, 2002, ACM T GRAPHIC, V21, P427, DOI 10.1145/566570.566599; MCALLISTER DK, 2002, GRAPHICS HARDWARE 20, P79; McCool MD, 2001, COMP GRAPH, P171, DOI 10.1145/383259.383276; Mersch S., 1984, P RI SME 3 ANN APPL, P40; Meseth J, 2004, COMPUT GRAPH-UK, V28, P105, DOI 10.1016/j.cag.2003.10.011; MICCHELLI CA, 1986, CONSTR APPROX, V2, P11, DOI 10.1007/BF01893414; Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113; Nayar SK, 2004, ACM T GRAPHIC, V23, P963, DOI 10.1145/1027411.1027414; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; NICODEMUS FE, 1977, MONOGRAPH NBS, V160; OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684; Ramantoorthi R, 2002, ACM T GRAPHIC, V21, P517, DOI 10.1145/566570.566611; Rusinkiewicz S. M., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P11; SATO Y, 1997, P SIGGRAPH 97, P379; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; WAHBA G, 1990, P CBMSNSF REGIONAL C, V59; WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078; Wood DN, 2000, COMP GRAPH, P287, DOI 10.1145/344779.344925; Yu YZ, 1999, COMP GRAPH, P215; ZICKLER T, 2005, P EUR S REND; Zickler TE, 2002, INT J COMPUT VISION, V49, P215, DOI 10.1023/A:1020149707513	57	43	45	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1287	1302		10.1109/TPAMI.2006.170	http://dx.doi.org/10.1109/TPAMI.2006.170			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886864				2022-12-18	WOS:000238162400010
J	Charalampidis, D				Charalampidis, D			A modified K-means algorithm for circular invariant clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; algorithms; similarity measures	TEXTURE CLASSIFICATION; SEGMENTATION; FEATURES; MODELS	Several important pattern recognition applications are based on feature vector extraction and vector clustering. Directional patterns are commonly represented by rotation-variant vectors F-d formed from features uniformly extracted in M directions. It is often desirable that pattern recognition algorithms are invariant under pattern rotation. This paper introduces a distance measure and a K-means-based algorithm, namely, Circular K-means (CK-means) to cluster vectors containing directional information, such as F-d, in a circular-shift invariant manner. A circular shift of F-d corresponds to pattern rotation, thus, the algorithm is rotation invariant. An efficient Fourier domain representation of the proposed measure is presented to reduce computational complexity. A split and merge approach (SMCK-means), suited to the proposed CK-means technique, is proposed to reduce the possibility of converging at local minima and to estimate the correct number of clusters. Experiments performed for textural images illustrate the superior performance of the proposed algorithm for clustering directional vectors F-d, compared to the alternative approach that uses the original K-means and rotation-invariant feature vectors transformed from F-d.	Univ New Orleans, Dept Elect Engn, New Orleans, LA 70148 USA	University of Louisiana System; University of New Orleans	Charalampidis, D (corresponding author), Univ New Orleans, Dept Elect Engn, 2000 Lakeshore Dr, New Orleans, LA 70148 USA.	dcharala@uno.edu						Arof H, 1998, IEE P-VIS IMAGE SIGN, V145, P167, DOI 10.1049/ip-vis:19981688; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; BRADLEY PS, 1998, P 15 INT C MACH LEAR, P91; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Charalampidis D, 2002, IEEE T IMAGE PROCESS, V11, P825, DOI 10.1109/TIP.2002.801117; Charalampidis D, 2002, IEEE T GEOSCI REMOTE, V40, P1121, DOI 10.1109/TGRS.2002.1010899; Charalampidis D, 2001, IEEE T NEURAL NETWOR, V12, P1023, DOI 10.1109/72.950132; COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648; Duda R.O., 1973, J ROYAL STAT SOC SER; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Georgiopoulos M, 1999, NEURAL NETWORKS, V12, P837, DOI 10.1016/S0893-6080(99)00031-3; Gray R. M., 2005, TOEPLITZ CIRCULANT M; GREENSPAN H, 1994, P 12 INT C PATT REC, V2, P162; Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Kasparis T, 2001, PATTERN RECOGN, V34, P1963, DOI 10.1016/S0031-3203(00)00126-6; KOHONEN T, 1988, IEEE COMPUT, V27, P11; Kohonen T., 1989, SELF ORG ASSOCIATIVE, V3rd; MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5; MILLIGAN GW, 1985, PHYCHOMETRICA, P159; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478; Su M.-C., 2001, IEEE T PATTERN ANAL, V23; Tou JT, 1974, PATTERN RECOGN	25	43	44	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1856	1865		10.1109/TPAMI.2005.230	http://dx.doi.org/10.1109/TPAMI.2005.230			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16355655				2022-12-18	WOS:000232532600002
J	Kanatani, K				Kanatani, K			Uncertainty modeling and model selection for geometric inference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical method; feature point extraction; asymptotic evaluation; geometric AIC; geometric MDL	SEGMENTATION; INFORMATION	We first investigate the meaning of "statistical methods" for geometric inference based on image feature points. Tracing back the origin of feature uncertainty to image processing operations, we discuss the implications of asymptotic analysis in reference to "geometric fitting" and "geometric model selection" and point out that a correspondence exists between the standard statistical analysis and the geometric inference problem. Then, we derive the "geometric AIC" and the "geometric MDL" as counterparts of Akaike's AIC and Rissanen's MDL. We show by experiments that the two criteria have contrasting characteristics in detecting degeneracy.	Okayama Univ, Dept Informat Technol, Okayama 7008530, Japan	Okayama University	Kanatani, K (corresponding author), Okayama Univ, Dept Informat Technol, Okayama 7008530, Japan.	kanatani@suri.it.okayama-u.ac.jp						AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Bubna K, 2000, COMPUT VIS IMAGE UND, V80, P215, DOI 10.1006/cviu.2000.0871; Chabat F, 1999, IMAGE VISION COMPUT, V17, P761, DOI 10.1016/S0262-8856(98)00150-4; Cho K, 1997, IEEE T PATTERN ANAL, V19, P1185, DOI 10.1109/34.632979; Cho KJ, 1997, COMPUT VIS IMAGE UND, V68, P72, DOI 10.1006/cviu.1997.0546; Efron B., 1994, MONOGR STAT APPL PRO, DOI DOI 10.1007/978-1-4899-4541-9; Gu HS, 1996, IEEE T PATTERN ANAL, V18, P58, DOI 10.1109/34.476012; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Kanatani K, 2002, LECT NOTES COMPUT SC, V2352, P335; Kanatani K, 1998, INT J COMPUT VISION, V26, P171, DOI 10.1023/A:1007948927139; Kanatani K., 1996, STAT OPTIMIZATION GE; KANATANI K, 2002, P 5 AS C COMP VIS ME, V1, P7; KANATANI K, 2001, P 8 INT C COMP VIS V, V2, P301; KANATANI K, 2002, P 5 AS C COMP VIS JA, V1, pR21; Kanazawa Y., 2001, 3D Structure from Images - SMILE 2000. Second European Workshop on 3D Structure from Multiple Images of Large-Scale Environments. Revised Papers (Lecture Notes in Computer Science Vol.2018), P35; Kanazawa Y, 1997, IEICE T INF SYST, VE80D, P774; Kanazawa Y, 1996, IEICE T INF SYST, VE79D, P1317; Kanazawa Y, 1996, IEICE T INF SYST, VE79D, P1323; KANAZAWA Y, 2001, P INT C COMP VIS VAN, V2, P586; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; Matsunaga C., 2000, P 6 EUR C COMP VIS D, V2, P595; Maxwell BA, 2000, COMPUT VIS IMAGE UND, V77, P1, DOI 10.1006/cviu.1999.0801; MAYBANK SJ, 1999, P 10 BRIT MACH VIS C, P53; Morris DD, 2001, PROC CVPR IEEE, P343; Ohta N, 1998, IEICE T INF SYST, VE81D, P243; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936; Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Sugaya Y, 2003, IEICE T INF SYST, VE86D, P1095; Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P485, DOI 10.1109/ICCV.1998.710762; Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; Torr PHS, 1997, PROC CVPR IEEE, P47, DOI 10.1109/CVPR.1997.609296; TORR PHS, 2000, P 6 EUR C COMP VIS J, V1, P511; Triono I, 1998, IEICE T INF SYST, VE81D, P246	39	43	43	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2004	26	10					1307	1319		10.1109/TPAMI.2004.93	http://dx.doi.org/10.1109/TPAMI.2004.93			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	844EM	15641718	Green Submitted			2022-12-18	WOS:000223140200006
J	Tong, WS; Tang, CK; Mordohai, P; Medioni, G				Tong, WS; Tang, CK; Mordohai, P; Medioni, G			First order augmentation to tensor voting for boundary inference and multiscale analysis in 3D	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tensor voting; first order voting; boundary inference; discontinuities; multiscale analysis; 3D perceptual organization	PERCEPTUAL ORGANIZATION; SCALE-SPACE; NEURAL MODEL; SHAPE; REPRESENTATION; SEGMENTATION; INTEGRATION; CONTOURS; SURFACE; CURVES	Most computer vision applications require the reliable detection of boundaries. In the presence of outliers, missing data, orientation discontinuities, and occlusion, this problem is particularly challenging. We propose to address it by complementing the tensor voting framework, which was limited to second order properties, with first order representation and voting. First order voting fields and a mechanism to vote for 3D surface and volume boundaries and curve endpoints in 3D are defined. Boundary inference is also useful for a second difficult problem in grouping, namely, automatic scale selection. We propose an algorithm that automatically infers the smallest scale that can preserve the finest details. Our algorithm then proceeds with progressively larger scales to ensure continuity where it has not been achieved. Therefore, the proposed approach does not oversmooth features or delay the handling of boundaries and discontinuities until model misfit occurs. The interaction of smooth features, boundaries, and outliers is accommodated by the unified representation, making possible the perceptual organization of data in curves, surfaces, volumes, and their boundaries simultaneously. We present results on a variety of data sets to show the efficacy of the improved formalism.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90083 USA	Hong Kong University of Science & Technology; University of Southern California	Tong, WS (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Hong Kong, Hong Kong, Peoples R China.	cstws@cs.ust.hk; cktang@cs.ust.hk; mordohai@iris.usc.edu; medioni@iris.usc.edu	Mordohai, Philippos/B-8480-2008					Boyer KL, 1999, COMPUT VIS IMAGE UND, V76, P1, DOI 10.1006/cviu.1999.0797; Dolan J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P264, DOI 10.1109/CVPR.1992.223265; Gray CM, 1999, NEURON, V24, P31, DOI 10.1016/S0896-6273(00)80820-X; GROSSBERG S, 1988, PERCEPT PSYCHOPHYS, V43, P241, DOI 10.3758/BF03207869; GROSSBERG S, 1985, PSYCHOL REV, V92, P173, DOI 10.1037/0033-295X.92.2.173; Heitger F., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P32, DOI 10.1109/ICCV.1993.378238; Li ZP, 1998, NEURAL COMPUT, V10, P903, DOI 10.1162/089976698300017557; Lindeberg T, 1996, CERN REPORT, V96, P27; Lindeberg T., 1999, HDB COMPUTER VISION, P239; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Lorigo LM, 2000, PROC CVPR IEEE, P444, DOI 10.1109/CVPR.2000.855853; LOWE DG, 1989, INT J COMPUT VISION, V3, P119, DOI 10.1007/BF00126428; Marr D., 1982, VISION; *MCCONN BRAIN IM C, 2004, BRAINW; Medioni G., 2000, COMPUTATIONAL FRAMEW; Mingolla E, 1999, NEURAL NETWORKS, V12, P499, DOI 10.1016/S0893-6080(98)00144-0; MOHAN R, 1992, IEEE T PATTERN ANAL, V14, P616, DOI 10.1109/34.141553; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Mokhtarian F., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P298, DOI 10.1109/CVPR.1988.196252; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; Neumann H., 2001, FRAGMENTS OBJECTS SE, P353; Nicolescu M, 2003, IEEE T PATTERN ANAL, V25, P492, DOI 10.1109/TPAMI.2003.1190574; Osher S., 2002, LEVEL SET METHOD DYN; OSHER S, 2001, UCLA COMPUTATIONAL A, P32; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Raizada RDS, 2001, VIS COGN, V8, P431, DOI 10.1080/13506280143000070; SANDER PT, 1990, IEEE T PATTERN ANAL, V12, P833, DOI 10.1109/34.57680; SARKAR S, 1994, IEEE T SYST MAN CYB, V24, P246, DOI 10.1109/21.281424; Saund E., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P257, DOI 10.1109/CVPR.1992.223266; SAUND E, 1990, IEEE T PATTERN ANAL, V12, P817, DOI 10.1109/34.57672; Sethian JA, 1996, LEVEL SET METHODS EV; Tang CK, 2002, IEEE T PATTERN ANAL, V24, P858, DOI 10.1109/TPAMI.2002.1008395; Tang CK, 2001, IEEE T PATTERN ANAL, V23, P829, DOI 10.1109/34.946987; Tang CK, 1998, IEEE T PATTERN ANAL, V20, P1206, DOI 10.1109/34.730555; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TONG WS, 2001, P COMP VIS PATT REC, V1, P175; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; Williams MA, 1999, LEUKEMIA LYMPHOMA, V34, P1; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; Yen SC, 1998, VISION RES, V38, P719, DOI 10.1016/S0042-6989(97)00197-1; Zeng XL, 1998, LECT NOTES COMPUT SC, V1496, P519, DOI 10.1007/BFb0056237	44	43	48	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2004	26	5					594	611		10.1109/TPAMI.2004.1273934	http://dx.doi.org/10.1109/TPAMI.2004.1273934			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EY	15460281				2022-12-18	WOS:000220756400005
J	Zunic, J; Rosin, PL				Zunic, J; Rosin, PL			Rectilinearity measurements for polygons	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape; polygons; rectilinearity; measurement	BUILDINGS; SHAPE; CIRCULARITY; SHADOWS	The paper introduces a shape measure intended to describe the extent to which a closed polygon is rectilinear. Other than somewhat obvious measures of rectilinearity (e.g., the sum of the differences of each corner's angle from multiples of 90degrees), there has been little work in deriving a measure that is straightforward to compute, is invariant under scale, rotation, and translation, and corresponds with the intuitive notion of rectilinear shapes. There are applications in a number of different areas of computer vision and photogrammetry. Rectilinear structures often correspond to human-made objects and are therefore justified as attentional cues for further processing. For instance, in aerial image processing and reconstruction, where building footprints are often rectilinear on the local ground plane, building structures, once recognized as rectilinear, can be matched to corresponding shapes in other views for stereo reconstruction. Perceptual grouping algorithms may seek to complete shapes based on the assumption that the object in question is rectilinear. Using the proposed measure, such systems can verify this assumption.	Cardiff Univ, Dept Comp Sci, Cardiff CF24 3XF, S Glam, Wales; Serbian Acad Arts & Sci, Math Inst, Belgrade, Serbia	Cardiff University; Serbian Academy of Sciences & Arts	Zunic, J (corresponding author), Cardiff Univ, Dept Comp Sci, Queens Bldg,Newport Rd,POB 916, Cardiff CF24 3XF, S Glam, Wales.	J.Zunic@cs.cf.ac.uk; Paul.Rosin@cs.cf.ac.uk		Rosin, Paul/0000-0002-4965-3884				BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; BRUNN A, 1995, MUSTERERKENNUNG 1995, P260; Chen DZ, 2001, COMP GEOM-THEOR APPL, V18, P155, DOI 10.1016/S0925-7721(01)00005-0; Collins RT, 1998, COMPUT VIS IMAGE UND, V72, P143, DOI 10.1006/cviu.1998.0729; DARE P, 1997, P IM REG WORKSH NASA, P83; Diaz-Banez JM, 2001, EUR J OPER RES, V130, P214, DOI 10.1016/S0377-2217(00)00023-0; Feldman J, 2000, J EXP PSYCHOL HUMAN, V26, P152, DOI 10.1037/0096-1523.26.1.152; HANSON AR, 2001, P INT WORKSH AER SPA, P25; HARALICK RM, 1974, IEEE T SYST MAN CYB, VSMC4, P394, DOI 10.1109/TSMC.1974.5408463; HSIEH YC, 1992, IEEE T PATTERN ANAL, V14, P214, DOI 10.1109/34.121790; Hyde S., 1997, LANGUAGE SHAPE; IRVIN RB, 1989, IEEE T SYST MAN CYB, V19, P1564, DOI [10.1109/21.44071, 10.1117/12.952691]; Jain AK, 1998, PATTERN RECOGN, V31, P1369, DOI 10.1016/S0031-3203(97)00131-3; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; LIOW YT, 1990, COMPUT VISION GRAPH, V49, P242, DOI 10.1016/0734-189X(90)90139-M; MAYER S, 2001, P INT C IM PROC; Noronha S, 2001, IEEE T PATTERN ANAL, V23, P501, DOI 10.1109/34.922708; PROFFITT D, 1982, PATTERN RECOGN, V15, P383, DOI 10.1016/0031-3203(82)90041-3; Rosin PL, 1999, MACH VISION APPL, V11, P191, DOI 10.1007/s001380050101; Rosin PL, 2000, IEEE T SYST MAN CY A, V30, P202, DOI 10.1109/3468.833102; ROSIN PL, UNPUB INT J REMOTE S; Sonka M., 1993, IMAGE PROCESSING ANA, DOI DOI 10.1007/978-1-4899-3216-7_4; Ventura A. D., 1990, IEEE T GEOSCI REMOTE, V28, P305; Willats John, 1997, ART REPRESENTATION N; WILLOUGHBY LG, 1992, NOVA HEDWIGIA, V55, P1; WITKIN A, 1980, 589 MIT	26	43	45	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2003	25	9					1193	1200		10.1109/TPAMI.2003.1227997	http://dx.doi.org/10.1109/TPAMI.2003.1227997			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	715MX					2022-12-18	WOS:000184977300016
J	Rhouma, MBH; Frigui, H				Rhouma, MBH; Frigui, H			Self-organization of pulse-coupled oscillators with application to clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						oscillators; synchronization; phase-locking; unsupervised learning; clustering; hierarchical clustering	VISUAL-CORTEX; FUZZY; SYNCHRONIZATION; SEGMENTATION; ALGORITHM	We introduce an efficient synchronization model that organizes a population of Integrate and Fire oscillators into stable and structured groups. Each oscillator fires synchronously with all the others within its group. but the groups themselves fire with a constant phase difference. The structure of the synchronized groups depends on the choice of the coupling function. We show that by defining the interaction between oscillators according to the relative distance between them, our model can be used as a general clustering algorithm. Unlike existing models, our model incorporates techniques from relational and prototype-based clustering methods and results in a clustering algorithm that is simple, efficient, robust, unbiased by the size of the clusters, and that can find an arbitrary number of clusters. In addition to helping the model self-organize into stable groups, the synergy between clustering and synchronization reduces the computational complexity significantly. The resulting clustering algorithm has several advantages over conventional clustering techniques. In particular, it can generate a nested sequence of partitions and it can determine the optimum number of clusters in an efficient manner. Moreover, since our approach does not involve optimizing an objective function, it is not sensitive to initialization and it can incorporate nonmetric similarity measures. We illustrate the performance of our algorithms with several synthetic and real data sets.	Georgia Inst Technol, Dept Math, CDSNS, Atlanta, GA 30332 USA; Univ Memphis, Dept Elect & Comp Engn, Memphis, TN 38152 USA	University System of Georgia; Georgia Institute of Technology; University of Memphis	Rhouma, MBH (corresponding author), Georgia Inst Technol, Dept Math, CDSNS, Atlanta, GA 30332 USA.	rhouma@math.gatech.edu; hfrigui@mmphis.edu						BELAIR J, 1988, J MATH BIOL, V24, P74; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; BEZDEK JC, 1981, SIAM J APPL MATH, V40, P358, DOI 10.1137/0140030; Bressloff PC, 1997, PHYS REV LETT, V78, P4665, DOI 10.1103/PhysRevLett.78.4665; Bressloff PC, 1999, PHYSICA D, V126, P99, DOI 10.1016/S0167-2789(98)00264-4; Broussard RP, 1999, IEEE T NEURAL NETWOR, V10, P554, DOI 10.1109/72.761712; BUCK J, 1976, SCI AM, V234, P74; CARSON C, UNPUB IEEE T PATTERN; Coombes S, 1997, PHYS REV E, V55, pR2104, DOI 10.1103/PhysRevE.55.R2104; Coombes S, 1999, PHYS REV E, V60, P2086, DOI 10.1103/PhysRevE.60.2086; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R. O., 1981, PATTERN CLASSIFICATI; ECKHORN R, 1988, BIOL CYBERN, V60, P121, DOI 10.1007/BF00202899; ERNST U, 1995, PHYS REV LETT, V74, P1570, DOI 10.1103/PhysRevLett.74.1570; Frigui H, 1996, IEEE T FUZZY SYST, V4, P193, DOI 10.1109/91.493912; Frigui H, 1999, IEEE T PATTERN ANAL, V21, P450, DOI 10.1109/34.765656; Frigui H, 1997, PATTERN RECOGN, V30, P1109, DOI 10.1016/S0031-3203(96)00140-9; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GOLOMB D, 1992, PHYS REV A, V45, P3516, DOI 10.1103/PhysRevA.45.3516; GRANNAN ER, 1993, NEURAL COMPUT, V5, P550, DOI 10.1162/neco.1993.5.4.550; GRAY CM, 1989, NATURE, V338, P334, DOI 10.1038/338334a0; Horn D, 1991, NEURAL COMPUT, V3, P510, DOI 10.1162/neco.1991.3.4.510; Horn D, 1998, PULSED NEURAL NETWORKS, P297; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JOHNSON JL, 1994, APPL OPTICS, V33, P6239, DOI 10.1364/AO.33.006239; Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706; JOLION JM, 1991, IEEE T PATTERN ANAL, V13, P791, DOI 10.1109/34.85669; KEENER JP, 1981, SIAM J APPL MATH, V41, P734; Kinser J. M., 1996, Optical Memory & Neural Networks, V5, P179; KRISHNAPURAM R, 1992, IEEE T NEURAL NETWOR, V3, P663, DOI 10.1109/72.159056; KRISHNAPURAM R, 1992, PATTERN RECOGN, V25, P385, DOI 10.1016/0031-3203(92)90087-Y; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387; KRISHNAPURAM R, 1995, IEEE T FUZZY SYST, V3, P29, DOI 10.1109/91.366564; Kuramoto Y., 1984, CHEM OSCILLATORS WAV, V19; Lindblad T., 1998, IMAGE PROCESSING USI; Liu XW, 1999, IEEE T NEURAL NETWOR, V10, P564, DOI 10.1109/72.761713; MIROLLO RE, 1990, SIAM J APPL MATH, V50, P1645, DOI 10.1137/0150098; NISCHWITZ A, 1995, BIOL CYBERN, V73, P389, DOI 10.1007/BF00201473; Peskin C. S, 1975, MATH ASPECT HEART PH; RHOUMA MBH, 1999, THESIS U MISSOURI CO; RUSSELL MJ, 1980, PHARMACOL BIOCHEM BE, V13, P737, DOI 10.1016/0091-3057(80)90020-9; SHERMAN A, 1988, BIOPHYS J, V54, P411, DOI 10.1016/S0006-3495(88)82975-8; Sneath P.H.A., 1973, NUMERICAL TAXONOMY P; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; STROGATZ SH, 1991, J STAT PHYS, V63, P613, DOI 10.1007/BF01029202; TERMAN D, 1995, PHYSICA D, V81, P148, DOI 10.1016/0167-2789(94)00205-5; WALKER TJ, 1969, SCIENCE, V166, P891, DOI 10.1126/science.166.3907.891; Wang DL, 1997, NEURAL COMPUT, V9, P805, DOI 10.1162/neco.1997.9.4.805; Winfree A. T, 1980, GEOMETRY BIOL TIME, V8, DOI 10.1007/978-1-4757-3484-3; WINFREE AT, 1967, J THEOR BIOL, V16, P15, DOI 10.1016/0022-5193(67)90051-3; [No title captured]	52	43	58	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2001	23	2					180	195		10.1109/34.908968	http://dx.doi.org/10.1109/34.908968			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	401NJ					2022-12-18	WOS:000166933500007
J	Huet, B; Hancock, ER				Huet, B; Hancock, ER			Line pattern retrieval using relational histograms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image database; line patterns; content-based retrieval; relational representation; geometric features; histogram comparison	RELAXATION	This paper presents a new compact shape representation for retrieving line-patterns from large databases. The basic idea is to exploit both geometric attributes and structural information to construct a shape histogram. We realize. this goal by computing the N-nearest neighbor graph for the lines-segments for: each pattern. The edges of the neighborhood graphs are used to gate contributions to a two-dimensional pairwise geometric histogram. Shapes are indexed by searching for the line-pattern that maximizes the cross correlation of the normalized histogram bin-contents. We evaluate the new method on a database containing over 2,500 line-patterns each composed of hundreds of lines.	Univ York, Dept Comp Sci, York Y10 5DD, N Yorkshire, England	University of York - UK	Huet, B (corresponding author), Univ York, Dept Comp Sci, York Y10 5DD, N Yorkshire, England.	huetb@cs.york.ac.uk; erh@cs.york.ac.uk	Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028; Huet, Benoit/0000-0002-0608-6939				ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509; BRAY AJ, 1991, P 2 BRIT MACH VIS C, P95; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Costa M. S., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P103, DOI 10.1109/ISCV.1995.476985; DIMAURO EC, 1996, P 7 BRIT MACH VIS C, V1, P353; EVANS AC, 1993, P 4 BRIT MACH VIS C, P429; Gimelfarb GL, 1996, PATTERN RECOGN, V29, P1461, DOI 10.1016/0031-3203(96)00011-8; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; HECKER YC, 1994, IEEE T SYST MAN CYB, V24, P1328, DOI 10.1109/21.310509; Horaud R, 1995, PATTERN RECOGN, V28, P1855, DOI 10.1016/0031-3203(95)00048-8; HUET B, 1998, ADV NEURAL INFORMATI, V11, P896; RUBNER Y, 1998, P IEEE INT C COMP VI, P59; SENGUPTA K, 1995, IEEE T PATTERN ANAL, V17, P321, DOI 10.1109/34.385984; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P1198, DOI 10.1109/34.177385; STRICKER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P704, DOI 10.1109/CVPR.1994.323774; SWAIN MJ, 1993, IMAGE VISION STORAGE, P95; THACKER A, 1995, IMAGE VISION COMPUT, V13, P423, DOI 10.1016/0262-8856(95)99729-K; TSAI FCD, 1994, PATTERN RECOGN, V27, P377, DOI 10.1016/0031-3203(94)90115-5; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251	19	43	46	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1999	21	12					1363	1370		10.1109/34.817414	http://dx.doi.org/10.1109/34.817414			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	275PG		Green Submitted			2022-12-18	WOS:000084828100009
J	Sapiro, G				Sapiro, G			Color and illuminant voting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						physics-based vision; color constancy; illuminant estimation; Hough transform; physical constraints; bilinear models	SURFACE SPECTRAL REFLECTANCE; 2-STAGE LINEAR RECOVERY; RETINEX THEORY; CONSTANCY; IMAGES; RECOGNITION; VISION; LIGHTS; MODELS	A geometric-vision approach to color constancy and illuminant estimation is presented in this paper. We show a general framework, based on ideas from the generalized probabilistic Hough transform, to estimate the illuminant and reflectance of natural images. Each image pixel "votes" for possible illuminants and the estimation is based on cumulative votes. The framework is natural for the introduction of physical constraints in the color constancy problem. We show the relationship of this work to previous algorithms for color constancy and present examples.	Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Sapiro, G (corresponding author), Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA.	guille@ece.umn.edu						BRAINARD D, 1995, HDB OPTICS FUNDAMENT; BRAINARD DH, 1986, J OPT SOC AM A, V3, P1651, DOI 10.1364/JOSAA.3.001651; BRAINARD DH, 1989, IEEE T BIO-MED ENG, V36, P140, DOI 10.1109/10.16459; BUCHBERGER B, 1988, MULTIDIMENSIONAL SYS; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; COHEN J, 1964, PSYCHON SCI, V1, P369, DOI 10.3758/BF03342963; Duda RO, 1973, PATTERN RECOGNITION; DZMURA M, 1993, J OPT SOC AM A, V10, P2166, DOI 10.1364/JOSAA.10.002166; DZMURA M, 1993, J OPT SOC AM A, V10, P2148, DOI 10.1364/JOSAA.10.002148; DZMURA M, 1995, GEOMETRIC REPRESENTA; DZUMRA M, 1994, J OPT SOC AM A, V11, P2389, DOI 10.1364/JOSAA.11.002389; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553; FINLAYSON GD, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P218, DOI 10.1109/ICCV.1995.466783; FINLAYSON GD, 1997, P IS T 5 COL IM C NO; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; FREEMAN WT, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P210, DOI 10.1109/ICCV.1995.466784; FREEMAN WT, 1997, P COMP VIS PATT REC; GERSHON R, 1989, COLOR RES APPL, V14, P325, DOI 10.1002/col.5080140610; HEALEY G, 1995, J OPT SOC AM A, V12, P1877, DOI 10.1364/JOSAA.12.001877; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; HOUGH PVC, 1962, Patent No. 1069654; JUDD DB, 1964, J OPT SOC AM, V54, P1031, DOI 10.1364/JOSA.54.001031; KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279; Koenderink JJ, 1997, INT J COMPUT VISION, V23, P217, DOI 10.1023/A:1007971132346; LAND EH, 1983, P NATL ACAD SCI USA, V80, P5163, DOI 10.1073/pnas.80.16.5163; LAND EH, 1959, P NATL ACAD SCI USA, V45, P115, DOI 10.1073/pnas.45.1.115; MALONEY LT, 1986, J OPT SOC AM A, V3, P1673, DOI 10.1364/JOSAA.3.001673; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; SAPIRO G, 1998, P INT C COMP VIS BOM; Shaked D, 1996, COMPUT VIS IMAGE UND, V63, P512, DOI 10.1006/cviu.1996.0038; Shashua A., 1992, THESIS MIT CAMBRIDGE; TRUSSELL HJ, 1991, P INT C AC SPEECH SI, P2513; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; VRHEL MJ, 1994, COLOR RES APPL, V19, P4, DOI 10.1111/j.1520-6378.1994.tb00053.x; WRMAN M, 1995, P INT C COMP VIS, P473; WYSZECKI G, 1992, COLOR SCI CONCEPTS M	37	43	43	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1210	1215		10.1109/34.809114	http://dx.doi.org/10.1109/34.809114			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100010
J	DiZenzo, S; Cinque, L; Levialdi, S				DiZenzo, S; Cinque, L; Levialdi, S			Run-based algorithms for binary image analysis and processing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						run representation; graph representation; raster-to-vector conversion; multigraph; character recognition	THINNING ALGORITHM	In this paper we suggest a variant of a binary image representation based on run length encoding. This variant allows to build a ''graph representation'' which turns convenient for a number of computing tasks like component labeling, computation of Euler number, diameter, convex hull and the detection of local extrema and multiple points. A running application in the raster-to-vector conversion of digital maps is finally provided.			DiZenzo, S (corresponding author), UNIV ROMA LA SAPIENZA,DIPARTIMENTO SCI INFORMAZ,VIA SALARIA 113,I-00198 ROME,ITALY.							ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P463, DOI 10.1109/TPAMI.1985.4767685; BOATTO L, 1992, COMPUTER, V25, P25, DOI 10.1109/2.144437; Di Zenzo S, 1989, P 5 INT C IM AN PROC, P170; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; FREEMAN H, 1975, COMMUN ACM, V18, P409, DOI 10.1145/360881.360919; MARTINEZPEREZ MP, 1987, COMPUT VISION GRAPH, V39, P186, DOI 10.1016/S0734-189X(87)80165-2; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PIPER J, 1985, PATTERN RECOGN LETT, V3, P119, DOI 10.1016/0167-8655(85)90018-2; PIPER J, 1985, PATTERN RECOGN LETT, V3, P389, DOI 10.1016/0167-8655(85)90025-X; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; Rutovitz D, 1968, PICTORIAL PATTERN RE, P105; RUTOVITZ D, 1989, PROGR IMAGE ANAL PRO, P229; SKLANSKY J, 1970, PATTERN RECOGN, V2, P3, DOI 10.1016/0031-3203(70)90037-3	16	43	50	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					83	89		10.1109/34.476016	http://dx.doi.org/10.1109/34.476016			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500012
J	KISWORO, M; VENKATESH, S; WEST, G				KISWORO, M; VENKATESH, S; WEST, G			MODELING EDGES AT SUBPIXEL ACCURACY USING THE LOCAL ENERGY APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EDGE DETECTION; LOCAL ENERGY; SUBPIXEL FEATURE DETECTION; COMPUTER VISION		In this paper we describe a new technique for 1-D and 2-D edge feature extraction to subpixel accuracy using edge models and the local energy approach. A candidate edge is modeled as one of a number of parametric edge models, and the fit is refined by a least-squared error fitting technique.			KISWORO, M (corresponding author), CURTIN UNIV TECHNOL,SCH COMP,COGNIT SYST GRP,PERTH,WA,AUSTRALIA.		Kisworo, Marsudi Wahyu/H-1199-2015	Kisworo, Marsudi Wahyu/0000-0002-5407-7869				BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; HUECKEL MH, 1973, J ASS COMPUT MACH, V20; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8; KISWORO M, 793 CURT U SCH COMP; KISWORO M, 1991, AUG P IEEE TENCON NE; KISWORO M, 591 CURT U SCH COMP; KLEIN SA, 1985, J OPT SOC AM A, V2; KUNDU A, 1990, PATTERN RECOGN, V23; LEE D, 1990, IEEE T PATTERN ANAL, V12; LYVERS E, 1989, IEEE T PATTERN ANAL, V11; MACVICARWHELAN PJ, 1981, P SPIE, V281; MORRONE MC, 1987, PATTERN RECOGN, V6; NEVATIA R, 1980, COMPUT GRAPHICS IMAG, V13; PERONA P, 1991, JUN IEEE C COMP VIS, P222; PERONA P, 1990, UCBCSD90590 U CAL RE; RONSE C, C235 PHILL LABS MAN; TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6; VENKATESH S, 1990, THESIS U W AUSTR; VENKATESH S, 1990, PATTERN RECOGN LETT, V11	19	43	55	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1994	16	4					405	410		10.1109/34.277593	http://dx.doi.org/10.1109/34.277593			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NH607		Green Published			2022-12-18	WOS:A1994NH60700006
J	PRINCEN, J; ILLINGWORTH, J; KITTLER, J				PRINCEN, J; ILLINGWORTH, J; KITTLER, J			HYPOTHESIS-TESTING - A FRAMEWORK FOR ANALYZING AND OPTIMIZING HOUGH TRANSFORM PERFORMANCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							SEGMENTS	In this paper a formal, quantitative approach to designing optimum Hough transform (HT) algorithms is proposed. This approach takes the view that a HT is a hypothesis testing method. Each sample in the HT array implements a test to determine whether a curve with the given parameters fits the edge point data. This view allows the performance of HT algorithms to be quantified. The power function, which gives the probability of rejection as a function of the underlying parametric distribution of data points, is shown to be the fundamentally important characteristic of HT behaviour. Attempting to make the power function narrow is a formal approach to optimizing HT performance. To illustrate how this framework is useful the particular problem of line detection is discussed in detail. It is shown that the hypothesis testing framework leads to a redefinition of HT in which the values are a measure of the distribution of points around a curve rather than the number of points on a curve. This change dramatically improves the sensitivity of the method to small structures. The solution to many HT design problems can be posed within the framework, including optimal quantizations and optimum sampling of the parameter space. In this paper we consider the design of optimum I-D filters, which can be used to sharpen the peak structure in parameter space. Results on several real images illustrate the improvements obtained.	TELECOM AUSTRALIA,RES LABS,CLAYTON,VIC 3168,AUSTRALIA; UNIV SURREY,DEPT ELECTR & ELECT ENGN,VIS SPEECH & SIGNAL PROC RES GRP,GUILDFORD GU2 5XH,SURREY,ENGLAND	University of Surrey								BROWN CM, 1983, IEEE T PATTERN ANAL, V5, P653; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; DUDANI SA, 1978, PATTERN RECOGN, V10, P145, DOI 10.1016/0031-3203(78)90023-7; Fraser DAS., 1957, NONPARAMETRIC METHOD; GERIG G, 1986, 8TH P INT C PATT REC, V1, P498; HAMPEL FR, 1986, ROBUST STATISTICS AP; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; KENDALL MG, 1979, ADV THEORY STATISTIC, V2; LEAVERS VF, 1987, IMAGE VISION COMPUT, V5, P161, DOI 10.1016/0262-8856(87)90044-8; LEHMANN EL, 1959, TESTING STATISTICAL; OGORMAN F, 1976, IEEE T COMPUT, V25, P449, DOI 10.1109/TC.1976.1674627; PETROU M, 1988, AUG P ALV VIS C MANC, P191; Princen J., 1992, Journal of Mathematical Imaging and Vision, V1, P153, DOI 10.1007/BF00122210; PRINCEN J, 1989, COMP STUDY HOUGH TRA; PRINCEN J, 1990, THESIS U SURREY; Serfling RJ, 1980, APPROXIMATION THEORE; SPACEK LA, 1986, IMAGE VISION COMPUT, V4, P43, DOI 10.1016/0262-8856(86)90007-7; THRIFT PR, 1983, COMPUT VISION GRAPH, V21, P383, DOI 10.1016/S0734-189X(83)80050-4; VANVEEN TM, 1981, PATTERN RECOGN, V14, P137, DOI 10.1016/0031-3203(81)90055-8; NAG FORTRAN LIBRARY, V1	21	43	45	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1994	16	4					329	341		10.1109/34.277588	http://dx.doi.org/10.1109/34.277588			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NH607					2022-12-18	WOS:A1994NH60700001
J	AHUJA, N; ABBOTT, AL				AHUJA, N; ABBOTT, AL			ACTIVE STEREO - INTEGRATING DISPARITY, VERGENCE, FOCUS, APERTURE, AND CALIBRATION FOR SURFACE ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ACTIVE VISION; CAMERA CALIBRATION; FIXATION; RANGE FROM FOCUS; RANGE FROM STEREO; RANGE FROM VERGENCE; SURFACE ESTIMATION; VISUAL CUE INTEGRATION; VISUAL TARGET SELECTION	EYE-MOVEMENTS	Much research has emphasized stereo disparity as a source of depth information. To a lesser extent, camera vergence and lens focus have also been investigated for their utility in depth recovery. Each of these visual cues exhibits shortcomings when used individually in the sense that none alone can be used to reconstruct surfaces for real scenes that often cover a wide field of view and a large range of depth. This paper presents an approach to integration of these cues that attempts to exploit their complementary strengths and weaknesses through active control of camera focus and orientations. In addition, the aperture and zoom settings of the cameras are controlled. The result is an active vision system that dynamically and cooperatively interleaves image acquisition with surface estimation. A dense composite map of a single contiguous surface is synthesized by automatically scanning the surface and combining estimates of adjacent, local surface patches. This problem is formulated as one of minimizing a pair of objective functions. The first such function is concerned with the selection of a target for fixation. The second objective function guides the surface estimation process in the vicinity of the fixation point. Calibration parameters of the cameras are treated as variables during optimization, thus making camera calibration an integral, flexible component of surface estimation. An implementation of this method is described, and a performance evaluation of the system is presented. An average absolute error of less than 0.15% in estimated depth was achieved for a large surface having a depth of approximately 2 m.	UNIV ILLINOIS,DEPT ELECT & COMP ENGN,URBANA,IL 61801; VIRGINIA POLYTECH INST & STATE UNIV,BRADLEY DEPT ELECT ENGN,BLACKSBURG,VA 24061	University of Illinois System; University of Illinois Urbana-Champaign; Virginia Polytechnic Institute & State University	AHUJA, N (corresponding author), UNIV ILLINOIS,BECKMAN INST,COORDINATED SCI LAB,URBANA,IL 61801, USA.							Abbott A. L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P532, DOI 10.1109/CCV.1988.590034; ABBOTT AL, 1990, THESIS U ILLINOIS; ALOIMONOS J, 1987, 1ST P INT C COMP VIS, P35; ALTMAN E, 1990, SEP P DARPA IM UND W, P423; AYACHE N, 1988, INT J ROBOTICS RES, V7; BAJCSY R, 1988, APR P DARPA IM UND W, P279; Bajcsy R., 1985, P IEEE WORKSHOP COMP, P55; Ballard D. H., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P524, DOI 10.1109/CCV.1988.590033; BANDOPADHAY A, 1986, JUN P IEEE C COMP VI, P498; Boult T. E., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P118, DOI 10.1109/CCV.1988.589980; BOZKOV V, 1982, COGNITION EYE MOVEME, P24; BURT PJ, 1988, APR P DARPA IM UND W, P139; CHOUDHARY AN, 1989, 4TH P C HYP CONC COM; CLARK JJ, 1988, 2ND P INT C COMP VIS, P541; COOMBS DJ, 1990, 5TH P IEEE INT S INT; DAS S, 1989, NOV P IEEE WORKSH IN, P9; DAS S, 1990, 3RD P INT C COMP VIS; EASTMAN RD, 1985, DEC P DARPA IM UND W, P245; FERRIE FP, 1987, DEC P WORKSH COMP VI; Findlay JM, 1981, EYE MOVEMENTS COGNIT, P171; Foley J. M., 1978, HDB SENSORY PHYSL; GEIGER D, 1987, 1ST P INT C COMP VIS, P306; Gennert M. A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P87, DOI 10.1109/CCV.1988.589974; GRIMSON WEL, 1981, IMAGES SURFACES; GRONER R, 1985, EYE MOVEMENTS HUMAN; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; HOFF W, 1985, DEC P DARPA IM UND W, P98; HOFF W, 1987, 1ST P INT C COMP VIS, P284; HORN BKP, 1968, MIT160 ART INT LAB R; HUNG GK, 1980, IEEE T BIOMED ENG, V27; JARVIS RA, 1976, MICROSCOPE, V24, P163; Kamgar-Parsi B., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P282, DOI 10.1109/CVPR.1989.37862; KOCH C, 1984, MIT AL770; KRISHANN VV, 1977, IEEE T BIOMED ENG, V24; Krotkov E. P., 1986, MSCIS8622 U PENNS GR; Krotkov EP, 1989, ACTIVE COMPUTER VISI; LEVYSCHOEN A, 1981, EYE MOVEMENTS COGNIT, P299; LIGHART G, 1982, 6TH P INT C PATT REC, P697; LOOCHER PJ, 1987, EYE MOVEMENTS PHYSL, P353; MACKWORTH NH, 1967, PERCEPT PSYCHOPHYS, V2, P547, DOI 10.3758/BF03210264; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; Marr D., 1982, VISION; NOTON D, 1971, VISION RES, V11, P929, DOI 10.1016/0042-6989(71)90213-6; OLSON TJ, 1989, CVPR 89, P404; OREGAN JK, 1983, VISION RES, V23, P765, DOI 10.1016/0042-6989(83)90198-0; SCHOR CM, 1979, VISION RES, V19, P1359, DOI 10.1016/0042-6989(79)90208-6; SHMUEL A, 1990, 10TH P INT C PATT RE, P48; SPERLING G, 1970, AM J PSYCHOL, V83, P461, DOI 10.2307/1420686; Takahashi H., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P123, DOI 10.1109/CCV.1988.589981; TENENBAUM JM, 1971, THESIS STANFORD U	50	43	43	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1993	15	10					1007	1029		10.1109/34.254059	http://dx.doi.org/10.1109/34.254059			23	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MD775					2022-12-18	WOS:A1993MD77500004
J	COOPER, J; VENKATESH, S; KITCHEN, L				COOPER, J; VENKATESH, S; KITCHEN, L			EARLY JUMP-OUT CORNER DETECTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CORNER DETECTION; IMAGE NOISE MODELING; SEQUENTIAL ANALYSIS; SIMILARITY MEASURES; THRESHOLDING		We present two new corner detectors. one works by using dissimilarity along the contour direction to detect curves in the image contour and the other estimates image curvature along the contour direction. These operators are fast, robust to noise, and require no subjective thresholding.	CURTIN UNIV TECHNOL,DEPT COMP SCI,PERTH,AUSTRALIA; UNIV MELBOURNE,DEPT COMP SCI,PARKVILLE,VIC 3052,AUSTRALIA	Curtin University; University of Melbourne	COOPER, J (corresponding author), EDITH COWAN UNIV,DEPT COMP SCI,MT LAWLEY,AUSTRALIA.			venkatesh, svetha/0000-0001-8675-6631				BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; COOPER J, 1990, 9014 U W AUSTR COMP; Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NOBEL AJ, 1988, IMAGE VISION COMPUT, V6, P121; SPACEK LA, 1985, THESIS U ESSEX; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; Wald A., 1947, SEQUENTIAL ANAL	8	43	47	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1993	15	8					823	828		10.1109/34.236246	http://dx.doi.org/10.1109/34.236246			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR948		Green Published, Green Submitted			2022-12-18	WOS:A1993LR94800008
J	GREGSON, PH				GREGSON, PH			USING ANGULAR-DISPERSION OF GRADIENT DIRECTION FOR DETECTING EDGE RIBBONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ADAPTIVE THRESHOLDING; ANGULAR DISPERSION; EDGE DETECTION; GRADIENT DIRECTION; SIGNAL-TO-NOISE RATIO	RELAXATION	Selection of suitable thresholds for edgel detection is frequently problematical due to the conflicting requirements of minimizing the number of false edgels detected while simultaneously minimizing the number of valid edgels missed. To minimize detection errors, detection thresholds should be based on the image signal to noise ratio (SNR), with the added benefit of maximizing the useful dynamic range of the imaging system. Edges in the scene generally project to smooth continuous curves nearly everywhere in the image. This results in low angular deviation of the intensity gradients in small neighborhoods straddling edges. Angular deviation is shown to be a measure of SNR. A theoretical analysis of angular deviation arising due to i.i.d. N(0, sigma2) random noise is presented. Angular deviation thresholds for neighborhood sizes from 3 x 3 to 11 x 11 are determined both from this analysis and numerical examples. The proposed gradient angular dispersion detection algorithm detects edge elements by comparing the measured angular deviation with values computed for the minimum acceptable SNR. Low values of deviation violate the ''no edge'' hypothesis. The algorithm is shown to make good use of the limited dynamic range of the imaging system. The sensitivity and selectivity of the strategy are both shown to be high.			GREGSON, PH (corresponding author), TECH UNIV NOVA SCOTIA,DEPT ELECT ENGN,COMP VIS IMAGE PROC LAB,HALIFAX B3J 2X4,NS,CANADA.							Ballard D.H., 1982, COMPUTER VISION; Batschelet E, 1981, CIRCULAR STAT BIOL; Boie R. A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P100; Boie R. A., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P450; BURNS JD, 1987, READINGS COMPUTER VI, P180; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DAVIES ER, 1987, PATTERN RECOGN LETT, V6, P315, DOI 10.1016/0167-8655(87)90014-6; Gonzalez R. C., 1987, DIGITAL IMAGE PROCES; GREGSON PH, 1988, THESIS TU NOVA SCOTI; Levine M., 1985, VISION MAN MACHINE; LYVERS EP, 1988, IEEE T PATTERN ANAL, V10, P927, DOI 10.1109/34.9114; Marr D., 1982, VISION; Papoulis A., 2002, PROBABILITY RANDOM V; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; PRESS WH, NUMERICAL RECIPES C, P202; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; WATT RJ, 1983, INVEST OPHTH VIS SCI, V24, P66; WATT RJ, 1984, VISION RES, V24, P1387, DOI 10.1016/0042-6989(84)90194-9; WICHMANN B, 1987, BYTE, V12, P127; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848	20	43	43	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1993	15	7					682	696		10.1109/34.221169	http://dx.doi.org/10.1109/34.221169			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LM185					2022-12-18	WOS:A1993LM18500003
