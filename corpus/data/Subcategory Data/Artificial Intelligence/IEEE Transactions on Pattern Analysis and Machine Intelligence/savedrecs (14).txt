PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	You, Y; Li, CK; Lou, YJ; Cheng, ZJ; Li, LW; Ma, LZ; Wang, WM; Lu, CW				You, Yang; Li, Chengkun; Lou, Yujing; Cheng, Zhoujun; Li, Liangwei; Ma, Lizhuang; Wang, Weiming; Lu, Cewu			Understanding Pixel-Level 2D Image Semantics With 3D Keypoint Knowledge Engine	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Three-dimensional displays; Engines; Annotations; Solid modeling; Pipelines; Training; Keypoint; dataset; point cloud; object analysis; semantic understanding	MODEL	Pixel-level 2D object semantic understanding is an important topic in computer vision and could help machine deeply understand objects (e.g., functionality and affordance) in our daily life. However, most previous methods directly train on correspondences in 2D images, which is end-to-end but loses plenty of information in 3D spaces. In this paper, we propose a new method on predicting image corresponding semantics in 3D domain and then projecting them back onto 2D images to achieve pixel-level understanding. In order to obtain reliable 3D semantic labels that are absent in current image datasets, we build a large scale keypoint knowledge engine called KeypointNet, which contains 103,450 keypoints and 8,234 3D models from 16 object categories. Our method leverages the advantages in 3D vision and can explicitly reason about objects self-occlusion and visibility. We show that our method gives comparative and even superior results on standard semantic benchmarks.	[You, Yang; Li, Chengkun; Lou, Yujing; Cheng, Zhoujun; Li, Liangwei; Ma, Lizhuang; Wang, Weiming; Lu, Cewu] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China; [Lu, Cewu] Shanghai Jiao Tong Univ, Qing Yuan Res Inst, Shanghai Qizhi Res Inst, Shanghai 200240, Peoples R China; [Lu, Cewu] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China	Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University	Wang, WM; Lu, CW (corresponding author), Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.	qq456cvb@sjtu.edu.cn; sjtulck@sjtu.edu.cn; louyujing@sjtu.edu.cn; blankcheng@sjtu.edu.cn; liliangwei@sjtu.edu.cn; ma-lz@ks.sjtu.edu.cn; wangweiming@sjtu.edu.cn; lucewu@sjtu.edu.cn	You, Yang/GQQ-9174-2022; You, Yang/ADR-4244-2022	Lou, Yujing/0000-0001-6292-8953	National Key R&D Program of China [2017YFA0700800]; National Natural Science Foundation of China [61772332, 51675342, 51975350]; SHEITC [2018-RGZN-02046]; Shanghai Qi Zhi Institute	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); SHEITC; Shanghai Qi Zhi Institute	This work was supported in part by the National Key R&D Program of China under Grant 2017YFA0700800, National Natural Science Foundation of China under Grants 61772332, Grant 51675342, and Grant 51975350. This work was also supported by the SHEITC (2018-RGZN-02046) and Shanghai Qi Zhi Institute.	Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Andriluka M, 2018, PROC CVPR IEEE, P5167, DOI 10.1109/CVPR.2018.00542; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Angel X. Chang, 2015, Arxiv, DOI arXiv:1512.03012; [Anonymous], 2016, MSCOCO KEYPOINT CHAL; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491; Bueno M, 2016, INT ARCH PHOTOGRAMM, V41, P187, DOI 10.5194/isprsarchives-XLI-B3-187-2016; Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen Liang-Chieh, 2018, P EUROPEAN C COMPUTE, P801; Choy CB, 2016, ADV NEUR IN, V29; Cohen Taco S, 2018, ICLR; Dai JF, 2016, LECT NOTES COMPUT SC, V9910, P534, DOI 10.1007/978-3-319-46466-4_32; Dutagaci H, 2012, VISUAL COMPUT, V28, P901, DOI 10.1007/s00371-012-0746-4; Eslami SMA, 2018, SCIENCE, V360, P1204, DOI 10.1126/science.aar6170; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264; Gao L, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356488; Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720; Girshick R., 2014, PROC IEEE C COMPUT V; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gkioxari G, 2019, IEEE I CONF COMP VIS, P9784, DOI 10.1109/ICCV.2019.00988; Groueix T, 2018, LECT NOTES COMPUT SC, V11206, P235, DOI 10.1007/978-3-030-01216-8_15; Guler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762; Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550; Halimi O, 2019, PROC CVPR IEEE, P4365, DOI 10.1109/CVPR.2019.00450; Ham B, 2018, IEEE T PATTERN ANAL, V40, P1711, DOI 10.1109/TPAMI.2017.2724510; Ham B, 2016, PROC CVPR IEEE, P3475, DOI 10.1109/CVPR.2016.378; Han K, 2017, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2017.203; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Jean Ponce, 2019, Arxiv, DOI arXiv:1908.10543; JiajunWu Chengkai Zhang, 2016, ADV NEURAL INFORM PR, V29, DOI DOI 10.5555/3157096.3157106; Jiang Y, 2020, PROC CVPR IEEE, P1248, DOI 10.1109/CVPR42600.2020.00133; Juhong Min, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P346, DOI 10.1007/978-3-030-58555-6_21; Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411; Khoury M, 2017, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2017.26; Kim S, 2017, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2017.73; Kim VG, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461933; Kim VG, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185550; Kingma D.P, P 3 INT C LEARNING R; Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963; Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98; Kulkarni N, 2019, IEEE I CONF COMP VIS, P2202, DOI 10.1109/ICCV.2019.00229; Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244; Li S., 2020, PROC IEEECVF C COMPU, P10196; Li TM, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275109; Li X, 2019, PROC CVPR IEEE, P5530, DOI 10.1109/CVPR.2019.00568; Lin CH, 2018, AAAI CONF ARTIF INTE, P7114; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu SC, 2019, ADV NEUR IN, V32; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Min J, 2019, IEEE I CONF COMP VIS, P3394, DOI 10.1109/ICCV.2019.00349; Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100; Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356; Novatnack J, 2007, IEEE I CONF COMP VIS, P2001; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; Pan JY, 2019, IEEE I CONF COMP VIS, P9963, DOI 10.1109/ICCV.2019.01006; Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025; Pavlakos G., 2017, P IEEE INT C ROB AUT, V2017, P2011, DOI [10.1109/ICRA.2017.7989233, DOI 10.1109/ICRA.2017.7989233]; Porzi L, 2019, PROC CVPR IEEE, P8269, DOI 10.1109/CVPR.2019.00847; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Rematas K, 2020, PROC CVPR IEEE, P5416, DOI 10.1109/CVPR42600.2020.00546; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701; Rocco I, 2018, ADV NEUR IN, V31; Rocco I, 2018, PROC CVPR IEEE, P6917, DOI 10.1109/CVPR.2018.00723; Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12; Roufosse JM, 2019, IEEE I CONF COMP VIS, P1617, DOI 10.1109/ICCV.2019.00170; Schmidt T, 2017, IEEE ROBOT AUTOM LET, V2, P420, DOI 10.1109/LRA.2016.2634089; Seo PH, 2018, LECT NOTES COMPUT SC, V11208, P367, DOI 10.1007/978-3-030-01225-0_22; Sipiran I, 2011, VISUAL COMPUT, V27, P963, DOI 10.1007/s00371-011-0610-y; Sitzmann V, 2019, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2019.00254; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x; Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314; Sung M, 2018, ADV NEURAL INFORM PR, P485; Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230; Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wah C., 2011, TECH REP; Wang CY, 2020, INT CONF 3D VISION, P12, DOI 10.1109/3DV50981.2020.00011; Wang HY, 2018, LECT NOTES COMPUT SC, V11212, P3, DOI 10.1007/978-3-030-01237-3_1; Wen C, 2019, IEEE I CONF COMP VIS, P1042, DOI 10.1109/ICCV.2019.00113; Wu JJ, 2018, LECT NOTES COMPUT SC, V11215, P673, DOI 10.1007/978-3-030-01252-6_40; Wu JJ, 2017, ADV NEUR IN, V30; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Yao Y, 2020, PROC CVPR IEEE, P528, DOI 10.1109/CVPR42600.2020.00061; Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697; You Y., 2020, P IEEE CVF C COMP VI, P13647; You Y, 2020, AAAI CONF ARTIF INTE, V34, P12717; Yu Chen, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1425, DOI 10.1109/ICCVW.2009.5457443; Yujing Lou, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P496, DOI 10.1007/978-3-030-58542-6_30; Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20	99	0	0	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5780	5795		10.1109/TPAMI.2021.3072659	http://dx.doi.org/10.1109/TPAMI.2021.3072659			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33848241	Green Submitted			2022-12-18	WOS:000836666600089
J	Zhu, YJ; Li, C; Li, S; Shi, BX; Tai, YW				Zhu, Yongjie; Li, Chen; Li, Si; Shi, Boxin; Tai, Yu-Wing			Hybrid Face Reflectance, Illumination, and Shape From a Single Image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Faces; Lighting; Shape; Skin; Image color analysis; Estimation; Data models; Face modeling; intrinsic image decomposition; shading; reflectance; illumination	DECOMPOSITION; MODEL	We propose HyFRIS-Net to jointly estimate the hybrid reflectance and illumination models, as well as the refined face shape from a single unconstrained face image in a pre-defined texture space. The proposed hybrid reflectance and illumination representation ensure photometric face appearance modeling in both parametric and non-parametric spaces for efficient learning. While forcing the reflectance consistency constraint for the same person and face identity constraint for different persons, our approach recovers an occlusion-free face albedo with disambiguated color from the illumination color. Our network is trained in a self-evolving manner to achieve general applicability on real-world data. We conduct comprehensive qualitative and quantitative evaluations with state-of-the-art methods to demonstrate the advantages of HyFRIS-Net in modeling photo-realistic face albedo, illumination, and shape.	[Zhu, Yongjie; Li, Si] Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Beijing 100876, Peoples R China; [Li, Chen] Tencent, WeChat, Shenzhen 518064, Guangdong, Peoples R China; [Shi, Boxin] Peking Univ, Inst Artificial Intelligence, Dept Comp Sci & Technol, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China; [Tai, Yu-Wing] Kuaishou Technol, Beijing 100085, Peoples R China	Beijing University of Posts & Telecommunications; Tencent; Peking University	Li, S (corresponding author), Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Beijing 100876, Peoples R China.; Shi, BX (corresponding author), Peking Univ, Inst Artificial Intelligence, Dept Comp Sci & Technol, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.	zhuyongjie@bupt.edu.cn; chaselli@tencent.com; lisi@bupt.edu.cn; shiboxin@pku.edu.cn; yuwing@gmail.com			National Natural Science Foundation of China [61872012, 62088102]; Beijing Academy of Artificial Intelligence (BAAI)	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Academy of Artificial Intelligence (BAAI)	This work was supported in part by the National Natural Science Foundation of China under Grants 61872012 and 62088102 and in part by the Beijing Academy of Artificial Intelligence (BAAI).	Abhishek Dutta, 2016, Arxiv, DOI arXiv:1609.02368; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Tran AT, 2018, PROC CVPR IEEE, P3935, DOI 10.1109/CVPR.2018.00414; Bagdanov Andrew D, 2011, P 2011 JOINT ACM WOR, P79, DOI DOI 10.1145/2072572.2072597; Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; Barron JT, 2013, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2013.10; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116; Cao C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925873; Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020; Cao X, 2018, PROC CVPR IEEE, P4635, DOI 10.1109/CVPR.2018.00487; Chang HW, 2018, PROC CVPR IEEE, P40, DOI 10.1109/CVPR.2018.00012; Chen AP, 2019, IEEE I CONF COMP VIS, P9428, DOI 10.1109/ICCV.2019.00952; Chen QF, 2013, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2013.37; Dror RO, 2001, PROC CVPR IEEE, P164; Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33; Freeman William T, 2006, P C COMP VIS PATT RE; Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493; Georgoulis S, 2018, IEEE T PATTERN ANAL, V40, P1932, DOI 10.1109/TPAMI.2017.2742999; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; He K., 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90; Hu LW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130887; Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117; Jampour M, 2017, COMPUT VIS IMAGE UND, V161, P29, DOI 10.1016/j.cviu.2017.05.008; Jianbing Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3481, DOI 10.1109/CVPR.2011.5995507; Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63; Kim H, 2018, PROC CVPR IEEE, P4625, DOI 10.1109/CVPR.2018.00486; Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Laffont PY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366221; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Li C, 2017, PROC CVPR IEEE, P2780, DOI 10.1109/CVPR.2017.297; Li C, 2015, PROC CVPR IEEE, P4621, DOI 10.1109/CVPR.2015.7299093; Li C, 2014, LECT NOTES COMPUT SC, V8693, P218, DOI 10.1007/978-3-319-10602-1_15; Li YZ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1366, DOI 10.1109/ICCV.2003.1238649; Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317; Ronneberger O., 2015, P INT C MED IM COMP; Saito S, 2017, PROC CVPR IEEE, P2326, DOI 10.1109/CVPR.2017.250; Sato I, 2003, IEEE T PATTERN ANAL, V25, P290, DOI 10.1109/TPAMI.2003.1182093; Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175; Sengupta S, 2018, PROC CVPR IEEE, P6296, DOI 10.1109/CVPR.2018.00659; Shu ZX, 2017, PROC CVPR IEEE, P5444, DOI 10.1109/CVPR.2017.578; Tewari A, 2018, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2018.00270; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Trigeorgis G, 2017, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2017.44; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; Weyrich T, 2006, ACM T GRAPHIC, V25, P1013, DOI 10.1145/1141911.1141987; Yamaguchi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201364; Yang QX, 2010, LECT NOTES COMPUT SC, V6314, P87, DOI 10.1007/978-3-642-15561-1_7; Yi RJ, 2018, LECT NOTES COMPUT SC, V11213, P321, DOI 10.1007/978-3-030-01240-3_20; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23	53	0	0	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5002	5015		10.1109/TPAMI.2021.3080586	http://dx.doi.org/10.1109/TPAMI.2021.3080586			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33989152				2022-12-18	WOS:000836666600039
J	Gu, B; Dang, ZY; Huo, ZY; Deng, C; Huang, H				Gu, Bin; Dang, Zhiyuan; Huo, Zhouyuan; Deng, Cheng; Huang, Heng			Scaling Up Generalized Kernel Methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel; Training; Stochastic processes; Convergence; Computational modeling; Scalability; Optimization; Kernel method; asynchronous parallel computation; stochastic gradient descent; coordinate descent; random feature	CONVERGENCE	Kernel methods have achieved tremendous success in the past two decades. In the current big data era, data collection has grown tremendously. However, existing kernel methods are not scalable enough both at the training and predicting steps. To address this challenge, in this paper, we first introduce a general sparse kernel learning formulation based on the random feature approximation, where the loss functions are possibly non-convex. In order to reduce the scale of random features required in experiment, we also use that formulation based on the orthogonal random feature approximation. Then we propose a new asynchronous parallel doubly stochastic algorithm for large scale sparse kernel learning (AsyDSSKL). To the best our knowledge, AsyDSSKL is the first algorithm with the techniques of asynchronous parallel computation and doubly stochastic optimization. We also provide a comprehensive convergence guarantee to AsyDSSKL. Importantly, the experimental results on various large-scale real-world datasets show that, our AsyDSSKL method has the significant superiority on the computational efficiency at the training and predicting steps over the existing kernel methods.	[Gu, Bin] Mohamed Bin Zayed Univ Artificial Intelligence, Dept Machine Learning, Abu Dhabi, U Arab Emirates; [Gu, Bin; Huang, Heng] JD Finance Amer Corp, Mountain View, CA 94043 USA; [Dang, Zhiyuan; Deng, Cheng] Xidian Univ, Sch Elect Engn, Xian 710126, Shaanxi, Peoples R China; [Dang, Zhiyuan] JD Tech, Beijing 101111, Peoples R China; [Huo, Zhouyuan; Huang, Heng] Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15260 USA	Mohamed Bin Zayed University of Artificial Intelligence; Xidian University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Gu, B (corresponding author), Mohamed Bin Zayed Univ Artificial Intelligence, Dept Machine Learning, Abu Dhabi, U Arab Emirates.; Deng, C (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710126, Shaanxi, Peoples R China.; Huang, H (corresponding author), Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15260 USA.	jsgubin@gmail.com; zydang@stu.xidian.edu.cn; zhouyuan.huo@pitt.edu; chdeng@mail.xidian.edu.cn; heng.huang@pitt.edu			National Natural Science Foundation of China [62076138]; Natural Science Foundation [BK20161534]; six talent peaks project [XYDXX-042]; 333 Project in Jiangsu Province [BRA2017455]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation(National Natural Science Foundation of China (NSFC)); six talent peaks project; 333 Project in Jiangsu Province	The work of Bin Gu was supported in part by the National Natural Science Foundation of China under Grant 62076138, the Natural Science Foundation under Grant BK20161534, six talent peaks project (No. XYDXX-042) and the 333 Project (No. BRA2017455) in Jiangsu Province.	Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Chandra R., 2001, PARALLEL PROGRAMMING; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI [10.1145/1961189.1961199, DOI 10.1145/1961189.1961199]; Dai B, 2014, ADV NEUR IN, V27; Feng YL, 2015, J MACH LEARN RES, V16, P993; Gu B, 2018, AAAI CONF ARTIF INTE, P3085; Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991; Li F., 2005, ADV NEURAL INF PROCE, V18, P779; Lin Y, 2004, STAT PROBABIL LETT, V68, P73, DOI 10.1016/j.spl.2004.03.002; Liu J, 2015, SIAM J OPTIMIZ, V25, P351, DOI 10.1137/140961134; Mania H, 2017, SIAM J OPTIMIZ, V27, P2202, DOI 10.1137/16M1057000; Rahimi A, 2007, PROC 20 INT C NEURAL, P1177, DOI DOI 10.5555/2981562.2981710; Razaviyayn M., 2014, P NEUR INF PROC NIPS, P1440; Sanderson C., 2016, J OPEN SOURCE SOFTWA, V1, P26, DOI [10.21105/joss.00026, DOI 10.21105/JOSS.00026]; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416, DOI 10.1007/3-540-44581-1_27; Schu┬lkopf B., 2004, KERNEL METHODS COMPU; SHALEV- SHWARTZ S., 2007, P 24 INT C MACH LEAR, P807, DOI [DOI 10.1145/1273496.1273598, 10.1145/1273496.1273598]; Shamir O., 2013, P INT C MACH LEARN A, P71; Swell M, 2009, KERNEL METHODS; Takahashi N, 2006, IEEE T NEURAL NETWOR, V17, P1362, DOI 10.1109/TNN.2006.880584; Tseng P, 2009, MATH PROGRAM, V117, P387, DOI 10.1007/s10107-007-0170-0; Vapnik V.N, 1998, STAT LEARNING THEORY; Xie B., 2015, ADV NEURAL INFORM PR, P2341; Yen I.E.-H., 2014, ADV NEURAL INF PROCE, P2456; You Y., 2016, ADV NEURAL INFORM PR, P4682; You Y, 2015, J PARALLEL DISTR COM, V76, P16, DOI 10.1016/j.jpdc.2014.09.005; Yu Felix X, 2016, ADV NEURAL INFORM PR, V29, P1975; Zhang T., 2004, P 21 INT C MACH LEAR, P116, DOI 10.1145/1015330.1015332; Zhao Hai- xiang, 2011, 11 INT C ART INT APP; Zhu J, 2005, J COMPUT GRAPH STAT, V14, P185, DOI 10.1198/106186005X25619; Zhu J, 2004, ADV NEUR IN, V16, P49	36	0	0	5	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3767	3778		10.1109/TPAMI.2021.3059702	http://dx.doi.org/10.1109/TPAMI.2021.3059702			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33591910				2022-12-18	WOS:000805820500031
J	Kutbi, M; Peng, KC; Wu, ZY				Kutbi, Mohammed; Peng, Kuan-Chuan; Wu, Ziyan			Zero-Shot Deep Domain Adaptation With Common Representation Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Measurement; Training data; Training; Sensor fusion; Semantics; Faces; Zero-shot; domain adaptation; sensor fusion; open-set; metric learning		Domain Adaptation aims at adapting the knowledge learned from a domain (source-domain) to another (target-domain). Existing approaches typically require a portion of task-relevant target-domain data a priori. We propose an approach, zero-shot deep domain adaptation (ZDDA), which uses paired dual-domain task-irrelevant data to eliminate the need for task-relevant target-domain training data. ZDDA learns to generate common representations for source and target domains data. Then, either domain representation is used later to train a system that works on both domains or having the ability to eliminate the need to either domain in sensor fusion settings. Two variants of ZDDA have been developed: ZDDA for classification task (ZDDA-C) and ZDDA for metric learning task (ZDDA-ML). Another limitation in Existing approaches is that most of them are designed for the closed-set classification task, i.e., the sets of classes in both the source and target domains are "known." However, ZDDA-C is also applicable to the open-set classification task where not all classes are "known" during training. Moreover, the effectiveness of ZDDA-ML shows ZDDA's applicability is not limited to classification tasks. ZDDA-C and ZDDA-ML are tested on classification and metric-learning tasks, respectively. Under most experimental conditions, ZDDA outperforms the baseline without using task-relevant target-domain-training data.	[Kutbi, Mohammed] Saudi Elect Univ, Jeddah 23442, Saudi Arabia; [Peng, Kuan-Chuan] Mitsubishi Elect Res Labs MERL, Cambridge, MA 02139 USA; [Wu, Ziyan] United Imaging Intelligence UII Amer Inc, Cambridge, MA 02140 USA	Saudi Electronic University	Kutbi, M (corresponding author), Saudi Elect Univ, Jeddah 23442, Saudi Arabia.	m.kutbi@seu.edu.sa; kpeng@merl.com; wuzy.buaa@gmail.com	Kutbi, Mohammed/HGB-1707-2022	Kutbi, Mohammed/0000-0002-3815-8028				Aljundi R, 2016, LECT NOTES COMPUT SC, V9915, P508, DOI 10.1007/978-3-319-49409-8_43; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; BAIR/BVLC, 2016, LEN ARCH CAFF TUT; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Busto PP, 2017, IEEE I CONF COMP VIS, P754, DOI 10.1109/ICCV.2017.88; Carl G, 2018, TECHNOL CANCER RES T, V17, DOI 10.1177/1533033818806002; Chen C., 2019, PROC CVPR IEEE, P10542, DOI DOI 10.1109/CVPR.2019.01079; Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145; Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Ding ZM, 2015, IEEE T IMAGE PROCESS, V24, P4322, DOI 10.1109/TIP.2015.2462023; Fu ZY, 2015, PROC CVPR IEEE, P2635, DOI 10.1109/CVPR.2015.7298879; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Gebru T, 2017, IEEE I CONF COMP VIS, P1358, DOI 10.1109/ICCV.2017.151; Georgakis G, 2016, INT CONF 3D VISION, P426, DOI 10.1109/3DV.2016.52; Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36; Gretton A, 2009, NEURAL INF PROCESS S, P131; Grother PJ, 1995, HANDPRINTED FORMS CH, P10; Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309; Haeusser P, 2017, IEEE I CONF COMP VIS, P2784, DOI 10.1109/ICCV.2017.301; Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7; Hoffman J, 2016, PROC CVPR IEEE, P826, DOI 10.1109/CVPR.2016.96; Hoffman J, 2014, PROC CVPR IEEE, P867, DOI 10.1109/CVPR.2014.116; Hou JY, 2019, IEEE INT CONF COMP V, P3257, DOI 10.1109/ICCVW.2019.00407; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Iandola F.N., 2016, ARXIV PREPRINT ARXIV; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kang GL, 2018, LECT NOTES COMPUT SC, V11215, P420, DOI 10.1007/978-3-030-01252-6_25; Koniusz P, 2017, PROC CVPR IEEE, P7139, DOI 10.1109/CVPR.2017.755; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3; Leong B, 2019, J APPL CLIN MED PHYS, V20, P149, DOI 10.1002/acm2.12779; Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591; Mancini M, 2019, PROC CVPR IEEE, P6561, DOI 10.1109/CVPR.2019.00673; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; Motiian S, 2017, IEEE I CONF COMP VIS, P5716, DOI 10.1109/ICCV.2017.609; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Paszke A., 2017, 31 C NEUR INF PROC S; Russo P, 2018, PROC CVPR IEEE, P8099, DOI 10.1109/CVPR.2018.00845; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K, 2018, LECT NOTES COMPUT SC, V11209, P156, DOI 10.1007/978-3-030-01228-1_10; Saito K, 2017, PR MACH LEARN RES, V70; Sener Ozan, 2016, ADV NEURAL INFORM PR, P2; Sohn K, 2017, IEEE I CONF COMP VIS, P5917, DOI 10.1109/ICCV.2017.630; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; Sun Min, 2017, P IEEE INT C COMP VI, P521; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Wang WR, 2015, PR MACH LEARN RES, V37, P1083; Wang YF, 2017, IEEE INT CONF COMP V, P2651, DOI 10.1109/ICCVW.2017.315; Wu CP, 2017, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2017.88; Wulfmeier M, 2017, IEEE INT C INT ROBOT, P1551; Xiao H., 2017, ARXIV 170205374; Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107; Yang XT, 2017, PROC CVPR IEEE, P5066, DOI 10.1109/CVPR.2017.538; Yang Y., 2015, P 1 INT WORKSH DIFF; Yang YX, 2016, PROC CVPR IEEE, P5071, DOI 10.1109/CVPR.2016.548; Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16; Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547; Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223	67	0	0	10	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3909	3924		10.1109/TPAMI.2021.3061204	http://dx.doi.org/10.1109/TPAMI.2021.3061204			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33621167				2022-12-18	WOS:000805820500041
J	Li, YL; Liu, XP; Wu, XQ; Huang, XJ; Xu, L; Lu, CW				Li, Yong-Lu; Liu, Xinpeng; Wu, Xiaoqian; Huang, Xijie; Xu, Liang; Lu, Cewu			Transferable Interactiveness Knowledge for Human-Object Interaction Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Visualization; Image edge detection; Biological system modeling; Task analysis; Semantics; Knowledge engineering; Human-object interaction; interactiveness; transfer learning		Human-object interaction (HOI) Detection is an important problem to understand how humans interact with objects. In this paper, we explore Interactiveness Knowledge which indicates whether human and object interact with each other or not. We found that interactiveness knowledge can be learned across HOI datasets and alleviate the gap between diverse HOI category settings. Our core idea is to exploit an Interactiveness Network to learn the general interactiveness knowledge from multiple HOI datasets and perform Non-Interaction Suppression before HOI classification in inference. On account of the generalization of interactiveness, interactiveness network is a transferable knowledge learner and can be cooperated with any HOI detection models to achieve desirable results. We utilize the human instance and body part features together to learn the interactiveness in hierarchical paradigm, i.e., instance-level and body part-level interactivenesses. Thereafter, a consistency task is proposed to guide the learning and extract deeper interactive visual clues. We extensively evaluate the proposed method on HICO-DET, V-COCO, and a newly constructed HAKE-HOI dataset. With the learned interactiveness, our method outperforms state-of-the-art HOI detection methods, verifying its efficacy and flexibility. Code is available at https://github.com/DirtyHarryLYL/Transferable-Interactiveness-Network.	[Li, Yong-Lu; Liu, Xinpeng; Wu, Xiaoqian; Huang, Xijie; Xu, Liang] Shanghai Jiao Tong Univ, Dept Elect & Comp Engn, Shanghai 200240, Peoples R China; [Lu, Cewu] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Qing Yuan Res Inst, Shanghai 200240, Peoples R China; [Lu, Cewu] Shanghai Qi Zhi Inst, Shanghai 200240, Peoples R China	Shanghai Jiao Tong University; Shanghai Jiao Tong University	Lu, CW (corresponding author), Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Qing Yuan Res Inst, Shanghai 200240, Peoples R China.	yonglu_li@sjtu.edu.cn; xinpengliu0907@gmail.com; otaku_huang@sjtu.edu.cn; enlighten@sjtu.edu.cn; liangxu@sjtu.edu.cn; lucewu@sjtu.edu.cn	Liu, Xinpeng/AAB-7194-2022	Liu, Xinpeng/0000-0002-7525-3243	National Key R&D Program of China [2017YFA0700800]; National Natural Science Foundation of China [61772332]; Shanghai Qi Zhi Institute, SHEITC [2018-RGZN-02046]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shanghai Qi Zhi Institute, SHEITC	This work was supported in part by the National Key R&D Program of China, No. 2017YFA0700800, National Natural Science Foundation of China under Grants 61772332 and Shanghai Qi Zhi Institute, SHEITC (2018-RGZN-02046).	[Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Argall BD, 2009, ROBOT AUTON SYST, V57, P469, DOI 10.1016/j.robot.2008.10.024; Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698; Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048; Chao YW, 2015, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2015.122; Chen C.-Y, 2014, PROC ASIAN C COMPUT, P351; Delaitre V., 2010, BMVC, DOI DOI 10.5244/C.24.97; Fang HS, 2018, LECT NOTES COMPUT SC, V11214, P52, DOI 10.1007/978-3-030-01249-6_4; Fang HS, 2018, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2018.00015; Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256; Gao C., 2018, PROC BRIT MACH VIS C; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872; Gkioxari G, 2015, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2015.284; Gupta S., 2015, ARXIV PREPRINT ARXIV; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Ikizler N, 2008, P INT C PATT REC, P1, DOI [DOI 10.1109/ICPR.2008.4761663, 10.1109/icpr.2008.4761663]; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Li XL, 2018, SPRINGERBRIEF MATH, P1, DOI 10.1007/978-3-319-89617-5_1; Li YL, 2020, PROC CVPR IEEE, P379, DOI 10.1109/CVPR42600.2020.00046; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Lu CW, 2018, PROC CVPR IEEE, P6955, DOI 10.1109/CVPR.2018.00727; Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51; Mallya A, 2016, LECT NOTES COMPUT SC, V9905, P414, DOI 10.1007/978-3-319-46448-0_25; Maron O, 1998, ADV NEUR IN, V10, P570; Peyre J, 2019, IEEE I CONF COMP VIS, P1981, DOI 10.1109/ICCV.2019.00207; Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; Shen LY, 2018, IEEE WINT CONF APPL, P1568, DOI 10.1109/WACV.2018.00181; Wang Y., 2006, CVPR, V2, P1654, DOI [10.1109/CVPR.2006.321, DOI 10.1109/CVPR.2006.321]; Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330; Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41; Yang WL, 2010, PROC CVPR IEEE, P2030, DOI 10.1109/CVPR.2010.5539879; Yatskar M, 2016, PROC CVPR IEEE, P5534, DOI 10.1109/CVPR.2016.597; Yin GJ, 2018, LECT NOTES COMPUT SC, V11207, P330, DOI 10.1007/978-3-030-01219-9_20; Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331	39	0	0	11	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3870	3882		10.1109/TPAMI.2021.3054048	http://dx.doi.org/10.1109/TPAMI.2021.3054048			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33493110	Green Submitted			2022-12-18	WOS:000805820500038
J	Zhang, Q; Wang, Q; Li, HD; Yu, JY				Zhang, Qi; Wang, Qing; Li, Hongdong; Yu, Jingyi			Ray-Space Epipolar Geometry for Light Field Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Ray-space epipolar geometry; ray-space fundamental matrix; light field camera; Plucker parameterization	RECONSTRUCTION	Light field essentially represents rays in space. The epipolar geometry between two light fields is an important relationship that captures ray-ray correspondences and relative configuration of two views. Unfortunately, so far little work has been done in deriving a formal epipolar geometry model that is specifically tailored for light field cameras. This is primarily due to the high-dimensional nature of the ray sampling process with a light field camera. This paper fills in this gap by developing a novel ray-space epipolar geometry which intrinsically encapsulates the complete projective relationship between two light fields, while the generalized epipolar geometry which describes relationship of normalized light fields is the specialization of the proposed model to calibrated cameras. With Plucker parameterization, we propose the ray-space projection model involving a 6 x 6 ray-space intrinsic matrix for ray sampling of light field camera. Ray-space fundamental matrix and its properties are then derived to constrain ray-ray correspondences for general and special motions. Finally, based on ray-space epipolar geometry, we present two novel algorithms, one for fundamental matrix estimation, and the other for calibration. Experiments on synthetic and real data have validated the effectiveness of ray-space epipolar geometry in solving 3D computer vision tasks with light field cameras.	[Zhang, Qi; Wang, Qing] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China; [Li, Hongdong] Australian Natl Univ, ANU, Canberra, ACT 0200, Australia; [Li, Hongdong] Australian Natl Univ, ACRV, Canberra, ACT 0200, Australia; [Yu, Jingyi] ShanghaiTech Univ, Shanghai 200031, Peoples R China	Northwestern Polytechnical University; Australian National University; Australian National University; ShanghaiTech University	Wang, Q (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.	nwpuqzhang@gmail.com; qwang@nwpu.edu.cn; hongdong.li@anu.edu.au; jingyi.udel@gmail.com			NSFC [61531014, 61801396, 62031023]; Innovation Foundation for Doctor Dissertation of Northwestern Polytechnical University [CX201919]; China Scholarship Council (CSC)	NSFC(National Natural Science Foundation of China (NSFC)); Innovation Foundation for Doctor Dissertation of Northwestern Polytechnical University; China Scholarship Council (CSC)(China Scholarship Council)	The work was supported by the NSFC under Grants 61531014, 61801396, and 62031023. The work of Qi Zhang was also supported by Innovation Foundation for Doctor Dissertation of Northwestern Polytechnical University under CX201919 and China Scholarship Council (CSC). The authors would also like to thank anonymous reviewers for their valuable feedback.	[Anonymous], 2006, DIGITAL LIGHT FIELD, P1; Barath D, 2018, PROC CVPR IEEE, P235, DOI 10.1109/CVPR.2018.00032; Birklbauer C, 2014, COMPUT GRAPH FORUM, V33, P43, DOI 10.1111/cgf.12289; Bok Y, 2017, IEEE T PATTERN ANAL, V39, P287, DOI 10.1109/TPAMI.2016.2541145; Dansereau DG, 2019, PROC CVPR IEEE, P8034, DOI 10.1109/CVPR.2019.00823; Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137; Dansereau DG, 2011, IEEE INT C INT ROBOT, P4455, DOI 10.1109/IROS.2011.6048841; Dong FC, 2013, INT J ROBOT RES, V32, P206, DOI 10.1177/0278364912469420; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611; Guo XQ, 2016, IEEE T VIS COMPUT GR, V22, P1852, DOI 10.1109/TVCG.2015.2476805; Hahne C, 2018, INT J COMPUT VISION, V126, P21, DOI 10.1007/s11263-017-1036-4; Hartley R., 2003, MULTIPLE VIEW GEOMET; HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005; Hartley RI, 1997, INT J COMPUT VISION, V22, P5, DOI 10.1023/A:1007957826135; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hartley R, 2012, IEEE T PATTERN ANAL, V34, P2303, DOI 10.1109/TPAMI.2012.43; Hodge W. V. D., 1994, METHODS ALGEBRAIC GE, V2; Johannsen O, 2015, IEEE I CONF COMP VIS, P720, DOI 10.1109/ICCV.2015.89; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Li HD, 2006, LECT NOTES COMPUT SC, V3954, P200; Li HF, 2008, CURR MED RES OPIN, V24, P1, DOI [10.1185/030079908X253933, 10.1088/0256-307X/24/3/072]; Li Y., 2019, PROC SPIE OPTOELECTR, VVI; LONGUETHIGGINS HC, 1986, PROC R SOC SER B-BIO, V227, P399, DOI 10.1098/rspb.1986.0030; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lytro, 2011, LYTR RED PHOT LIGHT; Madsen K., 2004, INFORM MATH MODELLIN; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Nousias S, 2019, PROC CVPR IEEE, P3287, DOI 10.1109/CVPR.2019.00341; Nousias S, 2017, IEEE I CONF COMP VIS, P957, DOI 10.1109/ICCV.2017.109; Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520; Pottmann H., 2009, COMPUTATIONAL LINE G; Raytrix, 2013, 3D LIGHT FIELD CAMER; Ren Z, 2017, IEEE IMAGE PROC, P1157; Scaramuzza D, 2011, INT J COMPUT VISION, V95, P74, DOI 10.1007/s11263-011-0441-3; Sturm P, 2005, PROC CVPR IEEE, P206; Wang Q, 2018, PROC ASIAN C COMPUT, P50; Yan Zhou, 2015, 2015 23rd International Conference on Geoinformatics. Proceedings, P1, DOI 10.1109/GEOINFORMATICS.2015.7378670; Zhang Q., 2019, PROC SPIE OPTOELECTR, VVI; Zhang Q., 2018, AS C COMP VIS ACCV, P18; Zhang Q, 2019, PROC CVPR IEEE, P10113, DOI 10.1109/CVPR.2019.01036; Zhang Q, 2019, IEEE T PATTERN ANAL, V41, P2539, DOI 10.1109/TPAMI.2018.2864617; Zhang YL, 2017, IEEE I CONF COMP VIS, P4641, DOI 10.1109/ICCV.2017.496; Zhang YL, 2017, IEEE INT CONF COMPUT, P67	44	0	0	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3705	3718		10.1109/TPAMI.2020.3025949	http://dx.doi.org/10.1109/TPAMI.2020.3025949			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	32960761				2022-12-18	WOS:000805820500027
J	Gilet, C; Barbosa, S; Fillatre, L				Gilet, Cyprien; Barbosa, Susana; Fillatre, Lionel			Discrete Box-Constrained Minimax Classifier for Uncertain and Imbalanced Class Proportions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Minimax classifier; Gamma-minimax classifier; imbalanced datasets; uncertain class proportions; prior probability shift; discrete bayes classifier; histogram rule; Bayesian robustness	DISCRETIZATION; ALGORITHMS	This paper aims to build a supervised classifier for dealing with imbalanced datasets, uncertain class proportions, dependencies between features, the presence of both numeric and categorical features, and arbitrary loss functions. The Bayes classifier suffers when prior probability shifts occur between the training and testing sets. A solution is to look for an equalizer decision rule whose class-conditional risks are equal. Such a classifier corresponds to a minimax classifier when it maximizes the Bayes risk. We develop a novel box-constrained minimax classifier which takes into account some constraints on the priors to control the risk maximization. We analyze the empirical Bayes risk with respect to the box-constrained priors for discrete inputs. We show that this risk is a concave non-differentiable multivariate piecewise affine function. A projected subgradient algorithm is derived to maximize this empirical Bayes risk over the box-constrained simplex. Its convergence is established and its speed is bounded. The optimization algorithm is scalable when the number of classes is large. The robustness of our classifier is studied on diverse databases. Our classifier, jointly applied with a clustering algorithm to process mixed attributes, tends to equalize the class-conditional risks while being not too pessimistic.	[Gilet, Cyprien; Fillatre, Lionel] Univ Cote dAzur, CNRS, I3S Lab, 2000 Route Lucioles, F-06900 Sophia Antipolis, France; [Barbosa, Susana] Univ Cote dAzur, CNRS, IPMC Lab, 660 Route Lucioles, F-06560 Valbonne, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite Cote d'Azur; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite Cote d'Azur	Gilet, C (corresponding author), Univ Cote dAzur, CNRS, I3S Lab, 2000 Route Lucioles, F-06900 Sophia Antipolis, France.	gilet@i3s.unice.fr; sudocarmo@gmail.com; lionel.fillatre@i3s.unice.fr			Provence-Alpes-Cote d'Azur region	Provence-Alpes-Cote d'Azur region(Region Provence-Alpes-Cote d'Azur)	The authors would like to thank Marie Guyomard and Nicolas Glaichenhaus for their contributions and their help in this project, and the Provence-Alpes-Cote d'Azur region for its financial support.	AB S. C, 2016, APS FAILURE SCANIA T; Alaiz-Rodriguez R, 2007, J MACH LEARN RES, V8, P103; Alber YI, 1998, MATH PROGRAM, V81, P23, DOI 10.1007/BF01584842; [Anonymous], 2015, SATELLITE DATABASE; [Anonymous], 2020, DISCRETE BOX CONSTRA; B. University the National Heart Lung and B. Institute, 1948, FRAM HEART STUD; Barranquero J, 2013, PATTERN RECOGN, V46, P472, DOI 10.1016/j.patcog.2012.07.022; Berger J.O., 1985, STAT DECISION THEORY, P74; Bolton RJ, 2002, STAT SCI, V17, P235; Borovkov A., 1998, MATH STAT; Boyd S., 2003, LECT NOTES SUBGRADIE; Braga-Neto U, 2005, PATTERN RECOGN, V38, P1799, DOI 10.1016/j.patcog.2005.02.013; Cannon A, 2002, LAUR022951; Condat L, 2016, MATH PROGRAM, V158, P575, DOI 10.1007/s10107-015-0946-6; Dalton L. A., 2020, OPTIMAL BAYESIAN CLA; Dalton LA, 2015, EURASIP J BIOINFORM, DOI 10.1186/s13637-015-0028-3; Dalton LA, 2011, IEEE T SIGNAL PROCES, V59, P115, DOI 10.1109/TSP.2010.2084572; Davenport MA, 2010, IEEE T PATTERN ANAL, V32, P1888, DOI 10.1109/TPAMI.2010.29; Dong Q, 2019, IEEE T PATTERN ANAL, V41, P1367, DOI 10.1109/TPAMI.2018.2832629; Dougherty J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P194; Drummond C., 2003, WORKSH LEARN IMB DAT, V11, P1; Duda R.O., 2017, PATTERN CLASSIFICATI; Elkan C., 2001, INT JOINT C ART INT, P973; Feder M, 2002, IEEE T INFORM THEORY, V48, P1504, DOI 10.1109/TIT.2002.1003837; Ferguson T. S., 1967, MATH STAT DECISION T; Fillatre L, 2017, SIGNAL PROCESS, V141, P322, DOI 10.1016/j.sigpro.2017.06.020; Fillatre L, 2012, IEEE T SIGNAL PROCES, V60, P3357, DOI 10.1109/TSP.2012.2194286; Forman G, 2005, LECT NOTES ARTIF INT, V3720, P564, DOI 10.1007/11564096_55; Forman G, 2008, DATA MIN KNOWL DISC, V17, P164, DOI 10.1007/s10618-008-0097-y; Garcia S, 2015, INTEL SYST REF LIBR, V72, P1, DOI 10.1007/978-3-319-10247-4; Gentile C, 2014, PR MACH LEARN RES, V32, P757; Gilet C., 2019, PROC WORLD C CONDITI, DOI [10.1007/978-981-15-9199-0, DOI 10.1007/978-981-15-9199-0]; Gilet C., 2019, PROC MACH LEARN HLTH, P6680; Gonzalez P, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3117807; Guerrero-Curieses A, 2004, IEEE T SYST MAN CY C, V34, P383, DOI 10.1109/TSMCC.2004.833284; Hastie T, 2009, ELEMENTS STAT LEARNI, V2, DOI [10.1007/b94608, DOI 10.1007/B94608]; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Huang KZ, 2006, IEEE T SYST MAN CY B, V36, P913, DOI 10.1109/TSMCB.2006.870610; Huang KZ, 2004, J MACH LEARN RES, V5, P1253; Japkowicz N., 2002, Intelligent Data Analysis, V6, P429; Johannes R. S., 1988, J HOPKINS APL TECH D, V10, P262; Kar P, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1625, DOI 10.1145/2939672.2939832; Kawakubo H, 2016, IEICE T INF SYST, VE99D, P176, DOI 10.1587/transinf.2015EDP7212; KERBER R, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P123; Krizhevsky A., 2009, LEARNING MULTIPLE L; Kurgan LA, 2004, IEEE T KNOWL DATA EN, V16, P145, DOI 10.1109/TKDE.2004.1269594; Li Shuai, 2016, ARXIV160500596; Liu H, 1995, PROC INT C TOOLS ART, P388, DOI 10.1109/TAI.1995.479783; Liu P, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL IV, PROCEEDINGS, P380, DOI 10.1109/AICI.2009.385; Liu W, 2011, LECT NOTES ARTIF INT, V6635, P345, DOI 10.1007/978-3-642-20847-8_29; Lustgarten Jonathan L, 2008, AMIA Annu Symp Proc, P445; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; McCullagh P., 1990, GEN LINEAR MODELS, V2nd; Mena L., 2006, P 19 INT FLOR ART IN, P574; Milli L, 2013, IEEE DATA MINING, P528, DOI 10.1109/ICDM.2013.122; Moreno-Torres JG, 2012, PATTERN RECOGN, V45, P521, DOI 10.1016/j.patcog.2011.06.019; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Perez G., 2019, MATH PROGRAM; Pires B.A., 2013, P 30 INT C MACH LEAR, V28, P1391; Poor, 2013, INTRO SIGNAL DETECTI; Quinonero-Candela J, 2009, NEURAL INF PROCESS S, pXI; Rao C. R, 1973, LINEAR STAT INFERENC; Rastgoo Mojdeh, 2016, BIOSTEC 2016. 9th International Joint Conference on Biomedical Engineering Systems and Technologies. Proceedings: Bioimaging, P32; REED WJ, 1974, PAC J MATH, V54, P183, DOI 10.2140/pjm.1974.54.183; Rutkowski KE, 2017, SIAM J OPTIMIZ, V27, P1758, DOI 10.1137/16M1087540; SCHLESINGER M, 2002, 10 LECT STAT STRUCTU; Shirabad J. Sayyad, 2005, PROMISE REPOSITORY S; Tan MX, 2019, PR MACH LEARN RES, V97; TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306, DOI 10.1109/TPAMI.1979.4766926; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Warwick J. N., 1994, 48 DEP PRIM IND FISH; YABLON M, 1982, IEEE T PATTERN ANAL, V4, P35, DOI 10.1109/TPAMI.1982.4767192; Yang Y, 2009, MACH LEARN, V74, P39, DOI 10.1007/s10994-008-5083-5	75	0	0	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					2923	2937		10.1109/TPAMI.2020.3046439	http://dx.doi.org/10.1109/TPAMI.2020.3046439			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33351747	Green Submitted			2022-12-18	WOS:000803117500012
J	Li, J; Xiao, MQ; Fang, C; Dai, Y; Xu, C; Lin, ZC				Li, Jia; Xiao, Mingqing; Fang, Cong; Dai, Yue; Xu, Chao; Lin, Zhouchen			Training Neural Networks by Lifted Proximal Operator Machines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Artificial neural networks; Linear programming; Convergence; Tuning; Standards; Patents; Neural networks; lifted proximal operator machines; block multi-convex; block coordinate descent; parallel implementation		We present the lifted proximal operator machine (LPOM) to train fully-connected feed-forward neural networks. LPOM represents the activation function as an equivalent proximal operator and adds the proximal operators to the objective function of a network as penalties. LPOM is block multi-convex in all layer-wise weights and activations. This allows us to develop a new block coordinate descent (BCD) method with convergence guarantee to solve it. Due to the novel formulation and solving method, LPOM only uses the activation function itself and does not require any gradient steps. Thus it avoids the gradient vanishing or exploding issues, which are often blamed in gradient-based methods. Also, it can handle various non-decreasing Lipschitz continuous activation functions. Additionally, LPOM is almost as memory-efficient as stochastic gradient descent and its parameter tuning is relatively easy. We further implement and analyze the parallel solution of LPOM. We first propose a general asynchronous-parallel BCD method with convergence guarantee. Then we use it to solve LPOM, resulting in asynchronous-parallel LPOM. For faster speed, we develop the synchronous-parallel LPOM. We validate the advantages of LPOM on various network architectures and datasets. We also apply synchronous-parallel LPOM to autoencoder training and demonstrate its fast convergence and superior performance.	[Li, Jia; Lin, Zhouchen] Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China; [Li, Jia] Beijing Normal Univ, Sch Artificial Intelligence, Beijing 100875, Peoples R China; [Xiao, Mingqing; Xu, Chao] Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machinecept MOE, Beijing 100871, Peoples R China; [Fang, Cong] Univ Penn, Philadelphia, PA 19104 USA; [Dai, Yue] Beihang Univ, Coll Software, Beijing 100083, Peoples R China; [Lin, Zhouchen] Pazhou Lab, Guangzhou 510330, Peoples R China	Peking University; Beijing Normal University; Peking University; University of Pennsylvania; Beihang University; Pazhou Lab	Lin, ZC (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.; Lin, ZC (corresponding author), Pazhou Lab, Guangzhou 510330, Peoples R China.	jiali.gm@gmail.com; mingqing_xiao@pku.edu.cn; fangcong@pku.edu.cn; daiyue@buaa.edu.cn; xuchao@cis.pku.edu.cn; zlin@pku.edu.cn		Dai, Yue/0000-0001-9286-3185; Xiao, Mingqing/0000-0001-6191-7726	NSF of China [61802269, 61972132, 61625301, 61731018, 61876007]; Major Scientific Research Project of Zhejiang Lab [2019KB0AC01, 2019KB0AB02]; Beijing Academy of Artificial Intelligence, and Qualcomm; Fundamental Research Funds for the Central Universities	NSF of China(National Natural Science Foundation of China (NSFC)); Major Scientific Research Project of Zhejiang Lab; Beijing Academy of Artificial Intelligence, and Qualcomm; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	The work of Z. Lin was supported by the NSF of China (Grants 61625301 and 61731018), Major Scientific Research Project of Zhejiang Lab (Grants 2019KB0AC01 and 2019KB0AB02), Beijing Academy of Artificial Intelligence, and Qualcomm. The work of J. Li was supported by the NSF of China (Grants 61802269 and 61972132) and the Fundamental Research Funds for the Central Universities. The work of C. Xu was supported by theNSF of China (Grant 61876007).	Allen-Zhu Z, 2019, PR MACH LEARN RES, V97; Askari A., 2018, ARXIV180501532; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bertsekas D. P., 1997, PARALLEL DISTRIBUTED; Carreira-Perpinan MA, 2014, JMLR WORKSH CONF PRO, V33, P10; Chrabaszcz Patryk, 2017, ARXIV170708819; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Du SS, 2019, PR MACH LEARN RES, V97; Duchi J, 2011, J MACH LEARN RES, V12, P2121; Feng J, 2018, AAAI CONF ARTIF INTE, P2967; Ge R., 2015, P C LEARNING THEORY, P797, DOI DOI 10.1109/ICMTMA.2015.197; Glorot X., 2010, PROC MACH LEARN RES, P249; Golub G. H., 2012, J HOPKINS STUDIES MA; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Gu F, 2020, PR MACH LEARN RES, V108, P3362; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hubara I, 2016, ADV NEUR IN, V29; Ioffe S., 2015, PROC INT C MACH LEAR, P448; Kingma Diederik P., 2015, 3 INT C LEARN REPRES, V3; Kreyszig E., 1978, INTRO FUNCTIONAL ANA, V1; Krizhevsky A., 2009, LEARNING MULTIPLE L; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar S., 2019, ARXIV PREPRINT ARXIV; Le Q.V., 2011, P ICML JAN, P265; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li J, 2019, AAAI CONF ARTIF INTE, P4181; Lian X., 2016, ADV NEURAL INFORM PR, P3054; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Nesterov Y., 2004, APPL OPTIM; Netzer Y., 2011, NIPS WORKSH DEEP LEA, V2, P5; Parikh N., 2014, FDN TRENDS OPTIM, V1, P127, DOI DOI 10.1561/2400000003; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Sun T., 2017, ADV NEURAL INFORM PR, P6182; Sutskever I., 2013, P 30 INT C MACH LEAR, P1139, DOI DOI 10.1007/S00287-015-0911-Z; Taylor G, 2016, PR MACH LEARN RES, V48; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; Xu YY, 2013, SIAM J IMAGING SCI, V6, P1758, DOI 10.1137/120887795; Zeng JS, 2019, PR MACH LEARN RES, V97; Zhang ZM, 2016, PROC CVPR IEEE, P1487, DOI 10.1109/CVPR.2016.165; Zhang Ziming, 2017, ADV NEURAL INFORM PR, P1721; Zheng SX, 2017, PR MACH LEARN RES, V70; Zinkevich M., 2010, P ADV NEUR INF PROC, P2595	47	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3334	3348		10.1109/TPAMI.2020.3048430	http://dx.doi.org/10.1109/TPAMI.2020.3048430			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33382647				2022-12-18	WOS:000803117500039
J	Liu, ZQ; Yu, L; Hsiao, JH; Chan, AB				Liu, Ziquan; Yu, Lei; Hsiao, Janet H.; Chan, Antoni B.			PRIMAL-GMM: PaRametrIc MAnifold Learning of Gaussian Mixture Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manifolds; Hidden Markov models; Kernel; Data models; Probabilistic logic; Approximation algorithms; Analytical models; Dimensionality reduction and manifold learning; Gaussian mixture models; interpretability; unsupervised learning; probabilistic models	HIDDEN MARKOV-MODELS; KULLBACK-LEIBLER DIVERGENCE; COMPONENT ANALYSIS; CLASSIFICATION; KERNEL	We propose a ParametRIc MAnifold Learning (PRIMAL) algorithm for Gaussian mixtures models (GMM), assuming that GMMs lie on or near to a manifold of probability distributions that is generated from a low-dimensional hierarchical latent space through parametric mappings. Inspired by principal component analysis (PCA), the generative processes for priors, means and covariance matrices are modeled by their respective latent space and parametric mapping. Then, the dependencies between latent spaces are captured by a hierarchical latent space by a linear or kernelized mapping. The function parameters and hierarchical latent space are learned by minimizing the reconstruction error between ground-truth GMMs and manifold-generated GMMs, measured by Kullback-Leibler Divergence (KLD). Variational approximation is employed to handle the intractable KLD between GMMs and a variational EM algorithm is derived to optimize the objective function. Experiments on synthetic data, flow cytometry analysis, eye-fixation analysis and topic models show that PRIMAL learns a continuous and interpretable manifold of GMM distributions and achieves a minimum reconstruction error.	[Liu, Ziquan; Chan, Antoni B.] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; [Yu, Lei] Univ Hong Kong, Dept Stat & Actuarial Sci, Pok Fu Lam, Hong Kong, Peoples R China; [Hsiao, Janet H.] Univ Hong Kong, Dept Psychol, Pok Fu Lam, Hong Kong, Peoples R China	City University of Hong Kong; University of Hong Kong; University of Hong Kong	Liu, ZQ (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.	ziquanliu2-c@my.cityu.edu.hk; leiyu6-c@my.cityu.edu.hk; jhsiao@hku.hk; abchan@cityu.edu.hk	CHAN, Antoni B./D-7858-2013; Hsiao, Janet Hui Wen/D-4916-2009	CHAN, Antoni B./0000-0002-2886-2513; Hsiao, Janet Hui Wen/0000-0003-2271-8710; LIU, Ziquan/0000-0002-7526-1032; Liu, Ziquan/0000-0002-9724-2510	City University of Hong Kong [7005218]; Research Grant Council of Hong Kong [17609117]	City University of Hong Kong(City University of Hong Kong); Research Grant Council of Hong Kong(Hong Kong Research Grants Council)	This work was supported by a Strategic Research Grant from the City University of Hong Kong (Project No. 7005218), and a grant from the Research Grant Council of Hong Kong (GRF No. 17609117).	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Aghaeepour N, 2013, NAT METHODS, V10, P228, DOI [10.1038/NMETH.2365, 10.1038/nmeth.2365]; Altman RM, 2007, J AM STAT ASSOC, V102, P201, DOI 10.1198/016214506000001086; Amari S.-I., 2007, METHODS INFORM GEOME; Carter KM, 2009, IEEE T PATTERN ANAL, V31, P2093, DOI 10.1109/TPAMI.2009.67; Chan AB, 2010, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2010.5539878; Chan CYH, 2018, PSYCHON B REV, V25, P2200, DOI 10.3758/s13423-017-1419-0; Chuk T, 2014, J VISION, V14, DOI 10.1167/14.11.8; Contractor D., 2016, P C N AM CHAPT ASS C, P69; Coviello E, 2012, P INT C NEUR INF PRO, P404; Coviello E, 2014, J MACH LEARN RES, V15, P697; Das R, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P795; Davis J. V., 2007, ADV NEURAL INFORM PR, P337; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Goldberger J., 2005, ADV NEURAL INFORM PR, V17, P505; Greene D., 2006, P 23 INT C MACHINE L, P377, DOI DOI 10.1145/1143844.1143892; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Hershey JR, 2007, INT CONF ACOUST SPEE, P317, DOI 10.1109/icassp.2007.366913; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jiang BB, 2018, IEEE T NEUR NET LEAR, V29, P5643, DOI 10.1109/TNNLS.2018.2808332; Kingma D. P., 2013, AUTO ENCODING VARIAT; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Kullback S, 1997, INFORM THEORY STAT; Kwok JTY, 2004, IEEE T NEURAL NETWOR, V15, P1517, DOI 10.1109/TNN.2004.837781; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; Liu ZQ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3073; McCullagh P., 1989, GEN LINEAR MODELS, V2nd; McLachlan GJ, 2004, FINITE MIXTURE MODEL, DOI [10.1002/0471721182, DOI 10.1002/0471721182]; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Moreno PJ, 2004, ADV NEUR IN, V16, P1385; Mumtaz A, 2013, IEEE T PATTERN ANAL, V35, P1606, DOI 10.1109/TPAMI.2012.236; Newman D., 2009, P 14 AUSTR DOC COMP, P1; Perronnin F, 2006, LECT NOTES COMPUT SC, V3954, P464; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Richardson E., 2018, PROC C ADV NEURAL IN, P5847; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Roweis S, 2002, ADV NEUR IN, V14, P889; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Saunders C., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P515; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Snelson Edward, 2006, ADV NEURAL INFORM PR, V3; Titterington DM, 1985, STAT ANAL FINITE MIX; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; Vasconcelos N, 1999, ADV NEUR IN, V11, P606; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Yu L, 2019, IEEE T PATTERN ANAL, V41, P1323, DOI 10.1109/TPAMI.2018.2845371; Yurochkin M., 2016, ADV NEURAL INFORM PR, P2505; Zhang Z., 2010, P INT C ART INT STAT, P972; Zhao YP, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1181	53	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3197	3211		10.1109/TPAMI.2020.3048727	http://dx.doi.org/10.1109/TPAMI.2020.3048727			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33385310				2022-12-18	WOS:000803117500030
J	Marin-Jimenez, MJ; Kalogeiton, V; Medina-Suarez, P; Zisserman, A				Marin-Jimenez, Manuel J.; Kalogeiton, Vicky; Medina-Suarez, Pablo; Zisserman, Andrew			LAEO-Net plus plus : Revisiting People Looking at Each Other in Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Videos; Head; Magnetic heads; Three-dimensional displays; Estimation; Computational modeling; Task analysis; Looking at each other; video; human interactions; ConvNets	HEAD-POSE; VISUAL FOCUS; ATTENTION; GAZE; EYE	Capturing the 'mutual gaze' of people is essential for understanding and interpreting the social interactions between them. To this end, this paper addresses the problem of detecting people Looking At Each Other (LAEO) in video sequences. For this purpose, we propose LAEO-Net++, a new deep CNN for determining LAEO in videos. In contrast to previous works, LAEO-Net++ takes spatio-temporal tracks as input and reasons about the whole track. It consists of three branches, one for each character's tracked head and one for their relative position. Moreover, we introduce two new LAEO datasets: UCO-LAEO and AVA-LAEO. A thorough experimental evaluation demonstrates the ability of LAEO-Net++ to successfully determine if two people are LAEO and the temporal window where it happens. Our model achieves state-of-the-art results on the existing TVHID-LAEO video dataset, significantly outperforming previous approaches. Finally, we apply LAEO-Net++ to a social network, where we automatically infer the social relationship between pairs of people based on the frequency and duration that they LAEO, and show that LAEO can be a useful tool for guided search of human interactions in videos.	[Marin-Jimenez, Manuel J.; Medina-Suarez, Pablo] Univ Cordoba, Cordoba 14071, Spain; [Kalogeiton, Vicky] LIX, Ecole Polytech, Cordoba, Spain; [Zisserman, Andrew] Univ Oxford, Oxford OX1 2JD, England	Universidad de Cordoba; University of Oxford	Marin-Jimenez, MJ (corresponding author), Univ Cordoba, Cordoba 14071, Spain.	mjmarin@uco.es; vicky.kalogeiton@polytechnique.edu; i42mesup@uco.es; az@robots.ox.ac.uk		Zisserman, Andrew/0000-0002-8945-8573; Marin-Jimenez, Manuel J./0000-0001-9294-6714	Spanish grant "Jose Castillejo"; EPSRC [EP/M013774/1]; Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC) contract [D17PC00341]	Spanish grant "Jose Castillejo"; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC) contract	Weare grateful to our annotators (RF, RD, DK, DC, E. Pina), to Q. Plepl~e for proof-reading, to S. Koepke for the model, to the reviewers for the constructive suggestions, and to NVIDIA for donating some of the GPUs we used. This work was supported by the Spanish grant "Jos~e Castillejo", the EPSRC Programme Grant Seebibyte EP/M013774/1, and the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC) contract #D17PC00341. Manuel J. Mar~in-Jim~enez and Vicky Kalogeiton contributed equally to thiswork.	ABELE A, 1986, J NONVERBAL BEHAV, V10, P83, DOI 10.1007/BF01000006; Ajodan E. L., 2019, PSYARXIV, DOI [10.31234/osf.io/8c2dm, DOI 10.31234/OSF.IO/8C2DM]; Alameda-Pineda X, 2016, IEEE T PATTERN ANAL, V38, P1707, DOI 10.1109/TPAMI.2015.2496269; Ba SO, 2011, IEEE T PATTERN ANAL, V33, P101, DOI 10.1109/TPAMI.2010.69; Ba SO, 2009, IEEE T SYST MAN CY B, V39, P16, DOI 10.1109/TSMCB.2008.927274; Brau E, 2018, LECT NOTES COMPUT SC, V11208, P641, DOI 10.1007/978-3-030-01225-0_38; Chollet F., 2015, KERAS; Chong EJ, 2018, LECT NOTES COMPUT SC, V11209, P397, DOI 10.1007/978-3-030-01228-1_24; Chung JS, 2018, INTERSPEECH, P1086; Deng H, 2017, IEEE I CONF COMP VIS, P3162, DOI 10.1109/ICCV.2017.341; Doosti B, 2020, ARXIV 201007811; Drouard V, 2017, IEEE T IMAGE PROCESS, V26, P1428, DOI 10.1109/TIP.2017.2654165; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fischer T, 2018, LECT NOTES COMPUT SC, V11214, P339, DOI 10.1007/978-3-030-01249-6_21; Goffman E, 2008, BEHAV PUBLIC PLACES; Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633; Huang Q, 2017, MACH VISION APPL, V28, P445, DOI 10.1007/s00138-017-0852-4; James Melville, 2020, Arxiv, DOI arXiv:1802.03426; Kalogeiton V, 2017, IEEE I CONF COMP VIS, P4415, DOI 10.1109/ICCV.2017.472; Kellnhofer P, 2019, IEEE I CONF COMP VIS, P6911, DOI 10.1109/ICCV.2019.00701; Kobayashi H, 2001, J HUM EVOL, V40, P419, DOI 10.1006/jhev.2001.0468; Kostinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239; Kukleva A, 2020, IEEE CVF C COMP VIS; Langton SRH, 2004, PERCEPT PSYCHOPHYS, V66, P752, DOI 10.3758/BF03194970; Li Y, 2018, LECT NOTES COMPUT SC, V11209, P639, DOI 10.1007/978-3-030-01228-1_38; Liu XC, 2019, PROC CVPR IEEE, P3561, DOI 10.1109/CVPR.2019.00368; Loeb B. K., 1972, MUTUAL EYE CONTACT S; Lv JN, 2018, LECT NOTES COMPUT SC, V10704, P355, DOI 10.1007/978-3-319-73603-7_29; Marin-Jimenez MJ, 2014, INT J COMPUT VISION, V106, P282, DOI 10.1007/s11263-013-0655-7; Marin-Jimenez MJ, 2014, MACH VISION APPL, V25, P71, DOI 10.1007/s00138-013-0521-1; Marin-Jimenez MJ, 2019, PROC CVPR IEEE, P3472, DOI 10.1109/CVPR.2019.00359; Masse B, 2018, IEEE T PATTERN ANAL, V40, P2711, DOI 10.1109/TPAMI.2017.2782819; Nagrani A, 2018, LECT NOTES COMPUT SC, V11217, P73, DOI 10.1007/978-3-030-01261-8_5; Palmero C., 2018, PROC INT C METHODS T, P158; Patron-Perez A, 2010, PROC BRIT MACH VIS C; Recasens A, 2017, IEEE I CONF COMP VIS, P1444, DOI 10.1109/ICCV.2017.160; Recasens Adria, 2015, ADV NEURAL INFORM PR, P199, DOI DOI 10.1038/SCIENTIFICAMERICAN0700-38; Rehg JamesM, 2011, MVA, V11, P14; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ricci E, 2015, IEEE I CONF COMP VIS, P4660, DOI 10.1109/ICCV.2015.529; Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281; Schofield D, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw0736; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18; Wiles Olivia, 2018, ARXIV180806882; Zhang XC, 2019, IEEE T PATTERN ANAL, V41, P162, DOI 10.1109/TPAMI.2017.2778103; Zhou K, 2016, DESTECH TRANS COMP; Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152	49	0	0	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3069	3081		10.1109/TPAMI.2020.3048482	http://dx.doi.org/10.1109/TPAMI.2020.3048482			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33382648	Green Submitted			2022-12-18	WOS:000803117500021
J	Su, B; Zhou, JH; Wen, JR; Wu, Y				Su, Bing; Zhou, Jiahuan; Wen, Ji-Rong; Wu, Ying			Linear and Deep Order-Preserving Wasserstein Discriminant Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hidden Markov models; Feature extraction; Dimensionality reduction; Three-dimensional displays; Joints; Training; Distortion measurement; Optimal transport; order-preserving Wasserstein distance; barycenter; dimensionality reduction; sequence classification	ACTION RECOGNITION; LDA	Supervised dimensionality reduction for sequence data learns a transformation that maps the observations in sequences onto a low-dimensional subspace by maximizing the separability of sequences in different classes. It is typically more challenging than conventional dimensionality reduction for static data, because measuring the separability of sequences involves non-linear procedures to manipulate the temporal structures. In this paper, we propose a linear method, called order-preserving Wasserstein discriminant analysis (OWDA), and its deep extension, namely DeepOWDA, to learn linear and non-linear discriminative subspace for sequence data, respectively. We construct novel separability measures between sequence classes based on the order-preserving Wasserstein (OPW) distance to capture the essential differences among their temporal structures. Specifically, for each class, we extract the OPW barycenter and construct the intra-class scatter as the dispersion of the training sequences around the barycenter. The inter-class distance is measured as the OPW distance between the corresponding barycenters. We learn the linear and non-linear transformations by maximizing the inter-class distance and minimizing the intra-class scatter. In this way, the proposed OWDA and DeepOWDA are able to concentrate on the distinctive differences among classes by lifting the geometric relations with temporal constraints. Experiments on four 3D action recognition datasets show the effectiveness of OWDA and DeepOWDA.	[Su, Bing; Wen, Ji-Rong] Renmin Univ China, Beijing Key Lab Big Data Management & Anal Method, Gaoling Sch Artificial Intelligence, Beijing 100872, Peoples R China; [Zhou, Jiahuan; Wu, Ying] Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA	Renmin University of China; Northwestern University	Zhou, JH (corresponding author), Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA.	subingats@gmail.com; zhoujh09@gmail.com; jrwen@ruc.edu.cn; yingwu@ece.northwestern.edu		Zhou, Jiahuan/0000-0002-3301-747X; Koochak, Atousa/0000-0001-6547-2728	National Natural Science Foundation of China [61976206, 61832017]; CCF-Tencent Open Fund [RAGR20200110]; Fundamental Research Funds for the Central Universities; Research Funds of Renmin University of China; National Science Foundation [IIS-1619078, IIS-1815561]; Army Research Office ARO [W911NF-16-1-0138]; Public Computing Cloud, Renmin University of China; Beijing Outstanding Young Scientist Program [BJJWZYJH012019 100020098]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CCF-Tencent Open Fund; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Research Funds of Renmin University of China; National Science Foundation(National Science Foundation (NSF)); Army Research Office ARO; Public Computing Cloud, Renmin University of China; Beijing Outstanding Young Scientist Program	The authors would like to thank the associate editor and anonymous reviewers for their valuable comments. This work was supported in part by the National Natural Science Foundation of China under Grants 61976206 and 61832017, Beijing Outstanding Young Scientist Program NO. BJJWZYJH012019 100020098, CCF-Tencent Open Fund RAGR20200110, the Fundamental Research Funds for the Central Universities, the Research Funds of Renmin University of China, National Science Foundation grant IIS-1619078, IIS-1815561, and the Army Research Office ARO W911NF-16-1-0138. This work was also supported in part by Public Computing Cloud, Renmin University of China.	Baradel F., 2017, ARXIV 170310106; Bauschke H., 2000, OPTIMIZATION, V48, P409; Ben Tanfous A, 2018, PROC CVPR IEEE, P2840, DOI 10.1109/CVPR.2018.00300; Benamou JD, 2015, SIAM J SCI COMPUT, V37, pA1111, DOI 10.1137/141000439; Bian W, 2011, IEEE T PATTERN ANAL, V33, P1037, DOI 10.1109/TPAMI.2010.189; Bregman L. M., 1967, COMP MATH MATH PHYS+, V7, P200, DOI DOI 10.1016/0041-5553(67)90040-7; Caetano C, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Cavazza J, 2016, INT C PATT RECOG, P408, DOI 10.1109/ICPR.2016.7899668; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Cherian A, 2018, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2018.00234; Cherian A, 2017, PROC CVPR IEEE, P1581, DOI 10.1109/CVPR.2017.172; Cho S, 2020, IEEE WINT CONF APPL, P624, DOI 10.1109/WACV45572.2020.9093639; Cuturi M, 2017, PR MACH LEARN RES, V70; Cuturi M, 2014, PR MACH LEARN RES, V32, P685; Deng YX, 2017, IEEE DEVICE RES CONF; Dorfer M., 2016, ICML, P1, DOI 10.48550/arXiv.1511.04707; Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P365; Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595; Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; Flamary R, 2018, MACH LEARN, V107, P1923, DOI 10.1007/s10994-018-5717-1; Harandi M, 2014, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2014.132; Huang G., 2016, PROC NEURAL INF PROC, P4869; Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016; Jia CC, 2016, IEEE T IMAGE PROCESS, V25, P4641, DOI 10.1109/TIP.2016.2589320; Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486; Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339; Lajugie R., 2014, ADV NEURAL INFORM PR, P1817; Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115; Li C, 2018, IEEE INT CONF SENS, P1, DOI 10.1109/TFUZZ.2018.2878200; Li M., 2019, ARXIV 191002212; Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371; Li S, 2019, ARXIV 191006251; Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Liu AA, 2019, IEEE T IMAGE PROCESS, V28, P853, DOI 10.1109/TIP.2018.2872879; Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306; Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391; Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030; Lohit S, 2019, PROC CVPR IEEE, P12418, DOI 10.1109/CVPR.2019.01271; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Paassen B., 2018, P INT C MACH LEARN, P3976; Petersen A, 2019, BIOMETRIKA, V106, P339, DOI 10.1093/biomet/asz005; Pfister T, 2014, LECT NOTES COMPUT SC, V8694, P814, DOI 10.1007/978-3-319-10599-4_52; Qiao RZ, 2017, PATTERN RECOGN, V66, P202, DOI 10.1016/j.patcog.2017.01.015; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321; Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115; Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810; Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230; Shyr A, 2010, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2010.5539922; Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132; Song SJ, 2017, AAAI CONF ARTIF INTE, P4263; Su B., 2018, P 35 INT C MACH LEAR, P4761; Su B, 2019, IEEE I CONF COMP VIS, P9884, DOI 10.1109/ICCV.2019.00998; Su B, 2020, IEEE T PATTERN ANAL, V42, P2842, DOI 10.1109/TPAMI.2019.2919303; Su B, 2019, IEEE T PATTERN ANAL, V41, P2961, DOI 10.1109/TPAMI.2018.2870154; Su B, 2018, IEEE T PATTERN ANAL, V40, P77, DOI 10.1109/TPAMI.2017.2665545; Su B, 2017, IEEE T IMAGE PROCESS, V26, P3579, DOI 10.1109/TIP.2017.2704438; Su B, 2015, PROC CVPR IEEE, P4539, DOI 10.1109/CVPR.2015.7299084; Su B, 2013, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2013.115; Su Bing, 2017, P IEEE C COMP VIS PA, P1049; Trigeorgis G, 2018, IEEE T PATTERN ANAL, V40, P1128, DOI 10.1109/TPAMI.2017.2710047; Trigeorgis G, 2016, PROC CVPR IEEE, P5110, DOI 10.1109/CVPR.2016.552; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460; Wang J, 2013, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2013.334; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang L, 2015, IEEE I CONF COMP VIS, P4570, DOI 10.1109/ICCV.2015.519; Wu JX, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P453; Yao A, 2014, PROC CVPR IEEE, P1923, DOI 10.1109/CVPR.2014.247; Ye J., 2004, P 21 ACM INT C MACH, P113; Ye JB, 2017, IEEE T SIGNAL PROCES, V65, P2317, DOI 10.1109/TSP.2017.2659647; Ye JP, 2005, J MACH LEARN RES, V6, P483; Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342; Zhang PF, 2020, IEEE T IMAGE PROCESS, V29, P1061, DOI 10.1109/TIP.2019.2937724; Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24; Zhang YP, 2012, IEEE VTS VEH TECHNOL; Zhang Yu., 2010, P ADV NEURAL INFORM, P2568; Zheng W, 2019, IEEE INT CON MULTI, P826, DOI 10.1109/ICME.2019.00147; Zhou F., 2009, ADV NEURAL INFORM PR, V22, P2286; Zhou F, 2016, IEEE T PATTERN ANAL, V38, P279, DOI 10.1109/TPAMI.2015.2414429; Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	86	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3123	3138		10.1109/TPAMI.2021.3050750	http://dx.doi.org/10.1109/TPAMI.2021.3050750			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33434122				2022-12-18	WOS:000803117500025
J	Xu, QQ; Yang, ZY; Jiang, YBY; Cao, XC; Yao, Y; Huang, QM				Xu, Qianqian; Yang, Zhiyong; Jiang, Yangbangyan; Cao, Xiaochun; Yao, Yuan; Huang, Qingming			Not All Samples are Trustworthy: Towards Deep Robust SVP Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Noise measurement; Annotations; Task analysis; Predictive models; Robustness; Visualization; Training; Subjective visual property (SVP); robustness; outlier detection; probabilistic model		In this paper, we study the problem of estimating subjective visual properties (SVP) for images, which is an emerging task in Computer Vision. Generally speaking, collecting SVP datasets involves a crowdsourcing process where annotations are obtained from a wide range of online users. Since the process is done without quality control, SVP datasets are known to suffer from noise. This leads to the issue that not all samples are trustworthy. Facing this problem, we need to develop robust models for learning SVP from noisy crowdsourced annotations. In this paper, we construct two general robust learning frameworks for this application. Specifically, in the first framework, we propose a probabilistic framework to explicitly model the sparse unreliable patterns that exist in the dataset. It is noteworthy that we then provide an alternative framework that could reformulate the sparse unreliable patterns as a "contraction" operation over the original loss function. The latter framework leverages not only efficient end-to-end training but also rigorous theoretical analyses. To apply these frameworks, we further provide two models as implementations of the frameworks, where the sparse noise parameters could be interpreted with the HodgeRank theory. Finally, extensive theoretical and empirical studies show the effectiveness of our proposed framework.	[Xu, Qianqian; Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Yang, Zhiyong; Jiang, Yangbangyan; Cao, Xiaochun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China; [Yang, Zhiyong; Jiang, Yangbangyan; Cao, Xiaochun] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100049, Peoples R China; [Cao, Xiaochun] Peng Cheng Lab, Cyberspace Secur Res Ctr, Shenzhen 518055, Peoples R China; [Yao, Yuan] Hong Kong Univ Sci & Technol, Dept Math, Hong Kong, Peoples R China; [Yao, Yuan] Hong Kong Univ Sci & Technol, Courtesy Comp Sci & Engn, Hong Kong, Peoples R China; [Huang, Qingming] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 101408, Peoples R China; [Huang, Qingming] Univ Chinese Acad Sci, Key Lab Big Data Min & Knowledge Management BDKM, Beijing 101408, Peoples R China; [Huang, Qingming] Peng Cheng Lab, Shenzhen 518055, Peoples R China	Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; Institute of Information Engineering, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Peng Cheng Laboratory; Hong Kong University of Science & Technology; Hong Kong University of Science & Technology; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Peng Cheng Laboratory	Huang, QM (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.; Huang, QM (corresponding author), Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 101408, Peoples R China.; Huang, QM (corresponding author), Univ Chinese Acad Sci, Key Lab Big Data Min & Knowledge Management BDKM, Beijing 101408, Peoples R China.	xuqianqian@ict.ac.cn; yangzhiyong@iie.ac.cn; jiangyangbangyan@iie.ac.cn; caoxiaochun@iie.ac.cn; yuany@ust.hk; qmhuang@ucas.ac.cn		Yang, Zhiyong/0000-0002-4409-4999; Jiang, Yangbangyan/0000-0002-0148-8306	National Key R&D Program of China [2018AAA0102003]; Key Research Program of Frontier Sciences, CAS [QYZDJ-SSW-SYS013]; Beijing Education Committee Cooperation Beijing Natural Science Foundation; Youth Innovation Promotion Association CAS; Strategic Priority Research Program of Chinese Academy of Sciences [XDB28000000]; Hong Kong Research Grant Council (HKRGC) [16303817, ITF UIM/390]; Tencent AI Lab, Si Family Foundation; National Natural Science Foundation of China [61620106009, U1936208, 61733007, U1736219, 61931008, 61976202, 61836002]; Tencent AI Lab; Microsoft Research-Asia	National Key R&D Program of China; Key Research Program of Frontier Sciences, CAS; Beijing Education Committee Cooperation Beijing Natural Science Foundation; Youth Innovation Promotion Association CAS; Strategic Priority Research Program of Chinese Academy of Sciences(Chinese Academy of Sciences); Hong Kong Research Grant Council (HKRGC)(Hong Kong Research Grants Council); Tencent AI Lab, Si Family Foundation; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Tencent AI Lab; Microsoft Research-Asia(Microsoft)	This work was supported in part by the National Key R&D Program of China under Grant 2018AAA0102003, in part by theNational Natural Science Foundation of China under Grants 61620106009, U1936208, 61733007, U1736219, 61931008, 61976202, and 61836002, in part by the Key Research Program of Frontier Sciences, CAS: QYZDJ-SSW-SYS013, in part by Beijing Education Committee Cooperation Beijing Natural Science Foundation (No.KZ201910005007), in part by Youth Innovation Promotion Association CAS, and in part by the Strategic Priority Research Program of Chinese Academy of Sciences under Grant XDB28000000. The work of Yuan Yao was supported in part by Hong Kong Research Grant Council (HKRGC) Grant 16303817, ITF UIM/390, as well as awards from Tencent AI Lab, Si Family Foundation, andMicrosoft Research-Asia.	Bampis CG, 2018, IEEE T IMAGE PROCESS, V27, P3316, DOI 10.1109/TIP.2018.2815842; Bo Han, 2018, IEEE Trans Neural Netw Learn Syst, V29, P5136, DOI 10.1109/TNNLS.2018.2792062; Branson S, 2017, PROC CVPR IEEE, P6109, DOI 10.1109/CVPR.2017.647; Chen KT, 2009, MATH COMPUT SCI ENG, P491, DOI 10.1145/1631272.1631339; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Chris Burges T.S., 2005, P 22 INT MACH LEARN, DOI 10.1145/1102351.1102363; Daniel F, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3148148; Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Fu YW, 2016, IEEE T PATTERN ANAL, V38, P563, DOI 10.1109/TPAMI.2015.2456887; Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P488, DOI 10.1007/978-3-319-10605-2_32; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang Gary B., 2007, 0749 U MASS, P7; Huber P.J., 2004, ROBUST STAT; Jiang XY, 2011, MATH PROGRAM, V127, P203, DOI 10.1007/s10107-010-0419-x; Jiang YBY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P718, DOI 10.1145/3240508.3240582; Jindal I, 2016, IEEE DATA MINING, P967, DOI [10.1109/ICDM.2016.124, 10.1109/ICDM.2016.0121]; Jing PG, 2017, IEEE T MULTIMEDIA, V19, P1050, DOI 10.1109/TMM.2016.2644866; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]; Kovashka A, 2017, ADV COMPUT VIS PATT, P89, DOI 10.1007/978-3-319-50077-5_5; Kovashka A, 2015, INT J COMPUT VISION, V114, P56, DOI 10.1007/s11263-014-0798-1; Lu ZW, 2017, IEEE T PATTERN ANAL, V39, P486, DOI 10.1109/TPAMI.2016.2552172; Mohammad Norouzi, 2012, ADV NEURAL INFORM PR, P1061; Mohri M., 2018, FDN MACHINE LEARNING; Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240; Rashmi KV, 2015, JMLR WORKSH CONF PRO, V38, P489; Sandeep RN, 2014, PROC CVPR IEEE, P3614, DOI 10.1109/CVPR.2014.462; Squalli-Houssaini H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2371, DOI 10.1109/icassp.2018.8462292; Vandat A, 2017, ADV NEUR IN, V30; Xu, 2013, P 21 ACM INT C MULT, P43, DOI DOI 10.1145/2502081.2502083; Xu Q., 2012, P 20 ACM INT C MULTI, P359; Xu QQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1540, DOI 10.1145/3123266.3123267; Xu QQ, 2019, PROC CVPR IEEE, P8985, DOI 10.1109/CVPR.2019.00920; Yang XS, 2016, IEEE T MULTIMEDIA, V18, P1832, DOI 10.1109/TMM.2016.2582379; Yao JC, 2019, IEEE T IMAGE PROCESS, V28, P1909, DOI 10.1109/TIP.2018.2877939; Yu A, 2015, IEEE I CONF COMP VIS, P2416, DOI 10.1109/ICCV.2015.278; Zhang J, 2018, PROC CVPR IEEE, P9029, DOI 10.1109/CVPR.2018.00941	37	0	0	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3154	3169		10.1109/TPAMI.2020.3047817	http://dx.doi.org/10.1109/TPAMI.2020.3047817			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33373295				2022-12-18	WOS:000803117500027
J	Chen, YC; Jia, JY				Chen, Ying-Cong; Jia, Jiaya			Homomorphic Interpolation Network for Unpaired Image-to-Image Translation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Interpolation; Task analysis; Decoding; Aerospace electronics; Faces; Image synthesis; Generators		Generative adversarial networks have achieved great success in unpaired image-to-image translation. Cycle consistency, a key component for this task, allows modeling the relationship between two distinct domains without paired data. In this paper, we propose an alternative framework, as an extension of latent space interpolation, to consider the intermediate region between two domains during translation. It is based on the assumption that in a flat and smooth latent space, there exist many paths that connect two sample points. Properly selecting paths makes it possible to change only certain image attributes, which is useful for generating intermediate images between the two domains. With this idea, our framework includes an encoder, an interpolator and a decoder. The encoder maps natural images to a convex and smooth latent space where interpolation is applicable. The interpolator controls the interpolation path so that desired intermediate samples can be obtained. Finally, the decoder inverts interpolated features back to pixel space. We also show that by choosing different reference images and interpolation paths, this framework can be applied to multi-domain and multi-modal translation. Extensive experiments manifest that our framework achieves superior results and is flexible for various tasks.	[Chen, Ying-Cong] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Jia, Jiaya] Chinese Univ Hong Kong, Sch Engn, Dept Comp Sci, Hong Kong, Peoples R China	Massachusetts Institute of Technology (MIT); Chinese University of Hong Kong	Chen, YC (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	yingcong.ian.chen@gmail.com; leojia@cse.cuhk.edu.hk						Almahairi A, 2018, PR MACH LEARN RES, V80; Bauer M, 2019, PR MACH LEARN RES, V89, P66; Bengio Yoshua, 2013, INT C MACHINE LEARNI, P552; Berthelot D., 2018, P INT C LEARN REPR; Brock Andrew, 2018, P ICLR; Chen YC, 2019, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2019.00251; Chen YC, 2018, PROC CVPR IEEE, P3541, DOI 10.1109/CVPR.2018.00373; Cho W, 2019, PROC CVPR IEEE, P10631, DOI 10.1109/CVPR.2019.01089; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Dilokthanakul Nat, 2016, ARXIV161102648; Gong R, 2019, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2019.00258; Gulrajani I., 2017, INT C NEURAL INF PRO; Guo Chuan, 2017, ICML, DOI DOI 10.5555/3305381.3305518; He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751; Hensel M, 2017, ADV NEUR IN, V30; Hinton G., 2015, ARXIV150302531; Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Karras T, 2017, ARXIV171010196; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kim Taeksoo, 2017, P 34 INT C MACH LEAR, P1857, DOI [10.5555/3305381.3305573, DOI 10.5555/3305381.3305573]; Kingma D.P, P 3 INT C LEARNING R; Kingma D. P, 2014, ARXIV13126114; Kingma Diederik P, 2018, ADV NEURAL INFORM PR; Lample Guillaume, 2017, ARXIV170600409; Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076; Larsen A. B. L., 2015, ARXIV PREPRINT ARXIV; Lee HY, 2018, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2018.8439459; Liu MY, 2017, ADV NEUR IN, V30; Liu R, 2019, PROC CVPR IEEE, P7984, DOI 10.1109/CVPR.2019.00818; Lu YY, 2018, LECT NOTES COMPUT SC, V11216, P293, DOI 10.1007/978-3-030-01258-8_18; Makhzani Alireza, 2016, ICLR WORKSH; Miyato Takeru, 2018, 6 INT C LEARNING REP, P8; Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Reed S, 2015, ADV NEURAL INFORM PR, P1252; Romero Adriana, 2014, ARXIV14126550; Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481; Shen W, 2017, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2017.135; Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242; Simonyan K., 2015, INT C LEARN REPR ICL; Tolstikhin Ilya, 2017, ARXIV171101558; Tomczak JM, 2018, PR MACH LEARN RES, V84; Ulyanov D., 2018, PROC AAAI C ARTIF IN, P1; Upchurch P, 2017, PROC CVPR IEEE, P6090, DOI 10.1109/CVPR.2017.645; White T, 2016, ARXIV 160904468; Yan XC, 2016, LECT NOTES COMPUT SC, V9908, P776, DOI 10.1007/978-3-319-46493-0_47; Zhao B, 2018, LECT NOTES COMPUT SC, V11218, P157, DOI 10.1007/978-3-030-01264-9_10; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	51	0	0	3	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2534	2547		10.1109/TPAMI.2020.3036543	http://dx.doi.org/10.1109/TPAMI.2020.3036543			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33156783				2022-12-18	WOS:000792921400024
J	Moreau, T; Gramfort, A				Moreau, Thomas; Gramfort, Alexandre			DiCoDiLe: Distributed Convolutional Dictionary Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolution; Dictionaries; Machine learning; Convolutional codes; Complexity theory; Data models; Computational modeling; Convolutional dictionary learning; distributed system; coordinate descent	SPARSE; ALGORITHM	Convolutional dictionary learning (CDL) estimates shift invariant basis adapted to represent signals or images. CDL has proven useful for image denoising or inpainting, as well as for pattern discovery on multivariate signals. Contrarily to standard patch-based dictionary learning, patterns estimated by CDL can be positioned anywhere in signals or images. Optimization techniques consequently face the difficulty of working with extremely large inputs with millions of pixels or time samples. To address this optimization problem, we propose a distributed and asynchronous algorithm, employing locally greedy coordinate descent and a soft-locking mechanism that does not require a central server. Computation can be distributed on a number of workers which scales linearly with the size of the data. The parallel computation accelerates the parameter estimation and the distributed setting allows our algorithm to be used with data that do not fit into a single computer's RAM. Experiments confirm the theoretical scaling properties of the algorithm. This allows to demonstrate an improved pattern recovery as images grow in size, and to learn patterns on images from the Hubble Space Telescope containing tens of millions of pixels.	[Moreau, Thomas; Gramfort, Alexandre] Univ Paris Saclay, CEA, INRIA, F-91120 Palaiseau, France	CEA; Inria; UDICE-French Research Universities; Universite Paris Saclay	Moreau, T (corresponding author), Univ Paris Saclay, CEA, INRIA, F-91120 Palaiseau, France.	thomas.moreau@inria.fr; alexandre.gramfort@inria.fr		Moreau, Thomas/0000-0002-1523-3419; Gramfort, Alexandre/0000-0001-9791-4404	ERC Starting Grant SLAB [ERC-StG-676943]	ERC Starting Grant SLAB	This work was supported by the ERC Starting Grant SLAB ERC-StG-676943.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2013, P INT JOINT C NEUR N; Bauschke HH, 2011, CMS BOOKS MATH, P1, DOI 10.1007/978-1-4419-9467-7; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bergstra James S, 2011, ADV NEURAL INFORM PR, P2546, DOI [10.5555/2986459.2986743, DOI 10.5555/2986459.2986743]; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Bristow H, 2013, PROC CVPR IEEE, P391, DOI 10.1109/CVPR.2013.57; Dalcin L, 2005, J PARALLEL DISTR COM, V65, P1108, DOI 10.1016/j.jpdc.2005.03.010; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1; Giavalisco M, 2004, ASTROPHYS J, V600, pL93, DOI 10.1086/379232; Grosse R., 2007, CORTEX, V8; Jas M, 2017, ADV NEUR IN, V30; Karimireddy S. P., 2019, P MACHINE LEARNING R, P2887; Kavukcuoglu Koray, 2010, ADV NEURAL INFORM PR, V23, P1090; Kjolstad F. B., 2010, P 2010 WORKSH PAR PR, P1; Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053; Li YY, 2009, INVERSE PROBL IMAG, V3, P487, DOI 10.3934/ipi.2009.3.487; Mairal J, 2010, J MACH LEARN RES, V11, P19; Moreau T, 2018, P 35 INT C MACH LEAR, P3626; Nutini J, 2015, PR MACH LEARN RES, V37, P1632; Papyan V, 2017, IEEE I CONF COMP VIS, P5306, DOI 10.1109/ICCV.2017.566; Pereyra M, 2015, EUR SIGNAL PR CONF, P230, DOI 10.1109/EUSIPCO.2015.7362379; Pla PD, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2776; Python Software Fundation, 2017, PYTHON LANGUAGE REFE; Simon D., 2019, P 33 INT C NEUR INF, P2274; Skau E, 2018, PROCEEDINGS 2018 IEEE 13TH IMAGE, VIDEO, AND MULTIDIMENSIONAL SIGNAL PROCESSING WORKSHOP (IVMSP); Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206; Sulam J, 2020, IEEE T PATTERN ANAL, V42, P1968, DOI 10.1109/TPAMI.2019.2904255; Sulam J, 2018, IEEE T SIGNAL PROCES, V66, P4090, DOI 10.1109/TSP.2018.2846226; The ImageMagick Development Team, 2020, IMAGEMAGICK; Vidal AF, 2018, IEEE IMAGE PROC, P1742, DOI 10.1109/ICIP.2018.8451795; Wohlberg B, 2016, IEEE T IMAGE PROCESS, V25, P301, DOI 10.1109/TIP.2015.2495260; Yellin F, 2017, I S BIOMED IMAGING, P650, DOI 10.1109/ISBI.2017.7950604; Zisselman E, 2019, PROC CVPR IEEE, P8200, DOI 10.1109/CVPR.2019.00840	35	0	0	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2426	2437		10.1109/TPAMI.2020.3039215	http://dx.doi.org/10.1109/TPAMI.2020.3039215			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33211653	Green Submitted			2022-12-18	WOS:000792921400017
J	Sharma, G; Goyal, R; Liu, DF; Kalogerakis, E; Maji, S				Sharma, Gopal; Goyal, Rishabh; Liu, Difan; Kalogerakis, Evangelos; Maji, Subhransu			Neural Shape Parsers for Constructive Solid Geometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape; Three-dimensional displays; Two dimensional displays; Grammar; Task analysis; Decoding; Solid modeling; Constructive solid geometry; reinforcement learning; shape parsing	BOUNDARY	Constructive solid geometry (CSG) is a geometric modeling technique that defines complex shapes by recursively applying boolean operations on primitives such as spheres and cylinders. We present CSGNet, a deep network architecture that takes as input a 2D or 3D shape and outputs a CSG program that models it. Parsing shapes into CSG programs is desirable as it yields a compact and interpretable generative model. However, the task is challenging since the space of primitives and their combinations can be prohibitively large. CSGNet uses a convolutional encoder and recurrent decoder based on deep networks to map shapes to modeling instructions in a feed-forward manner and is significantly faster than bottom-up approaches. We investigate two architectures for this task-a vanilla encoder (CNN) - decoder (RNN) and another architecture that augments the encoder with an explicit memory module based on the program execution stack. The stack augmentation improves the reconstruction quality of the generated shape and learning efficiency. Our approach is also more effective as a shape primitive detector compared to a state-of-the-art object detector. Finally, we demonstrate CSGNet can be trained on novel datasets without program annotations through policy gradient techniques.	[Sharma, Gopal; Liu, Difan; Kalogerakis, Evangelos; Maji, Subhransu] Univ Massachusetts, Amherst, MA 01003 USA; [Goyal, Rishabh] Univ Illinois, Champaign, IL 61820 USA	University of Massachusetts System; University of Massachusetts Amherst; University of Illinois System; University of Illinois Urbana-Champaign	Sharma, G (corresponding author), Univ Massachusetts, Amherst, MA 01003 USA.	gopalsharma@cs.umass.edu; rgoyal6@illinois.edu; dliu@cs.umass.edu; kalo@cs.umass.edu; smaji@cs.umass.edu		Kalogerakis, Evangelos/0000-0002-5867-5735	National Science Foundation (NSF) [CHS-1422441, CHS-1617333, IIS-1617917, IIS-1908669]; MassTech collaborative grant	National Science Foundation (NSF)(National Science Foundation (NSF)National Research Foundation of Korea); MassTech collaborative grant	This work was supported in part by grants from the National Science Foundation (NSF) CHS-1422441, CHS-1617333, IIS-1617917, and IIS-1908669. The authors would like to thank the MassTech collaborative grant for funding the UMass GPU cluster.	Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; [Anonymous], TRIMBLE 3D WAREHOUSE; Balog M, 2017, P INT C LEARN REPR; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13; Buchele SF, 2004, COMPUT AIDED DESIGN, V36, P1063, DOI 10.1016/j.cad.2004.01.006; Chang Angel X., 2015, ARXIV151203012CSGR P; Chatfield K, 2014, P BRIT MACH VIS C 20, P1; Chen ZQ, 2020, PROC CVPR IEEE, P42, DOI 10.1109/CVPR42600.2020.00012; Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319; Chung Junyoung, 2014, ARXIV PREPRINT ARXIV; de Freitas N., 2016, P INT C LEARN REPR; Deng BY, 2020, PROC CVPR IEEE, P31, DOI 10.1109/CVPR42600.2020.00011; Denil M., 2017, ARXIV 170606383; Deprelle T, 2019, ADV NEUR IN, V32; Dijkstra E.W., 1960, NUMER MATH, P312; Du T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275006; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Eslami SM, 2016, NEURIPS, V1; Fayolle PA, 2016, COMPUT AIDED DESIGN, V74, P1, DOI 10.1016/j.cad.2016.01.001; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gao J., 2019, DEEPSPLINE DATA DRIV; Genova K, 2020, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR42600.2020.00491; Gershman SJ, 2014, P 36 ANN C COGN SCI; Hamza K, 2004, LECT NOTES COMPUT SC, V3103, P981; Hopcroft J.E., 2001, ACM SIGACT NEWS, V32, P60, DOI DOI 10.1145/568438.568455; Hu RH, 2017, IEEE I CONF COMP VIS, P804, DOI 10.1109/ICCV.2017.93; Huang HB, 2017, IEEE T VIS COMPUT GR, V23, P2003, DOI 10.1109/TVCG.2016.2597830; Jiahui Huang, 2018, Computational Visual Media, V4, P385, DOI 10.1007/s41095-018-0128-6; Johnson J, 2017, IEEE I CONF COMP VIS, P3008, DOI 10.1109/ICCV.2017.325; Joulin A, 2015, ADV NEUR IN, V28; Kaiser I., 2016, P INT C LEARN REPR; Kingma D.P., 2015, 3 INT C LEARN REPR I, P1, DOI DOI 10.1007/S11390-017-1754-7; Koch S, 2019, PROC CVPR IEEE, P9593, DOI 10.1109/CVPR.2019.00983; Kulkarni TD, 2015, ADV NEUR IN, V28; Laidlaw D. H., 1986, Computer Graphics, V20, P161, DOI 10.1145/15886.15904; Li LX, 2019, PROC CVPR IEEE, P2647, DOI 10.1109/CVPR.2019.00276; Liang C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P23, DOI 10.18653/v1/P17-1003; Lun ZL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766929; Martinovic A, 2013, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2013.33; Neelakantan Arvind, 2016, 4 INT C LEARN REPR I; Ng AY, 1999, MACHINE LEARNING, PROCEEDINGS, P278; Nishida G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925951; Paschalidou D., 2019, SUPERQUADRICS REVIST; POWELL MJD, 1964, COMPUT J, V7, P155, DOI 10.1093/comjnl/7.2.155; Pytorch, US; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ritchie D., 2016, ADV NEURAL INFORM PR, P622; Ritchie D, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766895; Romaszko L, 2017, IEEE INT CONF COMP V, P940, DOI 10.1109/ICCVW.2017.115; SHAPIRO V, 1991, COMPUT AIDED DESIGN, V23, P4, DOI 10.1016/0010-4485(91)90077-A; SHAPIRO V, 1993, ACM T GRAPHIC, V12, P35, DOI 10.1145/169728.169723; Sharma G, 2018, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2018.00578; Stava O, 2014, COMPUT GRAPH FORUM, V33, P118, DOI 10.1111/cgf.12282; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Sutton RS, 2000, ADV NEUR IN, V12, P1057; Talton JO, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P63; Teboul O., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2273, DOI 10.1109/CVPR.2011.5995319; Tenenbaum J. B., 2017, ARXIV 170709627; Tian Y, 2019, P INT C LEARN REPR; Tulsiani S, 2017, PROC CVPR IEEE, P1466, DOI 10.1109/CVPR.2017.160; Vanegas CA, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366187; Weiss D, 2009, GEOMETRY BASED STRUC; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Wu JJ, 2017, PROC CVPR IEEE, P7035, DOI 10.1109/CVPR.2017.744; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002; Zaremba W, 2014, CORR; Zaremba W, 2016, PR MACH LEARN RES, V48; Zou CH, 2017, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2017.103	71	0	0	2	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2628	2640		10.1109/TPAMI.2020.3044749	http://dx.doi.org/10.1109/TPAMI.2020.3044749			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33315554	Green Submitted			2022-12-18	WOS:000792921400030
J	Shi, WJ; Huang, G; Song, SJ; Wang, ZY; Lin, TY; Wu, C				Shi, Wenjie; Huang, Gao; Song, Shiji; Wang, Zhuoyuan; Lin, Tingyu; Wu, Cheng			Self-Supervised Discovering of Interpretable Features for Reinforcement Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Decision making; Perturbation methods; Reinforcement learning; Jacobian matrices; Visualization; Games; Deep reinforcement learning; interpretability; attention map; decision-making process		Deep reinforcement learning (RL) has recently led to many breakthroughs on a range of complex control tasks. However, the agent's decision-making process is generally not transparent. The lack of interpretability hinders the applicability of RL in safety-critical scenarios. While several methods have attempted to interpret vision-based RL, most come without detailed explanation for the agent's behavior. In this paper, we propose a self-supervised interpretable framework, which can discover interpretable features to enable easy understanding of RL agents even for non-experts. Specifically, a self-supervised interpretable network (SSINet) is employed to produce fine-grained attention masks for highlighting task-relevant information, which constitutes most evidence for the agent's decisions. We verify and evaluate our method on several Atari 2600 games as well as Duckietown, which is a challenging self-driving car simulator environment. The results show that our method renders empirical evidences about how the agent makes decisions and why the agent performs well or badly, especially when transferred to novel scenes. Overall, our method provides valuable insight into the internal decision-making process of vision-based RL. In addition, our method does not use any external labelled data, and thus demonstrates the possibility to learn high-quality mask through a self-supervised manner, which may shed light on new paradigms for label-free vision learning such as self-supervised segmentation and detection.	[Shi, Wenjie; Huang, Gao; Song, Shiji; Wang, Zhuoyuan; Wu, Cheng] Tsinghua University12442, Dept Automat, Beijing 100084, Peoples R China; [Lin, Tingyu] Beijing Inst Elect Syst Engn, State Key Lab Intelligent Mfg Syst Technol, Beijing 100039, Peoples R China		Huang, G (corresponding author), Tsinghua University12442, Dept Automat, Beijing 100084, Peoples R China.	shiwj16@mails.tsinghua.edu.cn; gaohuang@tsinghua.edu.cn; shijis@tsinghua.edu.cn; zhuoyuan16@mails.tsinghua.edu.cn; lintingyu2003@sina.com; wuc@tsinghua.edu.cn			National Science and Technology Major Project of the Ministry of Science and Technology of China [2018AAA0100701, 2018YFB1702903]; National Natural Science Foundation of China [61906106, 61936009, 62022048]; Institute for Guo Qiang of Tsinghua University; Beijing Academy of Artificial Intelligence	National Science and Technology Major Project of the Ministry of Science and Technology of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Institute for Guo Qiang of Tsinghua University; Beijing Academy of Artificial Intelligence	This work was supported in part by the National Science and Technology Major Project of the Ministry of Science and Technology of China under Grants 2018AAA0100701 and 2018YFB1702903, the National Natural Science Foundation of China under Grants 61906106, 61936009, and 62022048, the Institute for Guo Qiang of Tsinghua University and Beijing Academy of Artificial Intelligence. The authors would like to thank the reviewers for their valuable comments.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Annasamy RM, 2019, AAAI CONF ARTIF INTE, P4561; Bastani O, 2018, ADV NEUR IN, V31; Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354; Bellemare MG, 2013, J ARTIF INTELL RES, V47, P253, DOI 10.1613/jair.3912; Binder A, 2016, LECT NOTES COMPUT SC, V9887, P63, DOI 10.1007/978-3-319-44781-0_8; Brockman Greg, 2016, arXiv; Cao QX, 2021, IEEE T PATTERN ANAL, V43, P887, DOI 10.1109/TPAMI.2019.2943456; Chen L.-C., 2017, RETHINKING ATROUS CO; Choi J, 2017, IEEE UNDERWATER TECH; Dabkowski P, 2017, ADV NEUR IN, V30; Dodson T, 2011, LECT NOTES ARTIF INT, V6992, P42, DOI 10.1007/978-3-642-24873-3_4; Elizalde F., 2008, P 4 EUR WORKSH PROB, P97; Engel Y, 2001, P INT C MACH LEARN, P138; Fong R, 2019, IEEE I CONF COMP VIS, P2950, DOI 10.1109/ICCV.2019.00304; Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371; Fujimoto S, 2018, PR MACH LEARN RES, V80; Greydanus S, 2018, PR MACH LEARN RES, V80; Guidotti R., 2019, ACM COMPUT SURV, V51; Gupta U. D., 2015, P 29 AAAI C ART INT, P2547; Haarnoja T, 2018, PR MACH LEARN RES, V80; Hayes B, 2017, ACMIEEE INT CONF HUM, P303, DOI 10.1145/2909824.3020233; Jegou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156; Land MF, 2009, VISUAL NEUROSCI, V26, P51, DOI 10.1017/S0952523808080899; Lillicrap T.P., 2015, CONTINUOUS CONTROL D, DOI DOI 10.1561/2200000006; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Liu HM, 2021, IEEE T PATTERN ANAL, V43, P1791, DOI 10.1109/TPAMI.2019.2954501; Lundberg SM, 2017, ADV NEUR IN, V30; Madumal P, 2020, AAAI CONF ARTIF INTE, V34, P2493; Manchin A, 2019, COMM COM INF SC, V1143, P223, DOI 10.1007/978-3-030-36802-9_25; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Mirowski Piotr, 2017, INT C LEARN REPR; Mnih V., 2015, NATURE, V518; Monfort M, 2020, IEEE T PATTERN ANAL, V42, P502, DOI 10.1109/TPAMI.2019.2901464; Mott A., 2019, ARXIV190602500, p12 350; Mousavi S, 2016, ARXIV 161205753; Nikulin D, 2019, IEEE INT CONF COMP V, P4240, DOI 10.1109/ICCVW.2019.00522; Oztireli C., 2019, PR MACH LEARN RES, P272; Petsiuk V., 2018, P BRIT MACH VIS C; Ribeiro Marco Tulio, 2016, P KDD, P97, DOI [10.18653/v1/n16-3020, DOI 10.1145/2939672.2939778]; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Roth A. M, 2019, ARXIV 190701180; Schulman J., 2017, ARXIV PREPRINT ARXIV, DOI 10.48550/arXiv.1707.06347; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Shapley L. S., 1953, CONTRIBUTIONS THEORY, V28, P307, DOI [10.3390/atmos10110723, DOI 10.1515/9781400881970-018]; Shi W., 2019, P INT C NEUR INF PRO; Shi WJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3425; Shi WJ, 2018, IEEE SYS MAN CYBERN, P4138, DOI 10.1109/SMC.2018.00701; Shi WJ, 2019, IEEE T NEUR NET LEAR, V30, P3534, DOI 10.1109/TNNLS.2018.2884797; Shrikumar Avanti, 2017, PMLR, P3145, DOI DOI 10.1145/3292500.3330701; Silver D., 2016, NATURE, V529; Smilkov D, 2017, ARXIV; Sorokin I., 2015, ARXIV151201693; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Van Hasselt Hado, 2016, P AAAI C ART INT, V30; Waa J., 2018, P WORKSH EXPL AI IJC; Wang WG, 2021, IEEE T PATTERN ANAL, V43, P2413, DOI 10.1109/TPAMI.2020.2966453; Wang Z., 2016, SER P MACHINE LEARNI, DOI DOI https://doi.org/10.1016/j.molstruc.2016.06.044; Yang Z, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM); Zahavy T, 2016, PR MACH LEARN RES, V48; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang JM, 2018, INT J COMPUT VISION, V126, P1084, DOI 10.1007/s11263-017-1059-x; Zhang RH, 2020, AAAI CONF ARTIF INTE, V34, P6811, DOI 10.1609/aaai.v34i04.6161; Zhang RH, 2018, LECT NOTES COMPUT SC, V11215, P692, DOI 10.1007/978-3-030-01252-6_41; Zhou BL, 2019, IEEE T PATTERN ANAL, V41, P2131, DOI 10.1109/TPAMI.2018.2858759; Zintgraf Luisa M., 2017, P ICLR	67	0	0	9	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2712	2724		10.1109/TPAMI.2020.3037898	http://dx.doi.org/10.1109/TPAMI.2020.3037898			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33186101	Green Submitted			2022-12-18	WOS:000792921400036
J	Wang, CH; Fu, H; Tao, DC; Black, MJ				Wang, Chaohui; Fu, Huan; Tao, Dacheng; Black, Michael J.			Occlusion Boundary: A Formal Definition & Its Detection via Deep Exploration of Context	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Two dimensional displays; Three-dimensional displays; Image edge detection; Detectors; Computational modeling; Computer vision; Spatiotemporal phenomena; Occlusion boundaries; convolutional neural networks; fully convolutional networks; conditional random fields	T-JUNCTIONS; SEGMENTATION; VISION	Occlusion boundaries contain rich perceptual information about the underlying scene structure and provide important cues in many visual perception-related tasks such as object recognition, segmentation, motion estimation, scene understanding, and autonomous navigation. However, there is no formal definition of occlusion boundaries in the literature, and state-of-the-art occlusion boundary detection is still suboptimal. With this in mind, in this paper we propose a formal definition of occlusion boundaries for related studies. Further, based on a novel idea, we develop two concrete approaches with different characteristics to detect occlusion boundaries in video sequences via enhanced exploration of contextual information (e.g, local structural boundary patterns, observations from surrounding regions, and temporal context) with deep models and conditional random fields. Experimental evaluations of our methods on two challenging occlusion boundary benchmarks (CMU and VSB100) demonstrate that our detectors significantly outperform the current state-of-the-art. Finally, we empirically assess the roles of several important components of the proposed detectors to validate the rationale behind these approaches.	[Wang, Chaohui] Univ Gustave Eiffel, LIGM, CNRS, ESIEE,Paris Ecole Ponts, F-93160 Marne La Vallee, France; [Fu, Huan; Tao, Dacheng] Univ Sydney, Sch Comp Sci, Fac Engn, 6 Cleveland St, Darlington, NSW 2008, Australia; [Black, Michael J.] Max Planck Inst Intelligent Syst, Perceiving Syst Dept, D-70569 Tubingen, Germany	Centre National de la Recherche Scientifique (CNRS); Ecole des Ponts ParisTech; Universite Gustave-Eiffel; ESIEE Paris; University of Sydney; Max Planck Society	Wang, CH (corresponding author), Univ Gustave Eiffel, LIGM, CNRS, ESIEE,Paris Ecole Ponts, F-93160 Marne La Vallee, France.	chaohui.wang@univ-eiffel.fr; hufu6371@uni.sydney.edu.au; dacheng.tao@sydney.edu.au; black@tuebingen.mpg.de			CNRS INS2I-JCJC-INVISANA, Australian Research Council [FL170100117, IC-190100031]; Nvidia; Max Planck; Intel; Amazon; Facebook	CNRS INS2I-JCJC-INVISANA, Australian Research Council; Nvidia; Max Planck(Max Planck Society); Intel(Intel Corporation); Amazon; Facebook(Facebook Inc)	This work was partly supported by CNRS INS2I-JCJC-INVISANA, Australian Research Council Projects FL170100117 and IC-190100031. MJB has received research gift funds from Intel, Nvidia, Facebook, and Amazon. While MJB is a part-time employee of Amazon, his research was performed solely at, and funded solely by, Max Planck. MJB has financial interests in Amazon and Meshcapade GmbH. Chaohui Wang and Huan Fu are equal contributions.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Apostoloff N, 2005, PROC CVPR IEEE, P553; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Ayvaci A, 2012, IEEE T PATTERN ANAL, V34, P1942, DOI 10.1109/TPAMI.2011.271; Biederman I., 1981, SEMANTICS GLANCE SCE; Black M. J., 1990, AAAI-90 Proceedings. Eighth National Conference on Artificial Intelligence, P1060; BLACK MJ, 1992, LECT NOTES COMPUT SC, V588, P485; Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933; Blake A, 2011, MARKOV RANDOM FIELDS FOR VISION AND IMAGE PROCESSING, P1; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Cakir HI, 2016, LECT NOTES COMPUT SC, V9906, P492, DOI 10.1007/978-3-319-46475-6_31; Carbonetto P, 2004, LECT NOTES COMPUT SC, V3021, P350; Dai Jifeng, 2016, ADV NEURAL INFORM PR, P379, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075; Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Fan XC, 2015, PROC CVPR IEEE, P1347, DOI 10.1109/CVPR.2015.7298740; Feldman D, 2008, IEEE T PATTERN ANAL, V30, P1171, DOI 10.1109/TPAMI.2007.70766; Forsyth DA, 2002, PRENT HALL PROF TECH; Freund Y., 1997, P 20 9 ANN ACM S THE, P334, DOI [10.1145/258533.258616, DOI 10.1145/258533.258616]; Fu H, 2016, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2016.33; Galasso F, 2013, IEEE I CONF COMP VIS, P3527, DOI 10.1109/ICCV.2013.438; Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36; Gibson J., 1968, PERCEPTION SUR UNPUB; Goodfellow I.J., 2015, DEEP LEARNING; He XM, 2010, LECT NOTES COMPUT SC, V6314, P539; Hinton G.E., 2012, ARXIV; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Humayun A, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995517; Ilg E, 2018, LECT NOTES COMPUT SC, V11216, P626, DOI 10.1007/978-3-030-01258-8_38; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jacobson N, 2012, IEEE T IMAGE PROCESS, V21, P252, DOI 10.1109/TIP.2011.2162420; Jia Y., 2014, P 22 ACM INT C MULT, P675; Keuper M, 2016, LECT NOTES COMPUT SC, V9915, P789, DOI 10.1007/978-3-319-49409-8_65; Kontschieder P, 2011, IEEE I CONF COMP VIS, P2190, DOI 10.1109/ICCV.2011.6126496; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lei P, 2018, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2018.00346; Leordeanu M, 2014, IEEE T PATTERN ANAL, V36, P1312, DOI 10.1109/TPAMI.2014.17; Li SX, 2015, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2015.7298618; Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472; Lim H, 2011, IEEE IMAGE PROC, P1089, DOI 10.1109/ICIP.2011.6115615; Liu Y, 2016, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2016.32; Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849; Long J., 2015, P IEEE C COMPUTER VI, P3431, DOI DOI 10.1109/CVPR.2015.7298965; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Malisiewicz T., 2009, ADV NEURAL INF PROCE, V22, P1222; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Myeong H, 2012, PROC CVPR IEEE, P2727, DOI 10.1109/CVPR.2012.6247995; Nair V., 2010, ICML, P807; Owens A, 2014, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2014.350; Palou G, 2013, IEEE T IMAGE PROCESS, V22, P1926, DOI 10.1109/TIP.2013.2240002; Raza SH, 2015, IEEE WINT CONF APPL, P1022, DOI 10.1109/WACV.2015.141; Sand P, 2008, INT J COMPUT VISION, V80, P72, DOI 10.1007/s11263-008-0136-6; Sargin ME, 2009, IEEE I CONF COMP VIS, P560, DOI 10.1109/ICCV.2009.5459190; Saxena Ashutosh, 2005, ADV NEURAL INFORM PR; Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3; Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024; Stein A. N., 2006, P BRIT MACH VIS C, P407; Stein A, 2007, IEEE I CONF COMP VIS, P110; Stein AN, 2009, INT J COMPUT VISION, V82, P325, DOI 10.1007/s11263-008-0203-z; Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32; Sundberg P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2233, DOI 10.1109/CVPR.2011.5995364; Taylor B, 2015, PROC CVPR IEEE, P4268, DOI 10.1109/CVPR.2015.7299055; Teed Zachary, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P402, DOI 10.1007/978-3-030-58536-5_24; Wang CH, 2013, COMPUT VIS IMAGE UND, V117, P1610, DOI 10.1016/j.cviu.2013.07.004; Wang G., 2018, PROC ASIAN C COMPUT, P686; Wang P, 2016, LECT NOTES COMPUT SC, V9905, P545, DOI 10.1007/978-3-319-46448-0_33; Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652; Weinzaepfel P, 2015, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2015.7298873; Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175; Weiss Y, 2001, NEU INF PRO, P229; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164	78	0	0	9	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2641	2656		10.1109/TPAMI.2020.3039478	http://dx.doi.org/10.1109/TPAMI.2020.3039478			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33211655	Green Published			2022-12-18	WOS:000792921400031
J	Yuan, YT; Ma, L; Wang, JW; Liu, W; Zhu, WW				Yuan, Yitian; Ma, Lin; Wang, Jingwen; Liu, Wei; Zhu, Wenwu			Semantic Conditioned Dynamic Modulation for Temporal Sentence Grounding in Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Videos; Grounding; Semantics; Proposals; Task analysis; Convolution; Visualization; Temporal sentence grounding in videos (TSG); semantic conditioned dynamic modulation (SCDM); temporal convolution		Temporal sentence grounding in videos aims to localize one target video segment, which semantically corresponds to a given sentence. Unlike previous methods mainly focusing on matching semantics between the sentence and different video segments, in this paper, we propose a novel semantic conditioned dynamic modulation (SCDM) mechanism, which leverages the sentence semantics to modulate the temporal convolution operations for better correlating and composing the sentence-relevant video contents over time. The proposed SCDM also performs dynamically with respect to the diverse video contents so as to establish a precise semantic alignment between sentence and video. By coupling the proposed SCDM with a hierarchical temporal convolutional architecture, video segments with various temporal scales are composed and localized. Besides, more fine-grained clip-level actionness scores are also predicted with the SCDM-coupled temporal convolution on the bottom layer of the overall architecture, which are further used to adjust the temporal boundaries of the localized segments and thereby lead to more accurate grounding results. Experimental results on benchmark datasets demonstrate that the proposed model can improve the temporal grounding accuracy consistently, and further investigation experiments also illustrate the advantages of SCDM on stabilizing the model training and associating relevant video contents for temporal sentence grounding. Our code for this paper is available at https://github.com/yytzsy/SCDM-TPAMI.	[Yuan, Yitian] Tsinghua Univ, Tsinghua Berkeley Shenzhen Inst, Beijing 100084, Peoples R China; [Ma, Lin] Meituan, Beijing 100084, Peoples R China; [Wang, Jingwen; Liu, Wei] Tencent AI Lab, Shenzhen 518000, Guandong, Peoples R China; [Zhu, Wenwu] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China	Tsinghua University; Tencent; Tsinghua University	Zhu, WW (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	yyt18@mails.tsinghua.edu.cn; forest.linma@gmail.com; jaywongjaywong@gmail.com; wl2223@columbia.edu; yyt18@mails.tsinghua.edu.cn	Wang, Jin/GYA-2019-2022; wang, jing/GRS-7509-2022; wang, jing/GVT-8700-2022	Yuan, Yitian/0000-0001-8701-7689	National Key Research and Development Program of China [2020AAA0106300, 2018AAA0102000]; National Natural Science Foundation of China Major Project [U1611461]; Shenzhen Nanshan District Ling-Hang Team Grant; Tencent Elite Internship Program	National Key Research and Development Program of China; National Natural Science Foundation of China Major Project(National Natural Science Foundation of China (NSFC)); Shenzhen Nanshan District Ling-Hang Team Grant; Tencent Elite Internship Program	This work was supported by the National Key Research and Development Program of China (No. 2020AAA0106300, 2018AAA0102000), National Natural Science Foundation of China Major Project (No. U1611461) and Shenzhen Nanshan District Ling-Hang Team Grant under No.LHTD20170005. Yitian Yuan is partially supported by the Tencent Elite Internship Program.	Bojanowski P, 2015, IEEE I CONF COMP VIS, P4462, DOI 10.1109/ICCV.2015.507; Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chen JY, 2019, AAAI CONF ARTIF INTE, P8175; Chen Jingyuan, 2018, P C EMP METH NAT LAN, P162; Chen SX, 2019, AAAI CONF ARTIF INTE, P8199; Chen ZF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1884; De Brabandere B, 2016, ADV NEUR IN, V29; de Vries H., 2017, ADV NEUR IN, P6594; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Dumoulin Vincent, 2017, ICLR; Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P55, DOI 10.1007/978-3-030-01264-9_4; Feng Y, 2019, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2019.00138; Gao JY, 2017, IEEE I CONF COMP VIS, P5277, DOI 10.1109/ICCV.2017.563; Gavrilyuk K, 2018, PROC CVPR IEEE, P5958, DOI 10.1109/CVPR.2018.00624; Ge RZ, 2019, IEEE WINT CONF APPL, P245, DOI 10.1109/WACV.2019.00032; Ha David, 2017, ICLR; Hahn M., 2020, P BRIT MACH VIS C; Hendricks LA, 2017, IEEE I CONF COMP VIS, P5804, DOI 10.1109/ICCV.2017.618; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Kipf T.N., 2017, 5 INT C LEARN REPRES, P1; Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83; Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1; Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343; Liu M, 2018, ACM/SIGIR PROCEEDINGS 2018, P15, DOI 10.1145/3209978.3210003; Liu Y, 2019, PROC CVPR IEEE, P3599, DOI 10.1109/CVPR.2019.00372; Naim I, 2014, AAAI CONF ARTIF INTE, P1558; Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; Platanios Emmanouil Antonios, 2018, P 2018 C EMP METH NA, P425, DOI DOI 10.18653/V1/D18-1039; Regneri M., 2013, TACL, V1, P25, DOI DOI 10.1162/TACL_A_00207; Ren S., 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.169; Rodriguez Cristian, 2020, WACV, P2464; Santurkar S, 2018, ADV NEUR IN, V31; Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31; Simonyan K., 2015, INT C LEARN REPR ICL; Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Tapaswi M, 2015, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2015.7298792; Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang L., 2014, ACTION RECOGNITION D; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wu AM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1029; Xiong Y., 2017, ARXIV 170302716; Xu HJ, 2019, IEEE ANTENNAS PROP, P7, DOI 10.1109/APUSNCURSINRSM.2019.8888924; Yang B, 2019, ADV NEUR IN, V32; Yuan J, 2016, PROC CVPR IEEE, P3093, DOI 10.1109/CVPR.2016.337; Yuan YT, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2332, DOI 10.1145/3343031.3350985; Zhang D, 2019, PROC CVPR IEEE, P1247, DOI 10.1109/CVPR.2019.00134	51	0	1	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2725	2741		10.1109/TPAMI.2020.3038993	http://dx.doi.org/10.1109/TPAMI.2020.3038993			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33206601	Green Submitted			2022-12-18	WOS:000792921400037
J	Palazzi, A; Bergamini, L; Calderara, S; Cucchiara, R				Palazzi, Andrea; Bergamini, Luca; Calderara, Simone; Cucchiara, Rita			Warp and Learn: Novel Views Generation for Vehicles and Other Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Vehicle novel view generation; novel viewpoint synthesis; texture transfer; shape transfer; semi-parametric	IMAGE SYNTHESIS; NETWORKS	In this article we introduce a new self-supervised, semi-parametric approach for synthesizing novel views of a vehicle starting from a single monocular image. Differently from parametric (i.e., entirely learning-based) methods, we show how a-priori geometric knowledge about the object and the 3D world can be successfully integrated into a deep learning based image generation framework. As this geometric component is not learnt, we call our approach semi-parametric. In particular, we exploit man-made object symmetry and piece-wise planarity to integrate rich a-priori visual information into the novel viewpoint synthesis process. An Image Completion Network (ICN) is then trained to generate a realistic image starting from this geometric guidance. This careful blend between parametric and non-parametric components allows us to i) operate in a real-world scenario, ii) preserve high-frequency visual information such as textures, iii) handle truly arbitrary 3D roto-translations of the input, and iv) perform shape transfer to completely different 3D models. Eventually, we show that our approach can be easily complemented with synthetic data and extended to other rigid objects with completely different topology, even in presence of concave structures and holes (e.g., chairs). A comprehensive experimental analysis against state-of-the-art competitors shows the efficacy of our method both from a quantitative and a perceptive point of view.	[Palazzi, Andrea; Bergamini, Luca; Calderara, Simone; Cucchiara, Rita] Univ Modena & Reggio Emilia, I-41121 Modena, Italy	Universita di Modena e Reggio Emilia	Palazzi, A (corresponding author), Univ Modena & Reggio Emilia, I-41121 Modena, Italy.	andrea.palazzi@unimore.it; luca.bergamini24@unimore.it; simone.calderara@unimore.it; rita.cucchiara@unimore.it	calderara, simone/M-6932-2015	calderara, simone/0000-0001-9056-1538	MIUR PRIN project "PREVUE: PRediction of activities and Events by Vision in an Urban Environment" [E94I19000650001]	MIUR PRIN project "PREVUE: PRediction of activities and Events by Vision in an Urban Environment"	This work was supported by MIUR PRIN project "PREVUE: PRediction of activities and Events by Vision in an Urban Environment", under Grant E94I19000650001.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Marin-Reyes PA, 2018, IEEE COMPUT SOC CONF, P166, DOI 10.1109/CVPRW.2018.00030; Arjovsky M, 2017, PR MACH LEARN RES, V70; Ba J., 2017, P 3 INT C LEARN REPR; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); BUNDESEN C, 1975, J EXP PSYCHOL HUMAN, V1, P214, DOI 10.1037/0096-1523.1.3.214; Chang Angel X., 2015, ARXIV151203012CSGR P; Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238; Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168; Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470; Chen X, 2019, IEEE I CONF COMP VIS, P4089, DOI 10.1109/ICCV.2019.00419; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Esser P, 2018, PROC CVPR IEEE, P8857, DOI 10.1109/CVPR.2018.00923; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Feng D, 2018, IEEE INT C INTELL TR, P3266, DOI 10.1109/ITSC.2018.8569814; Gardner H.E., 2011, FRAMES MIND THEORY M, V3rd; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Hedman P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982420; Hensel M, 2017, ADV NEUR IN, V30; Huang XY, 2018, IEEE COMPUT SOC CONF, P1067, DOI 10.1109/CVPRW.2018.00141; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Isola P, 2013, IEEE I CONF COMP VIS, P3048, DOI 10.1109/ICCV.2013.457; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kingma D.P, P 3 INT C LEARNING R; Lalonde JF, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239454, 10.1145/1276377.1276381]; Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372; Liu WL, 2017, NEURAL PLAST, V2017, DOI 10.1155/2017/9545646; Liu XC, 2016, IEEE INT CON MULTI; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Lucic M., 2018, ADV NEUR IN, P698; Ma LQ, 2017, ADV NEUR IN, V30; Mirza M., 2014, ARXIV PREPRINT ARXIV; Oechsle M, 2019, IEEE I CONF COMP VIS, P4530, DOI 10.1109/ICCV.2019.00463; Olszewski K, 2019, IEEE I CONF COMP VIS, P7647, DOI 10.1109/ICCV.2019.00774; Ortiz-Cayon R, 2016, INT CONF 3D VISION, P286, DOI 10.1109/3DV.2016.37; Ortiz-Cayon R, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P469, DOI 10.1109/3DV.2015.59; Palazzi A., 2018, P 2 WORKSH 3D REC ME, P702; Park E, 2017, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2017.82; Pavlakos G., 2017, P IEEE INT C ROB AUT, V2017, P2011, DOI [10.1109/ICRA.2017.7989233, DOI 10.1109/ICRA.2017.7989233]; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Rematas K, 2017, IEEE T PATTERN ANAL, V39, P1576, DOI 10.1109/TPAMI.2016.2601093; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210; SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701; Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504; Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359; Sinha A, 2017, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2017.91; Sitzmann V, 2019, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2019.00254; Sun SH, 2018, LECT NOTES COMPUT SC, V11207, P162, DOI 10.1007/978-3-030-01219-9_10; Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314; Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20; Teichmann M, 2018, IEEE INT VEH SYM, P1013; Nguyen-Phuoc T, 2019, IEEE I CONF COMP VIS, P7587, DOI 10.1109/ICCV.2019.00768; Tulsiani S, 2015, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2015.7298758; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wang ZD, 2017, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2017.49; Wu JJ, 2018, INT J COMPUT VISION, V126, P1009, DOI 10.1007/s11263-018-1074-6; Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882; Xiang Y, 2016, LECT NOTES COMPUT SC, V9912, P160, DOI 10.1007/978-3-319-46484-8_10; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Xiao FY, 2019, IEEE I CONF COMP VIS, P7012, DOI 10.1109/ICCV.2019.00711; Yang Jimei, 2015, NIPS; Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388; Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629; Zhao B, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P383, DOI 10.1145/3240508.3240536; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zhou Qian-Yi, 2018, ARXIV180109847; Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; ZHU JY, 2018, ADV NEURAL INFORM PR	79	0	0	2	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2216	2227		10.1109/TPAMI.2020.3030701	http://dx.doi.org/10.1109/TPAMI.2020.3030701			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33048673	hybrid, Green Submitted			2022-12-18	WOS:000764815300040
J	Plummer, BA; Shih, K; Li, YC; Xu, K; Lazebnik, S; Sclaroff, S; Saenko, K				Plummer, Bryan Allen; Shih, Kevin; Li, Yichen; Xu, Ke; Lazebnik, Svetlana; Sclaroff, Stan; Saenko, Kate			Revisiting Image-Language Networks for Open-Ended Phrase Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Grounding; Visualization; Feature extraction; Benchmark testing; Detectors; Vocabulary; Vision and language; phrase grounding; object detection; representation learning		Most existing work that grounds natural language phrases in images starts with the assumption that the phrase in question is relevant to the image. In this paper we address a more realistic version of the natural language grounding task where we must both identify whether the phrase is relevant to an image and localize the phrase. This can also be viewed as a generalization of object detection to an open-ended vocabulary, introducing elements of few- and zero-shot detection. We propose an approach for this task that extends Faster R-CNN to relate image regions and phrases. By carefully initializing the classification layers of our network using canonical correlation analysis (CCA), we encourage a solution that is more discerning when reasoning between similar phrases, resulting in over double the performance compared to a naive adaptation on three popular phrase grounding datasets, Flickr30K Entities, ReferIt Game, and Visual Genome, with test-time phrase vocabulary sizes of 5K, 32K, and 159K, respectively.	[Plummer, Bryan Allen; Li, Yichen; Sclaroff, Stan; Saenko, Kate] Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA; [Shih, Kevin] NVIDIA Corp, Santa Clara, CA 95051 USA; [Xu, Ke; Lazebnik, Svetlana] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Boston University; Nvidia Corporation; University of Illinois System; University of Illinois Urbana-Champaign	Plummer, BA (corresponding author), Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA.	bplum@bu.edu; kshih@nvidia.com; liych@bu.edu; kexu6@illinois.edu; slazebni@illinois.edu; sclaroff@bu.edu; saenko@bu.edu		Sclaroff, Stanley/0000-0002-0711-4313; Saenko, Kate/0000-0002-7564-7218; Xu, Ke/0000-0002-2935-8968	DARPA; NSF [IIS-1724237, CNS-1629700, CCF-1723379, IIS-1718221, IIS-1563727]; Amazon Research Award; AWS ML Research Award; Google Faculty Award	DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); NSF(National Science Foundation (NSF)); Amazon Research Award; AWS ML Research Award; Google Faculty Award(Google Incorporated)	This work was supported in part by the DARPA and NSF awards IIS-1724237, CNS-1629700, CCF-1723379, IIS-1718221, IIS-1563727, an Amazon Research Award and AWS ML Research Award, and Google Faculty Award. The authors would like to thank Karen Livescu for helpful discussions.	Acharya M., 2019, P C N AM CHAPT ASS C, P1955; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Andrew Galen, 2013, ICML; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bajaj M, 2019, IEEE I CONF COMP VIS, P4280, DOI 10.1109/ICCV.2019.00438; Bojanowski P, 2015, IEEE I CONF COMP VIS, P4462, DOI 10.1109/ICCV.2015.507; Burns A, 2019, IEEE I CONF COMP VIS, P7473, DOI 10.1109/ICCV.2019.00757; Chen K, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P23, DOI 10.1145/3078971.3078976; Chen K, 2017, IEEE I CONF COMP VIS, P824, DOI 10.1109/ICCV.2017.95; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devlin J., 2018, P 2019 C N AM CHAPTE, P4171, DOI DOI 10.18653/V1/N19-1423DIEZPF; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Fukui Akira, 2016, ARXIV160601847; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Grubinger M, 2006, IAPR TC 12 BENCHMARK; Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550; Hinami R., 2018, P 2018 C EMP METH NA, P2605; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, P787, DOI DOI 10.3115/V1/D14-1086; Klein E, 2015, PROC CVPR IEEE, P4437, DOI 10.1109/CVPR.2015.7299073; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu CX, 2017, AAAI CONF ARTIF INTE, P4176; Liu JY, 2017, IEEE I CONF COMP VIS, P4866, DOI 10.1109/ICCV.2017.520; Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51; Luo RT, 2017, PROC CVPR IEEE, P3125, DOI 10.1109/CVPR.2017.333; Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9; Mikolov T., 2013, EFFICIENT ESTIMATION, P1, DOI DOI 10.48550/ARXIV.1301.3781; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Misra I, 2016, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2016.320; Plummer BA, 2018, LECT NOTES COMPUT SC, V11216, P258, DOI 10.1007/978-3-030-01258-8_16; Plummer BA, 2017, IEEE I CONF COMP VIS, P1946, DOI 10.1109/ICCV.2017.213; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49; Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541; Wang MZ, 2016, LECT NOTES COMPUT SC, V9912, P696, DOI 10.1007/978-3-319-46484-8_42; WangDH LiJK, 2017, TRANSPORTMETRICA B T, P1; Wehrmann J, 2018, PROC CVPR IEEE, P7718, DOI 10.1109/CVPR.2018.00805; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang ZY, 2019, IEEE I CONF COMP VIS, P4682, DOI 10.1109/ICCV.2019.00478; Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524; Yeh R., 2017, P NIPS; Young Peter, 2014, T ASSOC COMPUT LING, V2, P67; Zhang YT, 2017, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2017.122	54	0	0	5	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2155	2167		10.1109/TPAMI.2020.3029008	http://dx.doi.org/10.1109/TPAMI.2020.3029008			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33021939	Green Submitted			2022-12-18	WOS:000764815300036
J	Wang, CC; Wang, YZ; Yu, GQ				Wang, Congchao; Wang, Yizhi; Yu, Guoqiang			Efficient Global MOT Under Minimum-Cost Circulation Framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Complexity theory; Search problems; Computational modeling; Data models; Detectors; Inference algorithms; History; Minimum-cost circulation; overwhelming unit-vertex-capacity graph; data association; object tracking	OBJECT TRACKING; ASSOCIATION; ALGORITHM	We developed a minimum-cost circulation framework for solving the global data association problem, which plays a key role in the tracking-by-detection paradigm of multi-object tracking (MOT). The global data association problem was extensively studied under the minimum-cost flow framework, which is theoretically attractive as being flexible and globally solvable. However, the high computational burden has been a long-standing obstacle to its wide adoption in practice. While enjoying the same theoretical advantages and maintaining the same optimal solution as the minimum-cost flow framework, our new framework has a better theoretical complexity bound and leads to orders of practical efficiency improvement. This new framework is motivated by the observation that minimum-cost flow only partially models the data association problem and it must be accompanied by an additional and time-consuming searching scheme to determine the optimal object number. By employing a minimum-cost circulation framework, we eliminate the searching step and naturally integrate the number of objects into the optimization problem. By exploring the special property of the associated graph, that is, an overwhelming majority of the vertices are with unit capacity, we designed an implementation of the framework and proved it has the best theoretical computational complexity so far for the global data association problem. We evaluated our method with 40 experiments on five MOT benchmark datasets. Our method was always the most efficient in every single experiment and averagely 53 to 1,192 times faster than the three state-of-the-art methods. When our method served as a sub-module for global data association methods utilizing higher-order constraints, similar running time improvement was attained. We further illustrated through several case studies how the improved computational efficiency enables more sophisticated tracking models and yields better tracking accuracy. We made the source code publicly available on GitHub with both Python and MATLAB interfaces.	[Wang, Congchao; Wang, Yizhi; Yu, Guoqiang] Virginia Tech, Bradley Dept Elect & Comp Engn, Arlington, VA 22203 USA	Virginia Polytechnic Institute & State University	Yu, GQ (corresponding author), Virginia Tech, Bradley Dept Elect & Comp Engn, Arlington, VA 22203 USA.	ccwang@vt.edu; yzwang@vt.edu; yug@vt.edu		Yu, Guoqiang/0000-0002-6743-7413	 [NIHR01MH110504];  [NSF 1750931]	; 	The authors would like to thank the anonymous reviewers for their helpful suggestions. This work was supported by Grants NIHR01MH110504 and NSF 1750931.	Ahuja R. K., 1993, NETWORK FLOWS THEORY; Amat F, 2014, NAT METHODS, V11, P951, DOI [10.1038/NMETH.3036, 10.1038/nmeth.3036]; Ben Shitrit H, 2011, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2011.6126235; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Chenouard N, 2014, NAT METHODS, V11, P281, DOI 10.1038/nmeth.2808; Choi WG, 2015, IEEE I CONF COMP VIS, P3029, DOI 10.1109/ICCV.2015.347; Dendorfer P., 2019, ARXIV190604567CS; Emami P., 2018, ARXIV PREPRINT ARXIV; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Feng Weitao, 2019, ARXIV190106129; FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Goldberg A. V., 1991, NETWORK FLOWS MATCHI, P157; Goldberg AV, 2017, THEOR COMPUT SYST, V61, P987, DOI 10.1007/s00224-017-9776-7; Goldberg AV, 2015, LEIBNIZ INT PR INFOR, V30, P406, DOI 10.4230/LIPIcs.STACS.2015.406; Goldberg AV, 1997, J ALGORITHM, V22, P1, DOI 10.1006/jagm.1995.0805; Heili A, 2014, IEEE T IMAGE PROCESS, V23, P3040, DOI 10.1109/TIP.2014.2324292; Henschel Roberto, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P770, DOI 10.1109/CVPRW.2019.00105; Henschel R, 2018, IEEE COMPUT SOC CONF, P1509, DOI 10.1109/CVPRW.2018.00192; Hou J, 2019, ARXIV190712176; Leal-Taixe Laura, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P120, DOI 10.1109/ICCVW.2011.6130233; Leal-Taixe Laura, 2017, ARXIV170402781; Lenz P, 2015, IEEE I CONF COMP VIS, P4364, DOI 10.1109/ICCV.2015.496; McDole K, 2018, CELL, V175, P859, DOI 10.1016/j.cell.2018.09.031; Milan A., 2016, MOT16 BENCHMARK MULT; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Ren J, 2017, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2017.87; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Schulter S, 2017, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2017.292; Sharma S, 2018, IEEE INT CONF ROBOT, P3508; Shi XC, 2019, INT J COMPUT VISION, V127, P1063, DOI 10.1007/s11263-018-01147-z; Stiefelhagen R, 2007, LECT NOTES COMPUT SC, V4122, P1; Wang SF, 2017, PR MACH LEARN RES, V54, P1132; Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Xi ZH, 2015, J INTELL FUZZY SYST, V29, P2059, DOI 10.3233/IFS-151683; Xi ZH, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013009; Xing J., 2014, ARXIV PREPRINT ARXIV; Xinshuo W., 2019, ARXIV190703961; Yoon Y., 2019, ARXIV190700831; Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742	50	0	0	6	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1888	1904		10.1109/TPAMI.2020.3026257	http://dx.doi.org/10.1109/TPAMI.2020.3026257			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	32966213	Green Accepted, hybrid			2022-12-18	WOS:000764815300018
J	Wu, ZY; Wang, HT; Wang, ZW; Jin, HL; Wang, ZY				Wu, Zhenyu; Wang, Haotao; Wang, Zhaowen; Jin, Hailin; Wang, Zhangyang			Privacy-Preserving Deep Action Recognition: An Adversarial Learning Framework and A New Dataset	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Privacy; Data privacy; Videos; Task analysis; Visualization; Cryptography; Training; Visual privacy; action recognition; privacy-preserving learning; adversarial learning		We investigate privacy-preserving, video-based action recognition in deep learning, a problem with growing importance in smart camera applications. A novel adversarial training framework is formulated to learn an anonymization transform for input videos such that the trade-off between target utility task performance and the associated privacy budgets is explicitly optimized on the anonymized videos. Notably, the privacy budget, often defined and measured in task-driven contexts, cannot be reliably indicated using any single model performance because strong protection of privacy should sustain against any malicious model that tries to steal private information. To tackle this problem, we propose two new optimization strategies of model restarting and model ensemble to achieve stronger universal privacy protection against any attacker models. Extensive experiments have been carried out and analyzed. On the other hand, given few public datasets available with both utility and privacy labels, the data-driven (supervised) learning cannot exert its full power on this task. We first discuss an innovative heuristic of cross-dataset training and evaluation, enabling the use of multiple single-task datasets (one with target task labels and the other with privacy labels) in our problem. To further address this dataset challenge, we have constructed a new dataset, termed PA-HMDB51, with both target task labels (action) and selected privacy attributes (skin color, face, gender, nudity, and relationship) annotated on a per-frame basis. This first-of-its-kind video dataset and evaluation protocol can greatly facilitate visual privacy research and open up other opportunities. Our codes, models, and the PA-HMDB51 dataset are available at: https://github.com/VITA-Group/PA-HMDB51	[Wu, Zhenyu] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77840 USA; [Wang, Haotao; Wang, Zhaowen] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA; [Jin, Hailin; Wang, Zhangyang] Adobe Res, San Jose, CA 95110 USA	Texas A&M University System; Texas A&M University College Station; University of Texas System; University of Texas Austin; Adobe Systems Inc.	Wang, ZY (corresponding author), Adobe Res, San Jose, CA 95110 USA.	wuzhenyu_sjtu@tamu.edu; htwang@utexas.edu; zhawang@adobe.com; hljin@adobe.com; atlaswang@utexas.edu		Wu, Zhenyu/0000-0002-7183-6943	NSF [RI-1755701]	NSF(National Science Foundation (NSF))	The work of Z. Wu, H. Wang, and Z. Wang was supported in part by NSF Award RI-1755701. The authors would like to sincerely thank Scott Hoang, James Ault, and Prateek Shroff for assisting the labeling of the PA-HMDB51 dataset. Zhenyu Wuand Haotao Wang contributed equally to this work.	Bertran M, 2019, PR MACH LEARN RES, V97; Brewster T., 2019, 1000 BANNED CHINESE; Butler DJ, 2015, ACMIEEE INT CONF HUM, P27, DOI 10.1145/2696454.2696484; Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698; Chattopadhyay A., 2007, 2007 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2007.383413, DOI 10.1109/CVPR.2007.383413]; Cheng BW, 2017, INT CONF AFFECT, P65; Dai J, 2015, IEEE IMAGE PROC, P4238, DOI 10.1109/ICIP.2015.7351605; Desjardins G., 2012, ARXIV12105474; Dosovitskiy A, 2016, PROC CVPR IEEE, P4829, DOI 10.1109/CVPR.2016.522; Du D.-Z., 2013, MINIMAX APPL; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440; Gonzalez-Garcia A, 2018, ADV NEUR IN, V31; Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633; Gurari D, 2019, PROC CVPR IEEE, P939, DOI 10.1109/CVPR.2019.00103; Hamm J., 2018, P 35 INT C MACH LEAR, P3000; Harwell D., 2019, DOORBELL CAMERA FIRM; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Howard A. G., 2017, MOBILENETS EFFICIENT; Jia L, 2014, IEEE T IND INFORM, V10, P689, DOI 10.1109/TII.2013.2251892; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kato H, 2014, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2014.127; Kay W., 2017, ARXIV PREPRINT ARXIV; Kingma D.P., 2015, P ICLR; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Leenes R, 2017, DATA PROTECTION PRIV; Li YF, 2017, IEEE COMPUT SOC CONF, P1343, DOI 10.1109/CVPRW.2017.176; Lu C. H. Donna, 2019, ABUSERS ARE EXPLOITI; Mahendran A, 2016, INT J COMPUT VISION, V120, P233, DOI 10.1007/s11263-016-0911-8; McPherson R., 2016, 160900408CSCR ARXIV; Oh SJ, 2017, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2017.165; Oh SJ, 2016, LECT NOTES COMPUT SC, V9907, P19, DOI 10.1007/978-3-319-46487-9_2; Oleszkiewicz W, 2019, LECT NOTES COMPUT SC, V11365, P482, DOI 10.1007/978-3-030-20873-8_31; Orekondy T, 2017, IEEE I CONF COMP VIS, P3706, DOI 10.1109/ICCV.2017.398; Pittaluga F, 2019, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2019.00023; Pittaluga F, 2019, IEEE WINT CONF APPL, P791, DOI 10.1109/WACV.2019.00089; Pittaluga F, 2017, IEEE T PATTERN ANAL, V39, P2215, DOI 10.1109/TPAMI.2016.2637354; Pittaluga F, 2015, PROC CVPR IEEE, P314, DOI 10.1109/CVPR.2015.7298628; Reddy S, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1815, DOI 10.1145/2939672.2939850; Ren ZZ, 2018, LECT NOTES COMPUT SC, V11205, P639, DOI 10.1007/978-3-030-01246-5_38; Roy PC, 2019, PROC CVPR IEEE, P2581, DOI 10.1109/CVPR.2019.00269; Ryoo MS, 2017, AAAI CONF ARTIF INTE, P4255; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Soomro K., 2012, ARXIV; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; T. U. S. D. of Homeland Security, 2004, PASS NAM REC AGR; Tao S, 2012, SENSORS-BASEL, V12, P16920, DOI 10.3390/s121216920; TechCrunch, 2017, AM CAM EQ ECH LOOK R; Tobias M. W., 2016, IS YOUR SMART SECURI; Uplavikar P.M, 2019, CVPR WORKSHOPS, P1, DOI [https://doi.org/10.48550/580ARXIV.1905.13342, DOI 10.48550/580ARXIV.1905.13342]; Wang TL, 2019, IEEE I CONF COMP VIS, P5309, DOI 10.1109/ICCV.2019.00541; Wang ZY, 2016, PROC CVPR IEEE, P4792, DOI 10.1109/CVPR.2016.518; Wang Z, 2019, IEEE CONF COMPU INTE, DOI 10.1109/CVPRW.2019.00007; Weinzaepfel P, 2011, PROC CVPR IEEE, P337, DOI 10.1109/CVPR.2011.5995616; Weiss M. A., 2016, US EU DATA PRIVACY S; Winkler T, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P159, DOI 10.1109/AVSS.2014.6918661; Wu ZY, 2019, IEEE I CONF COMP VIS, P1201, DOI 10.1109/ICCV.2019.00129; Wu ZY, 2018, LECT NOTES COMPUT SC, V11220, P627, DOI 10.1007/978-3-030-01270-0_37; Xiang X, 2018, IEEE T CIRC SYST VID, V28, P3539, DOI 10.1109/TCSVT.2017.2771150; Xie P., 2014, ARXIV14126181; Xu MZ, 2018, IEEE WINT CONF APPL, P1597, DOI 10.1109/WACV.2018.00178; Yun Kiwon, 2012, 2012 IEEE COMP SOC C, P28; Zhang BH, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P335, DOI 10.1145/3278721.3278779; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	68	0	0	5	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2126	2139		10.1109/TPAMI.2020.3026709	http://dx.doi.org/10.1109/TPAMI.2020.3026709			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	32986544	Green Submitted			2022-12-18	WOS:000764815300034
J	Zhu, Z; Mittendorf, A; Shropshire, E; Allen, B; Miller, C; Bashir, MR; Mazurowski, MA				Zhu, Zhe; Mittendorf, Amber; Shropshire, Erin; Allen, Brian; Miller, Chad; Bashir, Mustafa R.; Mazurowski, Maciej A.			3D Pyramid Pooling Network for Abdominal MRI Series Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Magnetic resonance imaging; Biomedical imaging; Three-dimensional displays; Liver; Task analysis; Convolutional neural networks; Annotations; Magnetic resonance imaging (MRI); Abdominal MRI series; 3D pyramid pooling network	DEEP; STYLE	Recognizing and organizing different series in an MRI examination is important both for clinical review and research, but it is poorly addressed by the current generation of picture archiving and communication systems (PACSs) and post-processing workstations. In this paper, we study the problem of using deep convolutional neural networks for automatic classification of abdominal MRI series to one of many series types. Our contributions are three-fold. First, we created a large abdominal MRI dataset containing 3717 MRI series including 188,665 individual images, derived from liver examinations. 30 different series types are represented in this dataset. The dataset was annotated by consensus readings from two radiologists. Both the MRIs and the annotations were made publicly available. Second, we proposed a 3D pyramid pooling network, which can elegantly handle abdominal MRI series with varied sizes of each dimension, and achieved state-of-the-art classification performance. Third, we performed the first ever comparison between the algorithm and the radiologists on an additional dataset and had several meaningful findings.	[Zhu, Zhe; Mittendorf, Amber; Shropshire, Erin; Allen, Brian; Miller, Chad; Bashir, Mustafa R.] Duke Univ, Dept Radiol, Durham, NC 27708 USA; [Mazurowski, Maciej A.] Duke Univ, Dept Radiol Elect & Comp Engn & Biostat & Bioinfo, Durham, NC 27708 USA	Duke University; Duke University	Zhu, Z (corresponding author), Duke Univ, Dept Radiol, Durham, NC 27708 USA.	zhe.zhu@duke.edu; amber.mittendorf@duke.edu; erin.shropshire@duke.edu; brian.allen@duke.edu; chad.miller@duke.edu; mustafa.bashir@duke.edu; maciej.mazurowski@duke.edu						Aarti Bagul, 2017, Arxiv, DOI arXiv:1711.05225; Albertina B., 2016, **DATA OBJECT**, DOI [10.7937/K9/ TCIA.2016.JGNIHEP5, DOI 10.7937/K9/TCIA.2016.JGNIHEP5]; [Anonymous], 2016, MED DATA MACH LEARN; Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; Chu WT, 2018, IEEE T MULTIMEDIA, V20, P2491, DOI 10.1109/TMM.2018.2801718; Chu Wei-Ta, 2016, ACM INT C MULTIMEDIA, P402; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Depeursinge A, 2012, COMPUT MED IMAG GRAP, V36, P227, DOI 10.1016/j.compmedimag.2011.07.003; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Dumoulin Vincent, 2016, ARXIV161007629; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hinton G, 2018, JAMA-J AM MED ASSOC, V320, P1101, DOI 10.1001/jama.2018.11100; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Howard A. G., 2017, MOBILENETS EFFICIENT; Huang HZ, 2017, PROC CVPR IEEE, P7044, DOI 10.1109/CVPR.2017.745; Iandola Forrest, 2017, 2017 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), DOI 10.1145/3125502.3125606; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Karayev Sergey, 2014, P BRIT MACH VIS C, DOI 10.5244/C.28.122; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kohli MD, 2017, J DIGIT IMAGING, V30, P392, DOI 10.1007/s10278-017-9976-3; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; LeCun Y., 2015, NAT METHODS, V521, P436, DOI [10.1038/nature14539, DOI 10.1038/nmeth.3707, DOI 10.1038/nature14539]; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Poplin R, 2018, NAT BIOMED ENG, V2, P158, DOI 10.1038/s41551-018-0195-0; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920; Simonyan K., 2015, ICLR; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tarvainen J, 2014, IEEE T MULTIMEDIA, V16, P2085, DOI 10.1109/TMM.2014.2357688; Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273; Ulyanov D, 2016, PR MACH LEARN RES, V48; Wang P, 2017, IEEE T CIRC SYST VID, V27, P2613, DOI 10.1109/TCSVT.2016.2576761; Wang Y, 2016, IEEE T MULTIMEDIA, V18, P1869, DOI 10.1109/TMM.2016.2581580; Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226	41	0	0	4	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1688	1698		10.1109/TPAMI.2020.3033990	http://dx.doi.org/10.1109/TPAMI.2020.3033990			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33112740				2022-12-18	WOS:000764815300005
J	Feng, JY; Li, SY; Li, X; Wu, F; Tian, Q; Yang, MH; Ling, HB				Feng, Junyi; Li, Songyuan; Li, Xi; Wu, Fei; Tian, Qi; Yang, Ming-Hsuan; Ling, Haibin			TapLab: A Fast Framework for Semantic Video Segmentation Tapping Into Compressed-Domain Knowledge	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; Semantics; Streaming media; Motion segmentation; Real-time systems; Task analysis; Feature extraction; Semantic video segmentation; real-time; compressed domain		Real-time semantic video segmentation is a challenging task due to the strict requirements of inference speed. Recent approaches mainly devote great efforts to reducing the model size for high efficiency. In this paper, we rethink this problem from a different viewpoint: using knowledge contained in compressed videos. We propose a simple and effective framework, dubbed TapLab, to tap into resources from the compressed domain. Specifically, we design a fast feature warping module using motion vectors for acceleration. To reduce the noise introduced by motion vectors, we design a residual-guided correction module and a residual-guided frame selection module using residuals. TapLab significantly reduces redundant computations of the state-of-the-art fast semantic image segmentation models, running 3 to 10 times faster with controllable accuracy degradation. The experimental results show that TapLab achieves 70.6 percent mIoU on the Cityscapes dataset at 99.8 FPS with a single GPU card for the 1024x2048 videos. A high-speed version even reaches the speed of 160+ FPS. Code will be available soon at https://github.com/Sixkplus/TapLab.	[Feng, Junyi; Li, Songyuan; Li, Xi; Wu, Fei] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China; [Tian, Qi] Huawei Noahs Ark Lab, Beijing 100032, Peoples R China; [Yang, Ming-Hsuan] Univ Calif Merced, Elect Engn & Comp Sci, Merced, CA 95344 USA; [Ling, Haibin] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	Zhejiang University; Huawei Technologies; University of California System; University of California Merced; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Li, X (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China.	fengjunyi@zju.edu.cn; leizungjyun@zju.edu.cn; xilizju@zju.edu.cn; wufei@cs.zju.edu.cn; tian.qi1@huawei.com; mhyang@ucmerced.edu; haibin.ling@gmail.com	Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304	key scientific and technological innovation research project by the Ministry of Education, Zhejiang Provincial Natural Science Foundation of China [LR19F020004]; Baidu AI Frontier Technology Joint Research Program; Zhejiang University K.P. Chao's High Technology Development Foundation	key scientific and technological innovation research project by the Ministry of Education, Zhejiang Provincial Natural Science Foundation of China; Baidu AI Frontier Technology Joint Research Program; Zhejiang University K.P. Chao's High Technology Development Foundation	This work was supported by a key scientific and technological innovation research project by the Ministry of Education, Zhejiang Provincial Natural Science Foundation of China under Grant LR19F020004, Baidu AI Frontier Technology Joint Research Program, and Zhejiang University K.P. Chao's High Technology Development Foundation. Junyi Feng and Songyuan Li contributed equally to this work.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chadha A, 2019, IEEE T CIRC SYST VID, V29, P475, DOI 10.1109/TCSVT.2017.2786999; Chadha A, 2017, IEEE IMAGE PROC, P1832; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326; Gadde R, 2017, IEEE I CONF COMP VIS, P4463, DOI 10.1109/ICCV.2017.477; Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jain S., 2018, P ECCV WORKSH VID SE; King DB, 2015, ACS SYM SER, V1214, P1; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090; Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975; Li YL, 2018, PROC CVPR IEEE, P5997, DOI 10.1109/CVPR.2018.00628; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu X, 2016, PROC CVPR IEEE, P3016, DOI 10.1109/CVPR.2016.329; Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34; Orsic M, 2019, PROC CVPR IEEE, P12599, DOI 10.1109/CVPR.2019.01289; Paszke A., 2016, ARXIV PREPRINT ARXIV; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Ronneberger O., 2015, INT C MED IM COMP CO, P234, DOI [10.1007/978-3-319-24574-4_28, DOI 10.1007/978-3-319-24574-4_28]; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shou Z, 2019, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2019.00136; Siam M, 2018, IEEE COMPUT SOC CONF, P700, DOI 10.1109/CVPRW.2018.00101; Sofokleous A, 2005, H 264 MPEG 4 VIDEO C; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Treml M., 2016, P NIPS WORKSH MLITS; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang ZL, 2019, IEEE T CIRC SYST VID, V29, P263, DOI 10.1109/TCSVT.2017.2761992; Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631; Wu Z., 2017, ARXIV171200213; Xu YS, 2018, PROC CVPR IEEE, P6556, DOI 10.1109/CVPR.2018.00686; Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064; Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544; Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441; Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068	52	0	0	6	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1591	1603		10.1109/TPAMI.2020.3024646	http://dx.doi.org/10.1109/TPAMI.2020.3024646			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32986542	Green Submitted			2022-12-18	WOS:000752018000037
J	Han, L; Gu, SY; Zhong, DW; Quan, SX; Fang, L				Han, Lei; Gu, Siyuan; Zhong, Dawei; Quan, Shuxue; Fang, Lu			Real-Time Globally Consistent Dense 3D Reconstruction With Online Texturing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Real-time 3D reconstruction; TSDF fusion; online texturing; SLAM; global consistency; CPU computing		High-quality reconstruction of 3D geometry and texture plays a vital role in providing immersive perception of the real world. Additionally, online computation enables the practical usage of 3D reconstruction for interaction. We present an RGBD-based globally-consistent dense 3D reconstruction approach, where high-quality (i.e., the spatial resolution of the RGB image) texture patches are mapped on high-resolution (<= 1 cm) geometric models online. The whole pipeline uses merely the CPU computing of a portable device. For real-time geometric reconstruction with online texturing, we propose to solve the texture optimization problem with a simplified incremental MRF solver in the context of geometric reconstruction pipeline using sparse voxel sampling strategy. An efficient reference-based color adjustment scheme is also proposed to achieve consistent texture patch colors under inconsistent luminance situations. Quantitative and qualitative experiments demonstrate that our online scheme achieves a realistic visualization of the environment with more abundant details, while taking fairly compact memory consumption and much lower computational complexity than existing solutions.	[Han, Lei; Gu, Siyuan; Zhong, Dawei; Fang, Lu] Tsinghua Univ, Beijing 100084, Peoples R China; [Quan, Shuxue] OPPO Res Ctr, Beijing, Peoples R China	Tsinghua University	Han, L (corresponding author), Tsinghua Univ, Beijing 100084, Peoples R China.	lhanaf@connect.ust.hk; ericgeesejet@gmail.com; zdw19@mails.tsinghua.edu.cn; quanshuxue@outlook.com; fanglu@tsinghua.edu.cn		Gu, Siyuan/0000-0002-8481-1999	Natural Science Foundation of China (NSFC) [61722209, 61860206003]; Shenzhen Science and Technology Research and Development Funds [JCYJ20180507183706645, ZDYBH201900000002]	Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Shenzhen Science and Technology Research and Development Funds	This work was supported in part by the Natural Science Foundation of China (NSFC) under contract No. 61722209 and 61860206003, in part by the Shenzhen Science and Technology Research and Development Funds (JCYJ20180507183706645 and ZDYBH201900000002). The authors would like to acknowledge Huawei Technologies for providing the 'toy' and 'human body' sequences in Figs. 9 and 10. Lei Han and Siyuan Gu contributed equally to this work.	Agathos A, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P139, DOI 10.1109/IM.2003.1240243; Bannai N, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P558; Beauchesne E., 2003, PROC IEEE COMPUT SOC, V2, pII; Bi S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073610; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Callieri M, 2008, COMPUT GRAPH-UK, V32, P464, DOI 10.1016/j.cag.2008.05.004; Chen QF, 2014, PROC CVPR IEEE, P3914, DOI 10.1109/CVPR.2014.500; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739; Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Foley James D, 1996, COMPUTER GRAPHICS PR, V12110; Fu YP, 2018, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2018.00488; Gal R, 2010, COMPUT GRAPH FORUM, V29, P479, DOI 10.1111/j.1467-8659.2009.01617.x; Han L, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV; Han L, 2019, IEEE T ROBOT, V35, P498, DOI 10.1109/TRO.2018.2882730; Han L, 2017, IEEE INT CON MULTI, P139, DOI 10.1109/ICME.2017.8019479; Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054; Kahler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891; Keller M, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P1, DOI 10.1109/3DV.2013.9; Klingensmith M, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI; Kokaram A., 2007, 4 EUR C VIS MED PROD, P1, DOI DOI 10.1049/CP:20070055; Lempitsky V, 2007, PROC CVPR IEEE, P829; Li W, 2019, IEEE WINT CONF APPL, P1413, DOI 10.1109/WACV.2019.00155; Li W, 2019, IEEE T VIS COMPUT GR, V25, P2296, DOI 10.1109/TVCG.2018.2831220; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Maier R, 2017, IEEE I CONF COMP VIS, P3133, DOI 10.1109/ICCV.2017.338; Maier R, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P536, DOI 10.1109/3DV.2015.66; Marschner S., 2015, FUNDAMENTALS COMPUTE; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374; Park JJ, 2018, INT CONF 3D VISION, P12, DOI 10.1109/3DV.2018.00013; Pitie F, 2007, COMPUT VIS IMAGE UND, V107, P123, DOI 10.1016/j.cviu.2006.11.011; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629; Schops T, 2020, IEEE T PATTERN ANAL, V42, P2494, DOI 10.1109/TPAMI.2019.2947048; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Thuerck D., 2016, HIGH PERFORMANCE GRA, P173; Troccoli A, 2008, INT J COMPUT VISION, V78, P261, DOI 10.1007/s11263-007-0100-x; Waechter M, 2014, LECT NOTES COMPUT SC, V8693, P836, DOI 10.1007/978-3-319-10602-1_54; Whelan T., 2012, PROC RSS WORKSHOP RG; Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI; Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237; Whelan T, 2013, IEEE INT CONF ROBOT, P5724, DOI 10.1109/ICRA.2013.6631400; Zeng M, 2013, GRAPH MODELS, V75, P126, DOI 10.1016/j.gmod.2012.09.002; Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24; Zhou QY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461919; Zhou QY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601134	47	0	0	8	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1519	1533		10.1109/TPAMI.2020.3021023	http://dx.doi.org/10.1109/TPAMI.2020.3021023			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32877330				2022-12-18	WOS:000752018000032
J	Ioannidis, VN; Chen, SH; Giannakis, GB				Ioannidis, Vassilis N.; Chen, Siheng; Giannakis, Georgios B.			Efficient and Stable Graph Scattering Transforms via Pruning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Scattering; Transforms; Feature extraction; Stability analysis; Perturbation methods; Convolution	WAVELET	Graph convolutional networks (GCNs) have well-documented performance in various graph learning tasks, but their analysis is still at its infancy. Graph scattering transforms (GSTs) offer training-free deep GCN models that extract features from graph data, and are amenable to generalization and stability analyses. The price paid by GSTs is exponential complexity in space and time that increases with the number of layers. This discourages deployment of GSTs when a deep architecture is needed. The present work addresses the complexity limitation of GSTs by introducing an efficient so-termed pruned (p)GST approach. The resultant pruning algorithm is guided by a graph-spectrum-inspired criterion, and retains informative scattering features on-the-fly while bypassing the exponential complexity associated with GSTs. Stability of the novel pGSTs is also established when the input graph data or the network structure are perturbed. Furthermore, the sensitivity of pGST to random and localized signal perturbations is investigated analytically and experimentally. Numerical tests showcase that pGST performs comparably to the baseline GST at considerable computational savings. Furthermore, pGST achieves comparable performance to state-of-the-art GCNs in graph and 3D point cloud classification tasks. Upon analyzing the pGST pruning patterns, it is shown that graph data in different domains call for different network architectures, and that the pruning algorithm may be employed to guide the design choices for contemporary GCNs.	[Ioannidis, Vassilis N.; Giannakis, Georgios B.] Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA; [Chen, Siheng] Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA	University of Minnesota System; University of Minnesota Twin Cities	Chen, SH (corresponding author), Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA.	ioann006@umn.edu; schen@merl.com; georgios@umn.edu			Mitsubishi Electric Research Laboratories; Doctoral Dissertation Fellowship of the University of Minnesota; NSF [171141, 1500713]	Mitsubishi Electric Research Laboratories; Doctoral Dissertation Fellowship of the University of Minnesota; NSF(National Science Foundation (NSF))	This work was supported by Mitsubishi Electric Research Laboratories, the Doctoral Dissertation Fellowship of the University of Minnesota, and the NSF Grants 171141 and 1500713.	Belkin M, 2006, J MACH LEARN RES, V7, P2399; Borgwardt KM, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P74, DOI 10.1109/ICDM.2005.132; Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418; Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Gama F., 2019, P INT C LEARN REPR; Gama F., 2019, P ADV NEUR INF PROC, P8036; Gao F, 2019, PR MACH LEARN RES, V97; Goodfellow I.J., 2015, STATISTICAL, DOI DOI 10.48550/ARXIV.1412.6572; Hamilton WL, 2017, REPRESENTATION LEARN; Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005; Han S., 2016, P 4 INT C LEARN REPR, P1; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Horn R. A., 1986, MATRIX ANAL; Ioannidis V. N., 2020, P INT C LEARN REPR; Ioannidis VN, 2019, INT CONF ACOUST SPEE, P8157, DOI 10.1109/ICASSP.2019.8682836; Kipf T.N., 2017, 5 INT C LEARN REPRES, P1; Kriege NM, 2016, ADV NEUR IN, V29; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lee N., 2019, P INT C LEARN REPR; Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936; Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413; Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481; Niepert M, 2016, PR MACH LEARN RES, V48; Qi Charles Ruizhongtai, 2017, P ADV NEUR INF PROC, P5099; Ramchandran K, 1993, IEEE T IMAGE PROCESS, V2, P160, DOI 10.1109/83.217221; Shuman DI, 2015, IEEE T SIGNAL PROCES, V63, P4223, DOI 10.1109/TSP.2015.2424203; Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11; TSATSANIS MK, 1995, IEEE T SIGNAL PROCES, V43, P1766, DOI 10.1109/78.403336; Velickovic P., 2018, P INT C LEARN REPR; Vinyals Oriol, 2015, ARXIV151106391; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Weston Jason, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P639, DOI 10.1007/978-3-642-35289-8_34; Wu F, 2019, PR MACH LEARN RES, V97; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Xiong ZX, 1997, IEEE T IMAGE PROCESS, V6, P677, DOI 10.1109/83.568925; Yang Z, 2016, PR MACH LEARN RES, V48; Ying R, 2018, ADV NEUR IN, V31; Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890; Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438; Zhu X., 2003, INT C MACH LEARN; Zou DM, 2020, APPL COMPUT HARMON A, V49, P1046, DOI 10.1016/j.acha.2019.06.003; Zugner D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6246, DOI 10.1145/3219819.3220078	44	0	0	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1232	1246		10.1109/TPAMI.2020.3025258	http://dx.doi.org/10.1109/TPAMI.2020.3025258			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32946387	Green Submitted			2022-12-18	WOS:000752018000013
J	Li, HL; Wang, SQ; Wan, RJ; Kot, AC				Li, Haoliang; Wang, Shiqi; Wan, Renjie; Kot, Alex C.			GMFAD: Towards Generalized Visual Recognition via Multilayer Feature Alignment and Disentanglement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Adaptation models; Machine learning; Training; Task analysis; Data models; Correlation; Training data; Generalization capability; covariance matrix; disentanglement; visual recognition	DOMAIN; KERNEL	The deep learning based approaches which have been repeatedly proven to bring benefits to visual recognition tasks usually make a strong assumption that the training and test data are drawn from similar feature spaces and distributions. However, such an assumption may not always hold in various practical application scenarios on visual recognition tasks. Inspired by the hierarchical organization of deep feature representation that progressively leads to more abstract features at higher layers of representations, we propose to tackle this problem with a novel feature learning framework, which is called GMFAD, with better generalization capability in a multilayer perceptron manner. We first learn feature representations at the shallow layer where shareable underlying factors among domains (e.g., a subset of which could be relevant for each particular domain) can be explored. In particular, we propose to align the domain divergence between domain pair(s) by considering both inter-dimension and inter-sample correlations, which have been largely ignored by many cross-domain visual recognition methods. Subsequently, to learn more abstract information which could further benefit transferability, we propose to conduct feature disentanglement at the deep feature layer. Extensive experiments based on different visual recognition tasks demonstrate that our proposed framework can learn better transferable feature representation compared with state-of-the-art baselines.	[Li, Haoliang; Wan, Renjie; Kot, Alex C.] Nanyang Technol Univ, Rapid Rich Object SEarch ROSE Lab, Singapore 639798, Singapore; [Wang, Shiqi] City Univ Hong Kong, Sch Comp Sci, Hong Kong, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; City University of Hong Kong	Li, HL (corresponding author), Nanyang Technol Univ, Rapid Rich Object SEarch ROSE Lab, Singapore 639798, Singapore.	lihaoliang@ntu.edu.sg; shiqwang@cityu.edu.hk; rjwan@ntu.edu.sg; eackot@ntu.edu.sg		Kot, Alex/0000-0001-6262-8125; Wan, Renjie/0000-0002-0161-0367; Li, Haoliang/0000-0002-8723-8112	Wallenberg-NTU Presidential Postdoctoral Fellowship; NTU-PKU Joint Research Institute; Ng Teng Fong Charitable Foundation; Science and Technology Foundation of Guangzhou Huangpu Development District [2017GH22, 201902 010028]; Sino-Singapore International Joint Research Institute [206-A017023, 206-A018001]	Wallenberg-NTU Presidential Postdoctoral Fellowship; NTU-PKU Joint Research Institute; Ng Teng Fong Charitable Foundation; Science and Technology Foundation of Guangzhou Huangpu Development District; Sino-Singapore International Joint Research Institute	The researchwas done at the Rapid-RichObject Search (ROSE) Lab, Nanyang Technological University. This research was supported in part by the Wallenberg-NTU Presidential Postdoctoral Fellowship, the NTU-PKU Joint Research Institute, a collaboration between the Nanyang Technological University and Peking University that is sponsored by a donation from the Ng Teng Fong Charitable Foundation, the Science and Technology Foundation of Guangzhou Huangpu Development District under Grant 2017GH22 and 201902 010028, and Sino-Singapore International Joint Research Institute (Project No. 206-A017023 and 206-A018001).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; ARCONES MA, 1992, ANN STAT, V20, P655, DOI 10.1214/aos/1176348650; Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996; Balaji Y., 2018, P 32 INT C NEUR INF, P1004; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Berlinet A., 2011, REPRODUCING KERNEL H; Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542; Chen C, 2019, AAAI CONF ARTIF INTE, P3296; Chen X, 2016, ADV NEUR IN, V29; Donahue J, 2014, PR MACH LEARN RES, V32; Duan L., 2009, P 26 ANN INT C MACH, P289, DOI DOI 10.1145/1553374.1553411; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fang C, 2013, IEEE I CONF COMP VIS, P1657, DOI 10.1109/ICCV.2013.208; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Finn C, 2017, PR MACH LEARN RES, V70; Fukumizu K., 2009, ADV NEURAL INFORM PR, P1750; Fukumizu K, 2007, J MACH LEARN RES, V8, P361; Ganin Y, 2016, J MACH LEARN RES, V17; Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532; Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36; Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293; Glorot Xavier, 2011, P 28 INT C MACH LEAR, P513, DOI DOI 10.1177/1753193411430810; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Goodfellow I., 2009, ADV NEURAL INFORM PR, V22, P646, DOI DOI 10.5555/2984093.2984166; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goroshin R, 2015, IEEE I CONF COMP VIS, P4086, DOI 10.1109/ICCV.2015.465; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Herath S, 2017, PROC CVPR IEEE, P3956, DOI 10.1109/CVPR.2017.421; Higgins I., 2017, P INT C LEARN REPR T; Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6; Hoffman J, 2018, PR MACH LEARN RES, V80; Huang ZW, 2018, IEEE T PATTERN ANAL, V40, P2827, DOI 10.1109/TPAMI.2017.2776154; Huang ZW, 2017, AAAI CONF ARTIF INTE, P2036; Ioffe S., 2015, INT C MACH LEARN, P448, DOI [10.5555/3045118.3045167, DOI 10.5555/3045118.3045167]; Jayasumana S, 2013, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2013.17; Kim H, 2018, PR MACH LEARN RES, V80; King DB, 2015, ACS SYM SER, V1214, P1; Kingma DP, 2014, ADV NEUR IN, V27; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; LeCun Y, 2011, MNIST DATABASE HANDW, DOI DOI 10.1109/MSP.2012.2211477; Li D, 2018, AAAI CONF ARTIF INTE, P3490; Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566; Li W, 2018, IEEE T PATTERN ANAL, V40, P1114, DOI 10.1109/TPAMI.2017.2704624; Li YJ, 2015, PR MACH LEARN RES, V37, P1718; Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136; Long MS, 2018, ADV NEUR IN, V31; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Makhzani A, 2017, ADV NEUR IN, V30; Makhzani Alireza, 2016, ICLR WORKSH; Motiian S, 2017, IEEE I CONF COMP VIS, P5716, DOI 10.1109/ICCV.2017.609; Muandet K., 2013, P 30 INT C INT C MAC; Muandet K, 2017, FOUND TRENDS MACH LE, V10, P1, DOI 10.1561/2200000060; Niu L, 2015, IEEE I CONF COMP VIS, P4193, DOI 10.1109/ICCV.2015.477; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Reed S, 2014, PR MACH LEARN RES, V32, P1431; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saminger-Platz S., 2017, P INT C LEARN REPR I; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Tosato D, 2010, LECT NOTES COMPUT SC, V6312, P378, DOI 10.1007/978-3-642-15552-9_28; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Tzeng E., 2014, ARXIV PREPRINT ARXIV; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; van Steenkiste S, 2019, ADV NEURAL INFORM PR, P14222; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang YF, 2017, IEEE INT CONF COMP V, P2651, DOI 10.1109/ICCVW.2017.315; WATANABE S, 1960, IBM J RES DEV, V4, P66, DOI 10.1147/rd.41.0066; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Xu Z, 2014, LECT NOTES COMPUT SC, V8691, P628, DOI 10.1007/978-3-319-10578-9_41; Yang P., 2013, INT JOINT C ARTIFICI, P1848; Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547; Zhang WC, 2018, PROC CVPR IEEE, P3801, DOI 10.1109/CVPR.2018.00400	84	0	0	3	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1289	1303		10.1109/TPAMI.2020.3020554	http://dx.doi.org/10.1109/TPAMI.2020.3020554			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32870783				2022-12-18	WOS:000752018000017
J	Morales-Alvarez, P; Ruiz, P; Coughlin, S; Molina, R; Katsaggelos, AK				Morales-Alvarez, Pablo; Ruiz, Pablo; Coughlin, Scott; Molina, Rafael; Katsaggelos, Aggelos K.			Scalable Variational Gaussian Processes for Crowdsourcing: Glitch Detection in LIGO	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Crowdsourcing; Training; Probabilistic logic; Gaussian processes; Machine learning; Uncertainty; Bayes methods; Crowdsourcing; citizen science; laser interferometer gravitational waves observatory; sparse Gaussian processes; scalability; uncertainty quantification; deep learning	CITIZEN SCIENCE; CLASSIFICATION	In the last years, crowdsourcing is transforming the way classification training sets are obtained. Instead of relying on a single expert annotator, crowdsourcing shares the labelling effort among a large number of collaborators. For instance, this is being applied in the laureate laser interferometer gravitational waves observatory (LIGO), in order to detect glitches which might hinder the identification of true gravitational-waves. The crowdsourcing scenario poses new challenging difficulties, as it has to deal with different opinions from a heterogeneous group of annotators with unknown degrees of expertise. Probabilistic methods, such as Gaussian processes (GP), have proven successful in modeling this setting. However, GPs do not scale up well to large data sets, which hampers their broad adoption in real-world problems (in particular LIGO). This has led to the very recent introduction of deep learning based crowdsourcing methods, which have become the state-of-the-art for this type of problems. However, the accurate uncertainty quantification provided by GPs has been partially sacrificed. This is an important aspect for astrophysicists in LIGO, since a glitch detection system should provide very accurate probability distributions of its predictions. In this work, we first leverage a standard sparse GP approximation (SVGP) to develop a GP-based crowdsourcing method that factorizes into mini-batches. This makes it able to cope with previously-prohibitive data sets. This first approach, which we refer to as scalable variational Gaussian processes for crowdsourcing (SVGPCR), brings back GP-based methods to a state-of-the-art level, and excels at uncertainty quantification. SVGPCR is shown to outperform deep learning based methods and previous probabilistic ones when applied to the LIGO data. Its behavior and main properties are carefully analyzed in a controlled experiment based on the MNIST data set. Moreover, recent GP inference techniques are also adapted to crowdsourcing and evaluated experimentally.	[Morales-Alvarez, Pablo; Molina, Rafael] Univ Granada, Dept Comp Sci & Artificial Intelligence, Granada 18010, Spain; [Ruiz, Pablo; Katsaggelos, Aggelos K.] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA; [Coughlin, Scott] Northwestern Univ, Ctr Interdisciplinary Explorat & Res Astrophys CI, Evanston, IL 60208 USA; [Coughlin, Scott] Cardiff Univ, Dept Phys & Astron, Cardiff CF10 3AT, Wales	University of Granada; Northwestern University; Northwestern University; Cardiff University	Morales-Alvarez, P (corresponding author), Univ Granada, Dept Comp Sci & Artificial Intelligence, Granada 18010, Spain.	pablomoralvarez@gmail.com; mataran@northwestern.edu; scottcoughlin2014@u.northwestern.edu; rms@decsai.ugr.es; aggk@eecs.northwestern.edu	Morales-Álvarez, Pablo/GVU-6914-2022; Molina Soriano, Rafael/B-1849-2012	Morales-Álvarez, Pablo/0000-0003-2793-0083; Ruiz Mataran, Pablo/0000-0003-0381-0212; Molina Soriano, Rafael/0000-0003-4694-8588	Spanish Ministry of Economy and Competitiveness [DPI2016-77869-C22-R]; Spanish Ministry of Science and Innovation [PID2019-105142RB-C22]; US National Science Foundation [INSPIRE 15-47880]; US Department of Energy [DE-NA0002520]; University of Granada through the Visiting Scholar Program; La Caixa Banking Foundation (Barcelona, Spain) through La Caixa Fellowship for Doctoral Studies [100010434, LCF/BQ/ES17/11600011]	Spanish Ministry of Economy and Competitiveness(Spanish Government); Spanish Ministry of Science and Innovation(Ministry of Science and Innovation, Spain (MICINN)Spanish Government); US National Science Foundation(National Science Foundation (NSF)); US Department of Energy(United States Department of Energy (DOE)); University of Granada through the Visiting Scholar Program; La Caixa Banking Foundation (Barcelona, Spain) through La Caixa Fellowship for Doctoral Studies	This work was supported by the Spanish Ministry of Economy and Competitiveness under project DPI2016-77869-C22-R, the Spanish Ministry of Science and Innovation under project PID2019-105142RB-C22, the US National Science Foundation through the NSF INSPIRE 15-47880 grant (Gravity Spy project), the US Department of Energy under grant DE-NA0002520, and the University of Granada through the Visiting Scholar Program. Pablo Morales was supported by La Caixa Banking Foundation (ID 100010434, Barcelona, Spain) through La Caixa Fellowship for Doctoral Studies LCF/BQ/ES17/11600011. The authors would also like to thank Mike Zevin and Neda Rohani for useful discussions.	Abbott BP, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.061102; Abbott BP, 2016, CLASSICAL QUANT GRAV, V33, DOI 10.1088/0264-9381/33/13/134001; ABRAMOVICI A, 1992, SCIENCE, V256, P325, DOI 10.1126/science.256.5055.325; Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120; Bahaadini S, 2018, INFORM SCIENCES, V444, P172, DOI 10.1016/j.ins.2018.02.068; Bauer M, 2016, ADV NEUR IN, V29; Bishop C. M., 2006, PATTERN RECOGN, DOI DOI 10.1117/1.2819119.ARNING; Blei DM, 2017, J AM STAT ASSOC, V112, P859, DOI 10.1080/01621459.2017.1285773; Blomqvist K., 2020, ECML PKDD 2019, V1907; Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980; Burt DR, 2019, PR MACH LEARN RES, V97; Casale Francesco Paolo, 2018, ADV NEURAL INFORM PR, P10390; Castelvecchi D., 2016, NAT NEWS, V11, P1, DOI [10.1038/nature.2016.19361, DOI 10.1038/NATURE.2016.19361]; Chen J., 2020, PROC INT C MACH LEAR; Choi S, 2018, IEEE INT SYMP ELEC, P4; DAWID AP, 1979, J ROY STAT SOC B MET, V41, P1; Donmez P, 2008, P 17 ACM C INF KNOWL, P619, DOI DOI 10.1145/1458082.1458165; Fritz S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.75; Garnelo M, 2018, PR MACH LEARN RES, V80; Gordon J., 2020, PROC INT C LEARN REP; Guan MY, 2018, AAAI CONF ARTIF INTE, P3109; Guerrini CJ, 2018, SCIENCE, V361, P134, DOI 10.1126/science.aar8379; Heim E, 2018, IEEE T PATTERN ANAL, V40, P2814, DOI 10.1109/TPAMI.2017.2777967; Hensman J., 2013, P 20 9 C UNCERTAINTY, P282, DOI DOI 10.1093/IMAIAI/IAX023; Hensman J, 2015, JMLR WORKSH CONF PRO, V38, P351; Hernandez-Lobato D., 2011, ADV NEURAL INFORM PR, P280; Hoffman MD, 2013, J MACH LEARN RES, V14, P1303; Ipeirotis Panagiotis G., 2010, P ACM SIGKDD WORKSH, DOI [10.1145/1837885.1837906, DOI 10.1145/1837885.1837906]; Irwin A, 2018, NATURE, V562, P480, DOI 10.1038/d41586-018-07106-5; Kennefick D. J, 2016, TRAVELING SPEED THOU; Kingma D.P., 2015, INT C LEARN REPR, P1; Kingma DP., 2016, ADV NEURAL INFORM PR, V29, P4743; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Matthews AGD, 2017, J MACH LEARN RES, V18, P1; Minka T.P., 2001, P 17 C UNC ART INT, P362; Morales-Alvarez P, 2019, INFORM FUSION, V52, P110, DOI 10.1016/j.inffus.2018.12.008; Morales-Alvarez P, 2018, IEEE T GEOSCI REMOTE, V56, P1103, DOI 10.1109/TGRS.2017.2758922; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Nuttall L. K., 2015, CLASSICAL QUANT GRAV, V32; Papamakarios G., 2019, ARXIV PREPRINT ARXIV; Papamakarios George, 2017, ARXIV170507057; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Raykar VC, 2010, J MACH LEARN RES, V11, P1297; Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530; Rodrigues F, 2018, AAAI CONF ARTIF INTE, P1611; Rodrigues F, 2017, IEEE T PATTERN ANAL, V39, P2409, DOI 10.1109/TPAMI.2017.2648786; Rodrigues F, 2014, PR MACH LEARN RES, V32, P433; Roy R., 2010, NIST HDB MATH FUNCTI; Ruiz P, 2019, PATTERN RECOGN, V88, P298, DOI 10.1016/j.patcog.2018.11.021; Saez-Rodriguez J, 2016, NAT REV GENET, V17, P470, DOI 10.1038/nrg.2016.69; Salimbeni H, 2017, ADV NEUR IN, V30; Sheng Victor S, 2008, P 14 ACM SIGKDD INT, P614, DOI DOI 10.1145/1401890.1401965; Shi Jiaxin, 2019, INT C MACH LEARN, P5758; Snelson Edward, 2006, ADV NEURAL INFORM PR, V3; Snow Rion, 2008, P 2008 C EMP METH NA, P254, DOI DOI 10.3115/1613715.1613751; Sun S., 2019, P 2019 EMNLP IJCNLP, P4323, DOI [10.18653/v1/D19-1441, DOI 10.18653/V1/D19-1441]; Tegner M., 2018, 2018 ICML WORKSHOP T; Titsias M. K., 2009, ARTIF INTELL STAT, V3; van der Wilk M, 2017, ADV NEUR IN, V30; Whitehill J., 2009, ADV NEURAL INFORM PR, P2035; Yan Y, 2014, MACH LEARN, V95, P291, DOI 10.1007/s10994-013-5412-1; Zevin M, 2017, CLASSICAL QUANT GRAV, V34, DOI 10.1088/1361-6382/aa5cea	63	0	0	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1534	1551		10.1109/TPAMI.2020.3025390	http://dx.doi.org/10.1109/TPAMI.2020.3025390			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32956038	Green Submitted			2022-12-18	WOS:000752018000033
J	Rong, XJ; Yi, CC; Tian, YL				Rong, Xuejian; Yi, Chucai; Tian, Yingli			Unambiguous Text Localization, Retrieval, and Recognition for Cluttered Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Text recognition; Natural languages; Task analysis; Context modeling; Data mining; Visualization; Natural language description; text detection; text retrieval; text recognition; deep neural network; referring expression		Text instance as one category of self-described objects provides valuable information for understanding and describing cluttered scenes. The rich and precise high-level semantics embodied in the text could drastically benefit the understanding of the world around us. While most recent visual phrase grounding approaches focus on general objects, this paper explores extracting designated texts and predicting unambiguous scene text information, i.e., to accurately localize and recognize a specific targeted text instance in a cluttered image from natural language descriptions (referring expressions). To address this issue, first a novel recurrent dense text localization network (DTLN) is proposed to sequentially decode the intermediate convolutional representations of a cluttered scene image into a set of distinct text instance detections. Our approach avoids repeated text detections at multiple scales by recurrently memorizing previous detections, and effectively tackles crowded text instances in close proximity. Second, we propose a context reasoning text retrieval (CRTR) model, which jointly encodes text instances and their context information through a recurrent network, and ranks localized text bounding boxes by a scoring function of context compatibility. Third, a recurrent text recognition module is introduced to extend the applicability of aforementioned DTLN and CRTR models, via text verification or transcription. Quantitative evaluations on standard scene text extraction benchmarks and a newly collected scene text retrieval dataset demonstrate the effectiveness and advantages of our models for the joint scene text localization, retrieval, and recognition task.	[Rong, Xuejian; Tian, Yingli] CUNY, Dept Elect Engn, City Coll, New York, NY 10031 USA; [Yi, Chucai] CUNY, Grad Ctr, New York, NY 10031 USA; [Yi, Chucai] Google Augmented Real, Mountain View, CA 94043 USA	City University of New York (CUNY) System; City College of New York (CUNY); City University of New York (CUNY) System	Tian, YL (corresponding author), CUNY, Dept Elect Engn, City Coll, New York, NY 10031 USA.	xrong@ccny.cuny.edu; gschucai@gmail.com; ytian@ccny.cuny.edu			NSF [EFRI1137172, IIP-1343402, IIS-1400802]	NSF(National Science Foundation (NSF))	This work was supported in part by the NSF Grants EFRI1137172, IIP-1343402, and IIS-1400802.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959; Bai F, 2018, PROC CVPR IEEE, P1508, DOI 10.1109/CVPR.2018.00163; Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102; Biten AF, 2019, IEEE I CONF COMP VIS, P4290, DOI 10.1109/ICCV.2019.00439; Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242; Cheng ZZ, 2018, PROC CVPR IEEE, P5571, DOI 10.1109/CVPR.2018.00584; Choi WG, 2013, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2013.12; Dahl R, 2017, IEEE I CONF COMP VIS, P5449, DOI 10.1109/ICCV.2017.581; Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352; Deng D, 2018, AAAI CONF ARTIF INTE, P6773; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254; He T, 2018, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR.2018.00527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493; Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7; ICDAR, 2017, ICDAR 2017 ROBUST RE; Ioffe S., 2015, INT C MACH LEARN, P448, DOI [10.5555/3045118.3045167, DOI 10.5555/3045118.3045167]; Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z; Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990; Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, P787, DOI DOI 10.3115/V1/D14-1086; Krahmer E, 2012, COMPUT LINGUIST, V38, P173, DOI 10.1162/COLI_a_00088; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kumar MP, 2010, PROC CVPR IEEE, P3217, DOI 10.1109/CVPR.2010.5540072; Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560; Li YK, 2017, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2017.766; Liang XD, 2017, PROC CVPR IEEE, P4408, DOI 10.1109/CVPR.2017.469; Liao MH, 2017, AAAI CONF ARTIF INTE, P4161; Liu CX, 2017, IEEE I CONF COMP VIS, P1280, DOI 10.1109/ICCV.2017.143; Liu W, 2018, AAAI CONF ARTIF INTE, P7154; Long S, 2018, ARXIV 181104256; Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51; Lu SJ, 2015, INT J DOC ANAL RECOG, V18, P125, DOI 10.1007/s10032-015-0237-z; Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515; Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9; Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097; Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180; Plummer BA, 2017, IEEE I CONF COMP VIS, P1946, DOI 10.1109/ICCV.2017.213; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Prasad S, 2018, LECT NOTES COMPUT SC, V11220, P559, DOI 10.1007/978-3-030-01270-0_33; Ramanathan V, 2015, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.2015.7298713; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49; Rong XJ, 2020, IEEE T IMAGE PROCESS, V29, P591, DOI 10.1109/TIP.2019.2930176; Rong XJ, 2017, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2017.349; Rong XJ, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P570, DOI 10.1109/ICDSP.2016.7868622; Rong XJ, 2014, IEEE INT CON MULTI; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939; Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371; Socher R., 2013, ADV NEURAL INFORM PR, V26, P1; Stewart R, 2016, PROC CVPR IEEE, P2325, DOI 10.1109/CVPR.2016.255; Su BL, 2017, PATTERN RECOGN, V63, P397, DOI 10.1016/j.patcog.2016.10.016; Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Tian SX, 2016, PATTERN RECOGN, V51, P125, DOI 10.1016/j.patcog.2015.07.009; Tian Y., 2016, APPL COMP VIS WACV 2, P1; Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4; Veit Andreas, 2016, ARXIV160107140; Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43; Wang T, 2012, INT C PATT RECOG, P3304; Weinberger KQ, 2014, ADV NEURAL INFORM PR, P1889; Wikipedia, 2017, COGNITIVE NEUROSCIEN; Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0; Xiong B., 2016, PROC IEEEWINTER C AP, P1; Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330; Xue CH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P989; Xue CH, 2018, LECT NOTES COMPUT SC, V11220, P370, DOI 10.1007/978-3-030-01270-0_22; Xuejian Rong, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P109, DOI 10.1007/978-3-319-46604-0_8; Yan MK, 2019, IEEE I CONF COMP VIS, P9146, DOI 10.1109/ICCV.2019.00924; Yatskar Mark, 2016, P 2016 C N AM CHAPTE, P193; Yi CC, 2014, IEEE-ASME T MECH, V19, P808, DOI 10.1109/TMECH.2013.2261083; Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210; Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182; Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5; Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688; Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611; Zhan FN, 2019, IEEE I CONF COMP VIS, P9104, DOI 10.1109/ICCV.2019.00920; Zhan FN, 2019, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2019.00216; Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331; Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451; Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871; Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283; Zhou Xinyu, 2015, ARXIV150603184; Zhuang B, 2017, ARXIV 170509892; Zhuang BH, 2017, IEEE I CONF COMP VIS, P589, DOI 10.1109/ICCV.2017.71	95	0	0	10	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1638	1652		10.1109/TPAMI.2020.3018491	http://dx.doi.org/10.1109/TPAMI.2020.3018491			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32822292				2022-12-18	WOS:000752018000040
J	Shi, TY; Zou, ZX; Shi, ZW; Yuan, Y				Shi, Tianyang; Zou, Zhengxia; Shi, Zhenwei; Yuan, Yi			Neural Rendering for Game Character Auto-Creation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Faces; Games; Rendering (computer graphics); Three-dimensional displays; Solid modeling; Face recognition; Engines; Game character customization; role-playing games; neural rendering; deep learning		Many role-playing games feature character creation systems where players are allowed to edit the facial appearance of their in-game characters. This paper proposes a novel method to automatically create game characters based on a single face photo. We frame this "artistic creation" process under a self-supervised learning paradigm by leveraging the differentiable neural rendering. Considering the rendering process of a typical game engine is not differentiable, an "imitator" network is introduced to imitate the behavior of the engine so that the in-game characters can be smoothly optimized by gradient descent in an end-to-end fashion. Different from previous monocular 3D face reconstruction which focuses on generating 3D mesh-grid and ignores user interaction, our method produces fine-grained facial parameters with a clear physical significance where users can optionally fine-tune their auto-created characters by manually adjusting those parameters. Experiments on multiple large-scale face datasets show that our method can generate highly robust and vivid game characters. Our method has been applied to two games and has now provided over 10 million times of online services.	[Shi, Tianyang; Yuan, Yi] NetEase, Fuxi AI Lab, Hangzhou 310052, Zhejiang, Peoples R China; [Zou, Zhengxia] Univ Michigan, Dept Computat Med & Bioinformat, Ann Arbor, MI 48109 USA; [Shi, Zhenwei] Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China	University of Michigan System; University of Michigan; Beihang University	Yuan, Y (corresponding author), NetEase, Fuxi AI Lab, Hangzhou 310052, Zhejiang, Peoples R China.	shitianyang@corp.netease.com; zzhengxi@umich.edu; shizhenwei@buaa.edu.cn; yuanyi@corp.netease.com		Yuan, Yi/0000-0003-2507-8181; Zou, Zhengxia/0000-0003-1774-552X; , Tianyang/0000-0002-4587-7792				Aldrian O, 2013, IEEE T PATTERN ANAL, V35, P1080, DOI 10.1109/TPAMI.2012.206; Tran AT, 2018, PROC CVPR IEEE, P3935, DOI 10.1109/CVPR.2018.00414; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Booth J, 2017, PROC CVPR IEEE, P5464, DOI 10.1109/CVPR.2017.580; Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020; Cashman TJ, 2013, IEEE T PATTERN ANAL, V35, P232, DOI 10.1109/TPAMI.2012.68; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164; Eslami SMA, 2018, SCIENCE, V360, P1204, DOI 10.1126/science.aar6170; Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125; Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874; Gruber A, 2020, COMPUT GRAPH FORUM, V39; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu J., 2018, PROC CVPR IEEE, P7132, DOI [DOI 10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G.B., 2008, WORKSHOP FACES REAL; Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411; King DB, 2015, ACS SYM SER, V1214, P1; King DE, 2009, J MACH LEARN RES, V10, P1755; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li TM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275109; Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11; Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767; Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250; Nguyen-Phuoc Thu, 2018, ADV NEURAL INFORM PR; Paszke A, 2019, ADV NEUR IN, V32; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Peng WL, 2017, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2017.585; Pouget-Abadie Jean, 2014, COMMUN ACM, V27, DOI DOI 10.1145/3422622; Radford A., 2015, ARXIV PREPR ARXIV151; Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589; Sengupta S, 2016, IEEE WINT CONF APPL; Shi TY, 2020, AAAI CONF ARTIF INTE, V34, P1733; Shi TY, 2019, IEEE I CONF COMP VIS, P161, DOI 10.1109/ICCV.2019.00025; Tewari A, 2017, IEEE I CONF COMP VIS, P3735, DOI 10.1109/ICCV.2017.401; Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163; Tran L, 2021, IEEE T PATTERN ANAL, V43, P157, DOI 10.1109/TPAMI.2019.2927975; Wolf L, 2017, IEEE I CONF COMP VIS, P1539, DOI 10.1109/ICCV.2017.170; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; Yosinski J., 2015, ICML DEEP LEARN WORK; Zhao J, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4397; Zhao J, 2019, AAAI CONF ARTIF INTE, P9251; Zhao J, 2018, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2018.00235; Zheng T, 2018, REP NO 18 01	53	0	0	3	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1489	1502		10.1109/TPAMI.2020.3024009	http://dx.doi.org/10.1109/TPAMI.2020.3024009			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32931428				2022-12-18	WOS:000752018000030
J	Weinan, E; Zhou, YJ				Weinan, E.; Zhou, Yajun			A Mathematical Model for Universal Semantics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Numerical models; Pattern analysis; Markov processes; Statistical analysis; Exponential distribution; Recurring patterns in texts; semantic model; recurrence time; hitting time; word translation; question answering	LANGUAGE; EVOLUTION	We characterize the meaning of words with language-independent numerical fingerprints, through a mathematical analysis of recurring patterns in texts. Approximating texts by Markov processes on a long-range time scale, we are able to extract topics, discover synonyms, and sketch semantic fields from a particular document of moderate length, without consulting external knowledge-base or thesaurus. Our Markov semantic model allows us to represent each topical concept by a low-dimensional vector, interpretable as algebraic invariants in succinct statistical operations on the document, targeting local environments of individual words. These language-independent semantic representations enable a robot reader to both understand short texts in a given language (automated question-answering) and match medium-length texts across different languages (automated word translation). Our semantic fingerprints quantify local meaning of words in 14 representative languages across five major language families, suggesting a universal and cost-effective mechanism by which human languages are processed at the semantic level. Our protocols and source codes are publicly available on https://github.com/yajun-zhou/linguae-naturalis-principia-mathematica.	[Weinan, E.] Princeton Univ, Dept Math, Princeton, NJ 08544 USA; [Weinan, E.] Princeton Univ, Program Appl & Computat Math, Princeton, NJ 08544 USA; [Weinan, E.] Beijing Inst Big Data Res, Beijing 100871, Peoples R China; [Zhou, Yajun] Beijing Inst Big Data Res, Lab Nat Language Proc & Cognit Intelligence, Beijing 100871, Peoples R China	Princeton University; Princeton University	Weinan, E (corresponding author), Princeton Univ, Dept Math, Princeton, NJ 08544 USA.; Weinan, E (corresponding author), Princeton Univ, Program Appl & Computat Math, Princeton, NJ 08544 USA.; Zhou, YJ (corresponding author), Beijing Inst Big Data Res, Lab Nat Language Proc & Cognit Intelligence, Beijing 100871, Peoples R China.	weinan@math.princeton.edu; yajun.zhou.1982@pku.edu.cn		Zhou, Yajun/0000-0003-4431-6771				[Anonymous], 2010, PATTERN THEORY STOCH; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Chen X., 2018, 2018 C EMP METH NAT, P261, DOI DOI 10.18653/V1/D18-1024; Chen YX, 2016, NONLINEAR DYNAM, V85, P2801, DOI 10.1007/s11071-016-2863-5; Chomsky N., 1957, SYNTACTIC STRUCTURES; Christensen J. P. R., 1984, HARMONIC ANAL SEMIGR, V100; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; de Saussure Ferdinand, 1949, COURS LINGUISTIQUE G; Dunn M, 2011, NATURE, V473, P79, DOI 10.1038/nature09923; Everett C, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01285; Everett C, 2015, P NATL ACAD SCI USA, V112, P1322, DOI 10.1073/pnas.1417413112; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Friederici A. D., 1999, LANGUAGE COMPREHENSI, P265; Haydn N, 2005, ANN PROBAB, V33, P2043, DOI 10.1214/009117905000000242; Herrera JP, 2008, EUR PHYS J B, V63, P135, DOI 10.1140/epjb/e2008-00206-x; Joulin Armand, 2018, EMNLP; Kuhn HW, 2012, EUR J OPER RES, V219, P641, DOI 10.1016/j.ejor.2011.11.008; Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053; Lieberman E, 2007, NATURE, V449, P713, DOI 10.1038/nature06137; MarslenWilson WD, 1997, NATURE, V387, P592, DOI 10.1038/42456; Mikolov T., 2013, ARXIV; Newberry MG, 2017, NATURE, V551, P223, DOI 10.1038/nature24455; Nowak MA, 2000, NATURE, V404, P495, DOI 10.1038/35006635; Nowak MA, 1999, P NATL ACAD SCI USA, V96, P8028, DOI 10.1073/pnas.96.14.8028; Page L., 1999, TECH REP SIDL WP 199; PINKER S, 1988, COGNITION, V28, P73, DOI 10.1016/0010-0277(88)90032-7; Pinker S, 2000, NATURE, V404, P441, DOI 10.1038/35006523; Pinker S, 1997, NATURE, V387, P547, DOI 10.1038/42347; Pollicott M., 1998, DYNAMICAL SYSTEMS ER, V40; Ross S.M., 1995, STOCHASTIC PROCESSES; Ruzicka M., 1958, BIOLOGIA, V13, P647; Sloman SA, 1996, PSYCHOL BULL, V119, P3, DOI 10.1037/0033-2909.119.1.3; Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8; Yang Yi, 2015, P 2015 C EMP METH NA, P2013, DOI DOI 10.18653/V1/D15-1237; Zhou YJ, 2006, BIOPHYS J, V91, P4045, DOI 10.1529/biophysj.106.090688	35	0	0	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1124	1132		10.1109/TPAMI.2020.3022533	http://dx.doi.org/10.1109/TPAMI.2020.3022533			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32894708	Green Submitted			2022-12-18	WOS:000752018000005
J	Xing, XL; Gao, RQ; Han, T; Zhu, SC; Wu, YN				Xing, Xianglei; Gao, Ruiqi; Han, Tian; Zhu, Song-Chun; Wu, Ying Nian			Deformable Generator Networks: Unsupervised Disentanglement of Appearance and Geometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generators; Deformable models; Data models; Shape; Interpolation; Analytical models; Image color analysis; Unsupervised learning; deep generative model; deformable model	REPRESENTATION	We present a deformable generator model to disentangle the appearance and geometric information for both image and video data in a purely unsupervised manner. The appearance generator network models the information related to appearance, including color, illumination, identity or category, while the geometric generator performs geometric warping, such as rotation and stretching, through generating deformation field which is used to warp the generated appearance to obtain the final image or video sequences. Two generators take independent latent vectors as input to disentangle the appearance and geometric information from image or video sequences. For video data, a nonlinear transition model is introduced to both the appearance and geometric generators to capture the dynamics over time. The proposed scheme is general and can be easily integrated into different generative models. An extensive set of qualitative and quantitative experiments shows that the appearance and geometric information can be well disentangled, and the learned geometric generator can be conveniently transferred to other image datasets that share similar structure regularity to facilitate knowledge transfer tasks.	[Xing, Xianglei] Harbin Engn Univ, Coll Automat, Harbin 150001, Heilongjiang, Peoples R China; [Han, Tian] Stevens Inst Technol, Comp Sci Dept, Hoboken, NJ 07030 USA; [Gao, Ruiqi; Zhu, Song-Chun; Wu, Ying Nian] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Harbin Engineering University; Stevens Institute of Technology; University of California System; University of California Los Angeles	Xing, XL (corresponding author), Harbin Engn Univ, Coll Automat, Harbin 150001, Heilongjiang, Peoples R China.	xingxl@hrbeu.edu.cn; ruiqigao@stat.ucla.edu; than6@stevens.edu; sczhu@stat.ucla.edu; ywu@stat.ucla.edu		Xing, Xianglei/0000-0002-4159-1922	Natural Science Foundation of China [61703119]; Natural Science Fund of Heilongjiang Province of China [QC2017070]; Fundamental Research Funds for the Central Universities [3072020CF0403]; NSF [DMS-2015577]; DARPA [XAI N66001-17-2-4029]; ARO [W911NF1810296]; ONR MURI [N00014-16-1-2007]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Fund of Heilongjiang Province of China; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); NSF(National Science Foundation (NSF)); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); ARO; ONR MURI(MURIOffice of Naval Research)	Y Part of the work was done while the first author was visiting UCLA as a visiting scholar. The work of the first author was supported by Natural Science Foundation of China No. 61703119, Natural Science Fund of Heilongjiang Province of China No. QC2017070, and Fundamental Research Funds for the Central Universities No. 3072020CF0403. The work of the other authors was supported by NSF DMS-2015577, DARPA XAI N66001-17-2-4029, ARO W911NF1810296, and ONR MURI N00014-16-1-2007.	Achille A, 2018, J MACH LEARN RES, V19; Aghamaleki JA, 2019, MULTIMED TOOLS APPL, V78, P22861, DOI 10.1007/s11042-019-7530-7; Aifanti N, 2010, 11 INT WORKSH IM AN, P1; Alemi Alex, 2017, ICLR; Amos Brandon, 2016, CMUCS16118; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Brock AM, 2018, PROCEEDINGS PERVASIVE DISPLAYS 2018: THE 7TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, DOI 10.1145/3205873.3205877; Burgess CP, 2018, ARXIV180403599; Chen X, 2016, ADV NEUR IN, V29; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hallinan P. W., 1999, 2 3 DIMENSIONAL PATT; Han T, 2019, PROC CVPR IEEE, P8662, DOI 10.1109/CVPR.2019.00887; Han T, 2018, INT C PATT RECOG, P2062, DOI 10.1109/ICPR.2018.8545421; Han T, 2017, AAAI CONF ARTIF INTE, P1976; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Higgins I., 2017, P INT C LEARN REPR T; Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jaderberg M, 2015, ADV NEUR IN, V28; Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813; Karras T, 2017, ARXIV171010196; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kingma D.P, P 3 INT C LEARNING R; Kossaifi J, 2018, PROC CVPR IEEE, P878, DOI 10.1109/CVPR.2018.00098; Kossaifi J, 2017, IEEE T IMAGE PROCESS, V26, P1040, DOI 10.1109/TIP.2016.2642828; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Kumar A, 2018, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON FUTURE INDUSTRIAL COMMUNICATION NETWORKS (FICN'18), P1, DOI 10.1145/3243318.3243327; Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837; Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3; Li ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2418; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Locatello F., 2019, P ADV NEUR INF PROC, p14 584; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Mandal M, 2019, IET IMAGE PROCESS, V13, P850, DOI 10.1049/iet-ipr.2018.5683; Mathieu M, 2016, ADV NEUR IN, V29; Mescheder L, 2018, PR MACH LEARN RES, V80; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Sen D, 2019, MULTIMED TOOLS APPL, V78, P10287, DOI 10.1007/s11042-018-6537-9; Shu ZX, 2018, LECT NOTES COMPUT SC, V11214, P664, DOI 10.1007/978-3-030-01249-6_40; Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x; Thewlis James, 2017, ADV NEURAL INFORM PR, V3, P8; Nguyen-Phuoc T, 2019, IEEE I CONF COMP VIS, P7587, DOI 10.1109/ICCV.2019.00768; Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141; Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165; Verma Monu, 2019, IEEE Letters of the Computer Society, V2, P36, DOI 10.1109/LOCS.2019.2927959; Weber R, 2018, IEEE T AFFECT COMPUT; Xie J., 2019, P 34 AAAI C ART INT, P12442; Younes L., 1999, STOCHASTICS STOCHAST, V65, P177, DOI DOI 10.1080/17442509908834179; Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7	55	0	0	4	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1162	1179		10.1109/TPAMI.2020.3013905	http://dx.doi.org/10.1109/TPAMI.2020.3013905			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32749961				2022-12-18	WOS:000752018000008
J	Gui, SP; Zhang, XL; Zhong, P; Qiu, S; Wu, MR; Ye, JP; Wang, ZD; Liu, J				Gui, Shupeng; Zhang, Xiangliang; Zhong, Pan; Qiu, Shuang; Wu, Mingrui; Ye, Jieping; Wang, Zhengdao; Liu, Ji			PINE: Universal Deep Embedding for Graph Nodes via Partial Permutation Invariant Set Functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Laplace equations; Aggregates; Reinforcement learning; Matrix decomposition; Graph neural networks; Games; Graph embedding; partial permutation invariant set function; representation learning		Graph node embedding aims at learning a vector representation for all nodes given a graph. It is a central problem in many machine learning tasks (e.g., node classification, recommendation, community detection). The key problem in graph node embedding lies in how to define the dependence to neighbors. Existing approaches specify (either explicitly or implicitly) certain dependencies on neighbors, which may lead to loss of subtle but important structural information within the graph and other dependencies among neighbors. This intrigues us to ask the question: can we design a model to give the adaptive flexibility of dependencies to each node's neighborhood. In this paper, we propose a novel graph node embedding method (named PINE) via a novel notion of partial permutation invariant set function, to capture any possible dependence. Our method 1) can learn an arbitrary form of the representation function from the neighborhood, without losing any potential dependence structures, and 2) is applicable to both homogeneous and heterogeneous graph embedding, the latter of which is challenged by the diversity of node types. Furthermore, we provide theoretical guarantee for the representation capability of our method for general homogeneous and heterogeneous graphs. Empirical evaluation results on benchmark data sets show that our proposed PINE method outperforms the state-of-the-art approaches on producing node vectors for various learning tasks of both homogeneous and heterogeneous graphs.	[Gui, Shupeng] Univ Rochester, Rochester, NY 14627 USA; [Zhang, Xiangliang] King Abdullah Univ Sci & Technol, Thuwal 23955, Saudi Arabia; [Zhong, Pan; Wang, Zhengdao] Iowa State Univ, Dept Elect & Comp Engn, Ames, IA 50011 USA; [Qiu, Shuang; Ye, Jieping] Univ Michigan, Ann Arbor, MI 48109 USA; [Wu, Mingrui] Facebook, Menlo Pk, CA 94025 USA; [Liu, Ji] Kwai Inc, Bellevue, WA 98004 USA	University of Rochester; King Abdullah University of Science & Technology; Iowa State University; University of Michigan System; University of Michigan; Facebook Inc	Gui, SP (corresponding author), Univ Rochester, Rochester, NY 14627 USA.	sgui2@ur.rochester.edu; Xiangliang.Zhang@kaust.edu.sa; pzhong@iastate.edu; qiush@umich.edu; wu.mingrui@yahoo.com; jieping@gmail.com; zhengdao@iastate.edu; ji.liu.uwisc@gmail.com		Wang, Zhengdao/0000-0002-2972-6580; Gui, Shupeng/0000-0003-4744-4680; Zhang, Xiangliang/0000-0002-3574-5665				Abu-El-Haija S, 2018, ADV NEUR IN, V31; Aggarwal CC, 2011, SOCIAL NETWORK DATA ANALYTICS, P1, DOI 10.1007/978-1-4419-8462-3; Akujuobi U, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P16, DOI 10.1145/3336191.3371853; Akujuobi U, 2019, IEEE DATA MINING, P1, DOI 10.1109/ICDM.2019.00010; Bloem P., 2018, P 15 EUR SEM WEB C E, P593, DOI [10.1007/978-3-319-93417-4_38, DOI 10.1007/978-3-319-93417-4_38]; Bojchevski Aleksandar, 2018, INT C LEARN REPR; Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452; Cao S., 2015, P 24 ACM INT C INF K, P891, DOI DOI 10.1145/2806416.2806512; Cao SS, 2016, AAAI CONF ARTIF INTE, P1145; Chang SY, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P119, DOI 10.1145/2783258.2783296; Chen YJ, 2020, WORLD WIDE WEB, V23, P927, DOI 10.1007/s11280-019-00743-4; Cheng JH, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188467; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274; Derr T, 2018, IEEE DATA MINING, P929, DOI 10.1109/ICDM.2018.00113; Dong YX, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P135, DOI 10.1145/3097983.3098036; Donnat C, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1320, DOI 10.1145/3219819.3220025; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Gao HC, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1406, DOI 10.1145/3219819.3220041; Giles C. L., 1998, Digital 98 Libraries. Third ACM Conference on Digital Libraries, P89, DOI 10.1145/276675.276685; Gilmer J, 2017, PR MACH LEARN RES, V70; Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022; Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754; Gupta C, 2010, PROC INT CONF DATA, P569, DOI 10.1109/ICDE.2010.5447828; Hamilton W., 2017, P ADV NEUR INF PROC, P1024; Hamilton WL, 2017, REPRESENTATION LEARN; Hong HT, 2020, AAAI CONF ARTIF INTE, V34, P4132; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Huang X, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P731, DOI 10.1145/3018661.3018667; Kipf Thomas N., 2016, ARXIV161107308, V2, P1; Kipf TN, 2016, P INT C LEARN REPR; Kraft H., 2000, CLASSICAL INVARIANT; Leskovec J, 2007, ACM T WEB, V1, DOI 10.1145/1232722.1232727; Liao R., P ICLR, V1901, P1; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; LOUKAS A, 2019, ARXIV190703199; Lovasz L, 1993, BOLYAI MATH STUD, V1, P9; Lu YF, 2019, AAAI CONF ARTIF INTE, P4456; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; Nguyen GH, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P969, DOI 10.1145/3184558.3191526; Ou MD, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1105, DOI 10.1145/2939672.2939751; Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732; Ribeiro LFR, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P385, DOI 10.1145/3097983.3098061; Rossi RA, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P3, DOI 10.1145/3184558.3186900; Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157; Stone MH, 1937, T AM MATH SOC, V41, P375, DOI 10.2307/1989788; Stone MH., 1948, MATH MAG, V21, P148, DOI [DOI 10.2307/3029750, DOI 10.2307/3029337]; Tang J, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1165, DOI 10.1145/2783258.2783307; Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093; Tang L, 2011, DATA MIN KNOWL DISC, V23, P447, DOI 10.1007/s10618-010-0210-x; Thekumparampil, 2018, ATTENTION BASED GRAP; Pham T, 2017, AAAI CONF ARTIF INTE, P2485; Tu Cunchao, 2016, P 25 INT JOINT C ART, P3889; Tu K, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2357, DOI 10.1145/3219819.3220068; van der Merwe R, 2019, ARCH REC, V40, P239, DOI 10.1080/23257962.2017.1388224; Velickovic P., 2017, INT C LEARN REPR VAN; Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753; Wang X, 2019, AAAI CONF ARTIF INTE, P5337; Wang X, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2022, DOI 10.1145/3308558.3313562; Weyl H., 1946, CLASSICAL GROUPS THE; Wu F, 2019, PR MACH LEARN RES, V97; Xu K., 2018, INT C LEARN REPR; Yang C., 2017, P IJCAI, P19; Yang C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2111; Yang Z, 2016, PR MACH LEARN RES, V48; YAROTSKY D., 2018, ARXIV180410306; Yu X, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P283, DOI 10.1145/2556195.2556259; Yun S, 2019, ADV NEUR IN, V32; Zaheer Manzil, 2017, P ADV NEUR INF PROC, P3394; Zhang ZW, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2778, DOI 10.1145/3219819.3219969; Zhu DY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2827, DOI 10.1145/3219819.3220052	72	0	0	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					770	782		10.1109/TPAMI.2021.3061162	http://dx.doi.org/10.1109/TPAMI.2021.3061162			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	33621166	Green Submitted, Green Published			2022-12-18	WOS:000740006100018
J	Haris, M; Shakhnarovich, G; Ukita, N				Haris, Muhammad; Shakhnarovich, Greg; Ukita, Norimichi			Deep back-projectinetworks for single image super-resolution (vol 43, pg 4323, 2021)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction									[Haris, Muhammad; Ukita, Norimichi] Toyota Technol Inst TTI, Intelligent Informat Media Lab, Nagoya, Aichi 4688511, Japan; [Haris, Muhammad] Bukalapak, Jakarta 12430, Indonesia; [Shakhnarovich, Greg] Toyota Technol Inst Chicago, Chicago, IL 60637 USA	Toyota Technological Institute - Chicago	Haris, M (corresponding author), Toyota Technol Inst TTI, Intelligent Informat Media Lab, Nagoya, Aichi 4688511, Japan.	muhammad.haris@bukalapak.com; greg@ttic.edu; ukita@toyota-ti.ac.jp		Ukita, Norimichi/0000-0002-0240-1065				Haris M, 2021, IEEE T PATTERN ANAL, V43, P4323, DOI 10.1109/TPAMI.2020.3002836	1	0	0	3	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					1122	1122		10.1109/TPAMI.2021.3128797	http://dx.doi.org/10.1109/TPAMI.2021.3128797			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	34995179	Bronze			2022-12-18	WOS:000740006100041
J	Helala, MA; Qureshi, FZ; Pu, KQ				Helala, Mohamed A.; Qureshi, Faisal Z.; Pu, Ken Q.			A Stream Algebra for Performance Optimization of Large Scale Computer Vision Pipelines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Streaming media; Computer vision; Algebra; Pipelines; Approximation algorithms; Optimization; Buildings; Stream algebra; online vision algorithms; stream processing; large scale computer vision systems; parameter tuning; performance optimization	CONFIGURATION; SUBTRACTION; ALGORITHM; TRACKING	There is a large growth in hardware and software systems capable of producing vast amounts of image and video data. These systems are rich sources of continuous image and video streams. This motivates researchers to build scalable computer vision systems that utilize data-streaming concepts for processing of visual data streams. However, several challenges exist in building large-scale computer vision systems. For example, computer vision algorithms have different accuracy and speed profiles depending on the content, type, and speed of incoming data. Also, it is not clear how to adaptively tune these algorithms in large-scale systems. These challenges exist because we lack formal frameworks for building and optimizing large-scale visual processing. This paper presents formal methods and algorithms that aim to overcome these challenges and improve building and optimizing large-scale computer vision systems. We describe a formal algebra framework for the mathematical description of computer vision pipelines for processing image and video streams. The algebra naturally describes feedback control and provides a formal and abstract method for optimizing computer vision pipelines. We then show that a general optimizer can be used with the feedback-control mechanisms of our stream algebra to provide a common online parameter optimization method for computer vision pipelines.	[Helala, Mohamed A.; Qureshi, Faisal Z.; Pu, Ken Q.] Ontario Tech Univ, Fac Sci, Oshawa, ON L1G 0C5, Canada		Helala, MA (corresponding author), Ontario Tech Univ, Fac Sci, Oshawa, ON L1G 0C5, Canada.	Mohamed.Helala@ontariotechu.ca; Faisal.Qureshi@ontariotechu.ca; Ken.Pu@ontariotechu.ca			Natural Sciences and Engineering Research Council of Canada (NSERC)	Natural Sciences and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC))	This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC).	Adenso-Diaz B, 2006, OPER RES, V54, P99, DOI 10.1287/opre.1050.0243; Aggarwal CC, 2003, P 2003 VLDB C, V29, P81, DOI 10.1016/b978-012722442-8/50016-1; Al Harbi N, 2013, LECT NOTES COMPUT SC, V8047, P78, DOI 10.1007/978-3-642-40261-6_9; Ananthanarayanan R., 2013, P ACM SIGMOD INT C M, P577; Ansotegui C, 2009, LECT NOTES COMPUT SC, V5732, P142, DOI 10.1007/978-3-642-04244-7_14; Arasu A., 2002, 200229 STANF INFOLAB; Bartz-Beielstein T, 2005, IEEE C EVOL COMPUTAT, P773; Benoit A, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501664; Benoit A, 2010, ALGORITHMICA, V57, P689, DOI 10.1007/s00453-008-9229-4; Benoit A, 2009, INT J HIGH PERFORM C, V23, P171, DOI 10.1177/1094342009104009; Bergstra J., 2013, INT J COMPUT MATH, V65, P57; Bergstra J. A., 1994, LOGIC GROUP PREPRINT, V122, P1; Bifet A, 2010, JMLR WORKSH CONF PRO, V11, P44; Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524; Birattari M, 2010, F RACE ITERATED F RA, P311; Birattari M., 2002, P GENETIC EVOLUTIONA, V2, P11; Broy M, 2001, THEOR COMPUT SCI, V258, P99, DOI 10.1016/S0304-3975(99)00322-9; Brust C.-A., 2015, ARXIV150206344; Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343; Carlson J., 2004, P 4 ACM INT C EMB SP, P147; Chkodrov G., 2013, Patent, Patent No. [20 130 014 094 A1, 20130014094]; Demers A., 2005, TR20051997 CORN U; Chau DP, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P189, DOI 10.1109/AVSS.2013.6636638; Helala MA, 2016, ICDSC 2016: 10TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERA, P84, DOI 10.1145/2967413.2967432; Helala MA, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.5.053020; Helala MA, 2015, LECT NOTES COMPUT SC, V9009, P314, DOI 10.1007/978-3-319-16631-5_24; Helala MA, 2014, IEEE COMPUT SOC CONF, P800, DOI 10.1109/CVPRW.2014.122; Hutter F., 2013, P 15 ANN C COMP GEN, P1209; Hutter F., 2007, P 22 C ARTIFICIAL IN, V7, P1152; Hutter F, 2010, LECT NOTES COMPUT SC, V6073, P281, DOI 10.1007/978-3-642-13800-3_30; Hutter F, 2009, J ARTIF INTELL RES, V36, P267, DOI 10.1613/jair.2861; Jones DR, 1998, J GLOBAL OPTIM, V13, P455, DOI 10.1023/A:1008306431147; Kim D, 2010, IEEE SIGNAL PROC MAG, V27, P97, DOI 10.1109/MSP.2009.935384; Kim G, 2013, PROC CVPR IEEE, P620, DOI 10.1109/CVPR.2013.86; Kim K, 2004, IEEE IMAGE PROC, P3061; Kisilev P., 2010, P BRIT MACH VIS C, P1; Kong H, 2010, IEEE T IMAGE PROCESS, V19, P2211, DOI 10.1109/TIP.2010.2045715; Lai ZH, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225095; Loy CC, 2012, PROC CVPR IEEE, P1560, DOI 10.1109/CVPR.2012.6247847; Lu CW, 2013, PROC CVPR IEEE, P415, DOI 10.1109/CVPR.2013.60; Marlin T.E., 2003, PROCESS CONTROL DESI, V6, P263, DOI [10.1016/s0959-1524(96)90017-7, DOI 10.1016/S0959-1524(96)90017-7]; MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814; Meghdadi AH, 2013, IEEE T VIS COMPUT GR, V19, P2119, DOI 10.1109/TVCG.2013.168; Rice J. R., 1976, Advances in computers, vol.15, P65, DOI 10.1016/S0065-2458(08)60520-3; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Schuster R., 2010, P INT C MULT, V1, P1307; Sherrah J, 2010, LECT NOTES COMPUT SC, V6474, P414, DOI 10.1007/978-3-642-17688-3_39; Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005; Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308; Tabernik Domen, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P93, DOI 10.1007/978-3-642-39402-7_10; Wang D, 2011, PROC VLDB ENDOW, V4, P634, DOI 10.14778/2021017.2021021; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Xu CL, 2012, LECT NOTES COMPUT SC, V7577, P626, DOI 10.1007/978-3-642-33783-3_45; Yang JC, 2012, IEEE T MULTIMEDIA, V14, P1642, DOI 10.1109/TMM.2012.2198458; Yenikaya S, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522970; Yu K, 2016, COMM COM INF SC, V664, P37, DOI 10.1007/978-981-10-3476-3_5; Zhang HT, 2016, LECT NOTES COMPUT SC, V9784, P309, DOI 10.1007/978-3-319-42553-5_26; Zhou Z.-H, 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207	59	0	0	18	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					905	923		10.1109/TPAMI.2020.3015867	http://dx.doi.org/10.1109/TPAMI.2020.3015867			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32780697				2022-12-18	WOS:000740006100027
J	Vo, M; Sheikh, Y; Narasimhan, SG				Vo, Minh; Sheikh, Yaser; Narasimhan, Srinivasa G.			Spatiotemporal Bundle Adjustment for Dynamic 3D Human Reconstruction in the Wild	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Spatiotemporal bundle adjustment; motion prior; temporal alignment; dynamic 3D reconstruction; human model fitting		Bundle adjustment jointly optimizes camera intrinsics and extrinsics and 3D point triangulation to reconstruct a static scene. The triangulation constraint, however, is invalid for moving points captured in multiple unsynchronized videos and bundle adjustment is not designed to estimate the temporal alignment between cameras. We present a spatiotemporal bundle adjustment framework that jointly optimizes four coupled sub-problems: estimating camera intrinsics and extrinsics, triangulating static 3D points, as well as sub-frame temporal alignment between cameras and computing 3D trajectories of dynamic points. Key to our joint optimization is the careful integration of physics-based motion priors within the reconstruction pipeline, validated on a large motion capture corpus of human subjects. We devise an incremental reconstruction and alignment algorithm to strictly enforce the motion prior during the spatiotemporal bundle adjustment. This algorithm is further made more efficient by a divide and conquer scheme while still maintaining high accuracy. We apply this algorithm to reconstruct 3D motion trajectories of human bodies in dynamic events captured by multiple uncalibrated and unsynchronized video cameras in the wild. To make the reconstruction visually more interpretable, we fit a statistical 3D human body model to the asynchronous video streams. Compared to the baseline, the fitting significantly benefits from the proposed spatiotemporal bundle adjustment procedure. Because the videos are aligned with sub-frame precision, we reconstruct 3D motion at much higher temporal resolution than the input videos. Website: http://www.cs.cmu.edu/similar to ILIM/projects/IM/STBA	[Vo, Minh; Sheikh, Yaser; Narasimhan, Srinivasa G.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Vo, M (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	mpvo@cs.cmu.edu; yaser@cs.cmu.edu; srinivas@cs.cmu.edu	Vo, Minh/F-4937-2012	Vo, Minh/0000-0002-4608-7696; Narasimhan, Srinivasa/0000-0003-0389-1921	NSF [CNS-1446601]; ONR [N00014-14-1-0595]; Heinz Endowments "Platform Pittsburgh"; 2017 Qualcomm Innovation Fellowship; Metro 21 grants	NSF(National Science Foundation (NSF)); ONR(Office of Naval Research); Heinz Endowments "Platform Pittsburgh"; 2017 Qualcomm Innovation Fellowship; Metro 21 grants	This work was supported by NSF CNS-1446601, ONR N00014-14-1-0595, Heinz Endowments "Platform Pittsburgh", Metro 21 grants, and an Adobe Research Gift. The work of Minh Vo was supported in part by the 2017 Qualcomm Innovation Fellowship.	Albl C, 2015, PROC CVPR IEEE, P2292, DOI 10.1109/CVPR.2015.7298842; [Anonymous], 2004, P ADV CONC INT VIS S; Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Basha T, 2012, LECT NOTES COMPUT SC, V7577, P654, DOI 10.1007/978-3-642-33783-3_47; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257; Caspi Y, 2006, INT J COMPUT VISION, V68, P53, DOI 10.1007/s11263-005-4842-z; Elhayek A., 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P266, DOI 10.1007/978-3-642-32717-9_27; Feynman R. P., 1963, MAINLY ELECTROMAGNET, VII; Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802; Gaspar T, 2014, LECT NOTES COMPUT SC, V8689, P189, DOI 10.1007/978-3-319-10590-1_13; Geyer C., 2005, 6 OMNIVIS WS; Guler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762; Huang YH, 2017, INT CONF 3D VISION, P421, DOI 10.1109/3DV.2017.00055; Ito E, 2017, PROC CVPR IEEE, P4512, DOI 10.1109/CVPR.2017.480; Ji D, 2016, LECT NOTES COMPUT SC, V9910, P3, DOI 10.1007/978-3-319-46466-4_1; Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868; Kessler SE, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00199; Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500; Latimer R., 2014, P EUR C COMP VIS, P561; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013; Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554; Oth L, 2013, PROC CVPR IEEE, P1360, DOI 10.1109/CVPR.2013.179; Ovren H, 2018, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.2018.00041; Padua FLC, 2010, IEEE T PATTERN ANAL, V32, P304, DOI 10.1109/TPAMI.2008.301; Park HS, 2015, INT J COMPUT VISION, V115, P115, DOI 10.1007/s11263-015-0804-2; Raguse K., 2006, P ISPRS COMM 5 S IM, P254; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Schonberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31; Simon T, 2014, LECT NOTES COMPUT SC, V8691, P204, DOI 10.1007/978-3-319-10578-9_14; Snavely N, 2008, PROC CVPR IEEE, P2617; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Strang G, 1999, SIAM REV, V41, P135, DOI 10.1137/S0036144598336745; Tresadern PA, 2009, COMPUT VIS IMAGE UND, V113, P891, DOI 10.1016/j.cviu.2009.03.012; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; Tung HYF, 2017, ADV NEUR IN, V30; Valmadre J, 2012, PROC CVPR IEEE, P1394, DOI 10.1109/CVPR.2012.6247826; Vo M, 2021, IEEE T PATTERN ANAL, V43, P2794, DOI 10.1109/TPAMI.2020.2974726; Vo M, 2016, PROC CVPR IEEE, P1710, DOI 10.1109/CVPR.2016.189; Vo M, 2012, OPT EXPRESS, V20, P16926, DOI 10.1364/OE.20.016926; Wang O, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601208; Wedge D, 2006, LECT NOTES COMPUT SC, V3852, P832; Wu Changchang, 2011, VISUALSFM VISUAL STR, P1; Zeisl B., 2009, P BRIT MACH VIS C; Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076; Zheng EL, 2018, IEEE T PATTERN ANAL, V40, P2223, DOI 10.1109/TPAMI.2017.2742950; Zhou Kaiyang, 2019, ARXIV191006827; Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311	53	0	0	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					1066	1080		10.1109/TPAMI.2020.3012429	http://dx.doi.org/10.1109/TPAMI.2020.3012429			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32750836	Green Submitted			2022-12-18	WOS:000740006100037
J	Xue, F; Wang, X; Wang, JQ; Zha, HB				Xue, Fei; Wang, Xin; Wang, Junqiu; Zha, Hongbin			Deep Visual Odometry With Adaptive Memory	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Task analysis; Tracking; Simultaneous localization and mapping; Pose estimation; History; Visual odometry; recurrent neural networks; memory; attention		We propose a novel deep visual odometry (VO) method that considers global information by selecting memory and refining poses. Existing learning-based methods take the VO task as a pure tracking problem via recovering camera poses from image snippets, leading to severe error accumulation. Global information is crucial for alleviating accumulated errors. However, it is challenging to effectively preserve such information for end-to-end systems. To deal with this challenge, we design an adaptive memory module, which progressively and adaptively saves the information from local to global in a neural analogue of memory, enabling our system to process long-term dependency. Benefiting from global information in the memory, previous results are further refined by an additional refining module. With the guidance of previous outputs, we adopt a spatial-temporal attention to select features for each view based on the co-visibility in feature domain. Specifically, our architecture consisting of Tracking, Remembering and Refining modules works beyond tracking. Experiments on the KITTI and TUM-RGBD datasets demonstrate that our approach outperforms state-of-the-art methods by large margins and produces competitive results against classic approaches in regular scenes. Moreover, our model achieves outstanding performance in challenging scenarios such as texture-less regions and abrupt motions, where classic algorithms tend to fail.	[Xue, Fei; Wang, Xin; Zha, Hongbin] Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China; [Wang, Junqiu] AVIC Aviat Ind Corp China, Beijing Changcheng Aeronaut Measurement & Control, Beijing 10081, Peoples R China	Peking University; Aviation Industry Corporation of China (AVIC)	Xue, F (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.	feixue@pku.edu.cn; xinwang_cis@pku.edu.cn; jerywangjq@foxmail.com; zha@cis.pku.edu.cn		Wang, Xin/0000-0002-4279-9063	National Key Research and Development Program of China [2017YFB1002601]; National Natural Science Foundation of China [61632003, 61771026]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The work was supported by the National Key Research and Development Program of China (2017YFB1002601) and National Natural Science Foundation of China (61632003, 61771026).	Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13; Almalioglu Y, 2019, IEEE INT CONF ROBOT, P5474, DOI 10.1109/ICRA.2019.8793512; Babu VM, 2018, IEEE INT C INT ROBOT, P1082, DOI 10.1109/IROS.2018.8593864; Bloesch M, 2018, PROC CVPR IEEE, P2560, DOI 10.1109/CVPR.2018.00271; Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203; Brahmbhatt S, 2018, PROC CVPR IEEE, P2616, DOI 10.1109/CVPR.2018.00277; Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754; Clark R, 2018, LECT NOTES COMPUT SC, V11212, P291, DOI 10.1007/978-3-030-01237-3_18; Clark R, 2017, PROC CVPR IEEE, P2652, DOI 10.1109/CVPR.2017.284; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577; Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54; Engel J, 2013, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2013.183; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Henriques JF, 2018, PROC CVPR IEEE, P8476, DOI 10.1109/CVPR.2018.00884; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Iyer G, 2018, IEEE COMPUT SOC CONF, P380, DOI 10.1109/CVPRW.2018.00064; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Khan R.A., 2018, POWER INDIA INT C, V8, P1, DOI [10.1109/POWERI.2018.8704366, DOI 10.1109/POWERI.2018.8704366]; Kingma D.P., 2015, INT C LEARN REPR, P1; Klein George, 2007, P1; Kumar A, 2018, ADV NEUR IN, V31; Li RH, 2018, IEEE INT CONF ROBOT, P7286; Li Y, 2019, IEEE INT CONF ROBOT, P5439, DOI 10.1109/ICRA.2019.8793706; Lianos KN, 2018, LECT NOTES COMPUT SC, V11208, P246, DOI 10.1007/978-3-030-01225-0_15; Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594; Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103; Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513; Parisotto E, 2018, IEEE COMPUT SOC CONF, P350, DOI 10.1109/CVPRW.2018.00061; Parisotto Emilio, 2018, INT C LEARN REPR; Pascanu R., 2013, P 30 INT C INT C MAC, P1310; Paszke Adam, 2017, PYTORCH; Ranjan A, 2019, IEEE I CONF COMP VIS, P2404, DOI 10.1109/ICCV.2019.00249; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Saputra MRU, 2019, IEEE INT CONF ROBOT, P3549, DOI 10.1109/ICRA.2019.8793581; Shi XJ, 2015, ADV NEUR IN, V28; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Sukhbaatar S., 2015, ADV NEURAL INFORM PR, P175, DOI 10.1145/3130348.3130364; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Tang CR, 2020, PHARMACOLOGY, V105, P339, DOI 10.1159/000503865; Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695; Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596; Wang R, 2017, IEEE I CONF COMP VIS, P3923, DOI 10.1109/ICCV.2017.421; Wang S, 2018, INT J ROBOT RES, V37, P513, DOI 10.1177/0278364917734298; Wang S, 2017, INT CONF ACOUST SPEE, P436, DOI 10.1109/ICASSP.2017.7952193; Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826; Xian K, 2018, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2018.00040; Xue F., 2018, PROC ASIAN C COMPUT, P293; Xue F, 2019, PROC CVPR IEEE, P8567, DOI 10.1109/CVPR.2019.00877; Yang N, 2018, LECT NOTES COMPUT SC, V11212, P835, DOI 10.1007/978-3-030-01237-3_50; Yin XC, 2017, IEEE I CONF COMP VIS, P5871, DOI 10.1109/ICCV.2017.625; Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212; Younes G, 2017, ROBOT AUTON SYST, V98, P67, DOI 10.1016/j.robot.2017.09.010; Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043; Zhang Jingwei, 2017, ARXIV170609520; Zhao C, 2018, IEEE INT C INT ROBOT, P6864, DOI 10.1109/IROS.2018.8594151; Zhou HZ, 2018, LECT NOTES COMPUT SC, V11220, P851, DOI 10.1007/978-3-030-01270-0_50; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI 10.1007/978-3-030-01219-9_	62	0	0	6	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					940	954		10.1109/TPAMI.2020.3014100	http://dx.doi.org/10.1109/TPAMI.2020.3014100			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32749962	Green Submitted			2022-12-18	WOS:000740006100029
J	Yan, YC; Zhuang, N; Ni, BB; Zhang, J; Xu, MH; Zhang, Q; Zheng, Z; Cheng, S; Tian, Q; Xu, Y; Yang, XK; Zhang, WJ				Yan, Yichao; Zhuang, Ning; Ni, Bingbing; Zhang, Jian; Xu, Minghao; Zhang, Qiang; Zheng, Zhang; Cheng, Shuo; Tian, Qi; Xu, Yi; Yang, Xiaokang; Zhang, Wenjun			Fine-Grained Video Captioning via Graph-based Multi-Granularity Interaction Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video caption; representation learning; graphCNN; fine-grained; multiple granularity	SEGMENTATION	Learning to generate continuous linguistic descriptions for multi-subject interactive videos in great details has particular applications in team sports auto-narrative. In contrast to traditional video caption, this task is more challenging as it requires simultaneous modeling of fine-grained individual actions, uncovering of spatio-temporal dependency structures of frequent group interactions, and then accurate mapping of these complex interaction details into long and detailed commentary. To explicitly address these challenges, we propose a novel framework Graph-based Learning for Multi-Granularity Interaction Representation (GLMGIR) for fine-grained team sports auto-narrative task. A multi-granular interaction modeling module is proposed to extract among-subjects' interactive actions in a progressive way for encoding both intra- and inter-team interactions. Based on the above multi-granular representations, a multi-granular attention module is developed to consider action/event descriptions of multiple spatio-temporal resolutions. Both modules are integrated seamlessly and work in a collaborative way to generate the final narrative. In the meantime, to facilitate reproducible research, we collect a new video dataset from YouTube.com called Sports Video Narrative dataset (SVN). It is a novel direction as it contains 6 K team sports videos (i.e., NBA basketball games) with 10K ground-truth narratives(e.g., sentences). Furthermore, as previous metrics such as METEOR (i.e., used in coarse-grained video caption task) DO NOT cope with fine-grained sports narrative task well, we hence develop a novel evaluation metric named Fine-grained Captioning Evaluation (FCE), which measures how accurate the generated linguistic description reflects fine-grained action details as well as the overall spatio-temporal interactional structure. Extensive experiments on our SVN dataset have demonstrated the effectiveness of the proposed framework for fine-grained team sports video auto-narrative.	[Yan, Yichao; Zhuang, Ning; Ni, Bingbing; Zhang, Jian; Xu, Minghao; Zhang, Qiang; Zheng, Zhang; Cheng, Shuo; Xu, Yi; Zhang, Wenjun] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China; [Yang, Xiaokang] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China; [Tian, Qi] Univ Texas San Antonio, San Antonio, TX 78249 USA	Shanghai Jiao Tong University; Shanghai Jiao Tong University; University of Texas System; University of Texas at San Antonio (UTSA)	Ni, BB (corresponding author), Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.	yanyichao@sjtu.edu.cn; ningz.huang@sjtu.edu.cn; nibingbing@sjtu.edu.cn; stevenash0822@sjtu.edu.cn; xuminghao118@sjtu.edu.cn; zhangqiang2016@sjtu.edu.cn; 123derrick@sjtu.edu.cn; acccheng94@gmail.com; qitian@cs.utsa.edu; xuyi@sjtu.edu.cn; yangxiaokang@sjtu.edu.cn; zhangwenjun@sjtu.edu.cn	Yan, Yichao/ADT-5511-2022	Yan, Yichao/0000-0003-3209-8965; Xu, Minghao/0000-0001-7468-8790; Cheng, Shuo/0000-0002-4477-9875; ZHENG, ZHANG/0000-0002-7170-3884	State Key Research and Development Program [2016YFB1001003]; National Natural Science Foundation of China [61976137, U1611461]; MoE-China Mobile Research Fund Project [MCM20180702]; 111 Project [B07022, 150633]; Shanghai Key Laboratory of Digital Media Processing and Transmissions; SJTU-BIGO Joint Research Fund; CCF-Tencent Open Fund	State Key Research and Development Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); MoE-China Mobile Research Fund Project; 111 Project(Ministry of Education, China - 111 Project); Shanghai Key Laboratory of Digital Media Processing and Transmissions; SJTU-BIGO Joint Research Fund; CCF-Tencent Open Fund	The work was supported by State Key Research and Development Program (2016YFB1001003). This work was supported by National Natural Science Foundation of China (61976137, U1611461), MoE-China Mobile Research Fund Project (MCM20180702), the 111 Project (B07022 and Sheitc No.150633) and the Shanghai Key Laboratory of Digital Media Processing and Transmissions. This work was also supported by SJTU-BIGO Joint Research Fund, and CCF-Tencent Open Fund. Yichao Yan, Ning Zhuang, and Bingbing Ni are contribution equally to this paper. Corresponding author is Bingbing Ni.	[Anonymous], C N AM ASS COMP LING; Aradhye H, 2009, INT CONF DAT MIN WOR, P144, DOI 10.1109/ICDMW.2009.79; Ba J., 2015, ICLR 2015 C TRACK P; Banerjee Satanjeev, 2005, P ACL WORKSH INTR EX, P65; Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128; Botvinick M, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0480; Bouvrie J. V., 2009, THESIS MIT CAMBRIDGE; Cao Z., 2016, ARXIV161108050; Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47; Charles R., 2017, ADV NEURAL INFORM PR; Chen HC, 2018, AAAI CONF ARTIF INTE, P2127; Chen X, 2015, CORR, V1504, P325; Cheron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Das P, 2013, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2013.340; Ding L, 2011, IEEE I CONF COMP VIS, P699, DOI 10.1109/ICCV.2011.6126306; Ding L, 2010, LECT NOTES COMPUT SC, V6314, P410, DOI 10.1007/978-3-642-15561-1_30; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127; Gavves E, 2013, IEEE I CONF COMP VIS, P1713, DOI 10.1109/ICCV.2013.215; Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337; Hermosilla P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275110; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jiang Mingyang, 2018, ARXIV180700652; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kingma D.P., 2015, 3 INT C LEARN REPR I, P1, DOI DOI 10.1007/S11390-017-1754-7; Klimek M., 2017, C ROB LEARN, P301; Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811; Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608; Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356; Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83; Krishnamoorthy N., 2013, P WORKSHOP VISION NA, P10; Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162; Lea C, 2016, IEEE INT CONF ROBOT, P1642, DOI 10.1109/ICRA.2016.7487305; Lea C, 2015, IEEE WINT CONF APPL, P1123, DOI 10.1109/WACV.2015.154; Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020; Lingling Tao, 2012, Information Processing in Computer-Assisted Interventions. Proceedings Third International Conference, IPCAI 2012, P167, DOI 10.1007/978-3-642-30618-1_17; Liu JX, 2012, LECT NOTES COMPUT SC, V7572, P172, DOI 10.1007/978-3-642-33718-5_13; Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713; Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754; Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345; Luong M., 2015, ARXIV150804025; Mavroudi E, 2018, IEEE WINT CONF APPL, P1558, DOI 10.1109/WACV.2018.00174; Newell A., 2017, P 31 INT C NEUR INF, P2277; Newell A, 2017, ADV NEUR IN, V30; Ni BB, 2014, PROC CVPR IEEE, P756, DOI 10.1109/CVPR.2014.102; Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102; Ramanathan V, 2013, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2013.320; Rasmussen D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180234; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rohrbach A, 2015, LECT NOTES COMPUT SC, V9358, P209, DOI 10.1007/978-3-319-24947-6_17; Rohrbach A, 2014, LECT NOTES COMPUT SC, V8753, P184, DOI 10.1007/978-3-319-11752-2_15; Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61; Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801; Rosen J, 2006, IEEE T BIO-MED ENG, V53, P399, DOI 10.1109/TBME.2005.869771; Sermanet P., 2015, INT C LEARN REPR ICL; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shen ZQ, 2017, PROC CVPR IEEE, P5159, DOI 10.1109/CVPR.2017.548; Shih K.J., 2015, BRIT MACH VIS C, DOI DOI 10.5244/C.29.128; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Song JK, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2737; Sutskever I., 2014, P ADV INT C NEUR INF, P3104; Tao LL, 2013, LECT NOTES COMPUT SC, V8151, P339, DOI 10.1007/978-3-642-40760-4_43; Thomason Jesse, 2014, P 25 INT C COMP LING, P1218; Vaswani A, 2017, ADV NEUR IN, V30; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Venugopalan, 2016, ARXIV160401729; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276; Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362; Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685; Xie SN, 2018, PROC CVPR IEEE, P4606, DOI 10.1109/CVPR.2018.00484; Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yan YC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1032, DOI 10.1145/3123266.3123358; Yang S., 2012, ADV NEURAL INFORM PR, P3122; Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512; Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496; Yu HY, 2018, PROC CVPR IEEE, P6006, DOI 10.1109/CVPR.2018.00629; Zhang XS, 2017, PROC CVPR IEEE, P6250, DOI 10.1109/CVPR.2017.662	91	0	0	5	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					666	683		10.1109/TPAMI.2019.2946823	http://dx.doi.org/10.1109/TPAMI.2019.2946823			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	31613750				2022-12-18	WOS:000740006100010
J	Zhou, YY; Ji, RR; Sun, XS; Su, JS; Meng, DY; Gao, Y; Shen, CH				Zhou, Yiyi; Ji, Rongrong; Sun, Xiaoshuai; Su, Jinsong; Meng, Deyu; Gao, Yue; Shen, Chunhua			Plenty is Plague: Fine-Grained Learning for Visual Question Answering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Visualization; Knowledge discovery; Redundancy; Data models; Feature extraction; Training data; Fine-grained learning; visual question answering		Visual Question Answering (VQA) has attracted extensive research focus recently. Along with the ever-increasing data scale and model complexity, the enormous training cost has become an emerging challenge for VQA. In this article, we show such a massive training cost is indeed plague. In contrast, a fine-grained design of the learning paradigm can be extremely beneficial in terms of both training efficiency and model accuracy. In particular, we argue that there exist two essential and unexplored issues in the existing VQA training paradigm that randomly samples data in each epoch, namely, the "difficulty diversity" and the "label redundancy". Concretely, "difficulty diversity" refers to the varying difficulty levels of different question types, while "label redundancy" refers to the redundant and noisy labels contained in individual question type. To tackle these two issues, in this article we propose a fine-grained VQA learning paradigm with an actor-critic based learning agent, termed FG-A1C. Instead of using all training data from scratch, FG-A1C includes a learning agent that adaptively and intelligently schedules the most difficult question types in each training epoch. Subsequently, two curriculum learning based schemes are further designed to identify the most useful data to be learned within each inidividual question type. We conduct extensive experiments on the VQA2.0 and VQA-CP v2 datasets, which demonstrate the significant benefits of our approach. For instance, on VQA-CP v2, with less than 75 percent of the training data, our learning paradigms can help the model achieves better performance than using the whole dataset. Meanwhile, we also shows the effectivenesss of our method in guiding data labeling. Finally, the proposed paradigm can be seamlessly integrated with any cutting-edge VQA models, without modifying their structures.	[Zhou, Yiyi] Xiamen Univ, Sch Informat, Media Analyt & Comp Lab, Informat & Commun Engn Dept, Xiamen 361005, Fujian, Peoples R China; [Ji, Rongrong; Sun, Xiaoshuai] Xiamen Univ, Sch Informat, Media Analyt & Comp Lab, Dept Artificial Intelligence, Xiamen 361005, Fujian, Peoples R China; [Su, Jinsong] Xiamen Univ, Sch Informat, Xiamen 361005, Fujian, Peoples R China; [Meng, Deyu] Macau Univ Sci & Technol, Fac Informat Technol, Macau, Peoples R China; [Meng, Deyu] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China; [Gao, Yue] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China; [Shen, Chunhua] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	Xiamen University; Xiamen University; Xiamen University; Macau University of Science & Technology; Xi'an Jiaotong University; Tsinghua University; University of Adelaide	Ji, RR (corresponding author), Xiamen Univ, Sch Informat, Media Analyt & Comp Lab, Dept Artificial Intelligence, Xiamen 361005, Fujian, Peoples R China.	yiyizhou@stu.xmu.edu.cn; rrji@xmu.edu.cn; xiaoshuaisun.hit@gmail.cm; jssu@xmu.edu.cn; dymeng@mail.xjtu.edu.cn; kevin.gaoy@gmail.com; chunhua.shen@adelaide.edu.au		Shen, Chunhua/0000-0002-8648-8718	Nature Science Foundation of China [61772443, 61572410, 61802324, 61702136]; National Key RD Program [2017YFC0113000, 2016YFB1001503]; Nature Science Foundation of Fujian Province, China [2017J01125, 2018J01106]; Key R&D Program of Jiangxi Province [20171ACH80022]	Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key RD Program; Nature Science Foundation of Fujian Province, China(Natural Science Foundation of Fujian Province); Key R&D Program of Jiangxi Province	This work was supported by the Nature Science Foundation of China (No.U1705262, No.61772443, No.61572410, No.61802324, and No.61702136) National Key R&D Program (No.2017YFC0113000 and No.2016YFB1001503), and Nature Science Foundation of Fujian Province, China (No. 2017J01125 and No. 2018J01106), and Key R&D Program of Jiangxi Province (No. 20171ACH80022).	Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Andreas Jacob, 2016, ARXIV160101705, P1545, DOI [DOI 10.18653/V1/N16-1181, 10.18653/v1/N16-1181]; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Bachman P, 2017, PR MACH LEARN RES, V70; Bahdanau Dzmitry, 2016, ARXIV160707086; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Chen X, 2015, CORR, V1504, P325; Fan Y, 2017, INT C LEARN REPR WOR; Fukui Akira, 2016, ARXIV160601847; Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Grondman I, 2012, IEEE T SYST MAN CY C, V42, P1291, DOI 10.1109/TSMCC.2012.2218595; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jiang L, 2015, AAAI CONF ARTIF INTE, P2694; Jiang L, 2014, ADV NEUR IN, V27; Jiang Yu, 2018, ARXIV180709956; Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215; Jun SH, 2017, ICEC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, DOI 10.1145/3154943.3154947; Kim Jin-Hwa, 2016, ICLR; Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004; Kim Y., 2017, ABS170200887 CORR; King DB, 2015, ACS SYM SER, V1214, P1; Konda VR, 2000, ADV NEUR IN, V12, P1008; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3; Liu M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1874; Lu JS, 2016, ADV NEUR IN, V29; Ma L., 2015, ARXIV150600333; Misra I, 2018, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2018.00009; Mnih V, 2016, PR MACH LEARN RES, V48; Patro B, 2018, PROC CVPR IEEE, P7680, DOI 10.1109/CVPR.2018.00801; Precup D., 2000, P 17 INT C MACH LEAR; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Settles B, 2008, P 2008 C EMP METH NA, ppp1070, DOI DOI 10.3115/1613715.1613855; Settles Burr, 2010, ACTIVE LEARNING LIT, P11, DOI DOI 10.1111/J.1467-7687.2012.01135.X; Sutton R. S., 1988, Machine Learning, V3, P9, DOI 10.1023/A:1022633531479; Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444; Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243; Vlachos A., 2004, ACTIVE LEARNING SUPP; Wang P., 2016, ARXIV161205386; Wang Z., 2016, ARXIV161101224; Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500; Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202; Zhou ZW, 2017, PROC CVPR IEEE, P4761, DOI 10.1109/CVPR.2017.506; Zhu C, 2017, IEEE I CONF COMP VIS, P1300, DOI 10.1109/ICCV.2017.145	50	0	0	5	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					697	709		10.1109/TPAMI.2019.2956699	http://dx.doi.org/10.1109/TPAMI.2019.2956699			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	31796387				2022-12-18	WOS:000740006100012
J	Dickinson, S				Dickinson, Sven			State of the Journal Editorial	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					1	10		10.1109/TPAMI.2021.3122153	http://dx.doi.org/10.1109/TPAMI.2021.3122153			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY		Bronze			2022-12-18	WOS:000728561300001
J	Lam, BSY; Liew, AWC				Lam, Benson Shu Yan; Liew, Alan Wee-Chung			A Fast Binary Quadratic Programming Solver Based on Stochastic Neighborhood Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Binary quadratic programming; stochastic optimization; binary restoration; graph bisection; optimization	OPTIMIZATION; ALGORITHMS	Many image processing and pattern recognition problems can be formulated as binary quadratic programming (BQP) problems. However, solving a large BQP problem with a good quality solution and low computational time is still a challenging unsolved problem. Current methodologies either adopt an independent random search in a semi-definite space or perform search in a relaxed biconvex space. However, the independent search has great computation cost as many different trials are needed to get a good solution. The biconvex search only searches the solution in a local convex ball, which can be a local optimal solution. In this paper, we propose a BQP solver that alternatingly applies a deterministic search and a stochastic neighborhood search. The deterministic search iteratively improves the solution quality until it satisfies the KKT optimality conditions. The stochastic search performs bootstrapping sampling to the objective function constructed from the potential solution to find a stochastic neighborhood vector. These two steps are repeated until the obtained solution is better than many of its stochastic neighborhood vectors. We compare the proposed solver with several state-of-the-art methods for a range of image processing and pattern recognition problems. Experimental results showed that the proposed solver not only outperformed them in solution quality but also with the lowest computational complexity.	[Lam, Benson Shu Yan] Hang Seng Univ Hong Kong, Dept Math Stat & Insurance, Sin Lek Yuen, Hong Kong, Peoples R China; [Liew, Alan Wee-Chung] Griffith Univ, Sch Informat & Commun Technol, Brisbane, Qld, Australia	Hang Seng University of Hong Kong; Griffith University	Liew, AWC (corresponding author), Griffith Univ, Sch Informat & Commun Technol, Brisbane, Qld, Australia.	bensonlam@hsu.edu.hk; a.liew@griffith.edu.au	Liew, Alan Wee-Chung/F-6988-2011	Liew, Alan Wee-Chung/0000-0001-6718-7584	Research Grants Council of the Hong Kong Special Administrative Region, China [UGC/FDS14/E03/14, UGC/FDS14/P04/17]; Big Data Intelligence Centre of the Hang Seng University of Hong Kong	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council); Big Data Intelligence Centre of the Hang Seng University of Hong Kong	This work was supported in part by the grants from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. UGC/FDS14/E03/14 and UGC/FDS14/P04/17). The authors would like to thank to the great support from the Big Data Intelligence Centre of the Hang Seng University of Hong Kong. They are also thankful to the anonymous reviewers for their valuable comments that greatly helped to improve the paper.	Bi SJ, 2014, SIAM J SCI COMPUT, V36, pA1451, DOI 10.1137/110855867; Botelho-Andrade S, 2019, MATH INEQUAL APPL, V22, P59, DOI 10.7153/mia-2019-22-04; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Chandna S, 2013, IEEE T SIGNAL PROCES, V61, P5260, DOI 10.1109/TSP.2013.2279076; Chiverton J, 2012, IEEE T IMAGE PROCESS, V21, P1231, DOI 10.1109/TIP.2011.2167343; Cour T, 2007, ARTIF INTELL, P75; Feige U, 2002, RANDOM STRUCT ALGOR, V20, P403, DOI 10.1002/rsa.10036; Gentile C, 2017, PR MACH LEARN RES, V70; Glover F., 1989, ORSA Journal on Computing, V1, P190, DOI [10.1287/ijoc.2.1.4, 10.1287/ijoc.1.3.190]; Glover F., 1990, ORSA J COMPUTING, V2, P4, DOI [10.1287/ijoc.2.1.4, DOI 10.1287/IJOC.2.1.4]; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Guattery S, 1998, SIAM J MATRIX ANAL A, V19, P701, DOI 10.1137/S0895479896312262; GULATI VP, 1984, EUR J OPER RES, V15, P121, DOI 10.1016/0377-2217(84)90055-9; Huang HX, 2006, COMPUT OPTIM APPL, V33, P187, DOI 10.1007/s10589-005-3062-3; Javed S, 2017, IEEE T IMAGE PROCESS, V26, P5840, DOI 10.1109/TIP.2017.2746268; Kannan R, 2004, J ACM, V51, P497, DOI 10.1145/990308.990313; Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175; Kar P, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1625, DOI 10.1145/2939672.2939832; Keuchel J, 2003, IEEE T PATTERN ANAL, V25, P1364, DOI 10.1109/TPAMI.2003.1240111; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kochenberger G, 2014, J COMB OPTIM, V28, P58, DOI 10.1007/s10878-014-9734-0; Lang K., 2005, ADV NEURAL INFORM PR, P715; Lauer F, 2009, IEEE I CONF COMP VIS, P678, DOI 10.1109/ICCV.2009.5459173; Lu HC, 2017, IEEE T IMAGE PROCESS, V26, P414, DOI 10.1109/TIP.2016.2627804; Markopoulos PP, 2017, IEEE T SIGNAL PROCES, V65, P4252, DOI 10.1109/TSP.2017.2708023; Markopoulos PP, 2014, IEEE T SIGNAL PROCES, V62, P5046, DOI 10.1109/TSP.2014.2338077; Mauri GR, 2011, INT T OPER RES, V18, P257, DOI 10.1111/j.1475-3995.2009.00743.x; Mitchell M., 1998, INTRO GENETIC ALGORI; Murray W, 2010, COMPUT OPTIM APPL, V47, P257, DOI 10.1007/s10589-008-9218-1; Nguyen XV, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P512, DOI 10.1145/2623330.2623611; Olsson C, 2008, COMPUT VIS IMAGE UND, V112, P3, DOI 10.1016/j.cviu.2008.05.010; Olsson C, 2007, IEEE I CONF COMP VIS, P2025; RAGHAVACHARI M, 1969, OPER RES, V17, P680, DOI 10.1287/opre.17.4.680; Rudeanu, 1968, BOOLEAN METHODS OPER, V5; Schellewald C, 2005, LECT NOTES COMPUT SC, V3757, P171, DOI 10.1007/11585978_12; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Stein E.M., 2011, FUNCTIONAL ANAL INTR, V4; Sun XL, 2012, J GLOBAL OPTIM, V53, P255, DOI 10.1007/s10898-011-9683-4; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Toh KC, 1999, OPTIM METHOD SOFTW, V11-2, P545, DOI 10.1080/10556789908805762; Tutuncu RH, 2003, MATH PROGRAM, V95, P189, DOI 10.1007/s10107-002-0347-5; Wang P, 2017, IEEE T PATTERN ANAL, V39, P470, DOI 10.1109/TPAMI.2016.2541146; Wang P, 2013, PROC CVPR IEEE, P1312, DOI 10.1109/CVPR.2013.173; Wu BY, 2019, IEEE T PATTERN ANAL, V41, P1695, DOI 10.1109/TPAMI.2018.2845842; Yang Wang, 2012, Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems. Proceedings 9th International Conference, CPAIOR 2012, P395, DOI 10.1007/978-3-642-29828-8_26; Yu SX, 2004, IEEE T PATTERN ANAL, V26, P173, DOI 10.1109/TPAMI.2004.1262179; Yuan GZ, 2017, AAAI CONF ARTIF INTE, P2867; Zhang ZG, 2007, IEEE DATA MINING, P391, DOI 10.1109/ICDM.2007.99; Zhao RQ, 2016, IEEE T PATTERN ANAL, V38, P1640, DOI 10.1109/TPAMI.2015.2481404; Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236	51	0	0	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					32	49		10.1109/TPAMI.2020.3010811	http://dx.doi.org/10.1109/TPAMI.2020.3010811			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750824	Green Published			2022-12-18	WOS:000728561300004
J	Lee, KM				Lee, Kyoung Mu			Editorial	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					11	12		10.1109/TPAMI.2021.3121153	http://dx.doi.org/10.1109/TPAMI.2021.3121153			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY		Bronze			2022-12-18	WOS:000728561300002
J	Lyu, SW; Fan, YB; Ying, YM; Hu, BG				Lyu, Siwei; Fan, Yanbo; Ying, Yiming; Hu, Bao-Gang			Average Top-k Aggregate Loss for Supervised Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Aggregate loss; average top-k loss; supervised learning; learning theory	COORDINATE DESCENT METHOD; CONVERGENCE; OPTIMIZATION; MULTICLASS; ALGORITHM	In this work, we introduce the average top-k (AT(k)) loss, which is the average over the k largest individual losses over a training data, as a new aggregate loss for supervised learning. We show that the AT(k) loss is a natural generalization of the two widely used aggregate losses, namely the average loss and the maximum loss. Yet, the AT(k) loss can better adapt to different data distributions because of the extra flexibility provided by the different choices of k. Furthermore, it remains a convex function over all individual losses and can be combined with different types of individual loss without significant increase in computation. We then provide interpretations of the AT(k) loss from the perspective of the modification of individual loss and robustness to training data distributions. We further study the classification calibration of the AT(k) loss and the error bounds of AT(k)-SVM model. We demonstrate the applicability of minimum average top-k learning for supervised learning problems including binary/multi-class classification and regression, using experiments on both synthetic and real datasets.	[Lyu, Siwei] SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA; [Fan, Yanbo] Tencent AI Lab, Shenzhen 518000, Peoples R China; [Ying, Yiming] SUNY Albany, Dept Math & Stat, Albany, NY 12222 USA; [Hu, Bao-Gang] Univ Chinese Acad Sci, Natl Lab Pattern Recognit CASIA, Beijing 100190, Peoples R China	State University of New York (SUNY) System; State University of New York (SUNY) Albany; Tencent; State University of New York (SUNY) System; State University of New York (SUNY) Albany; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Fan, YB (corresponding author), Tencent AI Lab, Shenzhen 518000, Peoples R China.	slyu@albany.edu; fanyanbo0124@gmail.com; yying@albany.edu; hubg@nlpr.ia.ac.cn	Ying, Yiming/AGD-7246-2022	Ying, Yiming/0000-0001-7345-6672; Hu, Bao-Gang/0000-0002-6916-5394	US National Science Foundation [IIS-1816227]; U.S. Army Research Office [73042CS]; National Science Foundation of China [61620106003]; National Key Research and Development Program of China [2018AAA0101005]	US National Science Foundation(National Science Foundation (NSF)); U.S. Army Research Office; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China	This work was supported in part by the US National Science Foundation under Grant No IIS-1816227, and in part by the U.S. Army Research Office under contract/grant number 73042CS. The work of Yanbo Fan was supported in part by the National Science Foundation of China under Grant 61620106003. The work of Bao-Gang Hu was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0101005.	[Anonymous], 2017, ARXIV170508826; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bousquet O., 2008, ADV NEURAL INFORM PR, P161, DOI DOI 10.7751/mitpress/8996.003.0015; Brown DB, 2007, OPER RES LETT, V35, P722, DOI 10.1016/j.orl.2007.01.001; Buja A., 2005, LOSS FUNCTIONS BINAR; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cortes C, 2004, ADV NEUR IN, V16, P313; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; De Vito E, 2005, FOUND COMPUT MATH, V5, P59, DOI 10.1007/s10208-004-0134-1; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Duda R.O., 2000, PATTERN CLASSIFICATI; Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; LAPIN M, 2015, ADV NEURAL INFORM PR, P325; Lapin M, 2018, IEEE T PATTERN ANAL, V40, P1533, DOI 10.1109/TPAMI.2017.2751607; Lapin M, 2016, PROC CVPR IEEE, P1468, DOI 10.1109/CVPR.2016.163; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin Tsung-Yi, 2017, ARXIV170802002, P2980, DOI [DOI 10.1109/ICCV.2017.324, DOI 10.1109/TPAMI.2018.2858826]; Lin Y, 2004, STAT PROBABIL LETT, V68, P73, DOI 10.1016/j.spl.2004.03.002; LUO ZQ, 1992, J OPTIMIZ THEORY APP, V72, P7, DOI 10.1007/BF00939948; Masnadi-Shirazi Hamed, 2009, P 21 INT C NEUR INF; Namkoong H, 2017, ADV NEURAL INFORM PR, V30, P2971; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Ogryczak W, 2003, INFORM PROCESS LETT, V85, P117, DOI 10.1016/S0020-0190(02)00370-8; Prashanth, 2019, P 33 INT C NEUR INF; RAKHLIN A., 2012, P INT C MACH LEARN, P1571; Reid MD, 2010, J MACH LEARN RES, V11, P2387; Rudin C, 2009, J MACH LEARN RES, V10, P2233; Saha A, 2013, SIAM J OPTIMIZ, V23, P576, DOI 10.1137/110840054; SAVAGE LJ, 1971, J AM STAT ASSOC, V66, P783, DOI 10.2307/2284229; Scholkopf B., 2001, LEARNING KERNELS SUP; Shalev-Shwartz S, 2016, PR MACH LEARN RES, V48; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; SHUFORD EH, 1966, PSYCHOMETRIKA, V31, P125, DOI 10.1007/BF02289503; Steinwart I, 2003, IEEE T PATTERN ANAL, V25, P1274, DOI 10.1109/TPAMI.2003.1233901; Tewari, 2010, ICML TUT; Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105; Usunier Nicolas, 2009, ICML; Vapnik VN, 1998, STAT LEARNING THEORY, DOI DOI 10.1007/978-1-4419-1428-6_5864; Wei K, 2015, PR MACH LEARN RES, V37, P1954; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Weston Jason, 2011, 22 INT JOINT C ART I; Wu BY, 2019, IEEE ACCESS, V7, P172683, DOI 10.1109/ACCESS.2019.2956775; Wu Q, 2006, FOUND COMPUT MATH, V6, P171, DOI 10.1007/s10208-004-0155-9; Wu YC, 2007, J AM STAT ASSOC, V102, P974, DOI 10.1198/016214507000000617; Yang M., 2010, NEURAL INFORM PROCES, P2532	53	0	0	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					76	86		10.1109/TPAMI.2020.3005393	http://dx.doi.org/10.1109/TPAMI.2020.3005393			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750797				2022-12-18	WOS:000728561300007
J	Hua, G; Hoiem, D; Gupta, A; Tu, ZW				Hua, Gang; Hoiem, Derek; Gupta, Abhinav; Tu, Zhuowen			Editorial: Introduction to the Special Section on CVPR2019 Best Papers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Hua, Gang] Wormpex AI Res, Bellevue, WA 98004 USA; [Hoiem, Derek] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; [Gupta, Abhinav] Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA; [Tu, Zhuowen] Univ Calif San Diego, Dept Cognit Sci, San Diego, CA 92093 USA	University of Illinois System; University of Illinois Urbana-Champaign; Carnegie Mellon University; University of California System; University of California San Diego	Hua, G (corresponding author), Wormpex AI Res, Bellevue, WA 98004 USA.	ganghua@gmail.com; dhoiem@illinois.edu; abhinavg@cs.cmu.edu; ztu@ucsd.edu							0	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4203	4204		10.1109/TPAMI.2021.3080715	http://dx.doi.org/10.1109/TPAMI.2021.3080715			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ		Bronze			2022-12-18	WOS:000714203900005
J	Kong, C; Lucey, S				Kong, Chen; Lucey, Simon			Deep Non-Rigid Structure From Motion With Missing Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Shape; Two dimensional displays; Encoding; Neural networks; Image reconstruction; Structure from motion; Nonrigid structure from motion; hierarchical sparse coding; deep neural network; reconstructability; missing data	THRESHOLDING ALGORITHM; SHAPE	Non-rigid structure from motion (NRSfM) refers to the problem of reconstructing cameras and the 3D point cloud of a non-rigid object from an ensemble of images with 2D correspondences. Current NRSfM algorithms are limited from two perspectives: (i) the number of images, and (ii) the type of shape variability they can handle. These difficulties stem from the inherent conflict between the condition of the system and the degrees of freedom needing to be modeled - which has hampered its practical utility for many applications within vision. In this paper we propose a novel hierarchical sparse coding model for NRSFM which can overcome (i) and (ii) to such an extent, that NRSFM can be applied to problems in vision previously thought too ill posed. Our approach is realized in practice as the training of an unsupervised deep neural network (DNN) auto-encoder with a unique architecture that is able to disentangle pose from 3D structure. Using modern deep learning computational platforms allows us to solve NRSfM problems at an unprecedented scale and shape complexity. Our approach has no 3D supervision, relying solely on 2D point correspondences. Further, our approach is also able to handle missing/occluded 2D points without the need for matrix completion. Extensive experiments demonstrate the impressive performance of our approach where we exhibit superior precision and robustness against all available state-of-the-art works in some instances by an order of magnitude. We further propose a new quality measure (based on the network weights) which circumvents the need for 3D ground-truth to ascertain the confidence we have in the reconstructability. We believe our work to be a significant advance over state-of-the-art in NRSFM.	[Kong, Chen; Lucey, Simon] Carnegie Mellon Univ, Robot Inst, 5000 Forbes Ave, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Kong, C (corresponding author), Carnegie Mellon Univ, Robot Inst, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	chenk@cs.cmu.edu; slucey@cs.cmu.edu	Lucey, Simon/HDO-1716-2022		National Science Foundation [1526033]	National Science Foundation(National Science Foundation (NSF))	This material is based upon work supported by the National Science Foundation under Grant No.1526033.	Agudo A., 2017, P IEEE C COMP VIS PA, P6262; Agudo A, 2018, PROC CVPR IEEE, P2607, DOI 10.1109/CVPR.2018.00276; Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201; Akhter I, 2009, PROC CVPR IEEE, P1534, DOI 10.1109/CVPRW.2009.5206620; Akhter Ijaz, 2009, P NIPS; Beck A, 2009, INT CONF ACOUST SPEE, P693, DOI 10.1109/ICASSP.2009.4959678; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Chang Angel X., 2015, ARXIV151203012CSGR P; Dai YC, 2014, INT J COMPUT VISION, V107, P101, DOI 10.1007/s11263-013-0684-2; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Del Bue A, 2007, IMAGE VISION COMPUT, V25, P297, DOI 10.1016/j.imavis.2005.10.004; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Drover D, 2019, LECT NOTES COMPUT SC, V11132, P78, DOI 10.1007/978-3-030-11018-5_7; Fragkiadaki Katerina, 2014, ADV NEURAL INFORM PR, P55; Gotardo PFU, 2011, IEEE I CONF COMP VIS, P802, DOI 10.1109/ICCV.2011.6126319; Gotardo PFU, 2011, IEEE T PATTERN ANAL, V33, P2051, DOI 10.1109/TPAMI.2011.50; Hamsici OC, 2012, LECT NOTES COMPUT SC, V7575, P260, DOI 10.1007/978-3-642-33765-9_19; Jensen S. H. N., 2018, ARXIV180108388; Kong C, 2019, IEEE I CONF COMP VIS, P1558, DOI 10.1109/ICCV.2019.00164; Kong C, 2016, INT CONF 3D VISION, P296, DOI 10.1109/3DV.2016.38; Kong C, 2016, PROC CVPR IEEE, P4123, DOI 10.1109/CVPR.2016.447; Kudo Y., 2018, ARXIV180308244; Lee M, 2016, PROC CVPR IEEE, P4670, DOI 10.1109/CVPR.2016.505; Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372; Papyan V, 2017, J MACH LEARN RES, V18, P1; Rozell CJ, 2008, NEURAL COMPUT, V20, P2526, DOI 10.1162/neco.2008.03-07-486; Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2004, ADV NEUR IN, V16, P1555; Vicente S, 2014, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2014.13; Wu JJ, 2016, LECT NOTES COMPUT SC, V9910, P365, DOI 10.1007/978-3-319-46466-4_22; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9; Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537; Zhu YY, 2014, PROC CVPR IEEE, P1542, DOI 10.1109/CVPR.2014.200	36	0	0	4	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4365	4377		10.1109/TPAMI.2020.2997026	http://dx.doi.org/10.1109/TPAMI.2020.2997026			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	32750772	Green Submitted			2022-12-18	WOS:000714203900016
J	Verbin, D; Gortler, SJ; Zickler, T				Verbin, Dor; Gortler, Steven J.; Zickler, Todd			Unique Geometry and Texture From Corresponding Image Patches	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Geometry; Shape; Transmission line matrix methods; Surface texture; Structure from motion; Surface treatment; Estimation; Shape from texture; structure from motion		We present a sufficient condition for recovering unique texture and viewpoints from unknown orthographic projections of a flat texture process. We show that four observations are sufficient in general, and we characterize the ambiguous cases. The results are applicable to shape from texture and texture-based structure from motion.	[Verbin, Dor; Gortler, Steven J.; Zickler, Todd] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA	Harvard University	Verbin, D (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.	dorverbin@seas.harvard.edu; sjg@seas.harvard.edu; zickler@seas.harvard.edu						Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; Lobay A, 2006, INT J COMPUT VISION, V67, P71, DOI 10.1007/s11263-006-4068-8; Loh A. M. E., 2005, P BMVC, P69; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; Verbin D, 2020, PROC CVPR IEEE, P419, DOI 10.1109/CVPR42600.2020.00050; WHITE R, 2006, COMPUTER VISION PATT, V2, P1809	8	0	0	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4519	4522		10.1109/TPAMI.2021.3081360	http://dx.doi.org/10.1109/TPAMI.2021.3081360			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	34003744	Green Submitted			2022-12-18	WOS:000714203900028
J	Wang, X; Huang, QY; Celikyilmaz, A; Gao, JF; Shen, DH; Wang, YF; Wang, WY; Zhang, L				Wang, Xin; Huang, Qiuyuan; Celikyilmaz, Asli; Gao, Jianfeng; Shen, Dinghan; Wang, Yuan-Fang; Wang, William Yang; Zhang, Lei			Vision-Language Navigation Policy Learning and Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Navigation; Visualization; Trajectory; Task analysis; Cognition; Grounding; Natural languages; Vision-language navigation; reinforcement learning; imitation learning; multimodal machine learning		Vision-language navigation (VLN) is the task of navigating an embodied agent to carry out natural language instructions inside real 3D environments. In this paper, we study how to address three critical challenges for this task: the cross-modal grounding, the ill-posed feedback, and the generalization problems. First, we propose a novel Reinforced Cross-Modal Matching (RCM) approach that enforces cross-modal grounding both locally and globally via reinforcement learning (RL). Particularly, a matching critic is used to provide an intrinsic reward to encourage global matching between instructions and trajectories, and a reasoning navigator is employed to perform cross-modal grounding in the local visual scene. Evaluation on a VLN benchmark dataset shows that our RCM model significantly outperforms baseline methods by 10 percent on Success Rate weighted by Path Length (SPL) and achieves the state-of-the-art performance. To improve the generalizability of the learned policy, we further introduce a Self-Supervised Imitation Learning (SIL) method to explore and adapt to unseen environments by imitating its own past, good decisions. We demonstrate that SIL can approximate a better and more efficient policy, which tremendously minimizes the success rate performance gap between seen and unseen environments (from 30.7 to 11.7 percent).	[Wang, Xin] Univ Calif Santa Cruz, Dept Comp Sci & Engn, Santa Cruz, CA 95064 USA; [Wang, Yuan-Fang; Wang, William Yang] Univ Calif Santa Cruz, Dept Comp Sci, Santa Barbara, CA 93106 USA; [Huang, Qiuyuan] Microsoft Res, Deep Learning Grp, Redmond, WA 98052 USA; [Celikyilmaz, Asli; Zhang, Lei] Microsoft Res, Redmond, WA 98052 USA; [Gao, Jianfeng] Microsoft Res, Deep Learning Technol Ctr, Redmond, WA 98052 USA; [Shen, Dinghan] Duke Univ, Elect & Comp Engn Dept, Durham, NC USA	University of California System; University of California Santa Cruz; University of California System; University of California Santa Cruz; Microsoft; Microsoft; Microsoft; Duke University	Wang, X (corresponding author), Univ Calif Santa Cruz, Dept Comp Sci & Engn, Santa Cruz, CA 95064 USA.	xwang366@ucsc.edu; qihua@microsoft.com; aslicel@microsoft.com; jfgao@microsoft.com; dinghan.shen@duke.edu; yfwang@cs.ucsb.edu; william@cs.ucsb.edu; leizhang@microsoft.com	wangwangwang, yuanyaun/HHN-6432-2022; Wang, Xin/ABD-3905-2020; Wang, Yuan/HHC-1520-2022	Wang, Xin/0000-0003-2605-5504; Zhang, Lei/0000-0001-6926-0538				Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; Anderson Peter, 2018, EVALUATION EMBODIED, V1; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Bellemare M., 2016, NEURIPS; Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081; Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856; Das A, 2018, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2018.00008; Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Fried D, 2018, ADV NEUR IN, V31; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hemachandra S, 2015, IEEE INT CONF ROBOT, P5608, DOI 10.1109/ICRA.2015.7139984; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Houthooft R., 2016, ADV NEURAL INFORM PR, P1109; Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493; Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7; Huang QY, 2018, ADV NEUR IN, V31; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Ke LYM, 2019, PROC CVPR IEEE, P6734, DOI 10.1109/CVPR.2019.00690; King DB, 2015, ACS SYM SER, V1214, P1; Kolve Eric, 2017, ARXIV171205474; Ma C. Y, 2019, ARXIV190103035; Ma CY, 2019, PROC CVPR IEEE, P6725, DOI 10.1109/CVPR.2019.00689; Mirowski P., 2016, ARXIV PREPRINT ARXIV, DOI DOI 10.1016/j.neuroscience.2018.04.006; Mousavian Arsalan, 2019, 2019 International Conference on Robotics and Automation (ICRA), P8846, DOI 10.1109/ICRA.2019.8793493; Nguyen K, 2019, PROC CVPR IEEE, P12519, DOI 10.1109/CVPR.2019.01281; Oh J, 2018, PR MACH LEARN RES, V80; Ostrovski G, 2017, PR MACH LEARN RES, V70; Pathak D, 2017, IEEE COMPUT SOC CONF, P488, DOI 10.1109/CVPRW.2017.70; Paulus Romain, 2018, INT C LEARN REPR; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Ranzato M, 2016, ICLR; Savva Manolis, 2017, ARXIV171203931; Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28; Strehl AL, 2008, J COMPUT SYST SCI, V74, P1309, DOI 10.1016/j.jcss.2007.08.009; Tan Hao, 2019, NAACL; Tang HL, 2017, INT CONF MEAS, P1, DOI [10.1109/ICMTMA.2017.0009, 10.1109/ICMTMA.2017.8]; Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501; Thomason Jesse, 2019, NAACL, P8; Vaswani A, 2017, ADV NEUR IN, V30; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang X., 2018, NAACL HLT; Wang X, 2018, LECT NOTES COMPUT SC, V11220, P38, DOI 10.1007/978-3-030-01270-0_3; Wang X, 2019, PROC CVPR IEEE, P3622, DOI 10.1109/CVPR.2019.00679; Wang X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P899; Wang X, 2018, PROC CVPR IEEE, P4213, DOI 10.1109/CVPR.2018.00443; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496; Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5; Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391; Zhang D, 2019, PROC CVPR IEEE, P1247, DOI 10.1109/CVPR.2019.00134	59	0	0	7	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4205	4216		10.1109/TPAMI.2020.2972281	http://dx.doi.org/10.1109/TPAMI.2020.2972281			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	32054568				2022-12-18	WOS:000714203900006
J	Jeon, Y; Kim, J				Jeon, Yunho; Kim, Junmo			Integrating Multiple Receptive Fields Through Grouped Active Convolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolution; Shape; Task analysis; Computer architecture; Semantics; Network architecture; Backpropagation; Convolutional neural network (CNN); multiple receptive fields; depthwise convolution; deep learning		Convolutional networks have achieved great success in various vision tasks. This is mainly due to a considerable amount of research on network structure. In this study, instead of focusing on architectures, we focused on the convolution unit itself. The existing convolution unit has a fixed shape and is limited to observing restricted receptive fields. In earlier work, we proposed the active convolution unit (ACU), which can freely define its shape and learn by itself. In this paper, we provide a detailed analysis of the previously proposed unit and show that it is an efficient representation of a sparse weight convolution. Furthermore, we extend an ACU to a grouped ACU, which can observe multiple receptive fields in one layer. We found that the performance of a naive grouped convolution is degraded by increasing the number of groups; however, the proposed unit retains the accuracy even though the number of parameters decreases. Based on this result, we suggest a depthwise ACU (DACU), and various experiments have shown that our unit is efficient and can replace the existing convolutions.	[Jeon, Yunho; Kim, Junmo] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 305701, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Kim, J (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 305701, South Korea.	jyh2986@kaist.ac.kr; junmo.kim@kaist.ac.kr	Jeon, Yunho/HDO-2841-2022	Jeon, Yunho/0000-0001-8043-480X	National Research Foundation of Korea (NRF) - Korean Government MSIT [NRF-2017R1A2A2A05001400, NRF-2018R1A5A1059921]; ICT R&D program of MSIP/IITP [2016-0-00563]	National Research Foundation of Korea (NRF) - Korean Government MSIT(National Research Foundation of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); ICT R&D program of MSIP/IITP(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of Korea)	This work was supported in part by the National Research Foundation of Korea (NRF) funded by the Korean Government MSIT (NRF-2017R1A2A2A05001400), in part by the Engineering Research Center Program through the National Research Foundation of Korea (NRF) funded by the Korean Government MSIT (NRF-2018R1A5A1059921), and in part by the ICT R&D program of MSIP/IITP (2016-0-00563, Research on Adaptive Machine Learning Technology Development for IntelligentAutonomous Digital Companion)	Adam, 2017, MOBILENETS EFFICIENT; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], MULTISCALE CONTEXT A; Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314; Chen LC, 2015, CORR; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; De Brabandere B, 2016, ADV NEUR IN, V29; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Graham B, 2014, ARXIV14126071; Han D, 2017, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR.2017.668; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; He Y, 2017, LECT NOTES COMPUT SC, V10496, P41, DOI 10.1007/978-3-319-66709-6_4; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jeon Y, 2018, ADV NEUR IN, V31; Jeon YH, 2017, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2017.200; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lee CY, 2016, JMLR WORKSH CONF PRO, V51, P464; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luo WJ, 2016, ADV NEUR IN, V29; Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8; Maas A. L., 2013, P 30 INT C MACH LEAR, P3; Nair V, 2010, P 27 INT C MACHINE L, P807; Redmon J., 2016, P IEEE C COMPUTER VI, P779, DOI DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Unterthiner T, 2015, COMPUTER SCI, DOI DOI 10.48550/ARXIV.1511.07289; Worrall DE, 2017, PROC CVPR IEEE, P7168, DOI 10.1109/CVPR.2017.758; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093; Yu F, 2017, IEEE INT SYMP ELEC; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zhang R, 2017, IEEE I CONF COMP VIS, P2050, DOI 10.1109/ICCV.2017.224; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhou Bolei, 2015, OBJECT DETECTORS EME, P2; Zhou YZ, 2017, PROC CVPR IEEE, P4961, DOI 10.1109/CVPR.2017.527; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	58	0	0	4	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3892	3903		10.1109/TPAMI.2020.2995864	http://dx.doi.org/10.1109/TPAMI.2020.2995864			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32750767	Green Submitted			2022-12-18	WOS:000702649700015
J	Pritts, J; Kukelova, Z; Larsson, V; Lochman, Y; Chum, O				Pritts, James; Kukelova, Zuzana; Larsson, Viktor; Lochman, Yaroslava; Chum, Ondrej			Minimal Solvers for Rectifying From Radially-Distorted Conjugate Translations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Lenses; Cameras; Distortion; Transmission line matrix methods; Geometry; Feature extraction; Parallel processing; Rectification; radial distortion; minimal solvers; symmetry; repeated patterns; local features	AFFINE RECTIFICATION; TEXTURE; SCALE	This paper introduces minimal solvers that jointly solve for radial lens undistortion and affine-rectification using local features extracted from the image of coplanar translated and reflected scene texture, which is common in man-made environments. The proposed solvers accommodate different types of local features and sampling strategies, and three of the proposed variants require just one feature correspondence. State-of-the-art techniques from algebraic geometry are used to simplify the formulation of the solvers. The generated solvers are stable, small and fast. Synthetic and real-image experiments show that the proposed solvers have superior robustness to noise compared to the state of the art. The solvers are integrated with an automated system for rectifying imaged scene planes from coplanar repeated texture. Accurate rectifications on challenging imagery taken with narrow to wide field-of-view lenses demonstrate the applicability of the proposed solvers.	[Pritts, James] Czech Tech Univ, Czech Inst Informat Robot & Cybernet CIIRC, Prague 6, Czech Republic; [Kukelova, Zuzana; Chum, Ondrej] Czech Tech Univ, Fac Elect Engn, Visual Recognit Grp VRG, Prague 6, Czech Republic; [Larsson, Viktor] Swiss Fed Inst Technol, Comp Vis & Geometry Grp CVG, Dept Comp Sci, CH-8092 Zurich, Switzerland; [Lochman, Yaroslava] Ukrainian Catholic Univ, Machine Learning Lab, UA-79000 Lvov, Ukraine	Czech Technical University Prague; Czech Technical University Prague; Swiss Federal Institutes of Technology Domain; ETH Zurich; Ukrainian Catholic University	Pritts, J (corresponding author), Czech Tech Univ, Czech Inst Informat Robot & Cybernet CIIRC, Prague 6, Czech Republic.	prittjam@cvut.cz; kukelova@cmp.felk.cvut.cz; viktor.larsson@inf.ethz.ch; lochman@ucu.edu.ua; chum@cmp.felk.cvut.cz	Kukelova, Zuzana/AAM-9096-2020; Kukelova, Zuzana/GXG-1671-2022	Kukelova, Zuzana/0000-0002-1916-8829; Lochman, Yaroslava/0000-0001-8695-4718; Pritts, James/0000-0001-6533-8975	European Regional Development Fund under the project Robotics for Industry 4.0 [CZ.02.1.01/0.0/0.0/15_003/0000470]; ESI Fund, OP RDE programme under the project International Mobility of Researchers MSCA-IF at CTU [CZ.02.2.69/0.0/0.0/17_050/0008025]; grant OP VVV [CZ.02.1.01/0.0/0.0/16_019/0000765]; ERC-CZ grant [MSMT LL1901]; ETH Zurich Postdoctoral Fellowship program; Marie Sklodowska-Curie Actions COFUND program; ELEKS Ltd.	European Regional Development Fund under the project Robotics for Industry 4.0; ESI Fund, OP RDE programme under the project International Mobility of Researchers MSCA-IF at CTU; grant OP VVV; ERC-CZ grant; ETH Zurich Postdoctoral Fellowship program; Marie Sklodowska-Curie Actions COFUND program; ELEKS Ltd.	The work of James Pritts and Yaroslava Lochman was supported by the European Regional Development Fund under the project Robotics for Industry 4.0 (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000470). Thework of Zuzana Kukelovawas supported by the ESI Fund, OP RDE programme under the project International Mobility of Researchers MSCA-IF at CTU No. CZ.02.2.69/0.0/0.0/17_050/0008025. The work of Ondrej Chum was supported by the grant OP VVV funded project CZ.02.1.01/0.0/0.0/16_019/0000765 "Research Center for Informatics" and the ERC-CZ grant MSMT LL1901. The work of Viktor Larsson was supported by the ETH Zurich Postdoctoral Fellowship program and the Marie Sklodowska-Curie Actions COFUND program. The work of Yaroslava Lochman was supported by ELEKS Ltd.	Ahmad S, 2018, INT J COMPUT VISION, V126, P822, DOI 10.1007/s11263-018-1078-2; Aiger D, 2012, COMPUT GRAPH FORUM, V31, P439, DOI 10.1111/j.1467-8659.2012.03023.x; Antunes M, 2017, PROC CVPR IEEE, P6691, DOI 10.1109/CVPR.2017.708; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Barath D, 2017, PROC CVPR IEEE, P2557, DOI 10.1109/CVPR.2017.274; Boyd S, 2004, CONVEX OPTIMIZATION; Bukhari F, 2013, J MATH IMAGING VIS, V45, P31, DOI 10.1007/s10851-012-0342-2; Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3113, DOI 10.1109/CVPR.2011.5995551; Chum O., 2004, P ACCV, V2, P812; Chum O, 2011, LECT NOTES COMPUT SC, V6495, P347, DOI 10.1007/978-3-642-19282-1_28; Cox D., 2004, USING ALGEBRAIC GEOM; Criminisi A., 2000, P BRIT MACH VIS C; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fitzgibbon AW, 2001, PROC CVPR IEEE, P125; Funk C, 2017, IEEE INT CONF COMP V, P1692, DOI 10.1109/ICCVW.2017.198; Grayson Daniel R, 2002, MACAULAY 2 SOFTWARE, P4; Hartley R., 2004, ROBOTICA; Hartley RI, 1998, INT J COMPUT VISION, V26, P41, DOI 10.1023/A:1007984508483; Hays J, 2006, LECT NOTES COMPUT SC, V3952, P522; Kukelova Z, 2008, LECT NOTES COMPUT SC, V5304, P302, DOI 10.1007/978-3-540-88690-7_23; Kukelova Z, 2015, PROC CVPR IEEE, P639, DOI 10.1109/CVPR.2015.7298663; Larsson V, 2018, PROC CVPR IEEE, P3945, DOI 10.1109/CVPR.2018.00415; Larsson V, 2017, IEEE I CONF COMP VIS, P2307, DOI 10.1109/ICCV.2017.251; Larsson V, 2017, PROC CVPR IEEE, P2383, DOI 10.1109/CVPR.2017.256; Li H., 2005, 6 WORKSH OMN VIS CAM, V2, P7; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luk M., 2017, ACM T GRAPHIC, V36; Matas J, 2002, INT C PATT RECOG, P363, DOI 10.1109/ICPR.2002.1047471; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mishkin D, 2018, LECT NOTES COMPUT SC, V11213, P287, DOI 10.1007/978-3-030-01240-3_18; Obdrialek S., 2002, P BRIT MACH VIS C, P113; Ohta T.I., 1981, P INT JOINT C ART IN, P746; Perd'och M, 2006, INT C PATT RECOG, P215; Pritts J, 2020, INT J COMPUT VISION, V128, P950, DOI 10.1007/s11263-019-01216-x; Pritts J, 2018, PROC CVPR IEEE, P1993, DOI 10.1109/CVPR.2018.00213; Pritts J, 2014, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2014.380; Pritts James, 2018, AS C COMP VIS ACCV, P2; Pritts James, 2016, P BRIT MACH VIS C; Raposo C, 2016, PROC CVPR IEEE, P5470, DOI 10.1109/CVPR.2016.590; Schaffalitzky F., 1998, P BRIT MACH VIS C; Strand, 2005, PROC BRIT MACH VIS C; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Wang AQ, 2009, J MATH IMAGING VIS, V35, P165, DOI 10.1007/s10851-009-0162-1; Wildenauer H, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.106; Wildenauer H, 2012, PROC CVPR IEEE, P2831, DOI 10.1109/CVPR.2012.6248008; WILLSON RG, 1994, J OPT SOC AM A, V11, P2946, DOI 10.1364/JOSAA.11.002946; Zeng G., 2008, IEEE C COMP VIS PATT, P1; Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x	50	0	0	2	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3931	3948		10.1109/TPAMI.2020.2992261	http://dx.doi.org/10.1109/TPAMI.2020.2992261			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32386139	Green Submitted			2022-12-18	WOS:000702649700018
J	Song, SJ; Zhang, W; Liu, JY; Guo, ZM; Mei, T				Song, Sijie; Zhang, Wei; Liu, Jiaying; Guo, Zongming; Mei, Tao			Unpaired Person Image Generation With Semantic Parsing Transformation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Image synthesis; Training; Clothing; Generators; Shape; Task analysis; Image generation; semantic parsing transformation; appearance generation; fashion application		In this paper, we tackle the problem of pose-guided person image generation with unpaired data, which is a challenging problem due to non-rigid spatial deformation. Instead of learning a fixed mapping directly between human bodies as previous methods, we propose a new pathway to decompose a single fixed mapping into two subtasks, namely, semantic parsing transformation and appearance generation. First, to simplify the learning for non-rigid deformation, a semantic generative network is developed to transform semantic parsing maps between different poses. Second, guided by semantic parsing maps, we render the foreground and background image, respectively. A foreground generative network learns to synthesize semantic-aware textures, and another background generative network learns to predict missing background regions caused by pose changes. Third, we enable pseudo-label training with unpaired data, and demonstrate that end-to-end training of the overall network further refines the semantic map prediction and final results accordingly. Moreover, our method is generalizable to other person image generation tasks defined on semantic maps, e.g., clothing texture transfer, controlled image manipulation, and virtual try-on. Experimental results on DeepFashion and Market-1501 datasets demonstrate the superiority of our method, especially in keeping better body shapes and clothing attributes, as well as rendering structure-coherent backgrounds.	[Song, Sijie; Liu, Jiaying; Guo, Zongming] Peking Univ, Wangxuan Inst Comp Technol, Beijing, Peoples R China; [Zhang, Wei; Mei, Tao] JD AI Res, Beijing, Peoples R China	Peking University	Song, SJ (corresponding author), Peking Univ, Wangxuan Inst Comp Technol, Beijing, Peoples R China.	ssj940920@pku.edu.cn; wzhang.cu@gmail.com; liujiaying@pku.edu.cn; guozongming@pku.edu.cn; tmei@live.com	Mei, Tao/GQZ-0596-2022	Mei, Tao/0000-0002-5990-7307; Song, Sijie/0000-0002-2085-6370	National Natural Science Foundation of China [61772043]; Beijing Natural Science Foundation [4192025]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation)	This work was supported by the National Natural Science Foundation of China under contract No. 61772043 and Beijing Natural Science Foundation under contract No. 4192025.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2018, NEURIPS; Balakrishnan G, 2018, PROC CVPR IEEE, P8340, DOI 10.1109/CVPR.2018.00870; Brock A., 2019, INT C LEARNING REPRE; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Champandard Alex J., 2016, SEMANTIC STYLE TRANS, P2; Chen X., 2017, P ICLR; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Dosovitskiy Alexey, 2016, NEURIPS; Esser P, 2018, PROC CVPR IEEE, P8857, DOI 10.1109/CVPR.2018.00923; Fedus William, 2018, INT C LEARN REPR; Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Grigorev A, 2019, PROC CVPR IEEE, P12127, DOI 10.1109/CVPR.2019.01241; Gulrajani I., 2017, INT C LEARN REPR; Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787; Heusel M., 2017, 31 C NEUR INF PROC S, P6626; Hong S, 2018, PROC CVPR IEEE, P7986, DOI 10.1109/CVPR.2018.00833; Hong Seunghoon, 2018, ADV NEURAL INFORM PR, P2713; Huang HB, 2018, ADV NEUR IN, V31; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jaderberg M, 2015, ADV NEUR IN, V28; Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133; Karras Timo Aila Samuli Laine Tero, 2018, PROC INT C LEARN REP, Patent No. [1710.10196, 171010196]; Kim T, 2017, PR MACH LEARN RES, V70; Kingma D.P., 2015, INT C LEARN REPR, P1; Kingma D. P, 2014, ARXIV13126114; Lassner C, 2017, IEEE I CONF COMP VIS, P853, DOI 10.1109/ICCV.2017.98; Lee D, 2018, ADV NEUR IN, V31; Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Lorenz D, 2019, PROC CVPR IEEE, P10947, DOI 10.1109/CVPR.2019.01121; Ma LQ, 2017, ADV NEUR IN, V30; Ma LQ, 2018, PROC CVPR IEEE, P99, DOI 10.1109/CVPR.2018.00018; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Pumarola A, 2018, PROC CVPR IEEE, P8620, DOI 10.1109/CVPR.2018.00899; Raj Amit, 2018, P EUR C COMP VIS ECC, P666; Reed S. E., 2016, ADV NEURAL INFORM PR, P217; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Salimans T., 2016, ADV NEUR IN, P2234; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Si CY, 2018, PROC CVPR IEEE, P118, DOI 10.1109/CVPR.2018.00020; Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359; Sonderby C.K., 2017, ICLR, P1; Song SJ, 2019, PROC CVPR IEEE, P2352, DOI 10.1109/CVPR.2019.00246; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882; Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186	61	0	0	3	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					4161	4176		10.1109/TPAMI.2020.2992105	http://dx.doi.org/10.1109/TPAMI.2020.2992105			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32365019				2022-12-18	WOS:000702649700032
J	Taborsky, P; Vermue, L; Korzepa, M; Morup, M				Taborsky, Petr; Vermue, Laurent; Korzepa, Maciej; Morup, Morten			The Bayesian Cut	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes methods; Computational modeling; Social network services; Image segmentation; Stochastic processes; Computer vision; Analytical models; Normalized cut; ratio cut; graph cut; modularity; degree-corrected stochastic block modeling; Bayesian inference; incomplete gamma function; image segmentation	COMMUNITY STRUCTURE; GRAPH CUTS; PREDICTION	An important task in the analysis of graphs is separating nodes into densely connected groups with little interaction between each other. Prominent methods here include flow based graph cutting procedures as well as statistical network modeling approaches. However, adequately accounting for this, the so-called community structure, in complex networks remains a major challenge. We present a novel generic Bayesian probabilistic model for graph cutting in which we derive an analytical solution to the marginalization of nuisance parameters under constraints enforcing community structure. As a part of the solution a large scale approximation for integrals involving multiple incomplete gamma functions is derived. Our multiple cluster solution presents a generic tool for Bayesian inference on Poisson weighted graphs across different domains. Applied on three real world social networks as well as three image segmentation problems our approach shows on par or better performance to existing spectral graph cutting and community detection methods, while learning the underlying parameter space. The developed procedure provides a principled statistical framework for graph cutting and the Bayesian Cut source code provided enables easy adoption of the procedure as an alternative to existing graph cutting methods.	[Taborsky, Petr; Vermue, Laurent; Korzepa, Maciej; Morup, Morten] Tech Univ Denmark, Dept Appl Math & Comp Sci, DK-2800 Lyngby, Denmark	Technical University of Denmark	Taborsky, P (corresponding author), Tech Univ Denmark, Dept Appl Math & Comp Sci, DK-2800 Lyngby, Denmark.	ptab@dtu.dk; lauve@dtu.dk; mjko@dtu.dk; mmor@dtu.dk		Morup, Morten/0000-0003-4985-4368; Taborsky, Petr/0000-0002-1993-2700	Innovation Fund Denmark; Danish Center for Big Data Analytics driven Innovation (DABAI); Telenor Danmark	Innovation Fund Denmark; Danish Center for Big Data Analytics driven Innovation (DABAI); Telenor Danmark	This work was supported in part by the Innovation Fund Denmark with the Danish Center for Big Data Analytics driven Innovation (DABAI). P.T. gratefully acknowledges Telenor Danmark for support.	Adamic LA, 2005, INT WORKSHOP LINK DI, P36, DOI DOI 10.1145/1134271.1134277; Ahuja Ravindra, 2014, NETWORK FLOWS THEORY; AlAhmad R., 2016, ANALYSIS-UK, V36, P199; Nguyen BV, 2018, IEEE ACCESS, V6, P4135, DOI 10.1109/ACCESS.2018.2791581; Blum A., 2001, P INT C MACH LEARN I, P19, DOI DOI 10.1184/R1/6606860.V1; Condon A, 2001, RANDOM STRUCT ALGOR, V18, P116, DOI 10.1002/1098-2418(200103)18:2<116::AID-RSA1001>3.0.CO;2-2; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Foster DJ, 2018, PR MACH LEARN RES, V84; Gelman A., 2013, CHAPMAN HALL CRC TEX, V3, DOI [10.1201/b16018, DOI 10.1201/B16018]; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; Hartmann M, 2017, ARXIV170404736; Herlau T, 2014, PHYS REV E, V90, DOI 10.1103/PhysRevE.90.032819; HOLLAND PW, 1983, SOC NETWORKS, V5, P109, DOI 10.1016/0378-8733(83)90021-7; Jameson GJO, 2016, MATH GAZ, V100, P298, DOI 10.1017/mag.2016.67; Karrer B, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.016107; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Meila M, 2003, LECT NOTES ARTIF INT, V2777, P173, DOI 10.1007/978-3-540-45167-9_14; Morris M, 2011, HIV TRANSMISSION NET; Morup M, 2012, NEURAL COMPUT, V24, P2434, DOI 10.1162/NECO_a_00314; Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103; Newman MEJ, 2016, PHYS REV E, V94, DOI 10.1103/PhysRevE.94.052315; Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694; Nowicki K, 2001, J AM STAT ASSOC, V96, P1077, DOI 10.1198/016214501753208735; Park SW, 2006, IEEE T VIS COMPUT GR, V12, P243, DOI 10.1109/TVCG.2006.27; Parker RG., 2014, DISCRETE OPTIM; Peel L, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1602548; Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015; Reichardt J, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.016110; Rosvall M, 2007, P NATL ACAD SCI USA, V104, P7327, DOI 10.1073/pnas.0611034104; Schmidt MN, 2013, IEEE SIGNAL PROC MAG, V30, P110, DOI 10.1109/MSP.2012.2235191; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SIBUYA M, 1964, ANN I STAT MATH, V16, P409, DOI 10.1007/BF02868583; Sireci SG, 2003, J EDUC MEAS, V40, P277, DOI 10.1111/j.1745-3984.2003.tb01108.x; Snavely N, 2010, P IEEE, V98, P1370, DOI 10.1109/JPROC.2010.2049330; Tremeau A, 2000, IEEE T IMAGE PROCESS, V9, P735, DOI 10.1109/83.841950; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang J, 2013, J MACH LEARN RES, V14, P771; Witman M, 2018, ACS CENTRAL SCI, V4, P235, DOI 10.1021/acscentsci.7b00555; ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452, DOI 10.1086/jar.33.4.3629752; Zhang Y, 2012, ADV NEURAL INFORM PR, V25, P3194	44	0	0	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					4111	4124		10.1109/TPAMI.2020.2994396	http://dx.doi.org/10.1109/TPAMI.2020.2994396			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32406825	Green Published			2022-12-18	WOS:000702649700029
J	Yang, X; Meer, P; Meer, J				Yang, Xiang; Meer, Peter; Meer, Jonathan			A New Approach to Robust Estimation of Parametric Structures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Estimation; Robustness; Two dimensional displays; Linear programming; Three-dimensional displays; Complexity theory; Covariance matrices; Scale estimation; density based classification; structures segmentation	RANDOM SAMPLE CONSENSUS; RANSAC	Most robust estimators require tuning the parameters of the algorithm for the particular application, a bottleneck for practical applications. The paper presents the multiple input structures with robust estimator (MISRE), where each structure, inlier or outlier, is processed independently. The same two constants are used to find the scale estimates over expansions for each structure. The inlier/outlier classification is straightforward since the data is processed and ordered with the relevant inlier structures listed first. If the inlier noises are similar, MISRE's performance is equivalent to RANSAC-type algorithms. MISRE still returns the correct inlier estimates when inlier noises are very different, while RANSAC-type algorithms do not perform as well. MISRE's failures are gradual when too many outliers are present, beginning with the least significant inlier structure. Examples from 2D images and 3D point clouds illustrate the estimation.	[Yang, Xiang] Adv Corp Mat Equipments ACME, Dept Mech & Aerosp Engn, Changsha 410118, Hunan, Peoples R China; [Meer, Peter] Rutgers State Univ, Dept Elect & Comp Engn, New Brunswick, NJ 08854 USA; [Meer, Jonathan] Texas A&M, Dept Econ, College Stn, TX 77843 USA	Rutgers State University New Brunswick; Texas A&M University System; Texas A&M University College Station	Yang, X (corresponding author), Adv Corp Mat Equipments ACME, Dept Mech & Aerosp Engn, Changsha 410118, Hunan, Peoples R China.	xiang.yang@yahoo.com; meer@soe.rutgers.edu; jmeer@tamu.edu						[Anonymous], 2011, P 24 INT C NEUR INF; Barath D, 2018, PROC CVPR IEEE, P6733, DOI 10.1109/CVPR.2018.00704; Basah SN, 2009, IET COMPUT VIS, V3, P189, DOI 10.1049/iet-cvi.2009.0030; Beder C., 2010, P 9 EUR C COMP VIS, P135; Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302; Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267; Chin TJ, 2018, LECT NOTES COMPUT SC, V11216, P715, DOI 10.1007/978-3-030-01258-8_43; Choi J, 2009, PROC CVPR IEEE, P675, DOI 10.1109/CVPRW.2009.5206678; Choi S., 1997, P BRIT MACH VIS C, V24, P271; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Efron B., 1994, MONOGR STAT APPL PRO, DOI DOI 10.1007/978-1-4899-4541-9; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Farenzena Michela, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1489, DOI 10.1109/ICCVW.2009.5457435; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Hartley R., 2004, ROBOTICA; Hassner T, 2014, MACH VISION APPL, V25, P971, DOI 10.1007/s00138-013-0571-4; Hughes GB, 2012, COMPUT VIS SCI, V15, P291, DOI 10.1007/s00791-013-0214-3; Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7; Kanatani K, 2006, IEICE T INF SYST, VE89D, P2653, DOI 10.1093/ietisy/e89-4.10.2653; Korman S, 2018, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2018.00700; Lazic N, 2009, IEEE I CONF COMP VIS, P825, DOI 10.1109/ICCV.2009.5459302; Le H, 2017, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.2017.48; Litman R, 2015, PROC CVPR IEEE, P5243, DOI 10.1109/CVPR.2015.7299161; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Magri L, 2014, PROC CVPR IEEE, P3954, DOI 10.1109/CVPR.2014.505; Mittal S, 2012, IEEE T PATTERN ANAL, V34, P2351, DOI 10.1109/TPAMI.2012.52; Moisan L, 2012, IMAGE PROCESS ON LIN, V2, P56, DOI 10.5201/ipol.2012.mmm-oh; Morley D, 2017, PROC CVPR IEEE, P2661, DOI 10.1109/CVPR.2017.285; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Pham TT, 2014, IEEE T PATTERN ANAL, V36, P1658, DOI 10.1109/TPAMI.2013.2296310; Pollefeys P, 2017, P IEEE C COMP VIS PA, P4941; Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37; Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257; ReMake, 2015, AUTODESK; Schaffalitzky F, 1999, LECT NOTES COMPUT SC, V1681, P165; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Serradell E, 2010, LECT NOTES COMPUT SC, V6313, P58; Szpak ZL, 2015, J MATH IMAGING VIS, V52, P173, DOI 10.1007/s10851-014-0536-x; Tennakoon R, 2018, IEEE T IMAGE PROCESS, V27, P4182, DOI 10.1109/TIP.2018.2834821; Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Vedaldi A, 2005, IEEE I CONF COMP VIS, P633; Wang HZ, 2012, IEEE T PATTERN ANAL, V34, P1177, DOI 10.1109/TPAMI.2011.216; Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25; Yang X., 2017, ROBUST METHOD PHOTOG; Yu J, 2011, PROC CVPR IEEE; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	51	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3754	3769		10.1109/TPAMI.2020.2994190	http://dx.doi.org/10.1109/TPAMI.2020.2994190			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32406824				2022-12-18	WOS:000702649700006
J	Yang, ZY; Xu, QQ; Cao, XC; Huang, QM				Yang, Zhiyong; Xu, Qianqian; Cao, Xiaochun; Huang, Qingming			Task-Feature Collaborative Learning with Application to Personalized Attribute Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Convergence; Predictive models; Diseases; Collaborative work; Optimization; Training; Block diagonal structural learning; negative transfer; multi-task learning; global convergence	SHRINKAGE	As an effective learning paradigm against insufficient training samples, multi-task learning (MTL) encourages knowledge sharing across multiple related tasks so as to improve the overall performance. In MTL, a major challenge springs from the phenomenon that sharing the knowledge with dissimilar and hard tasks, known as negative transfer, often results in a worsened performance. Though a substantial amount of studies have been carried out against the negative transfer, most of the existing methods only model the transfer relationship as task correlations, with the transfer across features and tasks left unconsidered. Different from the existing methods, our goal is to alleviate negative transfer collaboratively across features and tasks. To this end, we propose a novel multi-task learning method called task-feature collaborative learning (TFCL). Specifically, we first propose a base model with a heterogeneous block-diagonal structure regularizer to leverage the collaborative grouping of features and tasks and suppressing inter-group knowledge sharing. We then propose an optimization method for the model. Extensive theoretical analysis shows that our proposed method has the following benefits: (a) it enjoys the global convergence property and (b) it provides a block-diagonal structure recovery guarantee. As a practical extension, we extend the base model by allowing overlapping features and differentiating the hard tasks. We further apply it to the personalized attribute prediction problem with fine-grained modeling of user behaviors. Finally, experimental results on both simulated dataset and real-world datasets demonstrate the effectiveness of our proposed method.	[Yang, Zhiyong; Cao, Xiaochun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China; [Yang, Zhiyong; Cao, Xiaochun] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100049, Peoples R China; [Xu, Qianqian; Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Cao, Xiaochun] Cyberspace Secur Res Ctr, Peng Cheng Lab, Shenzhen 518055, Peoples R China; [Huang, Qingming] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 101408, Peoples R China; [Huang, Qingming] Univ Chinese Acad Sci, Key Lab Big Data Min & Knowledge Management BDKM, Beijing 101408, Peoples R China; [Huang, Qingming] Peng Cheng Lab, Shenzhen 518055, Peoples R China	Chinese Academy of Sciences; Institute of Information Engineering, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Peng Cheng Laboratory; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Peng Cheng Laboratory	Yang, ZY (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.	yangzhiyong@iie.ac.cn; xuqianqian@ict.ac.cn; caoxiaochun@iie.ac.cn; qmhuang@ucas.ac.cn		Yang, Zhiyong/0000-0002-4409-4999	National Key R&D Program of China [2018AAA0102003]; National Natural Science Foundation of China [61620106009, U1636214, U1736219, 61971016, 61931008, 61836002, 61672514, 61976202]; Key Research Program of Frontier Sciences, CAS [QYZDJ-SSW-SYS013]; Strategic Priority Research Program of Chinese Academy of Sciences [XDB28000000]; Beijing Natural Science Foundation [4182079]; Youth Innovation Promotion Association CAS	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Research Program of Frontier Sciences, CAS; Strategic Priority Research Program of Chinese Academy of Sciences(Chinese Academy of Sciences); Beijing Natural Science Foundation(Beijing Natural Science Foundation); Youth Innovation Promotion Association CAS	This work was supported in part by the National Key R&D Program of China under Grant 2018AAA0102003, in part by National Natural Science Foundation of China: 61620106009, U1636214, U1736219, 61971016, 61931008, 61836002, 61672514, and 61976202, in part by Key Research Program of Frontier Sciences, CAS: QYZDJ-SSW-SYS013, in part by the Strategic Priority Research Program of Chinese Academy of Sciences, Grant No. XDB28000000, in part by Beijing Natural Science Foundation (4182079), and in part by Youth Innovation PromotionAssociation CAS.	Agarwal S, 2014, J MACH LEARN RES, V15, P1653; Andreani R, 2020, MATH PROGRAM, V180, P203, DOI 10.1007/s10107-018-1354-5; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Bach FR, 2004, ADV NEUR IN, V16, P305; Bakker B, 2004, J MACH LEARN RES, V4, P83, DOI 10.1162/153244304322765658; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Cao JJ, 2018, PROC CVPR IEEE, P4290, DOI 10.1109/CVPR.2018.00451; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547; FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652; Fan RK, 1997, SPECTRAL GRAPH THEOR, V92; Favaro P, 2011, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2011.5995365; Gao W, 2016, ARTIF INTELL, V236, P1, DOI 10.1016/j.artint.2016.03.003; Gong Pinghua, 2012, KDD, V2012, P895; Grave E., 2011, P 24 INT C NEUR INF, P2187; Han L, 2016, AAAI CONF ARTIF INTE, P1638; Han L, 2015, AAAI CONF ARTIF INTE, P2638; Heskes T., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P233; Jeong JY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1589, DOI 10.1145/3219819.3219992; Kang Z., 2011, P INT C MACH LEARN, V2, P4; Kovashka A, 2015, INT J COMPUT VISION, V114, P56, DOI 10.1007/s11263-014-0798-1; Kovashka A, 2013, IEEE I CONF COMP VIS, P3432, DOI 10.1109/ICCV.2013.426; Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026; Kshirsagar M, 2017, LECT NOTES ARTIF INT, V10535, P673, DOI 10.1007/978-3-319-71246-8_41; Kumar A., 2012, INT C MACH LEARN; Li CG, 2015, PROC CVPR IEEE, P277, DOI 10.1109/CVPR.2015.7298624; Li YG, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1695, DOI 10.1145/3219819.3220033; Lin Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P799; Liu GC, 2019, IEEE T IMAGE PROCESS, V28, P5161, DOI 10.1109/TIP.2019.2917857; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu PF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1, DOI 10.18653/v1/P17-1001; Liu SL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2358; Lu CY, 2018, AAAI CONF ARTIF INTE, P3714; Lu CY, 2019, IEEE T PATTERN ANAL, V41, P487, DOI 10.1109/TPAMI.2018.2794348; McDonald AM, 2016, J MACH LEARN RES, V17; Mianjy P., 2018, P INT C MACH LEARN, P3531; Ng AY, 2002, ADV NEUR IN, V14, P849; Ni K., 2007, PROC 24 INT C MACH L, P689; Nie FP, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2012, DOI 10.1145/3219819.3219951; Nie FP, 2016, AAAI CONF ARTIF INTE, P1969; Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726; Oliveira SHG, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3202; Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998; Qi Y., 2008, P 25 INT C MACH LEAR, P768; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Thrun S., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P489; Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x; Villani C, 2009, GRUNDLEHR MATH WISS, V338, P5; Wang S., 2011, P 25 AAAI C ARTIFICI, P519; Wang Y, 2015, PR MACH LEARN RES, V37, P1209; Wipf D. P., 2016, P C UNC ART INT; Xie XY, 2018, IEEE T IMAGE PROCESS, V27, P477, DOI 10.1109/TIP.2017.2764262; Xin B., 2017, PROC C UNCERTAINTY A; Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077; Xu LL, 2015, AAAI CONF ARTIF INTE, P1931; Xue Y, 2007, J MACH LEARN RES, V8, P35; Yang ZY, 2018, AAAI CONF ARTIF INTE, P515; Yang ZY, 2019, IEEE T IMAGE PROCESS, V28, P5147, DOI 10.1109/TIP.2019.2913096; Yao YQ, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1408, DOI 10.1145/3292500.3330904; You C, 2016, PROC CVPR IEEE, P3918, DOI 10.1109/CVPR.2016.425; Zhong W, 2012, P 29 INT C MACH LEAR; Zhou Q, 2016, IEEE T PATTERN ANAL, V38, P266, DOI 10.1109/TPAMI.2015.2452911	64	0	0	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					4094	4110		10.1109/TPAMI.2020.2991344	http://dx.doi.org/10.1109/TPAMI.2020.2991344			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32356738	Green Submitted			2022-12-18	WOS:000702649700028
J	Fabbri, R; Giblin, P; Kimia, B				Fabbri, Ricardo; Giblin, Peter; Kimia, Benjamin			Camera Pose Estimation Using First-Order Curve Differential Geometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Geometry; Image reconstruction; Robustness; Three-dimensional displays; Image edge detection; Pose estimation; Pose estimation; camera resectioning; differential geometry	FEATURES	This paper considers and solves the problem of estimating camera pose given a pair of point-tangent correspondences between a 3D scene and a projected image. The problem arises when considering curve geometry as the basis of forming correspondences, computation of structure and calibration, which in its simplest form is a point augmented with the curve tangent. We show that while the resectioning problem is solved with a minimum of three points given the intrinsic parameters, when points are augmented with tangent information only two points are required, leading to substantial robustness and computational savings, e.g., as a minimal engine within ransac. In addition, algorithms are developed to find a practical solution shown to effectively recover camera pose using synthetic and real datasets. This technology is intended as a building block of curve-based structure from motion systems, allowing new views to be incrementally registered to a core set of views for which relative pose has been computed.	[Fabbri, Ricardo] Univ Estado Rio De Janeiro, Polytech Inst, Dept Computat Modeling, Nova Friburgo, RJ, Brazil; [Giblin, Peter] Univ Liverpool, Liverpool, Merseyside, England; [Kimia, Benjamin] Brown Univ, Sch Engn, Providence, RI 02912 USA	Universidade do Estado do Rio de Janeiro; University of Liverpool; Brown University	Fabbri, R (corresponding author), Univ Estado Rio De Janeiro, Polytech Inst, Dept Computat Modeling, Nova Friburgo, RJ, Brazil.	rfabbri@gmail.com; pjgiblin@liverpool.ac.uk; kimia@lems.brown.edu		Fabbri, Ricardo/0000-0001-7949-6309	NSF [1116140]; CNPq/Brazil [200875/2004-3]; FAPERJ/Brazil [E26/112.082/2011, E26/190.180/2010]; 2011 UERJ Visiting Professor Grant; ICERM NSF Grant of the 2018 Nonlinear Algebra program [DMS-1439786]; 2019 Algebraic Vision Research Cluster	NSF(National Science Foundation (NSF)); CNPq/Brazil(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); FAPERJ/Brazil(Fundacao Carlos Chagas Filho de Amparo a Pesquisa do Estado do Rio De Janeiro (FAPERJ)); 2011 UERJ Visiting Professor Grant; ICERM NSF Grant of the 2018 Nonlinear Algebra program; 2019 Algebraic Vision Research Cluster	This work was supported by the NSF Grant 1116140, CNPq/Brazil proc. 200875/2004-3, FAPERJ/Brazil E26/112.082/2011, E26/190.180/2010, the 2011 UERJ Visiting Professor Grant, and ICERM NSF Grant DMS-1439786 of the 2018 Nonlinear Algebra program and the 2019 Algebraic Vision Research Cluster.	A. A. Team, 2018, UND ARK TRACK DET; Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Ayache N., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P422; Barath D, 2018, PROC CVPR IEEE, P235, DOI 10.1109/CVPR.2018.00032; Bianco S, 2018, J IMAGING, V4, DOI 10.3390/jimaging4080098; Bujnak M., 2008, 2008 IEEE C COMPUTER, P1; Cipolla R., 1999, VISUAL MOTION CURVES; Diskin Y, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.2.023003; Fabbri R, 2005, LECT NOTES COMPUT SC, V3757, P645, DOI 10.1007/11585978_42; Fabbri R., 2019, ABS190309755 CORR; Fabbri R., 2010, THESIS BROWN U PROVI, P02912; Fabbri R, 2016, INT J COMPUT VISION, V120, P324, DOI 10.1007/s11263-016-0912-7; Fabbri R, 2010, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2010.5539787; Finsterwalder S., 1937, SEBASTIAN FINSTERWAL, V75, P86; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Grunert J.A., ARCH MATH PHYS, V1, P238; Guo YL, 2014, LECT NOTES COMPUT SC, V8689, P663, DOI 10.1007/978-3-319-10590-1_43; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Heinly J, 2015, PROC CVPR IEEE, P3287, DOI 10.1109/CVPR.2015.7298949; HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2; Hu ZY, 2002, IEEE T PATTERN ANAL, V24, P550, DOI 10.1109/34.993561; Kahl F, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P761, DOI 10.1109/ICCV.1998.710803; Kaminski JY, 2004, INT J COMPUT VISION, V56, P195, DOI 10.1023/B:VISI.0000011204.89453.4d; Kimia BB, 2019, IEEE T PATTERN ANAL, V41, P1573, DOI 10.1109/TPAMI.2018.2846268; Kuang YB, 2013, IEEE I CONF COMP VIS, P529, DOI 10.1109/ICCV.2013.71; Liu LJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073682; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1; Nurutdinova I, 2015, IEEE I CONF COMP VIS, P2363, DOI 10.1109/ICCV.2015.272; Persson M., 2018, EUR C COMP VIS MUN G, P1; Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a; PORRILL J, 1991, IMAGE VISION COMPUT, V9, P45, DOI 10.1016/0262-8856(91)90048-T; Robert L., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P57, DOI 10.1109/CVPR.1991.139661; Seitz S., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI [10.1109/CVPR.2006.19, DOI 10.1109/CVPR.2006.19]; Shinozuka Y., 2014, P VIRT REAL INT C, DOI [10.1145/2617841.2620723, DOI 10.1145/2617841.2620723]; Simoes F., 2012, 2012 14th Symposium on Virtual and Augmented Reality (SVR), P74, DOI 10.1109/SVR.2012.5; Sinha SN, 2004, PROC CVPR IEEE, P195; Tamrakar A, 2007, IEEE I CONF COMP VIS, P714; Tange O., 2018, GNU PARALLEL 2018, DOI [10.5281/zenodo 1146014, 10.5281/zenodo.1146014]; Usumezbas A., 2016, P EUR C COMP VIS, P1; Usumezbas A, 2017, PROC CVPR IEEE, P4560, DOI 10.1109/CVPR.2017.485	43	0	0	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3321	3332		10.1109/TPAMI.2020.2985310	http://dx.doi.org/10.1109/TPAMI.2020.2985310			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32275583				2022-12-18	WOS:000692232400008
J	Escalante, HJ; Yao, QM; Tu, WW; Pillay, N; Qu, R; Yu, Y; Houlsby, N				Escalante, Hugo Jair; Yao, Quanming; Tu, Wei-Wei; Pillay, Nelishia; Qu, Rong; Yu, Yang; Houlsby, Neil			Guest Editorial: Automated Machine Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Escalante, Hugo Jair] Inst Nacl Astrofis Opt & Eectron, Puebla 72840, Mexico; [Yao, Quanming] 4Paradigm Inc, Beijing 100085, Peoples R China; [Tu, Wei-Wei] 4Paradigm Inc, Sci & Technol Dept, Beijing 100085, Peoples R China; [Pillay, Nelishia] Univ Pretoria, ZA-0002 Pretoria, South Africa; [Qu, Rong] Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England; [Yu, Yang] Nanjing Univ, Sch Artificial Intelligence, Nanjing 210023, Peoples R China; [Houlsby, Neil] Google Res Brain Team, CH-8002 Zurich, Switzerland	Instituto Nacional de Astrofisica, Optica y Electronica; University of Pretoria; University of Nottingham; Nanjing University	Escalante, HJ (corresponding author), Inst Nacl Astrofis Opt & Eectron, Puebla 72840, Mexico.	hugojair@inaoep.mx; yaoquanming@4paradigm.com; tuweiwei@4paradigm.com; npillay@cs.up.ac.za; Rong.Qu@nottingham.ac.uk; yuy@nju.edu.cn; neilhoulsby@google.com	Yao, Quanming/Y-6095-2019; 涂, 威威/GRF-5615-2022	涂, 威威/0000-0002-2407-0252; Yao, Quanming/0000-0001-8944-8618	INAOE; CONACyT-Mexico [CBA1-S-26314]	INAOE; CONACyT-Mexico(Consejo Nacional de Ciencia y Tecnologia (CONACyT))	The work of Hugo Jair Escalante was supported in part by INAOE and in part by CONACyT-Mexico under Grant CBA1-S-26314.	Celik B, 2021, IEEE T PATTERN ANAL, V43, P3067, DOI 10.1109/TPAMI.2021.3062900; Elsken T., 2018, J MACH LEARN RES; Escalante H. J., ARXIV200808516, V2021; Fang JM, 2021, IEEE T PATTERN ANAL, V43, P2990, DOI 10.1109/TPAMI.2020.3044416; He Xin, 2019, ARXIV190800709; Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5; Liu Hanxiao, 2019, INTERNATIONAL CONFER; Liu Z., 2019, P AUT DAT SCI WORKSH; Liu ZY, 2021, IEEE T PATTERN ANAL, V43, P3108, DOI 10.1109/TPAMI.2021.3075372; Lu ZC, 2021, IEEE T PATTERN ANAL, V43, P2971, DOI 10.1109/TPAMI.2021.3052758; Ma XC, 2021, IEEE T PATTERN ANAL, V43, P3024, DOI 10.1109/TPAMI.2020.3026019; Mohr F, 2021, IEEE T PATTERN ANAL, V43, P3055, DOI 10.1109/TPAMI.2021.3056950; Pillay N, 2018, IEEE COMPUT INTELL M, V13, P16, DOI 10.1109/MCI.2018.2806988; Rice John R., 1975, COMPUTER SCI TECHNIC; Tuggener L, 2019, 2019 6TH SWISS CONFERENCE ON DATA SCIENCE (SDS), P31, DOI 10.1109/SDS.2019.00-11; Wever M, 2021, IEEE T PATTERN ANAL, V43, P3037, DOI 10.1109/TPAMI.2021.3051276; Xu YH, 2021, IEEE T PATTERN ANAL, V43, P2953, DOI 10.1109/TPAMI.2021.3059510; Yao Quanming, 2018, ARXIV181013306; Yu ZT, 2021, IEEE T PATTERN ANAL, V43, P3005, DOI 10.1109/TPAMI.2020.3036338; Zhang M, 2021, IEEE T PATTERN ANAL, V43, P2921, DOI 10.1109/TPAMI.2020.3035351; Zhang XB, 2021, IEEE T PATTERN ANAL, V43, P2891, DOI 10.1109/TPAMI.2020.3020300; Zhang XB, 2021, IEEE T PATTERN ANAL, V43, P2905, DOI 10.1109/TPAMI.2020.3020315; Zheng XW, 2021, IEEE T PATTERN ANAL, V43, P2936, DOI 10.1109/TPAMI.2021.3065138; Zheng XW, 2021, IEEE T PATTERN ANAL, V43, P3091, DOI 10.1109/TPAMI.2021.3069250; Zimmer L, 2021, IEEE T PATTERN ANAL, V43, P3079, DOI 10.1109/TPAMI.2021.3067763; Zoller MA, 2019, ARXIV190412054	26	0	0	2	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					2887	2890		10.1109/TPAMI.2021.3077106	http://dx.doi.org/10.1109/TPAMI.2021.3077106			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH		Bronze			2022-12-18	WOS:000681124300005
J	Hirose, O				Hirose, Osamu			A Bayesian Formulation of Coherent Point Drift (vol 43, pg 2269, 2021)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction						Bayes methods			[Hirose, Osamu] Kanazawa Univ, Inst Sci & Engn, Kanazawa, Ishikawa 9201192, Japan	Kanazawa University	Hirose, O (corresponding author), Kanazawa Univ, Inst Sci & Engn, Kanazawa, Ishikawa 9201192, Japan.	hirose@se.kanazawa-u.ac.jp	Hirose, Osamu/K-7890-2015	Hirose, Osamu/0000-0002-8077-8589				Hirose O, 2021, IEEE T PATTERN ANAL, V43, P2269, DOI 10.1109/TPAMI.2020.2971687	1	0	0	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					3273	3273		10.1109/TPAMI.2021.3092384	http://dx.doi.org/10.1109/TPAMI.2021.3092384			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	34347588	Bronze			2022-12-18	WOS:000681124300031
J	Qi, SY; Jia, BX; Huang, SY; Wei, P; Zhu, SC				Qi, Siyuan; Jia, Baoxiong; Huang, Siyuan; Wei, Ping; Zhu, Song-Chun			A Generalized Earley Parser for Human Activity Parsing and Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Grammar; Hidden Markov models; Prediction algorithms; Videos; Computational modeling; Probabilistic logic; Task analysis; Video understanding; high-level vision; activity recognition; activity prediction; grammar models; grammar parser	OBJECT AFFORDANCES; ACTION RECOGNITION	Detection, parsing, and future predictions on sequence data (e.g., videos) require the algorithms to capture non-Markovian and compositional properties of high-level semantics. Context-free grammars are natural choices to capture such properties, but traditional grammar parsers (e.g., Earley parser) only take symbolic sentences as inputs. In this paper, we generalize the Earley parser to parse sequence data which is neither segmented nor labeled. Given the output of an arbitrary probabilistic classifier, this generalized Earley parser finds the optimal segmentation and labels in the language defined by the input grammar. Based on the parsing results, it makes top-down future predictions. The proposed method is generic, principled, and widely applicable. Experiment results clearly show the benefit of our method for both human activity parsing and prediction on three video datasets.	[Qi, Siyuan; Jia, Baoxiong; Huang, Siyuan; Zhu, Song-Chun] Univ Calif Los Angeles, Dept Comp Sci & Stat, Los Angeles, CA 90095 USA; [Wei, Ping] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China	University of California System; University of California Los Angeles; Xi'an Jiaotong University	Wei, P (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.	syqi@cs.ucla.edu; baoxiongjia@g.ucla.edu; huangsiyuan@ucla.edu; pingwei.pw@gmail.com; sczhu@stat.ucla.edu			DARPA XAI [N66001-17-2-4029]; ONR MURI [N00014-16-1-2007, N66001-17-2-3602]; NSFC [61876149]	DARPA XAI; ONR MURI(MURIOffice of Naval Research); NSFC(National Natural Science Foundation of China (NSFC))	The authors would like to thank Professor Ying Nian Wu from UCLA Statistics Department for helpful comments on this work. The work reported herein was supported by DARPA XAI N66001-17-2-4029, ONR MURI N00014-16-1-2007, N66001-17-2-3602, and NSFC 61876149.	Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Cherian A, 2018, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2018.00234; Ding L, 2018, PROC CVPR IEEE, P6508, DOI 10.1109/CVPR.2018.00681; EARLEY J, 1970, COMMUN ACM, V13, P94, DOI 10.1145/362007.362035; Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38; Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646; Graves A., 2006, P INT C MACH LEARN I; Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492; Holtzen S, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1489, DOI 10.1109/IROS.2016.7759242; Ibrahim MS, 2018, LECT NOTES COMPUT SC, V11207, P742, DOI 10.1007/978-3-030-01219-9_44; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332; Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15; Kong Y., 2018, HUMAN ACTION RECOGNI; Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Kuderer Markus, 2012, P C ROB SCI SYST, V8; Kuehne H, 2016, IEEE WINT CONF APPL; Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105; Lan T, 2015, IEEE I CONF COMP VIS, P4552, DOI 10.1109/ICCV.2015.517; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Laxton B., 2007, P IEEE C COMP VIS PA, P1; Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113; Li Kang, 2014, IEEE Trans Pattern Anal Mach Intell, V36, P1644, DOI 10.1109/TPAMI.2013.2297321; Ma WC, 2017, PROC CVPR IEEE, P4636, DOI 10.1109/CVPR.2017.493; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Parsing D, 2011, P 14 INT C FORM GRAM, P47; Pei MT, 2013, COMPUT VIS IMAGE UND, V117, P1369, DOI 10.1016/j.cviu.2012.12.003; Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279; Pirsiavash H, 2014, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2014.85; Qi S., 2018, P IEEE INT C MACH LE, P4168; Qi SY, 2017, IEEE I CONF COMP VIS, P1173, DOI 10.1109/ICCV.2017.132; Rhinehart N, 2017, IEEE I CONF COMP VIS, P3716, DOI 10.1109/ICCV.2017.399; Rohrbach M, 2012, LECT NOTES COMPUT SC, V7572, P144, DOI 10.1007/978-3-642-33718-5_11; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Solan Z, 2005, P NATL ACAD SCI USA, V102, P11629, DOI 10.1073/pnas.0409746102; Song Y, 2013, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2013.457; STOLCKE A, 1995, COMPUT LINGUIST, V21, P165; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Tu K., 2013, ADV NEURAL INFORM PR, P1322; Vu TH, 2014, LECT NOTES COMPUT SC, V8693, P421, DOI 10.1007/978-3-319-10602-1_28; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Vo NN, 2014, PROC CVPR IEEE, P2641, DOI 10.1109/CVPR.2014.338; Wagner J., 2012, THESIS DUBLIN CITY U; Wagner Joachim, 2009, P 11 INT C PARS TECH, P176; Walker J, 2014, PROC CVPR IEEE, P3302, DOI 10.1109/CVPR.2014.416; Wang XL, 2016, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2016.291; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214; Wang Z, 2012, ROBOTICS SCI SYSTEMS; Wei P, 2017, IEEE T PATTERN ANAL, V39, P1165, DOI 10.1109/TPAMI.2016.2574712; Wu C, 2014, P ROB SCI SYST; Wu CX, 2015, PROC CVPR IEEE, P4362; Xie D, 2018, IEEE T PATTERN ANAL, V40, P1639, DOI 10.1109/TPAMI.2017.2728788; Young S, 2002, HTK FOR HTK VERSION; Yuen J, 2010, LECT NOTES COMPUT SC, V6312, P707, DOI 10.1007/978-3-642-15552-9_51; Zhang YB, 2019, PROC CVPR IEEE, P9967, DOI 10.1109/CVPR.2019.01021; Zhu J, 2013, IEEE I CONF COMP VIS, P3559, DOI 10.1109/ICCV.2013.442; Ziebart BD, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3931, DOI 10.1109/IROS.2009.5354147	63	0	0	2	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2538	2554		10.1109/TPAMI.2020.2976971	http://dx.doi.org/10.1109/TPAMI.2020.2976971			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32142420				2022-12-18	WOS:000670578800002
J	Su, YC; Grauman, K				Su, Yu-Chuan; Grauman, Kristen			Learning Compressible 360 degrees Video Isomers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video analysis; omnidirectional video; 360 degrees video projection; learning for video compression	PROJECTION	Standard video encoders developed for conventional narrow field-of-view video are widely applied to 360 degrees video as well, with reasonable results. However, while this approach commits arbitrarily to a projection of the spherical frames, we observe that some orientations of a 360 degrees video, once projected, are more compressible than others. We introduce an approach to predict the sphere rotation that will yield the maximal compression rate. Given video clips in their original encoding, a convolutional neural network learns the association between a clip's visual content and its compressibility at different rotations of a cubemap projection. Given a novel video, our learning-based approach efficiently infers the most compressible direction in one shot, without repeated rendering and compression of the source video. We validate our idea on thousands of video clips and multiple popular video codecs. The results show that this untapped dimension of 360 degrees compression has substantial potential-"good" rotations are typically 8-18 percent more compressible than bad ones, and our learning approach can predict them reliably 78 percent of the time.	[Su, Yu-Chuan; Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA; [Grauman, Kristen] Facebook AI Res, Menlo Pk, CA 94025 USA	University of Texas System; University of Texas Austin; Facebook Inc	Su, YC (corresponding author), Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.	ycsu@utexas.edu; grauman@cs.utexas.edu			US National Science Foundation [IIS-1514118]; Google Faculty Research Award; AWS Machine Learning Research Award	US National Science Foundation(National Science Foundation (NSF)); Google Faculty Research Award(Google Incorporated); AWS Machine Learning Research Award	We would like to thank Philippe Hanhart and Michele Covell for helpful discussions. UT Austin was supported in part by US National Science Foundation IIS-1514118, a Google Faculty Research Award, and an AWS Machine Learning Research Award.	Abbas D. N. Adeel, 2017, PROC SPIE, P172; Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Akbari M, 2019, INT CONF ACOUST SPEE, P2042, DOI 10.1109/ICASSP.2019.8683541; Alshina E., 2017, JVETG2005; [Anonymous], 2017, INTRO FACEBOOK 360 G; [Anonymous], 2016, P INT C LEARN REPR; [Anonymous], 2017, JVETF1003; Blu-ray Disc Association, 2015, WHIT PAP BLUR DISC R; Brown C., 2017, BRINGING PIXELS FRON; Chang CH, 2013, IEEE I CONF COMP VIS, P2824, DOI 10.1109/ICCV.2013.351; Chen ZB, 2020, IEEE T CIRC SYST VID, V30, P566, DOI 10.1109/TCSVT.2019.2892608; Choi B., 2017, 2300020 ISO IEC; Coban M., 2017, JVETG2003; Cohen T., 2017, ARXIV170904893; Gabriel A., 2017, JVETG2006; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Hanhart P., 2017, JVETG2004; Hansen P, 2007, IEEE I CONF COMP VIS, P512; Hu HN, 2017, PROC CVPR IEEE, P1396, DOI 10.1109/CVPR.2017.153; Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461; Jooyoung Lee S. C., 2019, P INT C LEARN REPR; Kamali M., 2011, PROC IAPRMACH VIS AP, P177; Kammachi-Sreedhar K, 2016, IEEE INT SYM MULTIM, P583, DOI [10.1109/ISM.2016.143, 10.1109/ISM.2016.0126]; Kasahara S., 2015, PROC ACM INT C INTER, P33; Khasanova R, 2017, IEEE INT CONF COMP V, P860, DOI 10.1109/ICCVW.2017.106; Kim YW, 2017, IEEE I CONF COMP VIS, P4753, DOI 10.1109/ICCV.2017.508; Kingma D.P, P 3 INT C LEARNING R; Klopp J., 2018, P BMVC, P124; Kopf J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982405; Kuzyakov E., 2015, HOOD BUILDING 360 VI; Kuzyakov E., 2016, NEXT GENERATION VIDE; Lai WS, 2018, IEEE T VIS COMPUT GR, V24, P2610, DOI 10.1109/TVCG.2017.2750671; Li M, 2018, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2018.00339; Liu D, 2018, LECT NOTES COMPUT SC, V10705, P61, DOI 10.1007/978-3-319-73600-6_6; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu G, 2019, PROC CVPR IEEE, P10998, DOI 10.1109/CVPR.2019.01126; Mentzer F, 2019, PROC CVPR IEEE, P10621, DOI 10.1109/CVPR.2019.01088; Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462; Rao KR, 2014, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-94-007-6742-3; Rippel O, 2019, IEEE I CONF COMP VIS, P3453, DOI 10.1109/ICCV.2019.00355; Rippel O, 2017, PR MACH LEARN RES, V70; Sanchez Y, 2015, IEEE IMAGE PROC, P2244, DOI 10.1109/ICIP.2015.7351200; Santurkar S, 2018, PICT COD SYMP, P258; Simonyan K., 2014, 3 INT C LEARN REPR I; Snyder J.P., 1987, MAP PROJECTIONS A WO; Su Y.-C., 2017, ADV NEURAL INFORM PR, P529; Su YC, 2019, PROC CVPR IEEE, P9434, DOI 10.1109/CVPR.2019.00967; Su YC, 2018, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2018.00816; Su YC, 2017, LECT NOTES COMPUT SC, V10114, P154, DOI 10.1007/978-3-319-54190-7_10; Su YC, 2017, PROC CVPR IEEE, P1368, DOI 10.1109/CVPR.2017.150; Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577; Ukonaho V., 2017, GLOBAL 360 CAMERA SA; Wang L, 2019, INT CONF ACOUST SPEE, P4035, DOI 10.1109/ICASSP.2019.8683624; Wien M., 2017, JVETF1002; Wu CY, 2018, LECT NOTES COMPUT SC, V11212, P425, DOI 10.1007/978-3-030-01237-3_26; Xiong B, 2018, LECT NOTES COMPUT SC, V11209, P3, DOI 10.1007/978-3-030-01228-1_1; Zelnik-Manor L, 2005, IEEE I CONF COMP VIS, P1292	57	0	0	3	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2697	2709		10.1109/TPAMI.2020.2974472	http://dx.doi.org/10.1109/TPAMI.2020.2974472			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32078535	Green Submitted			2022-12-18	WOS:000670578800013
J	Li, FQ; Willomitzer, F; Balaji, MM; Rangarajan, P; Cossairt, O				Li, Fengqiang; Willomitzer, Florian; Balaji, Muralidhar Madabhushi; Rangarajan, Prasanna; Cossairt, Oliver			Exploiting Wavelength Diversity for High Resolution Time-of-Flight 3D Imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional imaging; computational photography; optical interferometry	SHAPE MEASUREMENT; INTERFEROMETRY; INSPECTION; STEREO; DEPTH	The poor lateral and depth resolution of state-of-the-art 3D sensors based on the time-of-flight (ToF) principle has limited widespread adoption to a few niche applications. In this work, we introduce a novel sensor concept that provides ToF-based 3D measurements of real world objects and surfaces with depth precision up to 35 mu m and point cloud densities commensurate with the native sensor resolution of standard CMOS/CCD detectors (up to several megapixels). Such capabilities are realized by combining the best attributes of continuous wave ToF sensing, multi-wavelength interferometry, and heterodyne interferometry into a single approach. We describe multiple embodiments of the approach, each featuring a different sensing modality and associated tradeoffs.	[Li, Fengqiang; Cossairt, Oliver] Northwestern Univ, Dept Comp Sci, Evanston, IL 60208 USA; [Willomitzer, Florian] Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA; [Balaji, Muralidhar Madabhushi; Rangarajan, Prasanna] Southern Methodist Univ, Dept Elect & Comp Engn, Dallas, TX 75205 USA	Northwestern University; Northwestern University; Southern Methodist University	Li, FQ (corresponding author), Northwestern Univ, Dept Comp Sci, Evanston, IL 60208 USA.	fengqiang.li@u.northwestern.edu; florian.willomitzer@northwestern.edu; mmadabhushibalaji@mail.smu.edu; prangara@mail.smu.edu; olivercossairt@gmail.com		Li, Fengqiang/0000-0002-0271-0693	Defense Advanced Research Projects Agency (DARPA) REVEAL [HR0011-16-C-0028]; National Science Foundation (NSF) CAREER Award [IIS-1453192]	Defense Advanced Research Projects Agency (DARPA) REVEAL(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); National Science Foundation (NSF) CAREER Award(National Science Foundation (NSF)NSF - Office of the Director (OD))	Fengqiang Li and Florian Willomitzer have contributed equally and are considered joint first authors of this paper. This work was supported in part by the Defense Advanced Research Projects Agency (DARPA) REVEAL under Grant HR0011-16-C-0028 and in part by the National Science Foundation (NSF) CAREER Award under Grant IIS-1453192.	[Anonymous], 2017, TOF SENSOR; [Anonymous], 2017, KINECTSENSOR; [Anonymous], 2006, LIDAR RANGE RESOLVED; [Anonymous], 2020, HOLOLENS; Antipa N, 2018, OPTICA, V5, P1, DOI 10.1364/OPTICA.5.000001; Balaji M. M., 2017, P FRONT OPT; Beer S, 2006, THESIS U NEUCHATEL N; Born M., 2013, PRINCIPLES OPTICS EL; Caulier Y, 2010, OPT EXPRESS, V18, P6642, DOI 10.1364/OE.18.006642; Cervantes FG, 2007, APPL OPTICS, V46, P4541, DOI 10.1364/AO.46.004541; CHENG YY, 1984, APPL OPTICS, V23, P4539, DOI 10.1364/AO.23.004539; Chia-Kai Yeh, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P738, DOI 10.1007/978-3-319-46604-0_51; Cossairt O. S., 2019, U.S. Patent App., Patent No. [16/367,532, 16367532]; Dalal SS, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00042; DANDLIKER R, 1988, OPT LETT, V13, P339, DOI 10.1364/OL.13.000339; Eigen D, 2014, ADV NEUR IN, V27; FERCHER AF, 1985, APPL OPTICS, V24, P2181, DOI 10.1364/AO.24.002181; Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060; Geng J, 2011, ADV OPT PHOTONICS, V3, P128, DOI 10.1364/AOP.3.000128; Goodman J., 2015, STAT OPTICS; Goodman J. W., 1975, Laser speckle and related phenomena, P9; Goodman J. W., 2007, THEORY APPL; Gupta M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2735702; H_ausler G., 2012, P 113 DGAO C, pA8; Harendt B, 2014, APPL OPTICS, V53, P7507, DOI 10.1364/AO.53.007507; Heist S, 2016, OPT LASER ENG, V87, P90, DOI 10.1016/j.optlaseng.2016.02.017; Heliotis, 2020, HEL LOCK IN CAM; Herraez MA, 2002, APPL OPTICS, V41, P7437, DOI 10.1364/AO.41.007437; HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169; Huber F., 2011, P 112 DGAO C, pP30; Izadi Shahram, 2011, UIST, DOI [10.1145/2047196.2047270, DOI 10.1145/2047196.2047270]; Kadambi A, 2017, IEEE ACCESS, V5, P26211, DOI 10.1109/ACCESS.2017.2775138; Kadambi A, 2015, IEEE I CONF COMP VIS, P3370, DOI 10.1109/ICCV.2015.385; Kumar UP, 2009, OPT LASER ENG, V47, P223, DOI 10.1016/j.optlaseng.2008.04.005; Lamoreux J, 2004, P SOC PHOTO-OPT INS, V5412, P273, DOI 10.1117/12.553810; Lange R, 2001, IEEE J QUANTUM ELECT, V37, P390, DOI 10.1109/3.910448; Lee GH, 2013, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2013.354; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Levinson J, 2011, IEEE INT VEH SYM, P163, DOI 10.1109/IVS.2011.5940562; Li F., 2019, P IMAG APPL OPT; Li F., 2019, P IMAG APPL OPT; Li FH, 2018, IEEE GLOB COMM CONF; Li FQ, 2017, APPL OPTICS, V56, pH51, DOI 10.1364/AO.56.000H51; Li FQ, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.016006; Liu TA, 2011, OPT EXPRESS, V19, P18501, DOI 10.1364/OE.19.018501; Madabhushi Balaji M., 2018, THESIS SO METHODIST; Maeda T., 2018, P IEEE INT C COMP PH, P1; Malacara D., 2007, OPTICAL SHOP TESTING, V59; Michelson A.A., 1881, AM J SCI, V22, P120, DOI DOI 10.2475/AJS.S3-22.128.120; Molleda J, 2013, COMPUT IND, V64, P1186, DOI 10.1016/j.compind.2013.05.002; Morimoto K, 2020, OPTICA, V7, P346, DOI 10.1364/OPTICA.386574; Nalpantidis L, 2008, INT J OPTOMECHATRONI, V2, P435, DOI 10.1080/15599610802438680; Piracha MU, 2010, OPT EXPRESS, V18, P7184, DOI 10.1364/OE.18.007184; POLHEMUS C, 1973, APPL OPTICS, V12, P2071, DOI 10.1364/AO.12.002071; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Schaffer M, 2010, APPL OPTICS, V49, P3622, DOI 10.1364/AO.49.003622; Schechner YY, 2000, INT J COMPUT VISION, V39, P141, DOI 10.1023/A:1008175127327; Schwarte R, 1997, P SOC PHOTO-OPT INS, V3100, P245, DOI 10.1117/12.287751; SCHWIDER J, 1989, APPL OPTICS, V28, P3889, DOI 10.1364/AO.28.003889; Su SC, 2018, PROC CVPR IEEE, P6383, DOI 10.1109/CVPR.2018.00668; Tadano R, 2016, IEEE IMAGE PROC, P1564, DOI 10.1109/ICIP.2016.7532621; Ti CP, 2015, PROC CVPR IEEE, P4334, DOI 10.1109/CVPR.2015.7299062; Verrier N., NEW TECHNIQUES DIGIT; Willomitzer F., 2020, RESEARCHSQUARE, DOI [10.21203/rs.3.rs-84906/v1, DOI 10.21203/RS.3.RS-84906/V1]; Willomitzer F., 2019, ARXIV191211438; Willomitzer F, 2020, OPT EXPRESS, V28, P9027, DOI 10.1364/OE.383475; Willomitzer F, 2017, OPT EXPRESS, V25, P23451, DOI 10.1364/OE.25.023451; Willomitzer F, 2015, APPL OPTICS, V54, P408, DOI 10.1364/AO.54.000408; Willomitzer F, 2013, AIP CONF PROC, V1537, P19, DOI 10.1063/1.4809687; Wu YK, 2020, IEEE IND APPLIC SOC, DOI 10.1109/IAS44978.2020.9334859; XU W, 1994, INT GEOSCI REMOTE SE, P730, DOI 10.1109/IGARSS.1994.399243; Yan Chen, 2020, 2020 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P2246, DOI 10.1109/WACV45572.2020.9093594	72	0	0	3	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2193	2205		10.1109/TPAMI.2021.3075156	http://dx.doi.org/10.1109/TPAMI.2021.3075156			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	33886466	Green Submitted			2022-12-18	WOS:000692540900003
J	Marrelec, G; Giron, A				Marrelec, Guillaume; Giron, Alain			Automated Extraction of Mutual Independence Patterns Using Bayesian Comparison of Partition Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes methods; Gaussian distribution; Numerical models; Markov processes; Monte Carlo methods; Covariance matrices; Task analysis; Mutual independence; Bayesian analysis; model comparison; likelihood ratio criterion; minimum discrimination information statistic; Markov chain Monte Carlo; Gibbs sampling; parallel tempering	NUMBER	Mutual independence is a key concept in statistics that characterizes the structural relationships between variables. Existing methods to investigate mutual independence rely on the definition of two competing models, one being nested into the other and used to generate a null distribution for a statistic of interest, usually under the asymptotic assumption of large sample size. As such, these methods have a very restricted scope of application. In this article, we propose to change the investigation of mutual independence from a hypothesis-driven task that can only be applied in very specific cases to a blind and automated search within patterns of mutual independence. To this end, we treat the issue as one of model comparison that we solve in a Bayesian framework. We show the relationship between such an approach and existing methods in the case of multivariate normal distributions as well as cross-classified multinomial distributions. We propose a general Markov chain Monte Carlo (MCMC) algorithm to numerically approximate the posterior distribution on the space of all patterns of mutual independence. The relevance of the method is demonstrated on synthetic data as well as two real datasets, showing the unique insight provided by this approach.	[Marrelec, Guillaume; Giron, Alain] Sorbonne Univ, CNRS, Lab Imagerie Biomed LIB, INSERM, F-75006 Paris, France; [Marrelec, Guillaume; Giron, Alain] Ctr Res & Etud Sci Interact CRESI, Ctr Interact Sci CIS, F-75006 Paris, France	Centre National de la Recherche Scientifique (CNRS); Institut National de la Sante et de la Recherche Medicale (Inserm); UDICE-French Research Universities; Sorbonne Universite; Universite Paris Cite	Marrelec, G (corresponding author), Sorbonne Univ, CNRS, Lab Imagerie Biomed LIB, INSERM, F-75006 Paris, France.; Marrelec, G (corresponding author), Ctr Res & Etud Sci Interact CRESI, Ctr Interact Sci CIS, F-75006 Paris, France.	guillaume.marrelec@inserm.fr; alain.giron@inserm.fr						Anderson T.W, 1958, INTRO MULTIVARIATE S; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161; Barnard J, 2000, STAT SINICA, V10, P1281; Bell ET, 1938, ANN MATH, V39, P539, DOI 10.2307/1968633; Bell ET, 1934, ANN MATH, V35, P258, DOI 10.2307/1968431; Bell ET., 1934, AM MATH MON, V41, P411, DOI DOI 10.2307/2300300; Birkhoff G., 1973, LATTICE THEORY, V3; Booth JG, 2008, J R STAT SOC B, V70, P119, DOI 10.1111/j.1467-9868.2007.00629.x; Crowley EM, 1997, J AM STAT ASSOC, V92, P192, DOI 10.2307/2291463; Earl DJ, 2005, PHYS CHEM CHEM PHYS, V7, P3910, DOI 10.1039/b509983h; Edwards D., 2000, INTRO GRAPHICAL MODE; Ferreira L, 2009, COMMUN STAT-SIMUL C, V38, P1925, DOI 10.1080/03610910903168603; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Fraley C, 2007, J CLASSIF, V24, P155, DOI 10.1007/s00357-007-0004-z; Gelman A., 1998, BAYESIAN DATA ANAL; Ghahramani Z., 2005, P 22 INT C MACH LEAR, P297, DOI DOI 10.1145/1102351.1102389; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; HARTIGAN JA, 1990, COMMUN STAT THEORY, V19, P2745, DOI 10.1080/03610929008830345; HARTIGAN JA, 1972, J AM STAT ASSOC, V67, P123, DOI 10.2307/2284710; Hastie DI, 2012, STAT NEERL, V66, P309, DOI 10.1111/j.1467-9574.2012.00516.x; Heard NA, 2006, J AM STAT ASSOC, V101, P18, DOI 10.1198/016214505000000187; Jacques J., 2013, 8198 INR; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Jaynes E.T., 2003, PROBABILITY THEORY L; JOE H, 1989, J AM STAT ASSOC, V84, P157, DOI 10.2307/2289859; Kelly C, 2012, NEUROIMAGE, V61, P1129, DOI 10.1016/j.neuroimage.2012.03.021; Knuth D., 2005, FASCICLE 2 GENERATIN, V4; Kotz S., 2004, MULTIVARIATE T DISTR; KULLBACK S, 1968, INFORM THEORY STAT; Lau JW, 2007, J COMPUT GRAPH STAT, V16, P526, DOI 10.1198/106186007X238855; Liu J. S., 2002, MONTE CARLO STRATEGI; Marrelec G, 2006, J MULTIVARIATE ANAL, V97, P1451, DOI 10.1016/j.jmva.2005.08.008; Marrelec G, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137278; Neal RM, 1996, STAT COMPUT, V6, P353, DOI 10.1007/BF00143556; Nijenhuis A., 1978, COMBINATORIAL ALGORI; Pitman J, 1997, AM MATH MON, V104, P201, DOI 10.2307/2974785; Pitman J., 2002, 621 UC BEK DEP STAT; Ramsay J, 2005, FUNCTIONAL DATA ANAL, Vsecond, DOI 10.1007/b98888; Rasmussen CE, 2000, ADV NEUR IN, V12, P554; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; ROTA GC, 1964, AM MATH MON, V71, P498, DOI 10.2307/2312585; Roverato A., 1999, CLASSIFICATION DATA, P335; Ruskey F., 1993, Algorithms and Computation. 4th International Symposium, ISAAC '93 Proceedings, P201; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Serban N, 2005, J AM STAT ASSOC, V100, P990, DOI 10.1198/016214504000001574; Sirinukunwattana K, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0075748; Sporns O, 2015, PHILOS T R SOC B, V370, P42, DOI 10.1098/rstb.2014.0173; Studeny M., 1998, P JOINT SESS 6 PRAG, P23; Wakefield JC, 2003, BAYESIAN STATISTICS 7, P721; Whittaker J., 1990, GRAPHICAL MODELS APP; Wilf H. S., 1999, E SIDE W SIDE; Wolf D. R., 1994, MUTUAL INFORM BAYESI; Yeo BTT, 2011, J NEUROPHYSIOL, V106, P1125, DOI 10.1152/jn.00338.2011; Zar J.J., 2010, BIOSTAT ANAL, Vfifth	56	0	0	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2299	2313		10.1109/TPAMI.2020.2968065	http://dx.doi.org/10.1109/TPAMI.2020.2968065			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	31985405	Green Submitted			2022-12-18	WOS:000692540900010
J	Schechner, YY; Bala, K; Katz, O; Sunkavalli, K; Nishino, K				Schechner, Yoav Y.; Bala, Kavita; Katz, Ori; Sunkavalli, Kalyan; Nishino, Ko			Guest Editorial: Introduction to the Special Section on Computational Photography	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Schechner, Yoav Y.] Technion Israel Inst Technol, Viterbi Fac Elect Engn, IL-3200003 Haifa, Israel; [Bala, Kavita] Cornell Univ, Dept Comp Sci, Ann S Bowers Coll Comp & Informat Sci, Ithaca, NY 14850 USA; [Katz, Ori] Hebrew Univ Jerusalem, Dept Appl Phys, Fac Sci, IL-91904 Jerusalem, Israel; [Sunkavalli, Kalyan] Adobe Res, San Jose, CA 95110 USA; [Nishino, Ko] Kyoto Univ, Dept Intelligence Sci & Technol, Kyoto 6068501, Japan	Technion Israel Institute of Technology; Cornell University; Hebrew University of Jerusalem; Adobe Systems Inc.; Kyoto University	Schechner, YY (corresponding author), Technion Israel Inst Technol, Viterbi Fac Elect Engn, IL-3200003 Haifa, Israel.	yoav@ee.technion.ac.il; kavitabala@cornell.edu; orik@mail.huji.ac.il; sunkaval@adobe.com; nishino.ko.5a@kyoto-u.ac.jp	Katz, Ori/GZL-1647-2022	Schechner, Yoav/0000-0002-4022-7037; Bala, Kavita/0000-0001-9761-6503; Nishino, Ko/0000-0002-3534-3447					0	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2175	2178		10.1109/TPAMI.2021.3078707	http://dx.doi.org/10.1109/TPAMI.2021.3078707			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK		Bronze			2022-12-18	WOS:000692540900001
J	Shen, SY; Wang, Z; Liu, P; Pan, ZQ; Li, RQ; Gao, T; Li, SY; Yu, JY				Shen, Siyuan; Wang, Zi; Liu, Ping; Pan, Zhengqing; Li, Ruiqian; Gao, Tian; Li, Shiying; Yu, Jingyi			Non-line-of-Sight Imaging via Neural Transient Fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Transient analysis; Image reconstruction; Imaging; Nonlinear optics; Measurement by laser beam; Surface reconstruction; Solid modeling; Computational photography; non-line-of-sight imaging; neural radiance field; neural rendering		We present a neural modeling framework for non-line-of-sight (NLOS) imaging. Previous solutions have sought to explicitly recover the 3D geometry (e.g., as point clouds) or voxel density (e.g., within a pre-defined volume) of the hidden scene. In contrast, inspired by the recent Neural Radiance Field (NeRF) approach, we use a multi-layer perceptron (MLP) to represent the neural transient field or NeTF. However, NeTF measures the transient over spherical wavefronts rather than the radiance along lines. We therefore formulate a spherical volume NeTF reconstruction pipeline, applicable to both confocal and non-confocal setups. Compared with NeRF, NeTF samples a much sparser set of viewpoints (scanning spots) and the sampling is highly uneven. We thus introduce a Monte Carlo technique to improve the robustness in the reconstruction. Experiments on synthetic and real datasets demonstrate NeTF achieves state-of-the-art performance and can provide reliable reconstructions even under semi-occlusions and on non-Lambertian materials.	[Shen, Siyuan; Wang, Zi; Liu, Ping; Pan, Zhengqing; Li, Ruiqian; Gao, Tian; Li, Shiying; Yu, Jingyi] Shanghai Tech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China; [Shen, Siyuan] DGene Inc, Shanghai 201203, Peoples R China; [Wang, Zi] Shanghai Inst Tech Phys, Chinese Acad Sci, Shanghai 200083, Peoples R China; [Pan, Zhengqing] Shanghai Inst Microsyst & Informat Technol, Chinese Acad Sci, Shanghai 200050, Peoples R China; [Li, Shiying; Yu, Jingyi] ShanghaiTech Univ, Shanghai Engn Res Ctr, Intelligent Vision & Imaging, Shanghai 201210, Peoples R China	ShanghaiTech University; Chinese Academy of Sciences; Shanghai Institute of Technical Physics, CAS; Chinese Academy of Sciences; Shanghai Institute of Microsystem & Information Technology, CAS; ShanghaiTech University	Li, SY; Yu, JY (corresponding author), Shanghai Tech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.; Li, SY; Yu, JY (corresponding author), ShanghaiTech Univ, Shanghai Engn Res Ctr, Intelligent Vision & Imaging, Shanghai 201210, Peoples R China.	shensy@shanghaitech.edu.cn; wangzi@shanghaitech.edu.cn; liuping@shanghaitech.edu.cn; panzhq@shanghaitech.edu.cn; lirq1@shanghaitech.edu.cn; gaotian@shanghaitech.edu.cn; lishy1@shanghaitech.edu.cn; yujingyi@shanghaitech.edu.cn		Wang, Zi/0000-0001-8721-4295; Liu, Ping/0000-0002-7044-3996	NSFC [61976138, 61977047]; STCSMunder Grant [2015F0203-000-06]	NSFC(National Natural Science Foundation of China (NSFC)); STCSMunder Grant	The authors would like to thank anonymous Reviewers for their valuable feedback. The authors would also like to thank Minye Wu and Huangjie Yu for their helpful discussions. This work was supported in part by the NSFC under Grants 61976138 and 61977047 and in part by the STCSMunder Grant 2015F0203-000-06. Siyuan Shen and Zi Wang contributed equally to thiswork.	Ahn B, 2019, IEEE I CONF COMP VIS, P7888, DOI 10.1109/ICCV.2019.00798; Altmann Y, 2018, SCIENCE, V361, P660, DOI 10.1126/science.aat2298; Arellano V, 2017, OPT EXPRESS, V25, P11574, DOI 10.1364/OE.25.011574; Ba J., 2017, P 3 INT C LEARN REPR; Bi Sai, 2020, ARXIV200803824; Buttafava M, 2015, OPT EXPRESS, V23, P20997, DOI 10.1364/OE.23.020997; Caramazza P, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30390-0; Faccio D, 2020, NAT REV PHYS, V2, P318, DOI 10.1038/s42254-020-0174-8; Galindo M, 2019, SIGGRAPH '19 - ACM SIGGRAPH 2019 POSTERS, DOI 10.1145/3306214.3338583; Gariepy G, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms7021; Gkioulekas I, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766928; Gupta O, 2012, OPT EXPRESS, V20, P19096, DOI 10.1364/OE.20.019096; Heide F, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3269977; Iseringhausen J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3368314; Isogawa Mariko, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P193, DOI 10.1007/978-3-030-58571-6_12; Isogawa M, 2020, PROC CVPR IEEE, P7011, DOI 10.1109/CVPR42600.2020.00704; Jarabo A, 2017, VIS INFORM, V1, P65, DOI 10.1016/j.visinf.2017.01.008; Jarabo A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661251; Kajiya J. T., 1984, Computers & Graphics, V18, P165; Kang Bingyi, 2020, INT C LEARN REPR; Kirmani A, 2011, INT J COMPUT VISION, V95, P13, DOI 10.1007/s11263-011-0470-y; Kirmani A, 2009, IEEE I CONF COMP VIS, P159, DOI 10.1109/ICCV.2009.5459160; La Manna M, 2019, IEEE T PATTERN ANAL, V41, P1615, DOI 10.1109/TPAMI.2018.2843363; Lawrence J. D., 2014, CATALOG SPECIAL PLAN; Lindell DB, 2019, PROC CVPR IEEE, P3773, DOI 10.1109/CVPR.2019.00694; Lindell DB, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322937; Liu XC, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15157-4; Liu XC, 2019, NATURE, V572, P620, DOI 10.1038/s41586-019-1461-3; Maeda T, 2019, IEEE INT CONF COMPUT; Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24; O'Toole M, 2018, NATURE, V555, P338, DOI 10.1038/nature25489; O'Toole M, 2017, PROC CVPR IEEE, P2289, DOI 10.1109/CVPR.2017.246; Reza SA, 2019, OPT EXPRESS, V27, P29379, DOI 10.1364/OE.27.029380; Shin D, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12046; Tsai CY, 2019, PROC CVPR IEEE, P1545, DOI 10.1109/CVPR.2019.00164; Tsai CY, 2017, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2017.251; Velten A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461928; Velten A, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1747; Xin SM, 2019, PROC CVPR IEEE, P6793, DOI 10.1109/CVPR.2019.00696; Xu FH, 2018, OPT EXPRESS, V26, P9945, DOI 10.1364/OE.26.009945; Yariv L., 2020, NEURIPS; Young SI, 2020, PROC CVPR IEEE, P1404, DOI 10.1109/CVPR42600.2020.00148	42	0	0	8	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2257	2268		10.1109/TPAMI.2021.3076062	http://dx.doi.org/10.1109/TPAMI.2021.3076062			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	33905326	Green Submitted			2022-12-18	WOS:000692540900007
J	Yang, A; Sankaranarayanan, AC				Yang, Anqi; Sankaranarayanan, Aswin C.			Designing Display Pixel Layouts for Under-Panel Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Apertures; Layout; Lenses; Organic light emitting diodes; Optics; Shape; Computational photography; under-panel cameras; deblurring	DEPTH	Under-panel cameras provide an intriguing way to maximize the display area for a mobile device. An under-panel camera images a scene via the openings in the display panel; hence, a captured photograph is noisy as well as endowed with a large diffractive blur as the display acts as an aperture on the lens. Unfortunately, the pattern of openings commonly found in current LED displays are not conducive to high-quality deblurring. This paper redesigns the layout of openings in the display to engineer a blur kernel that is robustly invertible in the presence of noise. We first provide a basic analysis using Fourier optics that indicates that the nature of the blur is critically affected by the periodicity of the display openings as well as the shape of the opening at each individual display pixel. Armed with this insight, we provide a suite of modifications to the pixel layout that promote the invertibility of the blur kernels. We evaluate the proposed layouts with photomasks placed in front of a cellphone camera, thereby emulating an under-panel camera. A key takeaway is that optimizing the display layout does indeed produce significant improvements.	[Yang, Anqi; Sankaranarayanan, Aswin C.] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Yang, A (corresponding author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.	anqiy1@andrew.cmu.edu; saswin@andrew.cmu.edu		Sankaranarayanan, Aswin/0000-0003-0906-4046; Yang, Anqi/0000-0003-0811-7951	Samsung Advanced Institute of Technology through Global Research Outreach Program; NSF CAREER Award [CCF-1652569]	Samsung Advanced Institute of Technology through Global Research Outreach Program(Samsung); NSF CAREER Award(National Science Foundation (NSF)NSF - Office of the Director (OD))	The authors would like to thank Dr. Eunhee Kang and Dr. Hyong-Euk Lee for introducing them to this problem and valuable discussions on display design. This work was supported in part by the Samsung Advanced Institute of Technology through Global Research Outreach Program and in part by the NSF CAREER Award under Grant CCF-1652569.	AndrewWilson D., 2004, P 6 INT C MULT INT N, P69, DOI DOI 10.1145/1027933.1027946; Benko H., 2009, MSRTR200923; Chang J, 2019, IEEE I CONF COMP VIS, P10192, DOI 10.1109/ICCV.2019.01029; Chi Jui Cheng, 2019, SID Symposium Digest of Technical Papers, V50, P1533, DOI 10.1002/sdtp.13235; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; DOWSKI ER, 1995, APPL OPTICS, V34, P1859, DOI 10.1364/AO.34.001859; FENIMORE EE, 1978, APPL OPTICS, V17, P337, DOI 10.1364/AO.17.000337; Goodman J. W., 2005, MCGRAW HILL PHYS QUA; Hasinoff SW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980254; Hirsch M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618505; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Lim S., 2020, P SOC INF DISPL INT, P1102; Lumsdaine A., 2009, IEEE INT C COMPUTATI, P1; Masia B, 2013, COMPUT GRAPH-UK, V37, P1012, DOI 10.1016/j.cag.2013.10.003; Metzler CA, 2020, PROC CVPR IEEE, P1372, DOI 10.1109/CVPR42600.2020.00145; Mitra K, 2014, IEEE T PATTERN ANAL, V36, P1909, DOI 10.1109/TPAMI.2014.2313118; Pavani SRP, 2008, OPT EXPRESS, V16, P22048, DOI 10.1364/OE.16.022048; Puthussery D, 2020, ARXIV200909393; Ronneberger O., 2015, P MEDICAL IMAGE COMP, P234; Saier MH, 2007, WATER AIR SOIL POLL, V181, P1, DOI 10.1007/s11270-007-9372-6; Shen KL, 2020, WORLD J PEDIATR, V16, P219, DOI 10.1007/s12519-020-00344-6; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Sun QL, 2020, PROC CVPR IEEE, P1383, DOI 10.1109/CVPR42600.2020.00146; Sundar V., 2020, PROC EUR C COMPUT VI; Tsujimura T, 2017, OLED DISPLAY FUNDAME, V2; Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang Z., 2020, PROC IEEE GLOBAL COM, P16; Wu Y, 2020, PSYCHOL MED, V50, P2816, DOI 10.1017/S0033291719002137; Yang A., 2021, DESIGN DISPLAY PIXEL; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zhou CY, 2009, IEEE I CONF COMP VIS, P325, DOI 10.1109/ICCV.2009.5459268; Zhou Y., 2020, P EUR C COMP VIS WOR, V12539, P337; Zhou Y, 2020, ARXIV200304857	34	0	0	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2245	2256		10.1109/TPAMI.2021.3075978	http://dx.doi.org/10.1109/TPAMI.2021.3075978			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	33905325				2022-12-18	WOS:000692540900006
J	Evain, S; Guillemot, C				Evain, Simon; Guillemot, Christine			A Lightweight Neural Network for Monocular View Generation With Occlusion Handling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Estimation; Three-dimensional displays; Neural networks; Image resolution; Computer vision; Tools; Computer vision; monocular; deep learning; stereo; view synthesis		In this article, we present a very lightweight neural network architecture, trained on stereo data pairs, which performs view synthesis from one single image. With the growing success of multi-view formats, this problem is indeed increasingly relevant. The network returns a prediction built from disparity estimation, which fills in wrongly predicted regions using a occlusion handling technique. To do so, during training, the network learns to estimate the left-right consistency structural constraint on the pair of stereo input images, to be able to replicate it at test time from one single image. The method is built upon the idea of blending two predictions: a prediction based on disparity estimation and a prediction based on direct minimization in occluded regions. The network is also able to identify these occluded areas at training and at test time by checking the pixelwise left-right consistency of the produced disparity maps. At test time, the approach can thus generate a left-side and a right-side view from one input image, as well as a depth map and a pixelwise confidence measure in the prediction. The work outperforms visually and metric-wise state-of-the-art approaches on the challenging KITTI dataset, all while reducing by a very significant order of magnitude (5 or 10 times) the required number of parameters (6.5 M).	[Evain, Simon; Guillemot, Christine] INRIA Rennes Bretagne Atlantique, Campus Beaulieu, F-35042 Rennes, France		Evain, S (corresponding author), INRIA Rennes Bretagne Atlantique, Campus Beaulieu, F-35042 Rennes, France.	simon.evain@irisa.fr; christine.guillemot@inria.fr		Guillemot, Christine/0000-0003-1604-967X; Evain, Simon/0000-0001-5389-9441	EU H2020 Research and Innovation Programme [694122]	EU H2020 Research and Innovation Programme	This work was funded by the EU H2020 Research and Innovation Programme under grant agreement No 694122 (ERC advanced grant CLIM).	Abadi M, 2015, P 12 USENIX S OPERAT; Cao YZH, 2018, IEEE T CIRC SYST VID, V28, P3174, DOI 10.1109/TCSVT.2017.2740321; Chollet F., 2015, KERAS; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Cun X., 2019, IEEE COMPUT GRAPHICS; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Eigen D, 2014, ADV NEUR IN, V27; Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Habtegebrial T., 2019, VISAPP; Hadfield S, 2013, PROC CVPR IEEE, P3398, DOI 10.1109/CVPR.2013.436; Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232; Horry Y., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P225, DOI 10.1145/258734.258854; Howard A. G., 2017, MOBILENETS EFFICIENT; Jaderberg M, 2015, ADV NEUR IN, V28; Kingma D.P., 2015, ICLR, P1; Kulkarni TD, 2015, ADV NEUR IN, V28; Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; LeCun Y, 2016, P INT C LEARN REPR; Liu M., 2018, PROC CVPR IEEE; Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI 10.1109/ICCV.2017.478; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Park E, 2017, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2017.82; Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Srinivasan PP, 2017, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2017.246; Sun SH, 2018, LECT NOTES COMPUT SC, V11207, P162, DOI 10.1007/978-3-030-01219-9_10; Tulsiani S., 2018, P EUR C COMP VIS INT, P311; von Amersfoort J., 2017, ARXIV171106045; Woodford O. J, 2007, BMVC, P1; Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51; Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18; Zimmer H, 2011, INT J COMPUT VISION, V93, P368, DOI 10.1007/s11263-011-0422-6	39	0	0	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					1832	1844		10.1109/TPAMI.2019.2960689	http://dx.doi.org/10.1109/TPAMI.2019.2960689			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	31869784	Green Submitted			2022-12-18	WOS:000649590200002
J	Poulin, V; Theberge, F				Poulin, Valerie; Theberge, Francois			Comparing Graph Clusterings: Set Partition Measures vs. Graph-Aware Measures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Partitioning algorithms; Indexes; Clustering algorithms; Mutual information; Size measurement; Topology; Computer vision; Graph clustering; partition similarity	COMMUNITY STRUCTURE; RESOLUTION	In this paper, we propose a family of graph partition similarity measures that take the topology of the graph into account. These graph-aware measures are alternatives to using set partition similarity measures that are not specifically designed for graphs. The two types of measures, graph-aware and set partition measures, are shown to have opposite behaviors with respect to resolution issues and provide complementary information necessary to compare graph partitions.	[Poulin, Valerie; Theberge, Francois] Tutte Inst Math & Comp, Ottawa, ON K1G 3Z4, Canada		Poulin, V (corresponding author), Tutte Inst Math & Comp, Ottawa, ON K1G 3Z4, Canada.	vpoulin@gmail.com; theberge@ieee.org		Theberge, Francois/0000-0002-5499-3680				Albatineh AN, 2006, J CLASSIF, V23, P301, DOI 10.1007/s00357-006-0017-z; Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008; Choi SS., 2010, J SYSTEMICS CYBERNET, V8910, P43; Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111; Condon A, 2001, RANDOM STRUCT ALGOR, V18, P116, DOI 10.1002/1098-2418(200103)18:2<116::AID-RSA1001>3.0.CO;2-2; Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013; Fortunato S, 2007, P NATL ACAD SCI USA, V104, P36, DOI 10.1073/pnas.0605965104; Fortunato S, 2016, PHYS REP, V659, P1, DOI 10.1016/j.physrep.2016.09.002; Gates AJ, 2017, J MACH LEARN RES, V18; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Kumpula JM, 2007, EUR PHYS J B, V56, P41, DOI 10.1140/epjb/e2007-00088-4; Labatut V., 2015, INT J SOCIAL NETWORK, V2, P44, DOI [10.1504/IJSNM.2015.069776, DOI 10.1504/IJSNM.2015.069776, 10.1504/ijsnm.2015.069776]; Lancichinetti A, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.056117; Lancichinetti A, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.016118; Meila M., 2005, PROC INT C MACHINE L, P577, DOI DOI 10.1145/1102351.1102424; Meila M, 2007, J MULTIVARIATE ANAL, V98, P873, DOI 10.1016/j.jmva.2006.11.013; Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104; Orman GK, 2009, LECT NOTES ARTIF INT, V5808, P242, DOI 10.1007/978-3-642-04747-3_20; Poulin V, 2019, APPL NETW SCI, V4, DOI 10.1007/s41109-019-0162-z; Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Reichardt J, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.016110; Romano S, 2016, J MACH LEARN RES, V17; Rosvall M, 2007, P NATL ACAD SCI USA, V104, P7327, DOI 10.1073/pnas.0611034104; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002; Soundararajan P, 2003, IEEE T PATTERN ANAL, V25, P642, DOI 10.1109/TPAMI.2003.1201817; Vinh N.X., 2009, P 26 ANN INT C MACH, P1073, DOI [10.1145/1553374.1553511, DOI 10.1145/1553374.1553511]; Vinh NX, 2010, J MACH LEARN RES, V11, P2837; Yang Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30750; Yu CP, 2015, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2015.361	34	0	0	4	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2127	2132		10.1109/TPAMI.2020.3009862	http://dx.doi.org/10.1109/TPAMI.2020.3009862			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	32750819	Green Submitted			2022-12-18	WOS:000649590200022
J	Tanaka, K; Ikeya, N; Takatani, T; Kubo, H; Funatomi, T; Ravi, V; Kadambi, A; Mukaigawa, Y				Tanaka, Kenichiro; Ikeya, Nobuhiro; Takatani, Tsuyoshi; Kubo, Hiroyuki; Funatomi, Takuya; Ravi, Vijay; Kadambi, Achuta; Mukaigawa, Yasuhiro			Time-Resolved Far Infrared Light Transport Decomposition for Thermal Photometric Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Infrared heating; Scattering; Thermal decomposition; Transient analysis; Computer vision; Photothermal effects; photometry; transient analysis; image decomposition	TRANSLUCENT OBJECTS; COLOR; SEPARATION; COMPONENTS	We present a novel time-resolved light transport decomposition method using thermal imaging. Because the speed of heat propagation is much slower than the speed of light propagation, the transient transport of far infrared light can be observed at a video frame rate. A key observation is that the thermal image looks similar to the visible light image in an appropriately controlled environment. This implies that conventional computer vision techniques can be straightforwardly applied to the thermal image. We show that the diffuse component in the thermal image can be separated, and therefore, the surface normals of objects can be estimated by the Lambertian photometric stereo. The effectiveness of our method is evaluated by conducting real-world experiments, and its applicability to black body, transparent, and translucent objects is shown.	[Tanaka, Kenichiro; Ikeya, Nobuhiro; Kubo, Hiroyuki; Funatomi, Takuya; Mukaigawa, Yasuhiro] Nara Inst Sci & Technol NAIST, Dept Informat Sci, 8916-5 Takayama, Nara 6300192, Japan; [Tanaka, Kenichiro; Ravi, Vijay; Kadambi, Achuta] Univ Calif Los Angeles, 420 Westwood Plaza, Los Angeles, CA 90095 USA; [Takatani, Tsuyoshi] Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan	Nara Institute of Science & Technology; University of California System; University of California Los Angeles; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan	Tanaka, K (corresponding author), Nara Inst Sci & Technol NAIST, Dept Informat Sci, 8916-5 Takayama, Nara 6300192, Japan.	ktanaka@is.naist.jp; ikeya.nobuhiro.ii6@is.naist.jp; takatani.tsuyoshi.to2@is.naist.jp; hkubo@is.naist.jp; funatomi@is.naist.jp; vijaysumaravi@ucla.edu; achuta@ee.ucla.edu; mukaigawa@is.naist.jp	Kubo, Hiroyuki/AAS-1487-2021; Funatomi, Takuya/K-5919-2018	Kubo, Hiroyuki/0000-0002-7061-7941; Funatomi, Takuya/0000-0001-5588-5932	JSPS KAKEN [JP18H03265, JP18K19822, JP26700013, JP15H05918, JP17J05602]; NSF Research Initiation Award [IIS 1849941]	JSPS KAKEN; NSF Research Initiation Award	This work was supported in part by JSPS KAKEN grant JP18H03265, JP18K19822, JP26700013, JP15H05918, and JP17J05602. Achuta Kadambi was supported in part by an NSF Research Initiation Award (IIS 1849941).	Becker T. W., 2016, LECT NOTES USC GEOL5; Bhandari A, 2014, IEEE SENSOR; Carslaw HS, 1986, CONDUCTION HEAT SOLI, V2nd; CRANK J, 1947, P CAMB PHILOS SOC, V43, P50, DOI 10.1007/BF02127704; Dorrington A.A., 2011, P SPIE THE INT SOC O; Eren G, 2009, OPT EXPRESS, V17, P11457, DOI 10.1364/OE.17.011457; Freedman D, 2014, LECT NOTES COMPUT SC, V8689, P234, DOI 10.1007/978-3-319-10590-1_16; Fuchs Stefan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3583, DOI 10.1109/ICPR.2010.874; Gkioulekas I, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766928; Godbaz J. P., 2012, P COMP IM 10; Gupta M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2735702; Hanrahan P., 1993, Computer Graphics Proceedings, P165, DOI 10.1145/166117.166139; Heide F, 2014, OPT EXPRESS, V22, P26338, DOI 10.1364/OE.22.026338; Heide F, 2014, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2014.418; Heide F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461945; Howell JR, 2015, THERMAL RAD HEAT TRA; Inoshita C, 2014, LECT NOTES COMPUT SC, V8690, P346, DOI 10.1007/978-3-319-10605-2_23; Ito Y, 2000, J BIOMED OPT, V5, P383, DOI 10.1117/1.1287730; Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319; Jimenez D, 2012, PROC CVPR IEEE, P893, DOI 10.1109/CVPR.2012.6247763; Kadambi A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2836164; Kadambi A, 2016, PROC CVPR IEEE, P893, DOI 10.1109/CVPR.2016.103; Kadambi A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508428; Kirmani A, 2013, IEEE INT CON MULTI; Kitano K., 2017, IPSJ T COMPUT VIS AP, V9, P15, DOI [10.1186/s41074-017-0026-3, DOI 10.1186/S41074-017-0026-3]; Lamond B., 2007, P SIGGRAPH SKETCH 20; Lee S, 2015, IMAGE VISION COMPUT, V43, P27, DOI 10.1016/j.imavis.2015.08.001; Maeda T, 2019, IEEE INT CONF COMPUT; Miyazaki D, 2002, J OPT SOC AM A, V19, P687, DOI 10.1364/JOSAA.19.000687; Mukaigawa Y, 2010, PROC CVPR IEEE, P153, DOI 10.1109/CVPR.2010.5540216; Murez Z, 2017, IEEE T PATTERN ANAL, V39, P1880, DOI 10.1109/TPAMI.2016.2613862; Naik N, 2015, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2015.7298602; Naik N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024205; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113; O'Toole M, 2017, PROC CVPR IEEE, P2289, DOI 10.1109/CVPR.2017.246; O'Toole M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766897; O'Toole M, 2014, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2014.421; O'Toole M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601103; O'Toole M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185535; Qiao H, 2015, OPT LETT, V40, P918, DOI 10.1364/OL.40.000918; Ren WH, 2017, IEEE T IMAGE PROCESS, V26, P2327, DOI 10.1109/TIP.2017.2675204; Saponaro P, 2015, PROC CVPR IEEE, P4649, DOI 10.1109/CVPR.2015.7299096; SATO Y, 1994, J OPT SOC AM A, V11, P2990, DOI 10.1364/JOSAA.11.002990; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Shim H, 2016, IEEE T CIRC SYST VID, V26, P841, DOI 10.1109/TCSVT.2015.2397231; Sun B, 2007, IEEE T VIS COMPUT GR, V13, P595, DOI 10.1109/TVCG.2007.1013; Nguyen T, 2014, APPL OPTICS, V53, P7924, DOI 10.1364/AO.53.007924; Tanaka K, 2013, IEEE INT CONF COMPUT; Tanaka K, 2018, PROC CVPR IEEE, P4804, DOI 10.1109/CVPR.2018.00505; Tanaka K, 2017, IEEE T PATTERN ANAL, V39, P746, DOI 10.1109/TPAMI.2016.2631625; Tanaka K, 2016, PROC CVPR IEEE, P4387, DOI 10.1109/CVPR.2016.475; Thompson AC, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.3.035004; Treibitz T, 2012, LECT NOTES COMPUT SC, V7578, P292, DOI 10.1007/978-3-642-33786-4_22; Treibitz T, 2009, IEEE T PATTERN ANAL, V31, P385, DOI 10.1109/TPAMI.2008.85; Ngo TT, 2015, PROC CVPR IEEE, P2310, DOI 10.1109/CVPR.2015.7298844; Tsai CY, 2017, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2017.251; UNSWORTH J, 1979, AM J PHYS, V47, P981, DOI 10.1119/1.11601; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu D, 2014, INT J COMPUT VISION, V107, P123, DOI 10.1007/s11263-013-0668-2	61	0	0	2	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2075	2085		10.1109/TPAMI.2019.2959304	http://dx.doi.org/10.1109/TPAMI.2019.2959304			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	31869777	Bronze			2022-12-18	WOS:000649590200018
J	Zhang, L; Shi, ZL; Cheng, MM; Liu, Y; Bian, JW; Zhou, JT; Zheng, GY; Zeng, Z				Zhang, Le; Shi, Zenglin; Cheng, Ming-Ming; Liu, Yun; Bian, Jia-Wang; Zhou, Joey Tianyi; Zheng, Guoyan; Zeng, Zeng			Nonlinear regression via deep negative correlation learning (vol 43, pg 982, 2021)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction									[Zhang, Le; Zhou, Joey Tianyi; Zeng, Zeng] ASTAR, Singapore 138632, Singapore; [Shi, Zenglin] Univ Amsterdam, NL-1012 Amsterdam, Netherlands; [Cheng, Ming-Ming; Liu, Yun] Nankai Univ, TKLNDST, Coll Comp Sci, Nankai 300071, Peoples R China; [Bian, Jia-Wang] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Zheng, Guoyan] Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai 200240, Peoples R China	Agency for Science Technology & Research (A*STAR); University of Amsterdam; Nankai University; University of Adelaide; Shanghai Jiao Tong University	Cheng, MM (corresponding author), Nankai Univ, TKLNDST, Coll Comp Sci, Nankai 300071, Peoples R China.	lzhang027@ntu.edu.sg; iezlshi@gmail.com; cmm@nankai.edu.cn; nk12csly@mail.nankai.edu.cn; jiawang.bian@gmail.com; joey.tianyi.zhou@gmail.com; guoyan.zheng@ieee.org; zengz@i2r.a-star.edu.sg	; Zheng, Guoyan/M-3617-2018; Cheng, Ming-Ming/A-2527-2009	Liu, Yun/0000-0001-6143-0264; Zhou, Joey Tianyi/0000-0002-4675-7055; Zheng, Guoyan/0000-0003-4173-0379; Cheng, Ming-Ming/0000-0001-5550-8758				Zhang L, 2021, IEEE T PATTERN ANAL, V43, P982, DOI 10.1109/TPAMI.2019.2943860	1	0	0	6	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2172	2172		10.1109/TPAMI.2021.3071929	http://dx.doi.org/10.1109/TPAMI.2021.3071929			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	33974540	Bronze			2022-12-18	WOS:000649590200028
J	Yang, W; Zhang, YL; Ye, JW; Ji, Y; Li, Z; Zhou, MY; Yu, JY				Yang, Wei; Zhang, Yingliang; Ye, Jinwei; Ji, Yu; Li, Zhong; Zhou, Mingyuan; Yu, Jingyi			Structure From Motion on XSlit Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Geometry; Distortion; Bundle adjustment; Feature extraction; Reliability; Multi-perspective imaging; generalized structure from motion; camera motion estimation; feature matching; bundle adjustment	3D RECONSTRUCTION; STEREO; GEOMETRY	We present a structure-from-motion (SfM) framework based on a special type of multi-perspective camera called the cross-slit or XSlit camera. Traditional perspective camera based SfM suffers from the scale ambiguity which is inherent to the pinhole camera geometry. In contrast, an XSlit camera captures rays passing through two oblique lines in 3D space and we show such ray geometry directly resolves the scale ambiguity when employed for SfM. To accommodate the XSlit cameras, we develop tailored feature matching, camera pose estimation, triangulation, and bundle adjustment techniques. Specifically, we devise a SIFT feature variant using non-uniform Gaussian kernels to handle the distortions in XSlit images for reliable feature matching. Moreover, we demonstrate that the XSlit camera exhibits ambiguities in pose estimation process which can not be handled by existing work. Consequently, we propose a 14 point algorithm to properly handle the XSlit degeneracy and estimate the relative pose between XSlit cameras from feature correspondences. We further exploit the unique depth-dependent aspect ratio (DDAR) property to improve the bundle adjustment for the XSlit camera. Synthetic and real experiments demonstrate that the proposed XSlit SfM can conduct reliable and high fidelity 3D reconstruction at an absolute scale.	[Yang, Wei; Zhang, Yingliang; Ji, Yu; Li, Zhong; Zhou, Mingyuan] DGene Prev Plex VR, 3500 Thomas RD, Santa Clara, CA 95054 USA; [Ye, Jinwei] Louisiana State Univ, Div Comp Sci & Engn, Baton Rouge, LA 70803 USA; [Yu, Jingyi] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China	Louisiana State University System; Louisiana State University; ShanghaiTech University	Ye, JW (corresponding author), Louisiana State Univ, Div Comp Sci & Engn, Baton Rouge, LA 70803 USA.; Yu, JY (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.	wyangcs@udel.edu; zhangyl@shanghaitech.edu.cn; jye@csc.lsu.edu; yuji@udel.edu; lizhong@udel.edu; mzhou@udel.edu; yujingyi@shanghaitech.edu.cn		Zhang, Yingliang/0000-0002-0594-7549; Zhou, Mingyuan/0000-0001-6722-1623; Ye, Jinwei/0000-0001-7780-7943	National Key Research and Development Program [2018YFB2100500]; NSFC [61976138, 61977047]; STCSM [2015F0203-000-06]; SHMEC [2019-01-07-00-01-E00003]	National Key Research and Development Program; NSFC(National Natural Science Foundation of China (NSFC)); STCSM(Science & Technology Commission of Shanghai Municipality (STCSM)); SHMEC	This work was supported by the National Key Research and Development Program (2018YFB2100500), the programs of NSFC (61976138 and 61977047), STCSM (2015F0203-000-06), and SHMEC (2019-01-07-00-01-E00003).	Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293; Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16; Astrom K., 2005, P MWORKSH OM VIS; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Clipp B, 2008, IEEE WORK APP COMP, P125; Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403; Ding YY, 2007, LECT NOTES COMPUT SC, V4843, P95; Dong JM, 2015, PROC CVPR IEEE, P5097, DOI 10.1109/CVPR.2015.7299145; Feldman D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P988; Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802; Hartley R., 2003, MULTIPLE VIEW GEOMET; Ji Y., 2015, P COMP OPT SENS K; Kim JS, 2010, J MATH IMAGING VIS, V37, P40, DOI 10.1007/s10851-010-0191-9; Kneip L, 2014, PROC CVPR IEEE, P446, DOI 10.1109/CVPR.2014.64; Kneip L, 2014, IEEE INT CONF ROBOT, P1, DOI 10.1109/ICRA.2014.6906582; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Lhuillier M, 2006, INT C PATT RECOG, P67; Li HF, 2008, CURR MED RES OPIN, V24, P1, DOI [10.1185/030079908X253933, 10.1088/0256-307X/24/3/072]; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Micusik B, 2004, PROC CVPR IEEE, P58; Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9; Moravec H. P, 1980, TECH REP CMU RI T 3; Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730; Nister D, 2006, J FIELD ROBOT, V23, P3, DOI 10.1002/rob.20103; Nister D, 2007, J MATH IMAGING VIS, V27, P67, DOI 10.1007/s10851-006-0450-y; Ovechkin V, 2018, IEEE ROBOT AUTOM LET, V3, P804, DOI 10.1109/LRA.2018.2792141; Pajdla T, 2002, INT J COMPUT VISION, V47, P161, DOI 10.1023/A:1014593824520; Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520; Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4; Ponce J, 2009, PROC CVPR IEEE, P1526, DOI 10.1109/CVPRW.2009.5206668; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Scaramuzza D, 2009, IEEE I CONF COMP VIS, P1413, DOI 10.1109/ICCV.2009.5459294; Schonberger JL, 2017, PROC CVPR IEEE, P6959, DOI 10.1109/CVPR.2017.736; Schweighofer G., 2006, P BRIT MACH VIS C, P147; Seitz SM, 2002, INT J COMPUT VISION, V48, P21, DOI 10.1023/A:1014851111084; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Sturm P, 2005, PROC CVPR IEEE, P206; Swaminathan R, 2003, PROC CVPR IEEE, P594; Szeliski R, 1997, IEEE T PATTERN ANAL, V19, P506, DOI 10.1109/34.589211; Trager M, 2017, P IEEE C COMP VIS PA, P1935; Yang W, 2015, IEEE I CONF COMP VIS, P3424, DOI 10.1109/ICCV.2015.391; Ye JW, 2013, IEEE I CONF COMP VIS, P489, DOI 10.1109/ICCV.2013.452; Ye JW, 2014, VISUAL COMPUT, V30, P93, DOI 10.1007/s00371-013-0786-4; Yu JY, 2005, PROC CVPR IEEE, P117; Yu JY, 2004, LECT NOTES COMPUT SC, V3022, P14; Zomet A, 2003, IEEE T PATTERN ANAL, V25, P741, DOI 10.1109/TPAMI.2003.1201823	49	0	0	4	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1691	1704		10.1109/TPAMI.2019.2957119	http://dx.doi.org/10.1109/TPAMI.2019.2957119			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31796390				2022-12-18	WOS:000637533800015
J	Dalens, T; Aubry, M; Sivic, J				Dalens, Theophile; Aubry, Mathieu; Sivic, Josef			Bilinear Image Translation for Temporal Analysis of Photo Collections	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Automobiles; Vocabulary; Task analysis; Training; Computer architecture; Image representation; Generative models; generative adversarial networks (GANs); bilinear models; convolutional networks		We propose an approach for analyzing unpaired visual data annotated with time stamps by generating how images would have looked like if they were from different times. To isolate and transfer time dependent appearance variations, we introduce a new trainable bilinear factor separation module. We analyze its relation to classical factored representations [1] and concatenation-based auto-encoders [2] . We demonstrate this new module has clear advantages compared to standard concatenation when used in a bottleneck encoder-decoder convolutional neural network architecture. We also show that it can be inserted in a recent adversarial image translation architecture [3] , enabling the image transformation to multiple different target time periods using a single network. We apply our model to a challenging collection of more than 13,000 cars manufactured between 1920 and 2000 [4] and a dataset of high school yearbook portraits from 1930 to 2009 [5] . This allows us, for a given new input image, to generate a "history-lapse video" revealing changes over time by simply varying the target year. We show that by analyzing the generated history-lapse videos we can identify object deformations across time, extracting interesting changes in visual style over decades.	[Dalens, Theophile; Aubry, Mathieu] PSL Res Univ, Dept Informat ENS, CNRS, Ecole Normale Super, F-75005 Paris, France; [Dalens, Theophile] Czech Tech Univ, Czech Inst Informat Robot & Cybernet, Prague, Czech Republic; [Sivic, Josef] Univ Paris Est, LIGM UMR 8049, CNRS, ENPC,ESIEE Paris,UPEM, F-77455 Marne La Vallee, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Universite Paris Cite; Czech Technical University Prague; Centre National de la Recherche Scientifique (CNRS); Ecole des Ponts ParisTech; Universite Gustave-Eiffel	Dalens, T (corresponding author), PSL Res Univ, Dept Informat ENS, CNRS, Ecole Normale Super, F-75005 Paris, France.	theophile.dalens@inria.fr; mathieu.aubry@imagine.enpc.fr; josef.sivic@inria.fr		Aubry, Mathieu/0000-0002-3804-0193	European Research Council (ERC) [336845]; Agence Nationale de la Recherche [ANR-13-CORD-0003]; ANR project EnHerit [ANR-17-CE23-0008]; CIFAR Learning in MachinesBrains Program; European Regional Development Fund under the project IMPACT [CZ.02.1.01/0.0/0.0/15_003/0000468]	European Research Council (ERC)(European Research Council (ERC)European Commission); Agence Nationale de la Recherche(French National Research Agency (ANR)); ANR project EnHerit(French National Research Agency (ANR)); CIFAR Learning in MachinesBrains Program; European Regional Development Fund under the project IMPACT	This work has been supported by the European Research Council (ERC Grant LEAP no. 336845), Agence Nationale de la Recherche (Semapolis Project, ANR-13-CORD-0003), ANR project EnHerit ANR-17-CE23-0008, CIFAR Learning in Machines&Brains Program and European Regional Development Fund under the project IMPACT (Reg. No. CZ.02.1.01/0.0/0.0/15_003/0000468).	[Anonymous], 2018, VISUAL ARTS DATA SER; [Anonymous], 2018, PROJECT WEBPAGE; [Anonymous], 2015, ICLR WORKSH; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Collobert R., 2011, NIPS; Crowley EJ, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.39; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Denton Emily L, 2015, NEURIPS, V2, P4; Doersch C., 2012, P ACM SIGGRAPH; Doersch Carl, 2013, NIPS; Dosovitskiy A, 2017, IEEE T PATTERN ANAL, V39, P692, DOI 10.1109/TPAMI.2016.2567384; Dosovitskiy Alexey, 2016, NEURIPS; Fukui Akira, 2016, ARXIV160601847; GINOSAR S, 2017, IEEE T COMPUT IMAG, P1; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Grauman K., 2006, P IEEE INT C COMP VI, V1, p19 ; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton, 2008, ADV NEURAL INFORM PR, P1121; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Isola P., 2017, IMAGE TO IMAGE TRANS, P1125; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124; Karlinsky L, 2009, PROC CVPR IEEE, P1263, DOI 10.1109/CVPRW.2009.5206499; Kingma D.P, P 3 INT C LEARNING R; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulkarni TD, 2015, ADV NEUR IN, V28; Kulkarni TD, 2015, PROC CVPR IEEE, P4390, DOI 10.1109/CVPR.2015.7299068; Le Roux N, 2011, NEURAL COMPUT, V23, P593, DOI 10.1162/NECO_a_00086; Lee H, 2009, P 26 ANN INT C MACH, V26, P609, DOI [10.1145/1553374.1553453, DOI 10.1145/1553374.1553453]; Lee S, 2015, PERSPECT CONTEMP KOR, P1; Lee YJ, 2013, IEEE I CONF COMP VIS, P1857, DOI 10.1109/ICCV.2013.233; Lee YJ, 2011, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2011.5995523; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Marcus DS, 2010, J COGNITIVE NEUROSCI, V22, P2677, DOI 10.1162/jocn.2009.21407; Martin-Brualla R, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766903; Matzen K., 2014, ECCV 2014, V7, P615; Matzen K, 2015, IEEE I CONF COMP VIS, P1931, DOI 10.1109/ICCV.2015.224; Michel JB, 2011, SCIENCE, V331, P176, DOI 10.1126/science.1199644; Palermo F, 2012, LECT NOTES COMPUT SC, V7577, P499; Radford A., 2016, P INT C MACH LEARN; Reed S, 2014, PR MACH LEARN RES, V32, P1431; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Roy D, 2006, LECT NOTES ARTIF INT, V4211, P192; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; Salakhutdinov R., 2008, ARTIF INTELL, P448; Salimans T, 2016, ADV NEUR IN, V29; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; Shen X., 2019, ARXIV190810254; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Sivic J, 2004, PROC CVPR IEEE, P488; Tang A, 2018, CAN ASSOC RADIOL J, V69, P120, DOI 10.1016/j.carj.2018.02.002; Tang Yichuan, 2013, INT C MACH LEARN, P163; Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; Todorovic S., 2006, COMPUTER VISION PATT, P927; TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586; Van Gool, 2008, P INT C CONT BAS IM, P47, DOI DOI 10.1145/1386352.1386363; Vasilescu M.A.O., 2002, P EUR C COMP VIS, P447; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Vittayakorn S, 2017, IEEE WINT CONF APPL, P715, DOI 10.1109/WACV.2017.85; Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20; Yan XC, 2016, LECT NOTES COMPUT SC, V9908, P776, DOI 10.1007/978-3-319-46493-0_47; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40; Zhou YP, 2016, LECT NOTES COMPUT SC, V9912, P262, DOI 10.1007/978-3-319-46484-8_16; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36	71	0	0	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1197	1212		10.1109/TPAMI.2019.2950317	http://dx.doi.org/10.1109/TPAMI.2019.2950317			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31675318	Green Published			2022-12-18	WOS:000626525300007
J	Dickinson, S				Dickinson, Sven			State of the Journal Editorial	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Dickinson, Sven] Univ Toronto, Samsung Toronto AI Res, Toronto, ON, Canada	University of Toronto	Dickinson, S (corresponding author), Univ Toronto, Samsung Toronto AI Res, Toronto, ON, Canada.	sven@cs.toronto.edu							0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1119	1128		10.1109/TPAMI.2020.3047719	http://dx.doi.org/10.1109/TPAMI.2020.3047719			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ		Bronze			2022-12-18	WOS:000626525300001
J	Fu, C; Wang, CX; Cai, D				Fu, Cong; Wang, Changxu; Cai, Deng			High Dimensional Similarity Search With Satellite System Graph: Efficiency, Scalability, and Unindexed Query Compatibility	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Indexing; Complexity theory; Nearest neighbor methods; Satellites; Quantization (signal); Databases; Time complexity; Nearest neighbors; similarity search; high dimension; large-scale database	NEAREST-NEIGHBOR SEARCH; PRODUCT QUANTIZATION; SMALL WORLD; ALGORITHMS; TREES	Approximate nearest neighbor search (ANNS) in high-dimensional space is essential in database and information retrieval. Recently, there has been a surge of interest in exploring efficient graph-based indices for the ANNS problem. Among them, navigating spreading-out graph (NSG) provides fine theoretical analysis and achieves state-of-the-art performance. However, we find there are several limitations with NSG: 1) NSG has no theoretical guarantee on nearest neighbor search when the query is not indexed in the database; and 2) NSG is too sparse which harms the search performance. In addition, NSG suffers from high indexing complexity. To address above problems, we propose the satellite system graphs (SSG) and a practical variant NSSG. Specifically, we propose a novel pruning strategy to produce SSGs from the complete graph. SSGs define a new family of MSNETs in which the out-edges of each node are distributed evenly in all directions. Each node in the graph builds effective connections to its neighborhood omnidirectionally, whereupon we derive SSG's excellent theoretical properties for both indexed and unindexed queries. We can adaptively adjust the sparsity of an SSG with a hyper-parameter to optimize the search performance. Further, NSSG is proposed to reduce the indexing complexity of the SSG for large-scale applications. Both theoretical and extensive experimental analysis are provided to demonstrate the strengths of the proposed approach over the existing representative algorithms. Our code has been released at https://github.com/ZJULearning/SSG.	[Fu, Cong; Wang, Changxu; Cai, Deng] Zhejiang Univ, State Key Lab Comp Aided Design CAD & Comp Graph, Hangzhou 310027, Peoples R China; [Fu, Cong; Wang, Changxu] Alibaba Grp, Beijing 100102, Peoples R China	Zhejiang University; Alibaba Group	Fu, C (corresponding author), Zhejiang Univ, State Key Lab Comp Aided Design CAD & Comp Graph, Hangzhou 310027, Peoples R China.	fucong.fc@alibaba-inc.com; changxu.wcx@alibaba-inc.com; dengcai@gmail.com			National Key Research and Development Program of China [2018AAA0101400]; National Nature Science Foundation of China [62036009, 61936006]; Alibaba-Zhejiang University Joint Institute of Frontier Technologies	National Key Research and Development Program of China; National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Alibaba-Zhejiang University Joint Institute of Frontier Technologies	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0101400, in part by the National Nature Science Foundation of China under Grants 62036009 and 61936006, and in part by the Alibaba-Zhejiang University Joint Institute of Frontier Technologies.	Arora A, 2018, PROC VLDB ENDOW, V11, P906, DOI 10.14778/3204028.3204034; ARYA S, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P271; Aumuller M, 2017, LECT NOTES COMPUT SC, V10609, P34, DOI 10.1007/978-3-319-68474-1_3; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Boguna M, 2009, NAT PHYS, V5, P74, DOI 10.1038/NPHYS1130; Chen L., 2005, P 2005 ACM SIGMOD IN, P491, DOI DOI 10.1145/1066157.1066213; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Dearholt D., 1988, P 22 AS C SIGN SYST, V2, P548; Dong Wei, 2011, P 20 INT C WORLD WID, P577, DOI DOI 10.1145/1963405.1963487; Ferhatosmanoglu H, 2001, PROC INT CONF DATA, P503, DOI 10.1109/ICDE.2001.914864; Fu AW, 2000, VLDB J, V9, P154, DOI 10.1007/PL00010672; Fu C., 2016, ABS160907228 CORR; Fu C., 2019, ARXIV 190706146; Fu C, 2019, PROC VLDB ENDOW, V12, P461, DOI 10.14778/3303753.3303754; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240; Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Hajebi K., 2011, PROC INT JOINT C ART, P1312, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-222; Harwood B, 2016, PROC CVPR IEEE, P5713, DOI 10.1109/CVPR.2016.616; Huang Q, 2015, PROC VLDB ENDOW, V9, P1; Jagadish HV, 2005, ACM T DATABASE SYST, V30, P364, DOI 10.1145/1071610.1071612; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jin ZM, 2014, IEEE T CYBERNETICS, V44, P2167, DOI 10.1109/TCYB.2014.2302018; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Kleinberg JM, 2000, NATURE, V406, P845, DOI 10.1038/35022643; LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785; Li W, 2020, IEEE T KNOWL DATA EN, V32, P1475, DOI 10.1109/TKDE.2019.2909204; Liu T., 2007, P 8 IEEE WORKSH APPL, P28, DOI 10.1109/WACV.2007.18; Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P907, DOI 10.1109/TIP.2015.2505180; Malkov YA, 2020, IEEE T PATTERN ANAL, V42, P824, DOI 10.1109/TPAMI.2018.2889473; Malkov Y, 2014, INFORM SYST, V45, P61, DOI 10.1016/j.is.2013.10.006; Shimomura LC, 2021, INFORM SYST, V95, DOI 10.1016/j.is.2020.101507; Silpa-Anan C, 2008, PROC CVPR IEEE, P2308; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194; Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824; Zhang T., 2014, PR MACH LEARN RES, P838; Zheng YX, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2023, DOI 10.1145/2882903.2882930	42	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 23	2021	44	8					4139	4150		10.1109/TPAMI.2021.3067706	http://dx.doi.org/10.1109/TPAMI.2021.3067706			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HS	33755554	Green Submitted			2022-12-18	WOS:000820522200002
J	Zhu, Z; Huang, TT; Xu, MD; Shi, BG; Cheng, WQ; Bai, X				Zhu, Zhen; Huang, Tengteng; Xu, Mengde; Shi, Baoguang; Cheng, Wenqing; Bai, Xiang			Progressive and Aligned Pose Attention Transfer for Person Image Generation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Generators; Image synthesis; Manifolds; Gallium nitride; Three-dimensional displays; Shape; Generative adversarial network; person image generation; pose attention; progressive		This paper proposes a new generative adversarial network for pose transfer, i.e., transferring the pose of a given person to a target pose. We design a progressive generator which comprises a sequence of transfer blocks. Each block performs an intermediate transfer step by modeling the relationship between the condition and the target poses with attention mechanism. Two types of blocks are introduced, namely pose-attentional transfer block (PATB) and aligned pose-attentional transfer block (APATB). Compared with previous works, our model generates more photorealistic person images that retain better appearance consistency and shape consistency compared with input images. We verify the efficacy of the model on the Market-1501 and DeepFashion datasets, using quantitative and qualitative measures. Furthermore, we show that our method can be used for data augmentation for the person re-identification task, alleviating the issue of data insufficiency. Code and pretrained models are available at: https://github.com/tengteng95/Pose-Transfer.git.	[Zhu, Zhen] Univ Illinois, Dept Comp Sci, Champaign, IL 61801 USA; [Huang, Tengteng; Xu, Mengde; Cheng, Wenqing] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Peoples R China; [Shi, Baoguang] Microsoft, Redmond, WA 98052 USA; [Bai, Xiang] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China	University of Illinois System; University of Illinois Urbana-Champaign; Huazhong University of Science & Technology; Microsoft; Huazhong University of Science & Technology	Bai, X (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.	zhenzhu4@illinois.edu; huangtengtng@hust.edu.cn; mdxu@hust.edu.cn; shibaoguang@gmail.com; chengwq@hust.edu.cn; xbai@hust.edu.cn			National Natural Science Foundation of China [61733007]; National Program for Support of Top-notch Young Professionals; Program for HUST Academic Frontier Youth Team [2017QYTD08]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Program for Support of Top-notch Young Professionals; Program for HUST Academic Frontier Youth Team	This work was supported in part by the National Natural Science Foundation of China, under Grant 61733007 and in part by the National Program for Support of Top-notch Young Professionals. The work of Xiang Bai was supported by the Program for HUST Academic Frontier Youth Team under Grant 2017QYTD08. Zhen Zhu and Tengteng Huang contributed equally to this work.	Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Balakrishnan G, 2018, PROC CVPR IEEE, P8340, DOI 10.1109/CVPR.2018.00870; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603; Dong H., 2018, ADV NEURAL INFORM PR, P474; Dong H, 2019, IEEE I CONF COMP VIS, P9025, DOI 10.1109/ICCV.2019.00912; Elgammal A, 2004, PROC CVPR IEEE, P681; Esser P, 2018, PROC CVPR IEEE, P8857, DOI 10.1109/CVPR.2018.00923; Gafni O., 2020, PROC INT C LEARN REP; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Grigorev A, 2019, PROC CVPR IEEE, P12127, DOI 10.1109/CVPR.2019.01241; Guler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762; Han XT, 2019, IEEE I CONF COMP VIS, P10470, DOI 10.1109/ICCV.2019.01057; Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787; Hao Tang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P717, DOI 10.1007/978-3-030-58595-2_43; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton GE, 2012, IMPROVING NEURAL NET, DOI DOI 10.9774/GLEAF.978-1-909493-38-4_2; Huang TT, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-019-9935-6; Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kingma D.P., 2015, INT C LEARN REPR ICL; Kingma D.P., 2014, P 2 INT C LEARN REPR, DOI DOI 10.1093/BIOINFORMATICS/BTAA169; Lassner C, 2017, IEEE I CONF COMP VIS, P853, DOI 10.1109/ICCV.2017.98; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lempitsky V., 2016, ARXIV160708022V3; Li YN, 2019, PROC CVPR IEEE, P3688, DOI 10.1109/CVPR.2019.00381; Liu JW, 2019, PROC CVPR IEEE, P7195, DOI 10.1109/CVPR.2019.00737; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Ma L., 2018, ARXIV 180511145; Ma LQ, 2018, PROC CVPR IEEE, P99, DOI 10.1109/CVPR.2018.00018; Ma Liqian, 2017, P NEUR INF PROC SYST, P405; Maas A.L., 2013, P ICML, V30, P3, DOI DOI 10.1016/0010-0277(84)90022-2; Mei L, 2011, IEEE I CONF COMP VIS, P967, DOI 10.1109/ICCV.2011.6126340; Mirza M., 2014, ARXIV; Neverova N., 2018, ARXIV 180901995; Odena A, 2017, PR MACH LEARN RES, V70; Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244; Pumarola A, 2018, PROC CVPR IEEE, P8620, DOI 10.1109/CVPR.2018.00899; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Raj A, 2018, LECT NOTES COMPUT SC, V11216, P679, DOI 10.1007/978-3-030-01258-8_41; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Salimans T, 2016, ADV NEUR IN, V29; Siarohin A, 2019, ADV NEUR IN, V32; Siarohin A, 2019, PROC CVPR IEEE, P2372, DOI 10.1109/CVPR.2019.00248; Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359; Simonyan K., 2014, 3 INT C LEARN REPR I; Song SJ, 2019, PROC CVPR IEEE, P2352, DOI 10.1109/CVPR.2019.00246; Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Walker J, 2017, IEEE I CONF COMP VIS, P3352, DOI 10.1109/ICCV.2017.361; Wang BC, 2018, LECT NOTES COMPUT SC, V11217, P607, DOI 10.1007/978-3-030-01261-8_36; Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372; Wang TC, 2019, ADV NEUR IN, V32; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wang TC, 2018, ADV NEUR IN, V31; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wu J., 2019, BRIT MACH VIS C; Wu ZH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P293, DOI 10.1145/3343031.3351083; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yu J., 2018, ARXIV 180603589; Zanfir M, 2018, PROC CVPR IEEE, P5391, DOI 10.1109/CVPR.2018.00565; Zhang H, 2019, PR MACH LEARN RES, V97; Zhao B, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P383, DOI 10.1145/3240508.3240536; Zheng L., 2016, ARXIV161002984V1; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068; Zhu Z, 2019, PROC CVPR IEEE, P2342, DOI 10.1109/CVPR.2019.00245	71	0	0	10	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 23	2021	44	8					4306	4320		10.1109/TPAMI.2021.3068236	http://dx.doi.org/10.1109/TPAMI.2021.3068236			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HS	33755557	Green Submitted			2022-12-18	WOS:000820522200003
J	Geng, QCA; Zhang, H; Lu, FX; Huang, XY; Wang, S; Zhou, Z; Yang, RG				Geng, Qichuan; Zhang, Hong; Lu, Feixiang; Huang, Xinyu; Wang, Sen; Zhou, Zhong; Yang, Ruigang			Part-Level Car Parsing and Reconstruction in Single Street View Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Automobiles; Three-dimensional displays; Shape; Image reconstruction; Two dimensional displays; Semantics; Annotations; Car parsing and reconstruction; part segmentation; pose and shape estimation; part-level car dataset	3D OBJECT DETECTION; RECOGNITION; VISION	Part information has been proven to be resistant to occlusions and viewpoint changes, which are main difficulties in car parsing and reconstruction. However, in the absence of datasets and approaches incorporating car parts, there are limited works that benefit from it. In this paper, we propose the first part-aware approach for joint part-level car parsing and reconstruction in single street view images. Without labor-intensive part annotations on real images, our approach simultaneously estimates pose, shape, and semantic parts of cars. There are two contributions in this paper. First, our network introduces dense part information to facilitate pose and shape estimation, which is further optimized with a novel 3D loss. To obtain part information in real images, a class-consistent method is introduced to implicitly transfer part knowledge from synthesized images. Second, we construct the first high-quality dataset containing 348 car models with physical dimensions and part annotations. Given these models, 60K synthesized images with randomized configurations are generated. Experimental results demonstrate that part knowledge can be effectively transferred with our class-consistent method, which significantly improves part segmentation performance on real street views. By fusing dense part information, our pose and shape estimation results achieve the state-of-the-art performance on the ApolloCar3D and outperform previous approaches by large margins in terms of both A3DP-Abs and A3DP-Rel.	[Geng, Qichuan; Zhou, Zhong] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China; [Zhang, Hong] SenseTime Grp Ltd, Beijing 100080, Peoples R China; [Lu, Feixiang; Huang, Xinyu] Natl Engn Lab Deep Learning Technol & Applicat, Beijing 100193, Peoples R China; [Wang, Sen] Univ Alberta, Edmonton, AB T6G 2X7, Canada; [Yang, Ruigang] Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA	Beihang University; University of Alberta; University of Kentucky	Zhou, Z (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.	zhaokefirst@buaa.edu.cn; fykalviny@gmail.com; lufeixiang@baidu.com; huangxinyu01@baidu.com; wangsen1312@gmail.com; zz@buaa.edu.cn; ryang2@iiky.edu		Wang, Sen/0000-0002-1808-5239	National Key Research and Development Program of China [2018YFB2100601]; National Natural Science Foundation of China (NSFC) [61872023]	National Key Research and Development Program of China; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work was supported by the National Key Research and Development Program of China under Grant No.2018YFB2100601, and National Natural Science Foundation of China (NSFC) under Grant 61872023. The work of Qichuan Geng was partially done when he was an intern at Baidu Research, Beijing 100193, China. The work of Hong Zhang and Ruigang Yang was done at Baidu Research, Beijing 100193, China.	Asvadi A, 2017, IEEE INT C INTELL TR; Bertozzi M, 2000, ROBOT AUTON SYST, V32, P1, DOI 10.1016/S0921-8890(99)00125-6; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198; Chang Angel X., 2015, ARXIV151203012CSGR P; Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI [10.1109/ICCV.2015.104, 10.1109/ICCV.2015.312]; Chen L, 2014, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2014.135; Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685; Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236; Chen XZ, 2015, ADV NEUR IN, V28; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Crafgun M., 2020, SIMULATION LIMITS DR; Duan LY, 2019, IEEE MULTIMEDIA, V26, P8, DOI 10.1109/MMUL.2018.2873564; Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47; Gupta S, 2015, PROC CVPR IEEE, P4731, DOI 10.1109/CVPR.2015.7299105; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132; Huang XY, 2018, IEEE COMPUT SOC CONF, P1067, DOI 10.1109/CVPRW.2018.00141; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Kalayeh MM, 2017, PROC CVPR IEEE, P4227, DOI 10.1109/CVPR.2017.450; Kundu A, 2018, PROC CVPR IEEE, P3559, DOI 10.1109/CVPR.2018.00375; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Li B, 2017, IEEE INT C INT ROBOT, P1513; Liang XD, 2016, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2016.347; Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179; Liu LJ, 2019, PROC CVPR IEEE, P1057, DOI 10.1109/CVPR.2019.00115; Liu S., 2017, ARXIV 170801936; Liu X., 2014, PASCAL SEMANTIC PART; Long MS, 2015, PR MACH LEARN RES, V37, P97; Manhardt F, 2019, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2019.00217; Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100; Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597; Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139; Pillai S, 2019, IEEE INT CONF ROBOT, P9250, DOI 10.1109/ICRA.2019.8793621; Poirson P, 2016, INT CONF 3D VISION, P676, DOI 10.1109/3DV.2016.78; Richter SR, 2017, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2017.243; Roddick T., 2019, P BRIT MACH VIS C; Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352; Smith BM, 2013, PROC CVPR IEEE, P3484, DOI 10.1109/CVPR.2013.447; Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94; Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41; Song XB, 2019, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2019.00560; Song YF, 2017, IEEE I CONF COMP VIS, P580, DOI 10.1109/ICCV.2017.70; Sorkine Olga, 2007, P EUROGRAPHICS ACM S, V4, P109, DOI 10.1145/1281991.1282006; Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308; Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531; Thomas A, 2007, IEEE I CONF COMP VIS, P23; Tickoo S., 2020, AUTODESK 3DS MAX 202; Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143; Tzeng E., 2014, ARXIV PREPRINT ARXIV; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492; Wang P, 2015, IEEE I CONF COMP VIS, P1573, DOI 10.1109/ICCV.2015.184; Wang Y., 2018, PROC EUR C COMPUT VI; Xiang Y., 2017, ROB SCI SYST 14; Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023; Zeng YM, 2018, IEEE ROBOT AUTOM LET, V3, P3434, DOI 10.1109/LRA.2018.2852843; Zhou XW, 2017, IEEE T PATTERN ANAL, V39, P1648, DOI 10.1109/TPAMI.2016.2605097; Zhu ML, 2015, IEEE I CONF COMP VIS, P927, DOI 10.1109/ICCV.2015.112	70	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 9	2021	44	8					4291	4305		10.1109/TPAMI.2021.3064837	http://dx.doi.org/10.1109/TPAMI.2021.3064837			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HO	33687835				2022-12-18	WOS:000820521800004
J	Wang, XJ; Zhang, R; Sun, Y; Qi, JZ				Wang, Xiaojie; Zhang, Rui; Sun, Yu; Qi, Jianzhong			Adversarial Distillation for Learning with Privileged Provisions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Task analysis; Generators; Gallium nitride; Computational modeling; Games; Lakes; Adversarial distillation; generative adversarial network; knowledge distillation; privileged information		Knowledge distillation aims to train a student (model) for accurate inference in a resource-constrained environment. Traditionally, the student is trained by a high-capacity teacher (model) whose training is resource-intensive. The student trained this way is suboptimal because it is difficult to learn the real data distribution from the teacher. To address this issue, we propose to train the student against a discriminator in a minimax game. Such a minimax game has an issue that it can take an excessively long time for the training to converge. To address this issue, we propose adversarial distillation consisting of a student, a teacher, and a discriminator. The discriminator is now a multi-class classifier that distinguishes among the real data, the student, and the teacher. The student and the teacher aim to fool the discriminator via adversarial losses, while they learn from each other via distillation losses. By optimizing the adversarial and the distillation losses simultaneously, the student and the teacher can learn the real data distribution. To accelerate the training, we propose to obtain low-variance gradient updates from the discriminator using a Gumbel-Softmax trick. We conduct extensive experiments to demonstrate the superiority of the proposed adversarial distillation under both accuracy and training speed.	[Wang, Xiaojie; Zhang, Rui; Qi, Jianzhong] Univ Melbourne, Parkville, Vic 3010, Australia; [Sun, Yu] Twitter Inc, San Francisco, CA 94103 USA	University of Melbourne; Twitter, Inc.	Wang, XJ (corresponding author), Univ Melbourne, Parkville, Vic 3010, Australia.	xiaojiew1@student.unimelb.edu.au; rui.zhang@unimelb.edu.au; ysun@twitter.com; jianzhong.qi@unimelb.edu.au	QI, JIANZHONG/P-7112-2015	QI, JIANZHONG/0000-0001-6501-9050	Australian Research Council [FT120100832, DP180102050]	Australian Research Council(Australian Research Council)	This work is supported by Australian Research Council Future Fellowship Project FT120100832 and Discovery Project DP180102050.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Arjovsky M., 2017, P INT C LEARN REPR; Bottou L., 2017, ARXIV170107875STATML; Bottou L, 2018, SIAM REV, V60, P223, DOI 10.1137/16M1080173; Bucilua Cristian, 2006, P 12 ACM SIGKDD INT, P535, DOI [10.1145/1150402.1150464, DOI 10.1145/1150402.1150464]; Chen L, 2012, IEEE T MULTIMEDIA, V14, P1057, DOI 10.1109/TMM.2012.2187435; Chen X, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3281659; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Feizi S., 2017, ARXIV PREPRINT ARXIV; Gan Zhe, 2017, ADV NEURAL INFORM PR, P5247; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266; Hinton G., 2014, P INT C NEUR INF PRO; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Howard A.G., 2017, ARXIV170404861; Huang J., 2017, ARXIV170900513; Huszar Ferenc, 2015, ABS151105101 CORR; Jang E., 2017, INT C LEARN REPR; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Lan X, 2018, ADV NEUR IN, V31; Lapin M, 2018, IEEE T PATTERN ANAL, V40, P1533, DOI 10.1109/TPAMI.2017.2751607; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li C., 2017, ADV NEURAL INFORM PR, V30, P4088; Li X., 2013, P 21 ACM INT C MULT, P485; Maddison C. J., 2017, P INT C REPR; Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6; Mikolov T, 2013, P 26 INT C NEURAL IN, P3111; Passos A., 2018, P INT C LEARN REPR; Pu Y., 2018, P INT C MACH LEARN, P4151; Rumelhart D.E., 1985, LEARNING INTERNAL RE; Salimans T., 2016, ADV NEUR IN, P2234; Sau BB, 2016, ARXIV PREPRINT ARXIV; Sch_olkopf B., 2016, P INT C LEARN REPR; Simonyan K, 2015, 3 INT C LEARN REPR I; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Tucker G., 2017, ADV NEURAL INFORM PR, P2624; Vapnik V, 2015, J MACH LEARN RES, V16, P2023; Wang J, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P515, DOI 10.1145/3077136.3080786; Wang R. J., 2018, NIPS, P1967; Wang X., 2018, PAKDD, P597, DOI DOI 10.1007/978-3-319-93040-447; Wang XJ, 2018, IEEE T KNOWL DATA EN, V30, P156, DOI 10.1109/TKDE.2017.2729559; Wang XJ, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415, DOI 10.1145/2911451.2911497; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Yu LT, 2017, AAAI CONF ARTIF INTE, P2852; Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39; Zhang Y., 2016, P NEURIPS WORKSH ADV; Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454; Zhang YZ, 2017, PR MACH LEARN RES, V70	52	0	0	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					786	797		10.1109/TPAMI.2019.2942592	http://dx.doi.org/10.1109/TPAMI.2019.2942592			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31545712				2022-12-18	WOS:000616309900003
J	Zhang, YQ; Lau, Y; Kuo, HW; Cheung, S; Pasupathy, A; Wright, J				Zhang, Yuqian; Lau, Yenson; Kuo, Han-Wen; Cheung, Sky; Pasupathy, Abhay; Wright, John			On the Global Geometry of Sphere-Constrained Sparse Blind Deconvolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image deblurring; blind deconvolution; nonconvex optimization	IMAGE	Blind deconvolution is the problem of recovering a convolutional kernel a(0) and an activation signal x(0) from their convolution y = a(0)circle star x(0). This problem is ill-posed without further constraints or priors. This paper studies the situation where the nonzero entries in the activation signal are sparsely and randomly populated. We normalize the convolution kernel to have unit Frobenius norm and cast the sparse blind deconvolution problem as a nonconvex optimization problem over the sphere. With this spherical constraint, every spurious local minimum turns out to be close to some signed shift truncation of the ground truth, under certain hypotheses. This benign property motivates an effective two stage algorithm that recovers the ground truth from the partial information offered by a suboptimal local minimum. This geometry-inspired algorithm recovers the ground truth for certain microscopy problems, also exhibits promising performance in the more challenging image deblurring problem. Our insights into the global geometry and the two stage algorithm extend to the convolutional dictionary learning problem, where a superposition of multiple convolution signals is observed.	[Zhang, Yuqian] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; [Lau, Yenson; Kuo, Han-Wen; Wright, John] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA; [Lau, Yenson; Kuo, Han-Wen; Wright, John] Columbia Univ, Data Sci Inst, New York, NY 10027 USA; [Cheung, Sky; Pasupathy, Abhay] Columbia Univ, Dept Phys, New York, NY 10027 USA	Cornell University; Columbia University; Columbia University; Columbia University	Zhang, YQ (corresponding author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.	yz2557@cornell.edu; yl3027@columbia.edu; hk2673@columbia.edu; cheung@phys.columbia.edu; apn2108@columbia.edu; jw2966@columbia.edu		Zhang, Yuqian/0000-0001-6080-9125; Kuo, Han-Wen/0000-0003-2989-5218	US National Science Foundation [IIS 1546411]	US National Science Foundation(National Science Foundation (NSF))	The authors gratefully acknowledge support from US National Science Foundation 1343282, US National Science Foundation CCF 1527809, and US National Science Foundation IIS 1546411.	Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; [Anonymous], 2011, P ADV NEURAL PROCESS; Benichoux A, 2013, INT CONF ACOUST SPEE, P6108, DOI 10.1109/ICASSP.2013.6638838; Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187; Chi YJ, 2016, IEEE J-STSP, V10, P782, DOI 10.1109/JSTSP.2016.2543462; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Gong D, 2016, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2016.202; Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521; Krishnan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531402; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; Kuo H.-W., 2019, P INT C MACH LEARN, P3570; Levin A, 2011, IEEE T PATTERN ANAL, V33, P2354, DOI 10.1109/TPAMI.2011.148; Lewicki MS, 1998, NETWORK-COMP NEURAL, V9, pR53, DOI 10.1088/0954-898X/9/4/001; Li XD, 2019, APPL COMPUT HARMON A, V47, P893, DOI 10.1016/j.acha.2018.01.001; Liu GC, 2014, IEEE T IMAGE PROCESS, V23, P5047, DOI 10.1109/TIP.2014.2362055; Mairal J, 2012, FOUND TRENDS COMPUT, V8, DOI 10.1561/0600000058; Pasupathy A., 2018, ARXIV PREPRINT ARXIV; Perrone D, 2014, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2014.372; Spielman D. A., 2012, P 25 ANN C LEARN THE; Sun LB, 2013, IEEE INT CONF COMPUT; Wipf D, 2014, J MACH LEARN RES, V15, P3595; Wright J., 2017, IEEE T INFORM THEORY, V63; Xiao L, 2016, LECT NOTES COMPUT SC, V9907, P734, DOI 10.1007/978-3-319-46487-9_45; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Zhang HC, 2013, PROC CVPR IEEE, P1051, DOI 10.1109/CVPR.2013.140; Zhang Y., 2018, P 32 INT C NEUR INF, P2328	29	0	0	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					999	1008		10.1109/TPAMI.2019.2939237	http://dx.doi.org/10.1109/TPAMI.2019.2939237			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31494544	Green Submitted			2022-12-18	WOS:000616309900017
J	Lu, J; Li, L; Zhang, CS				Lu, Jiang; Li, Lei; Zhang, Changshui			Self-Reinforcing Unsupervised Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Task analysis; Heuristic algorithms; Dynamic programming; Manuals; Tensors; Pattern analysis; Continual learning; self-learning system; unsupervised learning; image matching; dynamic programming	DEEP NEURAL-NETWORKS	Remarkable gains in deep learning usually benefit from large-scale supervised data. Ensuring the intra-class modality diversity in training set is critical for generalization capability of cutting-edge deep models, but it burdens human with heavy manual labor on data collection and annotation. In addition, some rare or unexpected modalities are new for the current model, causing reduced performance under such emerging modalities. Inspired by the achievements in speech recognition, psychology and behavioristics, we present a practical solution, self-reinforcing unsupervised matching (SUM), to annotate the images with 2D structure-preserving property in an emerging modality by cross-modality matching. Specifically, we propose a dynamic programming algorithm, dynamic position warping (DPW), to reveal the underlying element correspondence relationship between two matrix-form data in an order-preserving fashion, and devise a local feature adapter (LoFA) to allow for cross-modality similarity measurement. On these bases, we develop a two-tier self-reinforcing learning mechanism on both feature level and image level to optimize the LoFA. The proposed SUM framework requires no any supervision in emerging modality and only one template in seen modality, providing a promising route towards incremental learning and continual learning. Extensive experimental evaluation on two proposed challenging one-template visual matching tasks demonstrate its efficiency and superiority.	[Lu, Jiang; Li, Lei; Zhang, Changshui] Tsinghua Univ THUAI, Inst Artificial Intelligence, Beijing 100084, Peoples R China; [Lu, Jiang; Li, Lei; Zhang, Changshui] Tsinghua Univ, State Key Lab Intelligence Technol & Syst, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Dept Automat, Beijing 100084, Peoples R China	Tsinghua University	Lu, J; Zhang, CS (corresponding author), Tsinghua Univ THUAI, Inst Artificial Intelligence, Beijing 100084, Peoples R China.	lu-j13@mail.tsinghua.edu.cn; lilei17@mails.tsinghua.edu.cn; zcs@mail.tsinghua.edu.cn	于, 于增臣/AAH-4657-2021		Natural Science Fundation of China (NSFC); NSFC [62061136001/DFG TRR-169]; Beijing Academy of Artificial Intelligence (BAAI); German Research Foundation (DFG) in Project Crossmodal Learning	Natural Science Fundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); NSFC(National Natural Science Foundation of China (NSFC)); Beijing Academy of Artificial Intelligence (BAAI); German Research Foundation (DFG) in Project Crossmodal Learning(German Research Foundation (DFG))	This work was supported in part by the Natural Science Fundation of China (NSFC) and the German Research Foundation (DFG) in Project Crossmodal Learning, NSFC 62061136001/DFG TRR-169, and in part by the Beijing Academy of Artificial Intelligence (BAAI).	Aknin LB, 2012, J HAPPINESS STUD, V13, P347, DOI 10.1007/s10902-011-9267-5; Anderson J.F., 2005, RISK INSURANCE; [Anonymous], 2017, OPTIMIZATION MODEL F; BANDURA A, 1974, AM PSYCHOL, V29, P859, DOI 10.1037/h0037514; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Bilmes Jeff A, 1998, TECHNICAL REPORT, DOI DOI 10.1080/0042098032000136147; Bishop, 1995, NEURAL NETWORKS PATT; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Chen Z, 2018, SYNTHESIS LECT ARTIF, V12, P1, DOI [10.2200/S00737ED1V01Y201610AIM033, DOI 10.2200/S00737ED1V01Y201610AIM033]; Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Donahue J, 2013, PROC CVPR IEEE, P668, DOI 10.1109/CVPR.2013.92; Dozat T., 2016, INCORPORATING NESTER; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476; Feldman LB, 1999, J MEM LANG, V40, P559, DOI 10.1006/jmla.1998.2629; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Finn C, 2017, PR MACH LEARN RES, V70; Gebru T, 2017, P NATL ACAD SCI USA, V114, P13108, DOI 10.1073/pnas.1700035114; Ghosal S, 2018, P NATL ACAD SCI USA, V115, P4613, DOI 10.1073/pnas.1716999115; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jiang L., 2014, P INT C NEUR INF PRO, P2078; Koch G., 2015, ICML DEEP LEARNING W; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kumar A., 2010, ADV NEURAL INFORM PR, V23, P478; Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lehmann E.L., 2006, THEORY POINT ESTIMAT; Li BH, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P96, DOI 10.1109/DAS.2014.33; Li C., 2016, ADV NEURAL INFORM PR, P4188; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975; Munkhdalai T, 2017, PR MACH LEARN RES, V70; Nair V., 2010, ICML, P807; Norouzzadeh MS, 2018, P NATL ACAD SCI USA, V115, pE5716, DOI 10.1073/pnas.1719367115; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; RESCORLA RA, 1977, J EXP PSYCHOL ANIM B, V3, P203, DOI 10.1037/0097-7403.3.3.203; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900; Shrivastava A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024188; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Simonyan K., 2014, 3 INT C LEARN REPR I; Snell J., 2017, ADV NEURAL INFORM PR, P4077; Stallkamp J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1453, DOI 10.1109/IJCNN.2011.6033395; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Tzeng Eric, 2014, ABS14123474 CORR; Vinyals O., 2016, ADV NEURAL INFORM PR, P3637, DOI [10.48550/arXiv.1606.04080, DOI 10.5555/3157382.3157504]; Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wundt W., 1912, LECT HUMAN ANIMAL PS; Xing E. P., 2003, ADV NEURAL INF PROCE, P521; Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547; Zhang XY, 2013, IEEE T PATTERN ANAL, V35, P1773, DOI 10.1109/TPAMI.2012.239; Zhang XY, 2011, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2011.5995661	63	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 24	2021	44	8					4404	4418		10.1109/TPAMI.2021.3061945	http://dx.doi.org/10.1109/TPAMI.2021.3061945			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HY	33625977	Green Submitted			2022-12-18	WOS:000820522800002
J	Gong, C; Wang, QZ; Liu, TL; Han, B; You, JE; Yang, J; Tao, DC				Gong, Chen; Wang, Qizhou; Liu, Tongliang; Han, Bo; You, Jane; Yang, Jian; Tao, Dacheng			Instance-Dependent Positive and Unlabeled Learning With Labeling Bias Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Instance-dependent PU learning; labeling bias; maximum likelihood estimation; solution uniqueness; generalization bound	EXISTENCE	This paper studies instance-dependent Positive and Unlabeled (PU) classification, where whether a positive example will be labeled (indicated by s) is not only related to the class label y, but also depends on the observation x. Therefore, the labeling probability on positive examples is not uniform as previous works assumed, but is biased to some simple or critical data points. To depict the above dependency relationship, a graphical model is built in this paper which further leads to a maximization problem on the induced likelihood function regarding P(s, y vertical bar x). By utilizing the well-known EM and Adam optimization techniques, the labeling probability of any positive example P(s = 1 vertical bar y = 1, x) as well as the classifier induced by P(y vertical bar x) can be acquired. Theoretically, we prove that the critical solution always exists, and is locally unique for linear model if some sufficient conditions are met. Moreover, we upper bound the generalization error for both linear logistic and non-linear network instantiations of our algorithm, with the convergence rate of expected risk to empirical risk as O(1/root k+1/root n-k+1/root n) (k and n are the sizes of positive set and the entire training set, respectively). Empirically, we compare our method with state-of-the-art instance-independent and instance-dependent PU algorithms on a wide range of synthetic, benchmark and real-world datasets, and the experimental results firmly demonstrate the advantage of the proposed method over the existing PU approaches.	[Gong, Chen] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Key Lab Intelligent Percept & Syst High Dimens In, Minist Educ,PCA Lab, Nanjing 210094, Peoples R China; [Gong, Chen; You, Jane] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China; [Wang, Qizhou; Han, Bo] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China; [Liu, Tongliang] Univ Sydney, Trustworthy Machine Learning Lab, Darlington, NSW 2008, Australia; [Yang, Jian] Nanjing Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, PCA Lab, Nanjing 210094, Peoples R China; [Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China; [Tao, Dacheng] JD Explore Acad, JD Com, Beijing 101111, Peoples R China	Nanjing University of Science & Technology; Hong Kong Polytechnic University; Hong Kong Baptist University; University of Sydney; Nanjing University of Science & Technology; Nanjing University of Science & Technology	You, JE (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.; Yang, J (corresponding author), Nanjing Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, PCA Lab, Nanjing 210094, Peoples R China.; Yang, J (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.	chen.gong@njust.edu.cn; qizhouwang.nanjing@gmail.com; tongliang.liu@sydney.edu.au; bhanml@comp.hkbu.edu.hk; jane.you@polyu.edu.hk; csjyang@njust.edu.cn; dacheng.tao@jd.com			National Science Foundation (NSF) of China [61973162, U1713208, 62006202]; Fundamental Research Funds for the Central Universities [30920032202]; CCF-Tencent Open Fund [RAGR20200101]; "Young Elite Scientists Sponsorship Program" by CAST [2018QNRC001]; Hong Kong Scholars Program [XJ2019036]; 111 Program [B13022]; RGC Early Career Scheme [22200720]; HKBU CSD Departmental Incentive Grant; Hong Kong Polytechnic University [YZ3K, UAJP/UAGK, ZVRH]; ARC [DE190101473]	National Science Foundation (NSF) of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); CCF-Tencent Open Fund; "Young Elite Scientists Sponsorship Program" by CAST; Hong Kong Scholars Program; 111 Program(Ministry of Education, China - 111 Project); RGC Early Career Scheme; HKBU CSD Departmental Incentive Grant; Hong Kong Polytechnic University(Hong Kong Polytechnic University); ARC(Australian Research Council)	This work was supported by National Science Foundation (NSF) of China under Grants 61973162, U1713208, and 62006202, the Fundamental Research Funds for the Central Universities under Grant: 30920032202, CCF-Tencent Open Fund under Grant RAGR20200101, the "Young Elite Scientists Sponsorship Program" by CAST under Grant 2018QNRC001, Hong Kong Scholars Program under Grant XJ2019036, "111 Program" under Grant B13022, the RGC Early Career Scheme under Grant 22200720, HKBU CSD Departmental Incentive Grant, the Hong Kong Polytechnic University grants (Nos: YZ3K, UAJP/UAGK, and ZVRH), and the ARC (No: DE190101473).	Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Bekker J., 2019, PROC JOINT EUR C MAC, P1; Bekker J, 2020, MACH LEARN, V109, P719, DOI 10.1007/s10994-020-05877-5; Bekker J, 2018, AAAI CONF ARTIF INTE, P2712; Bing L, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P179, DOI 10.1109/icdm.2003.1250918; Bogdan K, 2000, STATISTICS, V34, P137, DOI 10.1080/02331880008802323; Chen JY, 2020, PUBLIC MANAG REV, V22, P1674, DOI 10.1080/14719037.2019.1645874; du Plessis MC, 2014, ADV NEUR IN, V27; du Plessis MC, 2015, PR MACH LEARN RES, V37, P1386; Elkan Charles, 2008, P 14 ACM SIGKDD INT, P213, DOI DOI 10.1145/1401890.1401920; Gao W, 2016, AAAI CONF ARTIF INTE, P1575; Golowich N., 2018, PROC C LEARN THEORY, P297; Gong C, 2022, IEEE T PATTERN ANAL, V44, P2841, DOI 10.1109/TPAMI.2020.3044997; Gong C, 2020, IEEE T CIRC SYST VID, V30, P1396, DOI 10.1109/TCSVT.2019.2903563; Gong C, 2021, IEEE T PATTERN ANAL, V43, P918, DOI 10.1109/TPAMI.2019.2941684; Gong C, 2019, IEEE T NEUR NET LEAR, V30, P3471, DOI 10.1109/TNNLS.2019.2892403; Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2261, DOI 10.1109/TNNLS.2014.2376936; He F, 2018, ARXIV 180802180; Hou M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2255; Hsieh Y.-G, 2019, PROC INT C MACH LEAR, P1; Jacob G., PROC INT C LEARN REP, P1; Jain S, 2016, PROC INT C NEURAL IN, P2693; Kato Masahiro, 2019, ICLR; Kingma D.P, P 3 INT C LEARNING R; Kiryo R, 2017, ADV NEUR IN, V30; Lee Wee Sun, 2003, ICML, P448, DOI DOI 10.1016/J.TCS.2005.09.007; Li G, 2013, SURVEY POSTIVE UNLAB; Li T, 2019, IEEE COMPUT SOC CONF, P56, DOI 10.1109/CVPRW.2019.00013; Li WK, 2011, IEEE T GEOSCI REMOTE, V49, P717, DOI 10.1109/TGRS.2010.2058578; Li Xiaoli, 2003, IJCAI 03 P 18 INT JO, P587; Li XL, 2005, LECT NOTES ARTIF INT, V3720, P218, DOI 10.1007/11564096_24; Liu Bing, 2002, ICML, P387; MAKELAINEN T, 1981, ANN STAT, V9, P758, DOI 10.1214/aos/1176345516; Menon AK, 2018, MACH LEARN, V107, P1561, DOI 10.1007/s10994-018-5715-3; Menon AK, 2015, PR MACH LEARN RES, V37, P125; Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240; Plessis du, 2015, P 7 AS C MACH LEARN, P221; Ramaswamy HG, 2016, PR MACH LEARN RES, V48; Rocchio J., 1971, SMART RETRIEVAL SYST, P313; Sansone E, 2019, IEEE T PATTERN ANAL, V41, P2584, DOI 10.1109/TPAMI.2018.2860995; Scott C, 2015, JMLR WORKSH CONF PRO, V38, P838; Settles B., 2009, ACTIVE LEARNING LIT; Shi H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2689; Wang G., 2018, 32 AAAI C ART INT, P3037; Ward G, 2009, BIOMETRICS, V65, P554, DOI 10.1111/j.1541-0420.2008.01116.x; Xia Xiaobo, 2019, NEURIPS, P1; Yang P, 2012, BIOINFORMATICS, V28, P2640, DOI 10.1093/bioinformatics/bts504; Yu XY, 2018, LECT NOTES COMPUT SC, V11205, P69, DOI 10.1007/978-3-030-01246-5_5; Zhang C, 2020, PEER PEER NETW APPL, V13, P16, DOI [10.1007/s12083-018-0715-4, 10.1109/IRMMW-THz.2019.8874219]; Zhang JQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P854, DOI 10.1145/3123266.3123304; Zhang JQ, 2019, IEEE T MULTIMEDIA, V21, P1332, DOI 10.1109/TMM.2018.2871421; Zhou F., 2019, PROC INT C NEURAL IN, P7013	53	0	0	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 23	2021	44	8					4163	4177		10.1109/TPAMI.2021.3061456	http://dx.doi.org/10.1109/TPAMI.2021.3061456			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HN	33621169				2022-12-18	WOS:000820521700002
J	Cha, G; Lee, M; Cho, J; Oh, S				Cha, Geonho; Lee, Minsik; Cho, Jungchan; Oh, Songhwai			Reconstruct as Far as You Can: Consensus of Non-Rigid Reconstruction from Feasible Regions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Trajectory; Strain; Benchmark testing; Structure from motion; Two dimensional displays; Cameras; Shape; Part-based reconstruction; stochastic stitching; non-rigid structure from motion; structure from motion	PROCRUSTEAN NORMAL-DISTRIBUTION; STRUCTURE-FROM-MOTION; 3D SHAPE; RECOVERY	Much progress has been made for non-rigid structure from motion (NRSfM) during the last two decades, which made it possible to provide reasonable solutions for synthetically-created benchmark data. In order to utilize these NRSfM techniques in more realistic situations, however, we are now facing two important problems that must be solved: First, general scenes contain complex deformations as well as multiple objects, which violates the usual assumptions of previous NRSfM proposals. Second, there are many unreconstructable regions in the video, either because of the discontinued tracks of 2D trajectories or those regions static towards the camera, which require careful manipulations. In this paper, we show that a consensus-based reconstruction framework can handle these issues effectively. Even though the entire scene is complex, its parts usually have simpler deformations, and even though there are some unreconstructable parts, they can be weeded out to reduce their harmful effect on the entire reconstruction. The main difficulty of this approach lies in identifying appropriate parts, however, it can be effectively avoided by sampling parts stochastically and then aggregate their reconstructions afterwards. Experimental results show that the proposed method renews the state-of-the-art for popular benchmark data under much harsher environments, i.e., narrow camera view ranges, and it can reconstruct video-based real-world data effectively for as many areas as it can without an elaborated user input.	[Cha, Geonho; Oh, Songhwai] Seoul Natl Univ, Dept Elect & Comp Engn, ASRI, Seoul, South Korea; [Lee, Minsik] Hanyang Univ, Div Elect Engn, Ansan, South Korea; [Cho, Jungchan] Gachon Univ, Dept Software, Seongnam, South Korea	Seoul National University (SNU); Hanyang University; Gachon University	Lee, M (corresponding author), Hanyang Univ, Div Elect Engn, Ansan, South Korea.	geonho.cha@rllab.snu.ac.kr; mleepaper@hanyang.ac.kr; thinkai@gachon.ac.kr; songhwai@snu.ac.kr	Lee, Minsik/S-7959-2017	Lee, Minsik/0000-0003-4941-4311; Cho, Jungchan/0000-0002-3859-1702; Cha, Geonho/0000-0002-3008-4642	'The Cross-Ministry Giga KOREA Project' grant - Korea government(MSIT) [GK19P0300]; Institute of Information & Communications Technology Planning & Evaluation (IITP) grant - Korea government (MSIT) [2019-0-01190]; Basic Science Research Program through the National Research Foundation of Korea - Ministry of Science and ICT [NRF-2017R1C1B2012277]	'The Cross-Ministry Giga KOREA Project' grant - Korea government(MSIT)(Giga Korea Co.Ministry of Science & ICT (MSIT), Republic of Korea); Institute of Information & Communications Technology Planning & Evaluation (IITP) grant - Korea government (MSIT)(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); Basic Science Research Program through the National Research Foundation of Korea - Ministry of Science and ICT(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea)	This work was supported in part by 'The Cross-Ministry Giga KOREA Project' grant funded by the Korea government(MSIT) (No.GK19P0300, Real-time 4D reconstruction of dynamic objects for ultra-realistic service), in part by Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2019-0-01190, [SW Star Lab] Robot Learning: Efficient, Safe, and Socially-Acceptable Machine Learning), and in part by the Basic Science Research Program through the National Research Foundation of Korea funded by the Ministry of Science and ICT under Grant NRF-2017R1C1B2012277.	Agudo A, 2018, IEEE T PATTERN ANAL, V40, P2137, DOI 10.1109/TPAMI.2017.2752710; Agudo A, 2019, IEEE T PATTERN ANAL, V41, P971, DOI 10.1109/TPAMI.2018.2823717; Agudo A, 2018, COMPUT VIS IMAGE UND, V167, P121, DOI 10.1016/j.cviu.2018.01.002; Agudo A, 2016, IEEE T PATTERN ANAL, V38, P979, DOI 10.1109/TPAMI.2015.2469293; Agudo A, 2015, IEEE I CONF COMP VIS, P756, DOI 10.1109/ICCV.2015.93; Agudo A, 2015, PROC CVPR IEEE, P2179, DOI 10.1109/CVPR.2015.7298830; Agudo A, 2014, PROC CVPR IEEE, P1558, DOI 10.1109/CVPR.2014.202; Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201; Akhter I, 2009, PROC CVPR IEEE, P1534, DOI 10.1109/CVPRW.2009.5206620; Akhter Ijaz, 2008, ADV NEURAL INFORM PR, P41; BAJAJ C, 1988, DISCRETE COMPUT GEOM, V3, P177, DOI 10.1007/BF02187906; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Cha G, 2018, PATTERN RECOGN LETT, V110, P51, DOI 10.1016/j.patrec.2018.03.019; Chhatkuli A, 2016, PROC CVPR IEEE, P1719, DOI 10.1109/CVPR.2016.190; Cho J, 2016, INT J COMPUT VISION, V117, P226, DOI 10.1007/s11263-015-0860-7; Dai YC, 2017, IEEE IMAGE PROC, P4532; Dai YC, 2012, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2012.6247905; Deng HZ, 2016, INT CONF ACOUST SPEE, P1999, DOI 10.1109/ICASSP.2016.7472027; Fayad J, 2011, IEEE I CONF COMP VIS, P431, DOI 10.1109/ICCV.2011.6126272; Fayad J, 2010, LECT NOTES COMPUT SC, V6314, P297, DOI 10.1007/978-3-642-15561-1_22; Fazel M, 2003, P AMER CONTR CONF, P2156, DOI 10.1109/acc.2003.1243393; Fragkiadaki Katerina, 2014, ADV NEURAL INFORM PR, P55; Galasso F, 2013, IEEE I CONF COMP VIS, P3527, DOI 10.1109/ICCV.2013.438; Gall J., 2013, DECISION FORESTCOM; Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168; Gotardo PFU, 2011, IEEE I CONF COMP VIS, P802, DOI 10.1109/ICCV.2011.6126319; Gotardo PFU, 2011, PROC CVPR IEEE, DOI 10.1109/cvpr.2011.5995560; Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333; Higham N. J., 2002, ACCURACY STABILITY N; Horn R.A., 2013, MATRIX ANAL, VSecond; Ji P, 2017, IEEE I CONF COMP VIS, P929, DOI 10.1109/ICCV.2017.106; Kong C, 2016, PROC CVPR IEEE, P4123, DOI 10.1109/CVPR.2016.447; Kumar S, 2018, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2018.00034; Kumar S, 2017, PATTERN RECOGN, V71, P428, DOI 10.1016/j.patcog.2017.05.014; Kumar S, 2016, INT CONF 3D VISION, P148, DOI 10.1109/3DV.2016.23; Lee M, 2017, IEEE T PATTERN ANAL, V39, P1388, DOI 10.1109/TPAMI.2016.2596720; Lee M, 2016, PROC CVPR IEEE, P4670, DOI 10.1109/CVPR.2016.505; Lee M, 2014, PROC CVPR IEEE, P1550, DOI 10.1109/CVPR.2014.201; Lee M, 2013, PROC CVPR IEEE, P1280, DOI 10.1109/CVPR.2013.169; Li X, 2018, PROC CVPR IEEE, P3032, DOI 10.1109/CVPR.2018.00320; Lin Z., 2009, UILUENG092215; na Calvo B, 2014, P BRIT MACH VIS C SE; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Paladini M, 2009, PROC CVPR IEEE, P2890; Parashar S, 2016, PROC CVPR IEEE, P4679, DOI 10.1109/CVPR.2016.506; Park HS, 2015, INT J COMPUT VISION, V115, P115, DOI 10.1007/s11263-015-0804-2; Perriollat M, 2011, INT J COMPUT VISION, V95, P124, DOI 10.1007/s11263-010-0352-8; Russell C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3009, DOI 10.1109/CVPR.2011.5995383; Salzmann M, 2008, PROC CVPR IEEE, P1213; Salzmann M, 2009, PROC CVPR IEEE, P1054, DOI 10.1109/CVPRW.2009.5206759; Simon T, 2017, IEEE T PATTERN ANAL, V39, P2201, DOI 10.1109/TPAMI.2016.2638904; Taylor J, 2010, PROC CVPR IEEE, P2761, DOI 10.1109/CVPR.2010.5540002; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2004, ADV NEUR IN, V16, P1555; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Varol A, 2009, IEEE I CONF COMP VIS, P1811, DOI 10.1109/ICCV.2009.5459403; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9; Zhu YY, 2014, PROC CVPR IEEE, P1542, DOI 10.1109/CVPR.2014.200	65	0	0	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					623	637		10.1109/TPAMI.2019.2931317	http://dx.doi.org/10.1109/TPAMI.2019.2931317			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31369369				2022-12-18	WOS:000607383300016
J	Kobayashi, Y; Morimoto, T; Sato, I; Mukaigawa, Y; Tomono, T; Ikeuchi, K				Kobayashi, Yoshie; Morimoto, Tetsuro; Sato, Imari; Mukaigawa, Yasuhiro; Tomono, Takao; Ikeuchi, Katsushi			Reconstruction of Geometric and Optical Parameters of Non-Planar Objects with Thin Film	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Refractive index; Optical films; Optical refraction; Optical variables control; Optical reflection; Interference; Adaptive optics; Shape and color reconstruction; thin film interference; refractive index; thickness		Here, we propose a novel method to estimate the parameters of non-planar objects with thin film surfaces. Being able to estimate the optical parameters of objects with thin film surfaces has a wide range of applications from industrial inspections to biological and archaeology research. However, there are many challenging issues that need to be overcome to model such parameters. The appearance of thin film objects is highly dependent on the surface orientation and optical parameters such as the refractive index and film thickness. First, we therefore analyzed the optical parameters of non-planar objects with thin film surfaces. Next, we proposed and implemented an analysis procedure and demonstrated its effectiveness for studying planar objects with thin film surfaces. Finally, we developed a device to acquire the shapes and optical parameters of objects with thin film surfaces using a camera and demonstrated the effectiveness of our method experimentally. Then, we surveyed the errors caused by the light source. We discussed the difference between the theoretically obtained parameters and experimental data obtained using a hyper spectral camera.	[Kobayashi, Yoshie; Ikeuchi, Katsushi] Univ Tokyo, Bunkyo Ku, 7-3-1 Hongo, Tokyo, Japan; [Morimoto, Tetsuro; Tomono, Takao] Toppan Printing Co Ltd, Chiyoda Ku, 1 Izumi Machi, Tokyo 1088539, Japan; [Sato, Imari] Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan; [Mukaigawa, Yasuhiro] Nara Inst Sci & Technol, 8916-5 Takayama Machi, Ikoma, Nara 6300192, Japan; [Ikeuchi, Katsushi] Microsoft Res Redmond, Redmond, WA USA	University of Tokyo; Toppan Printing Co Ltd; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan; Nara Institute of Science & Technology; Microsoft	Kobayashi, Y (corresponding author), Univ Tokyo, Bunkyo Ku, 7-3-1 Hongo, Tokyo, Japan.	k.yoshie@fujitsu.com; tetsuro.morimoto@toppan.co.jp; imarik@nii.ac.jp; mukaigawa@is.naist.jp; takao.tomono@ieee.org; katsuike@microsoft.com	Tomono, Takao/K-7438-2016	Tomono, Takao/0000-0003-4984-4063; Kobayashi, Yoshie/0000-0002-4872-3545	Toppan Printing Ltd.	Toppan Printing Ltd.	This work was supported by Toppan Printing Ltd.	Azzam R.M.A., 1977, ELLIPSOMETRY POLARIZ, V1st ed.; Belcour L, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073620; Cuypers T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231820; Hirayama H, 2001, COMPUT GRAPH-UK, V25, P391, DOI 10.1016/S0097-8493(01)00063-2; Hirayama H, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P15, DOI 10.1109/PCCGA.2000.883853; Imura Masataka, 2009, P 16 ACM S VIRT REAL, P95, DOI [10.1145/1643928.1643952, DOI 10.1145/1643928.1643952]; Iwasaki K, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P344, DOI 10.1109/CGI.2004.1309231; Johs B. D., 1999, P SPIE, V10294, P29; Kinoshita S, 2005, CHEMPHYSCHEM, V6, P1442, DOI 10.1002/cphc.200500007; Kinoshita S., 2008, STRUCTURAL COLORS RE; Kitagawa K, 2012, MECATRONICS REM 2012, P94, DOI 10.1109/MECATRONICS.2012.6450993; Kitagawa K, 2013, APPL OPTICS, V52, P1998, DOI 10.1364/AO.52.001998; Kobayashi Y., 2014, P AS C COMP VIS, P492; Kobayashi Y, 2016, PROC CVPR IEEE, P3774, DOI 10.1109/CVPR.2016.410; Meissner KW, 1941, J OPT SOC AM, V31, P405, DOI 10.1364/JOSA.31.000405; NAKATANI S, 1992, JPN J APPL PHYS 2, V31, pL426, DOI 10.1143/JJAP.31.L426; Sadeghi I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077344; Sun YL, 1999, IEEE COMPUT GRAPH, V19, P61, DOI 10.1109/38.773965; Sun YL, 2000, SPRING COMP SCI, P341; Woollam J., 1999, P SPIE INT SOC OPT E, V1, P3; Yoshioka S, 2004, P ROY SOC B-BIOL SCI, V271, P581, DOI 10.1098/rspb.2003.2618; Yoshioka S., 2002, FORMA, V17, P169; Yue YF, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5659	23	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					638	651		10.1109/TPAMI.2019.2937515	http://dx.doi.org/10.1109/TPAMI.2019.2937515			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31449008				2022-12-18	WOS:000607383300017
J	Kocak, MA; Ramirez, D; Erkip, E; Shasha, DE				Kocak, Mustafa A.; Ramirez, David; Erkip, Elza; Shasha, Dennis E.			SafePredict: A Meta-Algorithm for Machine Learning That Uses Refusals to Guarantee Correctness	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Prediction algorithms; Waste materials; Error analysis; Machine learning; Machine learning algorithms; Inference algorithms; Reliability	REJECT-OPTION; CLASSIFICATION; PROBABILITY; CONFIDENCE; ERROR	SafePredict is a novel meta-algorithm that works with any base prediction algorithm for online data to guarantee an arbitrarily chosen correctness rate, 1 - epsilon, by allowing refusals. Allowing refusals means that the meta-algorithm may refuse to emit a prediction produced by the base algorithm so that the error rate on non-refused predictions does not exceed epsilon. The SafePredict error bound does not rely on any assumptions on the data distribution or the base predictor. When the base predictor happens not to exceed the target error rate epsilon, SafePredict refuses only a finite number of times. When the error rate of the base predictor changes through time SafePredict makes use of a weight-shifting heuristic that adapts to these changes without knowing when the changes occur yet still maintains the correctness guarantee. Empirical results show that (i) SafePredict compares favorably with state-of-the-art confidence-based refusal mechanisms which fail to offer robust error guarantees; and (ii) combining SafePredict with such refusal mechanisms can in many cases further reduce the number of refusals. Our software is included in the supplementary material, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TPAMI.2019.2932415.	[Kocak, Mustafa A.] Broad Inst Harvard & MIT, Cambridge, MA 02142 USA; [Ramirez, David; Erkip, Elza] NYU, Dept Elect & Comp Engn, Tandon Sch Engn, Brooklyn, NY 11201 USA; [Shasha, Dennis E.] NYU, Courant Inst Math Sci, New York, NY 10012 USA	Harvard University; Massachusetts Institute of Technology (MIT); Broad Institute; New York University; New York University Tandon School of Engineering; New York University	Kocak, MA (corresponding author), Broad Inst Harvard & MIT, Cambridge, MA 02142 USA.	mkocak@broadinstitute.org; dar550@nyu.edu; elza@nyu.edu; shasha@courant.nyu.edu		Erkip, Elza/0000-0001-8718-8648	NYU Seed Grant; NYU WIRELESS; United States National Science Foundation [CNS-1302336, MCB-1158273, IOS-1339362, MCB-1412232]	NYU Seed Grant; NYU WIRELESS; United States National Science Foundation(National Science Foundation (NSF))	Work supported in part by NYU Seed Grant, NYU WIRELESS, and the United States National Science Foundation grantsCNS-1302336, MCB-1158273, IOS-1339362, and MCB-1412232. This support is greatly appreciated. We would also like to thank the editor and the reviewers for their suggestions and criticisms.	Adamskiy Dmitry, 2012, Algorithmic Learning Theory. 23rd International Conference (ALT 2012). Proceedings, P290, DOI 10.1007/978-3-642-34106-9_24; Bartlett PL, 2008, J MACH LEARN RES, V9, P1823; Campi MC, 2010, MACH LEARN, V80, P63, DOI 10.1007/s10994-010-5183-x; Cesa-Bianchi N, 2007, MACH LEARN, V66, P321, DOI 10.1007/s10994-006-5001-7; Cesa-Bianchi Nicolo, 2006, PREDICTION LEARNING, DOI DOI 10.1017/CBO9780511546921; Chen JM, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3056, DOI 10.1109/ICMLC.2008.4620932; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Cortes C., 2013, P INT C ALGO LEARN T, P67; Cortes C, 2016, LECT NOTES ARTIF INT, V9925, P67, DOI 10.1007/978-3-319-46379-7_5; de Rooij S, 2014, J MACH LEARN RES, V15, P1281; De Stefano C, 2000, IEEE T SYST MAN CY C, V30, P84, DOI 10.1109/5326.827457; Denis C., 2015, ARXIV PREPRINT ARXIV; Dua S, 2014, MACHINE LEARNING HEA; El-Yaniv R, 2010, J MACH LEARN RES, V11, P1605; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Fumera G, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P582, DOI 10.1109/ICIAP.2003.1234113; Golfarelli M, 1997, IEEE T PATTERN ANAL, V19, P786, DOI 10.1109/34.598237; Han B, 2015, IEEE SPECTRUM, V52, P46, DOI 10.1109/MSPEC.2015.7274195; Hanczar B, 2008, BIOINFORMATICS, V24, P1889, DOI 10.1093/bioinformatics/btn349; Harbert T, 2013, IEEE SPECTRUM, V50, P30, DOI 10.1109/MSPEC.2013.6655836; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; Herbei R, 2006, CAN J STAT, V34, P709, DOI 10.1002/cjs.5550340410; Herbster M, 1998, MACH LEARN, V32, P151, DOI 10.1023/A:1007424614876; Kalai AT, 2012, J COMPUT SYST SCI, V78, P1481, DOI 10.1016/j.jcss.2011.12.026; Kocak M. A., 2016, CONJUGATE CONFORMAL, P347; Krickeberg K., 1965, PROBABILITY THEORY; Landgrebe TCW, 2006, PATTERN RECOGN LETT, V27, P908, DOI 10.1016/j.patrec.2005.10.015; LeCun Y, 2010, ATT LAB; Lei J, 2014, BIOMETRIKA, V101, P755, DOI 10.1093/biomet/asu038; Li M, 2006, PATTERN RECOGN, V39, P1230, DOI 10.1016/j.patcog.2006.01.010; Lichman M., 2013, UCI MACHINE LEARNING; LITTLESTONE N, 1989, ANN IEEE SYMP FOUND, P256, DOI 10.1109/SFCS.1989.63487; Maas A., 2011, P 49 ANN M ASS COMPU, P142; Mikolov T, 2016, CORR; Mohri M., 2018, FDN MACHINE LEARNING; Sayedi Amin, 2010, ADV NEURAL INFORM PR, P2092; Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392; Siegel E, 2013, PREDICTIVE ANAL; Simonite T., 2017, MIT TECHNOL REV; TUKEY JW, 1986, AM STAT, V40, P72, DOI 10.2307/2683137; Vovk V., 2005, ALGORITHMIC LEARNING, DOI DOI 10.1007/B106715; Vovk V. G., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory, P371; Wiener Y., 2013, THESIS ISRAEL INS TE; Wiener Y., 2011, ADV NEURAL INFORM PR, V24, P1665; Yuan M, 2010, J MACH LEARN RES, V11, P111; Zhang B, 2013, IEEE INTEL TRANSP SY, V5, P8, DOI 10.1109/MITS.2013.2245725; Zhang C., 2016, COLT, P1584; Zhang C, 2018, J AM STAT ASSOC, V113, P730, DOI 10.1080/01621459.2017.1282372	48	0	0	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					663	678		10.1109/TPAMI.2019.2932415	http://dx.doi.org/10.1109/TPAMI.2019.2932415			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31380747	Green Submitted			2022-12-18	WOS:000607383300019
J	Qiu, JY; Wang, XC; Fua, P; Tao, DC				Qiu, Jiayan; Wang, Xinchao; Fua, Pascal; Tao, Dacheng			Matching Seqlets: An Unsupervised Approach for Locality Preserving Sequence Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hidden Markov models; Task analysis; Annotations; Pattern matching; Speech recognition; Optimization; Coherence; Sequence matching; unsupervised methods; temporal clustering; joint optimization	ACTION RECOGNITION; TIME; TRAJECTORIES	In this paper, we propose a novel unsupervised approach for sequence matching by explicitly accounting for the locality properties in the sequences. In contrast to conventional approaches that rely on frame-to-frame matching, we conduct matching using sequencelet or seqlet, a sub-sequence wherein the frames share strong similarities and are thus grouped together. The optimal seqlets and matching between them are learned jointly, without any supervision from users. The learned seqlets preserve the locality information at the scale of interest and resolve the ambiguities during matching, which are omitted by frame-based matching methods. We show that our proposed approach outperforms the state-of-the-art ones on datasets of different domains including human actions, facial expressions, speech, and character strokes.	[Qiu, Jiayan; Tao, Dacheng] Univ Sydney, UBTECH Sydney Artificial Intelligence Ctr, Camperdown, NSW 2006, Australia; [Qiu, Jiayan; Tao, Dacheng] Univ Sydney, Sch Comp Sci, Fac Engn & Informat Technol, Camperdown, NSW 2006, Australia; [Wang, Xinchao] Stevens Inst Technol, Dept Comp Sci, Hoboken, NJ 07030 USA; [Fua, Pascal] Ecole Polytech Fed Lausanne, Sch Comp & Commun Sci, CH-1015 Lausanne, Switzerland	University of Sydney; University of Sydney; Stevens Institute of Technology; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Wang, XC (corresponding author), Stevens Inst Technol, Dept Comp Sci, Hoboken, NJ 07030 USA.	jqiu3225@uni.sydney.edu.au; xinchao.wang@stevens.edu; pascal.fua@epfl.ch; dacheng.tao@sydney.edu.au		Qiu, Jiayan/0000-0002-1807-6666; Wang, Xinchao/0000-0003-0057-1404	Australian Research Council [FL-170100117]; Stevens Institute of Technology	Australian Research Council(Australian Research Council); Stevens Institute of Technology	This work is in part supported by the Australian Research Council Project FL-170100117, and the Stevens Institute of Technology Startup Funding.	Al-Naymat G., 2009, AUSTRALASIAN DATA MI, V101, P117, DOI DOI 10.1007/s10115-004-0154-9; Anirudh R, 2016, INT J COMPUT VISION, V116, P161, DOI 10.1007/s11263-015-0835-8; Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257; Bergroth L, 2000, SPIRE 2000: SEVENTH INTERNATIONAL SYMPOSIUM ON STRING PROCESSING AND INFORMATION RETRIEVAL - PROCEEDINGS, P39, DOI 10.1109/SPIRE.2000.878178; Brendel W, 2011, IEEE I CONF COMP VIS, P778, DOI 10.1109/ICCV.2011.6126316; Cheron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368; CUTURI M., 2013, P INT C ADV NEURAL I, V26; Dogan P, 2018, PROC CVPR IEEE, P8749, DOI 10.1109/CVPR.2018.00912; Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646; Gudmundsson S, 2008, IEEE IJCNN, P2772, DOI 10.1109/IJCNN.2008.4634188; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jiang H, 2006, P IEEE COMP SOC C CO, V2, P1646; Jiang H, 2007, IEEE T PATTERN ANAL, V29, P959, DOI 10.1109/TPAMI.2007.1048; Jung H. -J., 2014, P 12 AS C COMP VIS A, P226; Kulkarni K, 2015, INT J COMPUT VISION, V112, P90, DOI 10.1007/s11263-014-0758-9; Lajugie R., 2014, ADV NEURAL INFORM PR, P1817; Li K, 2012, LECT NOTES COMPUT SC, V7572, P286, DOI 10.1007/978-3-642-33718-5_21; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Lichman M, 2013, UCI MACHINE LEARNING; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Marteau PF, 2009, IEEE T PATTERN ANAL, V31, P306, DOI 10.1109/TPAMI.2008.76; Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365; Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279; Petitjean F, 2014, IEEE DATA MINING, P470, DOI 10.1109/ICDM.2014.27; Ratanamahatana CA, 2004, SIAM PROC S, P11; Rodriguez-Serrano JA, 2012, IEEE T PATTERN ANAL, V34, P2108, DOI 10.1109/TPAMI.2012.25; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508; Si ZZ, 2011, IEEE I CONF COMP VIS, P41, DOI 10.1109/ICCV.2011.6126223; Silva D.F., 2016, P SIAM INT C DAT MIN, DOI 10.1137/1.9781611974348.94; Simonyan K, 2014, ADV NEUR IN, V27; Su B, 2017, PROC CVPR IEEE, P2906, DOI 10.1109/CVPR.2017.310; Su B, 2017, IEEE T IMAGE PROCESS, V26, P5784, DOI 10.1109/TIP.2017.2745212; Su B, 2018, IEEE T PATTERN ANAL, V40, P77, DOI 10.1109/TPAMI.2017.2665545; Su B, 2017, IEEE T IMAGE PROCESS, V26, P3579, DOI 10.1109/TIP.2017.2704438; Su B, 2013, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2013.115; Su JY, 2014, ANN APPL STAT, V8, P530, DOI 10.1214/13-AOAS701; Villani C, 2009, GRUNDLEHR MATH WISS, V338, P5; Vlachos M, 2006, VLDB J, V15, P1, DOI 10.1007/s00778-004-0144-2; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang J, 2013, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2013.334; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059; Yao BP, 2010, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2010.5540234; Zhou F., 2009, ADV NEURAL INFORM PR, V22, P2286; Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812	48	0	0	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					745	752		10.1109/TPAMI.2019.2934052	http://dx.doi.org/10.1109/TPAMI.2019.2934052			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31425018	Green Submitted			2022-12-18	WOS:000607383300024
J	Yu, JY; Ramamoorthi, R				Yu, Jiyang; Ramamoorthi, Ravi			Selfie Video Stabilization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Three-dimensional displays; Two dimensional displays; Solid modeling; Tracking; Cameras; Video stabilization; face modeling		We propose a novel algorithm for stabilizing selfie videos. Our goal is to automatically generate stabilized video that has optimal smooth motion in the sense of both foreground and background. The key insight is that non-rigid foreground motion in selfie videos can be analyzed using a 3D face model, and background motion can be analyzed using optical flow. We use second derivative of temporal trajectory of selected pixels as the measure of smoothness. Our algorithm stabilizes selfie videos by minimizing the smoothness measure of the background, regularized by the motion of the foreground. Experiments show that our method outperforms state-of-the-art general video stabilization techniques in selfie videos.	[Yu, Jiyang] Univ Calif San Diego, Dept Elect & Comp Engn, 5500 Gilman Dr, La Jolla, CA 92093 USA; [Ramamoorthi, Ravi] Univ Calif San Diego, Dept Comp Sci & Engn, 5500 Gilman Dr,MC 0404, La Jolla, CA 92093 USA	University of California System; University of California San Diego; University of California System; University of California San Diego	Yu, JY (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, 5500 Gilman Dr, La Jolla, CA 92093 USA.	jiy173@eng.ucsd.edu; ravir@cs.ucsd.edu			Sony; Ronald L. Graham endowed Chair; UC San Diego Center for Visual Computing	Sony; Ronald L. Graham endowed Chair; UC San Diego Center for Visual Computing	We thank Nima Khademi Kalantari for the supplementary video voice over. This work was supported in part by Sony, the Ronald L. Graham endowed Chair, and the UC San Diego Center for Visual Computing.	Bai JM, 2014, COMPUT GRAPH FORUM, V33, P61, DOI 10.1111/cgf.12413; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712; Buehler C, 2001, PROC CVPR IEEE, P609; Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116; Cao C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766943; Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Fried O, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925933; Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493; Gleicher ML, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1404880.1404882; Goldstein A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231824; Grundmann M, 2011, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2011.5995525; Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974; Kroeger T, 2016, LECT NOTES COMPUT SC, V9908, P471, DOI 10.1007/978-3-319-46493-0_29; Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408; Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350; Liu SC, 2014, PROC CVPR IEEE, P4209, DOI 10.1109/CVPR.2014.536; Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995; Liu SC, 2012, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2012.6247662; Shi FH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661290; Smith BM, 2009, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2009.5459270; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang YS, 2013, IEEE T VIS COMPUT GR, V19, P1354, DOI 10.1109/TVCG.2013.11; Yu JY, 2018, LECT NOTES COMPUT SC, V11209, P569, DOI 10.1007/978-3-030-01228-1_34	27	0	0	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					701	711		10.1109/TPAMI.2019.2931897	http://dx.doi.org/10.1109/TPAMI.2019.2931897			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31380744				2022-12-18	WOS:000607383300021
J	Perez-Rua, JM; Miksik, O; Crivelli, T; Bouthemy, P; Torr, PHS; Perez, P				Perez-Rua, Juan-Manuel; Miksik, Ondrej; Crivelli, Tomas; Bouthemy, Patrick; Torr, Philip H. S.; Perez, Patrick			ROAM: A Rich Object Appearance Model with Application to Rotoscoping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Adaptation models; Tools; Shape; Task analysis; Pipelines; Labeling; Deformable models; Rotoscoping; trimaps; video segmentation; video alpha-matting; probabilistic graphical models; dynamic programming	VIDEO; TRACKING; IMAGE	Rotoscoping, the detailed delineation of scene elements through a video shot, is a painstaking task of tremendous importance in professional post-production pipelines. While pixel-wise segmentation techniques can help for this task, professional rotoscoping tools rely on parametric curves that offer the artists a much better interactive control on the definition, editing and manipulation of the segments of interest. Sticking to this prevalent rotoscoping paradigm, we propose a novel framework to capture and track the visual aspect of an arbitrary object in a scene, given an initial closed outline of this object. This model combines a collection of local foreground/background appearance models spread along the outline, a global appearance model of the enclosed object and a set of distinctive foreground landmarks. The structure of this rich appearance model allows simple initialization, efficient iterative optimization with exact minimization at each step, and on-line adaptation in videos. We further extend this model by so-called trimaps which serve as an input to alpha-matting algorithms to allow truly seamless compositing. To this end, we leverage local classifiers attached to the roto-curves to define a confidence measure that is well-suited to define trimaps with adaptive band-widths. The resulting trimaps are parametric, temporally consistent and remain fully editable by the artist. We demonstrate qualitatively and quantitatively the merit of this framework through comparisons with tools based on either dynamic segmentation with a closed curve or pixel-wise binary labelling.	[Perez-Rua, Juan-Manuel] Technicolor, F-35576 Cesson Sevigne, Bretagne, France; [Miksik, Ondrej; Torr, Philip H. S.] Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England; [Crivelli, Tomas] Technicolor Rennes Res & Innovat, F-35576 Cesson Sevigne, Bretagne, France; [Bouthemy, Patrick] IRISA INRIA, F-35000 Rennes, France; [Perez, Patrick] Valeo Ai, F-75017 Paris, France	Technicolor SA; University of Oxford; UDICE-French Research Universities; Universite Paris Saclay	Miksik, O (corresponding author), Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England.	juanmanpr@gmail.com; ondra.miksik@gmail.com; Tomas.Crivelli@technicolor.com; patrick.bouthemy@inria.fr; philip.torr@eng.ox.ac.uk; patrick.perez@valeo.com		perez, patrick/0000-0002-8124-1206; Perez Rua, Juan Manuel/0000-0002-5559-9626	ERC [ERC-2012-AdG 321162-HELIOS]; EPSRC [EP/M013774/1]; EPSRC/MURI [EP/N019474/1]; RAEng. Juan-Manuel Perez-Rua and Ondrej Miksik assert joint first authorship; EPSRC [EP/N019474/1] Funding Source: UKRI	ERC(European Research Council (ERC)European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC/MURI(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); RAEng. Juan-Manuel Perez-Rua and Ondrej Miksik assert joint first authorship; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by the ERC grant ERC-2012-AdG 321162-HELIOS, EPSRC grant Seebibyte EP/M013774/1, EPSRC/MURI grant EP/N019474/1 and the RAEng. Juan-Manuel Perez-Rua and Ondrej Miksik assert joint first authorship.	Agarwala A, 2004, ACM T GRAPHIC, V23, P584, DOI 10.1145/1015706.1015764; Ahn JH, 2006, LECT NOTES COMPUT SC, V4319, P1185; Aksoy Y, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2907940; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; [Anonymous], [No title captured]; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Bai X, 2011, LECT NOTES COMPUT SC, V6930, P63; Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376; Bhat P., 2005, P ACM SIGGRAPH, P585; Blake A., 2000, ACTIVE CONTOURS; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; BRATT B., 2011, ROTOSCOPING TECHNIQU; Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565; Castrejon L, 2017, PROC CVPR IEEE, P4485, DOI 10.1109/CVPR.2017.477; Chuang Yung-Yu, 2001, COMP VIS PATT REC 20, V2, pII; Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Erofeev M., 2015, BMVA PRESS P; Faktor A., 2014, P BRIT MACH VIS C; Fan JL, 2012, IEEE T PATTERN ANAL, V34, P1633, DOI 10.1109/TPAMI.2011.257; Fan QN, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818105; Fourure D, 2017, NEUROCOMPUTING, V251, P68, DOI 10.1016/j.neucom.2017.04.014; Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x; Gong ML, 2015, IEEE T IMAGE PROCESS, V24, P1356, DOI 10.1109/TIP.2015.2401516; Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hu Yuan-Ting, 2017, NEURIPS; Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336; Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Khan EA, 2006, ACM T GRAPHIC, V25, P654, DOI 10.1145/1141911.1141937; Kohli P, 2007, IEEE T PATTERN ANAL, V29, P2079, DOI 10.1109/TPAMI.2007.1128; Kundu A, 2016, PROC CVPR IEEE, P3168, DOI 10.1109/CVPR.2016.345; Li DZY, 2013, IEEE I CONF COMP VIS, P3599, DOI 10.1109/ICCV.2013.447; Li WB, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925973; Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234; Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406; Lu Y, 2016, PROC CVPR IEEE, P642, DOI 10.1109/CVPR.2016.76; Marki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Miksik O, 2017, PROC CVPR IEEE, P7426, DOI 10.1109/CVPR.2017.785; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perez P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P524, DOI 10.1109/ICCV.2001.937670; Perez-Rua JM, 2016, COMPUT VIS IMAGE UND, V153, P88, DOI 10.1016/j.cviu.2016.05.005; Price BL, 2009, IEEE I CONF COMP VIS, P779, DOI 10.1109/ICCV.2009.5459293; Rav-Acha A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360616; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Shen X, 2016, LECT NOTES COMPUT SC, V9905, P92, DOI 10.1007/978-3-319-46448-0_6; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; TANG GY, 1982, IEEE T PATTERN ANAL, V4, P242, DOI 10.1109/TPAMI.1982.4767241; Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423; Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019; WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L; Wright S., 2006, DIGITAL COMPOSITING; Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41; Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326	56	0	0	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1996	2010		10.1109/TPAMI.2019.2904963	http://dx.doi.org/10.1109/TPAMI.2019.2904963			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30872223	Green Submitted			2022-12-18	WOS:000545415400014
J	Chakrabarti, A; Sunkavalli, K; Forsyth, DA				Chakrabarti, Ayan; Sunkavalli, Kalyan; Forsyth, David A.			Guest Editors' Introduction to the Special Section on Computational Photography	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Chakrabarti, Ayan] Washington Univ, Dept CSE, St Louis, MO 63130 USA; [Sunkavalli, Kalyan] Adobe Res, San Jose, CA 95110 USA; [Forsyth, David A.] Univ Illinois, Dept CS, Urbana, IL 61801 USA	Washington University (WUSTL); Adobe Systems Inc.; University of Illinois System; University of Illinois Urbana-Champaign	Chakrabarti, A (corresponding author), Washington Univ, Dept CSE, St Louis, MO 63130 USA.	ayan@wustl.edu; sunkaval@adobe.com; daf@illinois.edu		Chakrabarti, Ayan/0000-0002-4843-740X					0	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1545	1546		10.1109/TPAMI.2020.2993888	http://dx.doi.org/10.1109/TPAMI.2020.2993888			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH		Bronze			2022-12-18	WOS:000542967200001
J	Di Martino, JM; Suzacq, F; Delbracio, M; Qiu, Q; Sapiro, G				Di Martino, J. Matias; Suzacq, Fernando; Delbracio, Mauricio; Qiu, Qiang; Sapiro, Guillermo			Differential 3D Facial Recognition: Adding 3D to Your State-of-the-Art 2D Method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Two dimensional displays; Feature extraction; Face recognition; Facial features; Image resolution; Data mining; Differential 3D; active stereo; face recognition; spoofing detection; 3D facial analysis	FACE RECOGNITION	Active illumination is a prominent complement to enhance 2D face recognition and make it more robust, e.g., to spoofing attacks and low-light conditions. In the present work we show that it is possible to adopt active illumination to enhance state-of-the-art 2D face recognition approaches with 3D features, while bypassing the complicated task of 3D reconstruction. The key idea is to project over the test face a high spatial frequency pattern, which allows us to simultaneously recover real 3D information plus a standard 2D facial image. Therefore, state-of-the-art 2D face recognition solution can be transparently applied, while from the high frequency component of the input image, complementary 3D facial features are extracted. Experimental results on ND-2006 dataset show that the proposed ideas can significantly boost face recognition performance and dramatically improve the robustness to spoofing attacks.	[Di Martino, J. Matias] Univ Republica, Sch Engn, Dept Phys, Montevideo 11200, Uruguay; [Di Martino, J. Matias; Qiu, Qiang; Sapiro, Guillermo] Duke Univ, Dept Elect Engn, Durham, NC 27708 USA; [Suzacq, Fernando; Delbracio, Mauricio] Univ Republica, Dept Elect Engn, Montevideo 11200, Uruguay	Universidad de la Republica, Uruguay; Duke University; Universidad de la Republica, Uruguay	Di Martino, JM (corresponding author), Univ Republica, Sch Engn, Dept Phys, Montevideo 11200, Uruguay.	matias.di.martino.uy@gmail.com; fernandosuzacq@gmail.com; mdelbra@fing.edu.uy; qiang.qiu@duke.edu; guillermo.sapiro@duke.edu		Sapiro, Guillermo/0000-0001-9190-6964	ARO; ONR; NSF; NGA	ARO; ONR(Office of Naval Research); NSF(National Science Foundation (NSF)); NGA	This work was supported in part by ARO, ONR, NSF, and NGA.	[Anonymous], 1957, I ANN I FOURIER GREN, DOI [DOI 10.5802/AIF.68, 10.5802/aif.68]; Ayubi GA, 2010, OPT LETT, V35, P3682, DOI 10.1364/OL.35.003682; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77; Cao KD, 2018, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2018.00544; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Cui JY, 2018, INT CONF BIOMETR, P140, DOI 10.1109/ICB2018.2018.00031; Deng JK, 2018, PROC CVPR IEEE, P7093, DOI 10.1109/CVPR.2018.00741; Deng Jiankang, 2019, P IEEE C COMP VIS PA, P4690, DOI DOI 10.1109/CVPR.2019.00482; Di Martino JM, 2015, OPT LASER ENG, V72, P26, DOI 10.1016/j.optlaseng.2015.04.001; Di Martino M, 2018, OPT LASER ENG, V105, P188, DOI 10.1016/j.optlaseng.2018.01.017; Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089; Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164; Eigen D, 2014, ADV NEUR IN, V27; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Faltemier TC, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P19; Gilani SZ, 2018, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR.2018.00203; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hayat M, 2017, PROC CVPR IEEE, P1551, DOI 10.1109/CVPR.2017.169; He LX, 2018, PROC CVPR IEEE, P7054, DOI 10.1109/CVPR.2018.00737; Huber P., 2015, P 11 INT JOINT C COM, P79; Kaya Y., 1972, FRONTIERS PATTERN RE, V1, P265; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; King DE, 2009, J MACH LEARN RES, V10, P1755; Kumar A, 2018, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2018.00052; Kuncheva L I, 2004, COMBINING PATTERN CL; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720; Li BW, 2014, OPT LASER ENG, V54, P236, DOI 10.1016/j.optlaseng.2013.07.010; Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152; Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048; Liu Y, 2018, PROC CVPR IEEE, P2080, DOI 10.1109/CVPR.2018.00222; Marks M., 1992, U.S Patent, Patent No. [5,151,821, 5151821]; Nech A, 2017, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2017.363; Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068; Pini S, 2018, INT CONF 3D VISION, P634, DOI 10.1109/3DV.2018.00078; Prados E, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P375, DOI 10.1007/0-387-28831-7_23; Pritt M. D., 1998, 2 DIMENSIONAL PHASE; Rosman G, 2016, PROC CVPR IEEE, P874, DOI 10.1109/CVPR.2016.101; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Yu X, 2017, PROC CVPR IEEE, P5367, DOI 10.1109/CVPR.2017.570; Yu Z, 2017, IEEE INT SYMP ELEC; Zafeiriou S, 2013, IEEE T INF FOREN SEC, V8, P121, DOI 10.1109/TIFS.2012.2224109; Zhang S, 2006, OPT EXPRESS, V14, P2644, DOI 10.1364/OE.14.002644; Zhang S, 2013, HDB 3D MACHINE VISIO; Zhang S, 2010, OPT LASER ENG, V48, P149, DOI 10.1016/j.optlaseng.2009.03.008; Zhang X, 2016, INT C PATT RECOG, P2995, DOI 10.1109/ICPR.2016.7900093; Zhao J, 2018, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2018.00235; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zheng YT, 2018, PROC CVPR IEEE, P5089, DOI 10.1109/CVPR.2018.00534; Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754; Zou X., 2005, P BRIT MACH VIS C	57	0	0	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1582	1593		10.1109/TPAMI.2020.2986951	http://dx.doi.org/10.1109/TPAMI.2020.2986951			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	32305901	Green Accepted, hybrid, Green Submitted			2022-12-18	WOS:000542967200005
J	Mo, ZP; Shi, BX; Yeung, SK; Matsushita, Y				Mo, Zhipeng; Shi, Boxin; Yeung, Sai-Kit; Matsushita, Yasuyuki			Ambiguity-Free Radiometric Calibration for Internet Photo Collections	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Radiometric calibration; photo collections; internet images; exponential ambiguity; edge color blending	CAMERA RESPONSE	Radiometrically calibrating nonlinear images from Internet photo collections makes photometric analysis applicable not only to lab data but also to big image data in the wild. However, conventional calibration methods cannot be directly applied to such photo collections. This paper presents a method to jointly perform radiometric calibration for a set of nonlinear images in Internet photo collections. By incorporating the consistency of scene reflectance of corresponding pixels across nonlinear images, the proposed method first estimates radiometric response functions of all the nonlinear images up to a unique exponential ambiguity using a rank minimization framework. The ambiguity is then resolved using the linear edge color blending constraint. Quantitative evaluation using both synthetic and real-world data shows the effectiveness of the proposed method.	[Mo, Zhipeng] Singapore Univ Technol & Design, Pillar Informat Syst Technol & Design, Singapore 487372, Singapore; [Shi, Boxin] Peking Univ, Sch Elect Engn & Comp Sci, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China; [Yeung, Sai-Kit] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Div Integrat Syst & Design, Hong Kong, Peoples R China; [Matsushita, Yasuyuki] Osaka Univ, Grad Sch Informat Sci & Technol, Suita, Osaka 5650871, Japan	Singapore University of Technology & Design; Peking University; Hong Kong University of Science & Technology; Osaka University	Shi, BX (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.	zhipeng_mo@mymail.sutd.edu.sg; shiboxin@pku.edu.cn; saikit@ust.hk; yasumat@ist.osaka-u.ac.jp		Matsushita, Yasuyui/0000-0002-1935-4752; Mo, Zhipeng/0000-0001-8749-9489	National Science Foundation of China [61872012]; Singapore MOE Academic Research Fund [MOE2016-T2-2-154]; HKUST [R9429]; JSPS KAKENHI [JP16H01732]	National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Singapore MOE Academic Research Fund(Ministry of Education, Singapore); HKUST; JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	We thank Joon-Young Lee for providing the code of [4]. This research is supported in part by National Science Foundation of China under Grant No. 61872012 and Singapore MOE Academic Research Fund MOE2016-T2-2-154. Sai-Kit Yeung is supported by an internal grant from HKUST (R9429). Yasuyuki Matsushita is supported by JSPS KAKENHI Grant Number JP16H01732.	Badki A., 2015, P IEEE INT C COMP PH, P1; Boxin Shi, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P361, DOI 10.1109/3DV.2014.9; Chakrabarti A, 2009, PRODUCT RESEARCH: THE ART AND SCIENCE BEHIND SUCCESSFUL PRODUCT LAUNCHES, P17, DOI 10.1007/978-90-481-2860-0_2; Chang YC, 1996, IEEE T IMAGE PROCESS, V5, P1414, DOI 10.1109/83.536890; Chen TY, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-24; Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190; Dale K, 2009, IEEE I CONF COMP VIS, P2217, DOI 10.1109/ICCV.2009.5459473; Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884; Diaz M, 2013, J MATH IMAGING VIS, V47, P93, DOI 10.1007/s10851-013-0442-7; Dlaz M., 2011, P OFTHE IEEE INT C C, P1; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802; Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88; Grossberg MD, 2003, IEEE T PATTERN ANAL, V25, P1455, DOI 10.1109/TPAMI.2003.1240119; Guangwei DT, 2018, PROC CVPR IEEE, P2831, DOI 10.1109/CVPR.2018.00299; HaCohen Y, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461997; Hwang Y, 2012, IEEE T PATTERN ANAL, V34, P1329, DOI 10.1109/TPAMI.2011.224; Kemelmacher-Shlizerman I., 2011, ACM T GRAPHICS SIGGR, P1, DOI DOI 10.1145/2010324.1964956; Kim S.-G., 2004, P 37 HAW INT C SYST, P1; Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732; Kim SJ, 2012, IEEE T PATTERN ANAL, V34, P2289, DOI 10.1109/TPAMI.2012.58; Kim SJ, 2008, CLIM DYNAM, V31, P1, DOI 10.1007/s00382-007-0332-z; KIM SJ, 2004, P IEEE C COMP VIS PA; Kuthirummal S, 2008, LECT NOTES COMPUT SC, V5305, P74, DOI 10.1007/978-3-540-88693-8_6; Laffont PY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366221; Lee JY, 2013, IEEE T PATTERN ANAL, V35, P144, DOI 10.1109/TPAMI.2012.66; Li C, 2017, PROC CVPR IEEE, P1695, DOI 10.1109/CVPR.2017.184; Li H, 2015, COMPUT GRAPH FORUM, V34, P109, DOI 10.1111/cgf.12683; Lin HT, 2011, IEEE I CONF COMP VIS, P129, DOI 10.1109/ICCV.2011.6126234; Lin S, 2005, PROC CVPR IEEE, P66; Lin S., 2004, Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pII; Martin-Brualla R, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766903; Matsuno Y, 2007, IEEE INT SYMP ELECTR, P1, DOI 10.1109/ISEE.2007.369091; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Mo ZP, 2017, PROC CVPR IEEE, P275, DOI 10.1109/CVPR.2017.37; Ng T.-T., 2007, PROC IEEE C COMPUT V, P1; Park J, 2016, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2016.53; Rodrigues P, 2015, PROC CVPR IEEE, P1028, DOI 10.1109/CVPR.2015.7298705; Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455; Shan Q, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P25, DOI 10.1109/3DV.2013.12; Shen L, 2009, PROC CVPR IEEE, P1850, DOI 10.1109/CVPRW.2009.5206732; Shi BX, 2010, PROC CVPR IEEE, P1118, DOI 10.1109/CVPR.2010.5540091; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Snavely N, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360614; Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555; Wilburn B., 2008, P IEEE C COMP VIS PA, P1	47	0	0	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1670	1684		10.1109/TPAMI.2019.2901458	http://dx.doi.org/10.1109/TPAMI.2019.2901458			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	30802848				2022-12-18	WOS:000542967200012
J	Escalera, S; Escalante, HJ; Baro, X; Guyon, I; Madadi, M; Wan, J; Ayache, S; Gucluturk, Y; Guclu, U				Escalera, Sergio; Escalante, Hugo Jair; Baro, Xavier; Guyon, Isabelle; Madadi, Meysam; Wan, Jun; Ayache, Stephane; Gucluturk, Yagmur; Guclu, Umut			Guest Editorial: Image and Video Inpainting and Denoising	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Escalera, Sergio; Madadi, Meysam] Univ Barcelona, E-08007 Barcelona, Spain; [Escalera, Sergio; Madadi, Meysam] Comp Vis Ctr, Barcelona 08007, Spain; [Escalante, Hugo Jair] Inst Nacl Astrofis Opt & Eect, Puebla, Mexico; [Escalante, Hugo Jair] CINVESTAV Zacatenco, Comp Sci Dept, Mexico City 07360, DF, Mexico; [Baro, Xavier] Univ Oberta Catalunya, Barcelona 08018, Spain; [Baro, Xavier] Comp Vis Ctr, Barcelona 08018, Spain; [Guyon, Isabelle] Univ Paris Saclay, INRIA, UPSud, F-91190 Essonne, France; [Guyon, Isabelle] ChaLearn, Berkeley, CA USA; [Wan, Jun] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100049, Peoples R China; [Wan, Jun] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China; [Ayache, Stephane] Aix Marseille Univ, Lab Informat & Syst, F-13007 Marseille, France; [Gucluturk, Yagmur; Guclu, Umut] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behaviour, NL-6525 XZ Nijmegen, Netherlands	University of Barcelona; Centre de Visio per Computador (CVC); Instituto Nacional de Astrofisica, Optica y Electronica; CINVESTAV - Centro de Investigacion y de Estudios Avanzados del Instituto Politecnico Nacional; UOC Universitat Oberta de Catalunya; Centre de Visio per Computador (CVC); Inria; UDICE-French Research Universities; Universite Paris Saclay; Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; UDICE-French Research Universities; Aix-Marseille Universite; Radboud University Nijmegen	Escalera, S (corresponding author), Univ Barcelona, E-08007 Barcelona, Spain.; Escalera, S (corresponding author), Comp Vis Ctr, Barcelona 08007, Spain.	sergio@maia.ub.es; hugojair@inaoep.mx; xbaro@uoc.edu; guyon@chalearn.org; meysam.madadi@gmail.com; jun.wan@ia.ac.cn; stephane.ayache@lis-lab.fr; ygucluturk@gmail.com; umuguc@gmail.com	Escalera, Sergio/L-2998-2015; Baró, Xavier/A-4064-2011; Güçlü, Umut/AAX-6105-2020	Escalera, Sergio/0000-0003-0617-8873; Baró, Xavier/0000-0001-5338-3007; Güçlü, Umut/0000-0003-4753-159X	MINECO/FEDER, UE [TIN2015-66951-C2-2-R, TIN2016-74946-P]; CERCA Programme/Generalitat de Catalunya; INAOE, CONACyT-Mexico [CB-A1-S-26314]; ICREA under the ICREA Academia programme; ChaLearn Looking at People	MINECO/FEDER, UE; CERCA Programme/Generalitat de Catalunya; INAOE, CONACyT-Mexico; ICREA under the ICREA Academia programme; ChaLearn Looking at People	This work was supported in part by the Spanish projects TIN2015-66951-C2-2-R and TIN2016-74946-P (MINECO/FEDER, UE) and CERCA Programme/Generalitat de Catalunya and by INAOE, CONACyT-Mexico under grant CB-A1-S-26314. This work was also supported in part by ICREA under the ICREA Academia programme. The authors would like to thank ChaLearn Looking at People sponsors for their support, including Microsoft Research, Google, NVIDIA Coorporation, Amazon, Facebook, andDisney Research.	Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832; Escalera S., 2012, INPAINTING DENOISING; Escalera S., 2019, P INP DEN CHALL, P23; He R, 2020, IEEE T PATTERN ANAL, V42, P1025, DOI 10.1109/TPAMI.2019.2961900; Huang D., 2012, IRIPTR12FR001 BEIJ U; Kim D, 2020, IEEE T PATTERN ANAL, V42, P1038, DOI 10.1109/TPAMI.2019.2958083; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59; Liu Z., 2019, P C APPR AUT HALARCH; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Soomro K., 2012, ARXIVPREPRINT, P2556; Szeto R, 2020, IEEE T PATTERN ANAL, V42, P1053, DOI 10.1109/TPAMI.2019.2951667; Xu N, 2018, LECT NOTES COMPUT SC, V11209, P603, DOI 10.1007/978-3-030-01228-1_36	14	0	0	3	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1021	1024		10.1109/TPAMI.2020.2971291	http://dx.doi.org/10.1109/TPAMI.2020.2971291			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT		Bronze, Green Submitted			2022-12-18	WOS:000523685800001
J	Parkhi, OM; Rahtu, E; Cao, Q; Zisserman, A				Parkhi, Omkar M.; Rahtu, Esa; Cao, Qiong; Zisserman, Andrew			Automated Video Face Labelling for Films and TV Material	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Target tracking; Labeling; TV; Visualization; Pattern analysis; Automatic face labelling; face tracking; deep learning		The objective of this work is automatic labelling of characters in TV video and movies, given weak supervisory information provided by an aligned transcript. We make five contributions: (i) a new strategy for obtaining stronger supervisory information from aligned transcripts; (ii) an explicit model for classifying background characters, based on their face-tracks; (iii) employing new ConvNet based face features, and (iv) a novel approach for labelling all face tracks jointly using linear programming. Each of these contributions delivers a boost in performance, and we demonstrate this on standard benchmarks using tracks provided by authors of prior work. As a fifth contribution, we also investigate the generalisation and strength of the features and classifiers by applying them "in the raw" on new video material where no supervisory information is used. In particular, to provide high quality tracks on those material, we propose efficient track classifiers to remove false positive tracks by the face tracker. Overall we achieve a dramatic improvement over the state of the art on both TV series and film datasets, and almost saturate performance on some benchmarks.	[Parkhi, Omkar M.; Cao, Qiong; Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Visual Geometry Grp, Oxford OX1 2JD, England; [Rahtu, Esa] Tampere Univ Technol, Dept Signal Proc, Tampere 33720, Finland	University of Oxford; Tampere University	Parkhi, OM (corresponding author), Univ Oxford, Dept Engn Sci, Visual Geometry Grp, Oxford OX1 2JD, England.	omkar@robots.ox.ac.uk; esa.rahtu@tut.fi; giong@robots.ox.ac.uk; az@robots.ox.ac.uk		Rahtu, Esa/0000-0001-8767-0864; Zisserman, Andrew/0000-0002-8945-8573; Cao, Qiong/0000-0001-8750-3505	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA) [2014-14071600010]; EPSRC [Seebibyte EP/M013774/1]; Academy of Finland [310325]; EPSRC [EP/M013774/1] Funding Source: UKRI	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Academy of Finland(Academy of Finland); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This research is based upon work supported by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via contract number 2014-14071600010. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purpose not with standing any copyright annotation thereon. Funding for this research was also provided by the EPSRC Programme Grant Seebibyte EP/M013774/1 and Academy of Finland project number 310325.	Andrews S., 2003, ADV NEURAL INFORM PR, P577; Bauml M, 2013, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2013.462; Bojanowski P, 2013, IEEE I CONF COMP VIS, P2280, DOI 10.1109/ICCV.2013.283; Chung J. S., 2016, P AS C COMP VIS, P87; Chung Joon Son, 2016, P AS C COMP VIS, P251, DOI [DOI 10.1007/978-3-319-54427-4_19, 10.1007/978-3-319-54427-4{_}19, DOI 10.1007/978-3-319-54427-4{_}19]; Cinbis RG, 2011, IEEE I CONF COMP VIS, P1559, DOI 10.1109/ICCV.2011.6126415; Cour T, 2011, J MACH LEARN RES, V12, P1501; Cour T, 2010, PROC CVPR IEEE, P1014, DOI 10.1109/CVPR.2010.5540106; Cour T, 2009, PROC CVPR IEEE, P919, DOI 10.1109/CVPRW.2009.5206667; Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279; Everingham M., 2006, P BRIT MACH VIS C BM, P899, DOI DOI 10.5244/C.20.92; Everingham M, 2009, IMAGE VISION COMPUT, V27, P545, DOI 10.1016/j.imavis.2008.04.018; Guillaumin M, 2010, LECT NOTES COMPUT SC, V6311, P634, DOI 10.1007/978-3-642-15549-9_46; Haurilet Monica, 2016, 2016 IEEE WINT C APP, P1, DOI [10.1109/WACV.2016.7477560, DOI 10.1109/WACV.2016.7477560]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jammalamadaka N, 2012, LECT NOTES COMPUT SC, V7574, P114, DOI 10.1007/978-3-642-33712-3_9; Jiang H., 2016, CORR; Klaser A., 2012, P EUR C COMP VIS, V6553, P219; Kostinger M., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P23, DOI 10.1109/AVSS.2011.6027287; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mathialagan CS, 2015, PROC CVPR IEEE, P4858, DOI 10.1109/CVPR.2015.7299119; Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47; Ozerov A, 2013, IEEE IMAGE PROC, P3003, DOI 10.1109/ICIP.2013.6738618; Parkhi O. M., 2015, P ICCV WORKSH DESCR; Parkhi OM, 2014, PROC CVPR IEEE, P1693, DOI 10.1109/CVPR.2014.219; Ramanan D, 2007, IEEE I CONF COMP VIS, P1432; Ramanathan V, 2014, LECT NOTES COMPUT SC, V8689, P95, DOI 10.1007/978-3-319-10590-1_7; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sivic J, 2009, PROC CVPR IEEE, P1145, DOI 10.1109/CVPRW.2009.5206513; Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111; Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501; Tapaswi M, 2015, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2015.7298792; Tapaswi M, 2012, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2012.6247986; Vedaldi A., 2014, CORR; Wohlhart Paul, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P132, DOI 10.1007/978-3-642-23123-0_14; Wolsey LA, 1998, INTEGER PROGRAMMING; Yang J, 2005, Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005), P28; Zhu Y., 2015, ARXIV150606724	39	0	0	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					780	792		10.1109/TPAMI.2018.2889831	http://dx.doi.org/10.1109/TPAMI.2018.2889831			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30596569	Green Submitted			2022-12-18	WOS:000526541100002
J	Park, HS; Shi, J				Park, Hyun Soo; Shi, Jianbo			Force from Motion: Decoding Control Force of Activity in a First-Person Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Visualization; Gravity; Torque; Dynamics; Three-dimensional displays; First-person vision; physical sensation; optimal control	EGOCENTRIC VIDEO; SHAPE; CALIBRATION; PEOPLE; SCENES	A first-person video delivers what the camera wearer (actor) experiences through physical interactions with surroundings. In this paper, we focus on a problem of Force from Motion-estimating the active force and torque exerted by the actor to drive her/his activity-from a first-person video. We use two physical cues inherited in the first-person video. (1) Ego-motion: the camera motion is generated by a resultant of force interactions, which allows us to understand the effect of the active force using Newtonian mechanics. (2) Visual semantics: the first-person visual scene is deployed to afford the actor's activity, which is indicative of the physical context of the activity. We estimate the active force and torque using a dynamical system that can describe the transition (dynamics) of the actor's physical state (position, orientation, and linear/angular momentum) where the latent physical state is indirectly observed by the first-person video. We approximate the physical state with the 3D camera trajectory that is reconstructed up to scale and orientation. The absolute scale factor and gravitation field are learned from the ego-motion and visual semantics of the first-person video. Inspired by an optimal control theory, we solve the dynamical system by minimizing reprojection error. Our method shows quantitatively equivalent reconstruction comparing to IMU measurements in terms of gravity and scale recovery and outperforms the methods based on 2D optical flow for an active action recognition task. We apply our method to first-person videos of mountain biking, urban bike racing, skiing, speedflying with parachute, and wingsuit flying where inertial measurements are not accessible.	[Park, Hyun Soo] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; [Shi, Jianbo] Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA	University of Minnesota System; University of Minnesota Twin Cities; University of Pennsylvania	Park, HS (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	hspark@umm.edu; jshi@seas.upenn.edu						Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13; Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751; Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201; [Anonymous], P INT DES ENG TECH C; [Anonymous], P SIGGRAPH C; [Anonymous], P AIAA ATM FLIGHT ME; [Anonymous], P IEEE C COMP VIS PA; [Anonymous], P IEEE C COMP VIS PA; [Anonymous], 2015, PROC CVPR IEEE; [Anonymous], P INT C INF CONTR AU; [Anonymous], P ANN M COGN SCI SOC; [Anonymous], 2003, TR0306 U TEX AUST; Arev I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601198; BAILLARGEON R, 1994, CURR DIR PSYCHOL SCI, V3, P133, DOI 10.1111/1467-8721.ep10770614; Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216; Bertasius Gedas, 2016, ARXIV160304908; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Brubaker R, 2007, U ILLINOIS LAW REV, P1; Choo K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P321, DOI 10.1109/ICCV.2001.937643; Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963; DALMONTE A, 1987, INT J SPORT BIOMECH, V3, P287; Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269; Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23; Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269; Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514; Greene MR, 2009, COGNITIVE PSYCHOL, V58, P137, DOI 10.1016/j.cogpsych.2008.06.001; Hartley R., 2004, ROBOTICA; Hassan HAH, 2016, IEEE ONL CONF GREEN, P1, DOI 10.1109/OnlineGreenCom.2016.7805398; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Howe NR, 2000, ADV NEUR IN, V12, P820; Jain A, 2015, LECT NOTES COMPUT SC, V9004, P302, DOI 10.1007/978-3-319-16808-1_21; Jayaraman D, 2015, IEEE I CONF COMP VIS, P1413, DOI 10.1109/ICCV.2015.166; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Kanade T, 2012, P IEEE, V100, P2442, DOI 10.1109/JPROC.2012.2200554; Kitani KM, 2011, PROC CVPR IEEE; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820; Li Y, 2013, IEEE I CONF COMP VIS, P3216, DOI 10.1109/ICCV.2013.399; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; Mirzaei FM, 2008, IEEE T ROBOT, V24, P1143, DOI 10.1109/TRO.2008.2004486; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Park H. S., 2012, P ADV NEUR INF PROC, P422; Park HS, 2016, PROC CVPR IEEE, P4697, DOI 10.1109/CVPR.2016.508; Park HS, 2016, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2016.416; Park HS, 2011, IEEE I CONF COMP VIS, P201, DOI 10.1109/ICCV.2011.6126243; Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010; Rehg JM, 2013, PROC CVPR IEEE, P3414, DOI 10.1109/CVPR.2013.438; Rogez G, 2015, PROC CVPR IEEE, P4325, DOI 10.1109/CVPR.2015.7299061; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Ryoo MS, 2015, PROC CVPR IEEE, P896, DOI 10.1109/CVPR.2015.7298691; Ryoo MS, 2013, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2013.352; Shin S, 2010, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2010), P96; Sidenbladh H., 2000, LNCS, V2, P702; Sontag ED., 1998, MATH CONTROL THEORY, DOI [10.1007/978-1-4612-0577-7, DOI 10.1007/978-1-4612-0577-7]; Todorov E, 2005, P AMER CONTR CONF, P300, DOI 10.1109/acc.2005.1469949; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Urtasun R., 2006, 2006 IEEE COMP VIS P, P238, DOI DOI 10.1109/CVPR.2006.15; Urtasun R, 2006, COMPUT VIS IMAGE UND, V104, P157, DOI 10.1016/j.cviu.2006.08.006; Valmadre J, 2012, LECT NOTES COMPUT SC, V7572, P72, DOI 10.1007/978-3-642-33718-5_6; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Vondrak M, 2008, PROC CVPR IEEE, P1849; Wei XL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778779; Wolpert DM, 2011, NAT REV NEUROSCI, V12, P739, DOI 10.1038/nrn3112; Wren CR, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P22, DOI 10.1109/AFGR.1998.670920; Xiong B, 2014, LECT NOTES COMPUT SC, V8693, P282, DOI 10.1007/978-3-319-10602-1_19; Yan JY, 2008, IEEE T PATTERN ANAL, V30, P865, DOI 10.1109/TPAMI.2007.70739; Yonetani R, 2015, PROC CVPR IEEE, P5445, DOI 10.1109/CVPR.2015.7299183; Zou YZ, 2015, IEEE INT CONF AUTOM, P1, DOI 10.1109/ASE.2015.24	71	0	0	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					622	635		10.1109/TPAMI.2018.2883327	http://dx.doi.org/10.1109/TPAMI.2018.2883327			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30489262				2022-12-18	WOS:000525365300008
J	Dickinson, S				Dickinson, Sven			State of the Journal Editorial	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					253	260		10.1109/TPAMI.2019.2958194	http://dx.doi.org/10.1109/TPAMI.2019.2958194			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB		Bronze			2022-12-18	WOS:000508386100001
J	Polyak, A; Taigman, Y; Wolf, L				Polyak, Adam; Taigman, Yaniv; Wolf, Lior			Unsupervised Generation of Free-Form and Parameterized Avatars	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Gallium nitride; Avatars; Generative adversarial networks; Engines; Face; Three-dimensional displays; Deep learning; domain adaptation; neural network; cross-domain transfer; analysis by synthesis; domain transfer network; tied output synthesis		We study two problems involving the task of mapping images between different domains. The first problem, transfers an image in one domain to an analog image in another domain. The second problem, extends the previous one by mapping an input image to a tied pair, consisting of a vector of parameters and an image that is created using a graphical engine from this vector of parameters. Similar to the first problem, the mapping's objective is to have the output image as similar as possible to the input image. In both cases, no supervision is given during training in the form of matching inputs and outputs. We compare the two unsupervised learning problems to the problem of unsupervised domain adaptation, define generalization bounds that are based on discrepancy, and employ a GAN to implement network solutions that correspond to these bounds. Experimentally, our methods are shown to solve the problem of automatically creating avatars.	[Polyak, Adam; Wolf, Lior] Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel; [Polyak, Adam; Taigman, Yaniv; Wolf, Lior] Facebook AI Res, Menlo Pk, CA 94025 USA	Tel Aviv University; Facebook Inc	Polyak, A (corresponding author), Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel.	adampolyak@fb.com; yaniv@fb.com; wolf@fb.com						[Anonymous], [No title captured]; [Anonymous], P ADV NEUR INF PROC; [Anonymous], [No title captured]; Bai Y, 2014, PROC INT CONF RECON; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Crammer K, 2008, J MACH LEARN RES, V9, P1757; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Dosovitskiy Alexey, 2016, NEURIPS; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Ganin Y, 2016, J MACH LEARN RES, V17; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jimenez Rezende D., 2016, ADV NEURAL INFORM PR, P4996; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kim T, 2017, PR MACH LEARN RES, V70; Kulkarni TD, 2015, ADV NEUR IN, V28; Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160; LeCun Yann, 2010, MNIST HANDWRITTEN DI, V2; Liu M. -Y., 2016, ADV NEURAL INFORM PR, P469; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155; Mansour Y, 2009, LECT NOTES ARTIF INT, V5809, P4, DOI 10.1007/978-3-642-04414-4_4; Mirza M., 2014, ARXIV PREPRINT ARXIV; Netzer Y., 2011, NIPS WORKSH DEEP LEA, V2, P5; Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068; Radford A., 2015, ARXIV PREPR ARXIV151; Reed S, 2016, PR MACH LEARN RES, V48; Royer A., 2017, ARXIV PREPRINT ARXIV; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Taigman Y., 2017, P INT C LEARN REPR; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Ulyanov D, 2016, PR MACH LEARN RES, V48; Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Wolf L, 2017, IEEE I CONF COMP VIS, P1539, DOI 10.1109/ICCV.2017.170; Yuqian Zhang, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P64, DOI 10.1007/978-3-319-46604-0_5; Zhmoginov Andrey, 2016, INVERTING FACE EMBED; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	42	0	0	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					444	459		10.1109/TPAMI.2018.2863282	http://dx.doi.org/10.1109/TPAMI.2018.2863282			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	30080143				2022-12-18	WOS:000508386100015
J	Nel, EM; Kristensson, PO; MacKay, DJC				Nel, Emli-Mari; Kristensson, Per Ola; MacKay, David J. C.			Ticker: An Adaptive Single-Switch Text Entry Method for Visually Impaired Users	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Single-switch systems; accessibility; augmentative and alternative communication; Bayesian inference		Ticker is a probabilistic stereophonic single-switch text entry method for visually-impaired users with motor disabilities who rely on single-switch scanning systems to communicate. Such scanning systems are sensitive to a variety of noise sources, which are inevitably introduced in practical use of single-switch systems. Ticker uses a novel interaction model based on stereophonic sound coupled with statistical models for robust inference of the user's intended text in the presence of noise. As a consequence of its design, Ticker is resilient to noise and therefore a practical solution for single-switch scanning systems. Ticker's performance is validated using a combination of simulations and empirical user studies.	[Nel, Emli-Mari; Kristensson, Per Ola; MacKay, David J. C.] Univ Cambridge, Cambridge CB2 1TN, England	University of Cambridge	Nel, EM (corresponding author), Univ Cambridge, Cambridge CB2 1TN, England.	en256@cam.ac.uk; pok21@cam.ac.uk; djcm1@cam.ac.uk			Aegis EU project; Gatsby Charitable Foundation	Aegis EU project; Gatsby Charitable Foundation	We thank Mick and his son Bill Donegan who connected us with several users, and assisted us with every visit to them. We specifically thank two users, Michael and Sara for their valuable feedback. Tom Ash initiated the project and suggested the name Ticker. We thank Christian Steinruecken for revising, and Philipp Hennig for proofreading the manuscript before its first submission. We thank Robert Fanner for his help with the software. The work was funded by the Aegis EU project and the Gatsby Charitable Foundation.	Bishop C.M, 2006, PATTERN RECOGN; Broderick T, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007481; Bronkhorst A. W., 1999, ACTA ACUST UNITED AC, V86, P117; Bronkhorst AW, 2015, ATTEN PERCEPT PSYCHO, V77, P1465, DOI 10.3758/s13414-015-0882-9; De Berg M., 2008, COMPUTATIONAL GEOMET, Vthird; Grafton ST, 2010, P NATL ACAD SCI USA, V107, P13979, DOI 10.1073/pnas.1009925107; Grauman Kristen, 2003, UNIVERSAL ACCESS INF, V2, P359, DOI [10.1007/s10209-003-0062-x, DOI 10.1007/s10209-003-0062-x]; Kilgarriff Adam, 1998, BNC DATABASE WORD FR; Kingman J. F. C, 1993, POISSON PROCESSES, V3; Nel E., 2017, MODELLING NOISERESIL; Nel E., 2017, TICKER; Nel E., 2018, STAT MODEL TICKER AD; Nijholt A, 2010, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-1-84996-272-8; Scott MacKenzie I., 2003, PROC CHI EXTENDED AB, P754, DOI DOI 10.1145/765891.765971; Sensory Software International Ltd, GRID 2 REF MAN; Stifelman L. J., 1997, COCKTAIL PARTY EFFEC; Vertanen Keith, 2011, P 2011 C EMPIRICAL M, P700	17	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2756	2769		10.1109/TPAMI.2018.2865897	http://dx.doi.org/10.1109/TPAMI.2018.2865897			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30130177	Green Submitted			2022-12-18	WOS:000489838200014
J	Liu, L; Pietikainen, M; Chen, J; Zhao, GY; Wang, XG; Chellappa, R				Liu, Li; Pietikainen, Matti; Chen, Jie; Zhao, Guoying; Wang, Xiaogang; Chellappa, Rama			Guest Editors' Introduction to the Special Section on Compact and Efficient Feature Representation and Learning in Computer Vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Liu, Li] NUDT, Fac, Changsha, Hunan, Peoples R China; [Liu, Li] Coll Syst Engn, Changsha, Hunan, Peoples R China; [Liu, Li; Pietikainen, Matti; Chen, Jie; Zhao, Guoying] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland; [Liu, Li; Zhao, Guoying; Wang, Xiaogang] CVPR, Beijing, Peoples R China; [Liu, Li; Zhao, Guoying; Wang, Xiaogang] ICCV, Beijing, Peoples R China; [Liu, Li; Zhao, Guoying; Wang, Xiaogang] ECCV, Oulu, Finland; [Liu, Li] Natl Univ Def Technol, Coll Syst Engn, Changsha, Hunan, Peoples R China; [Pietikainen, Matti] Pattern Recognit Soc Finland, Tampere, Finland; [Pietikainen, Matti; Chellappa, Rama] IAPR, Montreal, PQ, Canada; [Chen, Jie] Peking Univ, Grad Sch Shenzhen, Beijing, Peoples R China; [Chen, Jie] Sch Elect & Comp Engn, Beijing, Peoples R China; [Chen, Jie] Peng Cheng Lab, Shenzhen, Peoples R China; [Zhao, Guoying; Wang, Xiaogang] ACCV, Perth, WA, Australia; [Zhao, Guoying] BMVC, Cardiff, S Glam, Wales; [Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China; [Chellappa, Rama] Univ Maryland, Engn Elect & Comp Engn Dept, College Pk, MD 20742 USA; [Chellappa, Rama] AAAI, Menlo Pk, CA USA; [Chellappa, Rama] AAAS, Washington, DC USA; [Chellappa, Rama] ACM, New York, NY USA; [Chellappa, Rama] OSA, Washington, DC USA	National University of Defense Technology - China; University of Oulu; National University of Defense Technology - China; Peking University; Peng Cheng Laboratory; Chinese University of Hong Kong; University System of Maryland; University of Maryland College Park	Liu, L (corresponding author), NUDT, Fac, Changsha, Hunan, Peoples R China.; Liu, L (corresponding author), Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.; Liu, L (corresponding author), CVPR, Beijing, Peoples R China.; Liu, L (corresponding author), ICCV, Beijing, Peoples R China.; Liu, L (corresponding author), ECCV, Oulu, Finland.; Liu, L (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha, Hunan, Peoples R China.		Chellappa, Rama/AAV-8690-2020; Zhao, Guoying/ABE-7716-2020	Zhao, Guoying/0000-0003-3694-206X; Liu, li/0000-0002-2011-2873					0	0	0	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2287	2290		10.1109/TPAMI.2019.2935426	http://dx.doi.org/10.1109/TPAMI.2019.2935426			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC		Green Accepted, Bronze			2022-12-18	WOS:000489763000001
J	Schluter, R; Beck, E; Ney, H				Schlueter, Ralf; Beck, Eugen; Ney, Hermann			Upper and Lower Tight Error Bounds for Feature Omission with an Extension to Context Reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Error bound; Bayes error; feature selection; language model; perplexity; context reduction; pattern classification; sequence classification	LANGUAGE; RECOGNITION	In this work, fundamental analytic results in the form of error bounds are presented that quantify the effect of feature omission and selection for pattern classification in general, as well as the effect of context reduction in string classification, like automatic speech recognition, printed/handwritten character recognition, or statistical machine translation. A general simulation framework is introduced that supports discovery and proof of error bounds, which lead to the error bounds presented here. Initially derived tight lower and upper bounds for feature omission are generalized to feature selection, followed by another extension to context reduction of string class priors (aka language models) in string classification. For string classification, the quantitative effect of string class prior context reduction on symbol-level Bayes error is presented. The tightness of the original feature omission bounds seems lost in this case, as further simulations indicate. However, combining both feature omission andcontext reduction, the tightness of the bounds is retained. A central result of this work is the proof of the existence, and the amount of a statistical threshold w.r.t. the introduction of additional features in general pattern classification, or the increase of context in string classification beyond which a decrease in Bayes error is guaranteed.	[Schlueter, Ralf; Beck, Eugen; Ney, Hermann] Rhein Westfal TH Aachen, Dept Comp Sci, Human Language Technol & Pattern Recognit, Ahornstr 55, D-52056 Aachen, Germany	RWTH Aachen University	Schluter, R (corresponding author), Rhein Westfal TH Aachen, Dept Comp Sci, Human Language Technol & Pattern Recognit, Ahornstr 55, D-52056 Aachen, Germany.	schlueter@cs.rwth-aachen.de; beck@cs.rwth-aachen.de; ney@cs.rwth-aachen.de		Beck, Eugen/0000-0003-1641-6628; Schluter, Ralf/0000-0003-2839-9247	project EU-Bridge [FP7-287658]; DIGITEO, a French research cluster in Ile-de-France; European Research Council (ERC) under the European Union [694537]	project EU-Bridge; DIGITEO, a French research cluster in Ile-de-France; European Research Council (ERC) under the European Union(European Research Council (ERC))	The authors would like to thank Tamer Alkhouli and Malte Nuhn for many insightful conversations on this topic. This work has been supported by a compute time grant on the RWTH ITC cluster. This work was partly funded under the project EU-Bridge (FP7-287658). H. Ney was partially supported by a senior chair award from DIGITEO, a French research cluster in Ile-de-France. This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No 694537). The work reflects only the author's view and the European Research Council Executive Agency is not responsible for any use that may be made of the information it contains.	Beck E, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1280; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Casella G., 1990, STAT INFERENCE; CHU JT, 1971, IEEE T COMPUT, VC 20, P1203, DOI 10.1109/T-C.1971.223106; Csiszar I., 1963, AKAD MAT KUTAT INT K, V8, P85; DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; Dong Y., 2014, AUTOMATIC SPEECH REC; Gulcehre C, 2017, COMPUT SPEECH LANG, V45, P137, DOI 10.1016/j.csl.2017.01.014; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Klakow D, 2002, SPEECH COMMUN, V38, P19, DOI 10.1016/S0167-6393(01)00041-3; KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394; Koehn Philipp, 2010, STAT MACHINE TRANSLA; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LAINIOTIS DG, 1969, IEEE T INFORM THEORY, V15, P730, DOI 10.1109/TIT.1969.1054374; MAKHOUL J, 1994, VOICE COMMUNICATION BETWEEN HUMANS AND MACHINES, P165; Ney H, 2003, LECT NOTES COMPUT SC, V2652, P636; Schluter R., 2016, INT C SPEECH COMP SP; Schluter R., 2013, P IEEE INF THEOR WOR, P432; Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003; Tang J., 2014, DATA CLASSIFICATION, P37; Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765	22	0	0	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					502	514		10.1109/TPAMI.2017.2788434	http://dx.doi.org/10.1109/TPAMI.2017.2788434			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29990282	Green Published			2022-12-18	WOS:000456150600017
J	Dickinson, S				Dickinson, Sven			State of the Journal	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					1	5		10.1109/TPAMI.2018.2879214	http://dx.doi.org/10.1109/TPAMI.2018.2879214			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX		Bronze			2022-12-18	WOS:000452434800001
J	Hayat, M; Bennamoun, M; An, SJ				Hayat, Munawar; Bennamoun, Mohammed; An, Senjian			Response to "Ghost Numbers"	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material						Image set classification; auto-encoders; video based face recognition		This note clarifies the experimental settings of [1] and shows that the issue raised by [2] is due to a lack of details in [1] which resulted in a misinterpretation of the experimental settings.	[Hayat, Munawar] Univ Canberra, Univ Dr, Bruce, ACT 2617, Australia; [Bennamoun, Mohammed; An, Senjian] Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia	University of Canberra; University of Western Australia	Hayat, M (corresponding author), Univ Canberra, Univ Dr, Bruce, ACT 2617, Australia.	munawar.hayat@canberra.edu.au; mohammed.bennamoun@uwa.edu.au; senjian.an@uwa.edu.au	Bennamoun, Mohammed/C-2789-2013	Bennamoun, Mohammed/0000-0002-6603-3257; Hayat, Munawar/0000-0002-2706-5985; An, Senjian/0000-0002-1758-6824				Chen L, 2018, IEEE T PATTERN ANAL, V40, P2538, DOI 10.1109/TPAMI.2017.2757489; Chen L, 2017, COMPUT VIS IMAGE UND, V160, P1, DOI 10.1016/j.cviu.2017.03.004; Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635	3	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2540	2540		10.1109/TPAMI.2018.2789444	http://dx.doi.org/10.1109/TPAMI.2018.2789444			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	30183618				2022-12-18	WOS:000443875500021
J	Lejeune, A; Verly, JG; Van Droogenbroeck, M				Lejeune, Antoine; Verly, Jacques G.; Van Droogenbroeck, Marc			Probabilistic Framework for the Characterization of Surfaces and Edges in Range Images, with Application to Edge Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Range image; surface; probabilistic framework; edge detection; time-of-flight camera; Kinect		We develop a powerful probabilistic framework for the local characterization of surfaces and edges in range images. We use the geometrical nature of the data to derive an analytic expression for the joint probability density function (pdf) for the random variables used to model the ranges of a set of pixels in a local neighborhood of an image. We decompose this joint pdf by considering independently the cases where two real world points corresponding to two neighboring pixels are locally on the same real world surface or not. In particular, we show that this joint pdf is linked to the Voigt pdf and not to the Gaussian pdf as it is assumed in some applications. We apply our framework to edge detection and develop a locally adaptive algorithm that is based on a probabilistic decision rule. We show in an objective evaluation that this new edge detector performs better than prior art edge detectors. This proves the benefits of the probabilistic characterization of the local neighborhood as a tool to improve applications that involve range images.	[Lejeune, Antoine; Verly, Jacques G.; Van Droogenbroeck, Marc] Univ Liege, Dept Elect Engn & Comp Sci, B-4000 Liege, Belgium	University of Liege	Lejeune, A (corresponding author), Univ Liege, Dept Elect Engn & Comp Sci, B-4000 Liege, Belgium.	Antoine.Lejeune@ulg.ac.be; Jacques.Verly@ulg.ac.be; M.VanDroogenbroeck@ulg.ac.be		Van Droogenbroeck, Marc/0000-0001-6260-6487	European Regional Development Fund program of the Walloon Region of Belgium	European Regional Development Fund program of the Walloon Region of Belgium	This work was funded by the European Regional Development Fund program of the Walloon Region of Belgium.	Abramowitz M., 1965, HDB MATH FUNCTIONS F; Adams M. D., 1993, Proceedings IEEE International Conference on Robotics and Automation (Cat. No.93CH3247-4), P8, DOI 10.1109/ROBOT.1993.292116; [Anonymous], P AUSTR C ROB AUT; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Blais F, 2004, J ELECTRON IMAGING, V13, P231, DOI 10.1117/1.1631921; Boulanger P., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P729, DOI 10.1109/ICPR.1990.118205; Buch AG, 2013, LECT NOTES COMPUT SC, V7944, P54; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Coleman SA, 2010, IEEE T IMAGE PROCESS, V19, P2814, DOI 10.1109/TIP.2010.2050733; Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715; Freedman Barak, 2010, US Application Publication, Patent No. [US 2010/0118123 A1, 20100118123, 20100118123 A1]; Gunsel B, 1996, COMPUT VIS IMAGE UND, V63, P353, DOI 10.1006/cviu.1996.0025; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Hartley R., 2004, ROBOTICA; Huang JG, 2000, PROC CVPR IEEE, P324, DOI 10.1109/CVPR.2000.855836; Ida T, 2000, J APPL CRYSTALLOGR, V33, P1311, DOI 10.1107/S0021889800010219; Jiang XY, 1999, COMPUT VIS IMAGE UND, V73, P183, DOI 10.1006/cviu.1998.0715; Kanade T, 1996, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1996.517074; Kerl Christian, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P39, DOI 10.1109/3DV.2014.62; Khoshelham K, 2011, INT ARCH PHOTOGRAMM, V38-5, P133; Krishnapuram R., 1992, Journal of Mathematical Imaging and Vision, V2, P351, DOI 10.1007/BF00121878; Lange R, 2001, IEEE J QUANTUM ELECT, V37, P390, DOI 10.1109/3.910448; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; Lejeune A., 2011, 3D IM IC3D 2011 INT, P1; Lindner M, 2010, COMPUT VIS IMAGE UND, V114, P1318, DOI 10.1016/j.cviu.2009.11.002; Mufti F, 2011, ISPRS J PHOTOGRAMM, V66, P720, DOI 10.1016/j.isprsjprs.2011.06.004; Papoulis A., 1991, COMMUNICATIONS SIGNA, V3; PARVIN B, 1989, COMPUT VISION GRAPH, V45, P346, DOI 10.1016/0734-189X(89)90086-8; Rapp H., 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P402, DOI 10.1504/IJISTA.2008.021303; Ren X., 2012, ADV NEURAL INFORM PR, V1, P584, DOI DOI 10.5555/2999134.2999200; Schafer H, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P111, DOI 10.1109/3DV.2013.23; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Ye C, 2009, IEEE INT CONF ROBOT, P2396	39	0	0	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2209	2222		10.1109/TPAMI.2017.2746618	http://dx.doi.org/10.1109/TPAMI.2017.2746618			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28866481	Green Submitted			2022-12-18	WOS:000440868400013
J	Darrell, T; Lampert, C; Sebe, N; Wu, Y; Yan, Y				Darrell, Trevor; Lampert, Christoph; Sebe, Nicu; Wu, Ying; Yan, Yan			Guest Editors' Introduction to the Special Section on Learning with Shared Information for Computer Vision and Multimedia Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Darrell, Trevor] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA; [Lampert, Christoph] IST Austria, A-3400 Klosterneuburg, Austria; [Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, TN, Italy; [Wu, Ying] Northwestern Univ, Dept EECS, Evanston, IL 60208 USA; [Yan, Yan] Texas State Univ, Dept Comp Sci, San Marcos, TX 78666 USA	University of California System; University of California Berkeley; Institute of Science & Technology - Austria; University of Trento; Northwestern University; Texas State University System; Texas State University San Marcos	Darrell, T (corresponding author), Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA.	trevor@eecs.berkeley.edu; chl@ist.ac.at; sebe@disi.unitn.it; yingwu@eecs.northwestern.edu; tom_yan@txstate.edu	Wu, Ying/B-7283-2009	Sebe, Niculae/0000-0002-6597-7248; Koochak, Atousa/0000-0001-6547-2728					0	0	0	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1029	1031		10.1109/TPAMI.2018.2804998	http://dx.doi.org/10.1109/TPAMI.2018.2804998			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB					2022-12-18	WOS:000428901200001
J	Kumar, S; Dhiman, V; Koch, PA; Corso, JJ				Kumar, Suren; Dhiman, Vikas; Koch, Parker A.; Corso, Jason J.			Learning Compositional Sparse Bimodal Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multimodal learning; compositional learning; symbol grounding; artificial intelligence; tabletop robotics; human-robot interaction	IMAGE SUPERRESOLUTION; DICTIONARY; REPRESENTATION; WORDS	Various perceptual domains have underlying compositional semantics that are rarely captured in current models. We suspect this is because directly learning the compositional structure has evaded these models. Yet, the compositional structure of a given domain can be grounded in a separate domain thereby simplifying its learning. To that end, we propose a new approach to modeling bimodal perceptual domains that explicitly relates distinct projections across each modality and then jointly learns a bimodal sparse representation. The resulting model enables compositionality across these distinct projections and hence can generalize to unobserved percepts spanned by this compositional basis. For example, our model can be trained on red triangles and blue squares; yet, implicitly will also have learned red squares and blue triangles. The structure of the projections and hence the compositional basis is learned automatically; no assumption is made on the ordering of the compositional elements in either modality. Although our modeling paradigm is general, we explicitly focus on a tabletop building-blocks setting. To test our model, we have acquired a new bimodal dataset comprising images and spoken utterances of colored shapes (blocks) in the tabletop setting. Our experiments demonstrate the benefits of explicitly leveraging compositionality in both quantitative and human evaluation studies.	[Kumar, Suren; Dhiman, Vikas; Koch, Parker A.; Corso, Jason J.] Univ Michigan, Elect Engn & Comp Sci Dept, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan	Kumar, S (corresponding author), Univ Michigan, Elect Engn & Comp Sci Dept, Ann Arbor, MI 48109 USA.	surenkum@umich.edu; dhiman@umich.edu; pakoch@umich.edu; jjcorso@umich.edu	ARSLAN, Okan/AAA-3232-2020; Dhiman, Vikas/AAS-3092-2021	Corso, Jason/0000-0001-6454-9594; Kumar, Suren/0000-0002-9706-2827; Dhiman, Vikas/0000-0003-0078-3677	National Science Foundation [NRI IIS 1522904]; Army Research Office [W911NF-15-1-0354]; University of Michigan College of Engineering	National Science Foundation(National Science Foundation (NSF)); Army Research Office; University of Michigan College of Engineering	We acknowledge the partial support for this work from the National Science Foundation NRI IIS 1522904, Army Research Office W911NF-15-1-0354, as well as the University of Michigan College of Engineering. We thank Julien Mairal and collaborators for their release of the SPAMS package (http://spams-devel.gforge.inria.fr/) as well as Niclas Borlin for his publicly available MATLAB implementation of the Hungarian algorithm (http://www.mathworks.com/matlabcentral/fileexchange/94-assignprob-zip).	Argyriou A., 2007, NIPS, V19, P41, DOI DOI 10.1007/S10994-007-5040-8; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Bahrampour S, 2014, PROC CVPR IEEE, P4114, DOI 10.1109/CVPR.2014.524; Barbu A., 2012, ARXIV12042742, P102; Barlow H., 1961, SENSORY COMMUNICATIO, P217; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Borgohain, 2010, INT J ASIAN LANG P, V20, P87; Chen D. L., 2011, P IEEE INT C ROB BIO, P7; Chen JH, 2012, ACM T KNOWL DISCOV D, V5, DOI 10.1145/2086737.2086742; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Das P, 2013, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2013.340; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; ELDER J, 1993, VISION RES, V33, P981, DOI 10.1016/0042-6989(93)90080-G; Fidler S., 2007, 2007 IEEE C COMP VIS, P1, DOI [10.1109/CVPR.2007.383269, DOI 10.1109/CVPR.2007.383269]; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; Gribonval R, 2015, IEEE T INFORM THEORY, V61, P3469, DOI 10.1109/TIT.2015.2424238; Jackendoff Ray S., 1983, SEMANTICS COGNITION; Knepper RA, 2013, ACMIEEE INT CONF HUM, P167, DOI 10.1109/HRI.2013.6483554; KNUDSEN EI, 1995, ANNU REV NEUROSCI, V18, P19, DOI 10.1146/annurev.ne.18.030195.000315; Koehn P, 2007, 45 ANN M ASS COMP LI, P177, DOI DOI 10.3115/1557769.1557821; Krishnamoorthy N., 2013, P WORKSHOP VISION NA, P10; KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Kumar S, 2014, AAAI CONF ARTIF INTE, P366; Kyriazis N, 2013, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2013.9; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Lewicki MS, 2002, NAT NEUROSCI, V5, P356, DOI 10.1038/nn831; Liu J., 2009, P 25 C UNCERTAINTY A, P339, DOI DOI 10.5555/1795114.1795154; Logan Beth, 2000, ISMIR, V270; MAIRAL J., 2009, P 26 ANN INT C MACH, P689, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]; Mairal J, 2012, FOUND TRENDS COMPUT, V8, DOI 10.1561/0600000058; Mairal J, 2010, J MACH LEARN RES, V11, P19; Matuszek Cynthia, 2012, P 29 INT C MACH LEAR, P1671; Mavridis N, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4690, DOI 10.1109/IROS.2006.282258; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Porway J., 2008, OBJECT CATEGORIZATIO, P241; Rosenberg A., 2007, P 2007 JOINT C EMP M, P410; Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1207/s15516709cog2601_4; Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109; Tellex S., 2011, P 25 AAAI C ART INT; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Vogt P., 2002, COGNITIVE SYSTEMS RE, V3, P429, DOI DOI 10.1016/S1389-0417(02)00051-7; Vondrick C, 2013, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2013.8; Walde S. S. im, 2013, EMNLP, P1146; Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930; Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340; Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yu H, 2013, PROCEEDINGS OF THE AMERICAN SOCIETY FOR COMPOSITES; Zhou J., 2011, MALSAR MULTI TASK LE; Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702	53	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1032	1044		10.1109/TPAMI.2017.2693987	http://dx.doi.org/10.1109/TPAMI.2017.2693987			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28422653	hybrid			2022-12-18	WOS:000428901200002
J	Dickinson, S				Dickinson, Sven			State of the Journal	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					1	6		10.1109/TPAMI.2017.2770038	http://dx.doi.org/10.1109/TPAMI.2017.2770038			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH					2022-12-18	WOS:000417806000001
J	Grauman, K; Learned-Miller, E; Torralba, A; Zisserman, A				Grauman, Kristen; Learned-Miller, Eric; Torralba, Antonio; Zisserman, Andrew			Guest Editorial: Best of CVPR 2015	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA; [Learned-Miller, Eric] CORITechs, Royal Oak, MI USA; [Learned-Miller, Eric] CVPR 2015, Boston, MA USA; [Torralba, Antonio] MIT, Brain & Cognit Sci Dept, Cambridge, MA 02139 USA; [Torralba, Antonio] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; [Torralba, Antonio] MIT, Elect Engn & Comp Sci, Cambridge, MA 02139 USA; [Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Oxford, England	University of Texas System; University of Texas Austin; Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); University of Oxford	Grauman, K (corresponding author), Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.								0	0	0	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					625	626		10.1109/TPAMI.2017.2663859	http://dx.doi.org/10.1109/TPAMI.2017.2663859			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD					2022-12-18	WOS:000397717600001
J	Dickinson, S				Dickinson, Sven			Incoming EIC Editorial	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Dickinson, Sven] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada	University of Toronto	Dickinson, S (corresponding author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.								0	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					3	4		10.1109/TPAMI.2016.2622418	http://dx.doi.org/10.1109/TPAMI.2016.2622418			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP					2022-12-18	WOS:000390421300002
J	Forsyth, DA				Forsyth, David A.			State of the Journal	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					1	2		10.1109/TPAMI.2016.2622398	http://dx.doi.org/10.1109/TPAMI.2016.2622398			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP					2022-12-18	WOS:000390421300001
J	Basri, R; Fermuller, C; Martinez, AM; Vidal, R				Basri, Ronen; Fermueller, Cornelia; Martinez, Aleix M.; Vidal, Rene			Special Section on CVPR 2014	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Basri, Ronen] MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA; [Basri, Ronen] MIT, Artificial Intelligence Lab, Cambridge, MA 02139 USA; [Basri, Ronen] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel; [Fermueller, Cornelia] Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA; [Martinez, Aleix M.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA; [Martinez, Aleix M.] Ohio State Univ, Computat Biol & Cognit Sci Lab, Columbus, OH 43210 USA; [Martinez, Aleix M.] Purdue Univ, Elect & Comp Engn Dept, W Lafayette, IN 47907 USA; [Martinez, Aleix M.] Sony Comp Sci Lab, Paris, France; [Vidal, Rene] ICCV 2015, Columbus, OH USA; [Vidal, Rene] CVPR 2014, Columbus, OH USA; [Vidal, Rene] PSIVT 2007, Santiago, Chile; [Vidal, Rene] MICCAI 2013 & 2014, Nagoya, Aichi, Japan	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Weizmann Institute of Science; University System of Maryland; University of Maryland College Park; University System of Ohio; Ohio State University; University System of Ohio; Ohio State University; Purdue University System; Purdue University; Purdue University West Lafayette Campus	Basri, R (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.								0	0	0	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1281	10.1109/TPAMI.2016.2560278	http://dx.doi.org/10.1109/TPAMI.2016.2560278			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DO6MH					2022-12-18	WOS:000377897100001
J	Freeman, WT; Szeliski, R; Hager, GD				Freeman, William T.; Szeliski, Richard; Hager, Gregory D.			Guest Editorial: Special Section on CVPR 2013	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Freeman, William T.] MIT, EECS, Cambridge, MA 02139 USA; [Freeman, William T.] Google, Comp Vis Res Grp, Cambridge, MA USA; [Szeliski, Richard] Facebook, Computat Photog Grp, Menlo Pk, CA 94025 USA; [Hager, Gregory D.] Johns Hopkins Univ, Comp Sci, Baltimore, MD 21218 USA; [Hager, Gregory D.] Malone Inst Engn Healthcare, Baltimore, MD 21218 USA	Massachusetts Institute of Technology (MIT); Google Incorporated; Facebook Inc; Johns Hopkins University	Freeman, WT (corresponding author), MIT, EECS, Cambridge, MA 02139 USA.; Freeman, WT (corresponding author), Google, Comp Vis Res Grp, Cambridge, MA USA.; Szeliski, R (corresponding author), Facebook, Computat Photog Grp, Menlo Pk, CA 94025 USA.; Hager, GD (corresponding author), Johns Hopkins Univ, Comp Sci, Baltimore, MD 21218 USA.; Hager, GD (corresponding author), Malone Inst Engn Healthcare, Baltimore, MD 21218 USA.	billf@mit.edu; szeliski@fb.com; hager@cs.jhu.edu							0	0	0	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					625	626		10.1109/TPAMI.2016.2529898	http://dx.doi.org/10.1109/TPAMI.2016.2529898			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	27403473				2022-12-18	WOS:000372549700001
J	Forsyth, DA				Forsyth, David A.			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					209	210		10.1109/TPAMI.2015.2507219	http://dx.doi.org/10.1109/TPAMI.2015.2507219			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI					2022-12-18	WOS:000369989600001
J	Mirzaei, H; Funt, B				Mirzaei, Hamidreza; Funt, Brian			Gaussian-Based Hue Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color; hue; Gaussian reflectance; wraparound Gaussian; color atlas		A robust and accurate hue descriptor that is useful in modeling human color perception and for computer vision applications is explored. The hue descriptor is based on the peak wavelength of a Gaussian-like function (called a wraparound Gaussian) and is shown to correlate as well as CIECAM02 hue to the hue designators of papers from the Munsell and Natural Color System color atlases and to the hue names found in Moroney's Color Thesaurus. The new hue descriptor is also shown to be significantly more stable under a variety of illuminants than CIECAM02. The use of wraparound Gaussians as a hue model is similar in spirit to the use of subtractive Gaussians proposed by Mizokami et al., but overcomes many of their limitations.	[Mirzaei, Hamidreza; Funt, Brian] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Simon Fraser University	Mirzaei, H (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	hmirzaei@sfu.ca; funt@sfu.ca	Mirzaee, Hamidreza/AAU-8999-2021		Natural Sciences and Engineering Research Council of Canada	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR)	This work was supported in part by the Natural Sciences and Engineering Research Council of Canada. B. Funt is the corresponding author of the article.	Berlin B., 1991, BASIC COLOR TERMS TH; CONN AR, 1991, SIAM J NUMER ANAL, V28, P545, DOI 10.1137/0728030; Finlayson G, 2012, P CIC 20 20 IS T COL, P265; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553; Funt B., 2011, P CIC 19 19 IS T COL, V2011, P166; Godau C, 2012, COLOR RES APPL, V37, P117, DOI 10.1002/col.20680; HARD A, 1981, COLOR RES APPL, V6, P129, DOI 10.1002/col.5080060303; Hunt RWG, 2011, WILEY-ISTE, P1, DOI 10.1002/9781119975595; Logvinenko A., 2015, RETHINKING COL UNPUB; Logvinenko AD, 2013, INT J COMPUT VISION, V101, P143, DOI 10.1007/s11263-012-0555-2; Logvinenko AD, 2011, SEEING PERCEIVING, V24, P407, DOI 10.1163/187847511X588746; Logvinenko AD, 2009, J VISION, V9, DOI 10.1167/9.11.5; MacLeod D. I., 2003, PERCEPTION MIND PHYS, P205; Mirzaei Hamidreza, 2013, Twenty-first Color and Imaging Conference. Color Science and Engineering Systems, Technologies, and Applications (CIC21). Proceedings, P75; Mirzaei H., 2013, AIC 2013 12 INT COL, P1133; Mirzaei H, 2014, J OPT SOC AM A, V31, P1680, DOI 10.1364/JOSAA.31.001680; Mizokami Y, 2006, J VISION, V6, P996, DOI 10.1167/6.9.12; Mizokami Y, 2012, J OPT SOC AM A, V29, pA10, DOI 10.1364/JOSAA.29.000A10; Moroney N, 2003, PROC SPIE, V5008, P36, DOI 10.1117/12.472013; Moroney N., 2002, P COL IM C, P23; Moroney N., 2008, THE COLOR THESAURUS; O'Neil SF, 2012, J OPT SOC AM A, V29, pA165, DOI 10.1364/JOSAA.29.00A165; U. of Joensuu Color Group, JOENS COL GROUP SPEC; WEINBERG JW, 1976, GEN RELAT GRAVIT, V7, P135, DOI 10.1007/BF00762021; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd; Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811; [No title captured]	27	0	1	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2441	2450		10.1109/TPAMI.2015.2420560	http://dx.doi.org/10.1109/TPAMI.2015.2420560			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539849	Green Published			2022-12-18	WOS:000364831700007
J	Harel, M; Mannor, S				Harel, Maayan; Mannor, Shie			The Perturbed Variation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Distributional similarity; distance; discrepancy; homogeneity testing		We introduce a new discrepancy measure between two distributions that gives an indication on their similarity. The new measure, termed the Perturbed Variation (PV), gives an intuitive interpretation of similarity; it optimally perturbs the distributions so that they best fit each other. The PV is defined between continuous and discrete distributions, and can be efficiently estimated from samples. We provide bounds on the convergence of the estimated score to its distributional value, as well as robustness analysis of the PV to outliers. A number of possible applications of the score are presented, and its ability to detect similarity is compared with that of other known measures on real data. We also present a new visual tracking algorithm based on the PV, and compare its performance with known tracking algorithms.	[Harel, Maayan; Mannor, Shie] Israel Inst Technol, Dept Elect Engn, Haifa, Israel	Technion Israel Institute of Technology	Harel, M (corresponding author), Israel Inst Technol, Dept Elect Engn, Haifa, Israel.	maayanga@tx.technion.ac.il; shie@ee.technion.ac.il		Mannor, Shie/0000-0003-4439-7647	Israel Science Foundation [920/12]	Israel Science Foundation(Israel Science Foundation)	This Research was supported in part by the Israel Science Foundation (grant No. 920/12).	Ahuja R., 1993, NETWORK FLOWS THEORY, V469-473; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Bischof H., 2006, BMVC, P47; Efron B, 1993, INTRO BOOTSTRAP, P178; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Frank J., 2010, DATA SETS MOBILE PHO; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; Kadous Mohammed Waleed, 2002, HIGH QUALITY RECORDI; Kifer Daniel, 2004, VLDB, DOI DOI 10.1016/B978-012088469-8/50019-X; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Monge G., 1781, MEMOIRES MATH PHYS M; Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895; Peter J.H, 2009, ROBUST STAT, V2nd; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; Ruschendorf L., 2007, JAHRESBERICHT DMV, V109, P113; SCHILLING MF, 1986, J AM STAT ASSOC, V81, P799, DOI 10.2307/2289012; Schrijver A., 1998, THEORY LINEAR INTEGE; Shao J., 2008, P 16 ACM INT C MULT, P429; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Weissman Tsachy, 2003, INEQUALITIES 11 DEVI; Wellek S., 2010, TESTING STAT HYPOTHE, DOI DOI 10.1201/EBK1439808184	23	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					2119	2130		10.1109/TPAMI.2015.2404836	http://dx.doi.org/10.1109/TPAMI.2015.2404836			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26353188				2022-12-18	WOS:000360813400013
J	Forsyth, D				Forsyth, David			State of the Journal	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					1	1		10.1109/TPAMI.2014.2370854	http://dx.doi.org/10.1109/TPAMI.2014.2370854			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML					2022-12-18	WOS:000346970600001
J	Kaul, V; Yezzi, A; Tsai, YC				Kaul, Vivek; Yezzi, Anthony; Tsai, Yichang (James)			Detecting Curves with Unknown Endpoints and Arbitary Topology Using Minimal Paths (vol 34, pg 1952, 2012)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction									[Kaul, Vivek] Junio Inc, 1971 Landings Dr, Mountain View, CA 94043 USA; [Yezzi, Anthony] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA; Georgia Inst Technol, Sch Civil & Environm Engn, Savannah, GA 31407 USA	University System of Georgia; Georgia Institute of Technology; University System of Georgia; Georgia Institute of Technology	Kaul, V (corresponding author), Junio Inc, 1971 Landings Dr, Mountain View, CA 94043 USA.	vkaul1@yahoo.com; ayezzi@ece.gatech.edu; james.tsai@ce.gatech.edu	Yezzi, Anthony/AAB-4235-2020					Kaul V, 2012, IEEE T PATTERN ANAL, V34, P1952, DOI 10.1109/TPAMI.2011.267	1	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3								10.1109/TPAMI.2014.22	http://dx.doi.org/10.1109/TPAMI.2014.22			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX					2022-12-18	WOS:000331450100001
J	Felzenszwalb, PF; Forsyth, DA; Fua, P; Boult, TE				Felzenszwalb, Pedro F.; Forsyth, David A.; Fua, Pascal; Boult, Terrance E.			TPAMI CVPR Special Section	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Felzenszwalb, Pedro F.] Brown Univ, Sch Engn, Providence, RI 02912 USA; [Felzenszwalb, Pedro F.] Brown Univ, Dept Comp Sci, Providence, RI 02912 USA; [Forsyth, David A.] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; [Fua, Pascal] Ecole Polytech Fed Lausanne, Sch Informat & Commun Sci, Lausanne, Switzerland; [Boult, Terrance E.] Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80918 USA	Brown University; Brown University; University of Illinois System; University of Illinois Urbana-Champaign; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; University of Colorado System; University of Colorado at Colorado Springs	Felzenszwalb, PF (corresponding author), Brown Univ, Sch Engn, Box D, Providence, RI 02912 USA.	pff@brown.edu; daf@illilnois.edu; pascal.fua@epfl.ch; tboutl@vast.uccs.edu	Boult, Terrance E./AAT-2134-2021	Boult, Terrance E./0000-0001-5007-2529; Fua, Pascal/0000-0002-6702-9970					0	0	0	3	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2819	2820		10.1109/TPAMI.2013.208	http://dx.doi.org/10.1109/TPAMI.2013.208			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV		Green Submitted, Bronze			2022-12-18	WOS:000326502200001
J	Flach, B				Flach, Boris			A Class of Random Fields on Complete Graphs with Tractable Partition Function	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields		The aim of this short note is to draw attention to a method by which the partition function and marginal probabilities for a certain class of random fields on complete graphs can be computed in polynomial time. This class includes Ising models with homogeneous pairwise potentials but arbitrary (inhomogeneous) unary potentials. Similarly, the partition function and marginal probabilities can be computed in polynomial time for random fields on complete bipartite graphs, provided they have homogeneous pairwise potentials. We expect that these tractable classes of large-scale random fields can be very useful for the evaluation of approximation algorithms by providing exact error estimates.	Czech Tech Univ, Fac Elect Engn, Prague 16627, Czech Republic	Czech Technical University Prague	Flach, B (corresponding author), Czech Tech Univ, Fac Elect Engn, Prague 16627, Czech Republic.				Grant Agency of the Czech Republic [P202/12/2071]	Grant Agency of the Czech Republic(Grant Agency of the Czech Republic)	The work of the author was supported by the Grant Agency of the Czech Republic, Project P202/12/2071. He would like to thank the reviewers, especially for the exceptionally thorough and favorable consideration that greatly helped to improve the original manuscript. The author wants to express his special gratitude to Tomas Werner for valuable discussions which were, as usual, strict and motivating.	Bulatov A, 2005, THEOR COMPUT SCI, V348, P148, DOI 10.1016/j.tcs.2005.09.011; Hazan T, 2010, IEEE T INFORM THEORY, V56, P6294, DOI 10.1109/TIT.2010.2079014; Lampert C.H., 2012, P WORKSH INF INT INF; Schraudolph N. N., 2009, ADV NEURAL INFORM PR, P1417; Wainwright MJ, 2006, IEEE T SIGNAL PROCES, V54, P2099, DOI 10.1109/TSP.2006.874409; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P2313, DOI 10.1109/TIT.2005.850091; [No title captured]	7	0	0	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2304	2306		10.1109/TPAMI.2013.99	http://dx.doi.org/10.1109/TPAMI.2013.99			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868787	Green Submitted			2022-12-18	WOS:000322029000019
J	Forsyth, DA				Forsyth, David A.			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1281	1281		10.1109/TPAMI.2013.79	http://dx.doi.org/10.1109/TPAMI.2013.79			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV					2022-12-18	WOS:000317857900001
J	Forsyth, D				Forsyth, David			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					257	257		10.1109/TPAMI.2013.13	http://dx.doi.org/10.1109/TPAMI.2013.13			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX					2022-12-18	WOS:000312560600001
J	Forsyth, DA				Forsyth, David A.			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					3	4		10.1109/TPAMI.2013.7	http://dx.doi.org/10.1109/TPAMI.2013.7			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV					2022-12-18	WOS:000311127700002
J	Zabih, R				Zabih, Ramin			Introduction of New Editor in Chief	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					1	2		10.1109/TPAMI.2013.8	http://dx.doi.org/10.1109/TPAMI.2013.8			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV					2022-12-18	WOS:000311127700001
J	Darrell, T; Hogg, D; Jacobs, D				Darrell, Trevor; Hogg, David; Jacobs, David			Special Editors' Introduction to the Special Issue on Award-Winning Papers from the IEEE Conference on Computer Vision and Pattern Recognition 2010 (CVPR 2010)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Darrell, Trevor] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94704 USA; [Darrell, Trevor] Int Comp Sci Inst, Berkeley, CA 94704 USA; [Hogg, David] Univ Leeds, Sch Comp, Leeds, W Yorkshire, England; [Jacobs, David] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	University of California System; University of California Berkeley; University of Leeds; University System of Maryland; University of Maryland College Park	Darrell, T (corresponding author), Univ Calif Berkeley, Div Comp Sci, 1947 Ctr St,Suite 600, Berkeley, CA 94704 USA.	trevor@eecs.berkeley.edu; d.c.hogg@leeds.ac.uk; djacobs@umiacs.umd.edu		Hogg, David/0000-0002-6125-9564					0	0	0	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1665	1666		10.1109/TPAMI.2012.153	http://dx.doi.org/10.1109/TPAMI.2012.153			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD					2022-12-18	WOS:000306409100001
J	Zabih, R; Kang, SB; Lawrence, N; Matas, J; Welling, M				Zabih, Ramin; Kang, Sing Bing; Lawrence, Neil; Matas, Jiri; Welling, Max			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material													, Matas/AAW-3282-2020						0	0	0	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					209	210		10.1109/TPAMI.2012.14	http://dx.doi.org/10.1109/TPAMI.2012.14			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ					2022-12-18	WOS:000298105500001
J	Zabih, R; Kang, SB; Matas, J; Welling, M				Zabih, Ramin; Kang, Sing Bing; Matas, Jiri; Welling, Max			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material													, Matas/AAW-3282-2020						0	0	0	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2337	2338		10.1109/TPAMI.2011.214	http://dx.doi.org/10.1109/TPAMI.2011.214			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE					2022-12-18	WOS:000295980000001
J	Arabadjis, D; Rousopoulos, P; Papaodysseus, C; Exarhos, M; Panagopoulos, M; Papazoglou-Manioudaki, L				Arabadjis, Dimitris; Rousopoulos, Panayiotis; Papaodysseus, Constantin; Exarhos, Michalis; Panagopoulos, Michail; Papazoglou-Manioudaki, Lena			Optimization in Differentiable Manifolds in Order to Determine the Method of Construction of Prehistoric Wall Paintings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Rotation and translation invariant curve fitting; pattern recognition in paintings; optimization in differentiable manifolds; geometric guides in prehistoric wall paintings; minimal parameters set for curve description; fitting prototype curves to drawn borders	CURVES; ALGORITHM; SURFACES	In this paper, a general methodology is introduced for the determination of potential prototype curves used for the drawing of prehistoric wall paintings. The approach includes 1) preprocessing of the wall-paintings contours to properly partition them, according to their curvature, 2) choice of prototype curves families, 3) analysis and optimization in 4-manifold for a first estimation of the form of these prototypes, 4) clustering of the contour parts and the prototypes to determine a minimal number of potential guides, and 5) further optimization in 4-manifold, applied to each cluster separately, in order to determine the exact functional form of the potential guides, together with the corresponding drawn contour parts. The methodology introduced simultaneously deals with two problems: 1) the arbitrariness in data-points orientation and 2) the determination of one proper form for a prototype curve that optimally fits the corresponding contour data. Arbitrariness in orientation has been dealt with a novel curvature based error, while the proper forms of curve prototypes have been exhaustively determined by embedding curvature deformations of the prototypes into 4-manifolds. Application of this methodology to celebrated wall paintings excavated at Tyrins, Greece, and the Greek island of Thera manifests that it is highly probable that these wall paintings were drawn by means of geometric guides that correspond to linear spirals and hyperbolae. These geometric forms fit the drawings' lines with an exceptionally low average error, less than 0.39 mm. Hence, the approach suggests the existence of accurate realizations of complicated geometric entities more than 1,000 years before their axiomatic formulation in the Classical Ages.	[Arabadjis, Dimitris; Rousopoulos, Panayiotis; Papaodysseus, Constantin; Exarhos, Michalis] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece; [Panagopoulos, Michail] Ionian Univ, Dept Audio & Visual Arts, Corfu 49100, Greece; [Papazoglou-Manioudaki, Lena] Natl Archaeol Museum Greece, Athens 10682, Greece	National Technical University of Athens; Ionian University	Arabadjis, D (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Iroon Polytech 9, GR-15773 Athens, Greece.	alphad.d@gmail.com; panrous@gmail.com; cpapaod@cs.ntua.gr; mexarhos@mail.ntua.gr; mpanagop@ionio.gr; mann@otenet.gr	Exarhos, Mihalis/AAQ-4363-2021; Arabadjis, Dimitris/F-2974-2012; Arabadjis, Dimitris/AAS-4975-2021; Papaodysseus, Constantin/AAI-6900-2020	Arabadjis, Dimitris/0000-0002-8438-0471; Arabadjis, Dimitris/0000-0002-8438-0471; Panagopoulos, Michail/0000-0003-4585-8185; Papaodysseus, Constantin/0000-0002-5238-5833				Ahn SJ, 2002, IEEE T PATTERN ANAL, V24, P620, DOI 10.1109/34.1000237; Ahn SJ, 2001, PATTERN RECOGN, V34, P2283, DOI 10.1016/S0031-3203(00)00152-7; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BIRTACHA K, 1997, P 1 INT S WALL PAINT, P159; Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; Chernov N, 2004, COMPUT STAT DATA AN, V47, P713, DOI 10.1016/j.csda.2003.11.008; Doumas C. D, 1992, WALL PAINTINGS THERA; Flory S, 2008, COMPUT AIDED DESIGN, V40, P25, DOI 10.1016/j.cad.2007.01.012; Immerwahr S., 1990, AEGEAN PAINTING BRON; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; KATANI K, 1998, ELSEVIER GRAPHICAL M, V60, P93; KATZ VJ, 1997, MATH MAG, V52, P146; Papaodysseus C, 2005, IEEE T IMAGE PROCESS, V14, P862, DOI 10.1109/TIP.2005.849297; Papaodysseus C, 2006, IEEE T PATTERN ANAL, V28, P1361, DOI 10.1109/TPAMI.2006.183; Sener S, 2004, LECT NOTES COMPUT SC, V3211, P344; Spira A, 2005, LECT NOTES COMPUT SC, V3459, P492; SPIRA A, 2008, COMPUTATIONAL AESTHE, P123; TAUBIN G, 1994, IEEE T PATTERN ANAL, V16, P287, DOI 10.1109/34.276128; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273	19	0	0	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2229	2244		10.1109/TPAMI.2011.65	http://dx.doi.org/10.1109/TPAMI.2011.65			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Engineering	820MM	21422489	Green Submitted			2022-12-18	WOS:000294910000009
J	Zabih, R; Kang, SB; Matas, J; Welling, M				Zabih, Ramin; Kang, Sing Bing; Matas, Jiri; Welling, Max			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Welling, Max] Univ Calif Irvine, Dept Stat, Irvine, CA 92717 USA	University of California System; University of California Irvine			, Matas/AAW-3282-2020						0	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2129	2130		10.1109/TPAMI.2011.189	http://dx.doi.org/10.1109/TPAMI.2011.189			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM					2022-12-18	WOS:000294910000001
J	Zabih, R; Ghahramani, Z; Kang, SB; Matas, J				Zabih, Ramin; Ghahramani, Zoubin; Kang, Sing Bing; Matas, Jiri			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material													, Matas/AAW-3282-2020						0	0	0	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					865	866		10.1109/TPAMI.2011.60	http://dx.doi.org/10.1109/TPAMI.2011.60			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF					2022-12-18	WOS:000288677800001
J	Zhang, Y; Chu, CHH				Zhang, Yun; Chu, Chee-Hung Henry			Ray Projection for Recovering Projective Transformations and Illumination Changes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image matching; image motion analysis; lighting change; projective transformation; stereo vision	IMAGE REGISTRATION; AFFINE; SCALE; SHAPE	The ray projection and its application to recovering a projective geometric transformation and an affine lighting change between two objects are mathematically studied. A novel technique, viz., variable contour, is proposed for accurately evaluating the ray projection. Moreover, a novel flexible framework of the ray projection is devised for the joint recovery of the eight parameters for the projective transformation and the two parameters for the lighting change. Finally, the framework is experimentally evaluated by recovering a variety of geometric and photometric transformations between real images of indoor and outdoor scenes. Its robustness to image blur and occlusion is demonstrated. Its versatility is illustrated through matching different objects in different classes.	[Zhang, Yun; Chu, Chee-Hung Henry] Univ Louisiana Lafayette, Ctr Adv Comp Studies, Lafayette, LA 70504 USA	University of Louisiana Lafayette	Zhang, Y (corresponding author), Univ Louisiana Lafayette, Ctr Adv Comp Studies, Lafayette, LA 70504 USA.	yxz2646@cacs.louisiana.edu; cice@cacs.louisiana.edu		Chu, Cheehung/0000-0002-5817-8798	Louisiana Governor's Information Technology Initiative	Louisiana Governor's Information Technology Initiative	The authors wish to thank the reviewers for their comments and suggestions that led to improvements of the manuscript. This work was supported in part by the Louisiana Governor's Information Technology Initiative.	Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899; BRACEWELL NR, 1995, 2 DIMENSIONAL IMAGIN, P505; BRACEWELL RN, 1993, ELECTRON LETT, V29, P304, DOI 10.1049/el:19930207; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Criminisi A, 1999, IMAGE VISION COMPUT, V17, P625, DOI 10.1016/S0262-8856(98)00183-8; GOLUB GH, 1996, MATRIX COMPUTATIONS, P556; Guo YL, 2007, IEEE T PATTERN ANAL, V29, P824, DOI 10.1109/TPAMI.2007.1052; Hartley R., 2003, MULTIPLE VIEW GEOMET; Kadyrov A, 2001, IEEE T PATTERN ANAL, V23, P811, DOI 10.1109/34.946986; Kadyrov A, 2006, IEEE T PATTERN ANAL, V28, P1631, DOI 10.1109/TPAMI.2006.198; Kak AC., 1988, PRINCIPLES COMPUTERI, P49; Kruger SA, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P113, DOI 10.1109/ICIP.1996.559445; LI H, 1995, IEEE T IMAGE PROCESS, V4, P320, DOI 10.1109/83.366480; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; Lindeberg T, 1997, IMAGE VISION COMPUT, V15, P415, DOI 10.1016/S0262-8856(97)01144-X; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucchese L, 2001, COMPUT VIS IMAGE UND, V81, P72, DOI 10.1006/cviu.2000.0885; Malik J, 1997, INT J COMPUT VISION, V23, P149, DOI 10.1023/A:1007958829620; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; NOVIKOFF ABJ, 1961, T U ILL S SELF ORG, P347; Petrou M, 2004, IEEE T PATTERN ANAL, V26, P30, DOI 10.1109/TPAMI.2004.1261077; Wang Y, 2007, IEEE T PATTERN ANAL, V29, p1853A, DOI 10.1109/TPAMI.2007.1135; Xia MH, 2004, IEEE T IMAGE PROCESS, V13, P720, DOI 10.1109/TIP.2003.822611; Yang GH, 2007, IEEE T PATTERN ANAL, V29, P1973, DOI [10.1109/TPAMI.2007.1116, 10.1109/TPAMl.2007.1116.]; ZHANG Y, 2007, P IEEE INT C AC SPEE, V1, P1021, DOI DOI 10.1109/ICASSP.2007.366084; Zhang Y., 2008, P IEEE IFIP EUC, V1, P1; Zokai S, 2005, IEEE T IMAGE PROCESS, V14, P1422, DOI 10.1109/TIP.2005.854501	28	0	0	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					446	458		10.1109/TPAMI.2010.96	http://dx.doi.org/10.1109/TPAMI.2010.96			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	20421666				2022-12-18	WOS:000286204700002
J	Zhao, M; Chung, CKR				Zhao, Ming; Chung, Chi-Kit Ronald			Rank Classification of Linear Line Structures from Images by Trifocal Tensor Determinability	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Line structure; critical configurations; trifocal tensor	3 VIEWS; RECONSTRUCTION; MOTION	The problem we address is: Given line correspondences over three views, what is the condition of the line correspondences for the spatial relation of the three associated camera positions to be uniquely recoverable? The observed set of lines in space is called critical if there are multiple projectively nonequivalent configurations of the camera positions that can picture the same image triplet of the lines. We tackle the problem from the perspective of trifocal tensor, a quantity that captures the relative pose of the cameras in relation to the captured views. We show that the rank of a matrix that leads to the estimation of the tensor is reduced to 7, 11, 15 if the observed lines come from a line pencil, a line bundle, and a line field, respectively, which are line families belonging to linear line space; and 12, 19, 23 if the lines come from a general linear ruled surface, a general linear line congruence, and a general linear line complex, which are subclasses of linear line structures. We show that the above line structures, with the exception of linear line congruence and linear line complex, ought to be critical line structures. All of these structures are quite typical in reality, and thus, the findings are important to the validity and stability of practically all algorithms related to structure from motion and projective reconstruction using line correspondences.	[Zhao, Ming; Chung, Chi-Kit Ronald] Chinese Univ Hong Kong, Dept Mech & Automat Engn, Hong Kong, Hong Kong, Peoples R China	Chinese University of Hong Kong	Zhao, M (corresponding author), Chinese Univ Hong Kong, Dept Mech & Automat Engn, Hong Kong, Hong Kong, Peoples R China.	mzhao@mae.cuhk.edu.hk; rchung@mae.cuhk.edu.hk	Chung, Chi-Kit Ronald/C-7702-2011		Research Grants Council of the Hong Kong Special Administrative Region, China [CUHK4195/04E]	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council)	The work described in this paper was partially supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. CUHK4195/04E). This work is affiliated with the Microsoft-CUHK Joint Laboratory for Human-centric Computing and Interface Technologies.	Bartoli A, 2005, COMPUT VIS IMAGE UND, V100, P416, DOI 10.1016/j.cviu.2005.06.001; Bartoli A, 2004, INT J COMPUT VISION, V57, P159, DOI 10.1023/B:VISI.0000013092.07433.82; Bartoli A, 2003, PROC CVPR IEEE, P477; BUCHANAN T, 1992, GEOMETRIAE DEDICATA, V44, P223; BUCHANAN T, 1992, P 2 EUR C COMP VIS S, P730; FAUGERAS O, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P951, DOI 10.1109/ICCV.1995.466832; Hartley R, 2003, PROC CVPR IEEE, P511; Hartley R., 2004, ROBOTICA; Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022; HARTLEY RI, 2000, P 6 EUR C COMP VIS D, P922; Hartley R, 2007, INT J COMPUT VISION, V71, P5, DOI 10.1007/s11263-005-4796-1; Kahl F, 2001, PROC CVPR IEEE, P158; Leung M. K., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P62, DOI 10.1109/WVM.1991.212787; LIU Y, 1988, P 9 INT C PATT REC, V1, P213; LIU Y, 1990, THESIS U ILLINOIS UR; MAYBANK SJ, 1993, APPL ALGEBR ENG COMM, V6, P89; Navab N., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P254, DOI 10.1109/CVPR.1993.340981; Navab N, 1997, INT J COMPUT VISION, V23, P17, DOI 10.1023/A:1007911807871; PAPADOPOULO T, 1998, P 5 EUR C COMP VIS, V1, P109; Pottmann Helmut, 2001, MATH VISUAL, V2; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; Shashua A., 1995, P INT C COMP VIS; SHASHUA A, 1996, DEGENERATE N POINT C; Stein GP, 1999, IEEE T PATTERN ANAL, V21, P244, DOI 10.1109/34.754590; Strang G., 2003, INTRO LINEAR ALGEBRA, DOI 10.4324/9780203788219; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P318, DOI 10.1109/34.120327	26	0	0	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1197	1210		10.1109/TPAMI.2009.103	http://dx.doi.org/10.1109/TPAMI.2009.103			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489224				2022-12-18	WOS:000277649100004
J	Zabih, R				Zabih, Ramin			The 30th Anniversary of the IEEE Transactions on Pattern Analysis and Machine Intelligence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material														Zabih, Ramin/0000-0001-8769-5666					0	0	0	4	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					1	1		10.1109/TPAMI.2010.8	http://dx.doi.org/10.1109/TPAMI.2010.8			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ					2022-12-18	WOS:000271826700001
J	Boyer, K; Shah, M; Syeda-Mahmood, T				Boyer, Kim; Shah, Mubarak; Syeda-Mahmood, Tanveer			Guest Editors' Introduction to the Special Section on Award Winning Papers from the IEEE CS Conference on Computer Vision and Pattern Recognition (CVPR)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Boyer, Kim] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA; [Shah, Mubarak] Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA; [Syeda-Mahmood, Tanveer] IBM Almaden Res Ctr, San Jose, CA 95120 USA	Rensselaer Polytechnic Institute; State University System of Florida; University of Central Florida; International Business Machines (IBM)	Boyer, K (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, 110 8th St JEC 6049, Troy, NY 12180 USA.	kim@ecse.rpi.edu; shah@cs.ucf.edu; stf@almaden.ibm.com		Shah, Mubarak/0000-0001-6172-5572					0	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2113	2114		10.1109/TPAMI.2009.182	http://dx.doi.org/10.1109/TPAMI.2009.182			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY					2022-12-18	WOS:000271140100001
J	Dang, EKF; Luk, RWP; Lee, DL; Ho, KS; Chan, SCF				Dang, Edward K. F.; Luk, Robert W. P.; Lee, D. L.; Ho, K. S.; Chan, Stephen C. F.			Optimal Combination of Nested Clusters by a Greedy Approximation Algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering; classification; performance evaluation; optimization		Given a set of clusters, we consider an optimization problem which seeks a subset of clusters that maximizes the microaverage F-measure. This optimal value can be used as an evaluation measure of the goodness of clustering. For arbitrarily overlapping clusters, finding the optimal value is NP-hard. We claim that a greedy approximation algorithm yields the global optimal solution for clusters that overlap only by nesting. We present a mathematical proof of this claim by induction. For a family of n clusters containing a total of N objects, this algorithm has an O(n(2)) time complexity and O(N) space complexity.	[Dang, Edward K. F.; Luk, Robert W. P.; Ho, K. S.; Chan, Stephen C. F.] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China; [Lee, D. L.] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	Hong Kong Polytechnic University; Hong Kong University of Science & Technology	Dang, EKF (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.	cskfdang@comp.polyu.edu.hk; csrluk@comp.polyu.edu.hk; dlee@cse.ust.hk; csksho@comp.polyu.edu.hk; csschan@comp.polyu.edu.hk	Luk, Robert/B-9382-2015	Luk, Robert/0000-0002-9310-8867; Lee, Dik Lun/0000-0002-2413-3882; CHAN, Chi Fai Stephen/0000-0003-0985-1074				Carpineto C, 1996, MACH LEARN, V24, P95; Carr RD, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P345; CROFT WB, 1980, INFORM SYST, V5, P189, DOI 10.1016/0306-4379(80)90010-1; Dang EKF, 2008, J AM SOC INF SCI TEC, V59, P390, DOI 10.1002/asi.20745; Gao BJ, 2006, SIAM PROC S, P464; HANSEN P, 1991, MATH PROGRAM, V52, P255, DOI 10.1007/BF01582890; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JARDINE N, 1971, INFORM STORAGE RET, V7, P217, DOI 10.1016/0020-0271(71)90051-9; Judd D, 1998, IEEE T PATTERN ANAL, V20, P871, DOI 10.1109/34.709614; Koshman S, 2006, J AM SOC INF SCI TEC, V57, P1875, DOI 10.1002/asi.20408; Larsen, 1999, P 5 ACM SIGKDD INT C, P16, DOI [DOI 10.1145/312129.312186, 10.1145/312129.312186]; PELEG D, 2000, P SCAND WORKSH ALG T, P220; ROBILLARD P, 1971, NAV RES LOGIST Q, V18, P47, DOI 10.1002/nav.3800180104; Sieberts S, 2008, INT J TOMOGRAPHY STA, V8, P1; Tombros A, 2002, INFORM PROCESS MANAG, V38, P559, DOI 10.1016/S0306-4573(01)00048-6; Wang XF, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P515, DOI 10.1109/ICMLC.2002.1176809; WILLETT P, 1988, INFORM PROCESS MANAG, V24, P577, DOI 10.1016/0306-4573(88)90027-1	18	0	0	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					2083	2087		10.1109/TPAMI.2009.75	http://dx.doi.org/10.1109/TPAMI.2009.75			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	493VV	19762933				2022-12-18	WOS:000269767600012
J	Liu, JZ; Cao, LL; Li, ZG; Tang, XO				Liu, Jianzhuang; Cao, Liangliang; Li, Zhenguo; Tang, Xiaoou			Responses to the Comments on "Plane-Based Optimization for 3D Object Reconstruction from Single Line Drawings"	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; degree of reconstruction freedom; line drawings; singular value decomposition		We disagree with the comments made by Varley [1] on our previous paper [2]. In this paper, we respond to his comments and show that they are not correct.	[Liu, Jianzhuang; Li, Zhenguo; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China; [Cao, Liangliang] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA	Chinese University of Hong Kong; University of Illinois System; University of Illinois Urbana-Champaign	Liu, JZ (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.	jzliu@ie.cuhk.edu.hk; cao4@uiuc.edu; zgli@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012					Ge JX, 1999, COMPUT AIDED DESIGN, V31, P867, DOI 10.1016/S0010-4485(99)00074-3; Grimstead I. J., 1995, Proceedings. Third Symposium on Solid Modeling and Applications, P323, DOI 10.1145/218013.218082; Kumar AV, 2001, COMPUT AIDED DESIGN, V33, P475, DOI 10.1016/S0010-4485(00)00098-1; Langbein FC, 2004, COMPUT AIDED DESIGN, V36, P261, DOI 10.1016/S0010-4485(03)00108-8; LECLERC YG, 1992, INT J COMPUT VISION, V9, P113, DOI 10.1007/BF00129683; Li YT, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P118, DOI 10.1109/PCCGA.2001.962864; Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X; Liu JZ, 2008, IEEE T PATTERN ANAL, V30, P315, DOI 10.1109/TPAMI.2007.1172; Liu JZ, 2001, IEEE T PATTERN ANAL, V23, P1106; Sugihara K, 1999, DISCRETE COMPUT GEOM, V21, P243, DOI 10.1007/PL00009419; VARLEY PAC, 2009, IEEE T PATTERN ANAL, V31	11	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1726	1728		10.1109/TPAMI.2009.118	http://dx.doi.org/10.1109/TPAMI.2009.118			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD					2022-12-18	WOS:000267369800016
J	Varley, PAC				Varley, Peter A. C.			Comments on "Plane-Based Optimization for 3D Object Reconstruction from Single Line Drawings"	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D object reconstruction; geometric degrees of freedom; line drawing interpretation		I comment on a paper describing a method for inflating a 2D wireframe topological representation of an object to 3D. There are several problems with this paper and the method it describes. An oversimplified problem statement and concentration on mathematical ingenuity rather than comprehension lead the authors to develop a method which is not well-suited to the problem. Failure to take proper account of previous work leads them to compare their method, not with the true state of the art, but with older, less successful approaches. Finally, they omit entirely any mention of, let alone a proposed solution to, the most intractable problem in the area, that of finding resolution sequences.	Univ Jaume 1, Dept Mech Engn & Construct, E-12071 Castellon de La Plana, Spain	Universitat Jaume I	Varley, PAC (corresponding author), Univ Jaume 1, Dept Mech Engn & Construct, E-12071 Castellon de La Plana, Spain.	varley@emc.uji.es		Varley, Peter/0000-0003-4181-9234				BAUER L, 1971, HDB AUTOMATIC COMPUT, V2, P119; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Gao XS, 2006, COMPUT AIDED DESIGN, V38, P1, DOI 10.1016/j.cad.2005.03.002; Ge JX, 1999, COMPUT AIDED DESIGN, V31, P867, DOI 10.1016/S0010-4485(99)00074-3; GRIMSTEAD I, 1997, THESIS CARDIFF U; Grimstead I. J., 1995, Proceedings. Third Symposium on Solid Modeling and Applications, P323, DOI 10.1145/218013.218082; HOFFMANN CM, 1998, GEOMETRIC CONSTRAINT, P170; Hopcroft J. E., 1973, SIAM Journal on Computing, V2, P135, DOI 10.1137/0202012; Kumar AV, 2001, COMPUT AIDED DESIGN, V33, P475, DOI 10.1016/S0010-4485(00)00098-1; Langbein FC, 2004, COMPUT AIDED DESIGN, V36, P261, DOI 10.1016/S0010-4485(03)00108-8; Li YT, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P118, DOI 10.1109/PCCGA.2001.962864; Liu JZ, 2008, IEEE T PATTERN ANAL, V30, P315, DOI 10.1109/TPAMI.2007.1172; Sugihara K, 1999, DISCRETE COMPUT GEOM, V21, P243, DOI 10.1007/PL00009419; Varley PAC., 2003, THESIS CARDIFF U DEP	14	0	0	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1723	1725		10.1109/TPAMI.2008.262	http://dx.doi.org/10.1109/TPAMI.2008.262			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD	19574631				2022-12-18	WOS:000267369800015
J	Cao, LL; Liu, JZ; Tang, XO				Cao, Liangliang; Liu, Jianzhuang; Tang, Xiaoou			Responses to the Comments on "What the Back of the Object Looks Like: 3D Reconstruction from Line Drawings without Hidden Lines"	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material						3D reconstruction; hidden topology; line drawings; visual perception		Varley [1] made comments on our paper in [2] section by section. We answer them in this response paper.	[Cao, Liangliang] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA; [Liu, Jianzhuang; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China	University of Illinois System; University of Illinois Urbana-Champaign; Chinese University of Hong Kong	Cao, LL (corresponding author), Univ Illinois, Dept Elect & Comp Engn, 1406 W Green St, Urbana, IL 61801 USA.	cao4@uiuc.edu; jzliu@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012					Cao LL, 2008, IEEE T PATTERN ANAL, V30, P507, DOI 10.1109/TPAMI.2007.1185; Cao LL, 2005, IEEE I CONF COMP VIS, P272; Grimstead I. J., 1995, Proceedings. Third Symposium on Solid Modeling and Applications, P323, DOI 10.1145/218013.218082; Liu JZ, 2008, IEEE T PATTERN ANAL, V30, P315, DOI 10.1109/TPAMI.2007.1172; Varley PAC, 2005, COMPUT AIDED DESIGN, V37, P1285, DOI 10.1016/j.cad.2005.01.002; VARLEY PAC, 2000, P 1 KOR UK JOINT WOR, P129; Varley PAC., 2003, THESIS CARDIFF U DEP; Varley PAC, 2009, IEEE T PATTERN ANAL, V31, P1532, DOI 10.1109/TPAMI.2008.159	8	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1535	1536		10.1109/TPAMI.2009.58	http://dx.doi.org/10.1109/TPAMI.2009.58			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542587				2022-12-18	WOS:000267050600017
J	Lian, H				Lian, Heng			Bayesian Nonlinear Principal Component Analysis Using Random Fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; Gibbs sampling; Markov random field; principal component analysis		We propose a novel model for nonlinear dimension reduction motivated by the probabilistic formulation of principal component analysis. Nonlinearity is achieved by specifying different transformation matrices at different locations of the latent space and smoothing the transformation using a Markov random field type prior. The computation is made feasible by the recent advances in sampling from von Mises-Fisher distributions. The computational properties of the algorithm are illustrated through simulations as well as an application to handwritten digits data.	Nanyang Technol Univ, Sch Math & Phys Sci, Div Math Sci, Singapore 637371, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Lian, H (corresponding author), Nanyang Technol Univ, Sch Math & Phys Sci, Div Math Sci, Singapore 637371, Singapore.	henglian@ntu.edu.sg	Lian, Heng/J-6300-2012	Lian, Heng/0000-0002-6008-6614				BISHOP CM, 1993, NUCL INSTRUM METH A, V327, P580, DOI 10.1016/0168-9002(93)90728-Z; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; HOFF P, 2007, SIMULATION MATRIX BI; Hoff PD, 2007, J AM STAT ASSOC, V102, P674, DOI 10.1198/016214506000001310; KRAMER MA, 1991, PROBABILISTIC PRINCI, P233; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; LAWRENCE ND, 2007, P 11 INT C ART INT S; Li S., 1995, MARKOV RANDOM FIELD, P1; Liu JS, 2003, BAYESIAN STATISTICS 7, P249; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Webb AR, 1996, STAT COMPUT, V6, P159, DOI 10.1007/BF00162527; Winkler G., 2003, IMAGE ANAL RANDOM FI	15	0	0	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					749	754		10.1109/TPAMI.2008.212	http://dx.doi.org/10.1109/TPAMI.2008.212			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407WX	19229089				2022-12-18	WOS:000263396100014
J	Zabih, R				Zabih, Ramin			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					3	4		10.1109/TPAMI.2009.6	http://dx.doi.org/10.1109/TPAMI.2009.6			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI					2022-12-18	WOS:000260889700001
J	Baker, S; Matas, J; Zabih, R				Baker, Simon; Matas, Jiri; Zabih, Ramin			Guest editors' introduction to the special section on CVPR papers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Baker, Simon] Microsoft Res, Redmond, WA 98052 USA; [Matas, Jiri] Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Ctr Machine Percept, Prague 16627 6, Czech Republic; [Zabih, Ramin] Cornell Univ, Dept Comp Sci, Ithaca, NY 14583 USA	Microsoft; Czech Technical University Prague; Cornell University	Baker, S (corresponding author), Microsoft Res, 1 Microsoft Way, Redmond, WA 98052 USA.	sbaker@microsoft.com; matas@cmp.felk.cvut.cz; rdz@cs.cornell.edu	, Matas/AAW-3282-2020	Zabih, Ramin/0000-0001-8769-5666					0	0	0	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1681	1682		10.1109/TPAMI.2008.209	http://dx.doi.org/10.1109/TPAMI.2008.209			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	336DQ		Green Submitted			2022-12-18	WOS:000258344900001
J	Kriegman, DJ; Fleet, D; Ghahramani, Z				Kriegman, David J.; Fleet, David; Ghahramani, Zoubin			Introduction of new associate editors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					561	561		10.1109/TPAMI.2008.43	http://dx.doi.org/10.1109/TPAMI.2008.43			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY					2022-12-18	WOS:000253135600001
J	Kriegman, DJ; Fleet, D				Kriegman, David J.; Fleet, David			State of the transactions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					193	194		10.1109/TPAMI.2007.34	http://dx.doi.org/10.1109/TPAMI.2007.34			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV					2022-12-18	WOS:000242826900001
J	Kriegman, DJ; Fleet, D				Kriegman, DJ; Fleet, D			Introduction of new associate editors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1185	1186		10.1109/TPAMI.2006.164	http://dx.doi.org/10.1109/TPAMI.2006.164			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK					2022-12-18	WOS:000238162400001
J	Kriegman, DJ; Fleet, D				Kriegman, DJ; Fleet, D			Editorial - State of the transactions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material												tpami@computer.org							0	0	0	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					177	177		10.1109/TPAMI.2006.35	http://dx.doi.org/10.1109/TPAMI.2006.35			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY					2022-12-18	WOS:000233824500001
J	Bitouk, D; Miller, MI; Younes, L				Bitouk, D; Miller, MI; Younes, L			Clutter invariant ATR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						riemannian metrics; deformable templates; Automated Target Recognition (ATR)	MODELS	One of the central problems in Automated Target Recognition is to accommodate the infinite variety of clutter in real military environments. The principle focus of our paper is on the construction of metric spaces where the metric measures the distance between objects of interest invariant to the infinite variety of clutter. Such metrics are formulated using second-order random field models. Our results indicate that this approach significantly improves detection/ classification rates of targets in clutter.	Johns Hopkins Univ, Whiting Sch Engn, Ctr Imaging Sci, Baltimore, MD 21218 USA	Johns Hopkins University	Bitouk, D (corresponding author), Johns Hopkins Univ, Whiting Sch Engn, Ctr Imaging Sci, 3400 N Charles St, Baltimore, MD 21218 USA.	dima@cis.jhu.edu; mim@cis.jhu.edu; younes@cis.jhu.edu	Miller, Michael I./A-3213-2010; Younes, E. Laurent/A-3349-2010	Younes, Laurent/0000-0003-2017-9565				BELHUMEUR PN, 1996, P EUR C COMP VIS, P45; Chellappa R., 1985, PATTERN RECOGNITION, V2, P79; Cooper ML, 2000, IEEE T INFORM THEORY, V46, P1896, DOI 10.1109/18.857799; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; Grenander U, 2001, IEEE T PATTERN ANAL, V23, P424, DOI 10.1109/34.917579; HUANG J, 1999, IEEE C COMP VIS PATT, P541; KELLY EJ, 1986, IEEE T AERO ELEC SYS, V22, P115, DOI 10.1109/TAES.1986.310745; Miller MI, 2001, INT J COMPUT VISION, V41, P61, DOI 10.1023/A:1011161132514; SCHARF LL, 1994, IEEE T SIGNAL PROCES, V42, P2146, DOI 10.1109/78.301849; Van Trees H., 2013, DETECTION ESTIMATION; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	12	0	1	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					817	821		10.1109/TPAMI.2005.97	http://dx.doi.org/10.1109/TPAMI.2005.97			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875803				2022-12-18	WOS:000227569300015
J	Caglioti, V				Caglioti, V			Minimal representations of 3D models in terms of image parameters under calibrated and uncalibrated perspective	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; indexing; 3D point sets; perspective; uncalibrated perspective; minimum-dimensional representations; curved objects	OBJECT RECOGNITION; INVARIANTS	Indexing is a well-known paradigm for object recognition. In indexing, each 3D model is represented as the set of values assumed by a given vector of image parameters in correspondence to all the possible images of the 3D model. An open problem, posed by Jacobs [12], concerned the minimum dimensionality of such sets under perspective. This paper proves that, under calibrated or uncalibrated perspective, the minimum dimensionality of the set representing any 3D modeled point-set is two. Two-dimensional representations are found also for 3D curved objects.	Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy	Polytechnic University of Milan	Caglioti, V (corresponding author), Politecn Milan, Dipartimento Elettron & Informaz, Pza Leonardo da Vinci 32, I-20133 Milan, Italy.	Vincenzo.Caglioti@Polimi.It		Caglioti, Vincenzo/0000-0003-2741-7474				Beis JS, 1999, IEEE T PATTERN ANAL, V21, P1000, DOI 10.1109/34.799907; BREUEL TM, 1993, 9308 IDIAP; Burns B., 1992, GEOMETRIC INVARIANCE; BURNS JB, 1993, IEEE T PATTERN ANAL, V15; CAGLIOTI V, 2000, P IEEE C COMP VIS PA; CLARSSON S, 1998, INT J COMPUT VISION, V27, P1; CLEMENS D, 1991, IEEE T PATTERN ANAL, V13; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; JACOBS D, 1992, IEEE C COMP VIS PATT, P439; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P330, DOI 10.1109/34.485561; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; MOSES Y, 1992, P EUR C COMP VIS; TSAI FCD, 1994, PATTERN RECOGNITION, V27; VIJAYAKUMAR B, 1995, P INT C COMP VIS; Weinshall D, 1999, J MATH IMAGING VIS, V10, P75, DOI 10.1023/A:1008326801364; WEINSHALL D, 1993, INT J COMPUT VISION, V10, P27, DOI 10.1007/BF01440845	18	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1234	1238		10.1109/TPAMI.2004.69	http://dx.doi.org/10.1109/TPAMI.2004.69			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742898				2022-12-18	WOS:000222605100012
J	Chellappa, R; Kriegman, DJ				Chellappa, R; Kriegman, DJ			In memoriam, Azriel Rosenfeld (1931-2004)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Biographical-Item													Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012						0	0	0	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					673	673						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EZ					2022-12-18	WOS:000220756500001
J	Figueiredo, MAT; Hancock, ER; Pelillo, M; Zerubia, J				Figueiredo, MAT; Hancock, ER; Pelillo, M; Zerubia, J			Guest editors' introduction to the special section on Energy Minimization Methods in Computer Vision and Pattern Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									Inst Super Tecn, Inst Telecommun, P-1049001 Lisbon, Portugal; Inst Super Tecn, Dept Elect & Comp Engn, P-1049001 Lisbon, Portugal; Univ York, Dept Comp Sci, York O10 5DD, N Yorkshire, England; Univ Ca Foscari Venezia, Dipartimento Informat, I-30172 Venice, Italy; INRIA, F-06902 Sophia Antipolis, France	Instituto de Telecomunicacoes; Universidade de Lisboa; Instituto Superior Tecnico; Universidade de Lisboa; Instituto Superior Tecnico; University of York - UK; Universita Ca Foscari Venezia; Inria	Figueiredo, MAT (corresponding author), Inst Super Tecn, Inst Telecommun, P-1049001 Lisbon, Portugal.	mtf@lx.it.pt; erh@cs.york.ac.uk; pelillo@dsi.unive.it; josiane.zerubia@sophia.inria.fr	Hancock, Edwin/N-7548-2019; Figueiredo, Mario/C-5428-2008; Hancock, Edwin R/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028; Figueiredo, Mario/0000-0002-0970-7745; Hancock, Edwin R/0000-0003-4496-2028					0	0	0	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2004	26	2					145	146		10.1109/TPAMI.2004.1262176	http://dx.doi.org/10.1109/TPAMI.2004.1262176			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	762DA					2022-12-18	WOS:000187954300001
J	Figueiredo, MAT; Hancock, ER; Pelillo, M; Zerubia, J				Figueiredo, MAT; Hancock, ER; Pelillo, M; Zerubia, J			Guest editors' introduction to the special section on energy minimization methods in computer vision and pattern recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									Inst Super Tecn, Inst Telecommun, P-1049001 Lisbon, Portugal; Inst Super Tecn, Dept Elect & Comp Engn, P-1049001 Lisbon, Portugal; York Univ, Dept Comp Sci, York Y010 5DD, N Yorkshire, England; Univ Ca Foscari Venezia, Dipartimento Informat, I-30172 Venice, Italy; INRIA, F-06902 Sophia Antipolis, France	Instituto de Telecomunicacoes; Universidade de Lisboa; Instituto Superior Tecnico; Universidade de Lisboa; Instituto Superior Tecnico; University of York - UK; Universita Ca Foscari Venezia; Inria	Figueiredo, MAT (corresponding author), Inst Super Tecn, Inst Telecommun, P-1049001 Lisbon, Portugal.		Hancock, Edwin R/C-6071-2008; Hancock, Edwin/N-7548-2019; Figueiredo, Mario/C-5428-2008	Hancock, Edwin R/0000-0003-4496-2028; Hancock, Edwin/0000-0003-4496-2028; Figueiredo, Mario/0000-0002-0970-7745					0	0	0	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1361	1363		10.1109/TPAMI.2003.1240110	http://dx.doi.org/10.1109/TPAMI.2003.1240110			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	733NG					2022-12-18	WOS:000186006800001
J	Yuille, AL; Coughlan, JM; Konishi, S				Yuille, AL; Coughlan, JM; Konishi, S			The generic viewpoint assumption and planar bias	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						generic viewpoint; Bayesian inference; visual ambiguities	AFFINE	We show that generic viewpoint and lighting assumptions resolve standard visual ambiguities by biasing toward planar surfaces. Our model uses orthographic projection with a two-dimensional affine warp and Lambertian reflectance functions, including cast and attached shadows. We use uniform priors on nuisance variables such as viewpoint direction and the light source. Limitations of using uniform priors on nuisance variables are discussed.	Smith Kettlewell Eye Res Inst, San Francisco, CA 94115 USA	The Smith-Kettlewell Eye Research Institute	Yuille, AL (corresponding author), Smith Kettlewell Eye Res Inst, 2318 Fillmore St, San Francisco, CA 94115 USA.			Yuille, Alan L./0000-0001-5207-9249				Albert MK, 2000, PERCEPTION, V29, P303; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Berger J. O., 1985, STAT DECISION THEORY; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BRAINARD DH, 1994, P SPIE, V2719; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; LOWE DG, 1985, IEEE T PATTERN ANAL, V7, P320, DOI 10.1109/TPAMI.1985.4767660; Ripley BD., 1996; Weinshall D, 1997, IEEE T PATTERN ANAL, V19, P97, DOI 10.1109/34.574783; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P810, DOI 10.1109/34.400572; YUILLE AL, 2001, P INT C COMP VIS; YUILLE AL, 2000, P C INF SCI SYST MAR; YUILLE AL, 1996, BAYESIAN APPROACHES	17	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2003	25	6					775	778		10.1109/TPAMI.2003.1201826	http://dx.doi.org/10.1109/TPAMI.2003.1201826			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	680DP					2022-12-18	WOS:000182961300011
J	Jacobs, DW; Lindenbaum, M				Jacobs, DW; Lindenbaum, M			Guest editors' introduction to the special section on perceptual organization in computer vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	University System of Maryland; University of Maryland College Park; Technion Israel Institute of Technology	Jacobs, DW (corresponding author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.	djacobs@umiacs.umd.edu; mic@cs.technion.ac.il							0	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					385	386		10.1109/TPAMI.2003.1190566	http://dx.doi.org/10.1109/TPAMI.2003.1190566			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV					2022-12-18	WOS:000181758100001
J	Chellappa, R; Kriegman, DJ				Chellappa, R; Kriegman, DJ			Editorial - State of the transactions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									Univ Maryland, Ctr Automat Res, College Pk, MD 20741 USA; Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA	University System of Maryland; University of Maryland College Park; University of California System; University of California San Diego	Chellappa, R (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20741 USA.								0	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2003	25	3					289	289		10.1109/TPAMI.2003.1182092	http://dx.doi.org/10.1109/TPAMI.2003.1182092			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	647BL					2022-12-18	WOS:000181071300001
J	Muller, N; Herbst, BM				Muller, N; Herbst, BM			On the use of SDF-type filters for distortion parameter estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						synthetic discriminant functions; synthetic estimation filters; facial location	SYNTHETIC ESTIMATION FILTERS; PATTERN-RECOGNITION; INVARIANCE; DESIGN	Synthetic discriminant functions have been used to locate objects irrespective of distortions and to estimate the extent of the distortion. it was recognized from the beginning that accurate estimates are only possible provided the training set is constructed carefully. In this paper, we obtain conditions that will ensure the accuracy of the estimates. The conditions also suggest efficient ways of constructing the training sets and the results are extended to a wide class SDF-type filters. The theoretical results are illustrated with (idealized) examples and are also applied to the more realistic problem of accurate facial location.	Univ Stellenbosch, Dept Appl Math, ZA-7602 Matieland, South Africa	Stellenbosch University	Muller, N (corresponding author), Univ Stellenbosch, Dept Appl Math, ZA-7602 Matieland, South Africa.	herbst@ibis.sun.ac.za		Muller, Neil/0000-0001-6516-3992				BARNARD E, 1991, IEEE T NEURAL NETWOR, V2, P498, DOI 10.1109/72.134287; BENNETT MK, 1992, P SOC PHOTO-OPT INS, V1702, P121, DOI 10.1117/12.60551; DEBOOR C, 1973, P C NUM SOL DIFF EQ; EMBAR RS, 1994, P SOC PHOTO-OPT INS, V2237, P124, DOI 10.1117/12.169415; HESTER CF, 1980, APPL OPTICS, V19, P1758, DOI 10.1364/AO.19.001758; Hotta K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P70, DOI 10.1109/AFGR.1998.670927; JONSSON K, 1999, AUDIO VIDEO BASED BI, P60; Juday R. D., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V754, P40; Kostrzewski A, 1997, P SOC PHOTO-OPT INS, V3159, P60, DOI 10.1117/12.292739; KUMAR BVK, 1995, P SOC PHOTO-OPT INS, V2490, P2; KUMAR BVKV, 1992, OPT ENG, V31, P915, DOI 10.1117/12.56169; Kumar BVKV, 2000, IEEE T IMAGE PROCESS, V9, P1025, DOI 10.1109/83.846245; KUMAR BVKV, 1993, P SOC PHOTO-OPT INS, V1959, P23, DOI 10.1117/12.160298; MAHALANOBIS A, 1994, APPL OPTICS, V33, P3751, DOI 10.1364/AO.33.003751; MOGHADDAM B, 1995, P 5 INT C COMP VIS; Monroe S. E.  Jr., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V938, P253, DOI 10.1117/12.976600; MONROE SE, 1990, P SOC PHOTO-OPT INS, V1347, P179; MULLER N, 2000, P 15 INT C PATT REC, V3, P530; MULLER N, 2000, THESIS U STELLENBOSC; NEIBURG L, 1996, THESIS CARNEGIE MELL; PEREYRA V, 1974, NUMER MATH, V23, P261, DOI 10.1007/BF01400309; RAVICHANDRAN G, 1992, APPL OPTICS, V31; REFREGIER P, 1994, P SPIE PM, V12, P58; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; SIMARD P, 1992, ADV NEURAL INFORMATI, P651; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; SIPE MA, 1999, THESIS CARNEGIE MELL; Strang G., 1998, INTRO LINEAR ALGEBRA	28	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1521	1528		10.1109/TPAMI.2002.1046173	http://dx.doi.org/10.1109/TPAMI.2002.1046173			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY					2022-12-18	WOS:000178846400009
J	Tang, M; Ma, SD				Tang, M; Ma, SD			General scheme of region competition based on scale space (vol 23, pg 1370, 2001)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction									Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Tang, M (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, POB 2728, Beijing 100080, Peoples R China.	tangm@nlpr.ia.ac.cn; masd@nlpr.ia.ac.cn						Tang M, 2001, IEEE T PATTERN ANAL, V23, P1366, DOI 10.1109/34.977561	1	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2002	24	7					1007	1007						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	566UF					2022-12-18	WOS:000176446100013
J	Chellappa, R; Kriegman, DJ				Chellappa, R; Kriegman, DJ			Editorial - State of the transactions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	University System of Maryland; University of Maryland College Park; University of Illinois System; University of Illinois Urbana-Champaign	Chellappa, R (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.		Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012						0	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2002	24	5					577	578		10.1109/TPAMI.2002.1000233	http://dx.doi.org/10.1109/TPAMI.2002.1000233			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	544XU					2022-12-18	WOS:000175187800001
J	Sclaroff, S; Liu, L				Sclaroff, S; Liu, L			Deformable shape detection and description via model-based region grouping (vol 23, pg 475, 2001)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction												sclaroff@cs.bu.edu; liulf@cs.bu.edu						Sclaroff S, 2001, IEEE T PATTERN ANAL, V23, P475, DOI 10.1109/34.922706	1	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2001	23	6					685	685						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	438DC					2022-12-18	WOS:000169037600012
J	Chellappa, R				Chellappa, R			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign	Chellappa, R (corresponding author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.		Casetti, Lapo/F-7625-2011; Chellappa, Rama/AAV-8690-2020	Casetti, Lapo/0000-0002-6964-5611; 					0	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2001	23	1					1	2						2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	390VA					2022-12-18	WOS:000166316700001
J	Bowyer, K				Bowyer, K			AE introduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2000	22	6					553	553						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	342WE					2022-12-18	WOS:000088667700001
J	Bowyer, K				Bowyer, K			Untitled	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					321	321						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT					2022-12-18	WOS:000087250500001
J	Freeman, H				Freeman, H			Jean-Claude Simon, 1924-2000 - Obituary	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Biographical-Item									Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA	Rutgers State University New Brunswick	Freeman, H (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, 94 Brett Rd, Piscataway, NJ 08854 USA.							SIMON JR, PUBLICATION LIST	1	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2000	22	3					226	226						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	306EJ					2022-12-18	WOS:000086584100001
J	Hung, YS; Ho, HT				Hung, YS; Ho, HT			A Kalman filter approach to direct depth estimation incorporating surface structure (vol 21, pg 570, 1999)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction													Hung, Yeung Sam/C-1852-2009					Hung YS, 1999, IEEE T PATTERN ANAL, V21, P570, DOI 10.1109/34.771330	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1999	21	10					1101	1101						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	248DB					2022-12-18	WOS:000083259100012
J	Say, ACC				Say, ACC			Making use of contradictory behavior information in qualitative reasoning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						qualitative reasoning; qualitative simulation; QSIM; automated modeling; diagnosis	SIMULATION	We present a technique for automatically determining certain pairs of qualitative simulation predictions to be mutually contradictory. This leads the simulator to produce more informative outputs, which results in improved performance in reasoning tasks like diagnosis, model revision, and deletion of spurious "timelines" containing the input state.	Bogazici Univ, Dept Comp Engn, TR-80815 Bebek, Turkey	Bogazici University	Say, ACC (corresponding author), Bogazici Univ, Dept Comp Engn, TR-80815 Bebek, Turkey.			Say, A. C. Cem/0000-0002-4374-8460				CLANCY DJ, 1997, P 11 INT WORKSH QUAL, P53; CLANCY DJ, 1997, P 14 NAT C ART INT A; DECOSTE D, 1991, ARTIF INTELL, V51, P273, DOI 10.1016/0004-3702(91)90113-X; DVORAK D, 1992, THESIS U TEXAS AUSTI; FALKENHAINER B, 1991, ARTIF INTELL, V51, P95, DOI 10.1016/0004-3702(91)90109-W; FORBUS KD, 1990, READINGS QUALITATIVE, P220; KUIPERS B, 1987, IEEE T SYST MAN CYB, V17, P432, DOI 10.1109/TSMC.1987.4309059; Kuipers B., 1994, QUALITATIVE REASONIN; Say ACC, 1996, ARTIF INTELL, V83, P75, DOI 10.1016/0004-3702(95)00016-X; SAY ACC, 1993, IEEE T PATTERN ANAL, V15, P967, DOI 10.1109/34.232085; Say ACC, 1997, IEEE T SYST MAN CY A, V27, P84, DOI 10.1109/3468.553227; SAY ACC, 1997, NEW TRENDS ARTIFICIA, P121; SAY ACC, 1998, CMPE98QR1 BOAZ U AI; Shults B, 1997, ARTIF INTELL, V92, P91, DOI 10.1016/S0004-3702(96)00050-1	14	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1999	21	8					781	786		10.1109/34.784292	http://dx.doi.org/10.1109/34.784292			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	225YF					2022-12-18	WOS:000081993000010
J	Bowyer, K; Flynn, P				Bowyer, K; Flynn, P			Multiple submission: Professionalism, ethical issues, and copyright legalities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material													Flynn, Patrick J/J-3388-2013	Flynn, Patrick J/0000-0002-5446-114X					0	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1999	21	5					385	385		10.1109/TPAMI.1999.765651	http://dx.doi.org/10.1109/TPAMI.1999.765651			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	194LK					2022-12-18	WOS:000080194900001
J	Davis, R; Prieditis, A				Davis, R; Prieditis, A			Designing optimal sequential experiments for a Bayesian Classifier	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						machine learning; Bayesian classifiers; experimental design		As computing power has grown, the trend in experimental design has been from techniques requiring little computation towards techniques providing better, more general results at the cost of additional computation. This paper continues this trend presenting three new methods for designing experiments. A summary of previous work in experimental design is provided and used to show how these new methods generalize previous criteria and provide a more accurate analysis than prior methods. The first method generates experimental designs by maximizing the uncertainty of the experiment's result, while the remaining two methods minimize an approximation of the variance of a function of the parameters. The third method uses a computationally expensive discrete approximation to determine the variance. The methods are tested and compared using the logistic model and a Bayesian classifier. The results show that at the expense of greater computation. experimental designs more effective at reducing the uncertainty of the decision boundary of the Bayesian classifier can be generated.	Univ Calif Davis, Dept Comp Sci, Livermore, CA 95616 USA	University of California System; University of California Davis	Davis, R (corresponding author), Univ Calif Davis, Dept Comp Sci, Livermore, CA 95616 USA.	davis@rush.aero.org						BEDRICK E, 1993, UNPUB BAYESIAN METHO; Box G. E. P., 1987, EMPIRICAL MODEL BUIL; CHALONER K, 1989, J STAT PLAN INFER, V21, P191, DOI 10.1016/0378-3758(89)90004-9; CHERNOFF H, 1953, ANN MATH STAT, V24, P586, DOI 10.1214/aoms/1177728915; DAVIS R, 1995, CSE9512 U CAL DAV; DeGroot M.H., 2012, PROBABILITY STAT; DIXON WJ, 1948, J AM STAT ASSOC, V43, P109, DOI 10.2307/2280071; Duda R.O., 1973, J ROYAL STAT SOC SER; FALKENHAINER B, 1988, P 5 INT WORKSH MACH; FREEMAN PR, 1970, BIOMETRIKA, V57, P79, DOI 10.1093/biomet/57.1.79; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; LINDLEY DV, 1956, ANN MATH STAT, V27, P986, DOI 10.1214/aoms/1177728069; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; NELDER J, 1971, COMPUT J, V7, P308; Press WH, 1988, NUMERICAL RECIPES C; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; SILVAPULLE MJ, 1981, J ROY STAT SOC B MET, V43, P310; SUBRAMANIAN D, 1986, P AM ASS ART INT PHI; Tsutakawa R.K., 1980, APPL STATIST, V29, P25; TSUTAKAWA RK, 1972, J AM STAT ASSOC, V67, P584, DOI 10.2307/2284443; WEISS SM, 1991, COMPUTER SYSTEMS THA; WETHERILL G, 1963, J ROYAL STAT SOC B, V24, P1; WU CFJ, 1985, J AM STAT ASSOC, V80, P974, DOI 10.2307/2288563; ZYTKOW J, 1990, P AM ASS ART INT BOS	24	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					193	201		10.1109/34.754585	http://dx.doi.org/10.1109/34.754585			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD					2022-12-18	WOS:000079296000001
J	Baram, Y				Baram, Y			Partial classification can be beneficial even for ideal separation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Baram, Y (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.							Baram Y, 1998, IEEE T PATTERN ANAL, V20, P769, DOI 10.1109/34.709564	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1998	20	10					1117	1117		10.1109/34.722630	http://dx.doi.org/10.1109/34.722630			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	128QB					2022-12-18	WOS:000076416400010
J	Cho, K; Meer, P; Cabrera, J				Cho, K; Meer, P; Cabrera, J			Performance assessment through bootstrap (vol 19, pg 1196, 1997)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction									Samsung Data Syst, Open Solut Ctr, Seoul, South Korea; Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08855 USA; Rutgers State Univ, Dept Stat, Piscataway, NJ 08855 USA	Samsung; Rutgers State University New Brunswick; Rutgers State University New Brunswick	Cho, K (corresponding author), Samsung Data Syst, Open Solut Ctr, Seoul, South Korea.							CHO K, 1997, IEEE T PATTERN ANAL, V19, P1196	1	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1998	20	1					94	94						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YV876					2022-12-18	WOS:000071872400010
J	Kittler, J; Jain, A				Kittler, J; Jain, A			Pierre Devijver 1938-1996 - Obituary	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Item About an Individual																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1997	19	10					1057	1057						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YB678					2022-12-18	WOS:A1997YB67800001
J	Sin, BK; Kim, JH				Sin, BK; Kim, JH			Ligature modeling for online cursive script recognition (vol 19, pg 626, 1997)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition									KOREA ADV INST SCI & TECHNOL,DEPT COMP SCI,YUSONG KU,TAEJON 305701,SOUTH KOREA	Korea Advanced Institute of Science & Technology (KAIST)	Sin, BK (corresponding author), KOREA TELECOM,INFORMAT RETRIEVAL TECHNOL TEAM,SOCHO KU,17 UMYONDONG,SEOUL 137792,SOUTH KOREA.							SIN BK, 1997, IEEE T PATTERN ANAL, V19, P626	1	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1997	19	8					926	926						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XT987					2022-12-18	WOS:A1997XT98700013
J	Kasturi, R				Kasturi, R			Editor's notice	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1997	19	7					673	673						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM693					2022-12-18	WOS:A1997XM69300001
J	Hsu, TC; Wang, SD				Hsu, TC; Wang, SD			The K1-map reduction for pattern classifications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Karnaugh map (K map); pattern classifications; RCE; RBF; One-Class-One-Network	CLASSIFIERS; NETWORKS	A shortcut hand-reduction method known as the Karnaugh map (K map) is an efficient way of reducing Boolean functions to a minimum form for the purpose of minimizing hardware requirements. In this paper, by applying the prime group and the essential prime group concepts of the K maps to pattern classification problems, the K1-map reduction method is proposed. The K1-map reduction method can be used to design restricted coulomb energy (RCE) networks and to determine the number of bidden units problems in a systematic manner.			Hsu, TC (corresponding author), NATL TAIWAN UNIV,DEPT ELECT ENGN,TAIPEI 10764,TAIWAN.							AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Batchelor B. G., 1974, PRACTICAL APPROACH P; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Duda R.O., 1973, J ROYAL STAT SOC SER; Fahlman S., 1990, CMUCS90100 CARN MELL; FAHLMAN S, P 1988 CONN MOD SUMM, P38; HUDAK MJ, 1992, CYBERNET SYST, V23, P483, DOI 10.1080/01969729208927478; LEE S, 1991, NEURAL NETWORKS, V4, P207, DOI 10.1016/0893-6080(91)90005-P; LI R, 1988, THESIS MIT CAMBRIDGE; MOODY J, P 1988 CONN MOD SUMM, P133; MUSAVI MT, 1992, NEURAL NETWORKS, V5, P595, DOI 10.1016/S0893-6080(05)80038-3; Nowlan S.J., 1990, ADV NEURAL INFORM PR, P574; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Scofield C. L., 1988, NEURAL INFORM PROCES, P674; WHITEHEAD BA, 1994, IEEE T NEURAL NETWOR, V5, P15, DOI 10.1109/72.265957	17	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1997	19	6					616	622		10.1109/34.601249	http://dx.doi.org/10.1109/34.601249			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XG302					2022-12-18	WOS:A1997XG30200006
J	Kasturi, R				Kasturi, R			Associate editors join PAMI	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1996	18	12					1149	1149						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VZ150					2022-12-18	WOS:A1996VZ15000001
J	Lee, SW; Lee, DJ; Park, HS				Lee, SW; Lee, DJ; Park, HS			A new methodology for gray-scale character segmentation and recognition (vol 18, pg 1046, 1996)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition									KOREA TELECOM,TELECOMMUN NETWORK RES LAB,SEOUL 137792,SOUTH KOREA; SAMSUNG ELECT CO LTD,MULTIMEDIA LAB,KYONGGI DO 440600,SOUTH KOREA	Samsung	Lee, SW (corresponding author), KOREA UNIV,DEPT COMP SCI & ENGN,SEONGBUK KU,SEOUL 136701,SOUTH KOREA.		Lee, Seong-Whan/C-7928-2012					LEE SW, 1996, IEEE T PATTERN ANAL, V18, P1046	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1996	18	12					1262	1262						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VZ150					2022-12-18	WOS:A1996VZ15000012
J	Strackee, J				Strackee, J			The slope of a straight line: A phony estimator	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								This note discusses an estimator for the slope of a straight line as proposed by Werman and Geyzel [1]. By computing its frequency distribution, it is demonstrated that the estimator is a fake; it possesses neither a first nor a second moment. Application leads therefore to completely erratic outcomes.			Strackee, J (corresponding author), ACAD MED CTR,MED PHYS LAB,MEIBERGDREEF 15,NL-1105 AZ AMSTERDAM,NETHERLANDS.							KENDALL MG, 1958, ADV THEORY STAT, V1, P268; KENDALL MG, 1961, ADV THEORY STAT, V2, P377; NAGELKERKE NJD, 1982, IEEE T BIO-MED ENG, V29, P467, DOI 10.1109/TBME.1982.324976; POPOULIS A, 1985, PROBABILITY RANDOM V, P137; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P207, DOI 10.1109/34.368167; Wolfram, 2017, MATHEMATICA	6	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1996	18	10					1051	1051		10.1109/34.541416	http://dx.doi.org/10.1109/34.541416			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VP691					2022-12-18	WOS:A1996VP69100011
J	Werman, M				Werman, M			The slope of a straight line: A phony estimator - Remarks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											Werman, M (corresponding author), HEBREW UNIV JERUSALEM,INST COMP SCI,IL-91904 JERUSALEM,ISRAEL.							MADANSKY A, 1959, J AM STAT ASSOC, V54, P173, DOI 10.2307/2282145; Moran P.A.P., 1971, J MULTIVARIATE ANAL, V1, P232, DOI [10.1016/0047-259X(71)90013-3, DOI 10.1016/0047-259X(71)90013-3]; Wald A, 1940, ANN MATH STAT, V11, P284, DOI 10.1214/aoms/1177731868; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P207, DOI 10.1109/34.368167	4	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1996	18	10					1052	1052		10.1109/TPAMI.1996.541417	http://dx.doi.org/10.1109/TPAMI.1996.541417			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VP691					2022-12-18	WOS:A1996VP69100012
J	Kasturi, R				Kasturi, R			Associate editors join TPAMI	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					577	578						2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UR254					2022-12-18	WOS:A1996UR25400001
J	Kasturi, R				Kasturi, R			State of PAMI	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1996	18	2					97	98						2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TV669					2022-12-18	WOS:A1996TV66900001
J	Kaplan, LM; Kuo, CCJ				Kaplan, LM; Kuo, CCJ			Texture roughness analysis and synthesis via extended self-similar (ESS) model (vol 17, pg 1043, 1995)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition													Kuo, C.-C. Jay/A-7110-2011	Kuo, C.-C. Jay/0000-0001-9474-5035				KAPLAN LM, 1995, IEEE T PATTERN ANAL, V17, P1043, DOI 10.1109/34.473230	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					92	92						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500014
J	RAO, PVS				RAO, PVS			A KNOWLEDGE-BASED APPROACH FOR SCRIPT RECOGNITION WITHOUT TRAINING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CHARACTER SYNTHESIS; CURSIVE SCRIPT; DECODING; ENCODING; FEATURE MATRICES; ONLINE RECOGNITION; SCRIPT RECOGNITION; SHAPE VECTORS; TRANSFER FUNCTION; TRANSITION SEGMENTS	ONLINE	The approach is based on an empirical parametric model for the writing hand system. The parameters are so chosen and quantized as to retain only broad shape information ignoring writer-dependent and other variability. Concatenation of character prototypes generates archetypal reference words for recognition; training is unnecessary. Recognition scores exceed 90%.			RAO, PVS (corresponding author), TATA INST FUNDAMENTAL RES,COMP SYST & COMMUN GRP,BOMBAY 400005,MAHARASHTRA,INDIA.		Srinivasa Rao, Prof. P/ABG-1688-2021	Srinivasa Rao, Prof. P/0000-0003-1379-4906				BARRIERE C, 1992, P VISION INTERFACE, P83; Bellegarda EJ, 1993, 3RD P INT WORKSH FRO, P225; BERCU S, 1993, 3RD P INT WORKSH FRO, P385; CHEN MY, 1993, 3RD P INT WORKSH FRO, P82; FARAG RFH, 1979, IEEE T COMPUT, V28, P172, DOI 10.1109/TC.1979.1675310; FUJISAKI T, 1993, 3RD P INT WORKSH FRO, P235; MERMELSTEIN P, 1964, INFORM CONTROL, V7, P255, DOI 10.1016/S0019-9958(64)90142-1; MILLER GM, 1972, P IFIP C INFORMATION, P218; PARZEAU M, 1993, 3RD P INT WORKSH FRO, P252; RAMASUBRAMANIAN V, 1988, COMPUTER SCI INFORMA, V19, P1; RAO PSC, 1993, SORPTION AND DEGRADATION OF PESTICIDES AND ORGANIC CHEMICALS IN SOIL, P1, DOI 10.1007/BF02811383; RAO PVS, 1991, J I ELECTRONICS TELE, V37, P485; RAO PVS, 1990, NVA 90 IAPR WORKSHOP, P441; RAO PVS, 1991, ICDAR 91, P568; SAYRE KM, 1973, PATTERN RECOGN, V5, P213, DOI 10.1016/0031-3203(73)90044-7; SCHOMAKER L, 1993, PATTERN RECOGN, V26, P443, DOI 10.1016/0031-3203(93)90171-R; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669	17	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1233	1239		10.1109/34.476518	http://dx.doi.org/10.1109/34.476518			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500013
J	BOKIL, A; KHOTANZAD, A				BOKIL, A; KHOTANZAD, A			CONSTRAINT LEARNING FEEDBACK DYNAMIC-MODEL FOR STEREOPSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						COMPUTATIONAL BINOCULAR STEREO; LEARNING STEREO CONSTRAINTS; LEARNING CORRESPONDENCE PROBLEM; GENERALIZED MARR-POGGIO ALGORITHM; DYNAMIC FEEDBACK MODEL	NEURAL NETWORKS; DISPARITY	This paper presents a stereo matcher inspired by the earlier work of Marr and Poggio [7]. Two major extensions are introduced: the algorithm is extended to gray-level images, and the inhibitory/excitatory weights of the model are learned rather than set a priori according to ''uniqueness'' and ''continuity'' constraints. Gray level stereo pairs of real scenes with known disparity maps are used to train the model. The trained system is successfully tested on other gray level stereo pairs of real scenes as well as a set of random dot stereograms (RDS), Performance is compared to a recent stereo matching algorithm.	SO METHODIST UNIV, DEPT ELECT ENGN, IMAGE PROC & ANAL LAB, DALLAS, TX 75275 USA	Southern Methodist University	BOKIL, A (corresponding author), TEXAS INSTRUMENTS INC, M-S 947, 13536 N CENT EXPRESSWAY, DALLAS, TX 75243 USA.							BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; Dhond U.R., 1989, IEEE T SYSTEMS MAN C, V19; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; HSIEH YC, 1992, IEEE T PATTERN ANAL, V14; HU J, 1993, P IEEE INT C NEURAL, P126; KHOTANZAD A, 1993, IEEE T NEURAL NETWOR, V4, P332, DOI 10.1109/72.207620; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; NASRABADI NM, 1992, IEEE T NEURAL NETWOR, V3; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OTOOLE AJ, IN PRESS J BIOL SYST; PINEDA FJ, 1987, PHYS REV LETT, V59, P2229, DOI 10.1103/PhysRevLett.59.2229; QIAN N, 1988, 1988 P CONN MOD SUMM, P435; ZHOU YT, 1988, APR P IEEE ICASSP 88, P940	13	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1995	17	11					1095	1100		10.1109/34.473237	http://dx.doi.org/10.1109/34.473237			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TD854					2022-12-18	WOS:A1995TD85400009
J	PANJWANI, DK; HEALEY, G				PANJWANI, DK; HEALEY, G			MARKOV RANDOM-FIELD MODEL FOR UNSUPERVISED SEGMENTATION OF TEXTURED COLOR IMAGES (VOL 17, PG 939, 1995)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559	1	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1995	17	11					1128	1128						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TD854					2022-12-18	WOS:A1995TD85400014
J	SIDDIQI, K; KIMIA, BB				SIDDIQI, K; KIMIA, BB			PARTS OF VISUAL FORM - COMPUTATIONAL ASPECTS (VOL 17, PG 239, 1995)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		KIMIA BB, 1991, VISUAL FORM ANAL REC, P333; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189	2	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1995	17	5					544	544						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QW394					2022-12-18	WOS:A1995QW39400013
J	KUMAR, A; BARSHALOM, Y; ORON, E				KUMAR, A; BARSHALOM, Y; ORON, E			PRECISION TRACKING BASED ON SEGMENTATION WITH OPTIMAL LAYERING FOR IMAGING SENSORS (VOL 17, PG 182, 1995)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		KUMAR A, 1995, IEEE T PATTERN ANAL, V17, P182, DOI 10.1109/34.368171	1	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1995	17	3					320	320						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QM090					2022-12-18	WOS:A1995QM09000011
J	SOHN, W; KEHTARNAVAZ, ND				SOHN, W; KEHTARNAVAZ, ND			ANALYSIS OF CAMERA MOVEMENT ERRORS IN VISION-BASED VEHICLE TRACKING (VOL 16, PG 57, 1995)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		SOHN W, 1994, IEEE T PATTERN ANAL, V17, P57	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					224	224						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825					2022-12-18	WOS:A1995QE82500014
J	KAPOOR, S; MUNDKUR, PY; DESAI, UB				KAPOOR, S; MUNDKUR, PY; DESAI, UB			DEPTH AND IMAGE RECOVERY USING A MRF MODEL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DEPTH RECOVERY; MARKOV RANDOM FIELD; CLIQUE MODEL; SIMULATED ANNEALING; SURFACE RECONSTRUCTION; EARLY VISION; HEURISTIC RECOVERY METHODS	SURFACE RECONSTRUCTION	This paper deals with the problem of depth recovery and image restoration from sparse and noisy image data. The image is modeled as a Markov Random Field and a new energy function is developed to effectively detect discontinuities in highly sparse and noisy images. The model provides an alternative to the use of a line process. Interpolation over missing data sites is first done using local characteristics to obtain initial estimates and then simulated annealing is used to compute the Maximum a posteriori (MAP) estimate. A threshold on energy reduction per iteration is used to speed up simulated annealing by avoiding computation that contributes little to the energy minimization. Moreover, a minor modification of the posterior energy function gives improved results for random as well as structured sparsing problems. Results of simulations carried out on real range and intensity images along with details of the simulations are presented.	UNIV CALIF IRVINE,DEPT ELECT & COMP ENGN,IRVINE,CA 92717; INDIAN INST TECHNOL,DEPT ELECT ENGN,BOMBAY 400076,MAHARASHTRA,INDIA	University of California System; University of California Irvine; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay	KAPOOR, S (corresponding author), WASHINGTON STATE UNIV,SCH ELECT ENGN & COMP SCI,PULLMAN,WA 99164, USA.							Aarts E., 1989, SIMULATED ANNEALING; BERTERO M, 1988, P IEEE, V76; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; BOULT TE, 1986, JUN P IEEE C COMP VI, P68; CHOI DJ, 1988, JUN P IEEE C COMP VI, P189; FRANKOT RT, 1989, IEEE T PATTERN ANAL, V11, P799; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1987, P INT C MATH; KAPOOR S, 1993, MAR SADH AC P ENG SC, V18; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; Ripley B. D., 1981, SPAT STAT-NETH; SHAO M, 1987, JUN P IEEE C COMP VI, P530; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; VENKATESH KV, 1990, OPTICAL ENG      MAY; YOUNES L, 1988, ANN I H POINCARE-PR, V24, P269; ZERUBIA J, 1990, SEP P EUR SIGN P C B	20	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1994	16	11					1117	1122		10.1109/34.334392	http://dx.doi.org/10.1109/34.334392			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PW081					2022-12-18	WOS:A1994PW08100006
J	WANG, CA				WANG, CA			COLLISION DETECTION OF A MOVING POLYGON IN THE PRESENCE OF POLYGONAL OBSTACLES IN THE PLANE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COLLISION DETECTION; COMPUTATIONAL GEOMETRY; MOTION PLANNING; OPTIMAL ALGORITHM; ROBOTICS	BARRIERS	This paper presents a new approach for the following collision detection problem in the plane: Let a simple polygon P rotate at a center o with constant angular velocity omega and translate towards a set of polygonal obstacles S with constant velocity nu. Given P and S as well as their initial positions, and given also the velocities of P, determine whether or not P will collide with any element of S and report the collided elements of S if collisions occurred. An O(mn) worst-case optimal algorithm is proposed to solve this problem, where n is the number of vertices of P and m is the number of vertices of the obstacles in S.			WANG, CA (corresponding author), MEM UNIV NEWFOUNDLAND,DEPT COMP SCI,ST JOHNS A1C 5S7,NEWFOUNDLAND,CANADA.							CANNY J, 1986, IEEE T PATTERN ANAL, V8, P200, DOI 10.1109/TPAMI.1986.4767773; CHEW LP, 1985, 1ST P ACM S COMP GEO, P214; DUNLAING CO, 1985, COMMUN PURE APPL MAT, V39, P423; DUNLAING CO, 1985, ALGORITHMICA, V2, P27; HALPERIN D, 1990, 2ND P CAN C COMP GEO, P98; HALPERIN D, 1992, SIAM J COMPUTING, V21; HERSHBERGER J, 1986, 14 DEC SYST RES CTR; KE Y, 1987, DISCRETE COMPUT GEOM, V3, P197; KEDEM K, 1985, 1ST P ACM S COMP GEO, P75; LEE DT, 1984, NETWORKS, V14, P393, DOI 10.1002/net.3230140304; LEVEN D, 1987, J ALGORITHM, V8, P192, DOI 10.1016/0196-6774(87)90038-1; Reif J., 1985, 26th Annual Symposium on Foundations of Computer Science (Cat. No.85CH2224-4), P144, DOI 10.1109/SFCS.1985.36; TOUSSAINT GT, 1984, INT J COMPUT INF SCI, V13, P197, DOI 10.1007/BF00979872; WILFONG G, 1988, 4TH P ACM S COMP GEO, P279	14	0	0	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					571	580						10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200002
J	[Anonymous]				[Anonymous]			WATANABE,SATOSI 1910-1993 - IN-MEMORIAM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Item About an Individual																		WATANABE S, PUBLICATION LIST	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1994	16	3					226	226						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NF114					2022-12-18	WOS:A1994NF11400002
J	[Anonymous]				[Anonymous]			DUBES,RICHARD,C. 1934-1993 - IN-MEMORIAM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Item About an Individual																		DUBES RC, PUBLICATION LIST	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1994	16	3					226	226						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NF114					2022-12-18	WOS:A1994NF11400001
J	BANIHASHEMI, A				BANIHASHEMI, A			A FOURIER APPROACH TO CAMERA ORIENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note							RELATIVE ORIENTATION	Recovering camera orientation with respect to a known coordinate system is of great significance to photogrammetry and binocular stereo. In binocular stereo, the relative orientation between a camera pair may be obtained from the orientation of each camera with respect to a common frame. In this paper a Fourier technique is presented to determine the orientation of a camera with respect to a calibration object. This technique is limited to orthographic projection, but has two major strengths of; being very accurate, and the camera orientation being entirely decoupled from translation.			BANIHASHEMI, A (corresponding author), SIEMENS CORP RES,755 COLL RD E,PRINCETON,NJ 08540, USA.							BANIHASHEMI A, 1991, COMPUTER VISION PATT, P122; CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; CONIO RHB, 1989, COMPUTER VISION PATT, P500; GANAPATHY S, 1984, P INT C ROBOTICS, P130; HORN BKP, 1991, J OPT SOC AM A, V8, P1630, DOI 10.1364/JOSAA.8.001630; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781; Shuster M.D., 1978, P GUID CONTR C PAL A, P88; TSAI RY, 1987, 4TH INT S ROB RES SA, P345; TSAI RY, 1985, RC11413 IBM RES TECH	11	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1993	15	11					1197	1202		10.1109/34.244681	http://dx.doi.org/10.1109/34.244681			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MH083					2022-12-18	WOS:A1993MH08300009
J	WAN, SJ; WONG, SKM				WAN, SJ; WONG, SKM			A PARTIALLY SUPERVISED LEARNING ALGORITHM FOR LINEARLY SEPARABLE SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						LEARNABILITY; LEARNING FROM EXAMPLES; MACHINE LEARNING; LINEAR SEPARABILITY; PARTIALLY SUPERVISED LEARNING; SAMPLE SELECTION		An important aspect of human learning is the ability to select effective samples to learn and utilize the experience to infer the outcomes of new events. This type of learning is characterized as partially supervised learning. This paper suggests a learning algorithm of this type for linearly separable systems. The proposed algorithm selects a subset S from a finite set X of linearly separable vectors to construct a linear classifier that can correctly classify all the vectors in X. The sample set S is chosen without any prior knowledge of how the vectors in X - S are classified. The computational complexity of the algorithm is analyzed, and the lower bound on the size of the sample set is established.	UNIV REGINA,DEPT COMP SCI,REGINA S4S 0A2,SASKATCHEWAN,CANADA	University of Regina	WAN, SJ (corresponding author), EASTMAN KODAK CO,IMAGING SYST CONCEPT LAB,ROCHESTER,NY 14653, USA.							BAASE S, 1988, COMPUTER ALGORITHMS; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; Duda R.O., 1973, J ROYAL STAT SOC SER; KHACHIIAN LG, 1979, DOKL AKAD NAUK SSSR+, V244, P1093; Knuth D., 1973, ART COMPUTER PROGRAM, V3; Minsky M., 1988, PERCEPTRONS; Muroga S., 1971, THRESHOLD LOGIC ITS; Murty K.G., 1976, LINEAR COMBINATORIAL; Nilsson N., 1965, LEARNING MACHINES; PITT L, 1988, J ACM, V35, P965, DOI 10.1145/48014.63140; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; Rocchio J., 1971, SMART RETRIEVAL SYST, P313; Rumelhart D. E., 1988, PARALLEL DISTRIBUTED; STOER J, 1970, CONVEXITY OPTIMIZATI, V0001; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WONG SKM, 1990, J AM SOC INFORM SCI, V41, P334, DOI 10.1002/(SICI)1097-4571(199007)41:5<334::AID-ASI4>3.0.CO;2-2	16	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1992	14	10					1052	1056		10.1109/34.159907	http://dx.doi.org/10.1109/34.159907			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR944					2022-12-18	WOS:A1992JR94400007
J	DONCARLI, C; LECARPENTIER, E				DONCARLI, C; LECARPENTIER, E			AN OPTIMAL APPROACH FOR RANDOM SIGNALS CLASSIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BAYES PROCEDURES; DECISION THEORY; DISTANCES FOR SIGNAL PROCESSING; PATTERN CLASSIFICATION; SIGNAL RECOGNITION	DISTANCE	The classification of stationary ergodic random signals is usually done by techniques derived from the Bayes theory. The main problem is to test the coherence of the signal to be classified with the distribution laws of the clusters, and a large number of dissimilarity measures between signals are proposed in the literature. One can recall the distances dealing with probability laws (e.g., Kullback divergence) or with power spectrum density (Itakura distance, cepstrum coefficients Euclidian distance, etc.). It would then be natural to use those dissimilarity indexes with a k-NN method, which is a nonparametric approximation of the Bayes procedure. Nevertheless, a very important point is missed in this traditional approach: The descriptive parameters of the signals are always estimated from finite length data sequences but never exactly known while the previous procedures work with perfectly known models (except for the Itakura-Saito distance, which is between an estimated and a known model). This uncertainty of knowledge is a consequence of the finite length of the data sequences, and it automatically disturbs the performances of the classification rules except if it is precisely assessed and included in the decision process. We intend to reach this goal with a direct computation of the a posteriori probabilities of the classes conditionally to the learning data set and the sample to be classified. This new approach can be viewed as an application of the Bayes theory to the actual hypothesis (classes and samples known by finite length signals) of real problems, leading to an optimal decision law (minimization of the total classification error), whereas traditionnal methods, based on the wrong hypothesis of perfect knowledge of the clusters, cannot be optimal in a real case.			DONCARLI, C (corresponding author), ECOLE NATL SUPER MECAN 1,AUTOMAT LAB,NANTES,FRANCE.		Le Carpentier, Eric/AAT-9202-2021	Le Carpentier, Eric/0000-0002-1130-2974				BASSEVILLE M, 1989, SIGNAL PROCESSING, V18; DESOUZA P, 1977, IEEE T ACOUST SPEECH, V25, P554, DOI 10.1109/TASSP.1977.1163004; Gersch W., 1981, APPL TIME SERIES ANA, P221; GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849; GRAY RM, 1980, IEEE T ACOUST SPEECH, V28, P367, DOI 10.1109/TASSP.1980.1163421; GRETTENBERG TL, 1963, IEEE T INFORM THEORY, V9; Itakura F., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P1257; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; KAZAKOS D, 1978, IEEE T INFORM THEORY, V24, P747, DOI 10.1109/TIT.1978.1055967; Makhoul J., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P995; SHORE JE, 1982, IEEE T PATTERN ANAL, V14, P11; TRIBOLET JM, 1979, P ICASSP, P739; TROUBORST PM, 1974, 2 P INT JOINT C PATT	14	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1991	13	11					1192	1196		10.1109/34.103278	http://dx.doi.org/10.1109/34.103278			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GN338					2022-12-18	WOS:A1991GN33800007
J	LACROIX, V				LACROIX, V			A 3-MODULE STRATEGY FOR EDGE-DETECTION - REPLY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											LACROIX, V (corresponding author), PHILIPS RES LABS,AVE VAN BECELAERE 2,BOX 8,B-1170 BRUSSELS,BELGIUM.								0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1990	12	2					224	224						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CL282					2022-12-18	WOS:A1990CL28200012
J	PRASANNAKUMAR, VK				PRASANNAKUMAR, VK			CORRECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		PRASANNAKUMAR VK, 1989, IEEE T PATTERN ANAL, V11, P1194, DOI 10.1109/34.42857	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1990	12	1					108	108						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CG247					2022-12-18	WOS:A1990CG24700013
J	CHEN, JS; HUERTAS, A; MEDIONI, G				CHEN, JS; HUERTAS, A; MEDIONI, G			FAST CONVOLUTION WITH LAPLACIAN-OF-GAUSSIAN MASKS - REPLY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV SO CALIF,DEPT COMP SCI,LOS ANGELES,CA 90089	University of Southern California	CHEN, JS (corresponding author), UNIV SO CALIF,DEPT ELECT ENGN,LOS ANGELES,CA 90089, USA.							HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020	2	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1989	11	12					1332	1332						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB716					2022-12-18	WOS:A1989CB71600011
J	MATSUKI, M; UEDA, T				MATSUKI, M; UEDA, T			A REAL-TIME SECTIONAL IMAGE MEASURING SYSTEM USING TIME SEQUENTIALLY CODED GRATING METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MATSUKI, M (corresponding author), NIPPON TELEGRAPH & TEL PUBL CORP, YOKOSUKA ELECT COMMUN LABS, YOKOSUKA, KANAGAWA 23803, JAPAN.							ALTSCHULER MD, 1981, OPT ENG, V20, P953, DOI 10.1117/12.7972842; ALTSCHULER MD, 1981, P SOC PHOTO-OPT INST, V283, P15; FORSEN GE, 1968, PICTORIAL PATT RECOG; GENNERY DB, 1979, 6TH P INT JOINT C AR, P320; KANADE T, 1981, SPSE, V283, P48; Minou M., 1981, Transactions of the Institute of Electronics and Communication Engineers of Japan, Section E (English), VE64, P521; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; Sato K., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1168; SHIRAI Y, 1971, 2ND P INT JOINT C AR, P80; TAKASAKI H, 1970, APPL OPTICS, V9, P1467, DOI 10.1364/AO.9.001467; UEDA T, 1978, ELECTRONIC GRATING M, V1; UEDA T, 1981, T IECE JAPAN D, V64, P780; UENO K, 1980, APPL OPTICS, V19, P164, DOI 10.1364/AO.19.000164; Yagi, 1973, COMPUT VISION GRAPH, V2, P131; [No title captured]	15	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1225	1228		10.1109/34.42862	http://dx.doi.org/10.1109/34.42862			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796					2022-12-18	WOS:A1989AW79600011
J	MITICHE, A				MITICHE, A			ON KINEOPSIS AND COMPUTATION OF STRUCTURE AND MOTION - COMMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MITICHE, A (corresponding author), INRS TELECOMMUN,3 PL COMMERCE,ILE DES SOEURS H3E 1H6,QUEBEC,CANADA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7; MAYBANK SJ, 1986, IMAGE VISION COMPUT, V4, P38, DOI 10.1016/0262-8856(86)90006-5; MEIRI AZ, 1980, IEEE T PATTERN ANAL, V2, P582, DOI 10.1109/TPAMI.1980.6447706; MITICHE A, 1986, IEEE T PATTERN ANAL, V8, P109, DOI 10.1109/TPAMI.1986.4767758; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077	5	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1989	11	5					540	541						2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U3604					2022-12-18	WOS:A1989U360400010
J	SANZ, JLC				SANZ, JLC			PAMI SPECIAL ISSUE ON INDUSTRIAL MACHINE VISION AND COMPUTER VISION TECHNOLOGY .2. INTRODUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material											SANZ, JLC (corresponding author), UNIV CALIF DAVIS,COMP VIS RES LAB,DAVIS,CA 95616, USA.							1987, OCT P IEEE WORKSH CO; 1988, ADV MACHINE VISION; 1988, MACHINE VISION APPLI	3	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1988	10	3					289	290						2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	N5337					2022-12-18	WOS:A1988N533700001
J	ANTOY, S				ANTOY, S			MODELING AND ISOMORPHISMS OF POSITIONAL BOARD GAMES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											ANTOY, S (corresponding author), IST MATEMAT APPLICATA,VIA LB ALBERTI 4,I-16132 GENOVA,ITALY.							[Anonymous], 1980, PRINCIPLES ARTIFICIA; BANERJI RB, 1980, ARTIFICIAL INTELLIGE; BANERJI RB, 1972, ARTIFICIAL INTELL, V3; Barr A, 1981, HDB ARTIFICIAL INTEL, VI; CORAY G, 1976, COMPUTER ORIENTED LE; Gardner M., 1959, MATH PUZZLES DIVERSI; JACKSON PC, 1974, INTRO ARTIFICIAL INT; KING PF, 1970, THESIS CASE W RESERV; KOFFMAN EG, 1968, IEEE T SYST SCI CYBE, V4; LASKER E, 1934, GO GO MOKU; NEWELL A, 1966, COMPUT SCI RES REV; Pierce John Robinson, 1972, SYMBOLS SIGNALS NOIS, V9, P150; SILVER R, 1967, AM MATH MONTHLY, V74	13	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					669	675		10.1109/TPAMI.1987.4767961	http://dx.doi.org/10.1109/TPAMI.1987.4767961			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869425				2022-12-18	WOS:A1987J739300008
J	DORST, L				DORST, L			CORRECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		DORST L, 1986, IEEE PATT A, V8	1	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1986	8	5					676	676		10.1109/TPAMI.1986.4767845	http://dx.doi.org/10.1109/TPAMI.1986.4767845			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	D7584					2022-12-18	WOS:A1986D758400013
J	GOSHTASBY, A				GOSHTASBY, A			COMMENTS ON SCALE-BASED DESCRIPTION AND RECOGNITION OF PLANAR CURVES AND TWO-DIMENSIONAL SHAPES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											GOSHTASBY, A (corresponding author), UNIV KENTUCKY, DEPT COMP SCI, LEXINGTON, KY 40506 USA.							BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	3	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1986	8	5					674	675		10.1109/TPAMI.1986.4767841	http://dx.doi.org/10.1109/TPAMI.1986.4767841			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	D7584					2022-12-18	WOS:A1986D758400009
J	LEVINE, MD; NAZIF, AM				LEVINE, MD; NAZIF, AM			LOW-LEVEL SEGMENTATION - AN EXPERT SYSTEM - REPLY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV CAIRO,DEPT ELECT ENGN,CAIRO,EGYPT	Cairo University	LEVINE, MD (corresponding author), MCGILL UNIV,DEPT ELECT ENGN,MONTREAL H3A 2A7,QUEBEC,CANADA.							LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1986	8	5					676	676		10.1109/TPAMI.1986.4767844	http://dx.doi.org/10.1109/TPAMI.1986.4767844			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	D7584					2022-12-18	WOS:A1986D758400012
J	MOKHTARIAN, F; MACKWORTH, A				MOKHTARIAN, F; MACKWORTH, A			COMMENTS ON SCALE-BASED DESCRIPTION AND RECOGNITION OF PLANAR CURVES AND TWO-DIMENSIONAL SHAPES - REPLY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MOKHTARIAN, F (corresponding author), UNIV BRITISH COLUMBIA,DEPT COMP SCI,COMPUTAT VISION LAB,VANCOUVER V6T 1W5,BC,CANADA.								0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1986	8	5					675	675		10.1109/TPAMI.1986.4767842	http://dx.doi.org/10.1109/TPAMI.1986.4767842			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	D7584					2022-12-18	WOS:A1986D758400010
J	DUBOIS, SR				DUBOIS, SR			CORRECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					561	561		10.1109/TPAMI.1986.4767825	http://dx.doi.org/10.1109/TPAMI.1986.4767825			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000020
J	KIM, BS; PARK, SB				KIM, BS; PARK, SB			AN AUTOMATED APPROACH TO THE DESIGN OF DECISION TREE CLASSIFIERS - COMMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											KIM, BS (corresponding author), KOREA ADV INST SCI & TECHNOL,DEPT ELECT ENGN,POB 131,SEOUL 131,SOUTH KOREA.							ARGENTIERO P, 1982, IEEE T PATTERN ANAL, V4, P51, DOI 10.1109/TPAMI.1982.4767195	1	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					560	560		10.1109/TPAMI.1986.4767824	http://dx.doi.org/10.1109/TPAMI.1986.4767824			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000019
J	LI, CC; KASHYAP, RL				LI, CC; KASHYAP, RL			FU,KING-SUN (1930-1985) - A BIOGRAPHY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Item About an Individual									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907; AT&T BELL LABS,MURRAY HILL,NJ 07974	Purdue University System; Purdue University; Purdue University West Lafayette Campus; AT&T; Nokia Corporation; Nokia Bell Labs	LI, CC (corresponding author), UNIV PITTSBURGH,DEPT ELECT ENGN,PITTSBURGH,PA 15261, USA.							FU KS, PUBLICATION LIST	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1986	8	3					291	303						13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C0841					2022-12-18	WOS:A1986C084100001
J	MINOH, M; SAKAI, T				MINOH, M; SAKAI, T			MESH-ORIENTED LINE DRAWINGS THEORY (MOLD THEORY)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MINOH, M (corresponding author), KYOTO UNIV,DEPT INFORMAT SCI,KYOTO 606,JAPAN.							CLOWS MB, 1971, ARTIFICIAL INTELLIGE, V2, P101; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; JARVIS JF, 1980, IEEE T PATTERN ANAL, V2, P77, DOI 10.1109/TPAMI.1980.4766975; KNUDSON DR, 1975, MIT ESIR616 EL SYST; MINOH M, UNPUB ADAPTIVE SYSTE; MINOH M, 1982, THESIS KYOTO U KYOTO; PAVLIDIS T, 1982, ALGORITHMS GRAPHICS, P137; TOMINAGA H, 1974, IECE JAPAN IE, V74, P79; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19	9	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					210	221		10.1109/TPAMI.1986.4767774	http://dx.doi.org/10.1109/TPAMI.1986.4767774			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869339				2022-12-18	WOS:A1986A107300008
J	PAVLIDIS, T				PAVLIDIS, T			PAPERS ON SHAPE-ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1986	8	1					1	1						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AWT86					2022-12-18	WOS:A1986AWT8600001
J	BRUCKSTEIN, AM; COVER, TM				BRUCKSTEIN, AM; COVER, TM			MONOTONICITY OF LINEAR SEPARABILITY UNDER TRANSLATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									STANFORD UNIV,DEPT ELECT ENGN & STAT,STANFORD,CA 94305	Stanford University	BRUCKSTEIN, AM (corresponding author), STANFORD UNIV,DEPT ELECT ENGN,STANFORD,CA 94305, USA.							COVER T, 1965, IEEE T ELECT COMPUTE, P326; TOU JT, 1979, PATTERN RECOGNITION	2	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					355	358		10.1109/TPAMI.1985.4767666	http://dx.doi.org/10.1109/TPAMI.1985.4767666			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869272				2022-12-18	WOS:A1985AFM4400012
J	FOX, MS				FOX, MS			SPECIAL SECTION ON EXPERT SYSTEM - INTRODUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material											FOX, MS (corresponding author), CARNEGIE MELLON UNIV,INST ROBOT,INTELLIGENT SYST LAB,PITTSBURGH,PA 15213, USA.								0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	5					501	501		10.1109/TPAMI.1985.4767697	http://dx.doi.org/10.1109/TPAMI.1985.4767697			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AQH94					2022-12-18	WOS:A1985AQH9400001
J	MADARASZ, RL; THOMPSON, WB				MADARASZ, RL; THOMPSON, WB			RECOGNITION OF MOVING-OBJECTS USING FEATURE SIGNATURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MINNESOTA,DEPT COMP SCI,MINNEAPOLIS,MN 55455	University of Minnesota System; University of Minnesota Twin Cities	MADARASZ, RL (corresponding author), ARIZONA STATE UNIV,DEPT COMP SCI,TEMPE,AZ 85287, USA.							GLEASON GJ, 1979, 9TH P INT S IND ROB; HALL EL, 1982, COMPUTER, V15, P42; JOHANSSON G, 1976, PSYCHOL RES-PSYCH FO, V38, P379, DOI 10.1007/BF00309043; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SMITH SP, 1982, COMPUT VISION GRAPH, V20, P259, DOI 10.1016/0146-664X(82)90084-3; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VANDERBURG GJ, 1979, 9TH P INT S IND ROB, P213; WALLACH H, 1953, J EXP PSYCHOL, V45, P205, DOI 10.1037/h0056880	10	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					713	717		10.1109/TPAMI.1985.4767728	http://dx.doi.org/10.1109/TPAMI.1985.4767728			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869310				2022-12-18	WOS:A1985ATG0500010
J	MARSLAND, TA				MARSLAND, TA			CORRECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		MARSLAND TA, 1985, IEEE T PATTERN ANAL, V7, P442, DOI 10.1109/TPAMI.1985.4767683	1	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					748	748		10.1109/TPAMI.1985.4767737	http://dx.doi.org/10.1109/TPAMI.1985.4767737			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05					2022-12-18	WOS:A1985ATG0500019
J	PAVLIDIS, T				PAVLIDIS, T			FU,KING,SUN - IN MEMORIAM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Item About an Individual																			0	0	1	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					373	373						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69					2022-12-18	WOS:A1985ALB6900001
J	SHEELA, BV				SHEELA, BV			A COGNITIVE HEURISTIC ALGORITHM FOR RESEAU MARK DETECTION BY HILL CLIMBING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SHEELA, BV (corresponding author), ISRO,SATELLITE CTR,DIV MISS OPERATING & PLANNING,PEENYA IND ESTATE,BANGALORE 560058,INDIA.							BERNSTEIN R, 1971, 8TH P AN M AM I AER, V21; BERNSTEIN R, 1973, CR142335 IBM CORP; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; RAMAMOORTHY P, 1973, NALAETM51973 NAL; SHEELA BV, 1979, COMPUT METHOD APPL M, V19, P99, DOI 10.1016/0045-7825(79)90035-5; 1981, BHASKARA 2 DATA HDB	6	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					743	747		10.1109/TPAMI.1985.4767735	http://dx.doi.org/10.1109/TPAMI.1985.4767735			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869317				2022-12-18	WOS:A1985ATG0500017
J	BAILEY, T; COWLES, J				BAILEY, T; COWLES, J			CLUSTER DEFINITION BY THE OPTIMIZATION OF SIMPLE MEASURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											BAILEY, T (corresponding author), UNIV WYOMING, DEPT COMP SCI, LARAMIE, WY 82071 USA.							BAILEY TA, 1982, PATTERN RECOGN, V15, P61, DOI 10.1016/0031-3203(82)90002-4; BAKER FB, 1976, J AM STAT ASSOC, V71, P870, DOI 10.2307/2286853; Garey M. R., 1976, Theoretical Computer Science, V1, P237, DOI 10.1016/0304-3975(76)90059-1; Garey M.R., 1979, COMPUTERS INTRACTABI; GOWER JC, 1969, APPL STATIST, V18, P54, DOI DOI 10.2307/2346439; HARTIGAN JA, 1967, J AM STAT ASSOC, V62, P1140, DOI 10.2307/2283766; HUBERT LJ, 1974, PSYCHOMETRIKA, V39, P283, DOI 10.1007/BF02291704; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; LING RF, 1972, J AM STAT ASSOC, V68, P326; MATULA DW, 1977, CLASSIFICATION CLUST; MCQUITTY LL, 1961, EDUC PSYCHOL MEAS, V21, P677, DOI 10.1177/001316446102100314; MCQUITTY LL, 1967, EDUC PSYCHOL MEAS, V27, P21, DOI 10.1177/001316446702700103; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25, DOI 10.1109/TPAMI.1979.4766873; van Rijsbergen C. J., 1970, Computer Journal, V13, P113; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	15	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					645	652		10.1109/TPAMI.1984.4767579	http://dx.doi.org/10.1109/TPAMI.1984.4767579			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813	21869234				2022-12-18	WOS:A1984TM81300011
J	SHANMUGAN, KS				SHANMUGAN, KS			A MODEL FOR RADAR IMAGES AND ITS APPLICATION TO ADAPTIVE DIGITAL FILTERING OF MULTIPLICATIVE NOISE - REPLY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											SHANMUGAN, KS (corresponding author), UNIV KANSAS,DEPT ELECT ENGN,LAWRENCE,KS 66045, USA.							FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223; GOLDFINGER AD, 1982, AUG ISP RS S OTT; MEHL W, 1980, ESA SP172, P29; RUPPELT R, 1981, 3RD TU INT REP; RUPPELT R, 1981, 2ND TU INT REP; RUPPELT R, 1981, 1ST TU INT REP	6	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					659	659		10.1109/TPAMI.1984.4767583	http://dx.doi.org/10.1109/TPAMI.1984.4767583			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813					2022-12-18	WOS:A1984TM81300016
J	NAGURA, M; SUENAGA, Y				NAGURA, M; SUENAGA, Y			A FACSIMILE-BASED GRAPHICS EDITING SYSTEM BY AUXILIARY MARK RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											NAGURA, M (corresponding author), NIPPON TELEGRAPH & TEL PUBL CORP,YOKOSUKA ELECT COMMUN LABS,VISUAL COMMUN APPLICAT SECT,YOKOSUKA,KANAGAWA 23803,JAPAN.							ISHII M, 1981, 18TH P DES AUT C, P639; JARVIS JF, 1977, COMPUT GRAPHICS IMAG, V6, P452; Kamae T., 1981, Real-Time/Parallel Computing. Image Analysis. Proceedings of Part of the Japan-United States Seminar on Research Towards Real-Time Parallel Image Analysis and Recognition, P267; NAGURA M, 1981, T IECE JAPAN     SEP, P839; NAGURA M, 1981, T IECE JAPAN     MAR, P198; NAGURA M, 1981, T IECE JAPAN     JAN, P70; OKADA M, 1978, IE7874 IECE TECH REP, P17; SUENAGA Y, 1980, 5TH P INT C PATT REC, P856; SUENAGA Y, 1980, T IECE JAPAN D, V63, P1072; TANIGUCHI M, 1979, JUN ICC 79 C REC	10	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	4					433	441		10.1109/TPAMI.1983.4767413	http://dx.doi.org/10.1109/TPAMI.1983.4767413			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RA578	21869128				2022-12-18	WOS:A1983RA57800009
J	BHANU, B				BHANU, B			CORRECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition														Bhanu, Bir/0000-0001-8971-6416				BHANU B, 1982, IEEE T PATTERN ANAL, V4, P408, DOI 10.1109/TPAMI.1982.4767273	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					689	689		10.1109/TPAMI.1982.4767327	http://dx.doi.org/10.1109/TPAMI.1982.4767327			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237					2022-12-18	WOS:A1982PS23700019
J	FU, KS				FU, KS			THE 1ST 3 YEARS OF PAMI	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					1	1						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534					2022-12-18	WOS:A1982MY53400001
J	GIRYN, A				GIRYN, A			A SPECIES CLASSIFIER OF SEA CREATURES COMPILED ON THE BASIS OF THEIR ECHO SOUNDER SIGNALS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											GIRYN, A (corresponding author), MERCHANG NAVY ACAD,UL CZERWONYCH KOSYNIEROW 83,PL-81962 GDYNIA,POLAND.							GIRYN A, 1981, M HYDROACOUST METHOD, V2, P467; GIRYN A, 1981, M HYDROACOUST METHOD, V2, P455; SEBESTYN GS, 1962, DECISION MAKING PROC; Tou JT, 1974, PATTERN RECOGN; 1979, M HYDROACOUST METHOD, V2, P1	5	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					666	671		10.1109/TPAMI.1982.4767323	http://dx.doi.org/10.1109/TPAMI.1982.4767323			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499644				2022-12-18	WOS:A1982PS23700015
J	NIEMANN, H; SAGERER, G				NIEMANN, H; SAGERER, G			AN EXPERIMENTAL-STUDY OF SOME ALGORITHMS FOR UNSUPERVISED LEARNING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											NIEMANN, H (corresponding author), UNIV ERLANGEN NURNBERG,LEHRSTUHL INFORMAT 5,D-8520 ERLANGEN,FED REP GER.							AGRAWALA AK, 1970, IEEE T INFORM THEORY, V16, P373, DOI 10.1109/TIT.1970.1054472; Duda R.O., 1972, PATTERN CLASSIFICATI; FUKUNAGA K, 1972, INTRO STATISTICAL PA; IMAI T, 1976, PATTERN RECOGNITION, V8, P225; JAPEL D, 1980, THESIS ERLANGEN, V13; KAUFMANN M, 1980, THESIS U ERLANGEN ER; Mendel J. M., 1970, ADAPTIVE LEARNING PA; NIEMANN H, 1970, NACHRICHTENTECH Z, V23, P308; NIEMANN H, 1978, BILDVERARBEITUNG MUS, V17, P3; NIEMANN H, 1974, METHODEN MUSTERERKEN; PATRICK EA, 1970, IEEE T INFORM THEORY, V16, P556, DOI 10.1109/TIT.1970.1054534; SAGERER G, 1980, THESIS U ERLANGEN ER; SCUDDER HJ, 1965, IEEE T INFORM THEORY, V11, P167, DOI 10.1109/TIT.1965.1053752; SHANMUGA.K, 1972, IEEE T INFORM THEORY, V18, P300, DOI 10.1109/TIT.1972.1054780; TEICHER H, 1963, ANN MATH STAT, V34, P1265, DOI 10.1214/aoms/1177703862; TSYPKIN YZ, 1973, F THEORY LEARNING SY; WOLFE JH, 1970, MULTIVAR BEHAV RES, V5, P329, DOI 10.1207/s15327906mbr0503_6; YAKOWITZ SJ, 1970, IEEE T INFORM THEORY, V16, P330, DOI 10.1109/TIT.1970.1054442	18	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	4					400	405		10.1109/TPAMI.1982.4767271	http://dx.doi.org/10.1109/TPAMI.1982.4767271			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	NT735	21869054				2022-12-18	WOS:A1982NT73500006
J	SMITH, JW; THARP, AL				SMITH, JW; THARP, AL			A MICROCOMPUTER SYSTEM FOR PROCESSING NATURAL LANGUAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											SMITH, JW (corresponding author), N CAROLINA STATE UNIV,DEPT COMP SCI,RALEIGH,NC 27650, USA.							Akmajian Adrian, 1975, INTRO PRINCIPLES TRA; HAYS DG, 1973, P NCC, P1; HERMAN LR, 1975, P SEACM; KNUTH DE, 1975, ART COMPUTER PROGRAM, V3; Kohonen T., 1977, ASS MEMORY; PETRICK SA, 1965, THESIS MASSACHUSETTS; PLATH WJ, 1973, IBM RC4396 RES; SCHAY G, 1963, IBM J RES DEV, P121; SMITH JW, 1978, P SEACM          APR, P187; SMITH JW, 1979, INT J MAN MACH STUDI, V11; THARP AL, 1975, INT J MAN MACH STUD, V7, P703, DOI 10.1016/S0020-7373(75)80034-4; WOODS WA, 1970, COMMUN ACM, V13, P591, DOI 10.1145/355598.362773	12	0	0	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					221	223		10.1109/TPAMI.1982.4767230	http://dx.doi.org/10.1109/TPAMI.1982.4767230			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869029				2022-12-18	WOS:A1982NE95700019
J	TRUNK, GV; COLEMAN, JO				TRUNK, GV; COLEMAN, JO			REPEATED HYPOTHESIS-TESTING ON A GROWING DATA SET	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											TRUNK, GV (corresponding author), USN,RES LAB,DIV RADAR,RADAR ANALY BRANCH,WASHINGTON,DC 20375, USA.							Hartman P, 1941, AM J MATH, V63, P169, DOI 10.2307/2371287	1	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					343	345		10.1109/TPAMI.1982.4767256	http://dx.doi.org/10.1109/TPAMI.1982.4767256			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869046	Green Published			2022-12-18	WOS:A1982NN06900017
J	BRAILOVSKY, V				BRAILOVSKY, V			ON THE INFLUENCE OF SAMPLE SET STRUCTURE ON DECISION RULE QUALITY FOR THE CASE OF A LINEAR DISCRIMINANT FUNCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter																		AFIFI AA, 1966, J AM STAT ASSOC, V61, P595, DOI 10.2307/2282773; BARRA JR, 1979, NOV SEM EC POL PAR; BEALE EML, 1975, J ROY STAT SOC B MET, V37, P129; BUCK SF, 1960, J ROY STAT SOC B, V22, P302; CRAMER R, 1946, MATH METHODS STATIST; Duda R.O., 1973, J ROYAL STAT SOC SER; DUNN RPW, 1976, 3RD P INT JOINT C PA, P156; GLASSER M, 1964, JASA, V59, P839; HAITOVSKY Y, 1968, J R STAT SOC B, V30, P67; KITTLER J, 1978, IEEE T COMPUT, V27, P367, DOI 10.1109/TC.1978.1675109; OKAMOTO M, 1963, ANN MATH STAT, V34, P1286, DOI 10.1214/aoms/1177703864; ORCHARD T, 6TH P BERK S MATH ST, V1, P697	12	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					454	459		10.1109/TPAMI.1981.4767130	http://dx.doi.org/10.1109/TPAMI.1981.4767130			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ357	21868965				2022-12-18	WOS:A1981MQ35700009
J	CERCONE, NJ				CERCONE, NJ			REPRESENTING AND PROCESSING GRAMMATICAL MODIFIERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CERCONE, NJ (corresponding author), SIMON FRASER UNIV,DEPT COMP SCI,BURNABY V5A 1S6,BC,CANADA.							Anderson J.R., 1973, HUMAN ASS MEMORY; Bartsch R., 1972, SEMANTIC STRUCTURES; CERCONE N, 1975, 7511 U ALB DEP COMP; CERCONE N, 1975, 4TH INT JOINT C ART, P83; CERCONE N, 1977, 5TH P INT JOINT C AR, P139; Cresswell MJ, 1973, LOGICS AND LANGUAGES; DAVIDSON D, 1972, SEMANTICS NATURAL LA; Lakoff G., 1973, J PHILOS LOGIC, V2, P458, DOI DOI 10.1007/BF00262952; Montague RM, 1970, PROPER TREATMENT QUA; Norman D.A., 1975, EXPLORATIONS COGNITI; PARSONS T, 1972, SEMANTICS NATURAL LA, P127; Reichenbach Hans, 1966, ELEMENTS SYMBOLIC LO; REIGER C, 1976, ARTIFICIAL INTELL, V7, P89; RUSSELL B, 1975, LOGIC GRAMMAR, P184; SCHANK RC, 1974, LINGUA, V33, P45, DOI 10.1016/0024-3841(74)90055-2; SCHANK RC, 1972, COGNITIVE PSYCHOL, V3, P552, DOI 10.1016/0010-0285(72)90022-9; SCHUBERT LK, 1976, ARTIF INTELL, V7, P163, DOI 10.1016/0004-3702(76)90003-5; Zadeh LA, 1972, J CYBERNETICS, V2, P4, DOI [10.1080/01969727208542910, DOI 10.1080/01969727208542910]	18	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					357	367		10.1109/TPAMI.1981.4767122	http://dx.doi.org/10.1109/TPAMI.1981.4767122			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	MQ357	21868957				2022-12-18	WOS:A1981MQ35700001
J	DEVIJVER, PA				DEVIJVER, PA			COMMENTS ON NOSING AROUND THE NEIGHBORHOOD - A NEW SYSTEM STRUCTURE AND CLASSIFICATION RULE FOR RECOGNITION IN PARTIALLY EXPOSED ENVIRONMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											DEVIJVER, PA (corresponding author), PHILIPS RES LAB,B-1170 BRUSSELS,BELGIUM.							BUNGE E, 1977, THESIS TU DARMSTADT; DEVIJVER PA, 1979, R410 PHIL RES LAB RE; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; TOMEK I, 1976, JUN IEEE T SYST MAN, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	6	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					696	697		10.1109/TPAMI.1981.4767173	http://dx.doi.org/10.1109/TPAMI.1981.4767173			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	MR996	21868992				2022-12-18	WOS:A1981MR99600012
J	SHEELA, BV; DASARATHY, BV				SHEELA, BV; DASARATHY, BV			ANDAL - A NONPARAMETRIC DISCRIMINATION AND LEARNING ALGORITHM FOR RECOGNITION IN IMPERFECTLY SUPERVISED ENVIRONMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									INTERG CORP,HUNTSVILLE,AL 35805		SHEELA, BV (corresponding author), ISRO,SATELLITE CTR,BANGALORE 562140,INDIA.							DASARATHY BV, 1976, INT J COMPUT INF SCI, V5, P1, DOI 10.1007/BF00991068; DASARATHY BV, 1976, P IEEE, V64, P823, DOI 10.1109/PROC.1976.10222; DASARATHY BV, 1979, INT J COMPUT INF SCI, V8, P75, DOI 10.1007/BF00995428; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P917, DOI 10.1109/T-C.1970.222799; HO YC, 1966, SIAM J CONTROL, V4, P112; Kashyap R. L., 1970, Adaptive, learning, and pattern recognition systems: theory and applications, P81; LAKSHMINARASIMH.AL, 1975, THESIS INDIAN I SCI, P38; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; PETERSON DW, 1966, IEEE T INFORM THEORY, V12, P380, DOI 10.1109/TIT.1966.1053913; RAMAMOORTY P, 1973, NAL AETM473 NAT AER; SHANMUGAM K, 1971, IEEE T SYST MAN CYB, VSMC1, P223, DOI 10.1109/TSMC.1971.4308289; SHEELA BV, 1979, INT J COMPUT INF SCI, V8, P239, DOI 10.1007/BF00977790; TEICHER H, 1963, ANN MATH STAT, V34, P1265, DOI 10.1214/aoms/1177703862; WARMACK RE, 1973, IEEE T COMPUT, VC 22, P1065, DOI 10.1109/T-C.1973.223652	14	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					469	476		10.1109/TPAMI.1981.4767132	http://dx.doi.org/10.1109/TPAMI.1981.4767132			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ357	21868967				2022-12-18	WOS:A1981MQ35700011
J	WALLACE, TP				WALLACE, TP			COMMENTS ON ALGORITHMS FOR SHAPE-ANALYSIS OF CONTOURS AND WAVEFORMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											WALLACE, TP (corresponding author), MIT,LINCOLN LAB,LEXINGTON,MA 02173, USA.							PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; WALLACE TC, UNPUBLISHED; WALLACE TP, 1979, TREE7943 PURD U SCH	3	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	5					593	593		10.1109/TPAMI.1981.4767150	http://dx.doi.org/10.1109/TPAMI.1981.4767150			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	MQ358					2022-12-18	WOS:A1981MQ35800008
J	SKLANSKY, J; KRUGER, RP				SKLANSKY, J; KRUGER, RP			SPECIAL ISSUE ON BIOMEDICAL PATTERN-ANALYSIS - PREFACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									UNIV CALIF IRVINE,DEPT COMP SCI,IRVINE,CA 92664; UNIV CALIF IRVINE,DEPT RADIOL SCI,IRVINE,CA 92664; UNIV CALIF LOS ALAMOS SCI LAB,MAT EVALUAT GRP,LOS ALAMOS,NM 87544	University of California System; University of California Irvine; University of California System; University of California Irvine; United States Department of Energy (DOE); Los Alamos National Laboratory	SKLANSKY, J (corresponding author), UNIV CALIF IRVINE,DEPT ELECT ENGN,IRVINE,CA 92664, USA.								0	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	5					381	382		10.1109/TPAMI.1980.6592359	http://dx.doi.org/10.1109/TPAMI.1980.6592359			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KW185					2022-12-18	WOS:A1980KW18500001
J	WATANABE, S				WATANABE, S			CORRECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		WATANABE S, 1980, IEEE T PATTERN ANAL, V2, P161, DOI 10.1109/TPAMI.1980.4766993	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	3					273	274		10.1109/TPAMI.1980.4767018	http://dx.doi.org/10.1109/TPAMI.1980.4767018			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR843					2022-12-18	WOS:A1980JR84300011
J	EDEN, G				EDEN, G			DECLUSTERING CRITERION FOR FEATURE EXTRACTION IN PATTERN-RECOGNITION - COMMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											EDEN, G (corresponding author), VRIJE UNIV BRUSSEL,B-1050 BRUSSELS,BELGIUM.							FEHLAUER J, 1978, IEEE T COMPUT, V27, P261, DOI 10.1109/TC.1978.1675083	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					307	307		10.1109/TPAMI.1979.4766927	http://dx.doi.org/10.1109/TPAMI.1979.4766927			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868863				2022-12-18	WOS:A1979HC30100009
J	NAKAMURA, A				NAKAMURA, A			SOME DECISION PROBLEMS FOR BOTTOM-UP TRIANGLE ACCEPTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MARYLAND,CTR COMP SCI,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	NAKAMURA, A (corresponding author), HIROSHIMA UNIV,DEPT APPL MATH,HIROSHIMA 730,JAPAN.							CHOUEKA YA, 1974, IEEE T COMPUT, VC 23, P1218, DOI 10.1109/T-C.1974.223840; DYER CR, 1977, 544 U MAR COMP SCI C; NAKAMURA A, 1975, J COMPUT SYST SCI, V10, P253, DOI 10.1016/S0022-0000(75)80044-4	3	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	4					415	417		10.1109/TPAMI.1979.4766953	http://dx.doi.org/10.1109/TPAMI.1979.4766953			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HV227	21868879				2022-12-18	WOS:A1979HV22700013
J	OROURKE, J				OROURKE, J			CORRECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		OROURKE J, 1979, IEEE T PATTERN ANAL, V1, P295, DOI 10.1109/TPAMI.1979.4766925	1	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	4					417	417		10.1109/TPAMI.1979.4766954	http://dx.doi.org/10.1109/TPAMI.1979.4766954			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HV227					2022-12-18	WOS:A1979HV22700014
J	SMITH, CB				SMITH, CB			DUAL METHOD FOR MAXIMUM ENTROPY RESTORATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SMITH, CB (corresponding author), CALTECH,JET PROP LAB,PASADENA,CA 91103, USA.							DESCHAMPS GA, 1972, IEEE T ANTENN PROPAG, VAP20, P268, DOI 10.1109/TAP.1972.1140197; EKSTROM MP, 1972, 6TH P AS C CIRC SYST, P489; FRIEDEN BR, 1972, J OPT SOC AM, V62, P511, DOI 10.1364/JOSA.62.000511; GULL SF, 1978, NATURE, V272, P686, DOI 10.1038/272686a0; HOU HS, 1977, IEEE T COMPUT, V26, P856, DOI 10.1109/TC.1977.1674934; HUANG TS, 1975, PICTURE PROCESSING D, pCH5; LUENBERGER DG, 1973, INTRO LINEAR NONLINE, pCH10; Rockafellar R. T., 1974, CONJUGATE DUALITY OP; Tikhonov A., 1977, SOLUTIONS ILL POSED; WERNECKE SJ, 1977, IEEE T COMPUT, V26, P351, DOI 10.1109/TC.1977.1674845	10	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	4					411	414		10.1109/TPAMI.1979.4766951	http://dx.doi.org/10.1109/TPAMI.1979.4766951			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HV227	21868877				2022-12-18	WOS:A1979HV22700011
J	VANDERHEYDT, L; OOSTERLINCK, A; VANDENBERGHE, H				VANDERHEYDT, L; OOSTERLINCK, A; VANDENBERGHE, H			DESIGN OF A SPECIAL INTERPRETER FOR THE CLASSIFICATION OF HUMAN-CHROMOSOMES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											VANDERHEYDT, L (corresponding author), DEPT HUMAN BIOL,DIV HUMAN GENET,MINDERBROEDERSTR 12,LEUVEN,BELGIUM.							Fu K.S., 1974, MATH SCI ENG; LEDLEY RS, 1965, OPTICAL ELECTROOPTIC, P591; OOSTERLINCK A, 1977, JUN P IEEE COMP SOC, P61; RESCHER N, 1955, BRIT J PHILOS SCI, V6, P89; WINSTON P, 1975, PSYCHOLOGY COMPUTER; YUNIS JJ, 1977, MOL STRUCTURE HUMAN, P1	6	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					214	219		10.1109/TPAMI.1979.4766908	http://dx.doi.org/10.1109/TPAMI.1979.4766908			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	HA304	21868851				2022-12-18	WOS:A1979HA30400012
