PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Hua, H; Ahuja, N; Gao, CY				Hua, Hong; Ahuja, Narendra; Gao, Chunyu			Design analysis of a high-resolution panoramic camera using conventional imagers and a mirror pyramid	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						panoramic camera; mirror pyramids; omnidirectional imaging, and catadioptric systems		Wide field of view (FOV) and high-resolution image acquisition is highly desirable in many vision-based applications. Several systems have reported the use of reflections off mirror pyramids to capture high-resolution, single-viewpoint, and wide-FOV images. Using a dual mirror pyramid (DMP) panoramic camera as an example, in this paper, we examine how the pyramid geometry, and the selection and placement of imager clusters can be optimized to maximize the overall panoramic FOV, sensor utilization efficiency, and image uniformity. The analysis can be generalized and applied to other pyramid-based designs.	Univ Arizona, Coll Opt Sci, Tucson, AZ 85721 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	University of Arizona; University of Illinois System; University of Illinois Urbana-Champaign	Hua, H (corresponding author), Univ Arizona, Coll Opt Sci, 1630 E Univ Blvd, Tucson, AZ 85721 USA.	hhua@optics.arizona.edu; ahuja@vision.ai.uiuc.edu; cgao@vision.ai.uiuc.edu		Hua, Hong/0000-0002-7255-610X				Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Benosman R. B., 2001, PANORAMIC VISION SEN; Chahl JS, 1997, APPL OPTICS, V36, P8275, DOI 10.1364/AO.36.008275; GAO C, 2004, Patent No. 6809887; Hicks RA, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P97, DOI 10.1109/OMNVIS.2000.853813; Hua H, 2001, PROC CVPR IEEE, P960; ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792; Kawanishi T, 1998, INT C PATT RECOG, P485, DOI 10.1109/ICPR.1998.711187; Krishnan A, 1996, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.1996.517100; Majumder A, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P169, DOI 10.1145/319463.319485; Nalwa V, 2001, US Patent, Patent No. [6,195, 204B1, 6195204]; NALWA V, 1996, TRUE OMNIDIRECTIONAL; Nalwa V., 2004, U.S. Patent, Patent No. [6 700 711, 6700711]; Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369; Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346; Tan KH, 2004, IEEE T PATTERN ANAL, V26, P941, DOI 10.1109/TPAMI.2004.33; Xiong YL, 1997, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.1997.609326; YAMAZAWA K, 1993, IROS 93 : PROCEEDINGS OF THE 1993 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOL 1-3, P1029, DOI 10.1109/IROS.1993.583287; Zhang Z., 1998, MSRTR9871; Zhu ZG, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P29, DOI 10.1109/OMNVIS.2000.853800	20	9	20	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					356	361		10.1109/TPAMI.2007.33	http://dx.doi.org/10.1109/TPAMI.2007.33			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV	17170487				2022-12-18	WOS:000242826900015
J	Cheng, YC				Cheng, Yu Chin			The distinctiveness of a curve in a parameterized neighborhood: Extraction and applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature representation; feature extraction; feature evaluation and selection; geometric models; Hough transform; pattern analysis; object recognition	HOUGH TRANSFORM; ELLIPSES; IMAGES; DETECT	A new feature of curves pertaining to the acceptance/ rejection decision in curve detection is proposed. The feature measures a curve's distinctiveness in its neighborhood, which is modeled by a one- parameter family of curves. A computational framework based on the Hough transform for extracting the distinctiveness feature is elaborated and examples of feature extractors for the circle and the ellipse are given. It is shown that the proposed feature can be extracted efficiently and is effective in separating signals from false positives. Experimental results with circle and ellipse testing that strongly support the efficiency and effectiveness claims are obtained. The results further demonstrate that the proposed feature exhibits good noise resiliency.	Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 10608, Taiwan	National Taipei University of Technology	Cheng, YC (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, 1 Sec 3,Chung Hsiao E Rd, Taipei 10608, Taiwan.	yccheng@ntut.edu.tw						Barrow HG, 1977, P 5 INT JOINT C ART; Bennett N, 1999, IEEE T PATTERN ANAL, V21, P652, DOI 10.1109/34.777377; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BROWN CM, 1983, IEEE T PATTERN ANAL, V5, P493, DOI 10.1109/TPAMI.1983.4767428; CHENG YC, 1995, PATTERN RECOGN, V28, P663, DOI 10.1016/0031-3203(94)00138-C; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GERIG G, 1986, P ICPR, V8, P498; GRAUSTEIN WC, 1930, INTRO HIGHER GEOMETR; GRIMSON WEL, 1990, IEEE T PATTERN ANAL, V12, P255, DOI 10.1109/34.49052; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; Ioannou D, 1999, IMAGE VISION COMPUT, V17, P15, DOI 10.1016/S0262-8856(98)00090-0; LEAVERS VF, 1993, CVGIP-IMAG UNDERSTAN, V58, P250, DOI 10.1006/ciun.1993.1041; PRINCEN J, 1994, IEEE T PATTERN ANAL, V16, P329, DOI 10.1109/34.277588; Ross S.M., 2021, INTRO PROBABILITY ST, V6th ed., P221; ROTH G, 1993, CVGIP-IMAG UNDERSTAN, V58, P1, DOI 10.1006/ciun.1993.1028; Thayananthan A, 2003, PROC CVPR IEEE, P127; Vincze M, 2001, PATTERN RECOGN, V34, P487, DOI 10.1016/S0031-3203(99)00230-7; Xie YH, 2002, INT C PATT RECOG, P957, DOI 10.1109/ICPR.2002.1048464; XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883	23	9	9	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1215	1222						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886858				2022-12-18	WOS:000238162400004
J	Lin, ZC; He, JF; Zhong, ZC; Wang, RR; Shum, HY				Lin, Zhouchen; He, Junfeng; Zhong, Zhicheng; Wang, Rongrong; Shum, Heung-Yeung			Table detection in online ink notes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						table detection; table recognition; graphics recognition; handwriting recognition; document analysis; pen-based computing		In documents, tables are important structured objects that present statistical and relational information. In this paper, we present a robust system which is capable of detecting tables from free style online ink notes and extracting their structure so that they can be further edited in multiple ways. First, the primitive structure of tables, i. e., candidates for ruling lines and table bounding boxes, are detected among drawing strokes. Second, the logical structure of tables is determined by normalizing the table skeletons, identifying the skeleton structure, and extracting the cell contents. The detection process is similar to a decision tree so that invalid candidates can be ruled out quickly. Experimental results suggest that our system is robust and accurate in dealing with tables having complex structure or drawn under complex situations.	Microsoft Res Asia, Beijing 100080, Peoples R China; Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; Nankai Univ, Dept Elect Sci & Technol, Tianjin 300071, Peoples R China; Fudan Univ, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China	Microsoft; Microsoft Research Asia; Tsinghua University; Nankai University; Fudan University	Lin, ZC (corresponding author), Microsoft Res Asia, 5th Floor,Sigma Bldg Zhichun Rd 49, Beijing 100080, Peoples R China.	zhoulin@microsoft.com; heroson98@mails.tsinghua.edu.cn; zhongzhicheng@vip.sina.com; rrwang@fudan.edu.cn; hshum@microsoft.com						Alvarado C., 2002, P AAAI SPRING S SKET, P1; GREEN E, 1999, P IEEE INT  DOC AN R, P214; HANDLEY JC, 1999, SPIE OPTICAL ENG, P289; HURST M, 2001, SPIE, V4307, P56; Jain AK, 2001, PROC INT CONF DOC, P844, DOI 10.1109/ICDAR.2001.953906; KARA LB, 2004, P 17 ANN ACM S US IN, P13; Kieninger TG, 1998, P SOC PHOTO-OPT INS, V3305, P22, DOI 10.1117/12.304642; LAURENTINI A, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P405, DOI 10.1109/ICPR.1992.201803; Laviola JJ, 2004, ACM T GRAPHIC, V23, P432, DOI 10.1145/1015706.1015741; LIANG J, 1999, THESIS U WASHINGTON; LOPRESTI D, 1999, P 3 INT WORKSH GRAPH, P93; Lopresti D, 1999, P 3 IAPR WORKSHOP GR, P109; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; Saund E, 2003, IEEE T PATTERN ANAL, V25, P475, DOI 10.1109/TPAMI.2003.1190573; Shamilian JH, 1997, PROC INT CONF DOC, P158, DOI 10.1109/ICDAR.1997.619833; SKLANSKY J, 1980, PATTERN RECOGN, V12, P327, DOI 10.1016/0031-3203(80)90031-X; Taylor S. L., 1992, Machine Vision and Applications, V5, P211, DOI 10.1007/BF02626999; Wang YL, 2004, PATTERN RECOGN, V37, P1479, DOI 10.1016/j.patcog.2004.01.012; Zanibbi R., 2004, International Journal on Document Analysis and Recognition, V7, P1, DOI 10.1007/s10032-004-0120-9	19	9	9	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1341	1346		10.1109/TPAMI.2006.173	http://dx.doi.org/10.1109/TPAMI.2006.173			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886868				2022-12-18	WOS:000238162400014
J	Avraham, T; Lindenbaum, M				Avraham, T; Lindenbaum, M			Attention-based dynamic visual search using inner-scene similarity: Algorithms and bounds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; scene analysis; feature representation; similarity measures; performance evaluation of algorithms and systems; object recognition; visual search; attention	MODEL; SEGMENTATION; OBJECTS; VISION	A visual search is required when applying a recognition process on a scene containing multiple objects. In such cases, we would like to avoid an exhaustive sequential search. This work proposes a dynamic visual search framework based mainly on inner-scene similarity. Given a number of candidates (e. g., subimages), we hypothesize is that more visually similar candidates are more likely to have the same identity. We use this assumption for determining the order of attention. Both deterministic and stochastic approaches, relying on this hypothesis, are considered. Under the deterministic approach, we suggest a measure similar to Kolmogorov's epsilon-covering that quantifies the difficulty of a search task. We show that this measure bounds the performance of all search algorithms and suggest a simple algorithm that meets this bound. Under the stochastic approach, we model the identity of the candidates as a set of correlated random variables and derive a search procedure based on linear estimation. Several experiments are presented in which the statistical characteristics, search algorithm, and bound are evaluated and verified.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Avraham, T (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	tammya@cs.technion.ac.il; mic@cs.technion.ac.il						AVRAHAM T, 2005, CIS200302 TECHN COMP; Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CALLAGHAN TC, 1988, VISUAL SEARCH, P81; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596; Dickinson SJ, 1997, COMPUT VIS IMAGE UND, V67, P239, DOI 10.1006/cviu.1997.0532; DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433; Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476; GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5; HUMPHREYS GW, 1993, COGNITIVE PSYCHOL, V25, P43, DOI 10.1006/cogp.1993.1002; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; JULESZ B, 1984, TRENDS NEUROSCI, V7, P41, DOI 10.1016/S0166-2236(84)80275-1; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Kolmogorov A. N., 1961, AM MATH SOC TRANSL, V17, P277; Lienhart R, 2002, IEEE IMAGE PROC, P900; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Minut S., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, P457, DOI 10.1145/375735.376414; NAKAYAMA K, 1986, NATURE, V320, P264, DOI 10.1038/320264a0; Neisser U., 1967, COGNITIVE PSYCHOL; Nene A. S., 1996, CUCS00696; Papoulis A, 2002, PROBABILITY RANDOM V, V4th; POSNER MI, 1980, J EXP PSYCHOL GEN, V109, P160, DOI 10.1037/0096-3445.109.2.160; RAO RPN, 1995, ARTIF INTELL, V78, P461, DOI 10.1016/0004-3702(95)00026-7; RIMEY RD, 1994, INT J COMPUT VISION, V12, P173, DOI 10.1007/BF01421202; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Scholl BJ, 2001, COGNITION, V80, P1, DOI 10.1016/S0010-0277(00)00152-9; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; SWAIN MJ, 1993, INT J COMPUT VISION, V11, P109, DOI 10.1007/BF01469224; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tagare HD, 2001, IEEE T PATTERN ANAL, V23, P490, DOI 10.1109/34.922707; TREISMAN A, 1988, PSYCHOL REV, V95, P15, DOI 10.1037/0033-295X.95.1.15; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9; TSOTSOS JK, 1992, INT J COMPUT VISION, V7, P127, DOI 10.1007/BF00128132; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang DL, 1999, NEURAL NETWORKS, V12, P579, DOI 10.1016/S0893-6080(99)00028-3; WIXSON LE, 1994, INT J COMPUT VISION, V12, P209, DOI 10.1007/BF01421203; WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774; Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171	42	9	9	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					251	264		10.1109/TPAMI.2006.28	http://dx.doi.org/10.1109/TPAMI.2006.28			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468621	Green Submitted			2022-12-18	WOS:000233824500007
J	Campisi, P; Colonnese, S; Panci, G; Scarano, G				Campisi, P; Colonnese, S; Panci, G; Scarano, G			Reduced complexity rotation invariant texture classification using a blind deconvolution approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical texture model; texture analysis; texture classification; feature moments	SYNTHESIS-BY-ANALYSIS; SEGMENTATION; WAVELET; FEATURES; MODELS; FILTERS	In this paper, we present a texture classification procedure that makes use of a blind deconvolution approach. Specifically, the texture is modeled as the output of a linear system driven by a binary excitation. We show that features computed from one-dimensional slices extracted from the two-dimensional autocorrelation function (ACF) of the binary excitation allows representing the texture for rotation-invariant classification purposes. The two-dimensional classification problem is thus reconduced to a more simple one-dimensional one, which leads to a significant reduction of the classification procedure computational complexity.	Univ Roma Tre, Dipartimento Elettron Appl, I-00146 Rome, Italy; Univ Roma La Sapienza, Dipartimento Infocom, I-00184 Rome, Italy	Roma Tre University; Sapienza University Rome	Campisi, P (corresponding author), Univ Roma Tre, Dipartimento Elettron Appl, Via Vasca Navale 84, I-00146 Rome, Italy.	campisi@uniroma3.it; colonnese@infocom.uniroma1.it; gpanci@infocom.uniroma1.it; scarano@infocom.uniroma1.it	Scarano, Gaetano/B-2891-2010	Colonnese, Stefania/0000-0002-1807-2155; Scarano, Gaetano/0000-0002-1120-707X				BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; BRODATZ T, 1966, TEXTURES PHOTOGRAPHI; CADZOW JA, 1993, IEEE T AERO ELEC SYS, V29, P1110, DOI 10.1109/7.259515; Campisi P, 2000, IEEE T IMAGE PROCESS, V9, P510, DOI 10.1109/83.826788; Campisi P, 2002, IEEE T IMAGE PROCESS, V11, P37, DOI 10.1109/83.977881; Campisi P., 2004, IEEE T IMAGE PROCESS, V13; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; Charalampidis D, 2002, IEEE T IMAGE PROCESS, V11, P825, DOI 10.1109/TIP.2002.801117; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P194, DOI 10.1109/TASSP.1985.1164507; CHEN PC, 1983, IEEE T PATTERN ANAL, V5, P64, DOI 10.1109/TPAMI.1983.4767346; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; CURTIS SR, 1987, IEEE T ACOUST SPEECH, V35, P890, DOI 10.1109/TASSP.1987.1165212; Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Jacovitti G, 1998, IEEE T IMAGE PROCESS, V7, P1615, DOI 10.1109/83.725369; Jafari-Khouzani K, 2005, IEEE T IMAGE PROCESS, V14, P783, DOI 10.1109/TIP.2005.847302; Jain A. K., 1988, FUNDAMENTALS DIGITAL; Kaplan LM, 1999, IEEE T IMAGE PROCESS, V8, P1572, DOI 10.1109/83.799885; LIU F, 1996, IEEE T PATTERN ANAL, V18; Liu XW, 2003, IEEE T IMAGE PROCESS, V12, P661, DOI 10.1109/TIP.2003.812327; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Porter R, 1997, IEE P-VIS IMAGE SIGN, V144, P180, DOI 10.1049/ip-vis:19971182; Pun CM, 2003, IEEE T PATTERN ANAL, V25, P590, DOI 10.1109/TPAMI.2003.1195993; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; TEUNER A, 1995, IEEE T IMAGE PROCESS, V4, P863, DOI 10.1109/83.388091; Theodoridis S., 2008, PATTERN RECOGN; UNSER M, 1989, IEEE T PATTERN ANAL, V11, P717, DOI 10.1109/34.192466; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747	30	9	9	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2006	28	1					145	149		10.1109/TPAMI.2006.24	http://dx.doi.org/10.1109/TPAMI.2006.24			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	982OR	16402627				2022-12-18	WOS:000233172000013
J	Luengo Hendriks, CL; van Vliet, LJ				Luengo Hendriks, CL; van Vliet, LJ			Using line segments as structuring elements for sampling-invariant measurements	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mathematical morphology; granulometry; rotation invariance; translation invariance	ALGORITHM	When performing measurements in digitized images, the pixel pitch does not necessarily limit the attainable accuracy. Proper sampling of a band-limited continuous-domain image preserves all information present in the image prior to digitization. It is therefore (theoretically) possible to obtain measurements from the digitized image that are identical to measurements made in the continuous domain. Such measurements are sampling invariant, since they are independent of the chosen sampling grid. It is impossible to attain strict sampling invariance for filters in mathematical morphology due to their nonlinearity, but it is possible to approximate sampling invariance with arbitrary accuracy at the expense of additional computational cost. In this paper, we study morphological filters with line segments as structuring elements. We present a comparison of three known and three new methods to implement these filters. The method that yields a good compromise between accuracy and computational cost employs a (subpixel) skew to the image, followed by filtering along the grid axes using a discrete line segment, followed by an inverse skew. The staircase approximations to line segments under random orientations can be modeled by skewing a horizontal or vertical line segment. Rather than skewing the binary line segment we skew the image data, which substantially reduces quantization error. We proceed to determine the optimal number of orientations to use when measuring the length of line segments with unknown orientation.	Lawrence Berkeley Natl Lab, Div Life Sci, Berkeley, CA 94720 USA; Delft Univ Technol, Quantitat Imaging Grp, NL-2628 CJ Delft, Netherlands	United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; Delft University of Technology	Luengo Hendriks, CL (corresponding author), Lawrence Berkeley Natl Lab, Div Life Sci, 1 Cyclotron Rd,MS 84R171, Berkeley, CA 94720 USA.	clluengo@lbl.gov; L.J.vanVliet@ph.tn.tudelft.nl	Luengo Hendriks, Cris L./B-1097-2008; van Vliet, Lucas/E-1678-2012	Luengo Hendriks, Cris L./0000-0002-8279-1760; van Vliet, Lucas/0000-0001-7018-726X				[Anonymous], 1983, SIGNALS SYSTEMS; BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025; Chanussot J, 1998, COMP IMAG VIS, V12, P399; DORST L, 1994, SIGNAL PROCESS, V38, P79, DOI 10.1016/0165-1684(94)90058-2; Jones R, 1996, PATTERN RECOGN LETT, V17, P1057, DOI 10.1016/0167-8655(96)00066-9; Katartzis A, 2000, COMPUT IMAGING VIS, V18, P405; Luengo Hendriks CL, 2003, LECT NOTES COMPUT SC, V2695, P313; LUENGOHENDRIKS CL, 2001, P 4 INT WORKSH VIS F, P378; LUENGOHENDRIKS CL, 2003, P COMP AN IM PATT, P722; LUENGOHENDRIKS CL, 2004, THESIS DELFT U TECHN; Matheron G., 1975, RANDOM SETS INTEGRAL; Nyquist H., 1928, T AM I ELECT ENG, V47, P617, DOI [10.1109/T-AIEE.1928.5055024, DOI 10.1109/T-AIEE.1928.5055024]; Pham TQ, 2005, PROC SPIE, V5817, P133, DOI 10.1117/12.603304; Serra J, 1982, IMAGE ANAL MATH MORP; Soille P, 2001, IEEE T PATTERN ANAL, V23, P1313, DOI 10.1109/34.969120; Soille P, 1996, IEEE T PATTERN ANAL, V18, P562, DOI 10.1109/34.494646; Soille P, 1998, INT C PATT RECOG, P1467, DOI 10.1109/ICPR.1998.711982; Soille P., 2013, MORPHOLOGICAL IMAGE; VANHERK M, 1992, PATTERN RECOGN LETT, V13, P517, DOI 10.1016/0167-8655(92)90069-C; VANVLIET LJ, 1993, THESIS DELFT U TECHN; [No title captured]	22	9	9	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1826	1831		10.1109/TPAMI.2005.228	http://dx.doi.org/10.1109/TPAMI.2005.228			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285380				2022-12-18	WOS:000231826300012
J	Chung, RHY; Yung, NHC; Cheung, PYS				Chung, RHY; Yung, NHC; Cheung, PYS			An efficient parameterless quadrilateral-based image segmentation method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						approximate methods; object representations; region growing; quadrilateral-based segmentation	VIDEO; DESIGN	This paper proposes a general quadrilateral-based framework for image segmentation, in which quadrilaterals are first constructed from an edge map, where neighboring quadrilaterals with similar features of interest are then merged together to form regions. Under the proposed framework, the quadrilaterals enable the elimination of local variations and unnecessary details for merging from which each segmented region is accurately and completely described by a set of quadrilaterals. To illustrate the effectiveness of the proposed framework, we derived an efficient and high-performance parameterless quadrilateral-based segmentation algorithm from the framework. The proposed algorithm shows that the regions obtained under the framework are segmented into multiple levels of quadrilaterals that accurately represent the regions without severely over or undersegmenting them. When evaluated objectively and subjectively, the proposed algorithm performs better than three other segmentation techniques, namely, seeded region growing, K-means clustering and constrained gravitational clustering, and offers an efficient description of the segmented objects conducive to content-based applications.	Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; Univ Hong Kong, Dept Elect Engn & Elect, Hong Kong, Hong Kong, Peoples R China	University of Hong Kong; University of Hong Kong	Chung, RHY (corresponding author), Univ Hong Kong, Dept Comp Sci, Room 425,Chow Yei Ching Bldg, Hong Kong, Hong Kong, Peoples R China.	hychung@cs.hku.hk; nyung@eee.hku.hk; cheung@eee.hku.hk	Chung, Ren-Hua/AAB-8364-2019					ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Altunbasak Y, 1997, IEEE T IMAGE PROCESS, V6, P1270, DOI 10.1109/83.623190; Brejl M, 2000, IEEE T MED IMAGING, V19, P973, DOI 10.1109/42.887613; BROX T, 2001, P 22 S INF THEOR BEN, P181; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Castagno R, 1998, IEEE T CIRC SYST VID, V8, P562, DOI 10.1109/76.718503; Cheriet M, 1998, IEEE T IMAGE PROCESS, V7, P918, DOI 10.1109/83.679444; CHUNG HY, 2002, P INT C CONTR AUT RO; COHEN FS, 1995, IEEE T IMAGE PROCESS, V4, P1, DOI 10.1109/83.350818; de Queiroz RL, 2000, IEEE T IMAGE PROCESS, V9, P1461, DOI 10.1109/83.862619; Gao H, 2001, IEEE T CIRC SYST VID, V11, P1273, DOI 10.1109/76.974681; GERKEN P, 1994, IEEE T CIRC SYST VID, V4, P228, DOI 10.1109/76.305868; Goldenberg R, 2000, 21ST IEEE CONVENTION OF THE ELECTRICAL AND ELECTRONIC ENGINEERS IN ISRAEL - IEEE PROCEEDINGS, P101, DOI 10.1109/EEEI.2000.924332; Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533; Gu YH, 1999, IEEE T SYST MAN CY A, V29, P358, DOI 10.1109/3468.769754; Hao XH, 2001, IEEE T MED IMAGING, V20, P1373, DOI 10.1109/42.974932; Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Iannizzotto G, 2000, IEEE T IMAGE PROCESS, V9, P1232, DOI 10.1109/83.847835; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Lezoray O, 2002, IEEE T IMAGE PROCESS, V11, P783, DOI 10.1109/TIP.2002.800889; LIE WN, 1995, IEEE T IMAGE PROCESS, V4, P1036, DOI 10.1109/83.392347; LIU JQ, 1994, IEEE T PATTERN ANAL, V16, P689, DOI 10.1109/34.297949; Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433; Mendonca AP, 2000, ELECTRON LETT, V36, P1199, DOI 10.1049/el:20000869; MUNDAY JL, 1992, GEOMETRIC INVARIANCE; NIEWEGLOWSKI J, 1993, IEEE T CONSUM ELECTR, V39, P141, DOI 10.1109/30.234575; PAVLIDIS T, 1975, IEEE T SYST MAN CYB, V5, P610, DOI 10.1109/TSMC.1975.4309402; Salembier P, 1999, IEEE T CIRC SYST VID, V9, P1147, DOI 10.1109/76.809153; Sappa AD, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P292, DOI 10.1109/IM.2001.924460; SONKA M, 1999, IMAGE PROCESSING ANA, P176; Sumengen B, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P429; WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536; WRIGHT WE, 1977, PATTERN RECOGN, V9, P151, DOI 10.1016/0031-3203(77)90013-9; Yu ZY, 2002, IEEE IMAGE PROC, P828; Yung HC, 1998, OPT ENG, V37, P989, DOI 10.1117/1.601932; Yung NHC, 2002, OPT ENG, V41, P2844, DOI 10.1117/1.1511747; Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7	39	9	11	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1446	1458		10.1109/TPAMI.2005.171	http://dx.doi.org/10.1109/TPAMI.2005.171			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173187	Green Submitted			2022-12-18	WOS:000230463300007
J	Verdu-Mas, JL; Carrasco, RC; Calera-Rubio, J				Verdu-Mas, JL; Carrasco, RC; Calera-Rubio, J			Parsing with probabilistic strictly locally testable tree languages	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						parsing with probabilistic grammars; stochastic learning; tree grammars	CONTEXT-FREE GRAMMARS; POLYNOMIAL-TIME; AUTOMATA; RECOGNITION; INFERENCE; MODELS; LIMIT	Probabilistic k- testable models ( usually known as k- gram models in the case of strings) can be easily identified from samples and allow for smoothing techniques to deal with unseen events during pattern classification. In this paper, we introduce the family of stochastic k- testable tree languages and describe how these models can approximate any stochastic rational tree language. The model is applied to the task of learning a probabilistic k- testable model from a sample of parsed sentences. In particular, a parser for a natural language grammar that incorporates smoothing is shown.	Univ Alicante, Dept Llenguatges & Sistemas Informat, E-03071 Alicante, Spain	Universitat d'Alacant	Verdu-Mas, JL (corresponding author), Univ Alicante, Dept Llenguatges & Sistemas Informat, E-03071 Alicante, Spain.	verdu@dlsi.ua.es; carrasco@dlsi.ua.es; calera@dlsi.ua.es						Aho A.V., 1986, COMPILERS PRINCIPLES; Black E., 1991, P DARPA SPEECH NAT L, P306; Black Ezra, 1992, P 5 DARPA SPEECH NAT, P31; BOD R, 1996, LP9513; Calera-Rubio J, 1998, INFORM PROCESS LETT, V68, P283, DOI 10.1016/S0020-0190(98)00172-0; Carrasco RC, 1999, RAIRO-INF THEOR APPL, V33, P1, DOI 10.1051/ita:1999102; Carrasco RC, 2001, MACH LEARN, V44, P185, DOI 10.1023/A:1010836331703; Carroll J., 1998, P 1 INT C LANG RES E, P447; CHAPPELIER JC, 1998, P TAB PARS DED TAPD, P133; Charniak E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1031; Charniak Eugene, 1993, STAT LANGUAGE LEARNI; Chi ZY, 1998, COMPUT LINGUIST, V24, P299; Church K. W., 1991, Computer Speech and Language, V5, P19, DOI 10.1016/0885-2308(91)90016-J; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; ESTEVE Y, 2001, P EUROSPEECH, P725; FRAZIER L, 1982, COGNITIVE PSYCHOL, V14, P178, DOI 10.1016/0010-0285(82)90008-1; GARCIA P, 1990, IEEE T PATTERN ANAL, V12, P920, DOI 10.1109/34.57687; GESCSEG F, 1984, TREE AUTOMATA; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Hopcroft John E., 1979, INTRO AUTOMATA THEOR; HU J, 1996, P 4 INT C SPOK LANG, V1, P406; Hutchins J., 1992, INTRO MACHINE TRANSL; Johnson M, 1998, COMPUT LINGUIST, V24, P613; KNUUTILA T, 1993, P INT WORKSH STRUCT; Krotov Alexander, 1998, P COLING ACL 98 JOIN, P699; Manning CD, 1999, FDN STAT NATURAL LAN; McNaughton R., 1971, COUNTER FREE AUTOMAT; MURATA M, 1997, P 3 INT WORKSH PRINC, V1293, P153; NEY H, 1995, IEEE T PATTERN ANAL, V17, P1202, DOI 10.1109/34.476512; Nivat M, 1997, SIAM J COMPUT, V26, P39, DOI 10.1137/S0097539789164078; PRESCOD P, 2002, FORMALIZING XML SGML; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RADFOR A, 1999, LINGUISTICS INTRO; Riccardi G, 1996, COMPUT SPEECH LANG, V10, P265, DOI 10.1006/csla.1996.0014; SACHEZ J, 1997, IEEE T PATTERNS ANAL, V19, P1052; SAKAKIBARA Y, 1992, INFORM COMPUT, V97, P23, DOI 10.1016/0890-5401(92)90003-X; SAKAKIBARA Y, 1994, P 27 ANN HAW INT C S, V5, P284; Sima'an K., 1994, P INT C NEW METH LAN, P50; STOLCKE A, 1995, COMPUT LINGUIST, V21, P165; STOLCKE A, 1994, TR94007 INT COMP SCI; Thorup M, 1996, ACTA INFORM, V33, P511, DOI 10.1007/s002360050055; WETHERELL CS, 1980, COMPUT SURV, V12, P361, DOI 10.1145/356827.356829; YOKOMORI T, 1995, MACH LEARN, V19, P153, DOI 10.1023/A:1022615325466; Yokomori T., 1994, Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences. Vol.V: Biotechnology Computing (Cat. No.94TH0607-2), P113, DOI 10.1109/HICSS.1994.323560; [No title captured]	46	9	9	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1040	1050		10.1109/TPAMI.2005.144	http://dx.doi.org/10.1109/TPAMI.2005.144			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013752	Green Submitted			2022-12-18	WOS:000229024300004
J	Martins, AT; Aguiar, PMQ; Figueiredo, MAT				Martins, AT; Aguiar, PMQ; Figueiredo, MAT			Orientation in manhattan: Equiprojective classes and sequential estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						camera orientation; sequential estimation; Manhattan world assumption; camera calibration	MOTION	The problem of inferring 3D orientation of a camera from video sequences has been mostly addressed by first computing correspondences of image features. This intermediate step is now seen as the main bottleneck of those approaches. In this paper, we propose a new 3D orientation estimation method for urban ( indoor and outdoor) environments, which avoids correspondences between frames. The scene property exploited by our method is that many edges are oriented along three orthogonal directions; this is the recently introduced Manhattan world ( MW) assumption. The main contributions of this paper are: the definition of equivalence classes of equiprojective orientations, the introduction of a new small rotation model, formalizing the fact that the camera moves smoothly, and the decoupling of elevation and twist angle estimation from that of the compass angle. We build a probabilistic sequential orientation estimation method, based on an MW likelihood model, with the above-listed contributions allowing a drastic reduction of the search space for each orientation estimate. We demonstrate the performance of our method using real video sequences.	Univ Tecn Lisboa, Inst Super Tecn, Dept Elect & Comp Engn, P-1049001 Lisbon, Portugal	Universidade de Lisboa; Instituto Superior Tecnico	Martins, AT (corresponding author), Univ Tecn Lisboa, Inst Super Tecn, Dept Elect & Comp Engn, P-1049001 Lisbon, Portugal.	jah@clix.pt; aquiar@isr.ist.utl.pt; mtf@lx.it.pt	Figueiredo, Mario/C-5428-2008; Aguiar, Pedro MQ/C-5523-2008	Figueiredo, Mario/0000-0002-0970-7745; Aguiar, Pedro/0000-0002-3809-8416				COUGHLAN J, 2000, P NEUR INF PROC SYST; Coughlan J.M., 1999, P IEEE INT C COMP VI; Deutscher J., 2002, P EUR C COMP VIS; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; GORDON N, 2001, SEQUENTIAL MONTE CAR; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kosecka J., 2002, P EUR C COMP VIS; LUTTON E, 1994, IEEE T PATTERN ANAL, V16, P430, DOI 10.1109/34.277598; MARTINS A, 2003, P IEEE INT C IM PROC; Mundy L., 1992, GEOMETRIC INVARIANTS; SCHINDLER G, 2004, P IEEE CS C COMP VIS; Stein GP, 2000, IEEE T PATTERN ANAL, V22, P992, DOI 10.1109/34.877522; UTCKE S, 1998, P IEEE INT C COMP VI	15	9	9	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					822	U5		10.1109/TPAMI.2005.107	http://dx.doi.org/10.1109/TPAMI.2005.107			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875804	Green Submitted			2022-12-18	WOS:000227569300016
J	Steinherz, T; Rivlin, E; Intrator, N; Neskovic, P				Steinherz, T; Rivlin, E; Intrator, N; Neskovic, P			An integration of online and pseudo-online information for cursive word recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						online; offline; handwriting; cursive; word recognition; classifier combination	OFF-LINE	In this paper, we present a novel method to extract stroke order independent information from online data. This information, which we term pseudo-online, conveys relevant information on the offline representation of the word. Based on this information, a combination of classification decisions from online and pseudo- online cursive word recognizers is performed to improve the recognition of online cursive words. One of the most valuable aspects of this approach with respect to similar methods that combine online and offline classifiers for word recognition is that the pseudo- online representation is similar to the online signal and, hence, word recognition is based on a single engine. Results demonstrate that the pseudo- online representation is useful as the combination of classifiers perform better than those based solely on pure online information.	Tel Aviv Univ, Dept Comp Sci, IL-69978 Tel Aviv, Israel; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel; Brown Univ, Dept Phys, Providence, RI 02906 USA; Brown Univ, Inst Brain & Neural Syst, Providence, RI 02906 USA	Tel Aviv University; Technion Israel Institute of Technology; Brown University; Brown University	Steinherz, T (corresponding author), Tel Aviv Univ, Dept Comp Sci, IL-69978 Tel Aviv, Israel.	talstz@cs.tau.ac.il; ehudr@cs.technion.ac.il; nin@cs.tau.ac.il; pedja@brown.edu						BOCCIGNONE G, 1993, PATTERN RECOGN, V26, P409, DOI 10.1016/0031-3203(93)90168-V; DOERMANN DS, 1995, INT J COMPUT VISION, V15, P143, DOI 10.1007/BF01450853; GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870; Hamanaka M., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P204, DOI 10.1109/ICDAR.1993.395748; HOLLERBACH JM, 1981, BIOL CYBERN, V39, P139, DOI 10.1007/BF00336740; Jaeger S., 2001, International Journal on Document Analysis and Recognition, V3, P169, DOI 10.1007/PL00013559; JAEGER S, 2000, P INT WORKSH FRONT H, P291; Kang HJ, 1997, ENG APPL ARTIF INTEL, V10, P379, DOI 10.1016/S0952-1976(97)00020-1; KITTLER J, 1998, IEEE PAMI, V20, P222; MANKE S, 1994, INT C PATT RECOG, P596, DOI 10.1109/ICPR.1994.577051; Matan O, 1992, ADV NEURAL INFORM PR, P488; NESKOVIC P, 2000, P ADV NEUR INF PROC, P974; NESKOVIC P, 2000, P INT WORKSH FRONT H, P352; NISHIDA H, 1995, PATTERN RECOGN LETT, V16, P1213, DOI 10.1016/0167-8655(95)00071-N; Okamoto M, 1998, INT C PATT RECOG, P1747, DOI 10.1109/ICPR.1998.712064; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; RUMELHART DE, 1993, COMPUTATIONAL LEARNING & COGNITION, P177; SCHENKEL M, 1995, MACH VISION APPL, V8, P215, DOI 10.1007/BF01219589; Seiler R., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P505, DOI 10.1109/ICPR.1996.547616; Seni G, 1996, IEEE T PATTERN ANAL, V18, P757, DOI 10.1109/34.506798; Simon J. C., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P57, DOI 10.1142/S0218001491000065; SIMON JC, 1992, P IEEE, V80, P1150, DOI 10.1109/5.156476; SRIHARI SN, 1992, P IEEE, V80, P1120, DOI 10.1109/5.156474; Steinherz T., 1999, International Journal on Document Analysis and Recognition, V2, P90, DOI 10.1007/s100320050040; STEINHERZ T, 2000, P INT WORKSH FRONT H, P529; Tanaka H., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P209, DOI 10.1109/ICDAR.1999.791761; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; Velek O, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P177, DOI 10.1109/IWFHR.2002.1030905; Vinciarelli A, 2002, PATTERN RECOGN, V35, P1433, DOI 10.1016/S0031-3203(01)00129-7; WAKAHARA T, 1992, P IEEE, V80, P1181, DOI 10.1109/5.156478	30	9	9	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					669	683		10.1109/TPAMI.2005.94	http://dx.doi.org/10.1109/TPAMI.2005.94			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875790	Green Submitted			2022-12-18	WOS:000227569300002
J	Mignotte, M				Mignotte, M			Nonparametric multiscale energy-based model and its application in some imagery problems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonparametric multiscale energy-based (or multiresolution example-based) model; inpainting; non-photorealistic rendering (NPR); segmentation; contour-based shape recognition; shape indexing	SEGMENTATION; CLASSIFICATION	This paper investigates the use of a nonparametric regularization energy term for devising a example-based rendering and segmentation technique. We have stated this problem in the multiresolution energy minimization framework and exploited the multiscale structure proposed by Wei and Levoy for the texture synthesis problem. In this nonparametric energy minimization framework, we also propose a computationally efficient coarse-to-fine recursive optimization method to minimize the cost function related to this hierarchical model. In this context, the formulation of our example-based regularization term also allows to directly infer an intuitive dissimilarity measure between two contour shapes. This measure is herein exploited to define an efficient shape descriptor for the contour-based shape recognition and indexing problem.	DIRO, Dept Informat & Rech Operationnelle, Montreal, PQ H3C 3J7, Canada	Universite de Montreal	Mignotte, M (corresponding author), DIRO, Dept Informat & Rech Operationnelle, CP 6128,Succ Ctr Ville, Montreal, PQ H3C 3J7, Canada.	mignotte@iro.umontreal.ca	Mignotte, Max/F-7014-2015					Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BESAG J, 1986, J R STAT SOC B, V48, P259; Braathen B., 1993, MACHINE GRAPHICS VIS, V2, P39; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; CHAN TF, 2003, IMAGE INPAINTING; Chen H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P433, DOI 10.1109/ICCV.2001.937657; CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995; DEMPSTER AP, 1976, ROYAL STAT SOC, P1; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; GAVRILLA DM, 1999, P INT C COMP VIS SEP; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GONZELES RC, 1992, DIGITAL IMAGE PROCES; HEITZ F, 1994, CVGIP-IMAG UNDERSTAN, V59, P125, DOI 10.1006/ciun.1994.1008; HERTZMANN A, 2002, P 13 EUR WORKSH REND, P233; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; JODOIN PM, 2002, P NONPHOTOREALISTIC; Kervrann C, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P937, DOI 10.1109/ICIP.1996.559654; Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696; Memin E, 1998, IEEE T IMAGE PROCESS, V7, P703, DOI 10.1109/83.668027; Mignotte M, 2000, IEEE T IMAGE PROCESS, V9, P1216, DOI 10.1109/83.847834; Mignotte M, 2000, IEEE T PATTERN ANAL, V22, P129, DOI 10.1109/34.825752; Mignotte M, 2002, IEEE IMAGE PROC, P445; MIGNOTTE M, 2002, P IEEE INT C PATT RE, V1, P247; MIGNOTTE M, 1997, P IEEE INT C IM PROC; MIGNOTTE M, 1999, P SPIE C NON LINEAR; Mori G, 2001, PROC CVPR IEEE, P723; Nacken P. F. M., 1994, Journal of Mathematical Imaging and Vision, V4, P233, DOI 10.1007/BF01254101; Popat K, 1997, IEEE T IMAGE PROCESS, V6, P268, DOI 10.1109/83.551697; REGAZZONI CS, 1993, SIGNAL PROCESS, V34, P43, DOI 10.1016/0165-1684(93)90026-7; REYNOLDS C, 2003, STYLIZED DEPICTION C; SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174; VELTKAMP RC, 1999, UUCS199927 UTR; Wang L, 1999, PATTERN RECOGN LETT, V20, P171, DOI 10.1016/S0167-8655(98)00129-9; Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009	35	9	9	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2004	26	2					184	197		10.1109/TPAMI.2004.1262180	http://dx.doi.org/10.1109/TPAMI.2004.1262180			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	762DA	15376894	Green Submitted			2022-12-18	WOS:000187954300005
J	Ghebreab, S; Smeulders, AWM				Ghebreab, S; Smeulders, AWM			Strings: Variational deformable models of multivariate continuous boundary features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	3rd International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition	SEP 03-05, 2001	SOPHIA ANTIPOLIS, FRANCE	INRIA, Int Assoc Pattern Recognit, Conseil Gen Alpes Maritimes		machine learning; deformable models; energy minimization; multivariate statistics; shape analysis; functional data analysis; chemometrics; active shape models	SHAPE MODELS; SEGMENTATION; IMAGES	We propose a new image segmentation technique called strings. A string is a variational deformable model that is learned from a collection of example objects rather than built from a priori analytical or geometrical knowledge. As opposed to existing approaches, an object boundary is represented by a one-dimensional multivariate curve in functional space, a feature function, rather than by a point in vector space. In the learning phase, feature functions are defined by extraction of multiple shape and image features along continuous object boundaries in a given learning set. The feature functions are aligned, then subjected to functional principal components analysis and functional principal regression to summarize the feature space and to model its content, respectively. Also, a Mahalanobis distance model is constructed for evaluation of boundaries in terms of their feature functions, taking into account the natural variations seen in the learning set. In the segmentation phase, an object boundary in a new image is searched for with help of a curve. The curve gives rise to a feature function, a string, that is weighted by the regression model and evaluated by the Mahalanobis model. The curve is deformed in an iterative procedure to produce feature functions with minimal Mahalanobis distance. Strings have been compared with active shape models on 145 vertebra images, showing that strings produce better results when initialized close to the target boundary, and comparable results otherwise.	Univ Amsterdam, Inst Informat, Intelligent Sensory Informat Syst Grp, Amsterdam, Netherlands	University of Amsterdam	Ghebreab, S (corresponding author), Univ Med Ctr Rotterdam, Erasmus MC, Dept Med Informat, Biomed Imaging Grp Rotterdam, Room Ee2167, Rotterdam, Netherlands.	s.ghebreab@erasmusmc.nl; smeulders@science.uva.nl						BAUMBERG A, 1994, P EUR C COMP VIS, P299; Brejl M, 2000, IEEE T MED IMAGING, V19, P973, DOI 10.1109/42.887613; Chatterjee S, 2000, REGRESSION ANAL EXAM; COOTES TF, 1995, IMAGE VISION COMPUT, V13, P403, DOI 10.1016/0262-8856(95)99727-I; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COOTES TF, 1993, P 4 INT C COMP VIS, P242; Davies RH, 2001, P BRIT MACH VIS C, P3; Dryden I., 1998, STAT SHAPE ANAL; DUCKWORTH J, 1995, P INT C NEAR INFR SP; Duta N, 2001, IEEE T PATTERN ANAL, V23, P433, DOI 10.1109/34.922703; Edwards GJ, 1998, IMAGE VISION COMPUT, V16, P203, DOI 10.1016/S0262-8856(97)00069-3; Fenster SD, 2001, IEEE T PATTERN ANAL, V23, P1028, DOI 10.1109/34.955115; GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x; Grimson E., 2000, P COMP VIS PATT REC; HAMARNEH G, 1998, R0051998 CHALM U TEC; HASLAM J, 1994, P BRIT MACH VIS C, P33; KIRKPATRICK S, 1983, IEEE T PATTERN ANAL, V5, P267; Kotcheff A C, 1998, Med Image Anal, V2, P303; Kramer R., 1998, CHEMOMETRIC TECHNIQU; Piegl L., 1997, NURBS BOOK; Ramsay J.O., 1997, FUNCTIONAL DATA ANAL, DOI 10.1007/978-1-4757-7107-7; ROWE S, 1996, P 4 EUR C COMP VIS C, P560; van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121; Wang YM, 2000, IEEE T PATTERN ANAL, V22, P738, DOI 10.1109/34.865192; [No title captured]	28	9	10	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1399	1410		10.1109/TPAMI.2003.1240114	http://dx.doi.org/10.1109/TPAMI.2003.1240114			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	733NG					2022-12-18	WOS:000186006800005
J	Zhu, SC; Liu, XW				Zhu, SC; Liu, XW			Learning in Gibbsian fields: How accurate and how fast can it be?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; minimax entropy learning; texture modeling; Markov chain Monte Carlo; maximum-likelihood estimate; importance sampling	PARTITION-FUNCTION ESTIMATION; CARLO MAXIMUM-LIKELIHOOD; MONTE-CARLO; APPROXIMATION ALGORITHMS; TEXTURE	Gibbsian fields or Markov random fields are widely used in Bayesian image analysis, but learning Gibbs models is computationally expensive. The computational complexity is pronounced by the recent minimax entropy (FRAME) models which use large neighborhoods and hundreds of parameters [22]. In this paper, we present a common framework for learning Gibbs models. We identify two key factors that determine the accuracy and speed of learning Gibbs models: The efficiency of likelihood functions and the variance in approximating partition functions using Monte Carlo integration. We propose three new algorithms. In particular, we are interested in a maximum satellite likelihood estimator, which makes use of a set of precomputed Gibbs models called "satellites" to approximate likelihood functions. This algorithm can approximately estimate the minimax entropy model for textures in seconds in a HP workstation. The performances of various learning algorithms are compared in our experiments.	Univ Calif Los Angeles, Dept Comp Sci & Stat, Los Angeles, CA 90095 USA; Florida State Univ, Dept Comp Sci, Tallahassee, FL 32306 USA	University of California System; University of California Los Angeles; State University System of Florida; Florida State University	Zhu, SC (corresponding author), Univ Calif Los Angeles, Dept Comp Sci & Stat, Los Angeles, CA 90095 USA.							Almeida M.P., 1993, ANN APPL PROBAB, V3, P103; ANDERSON CH, 1996, UNPUB STAT MODELS IM; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1977, BIOMETRIKA, V64, P616, DOI 10.1093/biomet/64.3.616; Chellappa R, 1993, MARKOV RANDOM FIELDS; COUGHLAN J, 1998, P NEUR INF PROC SYST; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; DESCOMBES X, 1997, P INT C EN MIN METH; Ganan Stuart, 1985, P STAT COMP SECT AM, P12; GEMAN S, 1987, B INT STAT I, V4, P5; GEYER CJ, 1992, J R STAT SOC B, V54, P657; GEYER CJ, 1994, J ROY STAT SOC B MET, V56, P261; GIDAS B, 1988, STOCHASTIC DIFFERENT; JERRUM M, 1993, SIAM J COMPUT, V22, P1087, DOI 10.1137/0222066; Potamianos G, 1997, IEEE T INFORM THEORY, V43, P1948, DOI 10.1109/18.641558; POTAMIANOS GG, 1993, IEEE T INFORM THEORY, V39, P1322, DOI 10.1109/18.243449; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; SHAH J, 1998, P COMP VIS PATT REC; YOUNES L, 1988, ANN I H POINCARE-PR, V24, P269; ZHU S, 1997, NEURAL COMPUTATION, V9; Zhu SC, 2000, IEEE T PATTERN ANAL, V22, P554, DOI 10.1109/34.862195	22	9	10	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2002	24	7					1001	1006						6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	566UF					2022-12-18	WOS:000176446100012
J	Lim, T; Corney, J; Clark, DER				Lim, T; Corney, J; Clark, DER			Laminae-based feature recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						geometric feature recognition; CAD; CAM	EXTRACTION	Motivated by the needs of mould and die manufacturers, this paper presents a novel approach to recognizing shape features on geometric models composed of both simple and complex ruled surfaces. The algorithm described uses a network of adjacent 2D-laminae (i.e., bounded surfaces) derived from a component's CAD model to both locate and create generic protrusion and depression feature volumes. The approach also enables the automatic generation of alternative feature descriptions and requires no predefined feature libraries.	Heriot Watt Univ, Dept Mech & Chem Engn, Edinburgh, Midlothian, Scotland; Heriot Watt Univ, Dept Mat, Edinburgh, Midlothian, Scotland	Heriot Watt University; Heriot Watt University	Lim, T (corresponding author), Heriot Watt Univ, Dept Mech & Chem Engn, Edinburgh, Midlothian, Scotland.			Lim, Theodore/0000-0001-8931-2745				*ACIS SPAT TECHN I, 1998, GEOM MOD APPL GUID; Ansaldi S., 1985, Computer Graphics Forum, V4, P319, DOI 10.1111/j.1467-8659.1985.tb00237.x; DEFLORIANI L, 1989, IEEE T PATTERN ANAL, V11, P785, DOI 10.1109/34.31442; GAVANKAR P, 1990, COMPUT AIDED DESIGN, V22, P442, DOI 10.1016/0010-4485(90)90109-P; GRAYER AR, 1977, ADV COMPUTER AIDED M, P137; HAN JH, 1997, P COMP ENG C ENG INF; JI Q, 1997, ACM COMPUT SURV, V24, P264; JOSHI S, 1988, COMPUT AIDED DESIGN, V20, P58, DOI 10.1016/0010-4485(88)90050-4; KRYPRIANOU LK, 1980, THESIS U CAMBRIDGE U; LAAKKO T, 1993, COMPUT AIDED DESIGN, V25, P479, DOI 10.1016/0010-4485(93)90079-4; LIM T, 2000, THESIS HERIOT WATT U; Little G, 1998, COMPUT AIDED DESIGN, V30, P695, DOI 10.1016/S0010-4485(98)00023-2; Preiss K., 1983, Computer Applications in Production and Engineering, CAPE '83. Proceedings of the First International Conference, P773; Qamhiyah AZ, 1996, COMPUT AIDED DESIGN, V28, P887, DOI 10.1016/0010-4485(96)00015-2; Shah JJ, 1994, MANUFACTURING RES TE, P1; VENUVINOD PK, 1995, J INTELL MANUF, V6, P155, DOI 10.1007/BF00171444	16	9	9	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2001	23	9					1043	1048		10.1109/34.955117	http://dx.doi.org/10.1109/34.955117			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	470RP					2022-12-18	WOS:000170885200010
J	Basri, R; Jacobs, DW				Basri, R; Jacobs, DW			Projective alignment with regions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; pose estimation with regions	OBJECT RECOGNITION; 3-D; POSE	We have recently proposed an approach to recognition that uses regions to determine the pose of objects while allowing for partial occlusion of the regions. Regions introduce an attractive alternative to existing global and local approaches, since, unlike global features, they can handle occlusion and segmentation errors, and unlike local features they are not as sensitive to sensor errors, and they are easier to match. The region-based approach also uses image information directly, without the construction of intermediate representations, such as algebraic descriptions, which may be difficult to reliably compute. In this paper, we further analyze properties of the method for planar objects undergoing projective transformations. In particular, we prove that three visible regions are sufficient to determine the transformation uniquely and that for a large class of objects, two regions are insufficient for this purpose. However, we show that when several regions are available, the pose of the object can generally be recovered even when some or all regions are significantly occluded. Our analysis is based on investigating the flow patterns of points under projective transformations in the presence of fixed points.	Weizmann Inst Sci, Dept Comp Sci, IL-76100 Rehovot, Israel; NEC Res Inst, Princeton, NJ 08540 USA	Weizmann Institute of Science; NEC Corporation	Basri, R (corresponding author), Weizmann Inst Sci, Dept Comp Sci, IL-76100 Rehovot, Israel.	ronen.basri@weizmann.ac.il; dwj@research.nj.nec.com						BASRI R, 1999, INT C COMP VIS; BASRI R, 1997, INT J COMPUT VISION, V25, P141; Brand L., 1966, DIFFERENTIAL DIFFERE; CARLSSON S, 1989, P INT C COMP VIS, P629; CONWAY JB, 1990, COURSE FUNCTIONAL AN; Coxeter H.S.M., 1993, REAL PROJECTIVE PLAN, V3rd; Duda R.O., 1973, J ROYAL STAT SOC SER; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; HORAUD R, 1987, IEEE T PATTERN ANAL, V9, P401, DOI 10.1109/TPAMI.1987.4767922; HU MK, 1962, IEEE T INFORM THEORY, V8, P169; Jacobs D, 1999, INT J COMPUT VISION, V34, P123, DOI 10.1023/A:1008135819955; Kanatani K., 1993, GEOMETRIC COMPUTATIO; POLLEFEYS M, 1997, CVPR, P407; SCHAFFALITZKY F, 1998, P 9 BRIT MACH VIS C; SEIDEL R, 1990, PROCEEDINGS OF THE SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P211, DOI 10.1145/98524.98570; STRANG G, 1988, LINEAR ALGEBRA ITS A; VERRI A, 1989, J OPT SOC AM A, V6, P698, DOI 10.1364/JOSAA.6.000698; WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536	18	9	9	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2001	23	5					519	527		10.1109/34.922709	http://dx.doi.org/10.1109/34.922709			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431QA		Green Submitted			2022-12-18	WOS:000168641000007
J	Florack, L				Florack, L			A spatio-frequency trade-off scale for scale-space filtering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scale-space filtering; temporal versus frequency aliasing; time-frequency trade-off scale		We study implementation issues for spatial convolution filters and their Fourier alternative, with the aim to optimize the accuracy of filter output. We focus on Gaussian scale-space filters and show that there exists a trade-off scale that subdivides the available scale range into two subintervals of equal length. Below this trade-off scale Fourier filtering yields more accurate results than spatial filtering; above it is the other way around. This should be contrasted with demands of computational speed, which show the opposite tenet.	Univ Utrecht, Dept Math, NL-3508 TA Utrecht, Netherlands	Utrecht University	Florack, L (corresponding author), Univ Utrecht, Dept Math, POB 80100, NL-3508 TA Utrecht, Netherlands.							Brigham E. O., 1974, FAST FOURIER TRANSFO; DERICHE R, 1990, IEEE T PATTERN ANAL, V12, P78, DOI 10.1109/34.41386; Deriche R., 1992, P 2 INT C IM PROC, P263; Florack LMJ, 1997, IMAGE STRUCTURE; Jain A. K., 1989, FUNDAMENTALS DIGITAL; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Lindeberg T., 1994, SCALE SPACE THEORY C; Nussbaumer H.J., 1982, P IEEE, V70, P527; Press WH, 1988, NUMERICAL RECIPES C; ROMENY B, 1997, SCALE SPACE THEORY C; Rosenfeld A, 1982, COMPUTER SCI APPL MA; Sporring Jon, 1997, GAUSSIAN SCALE SPACE	12	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2000	22	9					1050	1055		10.1109/34.877526	http://dx.doi.org/10.1109/34.877526			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	361TY					2022-12-18	WOS:000089741300011
J	Vemuri, BC; Guo, YL				Vemuri, BC; Guo, YL			Snake pedals: Compact and versatile geometric models with physics-based control	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						geometric models; snakes; pedal curves/surfaces; alternating direction implicit method; Levenberg-Marquardt method	DEFORMATIONS; 2-D; MRI	In this paper, we introduce a novel geometric shape modeling scheme which allows for representation of global and local shape characteristics of an object. Geometric models are traditionally well-suited for representing global shapes without local detail. However, we propose a powerful geometric shape modeling scheme which allows for the representation of global shapes with local detail and permits model shaping as well as topological changes via physics-based control. The proposed modeling scheme consists of representing shapes by pedal curves and surfaces-pedal curves/surfaces are the loci of the foot of perpendiculars to the tangents of a fixed curve/surface from a fixed point called the pedal point. By varying the location of the pedal point, one can synthesize a large class of shapes which exhibit both local and global deformations. We introduce physics-based control for shaping these geometric models by letting the pedal point vary and use a snake to represent the position of this varying pedal point. The model dubbed as a "snake pedal" allows for interactive manipulation via forces applied to the snake. We develop a fast numerical iterative algorithm for shape recovery from image data using this geometric shape modeling scheme. The algorithm involves the Levenberg-Marquardt (LM) method in the outer loop for solving the global parameters and the Alternating Direction Implicit (ADI) method in the inner loop for solving the local parameters of the model. The combination of the global and local scheme leads to an efficient numerical solution to the model fitting problem. We demonstrate the applicability of this modeling scheme via examples of shape synthesis and shape estimation from real image data.	Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA; David Sarnoff Labs, Princeton, NJ USA	State University System of Florida; University of Florida; Sarnoff Corporation	Vemuri, BC (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.	vemuri@cise.ufl.edu; yguo@sarnoff.com						Amini AA, 1998, IEEE T MED IMAGING, V17, P344, DOI 10.1109/42.712124; Bardinet E., 1994, Proceedings of the IEEE Workshop on Biomedical Image Analysis (Cat. No.94TH0624-7), P184, DOI 10.1109/BIA.1994.315882; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; COHEN I, 1994, INT C PATT RECOG, P403, DOI 10.1109/ICPR.1994.576961; Cohen LD, 1996, J MATH IMAGING VIS, V6, P59, DOI 10.1007/BF00127375; DeCarlo D, 1996, IEEE T PATTERN ANAL, V18, P443, DOI 10.1109/34.491626; DYKSEN WR, 1987, SIAM J NUMER ANAL, V24, P59, DOI 10.1137/0724006; Gray A, 1993, MODERN DIFFERENTIAL; Guo YL, 1999, LECT NOTES COMPUT SC, V1613, P112; Han S., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P492, DOI 10.1109/ICCV.1993.378174; Jones T., 1997, P INF PROC MED IM, P113; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kelemen A, 1998, WORKSHOP ON BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P4, DOI 10.1109/BIA.1998.692374; LAI SH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P9, DOI 10.1109/CVPR.1994.323804; LAI SH, 93035 U FLOR DEP COM; LU A, 1991, COMPUT MATH APPL, V21, P43, DOI 10.1016/0898-1221(91)90124-M; LYNCH RE, 1965, J SOC IND APPL MATH, V13, P995, DOI 10.1137/0113067; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MARC PS, 1990, P IM UND WORKSH, P720; MCINERNEY T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P840, DOI 10.1109/ICCV.1995.466850; METAXAS D, 1996, MED IMAGE ANAL, V1, P53; ODonnell T, 1996, PROC CVPR IEEE, P293, DOI 10.1109/CVPR.1996.517088; OUELLETTE DV, 1981, LINEAR ALGEBRA APPL, V36, P187, DOI 10.1016/0024-3795(81)90232-9; Pentland A., 1989, Computer Graphics, V23, P215, DOI 10.1145/74334.74355; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Radeva P, 1997, COMPUT VIS IMAGE UND, V66, P163, DOI 10.1006/cviu.1997.0611; Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903; Staib L. H., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P98, DOI 10.1109/CVPR.1989.37834; Szekely G, 1996, Med Image Anal, V1, P19, DOI 10.1016/S1361-8415(96)80003-X; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; VEMURI BC, 1994, ACM T GRAPHIC, V13, P177, DOI 10.1145/176579.176583	31	9	9	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2000	22	5					445	459		10.1109/34.857002	http://dx.doi.org/10.1109/34.857002			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	337FV					2022-12-18	WOS:000088347500003
J	Davis, TJ				Davis, TJ			Fast decomposition of digital curves into polygons using the Haar transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Haar transform; Haar functions; digital curves; polygonal decomposition; feature perimeter	POINT DETECTION; IMAGE CURVES; ALGORITHM; APPROXIMATION; ORGANIZATION; SEGMENTATION; LINES; ARCS	The perimeters of features in digital images are decomposed into sets of straight lines using the Haar transform. The Haar basis functions preserve sharp changes in direction along the perimeter while still allowing smoothing. The coefficients of the Haar transform are simply related to the error between the polygonal decomposition and the true perimeter. The Haar transform can be calculated efficiently with a computational overhead linear in the number of data points.	CSIRO, Mfg Sci & Technol, Clayton S, Vic 3169, Australia	Commonwealth Scientific & Industrial Research Organisation (CSIRO)	Davis, TJ (corresponding author), CSIRO, Mfg Sci & Technol, Private Bag 33, Clayton S, Vic 3169, Australia.		Davis, Timothy J/B-7773-2012	Davis, Timothy J/0000-0002-7299-4900				Beauchamp K. G., 1975, WALSH FUNCTIONS THEI; COOPER DB, 1976, IEEE T COMPUT, V25, P1020; FISCHLER MA, 1994, IEEE T PATTERN ANAL, V16, P113, DOI 10.1109/34.273737; Hu JM, 1997, PATTERN RECOGN, V30, P701, DOI 10.1016/S0031-3203(96)00105-7; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; LOWE DG, 1989, INT J COMPUT VISION, V3, P119, DOI 10.1007/BF00126428; MONTNARI U, 1970, COMMUN ACM, V13, P41, DOI 10.1145/361953.361967; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PIKAZ A, 1994, IEEE T PATTERN ANAL, V16, P808, DOI 10.1109/34.308476; Rosin P. L., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P1381, DOI 10.1142/S0218001494000681; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; ROSIN PL, 1989, IMAGE VISION COMPUT, V7, P109, DOI 10.1016/0262-8856(89)90004-8; SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W; SHORE JE, 1973, IEEE T COMMUN, VCO21, P209, DOI 10.1109/TCOM.1973.1091637; WEST GAW, 1991, PATTERN RECOGN, V24, P643, DOI 10.1016/0031-3203(91)90031-Y; WUESCHER DM, 1991, IEEE T PATTERN ANAL, V13, P41, DOI 10.1109/34.67629; Yu DG, 1997, PATTERN RECOGN, V30, P57, DOI 10.1016/S0031-3203(96)00055-6; Zhang XT, 1997, PATTERN RECOGN, V30, P239, DOI 10.1016/S0031-3203(96)00075-1; ZHU PF, 1995, IEEE T PATTERN ANAL, V17, P737, DOI 10.1109/34.400564	20	9	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1999	21	8					786	790		10.1109/34.784293	http://dx.doi.org/10.1109/34.784293			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	225YF					2022-12-18	WOS:000081993000011
J	Ferreira, A; Ubeda, S				Ferreira, A; Ubeda, S			Computing the medial axis transform in parallel with eight scan operations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						parallel image processing; medial axis transform; parallel prefix; BSP algorithms	ALGORITHMS	The main result of this paper shows that the block-based digital medial axis transform can be computed in parallel by a constant number of calls to scan (parallel prefix) operations. This gives time- and/or work-optimal parallel implementations for the distance-based and the block-based medial axis transform in a wide variety of parallel architectures. Since only eight scan operations plus a dozen local operations are performed, the algorithm is very easy to program and use. The originality of our approach is the use of the notion of a derived grid and the oversampling of the image in order to reduce the computation of the block-based medial axis transform in the original grid to the much easier task of computing the distance based medial axis transform of the oversampling of the image on the derived grid.	INRIA, I3S, CNRS, Project SLOOP, F-06902 Sophia Antipolis, France; Ecole Normale Super Lyon, INRIA, CNRS, UMR 8512, F-69364 Lyon 7, France	Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; Universite Cote d'Azur; Centre National de la Recherche Scientifique (CNRS); Ecole Normale Superieure de Lyon (ENS de LYON); Inria	Ferreira, A (corresponding author), INRIA, I3S, CNRS, Project SLOOP, 2004 Route Lucioles,BP 93, F-06902 Sophia Antipolis, France.	Afonso.Ferreira@sophia.inria.fr; ubeda@ens-lyon.fr						Bertrand G., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P326; BITZ G, 1988, INT J COMPUT MATH, V25, P173; Blelloch G.E., 1993, SYNTHESIS PARALLEL A, V1st, P35; BLUM H, 1964, S MOD PERC SPEECH VI; FERREIRA A, 1996, PARALLEL COMMUNICATI; FERREIRA A, 1998, LECT NOTES COMPUTER; FERREIRA A, 1995, P IEEE INT C IM PROC, V2, P105; Garey M.R., 1979, COMPUTERS INTRACTABI; JENQ JF, 1992, IEEE T PATTERN ANAL, V14, P1218, DOI 10.1109/34.177389; KIM SK, 1991, SIAM J DISCRETE MATH, V4, P385; LU M, 1988, J PARALLEL DISTRIBUR, V5, P611; MIGUET S, 1990, INT J COMPUT MATH, V32, P61, DOI 10.1080/00207169008803815; MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486; Montanvert A., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P430; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PFALTZ JL, 1967, COMMUN ACM, V10, P119, DOI 10.1145/363067.363120; ROSENFELD A, 1989, DIGITAL PICTURE PROC; ROSENFELD A, 1966, J ACM, V13, P69; Serra J, 1982, IMAGE ANAL MATH MORP; VALIANT LG, 1990, COMMUN ACM, V33, P103, DOI 10.1145/79173.79181; WU AY, 1986, COMPUT VISION GRAPH, V34, P76, DOI 10.1016/0734-189X(86)90049-6	21	9	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					277	282		10.1109/34.754629	http://dx.doi.org/10.1109/34.754629			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD					2022-12-18	WOS:000079296000011
J	Schmitt, M				Schmitt, M			Response to the comment on "Geodesic saliency of watershed contours and hierarchical segmentation"	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material						mathematical morphology; watershed; dynamics; segmentation		This paper presents in details the algorithm of the watershed, which we have sketched in Transactions on Pattern Analysis and Machine intelligence, vol. 18, no. 12, pp 1,163-1,173 and criticized in this issue. First, the formal definition of the flooding list, the key data structure of the algorithm, is given. Then, the construction of this flooding list and of the watershed are described and proved.	Ecole Mines, Ctr Geostat, F-77305 Fontainebleau, France	UDICE-French Research Universities; PSL Research University Paris; MINES ParisTech	Schmitt, M (corresponding author), Ecole Mines, Ctr Geostat, 35 Rue St Honore, F-77305 Fontainebleau, France.			Schmitt, Michel/0000-0002-5003-1062				Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Schmitt M., 1993, MORPHOLOGIE MATH; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344	3	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1998	20	7					764	766		10.1109/TPAMI.1998.689308	http://dx.doi.org/10.1109/TPAMI.1998.689308			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZY930					2022-12-18	WOS:000074677200010
J	Chandran, S; Potty, AK				Chandran, S; Potty, AK			Energy minimization of contours using boundary conditions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dynamic programming; energy minimization; deformable contours; optimal solutions; active contours		Reconstruction of objects from a scene may be viewed as a data fitting problem using energy minimizing splines as the basic shape. The process of obtaining the minimum to construct the "best" shape can sometimes be important. Some of the potential problems in the Euler-Lagrangian variational solution proposed in the original formulation [1], were brought to light in [2], and a dynamic programming (DP) method was also suggested. In this paper we further develop the DP solution. We show that in certain cases, the discrete form of the solution in [2], and adopted subsequently [3], [4], [5], [6] may also produce local minima, and develop a strategy to avoid this. We provide a stronger form of the conditions necessary to derive a solution when the energy depends on the second derivative, as in the case of "active contours.".	Indian Inst Technol, Dept Comp Sci & Engn, Bombay 400076, Maharashtra, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay	Chandran, S (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Bombay 400076, Maharashtra, India.	sharat@cse.iitb.ernet.in; apkp@cse.iitb.ernet.in						Amini A. A, 1990, IEEE T PATTERN ANAL; Bellman RE, 1957, DYNAMIC PROGRAMMING; FUJIMURA K, 1993, J VISUAL COMM IM DEC; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; OHNISHI Y, 1990, THESIS TSUKUBA U; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POTTY AK, 1995, THESIS IIT BOMBAY; UEDA N, 1991, SPRING NATL CONV REC; WILLIAMS DJ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P592	10	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					546	549		10.1109/34.682184	http://dx.doi.org/10.1109/34.682184			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZR253		Green Submitted			2022-12-18	WOS:000073955600010
J	Say, ACC				Say, ACC			L'Hopital's filter for QSIM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						qualitative reasoning; qualitative simulation; spurious behaviors; QSIM; state filtering	QUALITATIVE SIMULATION	We have identified a source of spurious predictions inside the qualitative simulation algorithm QSIM. The algorithm fails to check for violations of l'Hopital's rule, which causes the addition of inconsistent states to the behavior tree. Our proposed solution involves adding a new state filter to make the required controls and does not necessitate any additions or restrictions in the input set: We make use of extended corresponding value tuples spanning multiple constraints. The necessary modifications to the algorithm are explained and the technique is demonstrated on examples. Used in conjunction with other spurious behavior elimination methods, this approach would increase QSIM's ability to handle more complex systems.	Bogazici Univ, Dept Comp Engn, TR-80815 Istanbul, Turkey	Bogazici University	Say, ACC (corresponding author), Bogazici Univ, Dept Comp Engn, TR-80815 Istanbul, Turkey.							FOUCHE P, 1992, IEEE T SYST MAN CYB, V22, P47, DOI 10.1109/21.141310; KUIPERS B, 1986, ARTIF INTELL, V29, P289, DOI 10.1016/0004-3702(86)90073-1; Kuipers B., 1994, QUALITATIVE REASONIN; KUIPERS BJ, 1991, ARTIF INTELL, V51, P343, DOI 10.1016/0004-3702(91)90114-Y; KUIPERS BJ, 1990, 90122 AI TR U TEX AU; LEE WW, 1988, P AAAI88 SAINT PAUL, P286; SAY ACC, 1993, IEEE T PATTERN ANAL, V15, P967, DOI 10.1109/34.232085; SAY ACC, 1997, P 11 INT WORKSH QUAL, P165; Thomas Jr G. B., 1983, CALCULUS ANAL GEOMET; WILLIAMS BC, 1991, ARTIF INTELL, V51, P39, DOI 10.1016/0004-3702(91)90108-V	10	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1998	20	1					1	8		10.1109/34.655645	http://dx.doi.org/10.1109/34.655645			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YV876					2022-12-18	WOS:000071872400001
J	Kopec, GE; Lomelin, M				Kopec, GE; Lomelin, M			Supervised template estimation for document image decoding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image decoding; Markov models; template estimation; character recognition; document recognition; maximum likelihood	SOURCE MODELS	An approach to supervised training of character templates from page images and unaligned transcriptions is proposed. The template training problem is formulated as one of constrained maximum likelihood parameter estimation within the document image decoding framework. This leads to a three-phase iterative training algorithm consisting pf transcription alignment, aligned template estimation (ATE), and channel estimation steps. The maximum likelihood ATE problem is shown to be NP-complete and, thus, an approximate solution approach is developed. An evaluation of the training procedure in a document-specific decoding task, using the University of Washington UW-II database of scanned technical journal articles, is described.	MICROSOFT CORP,SEATTLE,WA	Microsoft	Kopec, GE (corresponding author), XEROX CORP,PALO ALTO RES CTR,3333 COYOTE HILL RD,PALO ALTO,CA 94304, USA.							BAIRD HS, 1994, P SOC PHOTO-OPT INS, V2181, P106, DOI 10.1117/12.171098; *CA DEP WAT RES, 1994, CAL DEP WAT RES B; CHEN FR, 1995, P SOC PHOTO-OPT INS, V2422, P256, DOI 10.1117/12.205828; FRUCHTERMAN T, 1995, P S DOC IM UND TECHN, P94; Hopcroft John E., 1979, INTRO AUTOMATA THEOR; HULL JF, 1996, THESIS MIT CAMBRIDGE; KAM AC, 1995, P SOC PHOTO-OPT INS, V2422, P84, DOI 10.1117/12.205811; Kam AC, 1996, IEEE T PATTERN ANAL, V18, P945, DOI 10.1109/34.537350; KOPEC G, 1993, P 2 INT C DOC AN REC; KOPEC G, 1997, DOCUMENT RECOGNITION, V3027; KOPEC G, 1996, DOCUMENT RECOGNITION, V2660, P14; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; Kopec GE, 1996, P SOC PHOTO-OPT INS, V2660, P2, DOI 10.1117/12.234702; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; PHILLIPS I, 1995, REFERENCE MANUAL UW; Rabiner L., 1993, FUNDAMENTALS SPEECH; RUBENSTEIN R, 1988, DIGITAL TYPOGRAPHY; STABLER H, 1995, DOCUMENT ANAL SYSTEM; [No title captured]	20	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1997	19	12					1313	1324		10.1109/34.643891	http://dx.doi.org/10.1109/34.643891			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YK781					2022-12-18	WOS:A1997YK78100001
J	Lai, SH; Vemuri, BC				Lai, SH; Vemuri, BC			Physically based adaptive preconditioning for early vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						early vision; computational vision; adaptive preconditioning; wavelet transform; regularization; surface reconstruction; shape from shading; optic flow computation	OPTICAL-FLOW; SHAPE	Several problems in early vision have been formulated in the past in a regularization framework. These problems, when discretized, lead to large sparse linear systems. In this paper, we present a novel physically based adaptive preconditioning technique which can be used in conjunction with a conjugate gradient algorithm to dramatically improve the speed of convergence for solving the aforementioned linear systems. A preconditioner, based on the membrane spline, or the thin plate spline, or a convex combination of the two, is termed a physically based preconditioner for obvious reasons. The adaptation of the preconditioner to an early vision problem is achieved via the explicit use of the spectral characteristics of the regularization filter in conjunction with the data. This spectral function is used to modulate the frequency characteristics of a chosen wavelet basis, and these modulated values are then used in the construction of our preconditioner. We present the preconditioner construction for three different early vision problems namely, the surface reconstruction, the shape from shading, and the optical flow computation problems. Performance of the preconditioning scheme is demonstrated via experiments on synthetic and real data sets. We note that our preconditioner outperforms other methods of preconditioning for these early vision problems, described in computer Vision literature.	UNIV FLORIDA, DEPT COMP & INFORMAT SCI, GAINESVILLE, FL 32611 USA; UNIV FLORIDA, DEPT ELECT & COMP ENGN, GAINESVILLE, FL 32611 USA	State University System of Florida; University of Florida; State University System of Florida; University of Florida	Lai, SH (corresponding author), SIEMENS CORP RES, TECH STAFF, PRINCETON, NJ 08540 USA.			Lai, Shang-Hong/0000-0002-5092-993X				BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BEYLKIN G, 1991, COMMUN PUR APPL MATH, V44, P141, DOI 10.1002/cpa.3160440202; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; BUZBEE BL, 1971, SIAM J NUMER ANAL, V8, P722, DOI 10.1137/0708066; CHHABRA AK, 1994, IEEE T PATTERN ANAL, V16, P1133, DOI 10.1109/34.334395; GOLUB G, 1993, SCI COMPUTING; Golub G. H., 1996, MATRIX COMPUTATIONS; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; HORN BKP, 1989, ARTIFICIAL INTELLIGE; JAFFARD S, 1992, SIAM J NUMER ANAL, V29, P965, DOI 10.1137/0729059; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Lai S. H., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P455, DOI 10.1109/ISCV.1995.477044; LAI SH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P9, DOI 10.1109/CVPR.1994.323804; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; PENTLAND AP, 1994, IEEE T PATTERN ANAL, V16, P410, DOI 10.1109/34.277594; Rioul O, 1991, IEEE SIGNAL PROC MAG, V8, P14, DOI 10.1109/79.91217; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; SUTER D, 1991, IEEE T COMPUT, V40, P1359, DOI 10.1109/12.106221; SZELISKI R, 1990, IEEE T PATTERN ANAL, V12, P513, DOI 10.1109/34.56188; SZELISKI R, 1991, CVGIP-IMAG UNDERSTAN, V53, P129, DOI 10.1016/1049-9660(91)90023-I; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; VEMURI BC, 1994, ACM T GRAPHIC, V13, P177, DOI 10.1145/176579.176583; VEMURI BC, 1986, IMAGE VISION COMPUT, V4, P107, DOI 10.1016/0262-8856(86)90029-6; YAOU MH, 1994, IEEE T PATTERN ANAL, V16, P673, DOI 10.1109/34.297948; YSERENTANT H, 1986, NUMER MATH, V49, P379, DOI 10.1007/BF01389538	29	9	10	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1997	19	6					594	607		10.1109/34.601247	http://dx.doi.org/10.1109/34.601247			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XG302		Green Submitted			2022-12-18	WOS:A1997XG30200004
J	Sarachik, KB				Sarachik, KB			The effect of Gaussian error in object recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian error models; object recognition; error analysis		In model based recognition, the goal is to locate an instance of one or more known objects in an image. The problem is compounded in real images by the presence of clutter, occlusion, and sensor error, which can lead to ''false negatives,'' failures to recognize the presence of the object, and ''false positives,'' in which the algorithm incorrectly identifies an occurrence of the object. The probability of either event is affected by parameters within the recognition algorithm, which are almost always chosen in an ad-hoc fashion. The effect of the parameter values on the likelihood that the recognition algorithm will make a mistake are usually not understood explicitly. To address the problem, we explicitly model the noise that occurs in the image. In a typical recognition algorithm, hypotheses about the position of the object are tested against the evidence in the image, and an overall score is assigned to each hypothesis. We use a statistical model to determine what score a correct or incorrect hypothesis is likely to have, and use standard binary hypothesis testing techniques to distinguish correct from incorrect hypotheses. Using this approach, we can compare algorithms and noise models, and automatically choose values for internal system thresholds to minimize the probability of making a mistake.	MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)								ALTER T, 1993, P 4 INT C COMP VIS M; BAIRD HS, 1984, THESIS CAMBRIDGE; CASS TA, 1990, 1133 MIT AI LAB; COSTA M, 1990, 6TH P ISR C AI, P35; FISCHLER MA, 1980, 213 SRI INT; GRIMSON W, 1991, 1250 MIT AI LAB; GRIMSON W, 1992, 1362 MIT AI LAB; GRIMSON W, 1994, INT J COMPUTER VISIO, V13; HUTTENLOCHER DP, 1988, 1045 MIT AI LAB; JACOBS DW, 1992, 1416 MIT AI LAB; LAMDAN Y, 1991, P IEEE COMPUTER VISI; Rigoutsos I., 1991, P 8 ISR C ART INT CO; SARACHIK K, 1994, 1469 MIT AI LAB; Sarachik K. B., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P400, DOI 10.1109/CVPR.1993.341099; TSAI FCD, 1993, 640 NEW YORK U ROB R; VANTREES HL, 1968, DETECTION ESTIMATION, V1, pCH2; WELLS W, 1992, 1395 MIT AI LAB	17	9	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1997	19	4					289	301		10.1109/34.587990	http://dx.doi.org/10.1109/34.587990			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WW122					2022-12-18	WOS:A1997WW12200001
J	Geiger, D; Gupta, A; Costa, LA; Vlontzos, J				Geiger, D; Gupta, A; Costa, LA; Vlontzos, J			Dynamic programming for detecting, tracking, and matching deformable contours (vol 17, pg 294 1995)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194	1	9	9	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1996	18	5					575	575						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL691					2022-12-18	WOS:A1996UL69100012
J	Ostuni, J; Dunn, S				Ostuni, J; Dunn, S			Motion from three weak perspective images using image rotation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						weak perspective; correspondence; object pose; rigid object motion; image rotation		In this paper, it is shown that by using image rotation, one can develop a linear algorithm to find motion using three weak perspective images, By using the correspondence of four points over a pair of these images, a function can be developed which allows one to perform the necessary rotation. With the correct image rotation, one need only add a third image to have an overdetermined linear system with which to solve for the unknown elements of the rotation matrices relating these three images.	RUTGERS STATE UNIV,DEPT BIOMED ENGN,PISCATAWAY,NJ 08855	Rutgers State University New Brunswick	Ostuni, J (corresponding author), NIH,DIV COMP RES & TECHNOL,BLDG 13,ROOM 3W13,BETHESDA,MD 20892, USA.							HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; LEE CH, 1990, COMPUT VISION GRAPH, V52, P309, DOI 10.1016/0734-189X(90)90078-A; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P922; Vidyasagar M., 2008, ROBOT DYNAMICS CONTR	5	9	9	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					64	69		10.1109/34.476013	http://dx.doi.org/10.1109/34.476013			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500008
J	HADDAD, ZS; SIMANCA, SR				HADDAD, ZS; SIMANCA, SR			FILTERING IMAGE RECORDS USING WAVELETS AND THE ZAKAI EQUATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE FILTERING; ZAKAI EQUATION; WAVELETS; STOCHASTIC FILTER; TRACKING; IMAGE REPRESENTATION; NOISE; BROWNIAN MODEL; POISSON MODEL		Consider the problem of detecting and localizing a faint object moving in an ''essentially stationary'' background, using a sequence of two-dimensional low-SNR images of the scene. A natural approach consists of ''digitizing'' each snapshot into a discrete set of observations, sufficiently (perhaps not exactly) matched to the object in question, then tracking the object using an appropriate stochastic filter. The tracking would be expected to make up for the low signal-to-noise ratio, thus allowing one to ''coherently'' process successive images in order to beat down the noise and localize the object. Thus, ''tracking'' here does not refer to the ususal notion of detecting then tracking: rather, we track in order to detect. The problem then becomes one of choosing the appropriate image representation as well as the optimal (and necessarily nonlinear) filter. We propose exact and approximate solutions using wavelets and the Zakai equation. The smoothness of the wavelets used is required in the derivation of the evolution equation for the conditional density giving the filter, and their orthogonality makes it possible to carry out actual computations of the Ito- and change-of-gauge-terms in the algorithm effectively.	SUNY STONY BROOK,DEPT MATH,STONY BROOK,NY 11794	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	HADDAD, ZS (corresponding author), CALTECH,JET PROP LAB,4800 OAK GROVE BLVD,PASADENA,CA 91100, USA.							BENES VE, NONLINEAR FILTERING; Brockett R.W., 1981, STOCHASTIC SYSTEMS M, P441; Brockett R.W., 1980, ANAL OPTIMIZATION ST, P299; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; Duncan T. E., 1967, THESIS STANFORD U; HOPKINS WE, 1985, STOCHASTICS, V17, P313; LETGERS GR, 1982, IEEE T PATTERN ANAL, V4, P583; LIPSTER RS, 1977, STATISTICS RANDOM PR; Mallat S. G., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P2; Mortensen R. E., 1966, THESIS U CALIFORNIA; NAGEL HH, 1978, 4TH P INT JOINT C PA, P186; ZAKAI M, 1969, Z WAHRSCHEINLICHKEIT, V11, P230, DOI 10.1007/BF00536382	13	9	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1995	17	11					1069	1078		10.1109/34.473232	http://dx.doi.org/10.1109/34.473232			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TD854					2022-12-18	WOS:A1995TD85400005
J	RINGACH, DL; BARAM, Y				RINGACH, DL; BARAM, Y			A DIFFUSION MECHANISM FOR OBSTACLE DETECTION FROM SIZE-CHANGE INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						OBSTACLE DETECTION; COLLISION AVOIDANCE; MOTION FIELD; IMMEDIACY MEASURE; DIFFUSION PROCESS; SIZE-CHANGE INFORMATION	OPTICAL-FLOW; 3-DIMENSIONAL MOTION; FIELD; COLLISION; OBSERVER; PARALLAX; MOVEMENT; OBJECTS; IMAGE; DEPTH	A mechanism for the visual detection of obstacles is presented. A new immediacy measure, representing the imminence of collision between an object and a moving observer, is defined. A diffusion process on the image domain, whose initial condition is determined by the motion field normal to the object's boundary, is shown to converge asymptotically to the immediacy measure. A network of locally connected cells, derived from a finite-difference approximation of the diffusion equation, estimates the immediacy measure from normal velocity and boundary information provided by a motion measurement and segmentation stage. The algorithm's performance on real image sequences is demonstrated.	TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,IL-32000 HAIFA,ISRAEL	Technion Israel Institute of Technology	RINGACH, DL (corresponding author), NYU,CTR NEURAL SCI,NEW YORK,NY 10003, USA.							ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; [Anonymous], 1986, EVASION DIVISAS HIST; BARNIV Y, 1990, NASA102802 TECH MEM; Berezanskii J.M., 1968, EXPANSIONS EIGENFUNC, V17; BEVERLEY KI, 1983, VISION RES, V23, P1387, DOI 10.1016/0042-6989(83)90150-5; BRAMBLE JH, 1962, PAC J MATH, V12, P823, DOI 10.2140/pjm.1962.12.823; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; DAVIES MNO, 1988, J EXP BIOL, V138, P71; Forsythe G.E., 1960, PARTIAL DIFFERENTIAL, V20, P415; FOX DW, 1966, SIAM REV, V8, P427, DOI 10.1137/1008101; FRIEDMAN A, 1963, GENERALIZED FUNCTION; GELFAND IM, 1964, GENERALIZED FUNCTION, V3; Goodbody A. M., 1982, CARTESIAN TENSORS; Hildebrand F.B., 1968, FINITE DIFFERENCE EQ; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HURLBERT A, 1989, ADV NEURAL INFORMATI, V1; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; KOENDERINK JJ, 1976, J OPT SOC AM, V66, P717, DOI 10.1364/JOSA.66.000717; KOENDERINK JJ, 1986, VISION RES, V26, P161, DOI 10.1016/0042-6989(86)90078-7; KUTTLER JR, 1984, SIAM REV, V26, P163, DOI 10.1137/1026033; LEE DN, 1976, PERCEPTION, V5, P437, DOI 10.1068/p050437; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MEIS T, 1978, NUMERICAL SOLUTION P; Mitchell AR, 1980, FINITE DIFFERENCE ME; NELSON RC, 1989, IEEE T PATTERN ANAL, V11, P1102, DOI 10.1109/34.42840; NELSON RC, 1988, BIOL CYBERN, V58, P261, DOI 10.1007/BF00364131; NELSON RC, 1988, 2ND P ICCV, P548; Payne L. E., 1960, ARCH RATION MECH AN, V5, P286, DOI DOI 10.1007/BF00252910; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; PROTTER MH, 1987, SIAM REV, V29, P185, DOI 10.1137/1029041; RIEGER JH, 1985, J OPT SOC AM A, V2, P354, DOI 10.1364/JOSAA.2.000354; RINGACH DL, 1992, CIS9220 ISR I TECHN; RINGACH DL, 1990, THESIS ISRAEL I TECH; Saul'yev V.K., 1964, INTEGRATION EQUATION; SCHIFF W, 1979, PERCEPTION, V8, P647, DOI 10.1068/p080647; SIGILLITO VG, 1977, EXPLICIT PRIORI INEQ; SUBBARAO M, P AAAI87, P744; SUBBARAO M, 1986, CARTR221 U MAR CTR A; Tikhonov A., 1977, SOLUTIONS ILL POSED; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VERRI A, 1987, 1ST P INT C COMP VIS, P171; WAGNER H, 1982, NATURE, V297, P147, DOI 10.1038/297147a0; WAXMAN AM, 1988, ADV COMPUTER VISION, V1; WEINBERGER HF, 1956, J RATION MECH ANAL, V5, P533; Weyl H., 1911, NACHR KONIGL GES WIS, V1911, P110; YOUNG S, 1988, J EXP BIOL, V137, P387; Zauderer E, 1989, PARTIAL DIFFERENTIAL	50	9	9	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1994	16	1					76	80		10.1109/34.273715	http://dx.doi.org/10.1109/34.273715			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MV733					2022-12-18	WOS:A1994MV73300007
J	SAWHNEY, HS; OLIENSIS, J; HANSON, AR				SAWHNEY, HS; OLIENSIS, J; HANSON, AR			IMAGE DESCRIPTION AND 3-D RECONSTRUCTION FROM IMAGE TRAJECTORIES OF ROTATIONAL MOTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CONIC CURVE FITTING; IMAGE SEQUENCE ANALYSIS; MOTION TRAJECTORIES; NONLINEAR OPTIMIZATION; SPATIAL AND TEMPORAL GROUPING; STRUCTURE FROM MOTION; TIME-VARYING IMAGERY	EXTRACTION; ALGORITHM; OBJECTS	This paper presents a new technique for reconstructing the 3-D structure and motion of a scene undergoing relative rotational motion with respect to the camera. Given image correspondences of point features tracked over many frames, a two-stage technique for reconstruction is presented. First, a grouping algorithm that exploits spatio-temporal constraints of the common motion to achieve a reliable description of discrete point correspondences as curved trajectories (general conics in the case of rotational motion) in the image plane is developed. In contrast, trajectories fitted to points independent of each other lead to arbitrary image descriptions and very inaccurate 3-D parameters. Second, a new closed-form solution, under perspective projection, for the 3-D motion and location of points from the computed image trajectories is presented. Both stages are applied to real image sequences with good results. This approach represents a first step in a longer-term research effort examining the role of explicit spatio-temporal organization in the interpretation of scenes from dynamic images.	UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,AMHERST,MA 01003; UNIV MASSACHUSETTS,COMP VIS LAB,AMHERST,MA 01003	University of Massachusetts System; University of Massachusetts Amherst; University of Massachusetts System; University of Massachusetts Amherst	SAWHNEY, HS (corresponding author), IBM CORP,ALMADEN RES CTR,SAN JOSE,CA 95120, USA.							ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ADIV G, 1985, THESIS U MASSACHUSET; AGGARWAL JK, 1988, TR88247 U TEX TECH R; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; BOLDT M, 1989, IEEE T SYST MAN CYB, V19, P1581, DOI 10.1109/21.44073; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; Broida T. J., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P21, DOI 10.1109/WVM.1989.47090; CHEN DS, 1989, IEEE T PATTERN ANAL, V11, P749, DOI 10.1109/34.192470; COLLINS RT, 1989, P TOP M OPT SOC AM I, P92; DANIILIDIS K, 1990, 1ST P EUR C COMP VIS, P199; FAUGERAS OD, 1987, 1ST P INT C COMP VIS, P25; FORSYTH DA, 1990, 1ST P EUR C COMP VIS, P427; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; Jaenicke R. A., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P256, DOI 10.1109/WVM.1989.47117; KUMAR R, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P365; Kumar R., 1989, P WORKSHOP INTERPRET, P52; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781; MARIMONT DH, 1986, THESIS STANFORD U ST; PORRILL J, 1990, IMAGE VISION COMPUT, V8, P37, DOI 10.1016/0262-8856(90)90054-9; Press W. H., 1986, NUMERICAL RECIPES C; Roberts K. S., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P635, DOI 10.1109/CVPR.1988.196303; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; SAWHNEY HS, 1989, COINS TR8990 U MASS; SHARIAT H, 1986, THESIS U SO CALIFORN; SPETSAKIS ME, 1988, DEC P INT C COMP VIS, P449; STEVENS KA, 1978, BIOL CYBERN, V29, P19, DOI 10.1007/BF00365232; TODD JT, 1982, J EXP PSYCHOL HUMAN, V8, P238, DOI 10.1037/0096-1523.8.2.238; TSAI RY, 1984, IMAGE UNDERSTANDING, P135; WEBB JA, 1982, ARTIF INTELL, V19, P107, DOI 10.1016/0004-3702(82)90023-6; WENG J, 1989, JUN P IEEE C COMP VI, P144; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; Williams L. R., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P441, DOI 10.1109/CCV.1988.590021	35	9	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					885	898		10.1109/34.232075	http://dx.doi.org/10.1109/34.232075			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600003
J	LIU, Y; HUANG, TS				LIU, Y; HUANG, TS			VEHICLE-TYPE MOTION ESTIMATION FROM MULTIFRAME IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CONSTANT MOTION; LONG IMAGE SEQUENCE; MOTION MODEL; POINT CORRESPONDENCES; VEHICLE MOTION	SEQUENCE; PARAMETERS	A new model for vehicle-type motion, which assumes that the motion is a rotation around an axis through the vehicle center followed by a forward translation along the main axis of the vehicle, is proposed. The contribution of this paper is threefold: 1) When the rotation and the amplitude of translation are constant, this type of motion is shown to be equivalent to a constant camera-centered motion. This indicates that a constant motion in the conventional camera-centered model, which is commonly considered to be artificial, can in fact be a reasonable model in real life. 2) We show that a constant vehicle-type motion can be interpreted as a constant screw motion. 3) A linear algorithm for estimating constant vehicle-type motion is presented, and experiments using real scene images are included. As an extension, vehicle-type motion with constant rotation and constantly accelerated translation is also discussed.	UNIV ILLINOIS,BECKMAN INST,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign	LIU, Y (corresponding author), UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801, USA.							BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; CHASLES M, 1831, B SCI MATH FERUSSAC, V14, P321; Huang T. S., 1986, HDB PATTERN RECOGNIT; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MIKHAIL EM, 1988, DAAL0386001 CAIRI SC; PRICE K, 1990, JUN P INT C PATT REC, P114; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SHARIAT H, 1990, IEEE T PATTERN ANAL, V12, P417, DOI 10.1109/34.55102; TSAI RY, 1984, IEEE T PATT ANAL MAC, V6; WENG J, 1987, P INT C COMPUT INVIS; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; YASUMOTO Y, 1986, IEEE T PATTERN ANAL, V8, P464, DOI 10.1109/TPAMI.1986.4767810; ZHUANG X, 1986, J OPT SOC AM, V3, P1429	14	9	12	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1993	15	8					802	808		10.1109/34.236249	http://dx.doi.org/10.1109/34.236249			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR948					2022-12-18	WOS:A1993LR94800005
J	SVALBE, ID				SVALBE, ID			THE GEOMETRY OF BASIS-SETS FOR MORPHOLOGICAL CLOSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BOOLEAN LOGIC; DISCRETE AREAS AND GEOMETRY; FILTERING; MORPHOLOGY; PARALLEL PROCESSING	STRAIGHT-LINES; FILTERS; REPRESENTATION	Maragos [1] has recently provided an elegant framework for the decomposition of many morphologic operations into orthogonal components or basis sets. Using this framework, a method is described to find the minimal basis set for the important operation of closing in 2-D. The closing basis sets are special because their elements are members of an ordered, global set of closing shapes or primitives. The selection or design of appropriate individual or multiple structuring elements for image filtering can be better understood, and sometimes implemented more easily, through consideration of the orthogonal closing decomposition. Partial closing of images using ordered fractions of a closing basis set(s) may give a finer texture or roughness measure than that obtained from the conventional use of scaled sets of shapes such as the disc. The connection between elements of the basis set for closing and the complete, minimal representation of arbitrary logic functions is analyzed from a geometric viewpoint.	DELFT UNIV TECHNOL, FAC APPL PHYS, PATTERN RECOGNIT GRP, DELFT, NETHERLANDS	Delft University of Technology	SVALBE, ID (corresponding author), MONASH UNIV, FAC SCI, DEPT PHYS, MELBOURNE, VIC 3004, AUSTRALIA.							ARCE GR, 1987, IEEE T ACOUST SPEECH, V35, P60, DOI 10.1109/TASSP.1987.1165036; CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464; DORST L, 1986, IEEE T PATTERN ANAL, V8, P276, DOI 10.1109/TPAMI.1986.4767781; Giardina C., 1988, MORPHOLOGICAL METHOD; HEIJMANS HJAM, 1990, COMPUT VISION GRAPH, V50, P245, DOI 10.1016/0734-189X(90)90148-O; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1170, DOI 10.1109/TASSP.1987.1165254; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1153, DOI 10.1109/TASSP.1987.1165259; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P586, DOI 10.1109/34.24793; Matheron G., 1975, RANDOM SETS INTEGRAL; RONSE C, 1991, CVGIP-IMAG UNDERSTAN, V54, P74, DOI 10.1016/1049-9660(91)90076-2; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; Serra J, 1988, IMAGE ANAL MATH MORP; SONG JS, 1990, COMPUT VISION GRAPH, V50, P308, DOI 10.1016/0734-189X(90)90150-T; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; STEVENSON RL, 1987, IEEE T CIRCUITS SYST, V34, P1292, DOI 10.1109/TCS.1987.1086067; SVALBE ID, 1989, IEEE T PATTERN ANAL, V11, P941, DOI 10.1109/34.35497; WANG X, 1990, IEEE T ACOUST SPEECH, V38, P1473, DOI 10.1109/29.57587	18	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1991	13	12					1214	1224						11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GT950					2022-12-18	WOS:A1991GT95000002
J	CRISMAN, JD; WEBB, JA				CRISMAN, JD; WEBB, JA			THE WARP MACHINE ON NAVLAB	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AUTONOMOUS NAVIGATION; MOBILE ROBOTS; NEURAL NETWORKS; ROAD FOLLOWING; STEREO VISION; SUPERCOMPUTERS; WARP COMPUTER	ARCHITECTURE; PERFORMANCE	We review the history of the Carnegie-Mellon Warp machine on Navlab, an autonomous land vehicle, and describe three Navlab vision systems implemented on the Warp machine. We then critically evaluate components of Warp in light of this experience. The Warp machine was used to implement stereo vision for obstacle avoidance and color-based road-following systems. The stereo-vision system was FIDO, which is descended from some of the earliest work in vision-guided robot vehicle navigation. Two color-based road following systems were implemented; one adapted conventional vision techniques to the problem of road recognition, and the other used a neural network-based technique to "learn" road following on-line. Finally, we conclude with observations on the utility of Warp on Navlab, the value of applications integration with machine development, the limitations of the "attached processor" model, and recommendations for future systems.	CARNEGIE MELLON UNIV,SCH COMP SCI,PITTSBURGH,PA 15213	Carnegie Mellon University								ANNARATONE M, 1987, IEEE T COMPUT, V36, P1523, DOI 10.1109/TC.1987.5009502; CLUNE E, 1987, CMIRITR8716 CARN U R; Duda R.O., 1973, J ROYAL STAT SOC SER; HAMEY LGC, 1989, COMPUT VISION GRAPH, V48, P246, DOI 10.1016/S0734-189X(89)80040-4; Kung H. T., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P570; KUNG HT, 1984, P SOC PHOTO-OPT INST, V495, P130, DOI 10.1117/12.944018; KUNG HT, 1986, DISTRIB COMPUT, V1, P246, DOI 10.1007/BF01660036; KUNG HT, 1987, SYSTOLIC SIGNAL PROC, P73; KUNG HT, 1984, VLSI PATTERN RECOGNI, P9; KUNG HT, 1983, IMAGE VISION COMPUT, V1, P30; MATTHIES LH, 1984, SEP P IEEE OC 84 C, P594; MORAVEC HP, 1980, CMURITR3 CARN U ROB; POMERLEAU D, 1990, VISION NAVIGATION CA; POMERLEAU DA, 1989, ADV NEURAL INFORMATI; ROBERTS LG, 1964, P S TOPICAL ELECTRO, P159; THORPE CE, 1984, THESIS CARNEGIEMELLO; WALLACE RS, 1989, COMPUT VISION GRAPH, V48, P265, DOI 10.1016/S0734-189X(89)80041-6	17	9	9	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1991	13	5					451	465		10.1109/34.134044	http://dx.doi.org/10.1109/34.134044			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FQ207					2022-12-18	WOS:A1991FQ20700005
J	RICHARDSON, CH; SCHAFER, RW				RICHARDSON, CH; SCHAFER, RW			A LOWER BOUND FOR STRUCTURING ELEMENT DECOMPOSITIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						LOWER BOUND ON DECOMPOSITIONS; MATHEMATICAL MORPHOLOGY; OPTIMAL DECOMPOSITIONS; STRUCTURING ELEMENT DECOMPOSITIONS; STRUCTURING ELEMENTS		This correspondence describes a theoretical lower bound on the number of points required in the decomposition of morphological structuring elements. It is shown that the decomposition of an arbitrary N-point structuring element will require at least [GRAPHICS] points. Using this lower bound it is possible to find the optimal decompositions (in terms of the minimum number of unions or the minimum number of points) for all one-dimensional connected line segments. L-dimensional rectangles may be decomposed by optimally decomposing the L one-dimensional line segments that describe the rectangle.			RICHARDSON, CH (corresponding author), GEORGIA INST TECHNOL,SCH ELECT ENGN,DIGITAL SIGNAL PROC LAB,ATLANTA,GA 30332, USA.							Abbott L., 1988, Machine Vision and Applications, V1, P23, DOI 10.1007/BF01212310; [Anonymous], AUTOMATIC GENERATION; Chvatal V., 1983, LINEAR PROGRAMMING; LAND AH, 1960, ECONOMETRICA, V28, P497, DOI 10.2307/1910129; NEMHOUSER GL, 1988, INTEGER COMBINATORIA; Richardson C. H., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V845, P249, DOI 10.1117/12.976512; RICHARDSON CH, 1990, JUL P SPIE IM ALG MO, V1350; Serra J, 1982, IMAGE ANAL MATH MORP; Taha H., 1975, INTEGER PROGRAMMING; VOGT RC, 1988, THESIS U MICHIGAN; ZHUANG XH, 1986, COMPUT VISION GRAPH, V35, P370, DOI 10.1016/0734-189X(86)90006-X	11	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1991	13	4					365	369		10.1109/34.88571	http://dx.doi.org/10.1109/34.88571			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL566					2022-12-18	WOS:A1991FL56600006
J	WANG, YF				WANG, YF			CHARACTERIZING 3-DIMENSIONAL SURFACE-STRUCTURES FROM VISUAL IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CURVATURES; GAUSSIAN CURVATURES; PRINCIPAL CURVATURES; STRUCTURED LIGHTING; SURFACE SHAPE	CLOSE-RANGE STEREOPHOTOGRAMMETRY; MODEL RECONSTRUCTION; RASTERSTEREOGRAPHY; CALIBRATION; OBJECTS; VISION	A new technique for computing intrinsic surface properties is presented in this correspondence. Intrinsic surface properties refer to those properties of a surface that are not affected by the choice of the coordinate system, the position of the viewer relative to the surface, and the particular parametric representation used to describe the imaged surface. Since intrinsic properties are characteristics of a surface, they are ideal for the purposes of representation and recognition. The intrinsic properties in which we are interested are the principal curvatures, the Gaussian curvatures, and the lines of curvature. We propose to adopt a structured-light sensing configuration where a grid pattern is projected to encode the imaged surfaces for analysis. At each stripe junction, the curvatures of the projected stripes on the imaged surface are computed and related to those of the normal sections that share the same tangential direction as the projected curves. The principal curvatures and their directions at the stripe junction under consideration are then recovered using Euler's theorem. Results using both synthetic and real images are presented.			WANG, YF (corresponding author), UNIV CALIF SANTA BARBARA,DEPT COMP SCI,SANTA BARBARA,CA 93106, USA.							AGGARWAL JK, 1988, MACHINE VISION ALGOR, P193; AGIN GJ, 1973, AUG P INT JOINT C AR, P624; BESL PJ, 1985, JUN P COMPUT VIS PAT, P430; BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869; CHIN RT, 1986, COMPUT SURV, V18, P68; CLIN AK, 1981, CNA170 U TEX AUST; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; Foley J.D., 1984, FUNDAMENTALS INTERAC; FROBIN W, 1981, PHOTOGRAMM ENG REM S, V47, P1717; FROBIN W, 1982, PHOTOGRAMM ENG REM S, V48, P215; FROBIN W, 1982, PHOTOGRAMM ENG REM S, V48, P67; Goetz A., 1970, INTRO DIFFERENTIAL G; HAKALA DG, 1981, AUG SIGGR SEM SOL MO; Hall E.L., 1982, COMPUTER         DEC, P42; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; Kreyszig E, 1959, DIFFERENTIAL GEOMETR; Le Moigne J., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P203; LIANG P, 1987, THESIS U PITTSB; ONeill B., 1966, ELEMENTARY DIFFERENT; Pennington K. S., 1970, Optics Communications, V2, P167, DOI 10.1016/0030-4018(70)90007-6; POGORELOV AV, 1973, TRANSLATIONS MATH MO, V35; POPPLESTONE RJ, 1975, 4TH P INT JOINT C AR, P664; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; POTMESIL M, 1979, MAY P WORKSH REPR 3, pH1; POTMESIL M, 1983, 8TH P INT J C ART IN; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; Requicha A. G., 1980, ACM COMPUT SURV, P437; SHIRAI Y, 1971, 2ND P INT JOINT C AR, P80; Stockman G., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P602; STRUIK DJ, 1961, DIFFERENTIAL GEOMETR; SUGIHARA K, 1985, 2ND INT S ROB RES; WANG YF, 1987, IEEE T PATTERN ANAL, V9, P129, DOI 10.1109/TPAMI.1987.4767878; WANG YF, 1989, IEEE T ROBOTIC AUTOM, V5, P460, DOI 10.1109/70.88061; WANG YF, 1988, IEEE CONTROL SYST MA, V3, P7; WANG YF, 1985, OCT P WORKSH COMP VI, P96; WANG YF, 1987, MAY P IEEE INT C ROB, P1098; WANG YF, 1988, SPIE SENSOR FUSION W; WEI D, 1983, ROBOT VISION, P143; WILL PM, 1972, PR INST ELECTR ELECT, V60, P669, DOI 10.1109/PROC.1972.8726; WILL PM, 1971, ARTIF INTELL, V2, P319, DOI 10.1016/0004-3702(71)90015-4; [No title captured]	41	9	12	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1991	13	1					52	60		10.1109/34.67630	http://dx.doi.org/10.1109/34.67630			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EX773					2022-12-18	WOS:A1991EX77300005
J	STRINGA, L				STRINGA, L			A NEW SET OF CONSTRAINT-FREE CHARACTER-RECOGNITION GRAMMARS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											STRINGA, L (corresponding author), IST RIC SCI & TECNOL,I-38050 TRENT,ITALY.							AHMED P, 1987, INT J PATTERN RECOGN, V1; BAPTISTA G, 1988, PATTERN RECOGNITION, V21; BERTHOD M, 1982, COMPUTER ANAL PERCEP, V1; CHEN CH, 1973, STATISTICAL PATTERN; CHOMSKY N, 1959, INFORM CONTR, V2; DUERR B, 1980, PATTERN RECOGNITION, V12; ELWAKIL M, 1989, PATTERN RECOGNITION, V22; FEDER J, 1968, INFORM CONTR, V13; FOUNTAIN TJ, 1986, 8TH P INT C PATT REC; FREEMAN H, 1961, IEEE T ELECTRON COMP, V10; FREEMAN H, 1962, P NAT ELECTRON C; Fu K.S., 1974, MATH SCI ENG; FU KS, 1977, SYNTACTIC PATTERN RE; FU KS, 1982, SYNTACTIC PATTERN RE; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HUANG JS, 1986, PATTERN RECOGNITION, V19; KNOBE PJ, 1967, P IEEE COMPUT C; LAM L, 1988, PATTERN RECOGNITION, V21; MANARA R, 1981, LANGUAGES ARCHITECTU; MANTAS J, 1986, PATTERN RECOGNITION, V19; Nilsson N., 1965, LEARNING MACHINES; OCALLAGHAN JF, 1970, PICTURE LANGUAGE MAC; PAVLIDIS T, 1976, 3RD P INT JOINT C PA; PAVLIDIS T, 1968, PATTERN RECOGNITION, V1; Pavlidis T., 1977, STRUCTURAL PATTERN R; RAMESH SR, 1989, PATTERN RECOGNITION, V22; SAMET H, 1984, COMPUT SURVEYS, V16; SEBESTYEN GS, 1968, DECISION PROCESS PAT; SHRIDHAR M, 1986, PATTERN RECOGNITION, V19; STRINGA L, 1989, PATTERN RECOGNITION, V10; STRINGA L, 1978, 4TH P INT JOINT C PA; STRINGA L, 1990, P INT WORKSHOP FRONT; STRINGA L, 1988, TRAINABLE MULTILAYER; SUEN CY, 1977, P INT C CYBERN SOC; SUEN CY, 1982, SIGNAL PROCESSING, V4; SUEN CY, 1986, HDB PATTERN RECOGNIT; XIE SL, 1988, PATTERN RECOGNITION, V21; YHAP EF, 1981, IBM J RES DEV, V25; [No title captured]	39	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1210	1217		10.1109/34.62612	http://dx.doi.org/10.1109/34.62612			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500					2022-12-18	WOS:A1990EN50000011
J	LANDRAUD, AM; AVRIL, JF; CHRETIENNE, P				LANDRAUD, AM; AVRIL, JF; CHRETIENNE, P			AN ALGORITHM FOR FINDING A COMMON STRUCTURE SHARED BY A FAMILY OF STRINGS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									SERV TECH ELECTR & INFORMAT, ISSY LES MOULINEAUX, FRANCE; UNIV PARIS 06, INST PROGRAMMAT, METHODES & ARCHITECTURES SYST INFORMAT LAB, F-75230 PARIS 05, FRANCE	UDICE-French Research Universities; Sorbonne Universite	LANDRAUD, AM (corresponding author), UNIV PARIS 06, INST PROGRAMMAT, F-75230 PARIS 05, FRANCE.							AHO AV, 1983, DATA STRUCTURES ALGO, P264; [Anonymous], 1972, P 4 ANN ACM S THEOR; Knuth D., 1973, ART COMPUTER PROGRAM, V2nd; Knuth D., 1973, ART COMPUTER PROGRAM, V3; Knuth DE, 1973, ART COMPUTER PROGRAM, V2; KOHONEN T, 1985, TKKFA572 HELS U TECH; Kruskal J.B., 1983, TIME WARPS STRING ED; MARTINEZ HM, 1983, NUCLEIC ACIDS RES, V11; MURATA M, 1985, P NATL ACAD SCI USA, V82, P3073, DOI 10.1073/pnas.82.10.3073; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; SAURIN W, 1985, BIOCHIMIE, V67, P517, DOI 10.1016/S0300-9084(85)80271-6; SIMON JC, 1983, RECONNAISSANCE FORME; VANRIJSBERGEN CJ, 1975, INFORMATION RETRIEVA, P29; WATERMAN MS, 1984, B MATH BIOL, V46, P473, DOI 10.1007/BF02459498	14	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1989	11	8					890	895		10.1109/34.31450	http://dx.doi.org/10.1109/34.31450			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH079					2022-12-18	WOS:A1989AH07900009
J	NEWBORN, M				NEWBORN, M			UNSYNCHRONIZED ITERATIVELY DEEPENING PARALLEL ALPHA-BETA SEARCH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											NEWBORN, M (corresponding author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3A 2A7,QUEBEC,CANADA.							AKL SG, 1982, IEEE T PATTERN ANAL, V4, P192, DOI 10.1109/TPAMI.1982.4767226; BAUDET GM, 1978, CMUCS78116 CARN MELL; BERLINER H, 1986, ARTIF INTELL, V28, P3, DOI 10.1016/0004-3702(86)90026-3; BERLINER HJ, 1986, ADV COMPUTER CHESS, V4, P166; BRATKO I, 1982, ADV COMPUTER CHESS, V3, P31; CONDON JH, 1983, CHESS SKILL MAN MACH, P201; CONDON JH, 1982, ADV COMPUTER CHESS, V3, P45; FINKEL RA, 1982, ARTIF INTELL, V19, P89, DOI 10.1016/0004-3702(82)90022-4; FISHBURN JP, 1981, 431 U WISC TECH REP; Hyatt RM., 1984, ICGA J, V7, P4; HYATT RM, 1985, ICCA J, V8, P90; KNUTH DE, 1975, ARTIF INTELL, V6, P293, DOI 10.1016/0004-3702(75)90019-3; KORF RE, 1985, 9TH P INT JOINT C AI, P1034; MARSLAND TA, 1982, COMPUT SURV, V14, P533, DOI 10.1145/356893.356895; MARSLAND TA, 1985, IEEE T PATTERN ANAL, V7, P442, DOI 10.1109/TPAMI.1985.4767683; MARSLAND TA, 1985, ADV COMPUTER CHESS, V4, P37; NEWBORN M, 1979, ADV COMPUTERS, V19, P58; Newborn M., 1986, ICCA J, V8, P209; NEWBORN M, 1982, SOCS823 MCGILL U SCH; NEWBORN MM, 1985, 1985 P ACM ANN C, P272; PEARL J, 1980, ARTIF INTELL, V14, P113, DOI 10.1016/0004-3702(80)90037-5; REINEFELD A, 1985, 9TH P IJCAI, P1040; Schaeffer J., 1986, 1986 Proceedings of the Fall Joint Computer Conference (Cat. No.86CH2345-7), P519; SCHERZER T, 1985, UNPUB HARDWARE MOVE; Slate D. J., 1977, Chess skill in man and machine, P82; STICKEL ME, 1985, 9TH P INT JOINT C AR, P1073	26	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					687	694		10.1109/34.6777	http://dx.doi.org/10.1109/34.6777			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500008
J	FERRARI, LA; SANKAR, PV; SHINNAKA, S; SKLANSKY, J				FERRARI, LA; SANKAR, PV; SHINNAKA, S; SKLANSKY, J			RECURSIVE ALGORITHMS FOR IMPLEMENTING DIGITAL IMAGE FILTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									NATL DEF ACAD,YOKOSUKA,KANAGAWA 239,JAPAN	National Defence Academy - Japan	FERRARI, LA (corresponding author), UNIV CALIF IRVINE,DEPT RADIOL SCI & ELECT ENGN,IRVINE,CA 92717, USA.							ABRAMATIC JF, 1982, IEEE T ACOUST SPEECH, V30, P1, DOI 10.1109/TASSP.1982.1163840; BURT PJ, 1981, P IEEE C PATTERN REC; CASTAN S, 1981, P IEEE C PATTERN REC; FERRARI L, 1984, COMPUT VISION GRAPH, V28, P58, DOI 10.1016/0734-189X(84)90139-7; FERRARI LA, 1984, COMPUT VISION GRAPH, V26, P292, DOI 10.1016/0734-189X(84)90214-7; FERRARI LA, 1986, COMPUT VISION GRAPH, V35, P152, DOI 10.1016/0734-189X(86)90024-1; FERRARI LA, 1985, COMPUT VISION GRAPH, V29, P358, DOI 10.1016/0734-189X(85)90131-8; FERRARI LA, 1980, THESIS U CALIFORNIA; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Oppenheim A. V., 1976, DIGITAL SIGNAL PROCE, V1st; Prenter PM., 1975, SPLINES VARIATIONAL; SEIDMAN J, 1971, AUG P COMP IM PROC R, V2; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; WELLS WM, 1986, IEEE T PATTERN ANAL, V8, P234, DOI 10.1109/TPAMI.1986.4767776	14	9	10	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1987	9	3					461	466		10.1109/TPAMI.1987.4767929	http://dx.doi.org/10.1109/TPAMI.1987.4767929			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H0768	22516640				2022-12-18	WOS:A1987H076800012
J	CHENG, HD; LIN, WC; FU, KS				CHENG, HD; LIN, WC; FU, KS			SPACE-TIME DOMAIN EXPANSION APPROACH TO VLSI AND ITS APPLICATION TO HIERARCHICAL SCENE MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CHENG, HD (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.		Lin, Wei-Chung/B-7248-2009					AHMED HM, 1982, COMPUT, V15; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; CHEN MC, 1983, CALTECH5079 DISPL FI; CHEN MC, 1982, NOV USC WORKSH VLSI; CHENG HD, 1984, ALGORITHM PARTITION; CHIANG Y, 1982, 3RD INT C DISTR COMP; CHU KH, 1981, TREE8142 PURD U SCH; EGAN R, 1982, COMPUT ARCH NEWS, V10; FORSTER MJ, 1980, COMPUT, V13; FOSTER MJ, 1981, AUG VLSI 81 NEW YORK, P75; GUIBAS LJ, 1979, JAN CALTECH C VLSI; HALL EL, 1979, COMPUTER IMAGE PROCE, pCH8; HWANG K, 1983, COMPUT, V16; JOHNSSON L, 1981, P CALTECH C VLSI; JOHNSSON L, 1981, VLSI SYSTEMS COMPUTA; Kung H., 1980, INTRO VLSI SYSTEMS; Kung HT, 1981, VLSI SYSTEMS COMPUTA; KUNG HT, 1981, TR CMUCS81110 CARN M; KUNG HT, 1979, SPARSE MATRIX P, P256; KUNG HT, 1979, JAN CALTECH C VLSI; KUNG HT, 1982, COMPUT, V15; KUNG HT, 1980, 1980 ACM SIGMOD INT; KUNG SY, 1982, IEEE T COMPUT, V31; LEISERSON CE, 1979, JAN CALTECH C VLSI; LIU KY, 1982, IEEE INT C PARALLEL; Mead C, 1980, INTRO VLSI SYSTEMS; MEGDAL BB, 1980, CALTECH3937 DISPL FI; MUNTEANU C, 1981, PATTERN RECOGN, V13, P167, DOI 10.1016/0031-3203(81)90014-5; NAGEL RN, 1972, P IEEE, P242; ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104; ROSENFELD A, 1980, 5TH P INT C PATT REC, P802; SCHWARTZ M, 1975, SIGNAL PROCESSING; SONG SW, 1981, THESIS CARNEGIEMELLO; VANDERBRUG GJ, 1977, IEEE T COMPUT, V26, P384, DOI 10.1109/TC.1977.1674847; WONG RY, 1978, IEEE T AERO ELEC SYS, V14, P128, DOI 10.1109/TAES.1978.308586; WONG RY, 1978, COMPUT VISION GRAPH, V8, P16, DOI 10.1016/S0146-664X(78)80028-8; WONG RY, 1978, IEEE T COMPUT, V27, P359, DOI 10.1109/TC.1978.1675108	37	9	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					306	319		10.1109/TPAMI.1985.4767659	http://dx.doi.org/10.1109/TPAMI.1985.4767659			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869265				2022-12-18	WOS:A1985AFM4400005
J	CHIN, RT; YEH, CL; OLSON, WS				CHIN, RT; YEH, CL; OLSON, WS			RESTORATION OF MULTICHANNEL MICROWAVE RADIOMETRIC IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV WISCONSIN,DEPT METEOROL,MADISON,WI 53706	University of Wisconsin System; University of Wisconsin Madison	CHIN, RT (corresponding author), UNIV WISCONSIN,DEPT ELECT & COMP ENGN,MADISON,WI 53706, USA.		Chin, Roland Tai Hong/E-9856-2010					Andrews H.C., 1977, DIGITAL IMAGE RESTOR; CADZOW JA, 1979, IEEE T ACOUST SPEECH, V27, P4, DOI 10.1109/TASSP.1979.1163187; CAHANA D, 1981, APPL OPTICS, V20, P2780, DOI 10.1364/AO.20.002780; FIENUP JR, 1978, OPT LETT, V3, P27, DOI 10.1364/OL.3.000027; GERCHBERG RW, 1974, OPT ACTA, V21, P709, DOI 10.1080/713818946; HAYES MH, 1980, IEEE T ACOUST SPEECH, V28, P672, DOI 10.1109/TASSP.1980.1163463; MAEDA J, 1982, APPL OPTICS, V21, P2199, DOI 10.1364/AO.21.002199; OLSON WS, 1983, 5TH C ATM RAD BALT; OLSON WS, 1985, THESIS U WISCONSIN M; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; PAPOULIS A, 1975, IEEE T CIRCUITS SYST, V22, P735, DOI 10.1109/TCS.1975.1084118; RUSHFORTH CK, 1980, J OPT SOC AM, V70, P1539, DOI 10.1364/JOSA.70.001539; SABRI MS, 1978, IEEE T CIRCUITS SYST, V25, P74, DOI 10.1109/TCS.1978.1084442; SCHAFER RW, 1981, P IEEE, V69, P432, DOI 10.1109/PROC.1981.11987; SMITH WL, 1976, J ATMOS SCI, V33, P1127, DOI 10.1175/1520-0469(1976)033<1127:TUOEOS>2.0.CO;2; STARK H, 1981, J OPT SOC AM, V71, P635, DOI 10.1364/JOSA.71.000635; WILHEIT TT, 1977, J APPL METEOROL, V16, P551, DOI 10.1175/1520-0450(1977)016<0551:ASTFQM>2.0.CO;2; WILHEIT TT, 1979, NASA80278 TECH MEM; YOULA DC, 1978, IEEE T CIRCUITS SYST, V25, P694, DOI 10.1109/TCS.1978.1084541	19	9	9	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					475	484		10.1109/TPAMI.1985.4767686	http://dx.doi.org/10.1109/TPAMI.1985.4767686			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69	21869285	Green Submitted			2022-12-18	WOS:A1985ALB6900011
J	MATWIN, S; PIETRZYKOWSKI, T				MATWIN, S; PIETRZYKOWSKI, T			INTELLIGENT BACKTRACKING IN PLAN-BASED DEDUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									TECH UNIV NOVA SCOTIA,SCH COMP SCI,HALIFAX B3J 2X4,NS,CANADA	Dalhousie University	MATWIN, S (corresponding author), UNIV OTTAWA,DEPT COMP SCI,OTTAWA K1N 9B4,ONTARIO,CANADA.			Matwin, Stan/0000-0001-6629-8434				ANDREWS PB, 1981, J ACM, V28, P193, DOI 10.1145/322248.322249; [Anonymous], SYMBOLIC LOGIC MECHA; BAXTER LD, 1976, CS7613 U WAT DEP COM; Bibel W., 1982, AUTOMATED THEOREM PR; BRUYNOOGHE M, 1981, INFORM PROCESS LETT, V12, P36, DOI 10.1016/0020-0190(81)90074-0; BRUYNOOGHE M, 1982, COMMUNICATION; BRUYNOOGHE M, 1981, 881 U NOV LISB CTR I; BRUYNOOGHE M, 1978, C MATH LOGIC PROGRAM; CHANG CL, 1979, ARTIF INTELL, V12, P159, DOI 10.1016/0004-3702(79)90015-8; CLOCKSIN W, 1982, PROGRAMMING PROLOG; COX PT, 1981, IEEE T PATTERN ANAL, V3, P52, DOI 10.1109/TPAMI.1981.4767050; COX PT, 1979, 4TH P WORKSH AUT DED; COX PT, 1977, THESIS U WATERLOO WA; FOSTER DR, 1980, THESIS U WATERLOO WA; KOWALSKI R, 1975, J ACM, V22, P572, DOI 10.1145/321906.321919; MATWIN S, 1982, LECTURE NOTES COMPUT, V138; MATWIN S, 1982, TR8208 U OTT DEP COM; PEREIRA LM, 1979, INTELLIGENT BACKTRAC; PEREIRA LM, 1977, USERS GUIDE DEC SYST; PEREIRA LM, 1980, LECTURE NOTES COMPUT, V81; PIETRZYKOWSKI T, 1982, LECTURE NOTES COMPUT, V138; PIETRZYKOWSKI T, UNPUB LINEAR COMPLEX; ROBERTS G, 1980, WATERLOO PROLOG USER; ROUSSEL P, 1976, PROLOG MANUEL REFERE; SICKEL S, 1976, IEEE T COMPUT, V25, P823, DOI 10.1109/TC.1976.1674701; WARREN DHD, 1976, IMPLEMENTING PROLOG; [No title captured]; [No title captured]	28	9	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					682	692		10.1109/TPAMI.1985.4767724	http://dx.doi.org/10.1109/TPAMI.1985.4767724			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869306				2022-12-18	WOS:A1985ATG0500006
J	OGORMAN, L; SANDERSON, AC				OGORMAN, L; SANDERSON, AC			THE WEDGE FILTER TECHNIQUE FOR CONVEX BOUNDARY ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									CARNEGIE MELLON UNIV,INST ROBOT,PITTSBURGH,PA 15213; CARNEGIE MELLON UNIV,DEPT ELECT & COMP ENGN,PITTSBURGH,PA 15213	Carnegie Mellon University; Carnegie Mellon University								ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; Ballard D.H., 1982, COMPUTER VISION; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BALLARD DH, 1976, IEEE T COMPUT, V25, P503, DOI 10.1109/TC.1976.1674638; BROWN CM, 1983, IEEE T PATTERN ANAL, V5, P493, DOI 10.1109/TPAMI.1983.4767428; COOPER DB, 1980, IMAGE MODELING, P63; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Eberlein R.B., 1976, COMPUT GRAPHICS IMAG, V5, P245, DOI [10.1016/0146-664X(76)90032-0, DOI 10.1016/0146-664X(76)90032-0]; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; GALLAGHER NC, 1981, IEEE T ACOUST SPEECH, V29, P1136, DOI 10.1109/TASSP.1981.1163708; GRITTON CWK, 1983, IEEE T PATTERN ANAL, V5, P8, DOI 10.1109/TPAMI.1983.4767339; KIMME C, 1975, COMMUN ACM, V18, P120, DOI 10.1145/360666.360677; LESTER JM, 1978, COMPUT BIOL MED, V8, P293, DOI 10.1016/0010-4825(78)90030-6; MILGRAM DL, 1978, ADA057191; MINOR LG, 1981, IEEE T SYST MAN CYB, V11, P194, DOI 10.1109/TSMC.1981.4308652; OGORMAN L, 1984, IEEE T PATTERN ANAL, V6, P280, DOI 10.1109/TPAMI.1984.4767520; OGORMAN L, 1983, COMPUT VISION PATTER, P89; OGORMAN L, 1983, THESIS CARNEGIEMELLO; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PERKINS WA, 1980, IEEE T PATTERN ANAL, V2, P8, DOI 10.1109/TPAMI.1980.4766965; Pratt W. K., 1978, DIGITAL IMAGE PROCES; ROSENFELD A, 1979, P IEEE, V67, P764, DOI 10.1109/PROC.1979.11326; SANDERSON AC, 1976, BIOL CYBERN, V22, P61, DOI 10.1007/BF00320131; SANKAR PV, 1982, IEEE T PATTERN ANAL, V4, P326, DOI 10.1109/TPAMI.1982.4767253; SKLANSKY J, 1978, IEEE T COMPUT, V27, P923, DOI 10.1109/TC.1978.1674971; TUKEY JW, 1974 C REC EASCON, P673	27	9	9	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					326	332		10.1109/TPAMI.1985.4767661	http://dx.doi.org/10.1109/TPAMI.1985.4767661			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869267				2022-12-18	WOS:A1985AFM4400007
J	PRADE, H				PRADE, H			CORRECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Correction, Addition																		PRADE H, 1985, IEEE T PATTERN ANAL, V7, P260, DOI 10.1109/TPAMI.1985.4767656	1	9	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					747	747		10.1109/TPAMI.1985.4767736	http://dx.doi.org/10.1109/TPAMI.1985.4767736			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05					2022-12-18	WOS:A1985ATG0500018
J	WOODS, JW; BIEMOND, J				WOODS, JW; BIEMOND, J			A MODEL FOR RADAR IMAGES AND ITS APPLICATION TO ADAPTIVE DIGITAL FILTERING OF MULTIPLICATIVE NOISE - COMMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									DELFT UNIV TECHNOL,DEPT ELECT ENGN,INFORMAT THEORY GRP,DELFT,NETHERLANDS	Delft University of Technology	WOODS, JW (corresponding author), RENSSELAER POLYTECH INST,DEPT ELECT ENGN,DEPT ELECT COMP & SYST ENGN,TROY,NY 12181, USA.							FALCONER DG, 1970, OPT ACTA, V17, P693, DOI 10.1080/713818360; Franks L., 1969, SIGNAL THEORY; FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223; KONDO K, 1977, APPL OPTICS, V16, P2554, DOI 10.1364/AO.16.002554; NADERI F, 1978, APPL OPTICS, V17, P2883, DOI 10.1364/AO.17.002883; WALKUP JF, 1974, OPTICAL ENG, V13, P250	6	9	9	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					658	659		10.1109/TPAMI.1984.4767582	http://dx.doi.org/10.1109/TPAMI.1984.4767582			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813					2022-12-18	WOS:A1984TM81300015
J	BENBASSAT, M; CAMPBELL, DB; MACNEIL, AR; WEIL, MH				BENBASSAT, M; CAMPBELL, DB; MACNEIL, AR; WEIL, MH			EVALUATING MULTIMEMBERSHIP CLASSIFIERS - A METHODOLOGY AND APPLICATION TO THE MEDAS DIAGNOSTIC SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV SO CALIF,SCH MED,DIV CRIT CARE MED,LOS ANGELES,CA 90039; TEL AVIV UNIV,FAC MANAGEMENT,TEL AVIV,ISRAEL	University of Southern California; Tel Aviv University	BENBASSAT, M (corresponding author), UNIV SO CALIF,SCH MED,INST CRIT CARE MED,LOS ANGELES,CA 90039, USA.							BENBASSAT M, 1980, IEEE T PATTERN ANAL, V2, P148, DOI 10.1109/TPAMI.1980.4766992; BENBASSAT M, 1980, IEEE T SYST MAN CYB, V10, P331; de Dombal F T, 1979, Surg Annu, V11, P33; DEDOMBAL FT, 1972, BMJ-BRIT MED J, V2, P9, DOI 10.1136/bmj.2.5804.9; KULIKOWSKI CA, 1980, IEEE T PATTERN ANAL, V2, P464, DOI 10.1109/TPAMI.1980.6592368; SHORTLIFFE EH, 1979, P IEEE, V67, P1207, DOI 10.1109/PROC.1979.11436	6	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					225	229		10.1109/TPAMI.1983.4767377	http://dx.doi.org/10.1109/TPAMI.1983.4767377			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974	21869106				2022-12-18	WOS:A1983QJ97400014
J	FEIVESON, AH				FEIVESON, AH			CLASSIFICATION BY THRESHOLDING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											FEIVESON, AH (corresponding author), NASA,LYNDON B JOHNSON SPACE CTR,HOUSTON,TX 77058, USA.							Abadie J.M., 1967, NONLINEAR PROGRAMMIN; Anderson T.W, 1958, INTRO MULTIVARIATE S; GRAYBILL W, 1961, INTRO LINEAR STATIST; HALLUM CR, 1972, 640TR114 LOCKH EL CO; Mangasarian L., 1969, NONLINEAR PROGRAMMIN; 1970, REMOTE MULTISPECTRAL, V4	6	9	9	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					48	54		10.1109/TPAMI.1983.4767343	http://dx.doi.org/10.1109/TPAMI.1983.4767343			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PZ844	21869082				2022-12-18	WOS:A1983PZ84400006
J	FINKEL, RA; FISHBURN, JP				FINKEL, RA; FISHBURN, JP			IMPROVED SPEEDUP BOUNDS FOR PARALLEL ALPHA-BETA SEARCH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									BELL TEL LABS INC,MURRAY HILL,NJ 07974	AT&T; Nokia Corporation; Nokia Bell Labs	FINKEL, RA (corresponding author), UNIV WISCONSIN,DEPT COMP SCI,MADISON,WI 53706, USA.							AKL SG, 1982, IEEE T PATTERN ANAL, V4, P192, DOI 10.1109/TPAMI.1982.4767226; FINKEL RA, UNPUB ARTIFICIAL INT; Hansen PB, 1973, OPERATING SYSTEM PRI; KNUTH DE, UNPUB ARTIFICIAL INT; Slate D. J., 1977, Chess skill in man and machine, P82	5	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					89	92		10.1109/TPAMI.1983.4767350	http://dx.doi.org/10.1109/TPAMI.1983.4767350			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PZ844	21869089				2022-12-18	WOS:A1983PZ84400013
J	GROSKY, WI; JAIN, R				GROSKY, WI; JAIN, R			OPTIMAL QUADTREES FOR IMAGE SEGMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											GROSKY, WI (corresponding author), WAYNE STATE UNIV,DEPT COMP SCI,INTELLIGENT SYST LAB,DETROIT,MI 48202, USA.							ALEXANDRIDIS N, 1978, COMPUT VISION GRAPH, V8, P43, DOI 10.1016/S0146-664X(78)80030-6; [Anonymous], [No title captured]; DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838; DYER CR, 1979, TR769 U MAR COMP SCI; GROSKY WI, 1982, CSC82007 WAYN STAT U; GROSKY WI, 1980, CSC81010 WAYN STAT U; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; HUNTER GM, 1979, COMPUT VISION GRAPH, V10, P289, DOI 10.1016/0146-664X(79)90008-X; HUNTER GM, 1978, THESIS PRINCETON U P; KLINGER A, 1979, IEEE T PATTERN ANAL, V1, P50, DOI 10.1109/TPAMI.1979.4766875; Klinger A., 1973, 1st International Joint Conference on Pattern Recognition, P497; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; Knuth D. E., 1975, ART COMPUTER PROGRAM; RANADE S, 1979, TR847 U MAR COMP SCI; SAMET H, 1980, COMPUT VISION GRAPH, V13, P88, DOI 10.1016/0146-664X(80)90118-5; SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836; SAMET H, 1979, TR755 U MAR COMP SCI; SAMET H, 1979, TR756 U MAR COMP SCI; SAMET H, 1979, TR766 U MAR COMP SCI; SAMET H, 1979, TR780 U MAR COMP SCI; SAMET H, 1979, TR768 U MAR COMP SCI; SAMET H, 1979, TR803 U MAR COMP SCI; SHNEIER M, 1979, TR794 U MAR COMP SCI; SHNEIER M, 1979, TR770 U MAR COMP SCI	24	9	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					77	83		10.1109/TPAMI.1983.4767348	http://dx.doi.org/10.1109/TPAMI.1983.4767348			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PZ844	21869087				2022-12-18	WOS:A1983PZ84400011
J	HSU, YS; PRUM, S; KAGEL, JH; ANDREWS, HC				HSU, YS; PRUM, S; KAGEL, JH; ANDREWS, HC			PATTERN-RECOGNITION EXPERIMENTS IN THE MANDALA COSINE DOMAIN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									MCDONNELL DOUGLAS CORP,NEWPORT BEACH,CA 92660; COMTAL CORP,PASADENA,CA		HSU, YS (corresponding author), HUGHES AIRCRAFT CO,RADAR SYST GRP,LOS ANGELES,CA 90009, USA.							AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784; Andrews H. C., 1972, INTRO MATH TECHNIQUE; ANDREWS HC, 1971, IEEE T COMPUT, VC 20, P1045, DOI 10.1109/T-C.1971.223400; Fu K. S., 1968, SEQUENTIAL METHODS P, V240, P241; KAJIYA JT, 1976, NOV P USNPGS S MATH, P67; RANDYS S, 1980, IEEE T PATTERN ANAL, V2, P242; ROESE JA, 1977, IEEE T COMMUN, V25	7	9	13	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					512	520		10.1109/TPAMI.1983.4767430	http://dx.doi.org/10.1109/TPAMI.1983.4767430			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RM118	21869136				2022-12-18	WOS:A1983RM11800007
J	SCHATZKI, TF; GROSSMAN, A; YOUNG, R				SCHATZKI, TF; GROSSMAN, A; YOUNG, R			RECOGNITION OF AGRICULTURAL OBJECTS BY SHAPE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SCHATZKI, TF (corresponding author), US ARS,WESTERN REG RES CTR,BERKELEY,CA 94710, USA.							BEAUDET PR, 1978, 4TH P INT C PATT REC, P579; DUDA RO, 1973, PATTERN CLASSIFICATI, pCH8; HAGEN KS, 1981, CALIF AGR        MAR, P5; Haralick R. M., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P489; HARALICK RM, 1981, COMPUT VISION GRAPH, V15, P113, DOI 10.1016/0146-664X(81)90073-3; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; HUMMEL RA, 1979, COMPUT VISION GRAPH, V9, P40, DOI 10.1016/0146-664X(79)90081-9; JAIN AK, 1980, IEEE T PATTERN ANAL, V2, P232, DOI 10.1109/TPAMI.1980.4767010; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003	9	9	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					645	653		10.1109/TPAMI.1983.4767455	http://dx.doi.org/10.1109/TPAMI.1983.4767455			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869152				2022-12-18	WOS:A1983RV48800012
J	LIU, HH; FU, KS				LIU, HH; FU, KS			A SYNTACTIC APPROACH TO SEISMIC PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											LIU, HH (corresponding author), PURDUE UNIV,W LAFAYETTE,IN 47907, USA.							Aho A.V., 1972, THEORY PARSING TRANS; BIERMANN AW, 1972, IEEE T COMPUT C, V21; BOLT BA, 1976, NUCLEAR EXPLOSIONS E; CHEN CH, 1978, GEOEXPLORATION, V16; DAHLMAN O, 1977, MONITORING UNDERGROU; Duda R.O., 1973, J ROYAL STAT SOC SER; EHRICH RW, 1976, IEEE T COMPUT, V25, P725, DOI 10.1109/TC.1976.1674681; FU KS, 1976, DATA STRUCTURE COMPU; FU KS, 1975, IEEE T SYST MAN CYBE, V5; FU KS, 1977, IEEE T SYST MAN CYBE, V7; GIESE DA, 1979, IEEE T SYST MAN CYB, V9, P429, DOI 10.1109/TSMC.1979.4310255; HOROWITZ SL, 1975, COMMUN ACM, V18, P281, DOI 10.1145/360762.360810; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; MICLET L, 1980, IEEE T SYST MAN CYBE, V10; PAVLIDIS T, 1971, SOFTWARE ENGINEERING, V2, P203; SARNA CS, 1980, 5TH P INT C PATT REC; TJOSTHEIM D, 1975, GEOPHYS J ROY ASTR S, V43, P269, DOI 10.1111/j.1365-246X.1975.tb00635.x; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WAGNER RA, 1974, COMMUN ASS COMPUT MA, V17; [No title captured]	20	9	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					136	140		10.1109/TPAMI.1982.4767219	http://dx.doi.org/10.1109/TPAMI.1982.4767219			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869018				2022-12-18	WOS:A1982NE95700008
J	WAKAYAMA, T				WAKAYAMA, T			A CORE-LINE TRACING ALGORITHM BASED ON MAXIMAL SQUARE MOVING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											WAKAYAMA, T (corresponding author), YOKOSUKA ELECT COMMUN LAB,YAMATO RES SECT,12356 TAKE,YOKOSUKA,KANAGAWA,JAPAN.							ARCELLI C, 1981, IEEE T PATTERN ANAL, V3, P134, DOI 10.1109/TPAMI.1981.4767071; ARCELLI C, 1978, IEEE T SYST MAN CYB, V8, P139; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Blum H., 1964, MODELS PERCEPTION SP, P362; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V11, P123, DOI 10.1016/0146-664X(79)90062-5; CALABI L, 1968, AM MATH MON, V75, P335, DOI 10.2307/2313409; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DEUTSCH ES, 1972, COMMUN ACM, V15, P827, DOI 10.1145/361573.361583; FISCHLER MA, 1980, COMPUT VISION GRAPH, V13, P334, DOI 10.1016/0146-664X(80)90032-5; Hilditch C.J., 1969, MACH INTELL, P403; LEVI G, 1969, INFORM CONTR, V17, P403; MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486; PAVLIDIS T, 1980, COMPUT VISION GRAPH, V13, P142, DOI 10.1016/S0146-664X(80)80037-2; PAVLIDIS T, 1978, IEEE T SYST MAN CYB, V8, P66; PFALTZ JL, 1967, COMMUN ACM, V10, P119, DOI 10.1145/363067.363120; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1975, INFORM CONTROL, V29, P286, DOI 10.1016/S0019-9958(75)90448-9; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; ROSENFELD A, 1969, PICTURE PROCESSING C; TAMURA H, 1978, 4TH P INT JOINT C PA, P715; TORIWAKI J, 1979, IEEE T SYST MAN CYB, V9, P628, DOI 10.1109/TSMC.1979.4310092; TORIWAKI J, 1980, 5TH P INT JOINT C PA, P35	23	9	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					68	74		10.1109/TPAMI.1982.4767198	http://dx.doi.org/10.1109/TPAMI.1982.4767198			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21869006				2022-12-18	WOS:A1982MY53400012
J	COX, PT; PIETRZYKOWSKI, T				COX, PT; PIETRZYKOWSKI, T			DEDUCTION PLANS - A BASIS FOR INTELLIGENT BACKTRACKING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV WATERLOO,DEPT COMP SCI,WATERLOO N2L 3G1,ONTARIO,CANADA; ACADIA UNIV,SCH COMP SCI,WOLFVILLE B0P 1X0,NS,CANADA	University of Waterloo; Acadia University								ANDREWS PB, 1976, IEEE T COMPUT, V25, P801, DOI 10.1109/TC.1976.1674698; [Anonymous], SYMBOLIC LOGIC MECHA; BAXTER LD, 1976, CS7613 U WAT DEP COM; BAXTER LD, 1976, THESIS U WATERLOO; BOYER RS, 1972, MACHINE INTELLEGENCE, V7, P101; CHANG CL, 1977, RJ2117 IBM RES REP; COX PD, UNPUBLISHED; COX PT, 1979, 4TH P WORKSH AUT DED; COX PT, 1977, THESIS U WATERLOO; COX PT, 1979, CS7941 U WAT RES REP; HUET GP, 1972, 1117 CAS WEST RES U; KOWALSKI R, 1971, ARTIF INTELL, V2, P227, DOI 10.1016/0004-3702(71)90012-9; KOWALSKI RA, 1975, J ASS COMPUT MACH, V2, P572; LOVELAND DW, 1968, J ACM, V15, P236, DOI 10.1145/321450.321456; Loveland DW., 1978, AUTOMATED THEOREM PR; ROBINSON JA, 1965, J ACM, V12, P23, DOI 10.1145/321250.321253; SHOSTAK RE, 1976, ARTIF INTELL, V7, P51, DOI 10.1016/0004-3702(76)90021-7; SICKEL S, 1976, IEEE T COMPUT, V25, P823, DOI 10.1109/TC.1976.1674701; YATES RA, 1970, ARTIF INTELL, V1, P257, DOI 10.1016/0004-3702(70)90011-1; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	24	9	9	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					52	65		10.1109/TPAMI.1981.4767050	http://dx.doi.org/10.1109/TPAMI.1981.4767050			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LK116	21868918				2022-12-18	WOS:A1981LK11600006
J	MURAKAMI, K; AIBARA, T				MURAKAMI, K; AIBARA, T			CONSTRUCTION OF A DISTRIBUTED ASSOCIATIVE MEMORY ON THE BASIS OF BAYES DISCRIMINANT RULE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MURAKAMI, K (corresponding author), EHIME UNIV, DEPT ELECTR ENGN, MATSUYAMA, EHIME 790, JAPAN.							FUKUNAGA K, 1972, INTRO STATISTICAL PA; KOHONEN T, 1973, IEEE T COMPUT, VC 22, P701, DOI 10.1109/TC.1973.5009138; KOHONEN T, 1974, IEEE T COMPUT, VC 23, P444, DOI 10.1109/T-C.1974.223960; KOHONEN T, 1972, IEEE T COMPUT, VC 21, P353, DOI 10.1109/TC.1972.5008975; Kohonen T., 1978, ASSOCIATIVE MEMORY S; MURAKAMI K, 1978, BIOL CYBERN, V30, P95, DOI 10.1007/BF00337322; NAKANO K, 1972, IEEE T SYST MAN CYB, VSMC2, P380, DOI 10.1109/TSMC.1972.4309133; Nilsson N., 1965, LEARNING MACHINES; PAO YH, 1975, IEEE T SYST MAN CYB, V5, P620; PFAFFELHUBER E, 1975, BIOL CYBERN, V18, P217, DOI 10.1007/BF00326691; POGGIO T, 1975, BIOL CYBERN, V19, P201, DOI 10.1007/BF02281970; UESAKA Y, 1972, J I ELECTRICAL COMMU, V55, P323	12	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					210	214		10.1109/TPAMI.1981.4767083	http://dx.doi.org/10.1109/TPAMI.1981.4767083			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN968	21868940				2022-12-18	WOS:A1981MN96800015
J	WATANABE, S				WATANABE, S			PATTERN-RECOGNITION AS CONCEPTUAL MORPHOGENESIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV HAWAII,HONOLULU,HI 96822	University of Hawaii System								Bergson H., 1907, LEVOLUTION CREATRICE; FUJIWHARA S, 1923, JAP J ASTRON GEOPHYS, V5, P143; FUJIWHARA S, 1940, KUMO WO TSUKAMU HANA; FUJIWHARA S, 1923, J ROY MET SOC, V49, P89; GLANSDORFF P, 1971, THERMODYNAMICAL THEO; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; WATANABE S, 1960, IBM J RES DEV, V4, P208, DOI 10.1147/rd.42.0208; Watanabe S., 1976, 3rd International Joint Conference on Pattern Recognition, P176; WATANABE S, 1969, KNOWING GUESSING, P14; WATANABE S, 1975, IEEE T SYST MAN  MAY, P372; WATANABE S, 1974, 2ND P INT JOINT C PA, P413; WATANABE S, 1965, 4TH T PRAG C INF THE; WATANABE S, 1966, PROGR BIOCYBERNETICS, V3; WATANABE S, 1969, KNOWING GUESSING, P287; Watanabe S, 1978, COGNITION PATTERN; WATANABE S, 1978, 4TH P INT JOINT C PA; WATANABE S, 1962, IRE T INFORM THEORY, V8, P248; WIENER N, 1962, CYBERNETICS; [No title captured]	19	9	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	2					161	165		10.1109/TPAMI.1980.4766993	http://dx.doi.org/10.1109/TPAMI.1980.4766993			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JH803	21868886				2022-12-18	WOS:A1980JH80300007
J	BIRK, J; KELLEY, R; CHEN, N; WILSON, L				BIRK, J; KELLEY, R; CHEN, N; WILSON, L			IMAGE FEATURE EXTRACTION USING DIAMETER-LIMITED GRADIENT DIRECTION HISTOGRAMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BIRK, J (corresponding author), UNIV RHODE ISL,DEPT ELECT ENGN,KINGSTON,RI 02881, USA.							Baird M. L., 1976, 3rd International Joint Conference on Pattern Recognition, P3; DUDANI S, 1977, 1977 P IEEE COMP SOC, P366; HUECKEL MH, 1974, J ACM, V21, P350, DOI 10.1145/321812.321830; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; MCKEE JW, 1977, IEEE T COMPUT, V22, P790; MORI S, 1973, COMPUTER GRAPHICS IM, V2, P321; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; SHIRAI Y, 1975, 4TH P INT JOINT C AR, P674; YACHIDA M, 1977, IEEE T COMPUT, V26, P882, DOI 10.1109/TC.1977.1674936; YODA H, 1975, 4TH P INT JOINT C AR, P620	10	9	9	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					228	235		10.1109/TPAMI.1979.4766910	http://dx.doi.org/10.1109/TPAMI.1979.4766910			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA304	21868853				2022-12-18	WOS:A1979HA30400015
J	Liu, M; Wang, ZY; Ji, SW				Liu, Meng; Wang, Zhengyang; Ji, Shuiwang			Non-Local Graph Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sorting; Task analysis; Graph neural networks; Convolution; Aggregates; Nonhomogeneous media; Calibration; Graph neural networks; non-local aggregation; attention mechanism; disassortative graphs		Modern graph neural networks (GNNs) learn node embeddings through multilayer local aggregation and achieve great success in applications on assortative graphs. However, tasks on disassortative graphs usually require non-local aggregation. In addition, we find that local aggregation is even harmful for some disassortative graphs. In this work, we propose a simple yet effective non-local aggregation framework with an efficient attention-guided sorting for GNNs. Based on it, we develop various non-local GNNs. We perform thorough experiments to analyze disassortative graph datasets and evaluate our non-local GNNs. Experimental results demonstrate that our non-local GNNs significantly outperform previous state-of-the-art methods on seven benchmark datasets of disassortative graphs, in terms of both model performance and efficiency.	[Liu, Meng; Wang, Zhengyang; Ji, Shuiwang] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA; [Wang, Zhengyang] Amazon Com Serv LLC, Seattle, WA 98109 USA	Texas A&M University System; Texas A&M University College Station	Ji, SW (corresponding author), Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.	mengliu@tamu.edu; zhengyang.wang@tamu.edu; sji@tamu.edu			National Science Foundation [IIS-1908198, DBI-1922969]	National Science Foundation(National Science Foundation (NSF))	This work was supported in part by the National Science Foundation under Grants IIS-1908198 and DBI-1922969.	Adam Santoro, 2018, Arxiv, DOI arXiv:1806.01261; Alon U., 2021, P 9 INT C LEARN REPR; Bianchi FM, 2020, PR MACH LEARN RES, V119; Bo DY, 2021, AAAI CONF ARTIF INTE, V35, P3950; Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418; Chen DL, 2020, AAAI CONF ARTIF INTE, V34, P3438; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Defferrard M, 2016, ADV NEUR IN, V29; Errica Federico, 2019, P INF C LEARN REPR; Fey M., 2019, ICLR WORKSH REPR LEA; Gao HY, 2019, PR MACH LEARN RES, V97; Gao HY, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P741, DOI 10.1145/3292500.3330897; Gao HY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1416, DOI 10.1145/3219819.3219947; Gilmer J, 2017, PR MACH LEARN RES, V70; Hamilton WL, 2017, ADV NEUR IN, V30; Hu W., 2020, ADV NEURAL INFORM PR, V33, P22118; Jin W, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P148, DOI 10.1145/3437963.3441735; Kipf T. N., 2017, 5 INT C LEARN REPR; Knyazev B, 2019, ADV NEUR IN, V32; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee J, 2019, PR MACH LEARN RES, V97; Leskovec J, 2014, SNAP DATASETS STANFO; Li QM, 2018, AAAI CONF ARTIF INTE, P3538; Lim D., 2021, ARXIV; Ma Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P723, DOI 10.1145/3292500.3330982; Newman MEJ, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.208701; Nickel M, 2017, ADV NEUR IN, V30; Paszke A, 2019, ADV NEUR IN, V32; Pei H., 2020, PROC INT C LEARN REP; Ribeiro LFR, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P385, DOI 10.1145/3097983.3098061; Rozemberczki B, 2021, J COMPLEX NETW, V9, DOI 10.1093/comnet/cnab014; Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157; Si Zhang, 2018, Computational Data and Social Networks. 7th International Conference, CSoNet 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11280), P79, DOI 10.1007/978-3-030-04648-4_7; Tang J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P807; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vaswani A, 2017, ADV NEUR IN, V30; Velickovic P., 2018, P 6 INT C LEARN REPR; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang ZY, 2020, AAAI CONF ARTIF INTE, V34, P6315; Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386; Xu K., 2019, PROC INT C LEARN REP; Xu KYL, 2018, PR MACH LEARN RES, V80; Yanardag P, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1365, DOI 10.1145/2783258.2783417; Yang Z, 2016, P 2016 C N AM CHAPTE, P1480; Ying R, 2018, ADV NEUR IN, V31; Yuan H., 2020, PROC INT C LEARN REP; Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438; Zhang MH, 2018, ADV NEUR IN, V31; Zhang ZW, 2022, IEEE T KNOWL DATA EN, V34, P249, DOI 10.1109/TKDE.2020.2981333; Zhou J., 2020, OPEN, V1, DOI [10.1016/j.aiopen.2021.01.001, DOI 10.1016/J.AIOPEN.2021.01.001]; Zhu J., 2020, ADV NEURAL INFORM PR, P7793; Zhu J, 2021, AAAI CONF ARTIF INTE, V35, P11168	53	8	8	6	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					10270	10276		10.1109/TPAMI.2021.3134200	http://dx.doi.org/10.1109/TPAMI.2021.3134200			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34882549	Green Submitted			2022-12-18	WOS:000880661400122
J	Liang, J; Hu, DP; Wang, YB; He, R; Feng, JS				Liang, Jian; Hu, Dapeng; Wang, Yunbo; He, Ran; Feng, Jiashi			Source Data-Absent Unsupervised Domain Adaptation Through Hypothesis Transfer and Labeling Transfer	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Labeling; Adaptation models; Encoding; Image reconstruction; Feature extraction; Data models; Unsupervised domain adaptation; transfer learning; self-supervised learning; semi-supervised learning; model reuse		Unsupervised domain adaptation (UDA) aims to transfer knowledge from a related but different well-labeled source domain to a new unlabeled target domain. Most existing UDA methods require access to the source data, and thus are not applicable when the data are confidential and not shareable due to privacy concerns. This paper aims to tackle a realistic setting with only a classification model available trained over, instead of accessing to, the source data. To effectively utilize the source model for adaptation, we propose a novel approach called Source HypOthesis Transfer (SHOT), which learns the feature extraction module for the target domain by fitting the target data features to the frozen source classification module (representing classification hypothesis). Specifically, SHOT exploits both information maximization and self-supervised learning for the feature extraction module learning to ensure the target features are implicitly aligned with the features of unseen source data via the same hypothesis. Furthermore, we propose a new labeling transfer strategy, which separates the target data into two splits based on the confidence of predictions (labeling information), and then employ semi-supervised learning to improve the accuracy of less-confident predictions in the target domain. We denote labeling transfer as SHOT++ if the predictions are obtained by SHOT. Extensive experiments on both digit classification and object recognition tasks show that SHOT and SHOT++ achieve results surpassing or comparable to the state-of-the-arts, demonstrating the effectiveness of our approaches for various visual domain adaptation problems. Code will be available at https://github.com/tim-learn/SHOT-plus.	[Liang, Jian; He, Ran] Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit NLPR, Beijing 100190, Peoples R China; [Hu, Dapeng; Feng, Jiashi] Natl Univ Singapore NUS, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Wang, Yunbo] Peking Univ, Wangxuan Inst Comp Technol, Beijing 100871, Peoples R China	Peking University	Liang, J (corresponding author), Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit NLPR, Beijing 100190, Peoples R China.	liangjian92@gmail.com; dapeng.hu@u.nus.edu; wangyunbo09@gmail.com; rhe@nlpr.ia.ac.cn; elefjia@nus.edu.sg			 [AISG-100E-2019-035];  [MOE2017-T2-2-151];  [CRP20-2017-0006]	; ; 	The authors would like to thank the reviewers and the associate editor for their valuable comments. The authors also thank Quanhong Fu and Weihao Yu for their help to improve the technical writing aspect of this paper. This work was supported by AISG-100E-2019-035, MOE2017-T2-2-151, and CRP20-2017-0006.	[Anonymous], 2007, P 15 ACM INT C MULTI; Ben Usman, 2017, Arxiv, DOI arXiv:1710.06924; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Berthelot D, 2019, ADV NEUR IN, V32; Bousmalis K, 2016, ADV NEUR IN, V29; Busto PP, 2017, IEEE I CONF COMP VIS, P754, DOI 10.1109/ICCV.2017.88; Cao ZJ, 2019, PROC CVPR IEEE, P2980, DOI 10.1109/CVPR.2019.00310; Cao ZJ, 2018, PROC CVPR IEEE, P2724, DOI 10.1109/CVPR.2018.00288; Carlucci FM, 2019, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2019.00233; Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542; Caron M, 2019, IEEE I CONF COMP VIS, P2959, DOI 10.1109/ICCV.2019.00305; Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9; Chang WG, 2019, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2019.00753; Chen T, 2020, PR MACH LEARN RES, V119; Chen XY, 2019, PR MACH LEARN RES, V97; Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352; Chen Z., 2020, PROC IEEE C COMPUT V, p12 706; Chidlovskii B, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P451, DOI 10.1145/2939672.2939716; Cicek S, 2019, IEEE I CONF COMP VIS, P1416, DOI 10.1109/ICCV.2019.00150; Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921; Csurka G, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-58347-1_1; Cui SH, 2020, PROC CVPR IEEE, P3940, DOI 10.1109/CVPR42600.2020.00400; Danil Galeev, 2019, Arxiv, DOI arXiv:1910.03903; Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110; Deng ZJ, 2019, IEEE I CONF COMP VIS, P9943, DOI 10.1109/ICCV.2019.01004; Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36; Gidaris P., 2018, P INT C LEARN REPR I, V17; Glorot Xavier, 2011, P 28 INT C MACH LEAR, P513, DOI DOI 10.1177/1753193411430810; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gopalan R, 2014, IEEE T PATTERN ANAL, V36, P2288, DOI 10.1109/TPAMI.2013.249; Grandvalet Yves, 2004, NIPS, P529; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoffman J, 2018, PR MACH LEARN RES, V80; Hu WH, 2017, PR MACH LEARN RES, V70; Huang Z., 2020, ARXIV; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jian Liang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P123, DOI 10.1007/978-3-030-58621-8_8; Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393; Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975; Kang GL, 2019, PROC CVPR IEEE, P4888, DOI 10.1109/CVPR.2019.00503; Krause Andreas, 2010, ADV NEURAL INFORM PR, V23, P5; Kurmi VK, 2019, IEEE IJCNN; Kuzborskij Ilja, 2013, P 30 INT C MACH LEAR, P942; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053; Lee DH., 2013, ICML WORKSH CHALL RE; Lee S, 2019, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2019.00018; Li D., 2020, PROC EUR C COMPUT VI, P382; Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591; Li Rui, 2020, P IEEE CVF C COMP VI, P9641, DOI 10.1109/CVPR42600.2020.00966; Li S, 2021, IEEE T PATTERN ANAL, V43, P2329, DOI 10.1109/TPAMI.2020.2964173; Li WY, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P1808; Liang J., 2021, ARXIV; Liang J, 2019, PROC CVPR IEEE, P2970, DOI 10.1109/CVPR.2019.00309; Liang J, 2019, IEEE T PATTERN ANAL, V41, P1027, DOI 10.1109/TPAMI.2018.2832198; Liang Jian, 2020, ICML; Long MS, 2018, ADV NEUR IN, V31; Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Lu Zhihe, 2020, P IEEE CVF C COMP VI, P9111; Luyu Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P608, DOI 10.1007/978-3-030-58568-6_36; Mancini M, 2018, PROC CVPR IEEE, P3771, DOI 10.1109/CVPR.2018.00397; Muller R, 2019, ADV NEUR IN, V32; Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934; Peng ML, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2505; Peng X., 2020, PROC INT C LEARN REP; Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149; Qin C., 2021, PROC INT C SUSTAINAB, P576; Ren CX, 2021, IEEE T NEUR NET LEAR, V32, P1989, DOI 10.1109/TNNLS.2020.2995648; Rostamizadeh A., 2009, ADV NEURAL INFORM PR, P1041; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K., 2018, PROC INT C LEARN REP; Saito K, 2019, IEEE I CONF COMP VIS, P8049, DOI 10.1109/ICCV.2019.00814; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Saito K, 2017, PR MACH LEARN RES, V70; Saito Kuniaki, 2020, PROC ANN C NEURAL IN, V33, P2; Mishra S, 2021, Arxiv, DOI arXiv:2101.12727; Shi Y., 2012, P 29 INT C INT C MAC, P1275; Shin'ichi Satoh, 2020, Arxiv, DOI arXiv:1905.10048; Shu R., 2018, PROC INT C LEARN REP; Shuhao Cui, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12452, DOI 10.1109/CVPR42600.2020.01247; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Sugiyama M., 2008, NIPS, P1433; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Sun Yu, 2019, ARXIV; Toldo M, 2020, TECHNOLOGIES, V8, DOI 10.3390/technologies8020035; Tommasi T, 2010, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2010.5540064; Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Venkat N., 2020, PROC 34THADV C NEURA; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Wallace Bram, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P717, DOI 10.1007/978-3-030-58574-7_43; Wang XM, 2019, ADV NEUR IN, V32; Xie SA, 2018, PR MACH LEARN RES, V80; Xu JL, 2019, IEEE ACCESS, V7, P156694, DOI 10.1109/ACCESS.2019.2949697; Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151; Xu RJ, 2018, PROC CVPR IEEE, P3964, DOI 10.1109/CVPR.2018.00417; Yosinski J, 2014, ADV NEUR IN, V27; You KC, 2019, PROC CVPR IEEE, P2715, DOI 10.1109/CVPR.2019.00283; Zadrozny  B., 2004, INT C MACH LEARN ICM, DOI 10.1145/1015330.1015425; Zellinger W., 2017, 5 INT C LEARN REPR I; Zhai XH, 2019, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2019.00156; Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40; Zhang WC, 2018, PROC CVPR IEEE, P3801, DOI 10.1109/CVPR.2018.00400; Zhang Y, 2020, IEEE T PATTERN ANAL, V42, P1823, DOI 10.1109/TPAMI.2019.2903401; Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223; Zhang YC, 2019, PR MACH LEARN RES, V97; Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI 10.1007/978-3-030-01219-9_	119	8	8	6	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					8602	8617		10.1109/TPAMI.2021.3103390	http://dx.doi.org/10.1109/TPAMI.2021.3103390			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34383644	Green Submitted			2022-12-18	WOS:000864325900092
J	Deng, JK; Guo, J; Yang, J; Xue, NN; Kotsia, I; Zafeiriou, S				Deng, Jiankang; Guo, Jia; Yang, Jing; Xue, Niannan; Kotsia, Irene; Zafeiriou, Stefanos			ArcFace: Additive Angular Margin Loss for Deep Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Large-scale face recognition; additive angular margin; noisy labels; sub-class; model inversion		Recently, a popular line of research in face recognition is adopting margins in the well-established softmax loss function to maximize class separability. In this paper, we first introduce an Additive Angular Margin Loss (ArcFace), which not only has a clear geometric interpretation but also significantly enhances the discriminative power. Since ArcFace is susceptible to the massive label noise, we further propose sub-center ArcFace, in which each class contains K sub-centers and training samples only need to be close to any of the K positive sub-centers. Sub-center ArcFace encourages one dominant sub-class that contains the majority of clean faces and non-dominant sub-classes that include hard or noisy faces. Based on this self-propelled isolation, we boost the performance through automatically purifying raw web faces under massive real-world noise. Besides discriminative feature embedding, we also explore the inverse problem, mapping feature vectors to face images. Without training any additional generator or discriminator, the pre-trained ArcFace model can generate identity-preserved face images for both subjects inside and outside the training data only by using the network gradient and Batch Normalization (BN) priors. Extensive experiments demonstrate that ArcFace can enhance the discriminative feature embedding as well as strengthen the generative face synthesis.	[Deng, Jiankang; Xue, Niannan; Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, London SW7 2BX, England; [Guo, Jia] InsightFace, London SW7 2AZ, England; [Yang, Jing] Univ Nottingham, Dept Comp Sci, Nottingham NG7 2RD, England; [Kotsia, Irene] Cogitat, London W10 5YU, England	Imperial College London; University of Nottingham	Deng, JK (corresponding author), Imperial Coll London, Dept Comp, London SW7 2BX, England.	j.deng16@imperial.ac.uk; guojia@gmail.com; y.jing2016@gmail.com; sparrowxue@hotmail.com; e.kotsia@imperial.ac.uk; s.zafeiriou@imperial.ac.uk			University of Nottingham; EPSRC Fellowship DEFORM: Large Scale Shape Analysis of Deformable Models of Humans [EP/S010203/1]; FACER2VM: Face Matching for Automatic Identity Retrieval, Recognition, Verification and Management [EP/N007743/1]; Google Faculty Award; Imperial President's PhD Scholarship	University of Nottingham; EPSRC Fellowship DEFORM: Large Scale Shape Analysis of Deformable Models of Humans(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); FACER2VM: Face Matching for Automatic Identity Retrieval, Recognition, Verification and Management; Google Faculty Award(Google Incorporated); Imperial President's PhD Scholarship	The authors would like to thank NVIDIA for the hardware donation and AmazonWeb Services for the cloud credits. The work of JiankangDengwas supportedby Imperial President's PhD Scholarship. The work of Jing Yangwas supported by the Vice-Chancellor's PhD Scholarship from University of Nottingham. The work of Stefanos Zafeiriou was supported in part by the EPSRC Fellowship DEFORM: Large Scale Shape Analysis of Deformable Models of Humans under Grant EP/S010203/1, in part by the FACER2VM: Face Matching for Automatic Identity Retrieval, Recognition, Verification and Management under Grant EP/N007743/1, and in part by the Google FacultyAward.	Abadi M., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467; Alan L. Yuille, 2017, Arxiv, DOI arXiv:1704.06369; Ali Arslan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P133, DOI 10.1007/978-3-030-58595-2_9; Anh Nguyen, 2015, Arxiv, DOI arXiv:1506.06579; Bao JM, 2018, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2018.00702; Bing Xu, 2015, Arxiv, DOI arXiv:1512.01274; Brock A., 2019, PROC INT C LEARN REP, P37; Cao D, 2020, PROC CVPR IEEE, P5670, DOI 10.1109/CVPR42600.2020.00571; Cao JJ, 2018, IEEE IMAGE PROC, P2406, DOI 10.1109/ICIP.2018.8451704; Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020; Carlos D. Castillo, 2017, Arxiv, DOI arXiv:1703.09507; Chang Huang, 2015, Arxiv, DOI arXiv:1506.07310; Chang J, 2020, PROC CVPR IEEE, P5709, DOI 10.1109/CVPR42600.2020.00575; Duong CN, 2020, PROC CVPR IEEE, P6131, DOI 10.1109/CVPR42600.2020.00617; Duong CN, 2019, INT J COMPUT VISION, V127, P437, DOI 10.1007/s11263-018-1113-3; Duong N, 2015, PROC CVPR IEEE, P4786, DOI 10.1109/CVPR.2015.7299111; Cole F, 2017, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2017.361; Del Bimbo A., 2019, IEEE C COMPUT VIS PA, P46; Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525; Deng JK, 2019, IEEE INT CONF COMP V, P2638, DOI 10.1109/ICCVW.2019.00322; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Deng JK, 2017, IEEE COMPUT SOC CONF, P2006, DOI 10.1109/CVPRW.2017.251; Deng W., 2018, 1801 BEIJ U POSTS TE, V5; Dong Yi, 2014, Arxiv, DOI arXiv:1411.7923; Dongyoon Han, 2017, Arxiv, DOI arXiv:1610.02915; Dosovitskiy A, 2016, PROC CVPR IEEE, P4829, DOI 10.1109/CVPR.2016.522; Du Heming, 2020, ECCV; Duan YQ, 2019, PROC CVPR IEEE, P3410, DOI 10.1109/CVPR.2019.00353; Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677; Geoffrey Hinton, 2015, Arxiv, DOI arXiv:1503.02531; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805; Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6; Haroush Matan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8491, DOI 10.1109/CVPR42600.2020.00852; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He Zhao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7718, DOI 10.1109/CVPR42600.2020.00774; Hensel M, 2017, ADV NEUR IN, V30; Hongxu Yin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8712, DOI 10.1109/CVPR42600.2020.00874; Hu W, 2019, PROC CVPR IEEE, P11879, DOI 10.1109/CVPR.2019.01216; Huang G.B., 2008, WORKSHOP FACESREAL L; Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jiani Hu, 2017, Arxiv, DOI arXiv:1708.08197; Jiankang Deng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P741, DOI 10.1007/978-3-030-58621-8_43; Kang BN, 2019, IEEE I CONF COMP VIS, P5471, DOI 10.1109/ICCV.2019.00557; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; Kim Y, 2020, PROC CVPR IEEE, P5620, DOI 10.1109/CVPR42600.2020.00566; Kingma D.P, P 3 INT C LEARNING R; Li LZ, 2020, PROC CVPR IEEE, P5073, DOI 10.1109/CVPR42600.2020.00512; Li XY, 2019, IEEE INT CONF COMP V, P2678, DOI 10.1109/ICCVW.2019.00327; Liu BY, 2019, IEEE I CONF COMP VIS, P10051, DOI 10.1109/ICCV.2019.01015; Liu H, 2019, PROC CVPR IEEE, P11939, DOI 10.1109/CVPR.2019.01222; Liu WY, 2018, ADV NEUR IN, V31; Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713; Liu WY, 2016, PR MACH LEARN RES, V48; Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155; Mai GC, 2019, IEEE T PATTERN ANAL, V41, P1188, DOI 10.1109/TPAMI.2018.2827389; Masi I, 2019, INT J COMPUT VISION, V127, P642, DOI 10.1007/s11263-019-01178-0; Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067; Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35; Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033; Mordvintsev A, 2015, INCEPTIONISM GOING D; Moritz Hardt, 2018, Arxiv, DOI arXiv:1611.04231; Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250; Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47; Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068; Parkhi Omkar M., 2015, BRIT MACH VIS C; Paszke A.., 2017, PROC INT C NEURAL IN, P34; Pereyra G., 2017, ARXIV PREPRINT ARXIV; Qian Q, 2019, IEEE I CONF COMP VIS, P6459, DOI 10.1109/ICCV.2019.00655; Qian Q, 2018, PROC CVPR IEEE, P8542, DOI 10.1109/CVPR.2018.00891; Rippel O., 2016, P INT C LEARN REPR, P780; Samek W., 2019, LNAI, V11700; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sengupta S, 2016, IEEE WINT CONF APPL; Shen YJ, 2018, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2018.00092; Shi YC, 2020, PROC CVPR IEEE, P6816, DOI 10.1109/CVPR42600.2020.00685; Shi YC, 2019, IEEE I CONF COMP VIS, P6901, DOI 10.1109/ICCV.2019.00700; Sohn K, 2016, ADV NEUR IN, V29; Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tan MX, 2019, PR MACH LEARN RES, V97; TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586; uller R. M_, 2020, ARXIV; Wan H, 2018, IEEE T PATTERN ANAL, V40, P409, DOI 10.1109/TPAMI.2017.2672557; Wang F, 2018, LECT NOTES COMPUT SC, V11213, P780, DOI 10.1007/978-3-030-01240-3_47; Wang H, 2019, PROC CVPR IEEE, P3522, DOI 10.1109/CVPR.2019.00364; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Wang Q., 2020, P IEEE CVF C COMP VI, P8326, DOI [DOI 10.1109/CVPR42600.2020.00835, 10.1109/CVPR42600.2020.00835]; Wang XB, 2020, AAAI CONF ARTIF INTE, V34, P12241; Wang XB, 2019, IEEE I CONF COMP VIS, P9357, DOI 10.1109/ICCV.2019.00945; Wang Xiaobo, 2020, INT C MACH LEARN, P10029; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; Xie W.., 2018, PROC BRIT MACH VIS C, P1332; Xie WD, 2018, LECT NOTES COMPUT SC, V11215, P811, DOI 10.1007/978-3-030-01252-6_48; Yaohui Cai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13166, DOI 10.1109/CVPR42600.2020.01318; Yin X, 2019, PROC CVPR IEEE, P5697, DOI 10.1109/CVPR.2019.00585; Yonghyun Kim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P536, DOI 10.1007/978-3-030-58545-7_31; Zhang Q., 2019, ARXIV; Zhang X, 2019, PROC CVPR IEEE, P10815, DOI 10.1109/CVPR.2019.01108; Zhang X, 2017, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2017.578; Zhang X, 2019, PROC CVPR IEEE, P9898, DOI 10.1109/CVPR.2019.01014; Zhang Yan, 2020, IEEE C COMP VIS PATT; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhao J, 2019, AAAI CONF ARTIF INTE, P9251; Zhao K, 2019, PROC CVPR IEEE, P1136, DOI 10.1109/CVPR.2019.00123; Zhong YY, 2019, PROC CVPR IEEE, P7804, DOI 10.1109/CVPR.2019.00800; Zhu M.., 2004, P IEEE C COMP VIS PA, P97; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	121	8	8	32	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					5962	5979		10.1109/TPAMI.2021.3087709	http://dx.doi.org/10.1109/TPAMI.2021.3087709			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34106845	Green Submitted			2022-12-18	WOS:000853875300012
J	Jang, TJ; Kim, KC; Cho, HC; Seo, JK				Jang, Tae Jun; Kim, Kang Cheol; Cho, Hyun Cheol; Seo, Jin Keun			A Fully Automated Method for 3D Individual Tooth Identification and Segmentation in Dental CBCT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Teeth; Three-dimensional displays; Image segmentation; Dentistry; Computed tomography; Image reconstruction; Bones; Cone-beam computerized tomography; digital dentistry; tooth segmentation; tooth identification; deep learning	CLASSIFICATION; IMAGES; TEETH	Accurate and automatic segmentation of three-dimensional (3D) individual teeth from cone-beam computerized tomography (CBCT) images is a challenging problem because of the difficulty in separating an individual tooth from adjacent teeth and its surrounding alveolar bone. Thus, this paper proposes a fully automated method of identifying and segmenting 3D individual teeth from dental CBCT images. The proposed method addresses the aforementioned difficulty by developing a deep learning-based hierarchical multi-step model. First, it automatically generates upper and lower jaws panoramic images to overcome the computational complexity caused by high-dimensional data and the curse of dimensionality associated with limited training dataset. The obtained 2D panoramic images are then used to identify 2D individual teeth and capture loose- and tight- regions of interest (ROIs) of 3D individual teeth. Finally, accurate 3D individual tooth segmentation is achieved using both loose and tight ROIs. Experimental results showed that the proposed method achieved an F1-score of 93.35 percent for tooth identification and a Dice similarity coefficient of 94.79 percent for individual 3D tooth segmentation. The results demonstrate that the proposed method provides an effective clinical and practical framework for digital dentistry.	[Jang, Tae Jun; Kim, Kang Cheol; Cho, Hyun Cheol; Seo, Jin Keun] Yonsei Univ, Sch Math & Comp Computat Sci & Engn, Seoul 03722, South Korea	Yonsei University	Kim, KC (corresponding author), Yonsei Univ, Sch Math & Comp Computat Sci & Engn, Seoul 03722, South Korea.	taejunjang@yonsei.ac.kr; kangcheol@yonsei.ac.kr; whguscjf55@yonsei.ac.kr; seoj@yonsei.ac.kr	Jang, Tae Jun/GSM-9145-2022	Jang, Tae Jun/0000-0001-9582-0463	Korea Health Industry Development Institute through Korea Health Technology RD Project; Ministry of Health & Welfare, Republic of Korea [HI20C0127]	Korea Health Industry Development Institute through Korea Health Technology RD Project; Ministry of Health & Welfare, Republic of Korea(Ministry of Health & Welfare (MOHW), Republic of Korea)	The authors would like to thank HDXWILL, which shares dental CBCT images and ground-truth data. This work was supported in part by the Korea Health Industry Development Institute through Korea Health Technology R&D Project and in part by the Ministry of Health & Welfare, Republic of Korea under Grant HI20C0127.	Biguri A, 2016, BIOMED PHYS ENG EXPR, V2, DOI 10.1088/2057-1976/2/5/055010; Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511; Cui ZM, 2019, PROC CVPR IEEE, P6361, DOI 10.1109/CVPR.2019.00653; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gan YZ, 2015, MED PHYS, V42, P14, DOI 10.1118/1.4901521; Gao H, 2010, PATTERN RECOGN, V43, P2406, DOI 10.1016/j.patcog.2010.01.010; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; He K., 2017, IEEE INT C COMP VIS, P2961; Kingma D.P, P 3 INT C LEARNING R; Lee S, 2020, IEEE ACCESS, V8, P50507, DOI 10.1109/ACCESS.2020.2975826; LEE TC, 1994, CVGIP-GRAPH MODEL IM, V56, P462, DOI 10.1006/cgip.1994.1042; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Long J., 2015, P IEEE C COMPUTER VI, P3431, DOI DOI 10.1109/CVPR.2015.7298965; Miki Y, 2017, COMPUT BIOL MED, V80, P24, DOI 10.1016/j.compbiomed.2016.11.003; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Paszke A, 2019, ADV NEUR IN, V32; Rao YB, 2020, IEEE ACCESS, V8, P92028, DOI 10.1109/ACCESS.2020.2994592; Raudaschl PF, 2017, MED PHYS, V44, P2020, DOI 10.1002/mp.12197; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ronneberger O., 2015, P MEDICAL IMAGE COMP, P234; SAMET H, 1988, IEEE T PATTERN ANAL, V10, P579, DOI 10.1109/34.3918; Tian SK, 2019, IEEE ACCESS, V7, P84817, DOI 10.1109/ACCESS.2019.2924262; Tuzoff DV, 2019, DENTOMAXILLOFAC RAD, V48, DOI 10.1259/dmfr.20180051; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Xu XJ, 2019, IEEE T VIS COMPUT GR, V25, P2336, DOI 10.1109/TVCG.2018.2839685; Yau HT, 2014, COMPUT BIOL MED, V48, P8, DOI 10.1016/j.compbiomed.2014.02.001	28	8	8	21	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6562	6568		10.1109/TPAMI.2021.3086072	http://dx.doi.org/10.1109/TPAMI.2021.3086072			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34077356	Bronze, Green Submitted			2022-12-18	WOS:000853875300050
J	Georgescu, MI; Ionescu, RT; Khan, FS; Popescu, M; Shah, M				Georgescu, Mariana Iuliana; Ionescu, Radu Tudor; Khan, Fahad Shahbaz; Popescu, Marius; Shah, Mubarak			A Background-Agnostic Framework With Adversarial Training for Abnormal Event Detection in Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Event detection; Image reconstruction; Anomaly detection; Feature extraction; Public transportation; Detectors; Abnormal event detection; anomaly detection; auto-encoders; adversarial training; security and surveillance	ANOMALY DETECTION; LOCALIZATION	Abnormal event detection in video is a complex computer vision problem that has attracted significant attention in recent years. The complexity of the task arises from the commonly-adopted definition of an abnormal event, that is, a rarely occurring event that typically depends on the surrounding context. Following the standard formulation of abnormal event detection as outlier detection, we propose a background-agnostic framework that learns from training videos containing only normal events. Our framework is composed of an object detector, a set of appearance and motion auto-encoders, and a set of classifiers. Since our framework only looks at object detections, it can be applied to different scenes, provided that normal events are defined identically across scenes and that the single main factor of variation is the background. This makes our method background agnostic, as we rely strictly on objects that can cause anomalies, and not on the background. To overcome the lack of abnormal data during training, we propose an adversarial learning strategy for the auto-encoders. We create a scene-agnostic set of out-of-domain pseudo-abnormal examples, which are correctly reconstructed by the auto-encoders before applying gradient ascent on the pseudo-abnormal examples. We further utilize the pseudo-abnormal examples to serve as abnormal examples when training appearance-based and motion-based binary classifiers to discriminate between normal and abnormal latent features and reconstructions. Furthermore, to ensure that the auto-encoders focus only on the main object inside each bounding box image, we introduce a branch that learns to segment the main object. We compare our framework with the state-of-the-art methods on four benchmark data sets, using various evaluation metrics. Compared to existing methods, the empirical results indicate that our approach achieves favorable performance on all data sets. In addition, we provide region-based and track-based annotations for two large-scale abnormal event detection data sets from the literature, namely ShanghaiTech and Subway.	[Georgescu, Mariana Iuliana; Ionescu, Radu Tudor; Popescu, Marius] Univ Bucharest, SecurifAI, Bucharest 030018, Romania; [Georgescu, Mariana Iuliana; Ionescu, Radu Tudor; Popescu, Marius] Univ Bucharest, Dept Comp Sci, Bucharest 030018, Romania; [Khan, Fahad Shahbaz] Mohamed Bin Zayed Univ Artificial Intelligence MB, Abu Dhabi 44737, U Arab Emirates; [Shah, Mubarak] Univ Cent Florida, Ctr Res Comp Vis CRCV, Dept Comp Sci, Orlando, FL 32816 USA	University of Bucharest; University of Bucharest; Mohamed Bin Zayed University of Artificial Intelligence; State University System of Florida; University of Central Florida	Ionescu, RT (corresponding author), Univ Bucharest, SecurifAI, Bucharest 030018, Romania.; Ionescu, RT (corresponding author), Univ Bucharest, Dept Comp Sci, Bucharest 030018, Romania.	georgescu_lily@yahoo.com; raducu.ionescu@gmail.com; fahad.khan@liu.se; popescunmarius@gmail.com; shah@crcv.ucf.edu	Khan, Fahad Shahbaz/ABD-6646-2021	Khan, Fahad Shahbaz/0000-0002-4263-3143; Shah, Mubarak/0000-0001-6172-5572	EEA [EEA-RO-NO-2018-0496, 2014-2021]; Romanian Young Academy; Stiftung Mercator; Alexander von Humboldt Foundation; VR [2016-05543];  [GR010]	EEA; Romanian Young Academy; Stiftung Mercator; Alexander von Humboldt Foundation(Alexander von Humboldt Foundation); VR(Swedish Research Council); 	This work was supported in part by the EEA through Project EEA-RO-NO-2018-0496 under Grant 2014-2021, in part by the Romanian Young Academy, which is funded by Stiftung Mercator and the Alexander von Humboldt Foundation for the period 2020-2022, in part by Starting Grant under Grant GR010, and in part by VR Starting Grant under Grant 2016-05543.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825; Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Antic B, 2011, IEEE I CONF COMP VIS, P2415, DOI 10.1109/ICCV.2011.6126525; Beggel L, 2020, LECT NOTES ARTIF INT, V11906, P206, DOI 10.1007/978-3-030-46150-8_13; Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524; Chen ZX, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1989, DOI 10.1145/3340531.3412070; Cheng KW, 2015, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2015.7298909; Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434; Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21; Dong F, 2020, IEEE ACCESS, V8, P88170, DOI 10.1109/ACCESS.2020.2993373; Doshi K, 2020, IEEE COMPUT SOC CONF, P1025, DOI 10.1109/CVPRW50498.2020.00135; Doshi Keval, 2020, P IEEE CVF C COMP VI, P934; Dutta JK, 2015, AAAI CONF ARTIF INTE, P3755; Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063; Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guang Yu, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P583, DOI 10.1145/3394171.3413973; Guansong Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12170, DOI 10.1109/CVPR42600.2020.01219; Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391; Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803; Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212; Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315; Ji XL, 2020, IEEE IJCNN; Kieu T, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2725; Kim J, 2009, PROC CVPR IEEE, P2913; Kim YG, 2020, PR MACH LEARN RES, V108, P2507; Kingma D.P, P 3 INT C LEARNING R; Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee S, 2020, IEEE T IMAGE PROCESS, V29, P2395, DOI 10.1109/TIP.2019.2948286; Lee S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1323; Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu PP, 2019, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2019.00470; Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684; Liu Yusha, 2018, P BMVC, V1, P8; Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338; Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45; Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872; McHardy R., 2019, P C N, P660; Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641; Nair V., 2010, ICML, P807; Nilsback M-E., 2006, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2006., DOI 10.1109/CVPR.2006.42]; Park H., 2020, PROC IEEE C COMPUT V, p14 372; Ramachandra B, 2022, IEEE T PATTERN ANAL, V44, P2293, DOI 10.1109/TPAMI.2020.3040591; Ramachandra B, 2020, IEEE WINT CONF APPL, P2558, DOI 10.1109/WACV45572.2020.9093457; Ramachandra B, 2020, IEEE WINT CONF APPL, P2587, DOI 10.1109/WACV45572.2020.9093417; Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188; Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577; Ren H M, 2015, P BRIT MACH VIS C; Ronneberger O., 2015, P INT C MED IM COMP; Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006; Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780; Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917; Smeureanu S, 2017, LECT NOTES COMPUT SC, V10485, P779, DOI 10.1007/978-3-319-68548-9_70; Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678; Sun Che, 2020, P 28 ACM INT C MULT; Sun QR, 2017, PATTERN RECOGN, V64, P187, DOI 10.1016/j.patcog.2016.09.016; Tang Y, 2020, PATTERN RECOGN LETT, V129, P123, DOI 10.1016/j.patrec.2019.11.024; Tran Hanh TM, 2017, P BRIT MACH VIS C 20; Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wu P, 2020, IEEE T NEUR NET LEAR, V31, P2609, DOI 10.1109/TNNLS.2019.2933554; Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882; Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010; Yiwei Lu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P125, DOI 10.1007/978-3-030-58558-7_8; Zaigham Zaheer Muhammad, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14171, DOI 10.1109/CVPR42600.2020.01419; Zhang XF, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107394; Zhang Y, 2016, PATTERN RECOGN, V59, P302, DOI 10.1016/j.patcog.2015.11.018; Zhou C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P665, DOI 10.1145/3097983.3098052; Ziming Wang, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P2463, DOI 10.1145/3394171.3413529	76	8	8	16	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4505	4523		10.1109/TPAMI.2021.3074805	http://dx.doi.org/10.1109/TPAMI.2021.3074805			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33881990	Green Submitted			2022-12-18	WOS:000836666600007
J	Yu, ZB; Zhang, ML				Yu, Ze-Bang; Zhang, Min-Ling			Multi-Label Classification With Label-Specific Feature Generation: A Wrapped Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Correlation; Task analysis; Wrapping; Training; Predictive models; Optimization; Analytical models; Multi-label classification; label-specific features; label correlation; wrapped procedure	SELECTION	Label-specific features serve as an effective strategy to learn from multi-label data, where a set of features encoding specific characteristics of each label are generated to help induce multi-label classification model. Existing approaches work by taking the two-stage strategy, where the procedure of label-specific feature generation is independent of the follow-up procedure of classification model induction. Intuitively, the performance of resulting classification model may be suboptimal due to the decoupling nature of the two-stage strategy. In this paper, a wrapped learning approach is proposed which aims to jointly perform label-specific feature generation and classification model induction. Specifically, one (kernelized) linear model is learned for each label where label-specific features are simultaneously generated within an embedded feature space via empirical loss minimization and pairwise label correlation regularization. Comparative studies over a total of sixteen benchmark data sets clearly validate the effectiveness of the wrapped strategy in exploiting label-specific features for multi-label classification.	[Yu, Ze-Bang; Zhang, Min-Ling] Southeast Univ, Sch Comp Sci & Engn, Nanjing 210096, Peoples R China; [Yu, Ze-Bang; Zhang, Min-Ling] Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing, Peoples R China	Southeast University - China; Southeast University - China	Zhang, ML (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Nanjing 210096, Peoples R China.; Zhang, ML (corresponding author), Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing, Peoples R China.	yuzb@seu.edu.cn; zhangml@seu.edu.cn			National Key R&D Program of China [2018YFB1004300]; National Science Foundation of China [61573104]; China University S&T Innovation Plan Guided by the Ministry of Education; Collaborative Innovation Center of Novel Software Technology and Industrialization	National Key R&D Program of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); China University S&T Innovation Plan Guided by the Ministry of Education; Collaborative Innovation Center of Novel Software Technology and Industrialization	The authors would like to thank the associate editor and anonymous reviewers for their insightful comments and suggestions. This work was supported by the National Key R&D Program of China (2018YFB1004300), the National Science Foundation of China (61573104), the China University S&T Innovation Plan Guided by the Ministry of Education, and in part by the Collaborative Innovation Center of Novel Software Technology and Industrialization. We thank the Big Data Center of Southeast University for providing the facility support on the numerical calculations in this paper.	Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Brinker C, 2014, IEEE DATA MINING, P731, DOI 10.1109/ICDM.2014.102; Canuto S, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P53, DOI 10.1145/2835776.2835821; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen C, 2019, AAAI CONF ARTIF INTE, P3304; Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532; Chen ZS., 2019, PROC 11 ASIAN C MACH, P411; Cheng ZW, 2020, APPL INTELL, V50, P4029, DOI 10.1007/s10489-020-01715-2; Demsar J, 2006, J MACH LEARN RES, V7, P1; Furnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8; Gibaja E, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2716262; Gouk Henry, 2016, PROC 8 ASIAN C MACH, P318; Guo YM, 2019, ACM T KNOWL DISCOV D, V13, DOI 10.1145/3319911; Huang J, 2018, IEEE T CYBERNETICS, V48, P876, DOI 10.1109/TCYB.2017.2663838; Huang J, 2016, IEEE T KNOWL DATA EN, V28, P3309, DOI 10.1109/TKDE.2016.2608339; Huang M, 2019, MACH LEARN, V108, P747, DOI 10.1007/s10994-019-05783-5; Jia BB, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2905-3; Jia XY, 2020, J COMPUT SCI TECH-CH, V35, P247, DOI 10.1007/s11390-020-9900-z; Li T, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2159, DOI 10.1145/3132847.3133084; Li YC, 2017, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2017.199; Liu WW, 2015, AAAI CONF ARTIF INTE, P2800; Ma JH, 2021, IEEE T CYBERNETICS, V51, P1028, DOI 10.1109/TCYB.2019.2932439; Ma YL, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-9062-8; Nam J, 2019, PR MACH LEARN RES, V97; Pereira RB, 2018, ARTIF INTELL REV, V49, P57, DOI 10.1007/s10462-016-9516-4; Peters J, 2017, ADAPT COMPUT MACH LE; Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5; Rubin TN, 2012, MACH LEARN, V88, P157, DOI 10.1007/s10994-011-5272-5; Sitompul OS., 2018, INT J ADV INTELL INF, V4, P21; Sun FM, 2014, IEEE T IMAGE PROCESS, V23, P1028, DOI 10.1109/TIP.2014.2298978; Sun L., 2013, MULTILABEL DIMENSION; Sun L, 2016, INT C PATT RECOG, P1612, DOI 10.1109/ICPR.2016.7899867; Sun YP, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-9294-7; Tsoumakas G, 2011, IEEE T KNOWL DATA EN, V23, P1079, DOI 10.1109/TKDE.2010.164; Wang X, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P464; Wang YB, 2020, SOFT COMPUT, V24, P6553, DOI 10.1007/s00500-020-04775-1; Weng W, 2020, NEUROCOMPUTING, V377, P85, DOI 10.1016/j.neucom.2019.10.016; Weng W, 2018, NEUROCOMPUTING, V273, P385, DOI 10.1016/j.neucom.2017.07.044; Wu B, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P117, DOI 10.1145/2647868.2654904; Wu X, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3884; Xing YY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2882; Xu JH, 2021, IEEE T MULTIMEDIA, V23, P1696, DOI 10.1109/TMM.2020.3002185; Xu M, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-3132-4; Xu SP, 2016, KNOWL-BASED SYST, V104, P52, DOI 10.1016/j.knosys.2016.04.012; Yang YM, 2012, MACH LEARN, V88, P47, DOI 10.1007/s10994-011-5270-7; Yeh CK, 2017, AAAI CONF ARTIF INTE, P2838; Zhang CQ, 2018, AAAI CONF ARTIF INTE, P4414; Zhang J, 2018, KNOWL-BASED SYST, V159, P148, DOI 10.1016/j.knosys.2018.07.003; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhang ML, 2018, FRONT COMPUT SCI-CHI, V12, P191, DOI 10.1007/s11704-017-7031-7; Zhang ML, 2015, IEEE T PATTERN ANAL, V37, P107, DOI 10.1109/TPAMI.2014.2339815; Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39	52	8	8	9	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5199	5210		10.1109/TPAMI.2021.3070215	http://dx.doi.org/10.1109/TPAMI.2021.3070215			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33788680				2022-12-18	WOS:000836666600052
J	Wang, YL; Huang, G; Song, SJ; Pan, XR; Xia, YT; Wu, C				Wang, Yulin; Huang, Gao; Song, Shiji; Pan, Xuran; Xia, Yitong; Wu, Cheng			Regularizing Deep Networks With Semantic Data Augmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Training; Task analysis; Upper bound; Training data; Data models; Supervised learning; Data augmentation; deep learning; semi-supervised learning		Data augmentation is widely known as a simple yet surprisingly effective technique for regularizing deep networks. Conventional data augmentation schemes, e.g., flipping, translation or rotation, are low-level, data-independent and class-agnostic operations, leading to limited diversity for augmented samples. To this end, we propose a novel semantic data augmentation algorithm to complement traditional approaches. The proposed method is inspired by the intriguing property that deep networks are effective in learning linearized features, i.e., certain directions in the deep feature space correspond to meaningful semantic transformations, e.g., changing the background or view angle of an object. Based on this observation, translating training samples along many such directions in the feature space can effectively augment the dataset for more diversity. To implement this idea, we first introduce a sampling based method to obtain semantically meaningful directions efficiently. Then, an upper bound of the expected cross-entropy (CE) loss on the augmented training set is derived by assuming the number of augmented samples goes to infinity, yielding a highly efficient algorithm. In fact, we show that the proposed implicit semantic data augmentation (ISDA) algorithm amounts to minimizing a novel robust CE loss, which adds minimal extra computational cost to a normal training procedure. In addition to supervised learning, ISDA can be applied to semi-supervised learning tasks under the consistency regularization framework, where ISDA amounts to minimizing the upper bound of the expected KL-divergence between the augmented features and the original features. Although being simple, ISDA consistently improves the generalization performance of popular deep models (e.g., ResNets and DenseNets) on a variety of datasets, i.e., CIFAR-10, CIFAR-100, SVHN, ImageNet, and Cityscapes. Code for reproducing our results is available at https://github.com/blackfeather-wang/ISDA-for-Deep-Networks.	[Wang, Yulin; Huang, Gao; Song, Shiji; Pan, Xuran; Wu, Cheng] Tsinghua Univ, Dept Automat, BNRist, Beijing 100084, Peoples R China; [Xia, Yitong] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China	Tsinghua University; Beihang University	Huang, G (corresponding author), Tsinghua Univ, Dept Automat, BNRist, Beijing 100084, Peoples R China.	wang-yl19@mails.tsinghua.edu.cn; gaohuang@tsinghua.edu.cn; shijis@tsinghua.edu.cn; pxr18@mails.tsinghua.edu.cn; xyt990614@buaa.edu.cn; wuc@tsinghua.edu.cn			Ministry of Science and Technology of China [2018AAA0101604]; National Natural Science Foundation of China [62022048, 61906106, 61936009]; Institute for Guo Qiang of Tsinghua University; Beijing Academy of Artificial Intelligence	Ministry of Science and Technology of China(Ministry of Science and Technology, China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Institute for Guo Qiang of Tsinghua University; Beijing Academy of Artificial Intelligence	This work was supported in part by the Ministry of Science and Technology of China under Grant 2018AAA0101604, the National Natural Science Foundation of China under Grants 62022048, 61906106, and 61936009, the Institute for Guo Qiang of Tsinghua University and Beijing Academy of Artificial Intelligence. Yulin Wang and Gao Huang contributed equally to this work.	Antoniou Antreas, 2017, ARXIV171104340; Arjovsky M, 2017, PR MACH LEARN RES, V70; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bengio Yoshua, 2013, INT C MACHINE LEARNI, P552; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Bowles C, 2018, ARXIV181010863; Brock AM, 2018, PROCEEDINGS PERVASIVE DISPLAYS 2018: THE 7TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, DOI 10.1145/3205873.3205877; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chen X, 2016, ADV NEUR IN, V29; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359; Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Gal Y., 2015, ARXIV; Gal Y, 2016, PR MACH LEARN RES, V48; Gastaldi X, 2017, ARXIV 170507485; Goodfellow I.J., 2014, ABS13126082; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300; He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2022, IEEE T PATTERN ANAL, V44, P8704, DOI 10.1109/TPAMI.2019.2918284; Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069; Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z; Kendall A., 2017, WHAT UNCERTAINTIES W, V3, P4; Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781; Kingma D.P, P 3 INT C LEARNING R; Kingma DP, 2014, ADV NEUR IN, V27; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Laine S., 2017, P INT C LEARN REPR; Li M., 2016, ARXIV PREPRINT ARXIV; Liang XZ, 2017, LECT NOTES COMPUT SC, V10635, P413, DOI 10.1007/978-3-319-70096-0_43; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Liu WY, 2016, PR MACH LEARN RES, V48; Loshchilov I., 2017, P INT C LEARNING REP; Luo YC, 2018, PROC CVPR IEEE, P8896, DOI 10.1109/CVPR.2018.00927; Maaten L., 2013, P 30 INT C MACH LEAR, P410; Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155; Mirza M., 2014, ARXIV; Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821; Muller R, 2019, ADV NEUR IN, V32; Odena A, 2017, PR MACH LEARN RES, V70; Rasmus A., 2015, ADV NEURAL INFORM PR, P3546, DOI DOI 10.1186/1477-5956-9-S1-S5; Ratner AJ, 2017, ADV NEUR IN, V30; Ren S., 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.169; Shi YC, 2019, IEEE I CONF COMP VIS, P6901, DOI 10.1109/ICCV.2019.00700; Simonyan K., 2015, ICLR; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Srivastava RK, 2015, ADV NEUR IN, V28; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Tarvainen A, 2017, ADV NEUR IN, V30; Upchurch P, 2017, PROC CVPR IEEE, P6090, DOI 10.1109/CVPR.2017.645; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Verma V, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3635; Wang XB, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P992; Wang Y., 2019, PROC INT C NEURAL IN, P12614; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Xie LX, 2016, PROC CVPR IEEE, P4753, DOI 10.1109/CVPR.2016.514; Xie Q., 2019, ARXIV 190412848; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Yin X, 2019, PROC CVPR IEEE, P5697, DOI 10.1109/CVPR.2019.00585; Yu TY, 2019, IEEE I CONF COMP VIS, P552, DOI 10.1109/ICCV.2019.00064; Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612; Zagoruyko S, 2016, P BRIT MACH VIS C BM, DOI [10.5244/C.30.87, DOI 10.5244/C.30.87]; Zhang ZL, 2018, ADV NEUR IN, V31; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhong Z., 2017, ARXIV 170804896; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	71	8	8	15	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3733	3748		10.1109/TPAMI.2021.3052951	http://dx.doi.org/10.1109/TPAMI.2021.3052951			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33476265	Green Submitted			2022-12-18	WOS:000805820500029
J	Nie, FP; Xue, JJ; Wu, DY; Wang, R; Li, H; Li, XL				Nie, Feiping; Xue, Jingjing; Wu, Danyang; Wang, Rong; Li, Hui; Li, Xuelong			Coordinate Descent Method for k-means	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Coordinate descent method; k-means method; clustering; Lloyd heuristic	DIMENSIONALITY REDUCTION; ALGORITHM	k-means method using Lloyd heuristic is a traditional clustering method which has played a key role in multiple downstream tasks of machine learning because of its simplicity. However, Lloyd heuristic always finds a bad local minimum, i.e., the bad local minimum makes objective function value not small enough, which limits the performance of k-means. In this paper, we use coordinate descent (CD) method to solve the problem. First, we show that the k-means minimization problem can be reformulated as a trace maximization problem, then a simple and efficient coordinate descent scheme is proposed to solve the maximization problem. Two interesting findings through theory are that Lloyd cannot decrease the objective function value of k-means produced by our CD further, and our proposed method CD to solve k-means problem can avoid produce empty clusters. In addition, according to the computational complexity analysis, it is verified CD has the same time complexity with original k-means method. Extensive experiments including statistical hypothesis testing, on several real-world datasets with varying number of clusters, varying number of samples and varying number of dimensions show that CD performs better compared to Lloyd, i.e., lower objective value, better local minimum and fewer iterations. And CD is more robust to initialization than Lloyd whether the initialization strategy is random or initialization of k-means++.	[Nie, Feiping; Xue, Jingjing; Wu, Danyang; Li, Hui; Li, Xuelong] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China; [Nie, Feiping; Xue, Jingjing; Wu, Danyang; Wang, Rong; Li, Hui; Li, Xuelong] Northwestern Polytech Univ, Sch Artificial Intelligence Opt & Elect iOPEN, Xian 710072, Shaanxi, Peoples R China; [Wang, Rong] Northwestern Polytech Univ, Sch Cybersecur, Xian 710072, Shaanxi, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University	Nie, FP (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Nie, FP (corresponding author), Northwestern Polytech Univ, Sch Artificial Intelligence Opt & Elect iOPEN, Xian 710072, Shaanxi, Peoples R China.	feipingnie@gmail.com; jingjing_xue@mail.nwpu.edu.cn; danyangwu41x@mail.nwpu.edu.cn; wangrong07@tsinghua.org.cn; lihuihui235@gmail.com; li@nwpu.edu.cn	Wu, Danyang/GZH-0208-2022	Xue, Jingjing/0000-0002-6845-424X	National Key Research and Development Program of China [2018AAA0101902]; Natural Science Basic Research Program of Shaanxi [2021JM-071]; National Natural Science Foundation of China [61936014, 61772427]; Fundamental Research Funds for Central Universities [G2019KY0501]	National Key Research and Development Program of China; Natural Science Basic Research Program of Shaanxi; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0101902, in part by the Natural Science Basic Research Program of Shaanxi (Program No. 2021JM-071), in part by the National Natural Science Foundation of China under Grants 61936014 and 61772427, and in part by the Fundamental Research Funds for Central Universities under Grant G2019KY0501.	[Anonymous], 2018, P INT C MACH LEARN; Bachem O, 2016, AAAI CONF ARTIF INTE, P1459; Bahmani B, 2012, PROC VLDB ENDOW, V5, P622, DOI 10.14778/2180912.2180915; Boutsidis C., 2010, ADV NEURAL INFORM PR, V23, P298; Boutsidis C, 2015, IEEE T INFORM THEORY, V61, P1045, DOI 10.1109/TIT.2014.2375327; Bradley P. S., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P91; Cohen MB, 2015, ACM S THEORY COMPUT, P163, DOI 10.1145/2746539.2746569; Dasgupta S, 2008, CS20080916; David H., 2002, PHYS REV LETT, V88; Ding C, 2005, SIAM PROC S, P606; Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277; Ding YF, 2015, PR MACH LEARN RES, V37, P579; Drake J., 2012, P 5 NIPS WORKSH OPT, V8; Elkan C., 2003, P 20 INT C MACHINE L, V20, P147, DOI DOI 10.1016/0026-2714(92)90278-S; Erisoglu M, 2011, PATTERN RECOGN LETT, V32, P1701, DOI 10.1016/j.patrec.2011.07.011; Feldman D, 2013, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS (SODA 2013), P1434; Feldman D, 2011, ACM S THEORY COMPUT, P569; Gentile C, 2014, PR MACH LEARN RES, V32, P757; Hamerly G, 2010, P 2010 SIAM INT C DA, V2010, P130, DOI DOI 10.1137/1.9781611972801.12; Har-Peled S, 2007, DISCRETE COMPUT GEOM, V37, P3, DOI 10.1007/s00454-006-1271-x; Har-Peled Sariel, 2004, P ACM S THEOR COMP, P291; Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830; Hu ZX, 2020, INFORM FUSION, V55, P251, DOI 10.1016/j.inffus.2019.09.005; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Kim S, 2014, IEEE T PATTERN ANAL, V36, P1761, DOI 10.1109/TPAMI.2014.2303095; Korda N, 2016, PR MACH LEARN RES, V48; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; Kreyszig E., 1970, INTRO MATH STAT PRIN; Li Lihong, 2010, P 19 INT C WORLD WID, P661, DOI DOI 10.1145/1772690.1772758; Li S., 2016, THESIS U DEGLI STUDI; Li S, 2019, ARXIV190209162; Li S, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P539, DOI 10.1145/2911451.2911548; Liu WW, 2017, ADV NEUR IN, V30; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Mahadik K., 2020, P 34 ACM INT C SUP, P1; Mahajan D. K., 2012, P 21 ACM INT C INF K, P6, DOI DOI 10.1145/2396761.2396767; Newling J., 2016, ADV NEURAL INFORM PR, V29, P1352; Newling J, 2016, PR MACH LEARN RES, V48; Ng AY, 2002, ADV NEUR IN, V14, P849; NGUYEN TT, 2014, P 23 ACM INT C C INF, P1959, DOI DOI 10.1145/2661829.2662063; Nie F., 2016, P INT JOINT C ART IN, P1874; Nie FP, 2020, IEEE T NEUR NET LEAR, V31, P3428, DOI 10.1109/TNNLS.2019.2944565; Pelleg D., 2000, P 17 INT C MACH LEAR, DOI DOI 10.1038/S41598-021-86770-6; Pelleg D., 1999, PROC 5 ACM SIGKDD IN, P277, DOI [10.1145/312129.312248, DOI 10.1145/312129.312248]; Pena JM, 1999, PATTERN RECOGN LETT, V20, P1027, DOI 10.1016/S0167-8655(99)00069-0; Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302; Shen XB, 2017, AAAI CONF ARTIF INTE, P2527; Sieranoja S, 2018, LECT NOTES ARTIF INT, V10841, P680, DOI 10.1007/978-3-319-91253-0_63; Wright SJ, 2015, MATH PROGRAM, V151, P3, DOI 10.1007/s10107-015-0892-3; Wu WB, 2017, IEEE INTERNET THINGS, V4, P979, DOI 10.1109/JIOT.2017.2677578; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Yang XJ, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3035677; Zhang MJ, 2019, IEEE T NEUR NET LEAR, V30, P3109, DOI 10.1109/TNNLS.2018.2890017; Zhang MJ, 2019, IEEE T IMAGE PROCESS, V28, P642, DOI 10.1109/TIP.2018.2869688; Zhang MJ, 2018, IEEE T CYBERNETICS, V48, P904, DOI 10.1109/TCYB.2017.2664499; Zhao F, 2019, IEEE T FUZZY SYST, V27, P387, DOI 10.1109/TFUZZ.2018.2852289; Zhu W, 2017, INT CONF ACOUST SPEE, P2492, DOI 10.1109/ICASSP.2017.7952605	58	8	8	6	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2371	2385		10.1109/TPAMI.2021.3085739	http://dx.doi.org/10.1109/TPAMI.2021.3085739			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	34061737				2022-12-18	WOS:000792921400013
J	Zhang, C; Li, HX; Chen, CL; Qian, YH; Zhou, XZ				Zhang, Chao; Li, Huaxiong; Chen, Chunlin; Qian, Yuhua; Zhou, Xianzhong			Enhanced Group Sparse Regularized Nonconvex Regression for Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Low-rank structure; sparse representation; enhanced group sparsity; nonconvex relaxation; face recognition	ROBUST; ILLUMINATION; REPRESENTATION; ALGORITHMS	Regression analysis based methods have shown strong robustness and achieved great success in face recognition. In these methods, convex l(1)-norm and nuclear norm are usually utilized to approximate the l(0)-norm and rank function. However, such convex relaxations may introduce a bias and lead to a suboptimal solution. In this paper, we propose a novel Enhanced Group Sparse regularized Nonconvex Regression (EGSNR) method for robust face recognition. An upper bounded nonconvex function is introduced to replace l(1)-norm for sparsity, which alleviates the bias problem and adverse effects caused by outliers. To capture the characteristics of complex errors, we propose a mixed model by combining gamma-norm and matrix gamma-norm induced from the nonconvex function. Furthermore, an l(2,gamma)-norm based regularizer is designed to directly seek the interclass sparsity or group sparsity instead of traditional l(2,1)-norm. The locality of data, i.e., the distance between the query sample and multi-subspaces, is also taken into consideration. This enhanced group sparse regularizer enables EGSNR to learn more discriminative representation coefficients. Comprehensive experiments on several popular face datasets demonstrate that the proposed EGSNR outperforms the state-of-the-art regression based methods for robust face recognition.	[Zhang, Chao; Li, Huaxiong; Chen, Chunlin; Zhou, Xianzhong] Nanjing Univ, Dept Control & Syst Engn, Nanjing 210093, Peoples R China; [Qian, Yuhua] Shanxi Univ, Inst Big Data Sci & Ind, Taiyuan 030006, Peoples R China; [Qian, Yuhua] Minist Educ, Key Lab Computat Intelligence & Chinese Informat, Taiyuan 030006, Peoples R China	Nanjing University; Shanxi University	Li, HX (corresponding author), Nanjing Univ, Dept Control & Syst Engn, Nanjing 210093, Peoples R China.	chzhang@smail.nju.edu.cn; huaxiongli@nju.edu.cn; clchen@nju.edu.cn; jinchengqyh@126.com; zhouxz@nju.edu.cn		Zhang, Chao/0000-0002-5929-0853	National Key Research and Development Program of China [2018YFB1402600, 2016YFD0702100]; National Natural Science Foundation of China [61672332, 62073160, 61876079, 71671086]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors would like to thank the editor and anonymous reviewers for their constructive and valuable comments and suggestions. This work was partially supported by the National Key Research and Development Program of China (Nos. 2018YFB1402600, 2016YFD0702100), and the National Natural Science Foundation of China (Nos. 61672332, 62073160, 61876079, 71671086).	Asif MS, 2014, IEEE T SIGNAL PROCES, V62, P4209, DOI 10.1109/TSP.2014.2328981; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Cai SJ, 2016, PROC CVPR IEEE, P2950, DOI 10.1109/CVPR.2016.322; Chen CH, 2016, MATH PROGRAM, V155, P57, DOI 10.1007/s10107-014-0826-5; Chen JH, 2015, IEEE T NEUR NET LEAR, V26, P2291, DOI 10.1109/TNNLS.2014.2377477; Dehua Liu, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P210, DOI 10.1007/978-3-642-40991-2_14; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Deng WH, 2018, IEEE T PATTERN ANAL, V40, P2513, DOI 10.1109/TPAMI.2017.2757923; Dong JY, 2019, PROC CVPR IEEE, P11889, DOI 10.1109/CVPR.2019.01217; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Ghazi MM, 2016, IEEE COMPUT SOC CONF, P102, DOI 10.1109/CVPRW.2016.20; Gong Pinghua, 2013, JMLR Workshop Conf Proc, V28, P37; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714; Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271; Huang Gary B., 2007, 0749 U MASS, P7; Huang J., 2013, P 27 AAAI, P438; Iliadis M, 2017, IEEE T IMAGE PROCESS, V26, P2203, DOI 10.1109/TIP.2017.2675206; Jiang XD, 2015, IEEE T PATTERN ANAL, V37, P1067, DOI 10.1109/TPAMI.2014.2359453; Jing LP, 2014, IEEE T IMAGE PROCESS, V23, P1002, DOI 10.1109/TIP.2013.2294546; Ke JC, 2022, IEEE T CYBERNETICS, V52, P164, DOI 10.1109/TCYB.2019.2953337; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lai J, 2016, IEEE T IMAGE PROCESS, V25, P3261, DOI 10.1109/TIP.2016.2545249; Li FJ, 2019, ARTIF INTELL, V273, P37, DOI 10.1016/j.artint.2018.12.007; Li HX, 2016, KNOWL-BASED SYST, V91, P241, DOI 10.1016/j.knosys.2015.07.040; Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217; Liu Y, 2017, AAAI CONF ARTIF INTE, P2294; Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003; Lu CY, 2015, AAAI CONF ARTIF INTE, P1805; Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P829, DOI 10.1109/TIP.2015.2511584; Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70; Luo L, 2015, PATTERN RECOGN, V48, P3811, DOI 10.1016/j.patcog.2015.06.012; Martinez A., 1998, AR FACE DATABASE; Naseem I, 2012, PATTERN RECOGN, V45, P104, DOI 10.1016/j.patcog.2011.07.003; Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128; Nie F., 2012, PROC 26 AAAI C ARTIF, P655; Nie FP, 2019, IEEE T IMAGE PROCESS, V28, P2378, DOI 10.1109/TIP.2018.2886712; Qian JJ, 2015, PATTERN RECOGN, V48, P3145, DOI 10.1016/j.patcog.2015.04.017; Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sun YB, 2014, IEEE T IMAGE PROCESS, V23, P3816, DOI 10.1109/TIP.2014.2331760; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wang S., 2013, IJCAI, P1764; Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu CY, 2018, PATTERN RECOGN, V80, P256, DOI 10.1016/j.patcog.2018.03.016; Xie JC, 2017, IEEE T IMAGE PROCESS, V26, P2286, DOI 10.1109/TIP.2017.2662213; Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290; Xu J, 2018, LECT NOTES COMPUT SC, V11212, P21, DOI 10.1007/978-3-030-01237-3_2; Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218; Yang JF, 2011, SIAM J SCI COMPUT, V33, P250, DOI 10.1137/090777761; Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849; Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729; Zhang HM, 2017, INFORM SCIENCES, V394, P1, DOI 10.1016/j.ins.2017.02.020; Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277; Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255; Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359; Zheng JW, 2019, IEEE T NEUR NET LEAR, V30, P3788, DOI 10.1109/TNNLS.2019.2899073; Zheng JW, 2017, IEEE T IMAGE PROCESS, V26, P2408, DOI 10.1109/TIP.2017.2681841	62	8	8	13	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2438	2452		10.1109/TPAMI.2020.3033994	http://dx.doi.org/10.1109/TPAMI.2020.3033994			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33108280				2022-12-18	WOS:000792921400018
J	Xu, M; Jiang, L; Li, C; Wang, ZL; Tao, XM				Xu, Mai; Jiang, Lai; Li, Chen; Wang, Zulin; Tao, Xiaoming			Viewport-Based CNN: A Multi-Task Approach for Assessing 360 degrees Video Quality	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual quality assessment; 360 degrees video; viewport; CNN	SALIENCY PREDICTION	For 360 degrees video, the existing visual quality assessment (VQA) approaches are designed based on either the whole frames or the cropped patches, ignoring the fact that subjects can only access viewports. When watching 360 degrees video, subjects select viewports through head movement (HM) and then fixate on attractive regions within the viewports through eye movement (EM). Therefore, this paper proposes a two-staged multi-task approach for viewport-based VQA on 360 degrees video. Specifically, we first establish a large-scale VQA dataset of 360 degrees video, called VQA-ODV, which collects the subjective quality scores and the HM and EM data on 600 video sequences. By mining our dataset, we find that the subjective quality of 360 degrees video is related to camera motion, viewport positions and saliency within viewports. Accordingly, we propose a viewport-based convolutional neural network (V-CNN) approach for VQA on 360 degrees video, which has a novel multi-task architecture composed of a viewport proposal network (VP-net) and viewport quality network (VQ-net). The VP-net handles the auxiliary tasks of camera motion detection and viewport proposal, while the VQ-net accomplishes the auxiliary task of viewport saliency prediction and the main task of VQA. The experiments validate that our V-CNN approach significantly advances state-of-the-art VQA performance on 360 degrees video and it is also effective in the three auxiliary tasks.	[Xu, Mai; Jiang, Lai; Li, Chen; Wang, Zulin] Beihang Univ, Sch Elect & Informat Engn, Beijing 100191, Peoples R China; [Jiang, Lai] Univ British Columbia, Vancouver, BC V6T 1Z4, Canada; [Tao, Xiaoming] Tsinghua Univ, Beijing 100084, Peoples R China	Beihang University; University of British Columbia; Tsinghua University	Tao, XM (corresponding author), Tsinghua Univ, Beijing 100084, Peoples R China.	MaiXu@buaa.edu.cn; jianglai.china@buaa.edu.cn; jnlichen123@buaa.edu.cn; wzulin@buaa.edu.cn; taoxm@mail.tsinghua.edu.cn			Beijing Natural Science Foundation [JQ20020]; NSFC [61876013, 61922009, 61573037]	Beijing Natural Science Foundation(Beijing Natural Science Foundation); NSFC(National Natural Science Foundation of China (NSFC))	This work was supported by Beijing Natural Science Foundation under Grant JQ20020, and the NSFC projects 61876013, 61922009, and 61573037. Mai Xu and Lai Jiang contributed equally to this work.	7invensun, VR EYE TRACK ACC DRO; [Anonymous], 2016, IEEE18579 1 BEIJING; Assens M, 2017, IEEE INT CONF COMP V, P2331, DOI 10.1109/ICCVW.2017.275; Bo Zhang, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P163, DOI 10.1109/ICMEW.2017.8026226; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518; Boyce J., 2016, JOINT VID EXPL TEAM; BT RECOMMENDATION ITU-R, 2002, METH SUBJ ASS QUAL T; Chao FY, 2018, IEEE INT CONF MULTI; Cheng HT, 2018, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2018.00154; Choi B., 2017, 230902 ISOIEC; Cohen T. S., 2018, P INT C LEARN REPR; Corbillon X, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P199, DOI 10.1145/3083187.3083215; David EJ, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P432, DOI 10.1145/3204949.3208139; Davies A, 2016, EXPECT YOU; der Auwera G. V., 2016, JOINT VID EXPL TEAM; Dostal P, 2012, INT CARN CONF SECU, P367, DOI 10.1109/CCST.2012.6393587; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gitman Y, 2014, IEEE IMAGE PROC, P1105, DOI 10.1109/ICIP.2014.7025220; Guo CL, 2008, PROC CVPR IEEE, P2908; Hanhart P, 2018, PICT COD SYMP, P328; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300; Healy DM, 2003, J FOURIER ANAL APPL, V9, P341, DOI 10.1007/s00041-003-0018-9; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jeoong Sung Park, 2012, 2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA 2012). Proceedings, P996, DOI 10.1109/ICIEA.2012.6360868; Jiang HX, 2019, IEEE T CIRC SYST VID, V29, P1163, DOI 10.1109/TCSVT.2018.2826074; Jiang L, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107234; Jiang L, 2018, LECT NOTES COMPUT SC, V11218, P625, DOI 10.1007/978-3-030-01264-9_37; Kammachi-Sreedhar K, 2016, IEEE INT SYM MULTIM, P583, DOI [10.1109/ISM.2016.143, 10.1109/ISM.2016.0126]; Kells L. M., 1940, PLANE SPHERICAL TRIG; Kim J, 2017, PROC CVPR IEEE, P1969, DOI 10.1109/CVPR.2017.213; Kim W, 2018, LECT NOTES COMPUT SC, V11205, P224, DOI 10.1007/978-3-030-01246-5_14; Kuzyakov E., 2016, NEXT GENERATION VIDE; Lebreton P, 2018, SIGNAL PROCESS-IMAGE, V69, P69, DOI 10.1016/j.image.2018.03.006; Li B., 2016, P IEEE INT C UB MED, P258; Li C, 2019, PROC CVPR IEEE, P10169, DOI 10.1109/CVPR.2019.01042; Li C, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P932, DOI 10.1145/3240508.3240581; Li F, 2017, ASIAPAC SIGN INFO PR, P506; Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878; Lim HT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6737; Liotta A., 2013, P INT C ADV MOB COMP, DOI DOI 10.1145/2536853.2536903; Lopes F, 2018, PROC SPIE, V10752, DOI 10.1117/12.2321679; Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045; Maas A. L., 2013, P 30 INT C MACH LEAR, P3; Ng KT, 2005, IEEE T CIRC SYST VID, V15, P82, DOI 10.1109/TCSVT.2004.839989; Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205; Rahman F. D. A., 2017, P IEEE 4 INT C SMART, P1; Rai Y, 2017, INT WORK QUAL MULTIM; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111; Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599; Snyder J. P., 1987, US GEOLOGICAL SURVEY, V1532; Stutz T, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P247; Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693; Tao XM, 2015, CHINA COMMUN, V12, P22, DOI 10.1109/CC.2015.7275256; Tran HTT, 2017, INT CONF UBIQ FUTUR, P7; Upenik Evgeniy, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P73, DOI 10.1109/ICMEW.2017.8026231; van der Veen SM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173632; Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wu CL, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P193, DOI 10.1145/3083187.3083210; Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1; Xiu XY, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP); Xu M, 2019, IEEE T CIRC SYST VID, V29, P3516, DOI 10.1109/TCSVT.2018.2886277; Xu M, 2019, IEEE T PATTERN ANAL, V41, P2693, DOI 10.1109/TPAMI.2018.2858783; Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351; Xu M, 2017, IEEE T IMAGE PROCESS, V26, P369, DOI 10.1109/TIP.2016.2628583; Xu YY, 2018, PROC CVPR IEEE, P5333, DOI 10.1109/CVPR.2018.00559; Yang SY, 2017, PROC INT CONF EDU IN, P1, DOI 10.1109/EITT.2017.9; Ye Y., 2017, JOINT VID EXPL TEAM, V16; Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12; Zakharchenko V., 2016, P SPIE OPT PHOT INF; Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844; Zhang YX, 2018, IEEE T BROADCAST, V64, P461, DOI 10.1109/TBC.2018.2811627; Zhou ML, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107616	77	8	8	6	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2198	2215		10.1109/TPAMI.2020.3028509	http://dx.doi.org/10.1109/TPAMI.2020.3028509			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33017289				2022-12-18	WOS:000764815300039
J	Hong, RC; Liu, DQ; Mo, XY; He, XN; Zhang, HW				Hong, Richang; Liu, Daqing; Mo, Xiaoyu; He, Xiangnan; Zhang, Hanwang			Learning to Compose and Reason with Language Tree Structures for Visual Grounding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Grounding; Visualization; Dogs; Natural languages; Cognition; Computational modeling; Semantics; Fine-grained detection; tree structure; visual grounding; visual reasoning		Grounding natural language in images, such as localizing "the black dog on the left of the tree", is one of the core problems in artificial intelligence, as it needs to comprehend the fine-grained language compositions. However, existing solutions merely rely on the association between the holistic language features and visual features, while neglect the nature of composite reasoning implied in the language. In this paper, we propose a natural language grounding model that can automatically compose a binary tree structure for parsing the language and then perform visual reasoning along the tree in a bottom-up fashion. We call our model RvG-Tree: Recursive Grounding Tree, which is inspired by the intuition that any language expression can be recursively decomposed into two constituent parts, and the grounding confidence score can be recursively accumulated by calculating their grounding scores returned by the two sub-trees. RvG-Tree can be trained end-to-end by using the Straight-Through Gumbel-Softmax estimator that allows the gradients from the continuous score functions passing through the discrete tree construction. Experiments on several benchmarks show that our model achieves the state-of-the-art performance with more explainable reasoning.	[Hong, Richang] Hefei Univ Technol, Sch Comp & Informat, Hefei 230011, Anhui, Peoples R China; [Liu, Daqing] Univ Sci & Technol China, Hefei 230022, Anhui, Peoples R China; [Mo, Xiaoyu] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [He, Xiangnan] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230022, Anhui, Peoples R China; [Zhang, Hanwang] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore	Hefei University of Technology; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Zhang, HW (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.	hongrc.hfut@gmail.com; liudq@mail.ustc.edu.cn; moxy@ntu.edu.sg; xiangnanhe@gmail.com; zhanghw.ntu@gmail.com		Liu, Daqing/0000-0002-8286-0105; Zhang, Hanwang/0000-0001-7374-8739	National Key Research and Development Program [2017YFB1002203]; National Natural Science Foundation of China [61722204, 61732007]; AlibabaNTU Singapore Joint Research Institute	National Key Research and Development Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); AlibabaNTU Singapore Joint Research Institute(Nanyang Technological University)	We thank the editors and the reviewers for their helpful suggestions. This work was supported by the National Key Research and Development Program under Grant 2017YFB1002203, the National Natural Science Foundation of China under Grant 61722204 and 61732007, and AlibabaNTU Singapore Joint Research Institute.	Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Bowman SR, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1466; Choi J, 2018, AAAI CONF ARTIF INTE, P5094; Chung Joon Son, 2017, BMVC; Das A, 2018, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2018.00008; Das A, 2017, IEEE I CONF COMP VIS, P2970, DOI 10.1109/ICCV.2017.321; Deng CR, 2018, PROC CVPR IEEE, P7746, DOI 10.1109/CVPR.2018.00808; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu R, 2018, PROC CVPR IEEE, P4233, DOI 10.1109/CVPR.2018.00445; Hu RH, 2017, IEEE I CONF COMP VIS, P804, DOI 10.1109/ICCV.2017.93; Hu RH, 2017, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2017.470; Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493; Jang E., 2017, ICLR; Johnson J, 2017, IEEE I CONF COMP VIS, P3008, DOI 10.1109/ICCV.2017.325; Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215; Kingma D.P, P 3 INT C LEARNING R; Liu JY, 2017, IEEE I CONF COMP VIS, P4866, DOI 10.1109/ICCV.2017.520; Luo RT, 2017, PROC CVPR IEEE, P3125, DOI 10.1109/CVPR.2017.333; Maillard Jean, 2017, ARXIV170509189; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; Plummer BA, 2017, IEEE I CONF COMP VIS, P1946, DOI 10.1109/ICCV.2017.213; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Socher R., 2013, EMNLP, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541; Williams A, 2018, T ASSOC COMPUT LING, V6, P253, DOI DOI 10.1162/TACL_A_00019; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Xiao FY, 2017, PROC CVPR IEEE, P5253, DOI 10.1109/CVPR.2017.558; Yogatama D., 2017, P INT C LEARN REPR, P1; Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142; Yu LC, 2017, PROC CVPR IEEE, P3521, DOI 10.1109/CVPR.2017.375; Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5; Yu Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1114; Zhang HW, 2018, PROC CVPR IEEE, P4158, DOI 10.1109/CVPR.2018.00437; Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331; Zhu M., 2013, P 51 ANN M ASS COMP, V1, P434	43	8	8	12	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					684	696		10.1109/TPAMI.2019.2911066	http://dx.doi.org/10.1109/TPAMI.2019.2911066			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	30990419	Green Submitted			2022-12-18	WOS:000740006100011
J	Li, Y; Zeng, JB; Shan, SG				Li, Yong; Zeng, Jiabei; Shan, Shiguang			Learning Representations for Facial Actions From Unlabeled Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Facial action unit detection; self-supervised learning; representation learning; feature disentanglement; encoder-decoder structure		Facial actions are usually encoded as anatomy-based action units (AUs), the labelling of which demands expertise and thus is time-consuming and expensive. To alleviate the labelling demand, we propose to leverage the large number of unlabelled videos by proposing a twin-cycle autoencoder (TAE) to learn discriminative representations for facial actions. TAE is inspired by the fact that facial actions are embedded in the pixel-wise displacements between two sequential face images (hereinafter, source and target) in the video. Therefore, learning the representations of facial actions can be achieved by learning the representations of the displacements. However, the displacements induced by facial actions are entangled with those induced by head motions. TAE is thus trained to disentangle the two kinds of movements by evaluating the quality of the synthesized images when either the facial actions or head pose is changed, aiming to reconstruct the target image. Experiments on AU detection show that TAE can achieve accuracy comparable to other existing AU detection methods including some supervised methods, thus validating the discriminant capacity of the representations learned by TAE. TAE's ability in decoupling the action-induced and pose-induced movements is also validated by visualizing the generated images and analyzing the facial image retrieval results qualitatively and quantitatively.	[Li, Yong; Zeng, Jiabei; Shan, Shiguang] Chinese Acad Sci, Inst Comp Technol, CAS, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Li, Yong; Shan, Shiguang] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Shan, Shiguang] CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Shan, SG (corresponding author), Chinese Acad Sci, Inst Comp Technol, CAS, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.	yong.li@vipl.ict.ac.cn; jiabei.zeng@vipl.ict.ac.cn; sgshan@ict.ac.cn	; Zeng, Jiabei/J-3865-2016	Shan, Shiguang/0000-0002-8348-392X; Zeng, Jiabei/0000-0003-3256-4524	National Key R&D Program of China [2017YFA0700800]; National Natural Science Foundation of China [61702481, 61976203]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key R&D Program of China under contracts NO.2017YFA0700800, National Natural Science Foundation of China (Grants 61702481 and 61976203). The authors would like to thank Prof. Xilin Chen's contributions in the conference paper of this work. Yong Li and Jiabei Zeng contributed equally to this work.	Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13; Amos Brandon, 2016, CMUCS16118; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); Chen X, 2016, ADV NEUR IN, V29; Chu WS, 2017, IEEE INT CONF AUTOMA, P25, DOI 10.1109/FG.2017.13; Chu WS, 2013, PROC CVPR IEEE, P3515, DOI 10.1109/CVPR.2013.451; Chung JS, 2018, INTERSPEECH, P1086; CORNEANU CA, 2018, P EUR C COMP VIS, P309; Eleftheriadis S, 2015, IEEE I CONF COMP VIS, P3792, DOI 10.1109/ICCV.2015.432; Fernando B, 2017, PROC CVPR IEEE, P5729, DOI 10.1109/CVPR.2017.607; Friesen E., 1978, FACIAL ACTION CODING; Gan C, 2018, PROC CVPR IEEE, P5589, DOI 10.1109/CVPR.2018.00586; Girard JM, 2017, IEEE INT CONF AUTOMA, P581, DOI 10.1109/FG.2017.144; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He K, 2018, PROC CVPR IEEE, P4023, DOI 10.1109/CVPR.2018.00423; He ZL, 2017, IEEE COMPUT SOC CONF, P2044, DOI 10.1109/CVPRW.2017.255; Higgins I, 2016, BETA VAE LEARNING BA; Jayaraman D, 2017, INT J COMPUT VISION, V125, P136, DOI 10.1007/s11263-017-1001-2; Koepke A. Sophia, 2018, P BRIT MACH VIS C, P302; Kokkinos, 2019, P IEEE INT C COMP VI; Kolesnikov A, 2019, PROC CVPR IEEE, P1920, DOI 10.1109/CVPR.2019.00202; Kumar A, 2018, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON FUTURE INDUSTRIAL COMMUNICATION NETWORKS (FICN'18), P1, DOI 10.1145/3243318.3243327; Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3; LEE HY, 2017, P INT C COMP VIS, P3304; Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170; Li W, 2017, PROC CVPR IEEE, P6766, DOI 10.1109/CVPR.2017.716; Li W, 2017, IEEE INT CONF AUTOMA, P103, DOI 10.1109/FG.2017.136; Li ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2418; Liu PP, 2019, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2019.00470; Lorenz D, 2019, PROC CVPR IEEE, P10947, DOI 10.1109/CVPR.2019.01121; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu YF, 2019, IEEE IC COMP COM NET; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Martinez B, 2019, IEEE T AFFECT COMPUT, V10, P325, DOI 10.1109/TAFFC.2017.2731763; Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4; Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32; Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923; Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950; Ng JYH, 2018, IEEE WINT CONF APPL, P1606, DOI 10.1109/WACV.2018.00179; Peng GZ, 2018, PROC CVPR IEEE, P2188, DOI 10.1109/CVPR.2018.00233; Radford A., 2016, 4 INT C LEARNING REP; Shao ZW, 2018, LECT NOTES COMPUT SC, V11217, P725, DOI 10.1007/978-3-030-01261-8_43; Sharma P, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901319; Shu ZX, 2018, LECT NOTES COMPUT SC, V11214, P664, DOI 10.1007/978-3-030-01249-6_40; Taheri S, 2014, IEEE T IMAGE PROCESS, V23, P3590, DOI 10.1109/TIP.2014.2331141; Valstar M., 2006, COMP VIS PATT REC WO, P149; Walker J, 2015, IEEE I CONF COMP VIS, P2443, DOI 10.1109/ICCV.2015.281; Wang JL, 2019, PROC CVPR IEEE, P4001, DOI 10.1109/CVPR.2019.00413; Wang ZH, 2013, IEEE I CONF COMP VIS, P3304, DOI 10.1109/ICCV.2013.410; Wiles O, 2018, LECT NOTES COMPUT SC, V11217, P690, DOI 10.1007/978-3-030-01261-8_41; XING X, 2019, P IEEE CVF C COMP VI; Xu, 2019, P INT C ROB AUT; Zeng JB, 2015, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2015.413; Zhan XH, 2019, PROC CVPR IEEE, P1881, DOI 10.1109/CVPR.2019.00198; Zhang R, 2017, PROC CVPR IEEE, P645, DOI 10.1109/CVPR.2017.76; [张醒 Zhang Xing], 2013, [火工品, Initiators & Pyrotechnics], P1; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao KL, 2018, PROC CVPR IEEE, P2090, DOI 10.1109/CVPR.2018.00223; Zhao KL, 2016, PROC CVPR IEEE, P3391, DOI 10.1109/CVPR.2016.369; Zhao KL, 2015, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2015.7298833; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	65	8	9	11	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					302	317		10.1109/TPAMI.2020.3011063	http://dx.doi.org/10.1109/TPAMI.2020.3011063			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750828				2022-12-18	WOS:000728561300022
J	Gao, HY; Liu, Y; Ji, SW				Gao, Hongyang; Liu, Yi; Ji, Shuiwang			Topology-Aware Graph Pooling Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Topology; Network topology; Task analysis; Diversity reception; Training; Sampling methods; Feature extraction; Deep learning; graph neural networks; graph pooling; graph topology		Pooling operations have shown to be effective on computer vision and natural language processing tasks. One challenge of performing pooling operations on graph data is the lack of locality that is not well-defined on graphs. Previous studies used global ranking methods to sample some of the important nodes, but most of them are not able to incorporate graph topology. In this work, we propose the topology-aware pooling (TAP) layer that explicitly considers graph topology. Our TAP layer is a two-stage voting process that selects more important nodes in a graph. It first performs local voting to generate scores for each node by attending each node to its neighboring nodes. The scores are generated locally such that topology information is explicitly considered. In addition, graph topology is incorporated in global voting to compute the importance score of each node globally in the entire graph. Altogether, the final ranking score for each node is computed by combining its local and global voting scores. To encourage better graph connectivity in the sampled graph, we propose to add a graph connectivity term to the computation of ranking scores. Results on graph classification tasks demonstrate that our methods achieve consistently better performance than previous methods.	[Gao, Hongyang] Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA; [Liu, Yi; Ji, Shuiwang] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA	Iowa State University; Texas A&M University System; Texas A&M University College Station	Ji, SW (corresponding author), Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.	hygao@iastate.edu; yiliu@tamu.edu; sji@tamu.edu			National Science Foundation [IIS-2006861]	National Science Foundation(National Science Foundation (NSF))	This work was supported by National Science Foundation under Grant IIS-2006861. Hongyang Gao and Yi Liu contributed equally to this work.	Borgwardt KM, 2005, BIOINFORMATICS, V21, pI47, DOI 10.1093/bioinformatics/bti1007; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Dobson PD, 2003, J MOL BIOL, V330, P771, DOI 10.1016/S0022-2836(03)00628-4; Gao HY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1416, DOI 10.1145/3219819.3219947; Gao Hongyang., 2019, PR MACH LEARN RES, P2083; Hamilton W., 2017, P ADV NEUR INF PROC, P1024; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Kingma D.P, P 3 INT C LEARNING R; Kipf T.N., 2017, 5 INT C LEARN REPRES, P1; Lee J, 2019, PR MACH LEARN RES, V97; Liu Y, 2019, IEEE DATA MINING, P1234, DOI 10.1109/ICDM.2019.00153; Ma Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P723, DOI 10.1145/3292500.3330982; Mou LL, 2016, AAAI CONF ARTIF INTE, P1287; Niepert M, 2016, PR MACH LEARN RES, V48; Ruder S., 2017, PREPRINT; Shervashidze N, 2011, J MACH LEARN RES, V12, P2539; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Toivonen H, 2003, BIOINFORMATICS, V19, P1183, DOI 10.1093/bioinformatics/btg130; Unterthiner T, 2015, COMPUTER SCI, DOI DOI 10.48550/ARXIV.1511.07289; Wale N, 2008, KNOWL INF SYST, V14, P347, DOI 10.1007/s10115-007-0103-5; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang Y. G., 2020, ICML, P9952; Wang Zhengyang, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.2999032; Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093; Xu K., 2019, ICLR, P1, DOI DOI 10.1109/VTCFALL.2019.8891597; Yanardag P., 2015, ADV NEURAL INFORM PR, P2134; Ying Z., 2018, ADV NEURAL INFORM PR, P4800; Yuan H, 2019, P INT C LEARN REPR; Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438; Zhang Xiang, 2015, ADV NEURAL INFORM PR, P649, DOI DOI 10.5555/2969239.2969312	32	8	8	3	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4512	4518		10.1109/TPAMI.2021.3062794	http://dx.doi.org/10.1109/TPAMI.2021.3062794			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	33646947	Green Submitted			2022-12-18	WOS:000714203900027
J	VidalMata, RG; Banerjee, S; RichardWebster, B; Albright, M; Davalos, P; McCloskey, S; Miller, B; Tambo, A; Ghosh, S; Nagesh, S; Yuan, Y; Hu, YY; Wu, JR; Yang, WH; Zhang, XS; Liu, JY; Wang, ZY; Chen, HT; Huang, TW; Chin, WC; Li, YC; Lababidi, M; Otto, C; Scheirer, WJ				VidalMata, Rosaura G.; Banerjee, Sreya; RichardWebster, Brandon; Albright, Michael; Davalos, Pedro; McCloskey, Scott; Miller, Ben; Tambo, Asong; Ghosh, Sushobhan; Nagesh, Sudarshan; Yuan, Ye; Hu, Yueyu; Wu, Junru; Yang, Wenhan; Zhang, Xiaoshuai; Liu, Jiaying; Wang, Zhangyang; Chen, Hwann-Tzong; Huang, Tzu-Wei; Chin, Wen-Chi; Li, Yi-Chun; Lababidi, Mahmoud; Otto, Charles; Scheirer, Walter J.			Bridging the Gap Between Computational Photography and Visual Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational photography; object recognition; deconvolution; super-resolution; deep learning; evaluation	FACE RECOGNITION; IMAGE; SUPERRESOLUTION; DEBLOCKING; RESOLUTION	What is the current state-of-the-art for image restoration and enhancement applied to degraded images acquired under less than ideal circumstances? Can the application of such algorithms as a pre-processing step improve image interpretability for manual analysis or automatic visual recognition to classify scene content? While there have been important advances in the area of computational photography to restore or enhance the visual quality of an image, the capabilities of such techniques have not always translated in a useful way to visual recognition tasks. Consequently, there is a pressing need for the development of algorithms that are designed for the joint problem of improving visual appearance and recognition, which will be an enabling factor for the deployment of visual recognition tools in many real-world scenarios. To address this, we introduce the UG(2) dataset as a large-scale benchmark composed of video imagery captured under challenging conditions, and two enhancement tasks designed to test algorithmic impact on visual quality and automatic object recognition. Furthermore, we propose a set of metrics to evaluate the joint improvement of such tasks as well as individual algorithmic advances, including a novel psychophysics-based evaluation regime for human assessment and a realistic set of quantitative measures for object recognition performance. We introduce six new algorithms for image restoration or enhancement, which were created as part of the IARPA sponsored UG2 Challenge workshop held at CVPR 2018. Under the proposed evaluation regime, we present an in-depth analysis of these algorithms and a host of deep learning-based and classic baseline approaches. From the observed results, it is evident that we are in the early days of building a bridge between computational photography and visual recognition, leaving many opportunities for innovation in this area.	[VidalMata, Rosaura G.; Banerjee, Sreya; RichardWebster, Brandon; Scheirer, Walter J.] Univ Notre Dame, Notre Dame, IN 46556 USA; [Albright, Michael; Davalos, Pedro; McCloskey, Scott; Miller, Ben; Tambo, Asong] Honeywell ACST, Minneapolis, MN 55422 USA; [Ghosh, Sushobhan] Northwestern Univ, Evanston, IL 60208 USA; [Nagesh, Sudarshan] Zendar Co, Berkeley, CA 94710 USA; [Yuan, Ye; Wu, Junru; Wang, Zhangyang] Texas A&M Univ, College Stn, TX 77843 USA; [Hu, Yueyu; Zhang, Xiaoshuai; Liu, Jiaying] Peking Univ, Beijing 100871, Peoples R China; [Yang, Wenhan] Natl Univ Singapore, Singapore 119077, Singapore; [Chen, Hwann-Tzong; Huang, Tzu-Wei; Chin, Wen-Chi; Li, Yi-Chun] Natl Tsing Hua Univ, Hsinchu 30013, Taiwan; [Lababidi, Mahmoud] Johns Hopkins Univ, Baltimore, MD 21218 USA; [Otto, Charles] Noblis, Reston, VA 20191 USA	University of Notre Dame; Northwestern University; Texas A&M University System; Texas A&M University College Station; Peking University; National University of Singapore; National Tsing Hua University; Johns Hopkins University	Scheirer, WJ (corresponding author), Univ Notre Dame, Notre Dame, IN 46556 USA.	rvidalma@nd.edu; Sreya.Banerjee.9@nd.edu; brichar1@nd.edu; Michael.Albright@honeywell.com; pedro.davalos@honeywell.com; scott.mccloskey@honeywell.com; ben.miller@honeywell.com; Asongu.Tambo@honeywell.com; sushobhan@u.northwestern.edu; sudarshannagesh90@gmail.com; ye.yuan@tamu.edu; michael.ai1024@gmail.com; sandboxmaster@tamu.edu; yangwenhan@pku.edu.cn; jet@pku.edu.cn; liujiaying@pku.edu.cn; atlaswang@tamu.edu; htchen@cs.nthu.edu.tw; twhuang@oz.nthu.edu.tw; wcchin@cs.nthu.edu.tw; happyclass110@gmail.com; lababidi@gmail.com; Charles.Otto@noblis.org; walter.scheirer@nd.edu		Banerjee, Sreya/0000-0003-2658-9020; VidalMata, Rosaura/0000-0002-4096-3747	IARPA contract [201616070500002]; NSF DGE [1313583]; Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA); National Science Foundation (NSF) [CNS1629914]	IARPA contract; NSF DGE(National Science Foundation (NSF)NSF- Directorate for Education & Human Resources (EHR)); Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA); National Science Foundation (NSF)(National Science Foundation (NSF)National Research Foundation of Korea)	This work was supported by the IARPA contract #201616070500002, and NSF DGE #1313583. This work was also supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA). The views and conclusions contained herein are those of the organizers and should not be interpreted as necessarily representing the official policies, either expressed or implied, ofODNI, IARPA, or theU.S. Government. TheU.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. Hardware support was generously provided by the NVIDIA Corporation, and made available by the National Science Foundation (NSF) through grant #CNS1629914. We thank Drs. Adam Czajka, and Christopher Boehnen for conducting an impartial judgment for the challenge tracks to determine the winners, Mr. Vivek Sharma for executing his code on our data and providing uswith the result, Kelly Malecki for her tireless effort in annotating the test dataset for the UAV and Glider collections, and Sandipan Banerjee for assistance with data collection. Rosaura G. VidalMata and Sreya Banerjee are equal contributors.	Adam, 2017, MOBILENETS EFFICIENT; Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Banerjee S., 2019, ARXIV190711529; Barnum PC, 2010, INT J COMPUT VISION, V86, P256, DOI 10.1007/s11263-008-0200-2; Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135; Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652; Buades A, 2010, SIAM REV, V52, P113, DOI 10.1137/090773908; Chang JHR, 2017, IEEE I CONF COMP VIS, P5889, DOI 10.1109/ICCV.2017.627; Chen HT, 2005, PROC CVPR IEEE, P369; Chen J, 2018, PROC CVPR IEEE, P6286, DOI 10.1109/CVPR.2018.00658; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Chollet F., 2015, KERAS; Crump MJC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057410; da Costa GBP, 2016, ARXIV PREPRINT ARXIV; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Dodge S, 2017, 2017 26TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN 2017); Dodge S, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX); Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23; Efrat N, 2013, IEEE I CONF COMP VIS, P2832, DOI 10.1109/ICCV.2013.352; Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Fisher R. B., 2004, PROCEEDINGINGS 6 IEE, P1; Fookes C, 2012, J VIS COMMUN IMAGE R, V23, P75, DOI 10.1016/j.jvcir.2011.06.004; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592; Gondal M. W., 2018, ECCV WORKSHOPS; Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2; Guo J, 2017, PROC CVPR IEEE, P4867, DOI 10.1109/CVPR.2017.517; Haris M., 2018, INT C NEURAL INFORM; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Heide F, 2017, ARXIV PREPRINT ARXIV; Heide F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661260; Hennings-Yeomans PH, 2008, PROC CVPR IEEE, P3637; Hosseini H, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P101, DOI 10.1109/ICMLA.2017.0-172; Hradi M., 2015, BRIT MACH VIS C; Huang H, 2011, IEEE T NEURAL NETWOR, V22, P121, DOI 10.1109/TNN.2010.2089470; Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156; Jing XY, 2015, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2015.7298669; Joshi N, 2009, PROC CVPR IEEE, P1550, DOI 10.1109/CVPRW.2009.5206802; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kingdom FAA, 2016, PSYCHOPHYSICS PRACTI; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Law NM, 2006, ASTRON ASTROPHYS, V446, P739, DOI 10.1051/0004-6361:20053695; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2833, DOI 10.1109/CVPR.2011.5995309; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511; Li SY, 2019, PROC CVPR IEEE, P3833, DOI 10.1109/CVPR.2019.00396; Lin F, 2005, ISSPA 2005: THE 8TH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P667; Lin F, 2007, LECT NOTES COMPUT SC, V4642, P1; Lin S, 2001, PROC CVPR IEEE, P341; List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175; Liu JY, 2018, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2018.00341; Maggiori E, 2017, INT GEOSCI REMOTE SE, P3226; Mao X.-J., 2016, ARXIV160608921; Mao XJ, 2016, ADV NEUR IN, V29; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141; Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27; Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35; Namboodiri V. P., 2011, 2011 VISUAL COMMUNIC, P1; Nishiyama M, 2009, PROC CVPR IEEE, P1115, DOI 10.1109/CVPRW.2009.5206750; Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180; Pellizzari CJ, 2017, APPL OPTICS, V56, P4735, DOI 10.1364/AO.56.004735; Rasti P, 2016, LECT NOTES COMPUT SC, V9756, P175, DOI 10.1007/978-3-319-41778-3_18; REEVE HC, 1984, OPT ENG, V23, P34, DOI 10.1117/12.7973248; RichardWebster B, 2019, IEEE T PATTERN ANAL, V41, P2280, DOI 10.1109/TPAMI.2018.2849989; Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481; Schechner YY, 2001, PROC CVPR IEEE, P325; Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285; Sharma V, 2018, PROC CVPR IEEE, P4033, DOI 10.1109/CVPR.2018.00424; Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959; Shih YC, 2015, PROC CVPR IEEE, P3193, DOI 10.1109/CVPR.2015.7298939; Singh M, 2019, IEEE I CONF COMP VIS, P340, DOI 10.1109/ICCV.2019.00043; Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tahboub K, 2017, IEEE IMAGE PROC, P4187; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643; Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251; Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8; Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241; Uiboupin T, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P437, DOI 10.1109/SIU.2016.7495771; Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984; Vidal R. G., 2018, IEEE WINT CONF APPL, P1597, DOI DOI 10.1109/WACV.2018.00177; Vondrick C, 2013, INT J COMPUT VISION, V101, P184, DOI 10.1007/s11263-012-0564-1; Wheeler FW, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P193; Wu J., 2016, ARXIV161108091; Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418; Xiao L, 2016, LECT NOTES COMPUT SC, V9907, P734, DOI 10.1007/978-3-319-46487-9_45; Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25; Yang J., 2008, 2008 IEEE C COMP VIS, DOI 10.1109/CVPR.2008.4587647; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yang WH, 2017, IEEE T IMAGE PROCESS, V26, P5895, DOI 10.1109/TIP.2017.2750403; Yao Y, 2008, COMPUT VIS IMAGE UND, V111, P111, DOI 10.1016/j.cviu.2007.09.004; Yim J, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P345; Yu J., 2011, IEEE CVPR WORKSHOPS, P39; Yu K, 2018, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2018.00259; Zamir Syed Waqas, 2019, P IEEE C COMP VIS PA; Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957; Zeyde Roman, 2010, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47; Zhang HC, 2011, IEEE I CONF COMP VIS, P770, DOI 10.1109/ICCV.2011.6126315; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40; Zhang XP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P461, DOI 10.1109/ICME.2006.262572; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu Pengfei, 2018, ARXIV180407437, P2; Zhu XT, 2013, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2013.17; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907; Zuiderveld K., 1994, GRAPHICS GEMS, P474	131	8	8	4	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4272	4290		10.1109/TPAMI.2020.2996538	http://dx.doi.org/10.1109/TPAMI.2020.2996538			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	32750769	Green Submitted			2022-12-18	WOS:000714203900011
J	Cai, YJ; Ge, LH; Cai, JF; Thalmann, NM; Yuan, JS				Cai, Yujun; Ge, Liuhao; Cai, Jianfei; Thalmann, Nadia Magnenat; Yuan, Junsong			3D Hand Pose Estimation Using Synthetic Data and Weakly Labeled RGB Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Pose estimation; Training; Two dimensional displays; Solid modeling; Cameras; Testing; 3D hand pose estimation; weakly-supervised methods; depth regularizer; pose-specific subspace	TRACKING; RECOGNITION; SYNERGIES	Compared with depth-based 3D hand pose estimation, it is more challenging to infer 3D hand pose from monocular RGB images, due to the substantial depth ambiguity and the difficulty of obtaining fully-annotated training data. Different from the existing learning-based monocular RGB-input approaches that require accurate 3D annotations for training, we propose to leverage the depth images that can be easily obtained from commodity RGB-D cameras during training, while during testing we take only RGB inputs for 3D joint predictions. In this way, we alleviate the burden of the costly 3D annotations in real-world dataset. Particularly, we propose a weakly-supervised method, adaptating from fully-annotated synthetic dataset to weakly-labeled real-world single RGB dataset with the aid of a depth regularizer, which serves as weak supervision for 3D pose prediction. To further exploit the physical structure of 3D hand pose, we present a novel CVAE-based statistical framework to embed the pose-specific subspace from RGB images, which can then be used to infer the 3D hand joint locations. Extensive experiments on benchmark datasets validate that our proposed approach outperforms baselines and state-of-the-art methods, which proves the effectiveness of the proposed depth regularizer and the CVAE-based framework.	[Cai, Yujun; Ge, Liuhao] Nanyang Technol Univ, Inst Media Innovat, Singapore 639798, Singapore; [Cai, Jianfei] Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia; [Thalmann, Nadia Magnenat] Nanyang Tech Nol Univ, Inst Media Innovat, Singapore 639798, Singapore; [Yuan, Junsong] Univ Buffalo, Comp Sci & Engn Dept, Buffalo, NY 14260 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Monash University; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Cai, YJ (corresponding author), Nanyang Technol Univ, Inst Media Innovat, Singapore 639798, Singapore.	yujun001@e.ntu.edu.sg; ge0001ao@e.ntu.edu.sg; jianfei.cai@monash.edu; nadiathalmann@ntu.edu.sg; jsyuan@buffalo.edu	Cai, Jianfei/A-3691-2011	Cai, Jianfei/0000-0002-9444-3763; Thalmann, Nadia/0000-0002-1459-5960; CAI, YUJUN/0000-0002-0993-4024; Thalmann, Nadia/0000-0002-3897-4041	National Research Foundation, Singapore under its International Research Centres in Singapore Funding Initiative; Singapore MoE Tier-2 Grant [MOE2016-T2-2-065]; Monash University; University at Buffalo	National Research Foundation, Singapore under its International Research Centres in Singapore Funding Initiative; Singapore MoE Tier-2 Grant(Ministry of Education, Singapore); Monash University(Monash University); University at Buffalo	This work was supported by the National Research Foundation, Singapore under its International Research Centres in Singapore Funding Initiative. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore. This work was also supported in part by Singapore MoE Tier-2 Grant (MOE2016-T2-2-065) and start-up funds from Monash University and University at Buffalo.	Baek S, 2019, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2019.00116; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236; Cai YJ, 2018, LECT NOTES COMPUT SC, V11210, P678, DOI 10.1007/978-3-030-01231-1_41; Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49; Dibra E, 2017, INT CONF 3D VISION, P135, DOI 10.1109/3DV.2017.00025; Ge LH, 2018, LECT NOTES COMPUT SC, V11217, P489, DOI 10.1007/978-3-030-01261-8_29; Ge LH, 2019, PROC CVPR IEEE, P10825, DOI 10.1109/CVPR.2019.01109; Ge LH, 2018, PROC CVPR IEEE, P8417, DOI 10.1109/CVPR.2018.00878; Ge LH, 2019, IEEE T PATTERN ANAL, V41, P956, DOI 10.1109/TPAMI.2018.2827052; Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602; Ge L, 2016, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2016.391; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013; Hampali S., 2020, P IEEE INT C COMP VI, V3, P6; Hasson Yana, 2019, CVPR; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Iqbal U., 2018, P EUR C COMP VIS, P118; Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61; Kingma D.P, P 3 INT C LEARNING R; Kulon D., 2019, PROC 30 BRIT MACH VI, P45; Li PY, 2015, IEEE I CONF COMP VIS, P819, DOI 10.1109/ICCV.2015.100; Liang H, 2015, IEEE INT CON MULTI, DOI 10.1109/FPL.2015.7293954; Liang H, 2015, IEEE T CIRC SYST VID, V25, P1125, DOI 10.1109/TCSVT.2014.2363750; Liang H, 2013, VISUAL COMPUT, V29, P837, DOI 10.1007/s00371-013-0822-4; Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306; Lu S, 2003, PROC CVPR IEEE, P443; Malik J, 2018, INT CONF 3D VISION, P110, DOI 10.1109/3DV.2018.00023; Mueller F, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322958; Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013; Mueller F, 2017, IEEE INT CONF COMP V, P1284, DOI 10.1109/ICCVW.2017.82; Oberweger M, 2020, IEEE T PATTERN ANAL, V42, P1898, DOI 10.1109/TPAMI.2019.2907951; Oberweger M, 2017, IEEE INT CONF COMP V, P585, DOI 10.1109/ICCVW.2017.75; Oberweger M, 2016, PROC CVPR IEEE, P4957, DOI 10.1109/CVPR.2016.536; Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379; Oberweger Markus, 2015, ARXIV150206807; Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101; Oikonomidis I, 2011, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2011.6126483; Panteleris P, 2018, IEEE WINT CONF APPL, P436, DOI 10.1109/WACV.2018.00054; Poier G, 2018, PROC CVPR IEEE, P60, DOI 10.1109/CVPR.2018.00014; Qian C, 2014, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2014.145; Rad M., 2018, ACCV; Rad M, 2018, PROC CVPR IEEE, P4663, DOI 10.1109/CVPR.2018.00490; Rehg J. M., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P16, DOI 10.1109/MNRAO.1994.346260; Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148; Rosales R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P378, DOI 10.1109/ICCV.2001.937543; Santello M, 1998, J NEUROSCI, V18, P10105; Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179; Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241; Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494; Sohn Kihyuk, 2015, NEURAL INFORM PROCES; Spurr A, 2018, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2018.00017; Sridhar S, 2016, LECT NOTES COMPUT SC, V9906, P294, DOI 10.1007/978-3-319-46475-6_19; Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189; Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33; Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683; Tang DH, 2015, IEEE I CONF COMP VIS, P3325, DOI 10.1109/ICCV.2015.380; Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490; Taylor J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925965; Tekin B, 2019, PROC CVPR IEEE, P4506, DOI 10.1109/CVPR.2019.00464; Todorov E, 2004, P ANN INT IEEE EMBS, V26, P4637; Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603; Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; Tzionas D, 2016, INT J COMPUT VISION, V118, P172, DOI 10.1007/s11263-016-0895-4; Wan CD, 2017, PROC CVPR IEEE, P1196, DOI 10.1109/CVPR.2017.132; Wang R., 2011, P 24 ANN ACM S US IN, P549, DOI DOI 10.1145/2047196.2047269; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Weng JW, 2019, IEEE T CIRC SYST VID, V29, P1077, DOI 10.1109/TCSVT.2018.2818151; Weng JW, 2017, PROC CVPR IEEE, P445, DOI 10.1109/CVPR.2017.55; Wu JJ, 2016, LECT NOTES COMPUT SC, V9910, P365, DOI 10.1007/978-3-319-46466-4_22; Wu XK, 2018, LECT NOTES COMPUT SC, V11220, P246, DOI 10.1007/978-3-030-01270-0_15; Wu Y, 2000, PROC CVPR IEEE, P88, DOI 10.1109/CVPR.2000.854749; Xiang DL, 2019, PROC CVPR IEEE, P10957, DOI 10.1109/CVPR.2019.01122; Xu C, 2013, IEEE I CONF COMP VIS, P3456, DOI 10.1109/ICCV.2013.429; Yang LL, 2019, PROC CVPR IEEE, P9869, DOI 10.1109/CVPR.2019.01011; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535; Ye Q, 2018, LECT NOTES COMPUT SC, V11214, P817, DOI 10.1007/978-3-030-01249-6_49; Ying Wu, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P606, DOI 10.1109/ICCV.1999.791280; Yuan SX, 2017, PROC CVPR IEEE, P2605, DOI 10.1109/CVPR.2017.279; Zhang J., 2017, P INT C IM PROC, P982; Zhang X, 2019, IEEE I CONF COMP VIS, P2354, DOI 10.1109/ICCV.2019.00244; Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51; Zhou YD, 2018, LECT NOTES COMPUT SC, V11218, P521, DOI 10.1007/978-3-030-01264-9_31; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zimmermann C, 2019, IEEE I CONF COMP VIS, P813, DOI 10.1109/ICCV.2019.00090; Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525	89	8	8	2	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3739	3753		10.1109/TPAMI.2020.2993627	http://dx.doi.org/10.1109/TPAMI.2020.2993627			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32396073				2022-12-18	WOS:000702649700005
J	Celik, B; Vanschoren, J				Celik, Bilge; Vanschoren, Joaquin			Adaptation Strategies for Automated Machine Learning on Evolving Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pipelines; Adaptation models; Machine learning; Optimization; Data models; Task analysis; Bayes methods; AutoML; data streams; concept drift; adaptation strategies	DRIFT	Automated Machine Learning (AutoML) systems have been shown to efficiently build good models for new datasets. However, it is often not clear how well they can adapt when the data evolves over time. The main goal of this study is to understand the effect of concept drift on the performance of AutoML methods, and which adaptation strategies can be employed to make them more robust to changes in the underlying data. To that end, we propose 6 concept drift adaptation strategies and evaluate their effectiveness on a variety of AutoML approaches for building machine learning pipelines, including Bayesian optimization, genetic programming, and random search with automated stacking. These are evaluated empirically on real-world and synthetic data streams with different types of concept drift. Based on this analysis, we propose ways to develop more sophisticated and robust AutoML techniques.	[Celik, Bilge; Vanschoren, Joaquin] Eindhoven Univ Technol, NL-5612 AZ Eindhoven, Netherlands	Eindhoven University of Technology	Celik, B (corresponding author), Eindhoven Univ Technol, NL-5612 AZ Eindhoven, Netherlands.	B.Celik.Aydin@tue.nl; j.vanschoren@tue.nl		Vanschoren, Joaquin/0000-0001-7044-9805; Celik, Bilge/0000-0003-4082-6694	Dutch Science Foundation (NWO) Grant DACCOMPLI [628.011.022]	Dutch Science Foundation (NWO) Grant DACCOMPLI	The authors would like to thank Erin Ledell, Matthias Feurer and Pieter Gijsbers for their advice on adapting their AutoML systems. This work was supported by the Dutch Science Foundation (NWO) Grant DACCOMPLI (nr. 628.011.022).	Baena-Garc M, 2006, INT WORKSHOP KNOWLED, V6, P77, DOI DOI 10.1007/978-3-642-23857-4_12; Bakirov R., ABS181210793 CORR, Vabs, P10793; Bergstra James S, 2011, ADV NEURAL INFORM PR, P2546, DOI [10.5555/2986459.2986743, DOI 10.5555/2986459.2986743]; Bifet A, 2009, J EMPIR FINANCE, V8, P325; Bifet A, 2011, LECT NOTES ARTIF INT, V6913, P617, DOI 10.1007/978-3-642-23808-6_41; Bifet A, 2010, LECT NOTES ARTIF INT, V6321, P135, DOI 10.1007/978-3-642-15880-3_15; Brochu E, 2010, ARXIV PREPRINT ARXIV; Carnein M, 2019, JOINT EUR C MACH LEA, P137; De Lange M, 2019, ABS190908383 CORR; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P71, DOI 10.1145/347090.347107; Duarte MF, 2004, J PARALLEL DISTR COM, V64, P826, DOI 10.1016/j.jpdc.2004.03.020; Escalante H. J, 2020, P NEURIPS 18 COMP, P209; Feurer Matthias, 2015, ADV NEURAL INFORM PR, P2962; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Gama J, 2004, LECT NOTES ARTIF INT, V3171, P286; Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813; Gama J, 2011, LECT NOTES COMPUT SC, V7014, P162, DOI 10.1007/978-3-642-24800-9_17; Garnett R, 2010, LEARNING DATA STREAM; Garnett R, 2010, COMPUT J, V53, P1430, DOI 10.1093/comjnl/bxq003; Gijsbers P., 2019, ARXIV PREPRINT ARXIV; Gijsbers P., 2019, J OPEN SOURCE SOFTW, V4, P1132, DOI 10.21105/joss.01132; Golovin D, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1487, DOI 10.1145/3097983.3098043; Gomes HM, 2017, MACH LEARN, V106, P1469, DOI 10.1007/s10994-017-5642-8; H2O.ai, 2019, H2O PYTH INT H2O 3 1; Harries M., 1999, UNSWCSETR9905; Hulten G., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P97, DOI 10.1145/502512.502529; Hutter F, AUTOMATIC MACHINE LE; Madrid J. G, 2019, ABS190710772 CORR, Vabs, P10772; Malheiro, 2018, DATA STREAMS, DOI DOI 10.1007/978-3-030-01771-2_16; Olson RS, 2016, LECT NOTES COMPUT SC, V9597, P123, DOI 10.1007/978-3-319-31204-0_9; Oza N. C., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P359, DOI 10.1145/502512.502565; Oza NC, 2005, IEEE SYS MAN CYBERN, P2340; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Read Jesse, 2012, Advances in Intelligent Data Analysis XI. Proceedings 11th International Symposium, IDA 2012, P313, DOI 10.1007/978-3-642-34156-4_29; Snoek J., 2012, P 25 INT C NEUR INF, V2, P2951, DOI DOI 10.48550/ARXIV.1206.2944; Street W. N., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P377, DOI 10.1145/502512.502568; Thornton C, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P847, DOI 10.1145/2487575.2487629; van Rijn JN, 2015, IEEE DATA MINING, P1003, DOI 10.1109/ICDM.2015.55; van Rijn JN, 2014, LECT NOTES ARTIF INT, V8777, P325, DOI 10.1007/978-3-319-11812-3_28; Vanschoren J., 2013, ACM SIGKDD EXPLOR NE, V15, P49, DOI [10.1145/2641190.2641198, DOI 10.1145/2641190.2641198]; Webb GI, 2018, DATA MIN KNOWL DISC, V32, P1179, DOI 10.1007/s10618-018-0554-1; Webb GI, 2016, DATA MIN KNOWL DISC, V30, P964, DOI 10.1007/s10618-015-0448-4; Yao Quanming, 2018, ARXIV181013306	43	8	8	10	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					3067	3078		10.1109/TPAMI.2021.3062900	http://dx.doi.org/10.1109/TPAMI.2021.3062900			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	33651683	Green Submitted			2022-12-18	WOS:000681124300017
J	Hirose, O				Hirose, Osamu			Acceleration of Non-Rigid Point Set Registration With Downsampling and Gaussian Process Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape; Acceleration; Interpolation; Coherence; Strain; Gaussian processes; Computational efficiency; Non-rigid point set registration; motion coherence prior; soft matching; downsampling; displacement field interpolation; Bayesian coherent point drift; Gaussian process regression		Non-rigid point set registration is the process of transforming a shape represented as a point set into a shape matching another shape. In this paper, we propose an acceleration method for solving non-rigid point set registration problems. We accelerate non-rigid registration by dividing it into three steps: i) downsampling of point sets; ii) non-rigid registration of downsampled point sets; and iii) interpolation of shape deformation vectors corresponding to points removed during downsampling. To register downsampled point sets, we use a registration algorithm based on a prior distribution, called motion coherence prior. Using the same prior, we derive an interpolation method interpreted as Gaussian process regression. Through numerical experiments, we demonstrate that our algorithm registers point sets containing over ten million points. We also show that our algorithm reduces computing time more radically than a state-of-the-art acceleration algorithm.	[Hirose, Osamu] Kanazawa Univ, Inst Sci & Engn, Kanazawa, Ishikawa 9201192, Japan	Kanazawa University	Hirose, O (corresponding author), Kanazawa Univ, Inst Sci & Engn, Kanazawa, Ishikawa 9201192, Japan.	hirose@se.kanazawa-u.ac.jp	Hirose, Osamu/K-7890-2015	Hirose, Osamu/0000-0002-8077-8589				Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Amberg Brian, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1; BARNES J, 1986, NATURE, V324, P446, DOI 10.1038/324446a0; Berger M, 2017, COMPUT GRAPH FORUM, V36, P301, DOI 10.1111/cgf.12802; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bishop C.M, 2006, PATTERN RECOGN; Bogo F, 2017, PROC CVPR IEEE, P5573, DOI 10.1109/CVPR.2017.591; Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Dupej J, 2015, PATTERN RECOGN LETT, V52, P53, DOI 10.1016/j.patrec.2014.10.005; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; Golyanik V, 2019, INT CONF 3D VISION, P164, DOI 10.1109/3DV.2019.00027; Golyanik V, 2016, PROC CVPR IEEE, P5802, DOI 10.1109/CVPR.2016.625; Golyanik Vladislav, 2016, 2016 IEEE WINT C APP, P1, DOI DOI 10.1109/ICCV.2017.322; Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418; GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004; Hirose O, 2021, IEEE T PATTERN ANAL, V43, P2269, DOI 10.1109/TPAMI.2020.2971687; Hirshberg DA, 2012, LECT NOTES COMPUT SC, V7577, P242, DOI 10.1007/978-3-642-33783-3_18; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x; Ma JY, 2019, IEEE T NEUR NET LEAR, V30, P3584, DOI 10.1109/TNNLS.2018.2872528; Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217; Marin R, 2020, COMPUT GRAPH FORUM, V39, P160, DOI 10.1111/cgf.13751; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Rangarajan A, 1997, LECT NOTES COMPUT SC, V1230, P29; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Sahillioglu Y, 2020, VISUAL COMPUT, V36, P1705, DOI 10.1007/s00371-019-01760-0; Saval-Calvo M, 2018, COMPUT VIS IMAGE UND, V169, P119, DOI 10.1016/j.cviu.2018.01.008; Schlkopf B., 2006, ADV NEURAL INFORM PR, P1009; Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0; Wang G, 2021, IEEE T NEUR NET LEAR, V32, P203, DOI 10.1109/TNNLS.2020.2978031; Wang G, 2018, PATTERN RECOGN, V74, P305, DOI 10.1016/j.patcog.2017.09.029; Wang G, 2017, IEEE T IMAGE PROCESS, V26, P1759, DOI 10.1109/TIP.2017.2658947; Williams CKI, 2001, ADV NEUR IN, V13, P682; Yang CJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P464	36	8	8	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2858	2865		10.1109/TPAMI.2020.3043769	http://dx.doi.org/10.1109/TPAMI.2020.3043769			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	33301401	hybrid			2022-12-18	WOS:000670578800025
J	Wang, TH; Cook, DJ				Wang, Tinghui; Cook, Diane J.			sMRT: Multi-Resident Tracking in Smart Homes With Sensor Vectorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Smart homes; Layout; Hidden Markov models; Monitoring; Data models; Tracking; Building automation; Smart home; time series; multi-resident tracking; multi-target Bayes filter; sensor networks	ACTIVITY RECOGNITION; PEOPLE	Smart homes equipped with anonymous binary sensors offer a low-cost, unobtrusive solution that powers activity-aware applications, such as building automation, health monitoring, behavioral intervention, and home security. However, when multiple residents are living in a smart home, associating sensor events with the corresponding residents can pose a major challenge. Previous approaches to multi-resident tracking in smart homes rely on extra information, such as sensor layouts, floor plans, and annotated data, which may not be available or inconvenient to obtain in practice. To address those challenges in real-life deployment, we introduce the sMRT algorithm that simultaneously tracks the location of each resident and estimates the number of residents in the smart home, without relying on ground-truth annotated sensor data or other additional information. We evaluate the performance of our approach using two smart home datasets recorded in real-life settings and compare sMRT with two other methods that rely on sensor layout and ground truth-labeled sensor data.	[Wang, Tinghui; Cook, Diane J.] Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA	Washington State University	Wang, TH (corresponding author), Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA.	tinghui.wang@wsu.edu; cook@eecs.wsu.edu		Cook, Diane/0000-0002-4441-7508	US National Science Foundation [1543656]	US National Science Foundation(National Science Foundation (NSF))	The authors would like to thank Brian Thomas and Aaron Crandall for their assistance in collecting smart home sensor data and Sue Nelson for her assistance in providing ground truth labels for the smart home sensor data. This material is based upon work supported by the US National Science Foundation under Grant No. 1543656.	Ahmadi-Karvigh S, 2018, APPL ENERG, V211, P146, DOI 10.1016/j.apenergy.2017.11.055; Akl A, 2017, IEEE J BIOMED HEALTH, V21, P339, DOI 10.1109/JBHI.2015.2512273; Aramendi AA, 2018, J BIOMED INFORM, V81, P119, DOI 10.1016/j.jbi.2018.03.009; Amri MH, 2015, IEEE INT CON AUTO SC, P194, DOI 10.1109/CoASE.2015.7294061; Aran O, 2016, LECT NOTES COMPUT SC, V9997, P51, DOI 10.1007/978-3-319-46843-3_4; Arcelus A, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P820; Austin J, 2016, IEEE J TRANSL ENG HE, V4, DOI 10.1109/JTEHM.2016.2579638; Brdiczka O, 2009, IEEE T SYST MAN CY B, V39, P56, DOI 10.1109/TSMCB.2008.923526; Choi W, 2014, IEEE T PATTERN ANAL, V36, P1242, DOI 10.1109/TPAMI.2013.220; Cook DJ, 2012, IEEE INTELL SYST, V27, P32, DOI 10.1109/MIS.2010.112; Cook DJ, 2017, ROLE TECHNOL CLIN NE, P293; Corno F, 2012, IEEE T SMART GRID, V3, P2128, DOI 10.1109/TSG.2012.2214407; Crandall A. S., 2008, INT ENV 2008 IET 4 I, P1; Crandall A. S., 2011, HUMAN BEHAV RECOGNIT, P111; Crandall AS, 2009, J AMB INTEL SMART EN, V1, P323, DOI 10.3233/AIS-2009-0041; Dahmen J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040737; Dawadi PN, 2013, TECHNOL HEALTH CARE, V21, P323, DOI 10.3233/THC-130734; De D, 2012, INT CON DISTR COMP S, P163, DOI 10.1109/ICDCS.2012.76; De Paola A, 2017, IEEE T MOBILE COMPUT, V16, P1502, DOI 10.1109/TMC.2016.2599158; Gayathri KS, 2017, KNOWL-BASED SYST, V121, P173, DOI 10.1016/j.knosys.2017.01.025; Ghasemi V, 2017, INT J COMPUT INT SYS, V10, P1289, DOI 10.2991/ijcis.10.1.88; Gochoo M, 2019, IEEE J BIOMED HEALTH, V23, P693, DOI 10.1109/JBHI.2018.2833618; Goodman IR, 2013, MATH DATA FUSION; Gutmann M., 2010, AISTATS, V9, P297, DOI DOI 10.1145/3292500.3330651; Hagler S, 2010, IEEE T BIO-MED ENG, V57, P813, DOI 10.1109/TBME.2009.2036732; Hsu KC, 2010, LECT NOTES ARTIF INT, V6096, P417, DOI 10.1007/978-3-642-13022-9_42; Ordonez FJ, 2015, PERS UBIQUIT COMPUT, V19, P259, DOI 10.1007/s00779-014-0820-1; Krishnan NC, 2014, PERVASIVE MOB COMPUT, V10, P138, DOI 10.1016/j.pmcj.2012.07.003; Liu LL, 2016, INT J MED INFORM, V91, P44, DOI 10.1016/j.ijmedinf.2016.04.007; M_uller S. M., 2016, INT J ADV NETW SERV, V9, P20; Mekonnen AA, 2019, IEEE T CIRC SYST VID, V29, P996, DOI 10.1109/TCSVT.2018.2817609; Minor B, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P805, DOI 10.1145/2783258.2783408; Minor BD, 2017, IEEE T KNOWL DATA EN, V29, P2744, DOI 10.1109/TKDE.2017.2750669; Nayak Nandita M, 2015, IEEE Trans Image Process, V24, P2025, DOI 10.1109/TIP.2015.2404034; Park H, 2017, IEEE COMMUN LETT, V21, P757, DOI 10.1109/LCOMM.2016.2619700; Pennington J., 2014, P 2014 C EMPIRICAL M, P1532; Rafferty J, 2017, IEEE T HUM-MACH SYST, V47, P368, DOI 10.1109/THMS.2016.2641388; Song L., 2014, P 15 ACM INT S MOB A, P397; Suryadevara NK, 2013, ENG APPL ARTIF INTEL, V26, P2641, DOI 10.1016/j.engappai.2013.08.004; Thomas BL, 2016, ENERGIES, V9, DOI 10.3390/en9080624; Vo BN, 2006, IEEE T SIGNAL PROCES, V54, P4091, DOI 10.1109/TSP.2006.881190; Wang CL, 2013, KNOWL-BASED SYST, V37, P346, DOI 10.1016/j.knosys.2012.08.020; Wilson DH, 2005, LECT NOTES COMPUT SC, V3468, P62	43	8	8	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2809	2821		10.1109/TPAMI.2020.2973571	http://dx.doi.org/10.1109/TPAMI.2020.2973571			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32070942	Green Accepted, hybrid			2022-12-18	WOS:000670578800021
J	Nehme, E; Ferdman, B; Weiss, LE; Naor, T; Freedman, D; Michaeli, T; Shechtman, Y				Nehme, Elias; Ferdman, Boris; Weiss, Lucien E.; Naor, Tal; Freedman, Daniel; Michaeli, Tomer; Shechtman, Yoav			Learning Optimal Wavefront Shaping for Multi-Channel Imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Imaging; Three-dimensional displays; Microscopy; Location awareness; Optical microscopy; Optical imaging; Optical diffraction; Computational microscopy; wavefront coding; deep neural networks; end-to-end optimization	POINT-SPREAD-FUNCTION; SINGLE-MOLECULE MICROSCOPY; MULTICOLOR LOCALIZATION MICROSCOPY; EXTENDED DEPTH; DIFFRACTION-LIMIT; CODED-APERTURE; 3D POSITION; TRACKING; FIELD; ORIENTATION	Fast acquisition of depth information is crucial for accurate 3D tracking of moving objects. Snapshot depth sensing can be achieved by wavefront coding, in which the point-spread function (PSF) is engineered to vary distinctively with scene depth by altering the detection optics. In low-light applications, such as 3D localization microscopy, the prevailing approach is to condense signal photons into a single imaging channel with phase-only wavefront modulation to achieve a high pixel-wise signal to noise ratio. Here we show that this paradigm is generally suboptimal and can be significantly improved upon by employing multi-channel wavefront coding, even in low-light applications. We demonstrate our multi-channel optimization scheme on 3D localization microscopy in densely labelled live cells where detectability is limited by overlap of modulated PSFs. At extreme densities, we show that a split-signal system, with end-to-end learned phase masks, doubles the detection rate and reaches improved precision compared to the current state-of-the-art, single-channel design. We implement our method using a bifurcated optical system, experimentally validating our approach by snapshot volumetric imaging and 3D tracking of fluorescently labelled subcellular elements in dense environments.	[Nehme, Elias] Technion Israel Inst Technol, Viterbi Fac Elect Engn, Biomed Engn Dept, IL-3200003 Haifa, Israel; [Nehme, Elias; Weiss, Lucien E.; Naor, Tal] Technion Israel Inst Technol, Lorry I Lokey Ctr Life Sci & Engn, IL-3200003 Haifa, Israel; [Ferdman, Boris] Technion Israel Inst Technol, Russel Berrie Nanotechnol Inst, Biomed Engn Dept, IL-3200003 Haifa, Israel; [Ferdman, Boris] Technion Israel Inst Technol, Russel Berrie Nanotechnol Inst, Lorry I Lokey Ctr Life Sci & Engn, IL-3200003 Haifa, Israel; [Weiss, Lucien E.; Naor, Tal] Technion Israel Inst Technol, Biomed Engn Dept, IL-3200003 Haifa, Israel; [Freedman, Daniel] Google Res, IL-3508504 Haifa, Israel; [Michaeli, Tomer] Technion Israel Inst Technol, Viterbi Fac Elect Engn, IL-3200003 Haifa, Israel	Technion Israel Institute of Technology; Technion Israel Institute of Technology; Technion Israel Institute of Technology; Technion Israel Institute of Technology; Technion Israel Institute of Technology; Google Incorporated; Technion Israel Institute of Technology	Nehme, E (corresponding author), Technion Israel Inst Technol, Viterbi Fac Elect Engn, Biomed Engn Dept, IL-3200003 Haifa, Israel.; Nehme, E (corresponding author), Technion Israel Inst Technol, Lorry I Lokey Ctr Life Sci & Engn, IL-3200003 Haifa, Israel.	seliasne@campus.technion.ac.il; borisfer@campus.technion.ac.il; lucien.e.weiss@gmail.com; tal.naor86@gmail.com; danielfreedman@google.com; tomer.m@ee.technion.ac.il; yoavsh@bm.technion.ac.il		Shechtman, Yoav/0000-0001-8498-5203; Nehme, Elias/0000-0003-1759-1751; Freedman, Daniel/0000-0001-7354-0129; Michaeli, Tomer/0000-0003-0525-8054	European Union's Horizon 2020 Research and Innovation Programe [802567-ERC-5D-NanoTrack]; Israel Science Foundation [852/17, 450/18]; Zuckerman STEM Leadership Program; Google Faculty Research Award for Machine Perception; Technion Ollendorff Minerva Center	European Union's Horizon 2020 Research and Innovation Programe; Israel Science Foundation(Israel Science Foundation); Zuckerman STEM Leadership Program; Google Faculty Research Award for Machine Perception(Google Incorporated); Technion Ollendorff Minerva Center	The authors would like to thank Rotem Mulayoff for insights and fruitful discussions with respect to the EDOF design and Romain F. Laine for his help with conceiving the name Nebulae. The authors would also like to thank NVIDIA Corporation for the donation of the Titan Xp and the Titan V GPUs used for this research and Google for the cloud units provided to accelerate this research. This work was supported in part by the European Union's Horizon 2020 Research and Innovation Programe under Grant 802567-ERC-5D-NanoTrack, in part by the Israel Science Foundation under Grants 852/17 and 450/18, in part by the Technion OllendorffMinerva Center, in part by the Zuckerman STEM Leadership Program, and in part by the Google Faculty Research Award for Machine Perception. Elias Nehme and Boris Ferdman contributed equally to this work.	Akpinar U., 2019, ARXIV191213423; Aristov A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04709-4; Backer AS, 2014, J PHYS CHEM B, V118, P8313, DOI 10.1021/jp501778z; Backlund MP, 2012, P NATL ACAD SCI USA, V109, P19087, DOI 10.1073/pnas.1216687109; Badieirostami M, 2010, APPL PHYS LETT, V97, DOI 10.1063/1.3499652; Baek S.-H., 2020, END TO END HYPERSPEC; Barth R, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaz2196; Belthangady C, 2019, NAT METHODS, V16, P1215, DOI 10.1038/s41592-019-0458-z; Ben-Eliezer E, 2005, APPL OPTICS, V44, P2792, DOI 10.1364/AO.44.002792; Betzig E, 2006, SCIENCE, V313, P1642, DOI 10.1126/science.1127344; Bourg N, 2015, NAT PHOTONICS, V9, P587, DOI [10.1038/nphoton.2015.132, 10.1038/NPHOTON.2015.132]; Boyd N., 2018, 267096 BIORXIV, DOI [10.1101/267096, DOI 10.1101/267096]; Bronshtein I, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9044; Cabriel C, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09901-8; Chakrabarti Ayan, 2016, ADV NEURAL INFORM PR, P3081; Chang J, 2019, IEEE I CONF COMP VIS, P10192, DOI 10.1109/ICCV.2019.01029; Chen BY, 2020, BIOMED OPT EXPRESS, V11, P3830, DOI 10.1364/BOE.393931; Cooke C.L., 2021, P IEEE CVF INT C COM, P3803; DOWSKI ER, 1995, APPL OPTICS, V34, P1859, DOI 10.1364/AO.34.001859; Dun X, 2020, OPTICA, V7, P913, DOI 10.1364/OPTICA.394413; Elmalem S, 2018, OPT EXPRESS, V26, P15316, DOI 10.1364/OE.26.015316; Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2; Ferdman B, 2020, OPT EXPRESS, V28, P10179, DOI 10.1364/OE.388248; Franke C, 2017, NAT METHODS, V14, P41, DOI [10.1038/nmeth.4073, 10.1038/NMETH.4073]; Gaire SK, 2020, BIOMED OPT EXPRESS, V11, P2705, DOI 10.1364/BOE.391806; Gaskell J. D., 2019, P 2019 INT C IND, P1; Gil Y., 2019, ARXIV191013708; Goodman J. W., 2005, MCGRAW HILL PHYS QUA; Gopal S, 2016, PR MACH LEARN RES, V48; Hasinoff SW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980254; Hershko E, 2019, OPT EXPRESS, V27, P6158, DOI 10.1364/OE.27.006158; Hess ST, 2006, BIOPHYS J, V91, P4258, DOI 10.1529/biophysj.106.091116; Horstmeyer R., 2017, ARXIV170907223; Huang B, 2008, SCIENCE, V319, P810, DOI 10.1126/science.1153529; Juette MF, 2008, NAT METHODS, V5, P527, DOI 10.1038/nmeth.1211; Kay S. M., 1993, FUNDAMENTALS STAT SI; Kellman M, 2019, IEEE INT CONF COMPUT; Kim K., 2020, ARXIV200615404; King DB, 2015, ACS SYM SER, V1214, P1; Krull A, 2019, PROC CVPR IEEE, P2124, DOI 10.1109/CVPR.2019.00223; Leveque O, 2020, OPT EXPRESS, V28, P32426, DOI 10.1364/OE.402752; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Levin A, 2010, LECT NOTES COMPUT SC, V6311, P214, DOI 10.1007/978-3-642-15549-9_16; Lew MD, 2011, OPT LETT, V36, P202, DOI 10.1364/OL.36.000202; Lim S, 2020, IEEE T COMPUT IMAG, V6, P1127, DOI 10.1109/TCI.2020.3006735; Louis B, 2020, OPT EXPRESS, V28, P28656, DOI 10.1364/OE.401557; Lumsdaine A., 2009, IEEE INT C COMPUTATI, P1; Metzler CA, 2020, PROC CVPR IEEE, P1372, DOI 10.1109/CVPR42600.2020.00145; Min J, 2014, BIOMED OPT EXPRESS, V5, P3935, DOI 10.1364/BOE.5.003935; Mockl L, 2020, BIOMED OPT EXPRESS, V11, P1633, DOI 10.1364/BOE.386361; Muthumbi A, 2019, BIOMED OPT EXPRESS, V10, P6351, DOI 10.1364/BOE.10.006351; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; Nehme E, 2020, NAT METHODS, V17, P734, DOI 10.1038/s41592-020-0853-5; Nehme E, 2018, OPTICA, V5, P458, DOI 10.1364/OPTICA.5.000458; Ober RJ, 2004, BIOPHYS J, V86, P1185, DOI 10.1016/S0006-3495(04)74193-4; Odena A, 2016, DISTILL, DOI [10.23915/distill.00003.-URL, 10.23915/distill.00003]; Ongie Gregory, 2020, IEEE Journal on Selected Areas in Information Theory, V1, P39, DOI 10.1109/JSAIT.2020.2991563; Ouyang W, 2018, NAT BIOTECHNOL, V36, P460, DOI 10.1038/nbt.4106; Ovesny M, 2014, BIOINFORMATICS, V30, P2389, DOI 10.1093/bioinformatics/btu202; Pavani SRP, 2009, P NATL ACAD SCI USA, V106, P2995, DOI 10.1073/pnas.0900245106; Pinkard H, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22246-5; Ram S, 2008, BIOPHYS J, V95, P6025, DOI 10.1529/biophysj.108.140392; Rivenson Y, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/lsa.2017.141; Rivenson Y, 2017, OPTICA, V4, P1437, DOI 10.1364/OPTICA.4.001437; Roider C, 2014, OPT EXPRESS, V22, P4029, DOI 10.1364/OE.22.004029; Rust MJ, 2006, NAT METHODS, V3, P793, DOI 10.1038/nmeth929; Sage D, 2019, NAT METHODS, V16, P387, DOI 10.1038/s41592-019-0364-4; Schechner YY, 1996, PHYS REV E, V54, pR50, DOI 10.1103/PhysRevE.54.R50; Schwartz E, 2019, IEEE T IMAGE PROCESS, V28, P912, DOI 10.1109/TIP.2018.2872858; Shechtman Y, 2016, NAT PHOTONICS, V10, P590, DOI 10.1038/nphoton.2016.137; Shechtman Y, 2015, NANO LETT, V15, P4194, DOI 10.1021/acs.nanolett.5b01396; Shechtman Y, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.133902; Shen KL, 2020, WORLD J PEDIATR, V16, P219, DOI 10.1007/s12519-020-00344-6; Siemons M, 2018, OPT EXPRESS, V26, P8397, DOI 10.1364/OE.26.008397; Sitzmann V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201333; Smith C, 2016, OPT EXPRESS, V24, P4996, DOI 10.1364/OE.24.004996; Speiser A., 2019, TEACHING DEEP NEURAL; Sun QL, 2020, PROC CVPR IEEE, P1383, DOI 10.1109/CVPR42600.2020.00146; Takeda Y, 2013, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2013.34; Nguyen T, 2018, OPT EXPRESS, V26, P26470, DOI 10.1364/OE.26.026470; Toprak E, 2006, P NATL ACAD SCI USA, V103, P6495, DOI 10.1073/pnas.0507134103; Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520; von Diezmann A, 2017, CHEM REV, V117, P7244, DOI 10.1021/acs.chemrev.6b00629; Weigert M, 2018, NAT METHODS, V15, P1090, DOI 10.1038/s41592-018-0216-7; Weiss LE, 2018, BIOCHEM SOC T, V46, P729, DOI 10.1042/BST20170301; Wronski B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323024; Xue YJ, 2019, OPTICA, V6, P618, DOI [10.1364/OPTICA.6.000618, 10.1364/optica.6.000618]; Yu F., 2016, ABS151107122 CORR; Zada D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08806-w; Zhou CY, 2009, IEEE I CONF COMP VIS, P325, DOI 10.1109/ICCV.2009.5459268; Zhou CY, 2011, INT J COMPUT VISION, V93, P53, DOI 10.1007/s11263-010-0409-8	93	8	8	3	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2179	2192		10.1109/TPAMI.2021.3076873	http://dx.doi.org/10.1109/TPAMI.2021.3076873			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	34029185				2022-12-18	WOS:000692540900002
J	Deng, C; Zhang, YL; Mao, YF; Fan, JT; Suo, JL; Zhang, ZL; Dai, QH				Deng, Chao; Zhang, Yuanlong; Mao, Yifeng; Fan, Jingtao; Suo, Jinli; Zhang, Zhili; Dai, Qionghai			Sinusoidal Sampling Enhanced Compressive Camera for High Speed Imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Encoding; Image reconstruction; Cameras; Image coding; Frequency modulation; Frequency-domain analysis; Compressive sensing; compressive video; computational imaging; image processing; video processing; sinusoidal coding; high-speed video		Compressive sensing technique allows capturing fast phenomena at a much higher frame rate than the camera sensor, by recovering a frame sequence from their encoded combination. However, most conventional compressive video sensing methods limit the achieved frame rate improvement to tenfold and only support low resolution recovery. Making use of the camera's redundant spatial resolution for further frame rate improve, here we report a novel compressive video acquisition technique termed Sinusoidal Sampling Enhanced Compressive Camera (S2EC2) to encode denser frames within a snapshot. Specifically, we decompose the dense frames into groups and apply combinational coding: random codes within each group for compressive acquisition; group specific sinusoidal codes to multiplex different groups onto the high resolution sensor. The sinusoidal codes designed for these groups would shift their frequency components by different offsets in the Fourier domain and staggered the dominant frequencies of the coded measurements of these groups. Correspondingly, the reconstruction successfully separate coded measurements of different groups and recovers frames within each group. Besides, we also solve the implementation problem of insufficient gray scale spatial light modulation speed, and build a prototype achieving 2000 fps reconstruction with a 15.6 fps camera (the actual compression ratio is 0.009). The extensive experiments validate the proposed approach.	[Deng, Chao; Zhang, Yuanlong; Mao, Yifeng; Fan, Jingtao; Suo, Jinli; Dai, Qionghai] Tsinghua Univ, Beijing Key Lab Multidimens & Multiscale Computat, Dept Automat, Inst Brain & Cognit Sci, Beijing 100084, Peoples R China; [Zhang, Zhili] High Tech Inst Xian, Xian 710025, Peoples R China	Tsinghua University	Suo, JL (corresponding author), Tsinghua Univ, Beijing Key Lab Multidimens & Multiscale Computat, Dept Automat, Inst Brain & Cognit Sci, Beijing 100084, Peoples R China.	deng-c15@mails.tsinghua.edu.cn; ylzhang16@mails.tsinghua.edu.cn; myf@mails.tsinghua.edu.cn; fanjingtao@tsinghua.edu.cn; jlsuo@tsinghua.edu.cn; 157918018@qq.com; qhdai@tsinghua.edu.cn	Dai, Qionghai/ABD-5298-2021; Demg, Chao/AAH-3834-2021	Dai, Qionghai/0000-0001-7043-3061; Fan, Jingtao/0000-0003-4817-4141; Zhang, Yuanlong/0000-0003-3725-1973	National Science Foundation of China [61722110, 61631009, 61627804]	National Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported by the National Science Foundation of China (grant Nos. 61722110, 61631009 and 61627804).	Bian LH, 2016, J OPTICS-UK, V18, DOI 10.1088/2040-8978/18/8/085704; Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Chakrabarti A, 2011, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2011.5995660; Chen HJ, 2015, PROC CVPR IEEE, P2358, DOI 10.1109/CVPR.2015.7298849; Cossairt O, 2013, IEEE T IMAGE PROCESS, V22, P447, DOI 10.1109/TIP.2012.2216538; Deng Y., 2013, ARTIFICIAL INTELLIGE, V427, P345, DOI 10.1007/978-3-642-29694-9_14; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Dorozynska K, 2017, OPT EXPRESS, V25, P17211, DOI 10.1364/OE.25.017211; Feng W, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030331; FLOYD RW, 1976, P SID, V17, P75; de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004; Gao L, 2014, NATURE, V516, P74, DOI 10.1038/nature14005; Goldstein T, 2015, IEEE T IMAGE PROCESS, V24, P5581, DOI 10.1109/TIP.2015.2474697; Gupta M, 2010, LECT NOTES COMPUT SC, V6311, P100, DOI 10.1007/978-3-642-15549-9_8; Hitomi Y, 2011, IEEE I CONF COMP VIS, P287, DOI 10.1109/ICCV.2011.6126254; Iliadis M, 2018, DIGIT SIGNAL PROCESS, V72, P9, DOI 10.1016/j.dsp.2017.09.010; Koller R, 2015, OPT EXPRESS, V23, P15992, DOI 10.1364/OE.23.015992; Liao XJ, 2014, SIAM J IMAGING SCI, V7, P797, DOI 10.1137/130936658; Liu DY, 2014, IEEE T PATTERN ANAL, V36, P248, DOI 10.1109/TPAMI.2013.129; Llull P, 2013, OPT EXPRESS, V21, P10526, DOI 10.1364/OE.21.010526; Mudry E, 2012, NAT PHOTONICS, V6, P312, DOI [10.1038/NPHOTON.2012.83, 10.1038/nphoton.2012.83]; Portz T, 2013, IEEE INT CONF COMPUT; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Reddy D, 2011, PROC CVPR IEEE, P329, DOI 10.1109/CVPR.2011.5995542; Rubin Michael, 2008, EFFICIENT IMPLEMENTA, P1; Sankaranarayanan A. C., 2012, P IEEE INT C COMP PH, P1, DOI DOI 10.1109/ICCPHOT.2012.6215212; Shu XB, 2011, IEEE I CONF COMP VIS, P439, DOI 10.1109/ICCV.2011.6126273; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Tsai TH, 2015, OPT LETT, V40, P4054, DOI 10.1364/OL.40.004054; Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520; Veeraraghavan A, 2011, IEEE T PATTERN ANAL, V33, P671, DOI 10.1109/TPAMI.2010.87; Wetzstein G, 2013, INT J COMPUT VISION, V101, P384, DOI 10.1007/s11263-012-0585-9; Xu K, 2018, IEEE WINT CONF APPL, P1680, DOI 10.1109/WACV.2018.00187; Yang JB, 2014, IEEE T IMAGE PROCESS, V23, P4863, DOI 10.1109/TIP.2014.2344294; Yuan X, 2014, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2014.424; Zhang YL, 2018, OPT EXPRESS, V26, P6929, DOI 10.1364/OE.26.006929; Zhang ZB, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12228-3; Zhang ZB, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms7225; Zheng GA, 2013, NAT PHOTONICS, V7, P739, DOI [10.1038/NPHOTON.2013.187, 10.1038/nphoton.2013.187]	40	8	9	9	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1380	1393		10.1109/TPAMI.2019.2946567	http://dx.doi.org/10.1109/TPAMI.2019.2946567			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31603813				2022-12-18	WOS:000626525300020
J	Dai, LQ; Tang, JH				Dai, Longquan; Tang, Jinhui			iFlowGAN: An Invertible Flow-Based Generative Adversarial Network for Unsupervised Image-to-Image Translation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Flow, bijection; unsupervised image-to-image translation; banach fixed point theorem		We propose iFlowGAN that learns an invertible flow (a sequence of invertible mappings) via adversarial learning and exploit it to transform a source distribution into a target distribution for unsupervised image-to-image translation. Existing GAN-based generative model such as CycleGAN [1], StarGAN [2], AGGAN [3] and CyCADA [4] needs to learn a highly under-constraint forward mapping F : X -> Y from a source domain X to a target domain Y. Researchers do this by assuming there is a backward mapping B : Y -> X such that x and y are fixed points of the composite functions B omicron F and F omicron B. Inspired by zero-order reverse filtering [5], we (1) understand F via contraction mappings on a metric space; (2) provide a simple yet effective algorithm to present B via the parameters of F in light of Banach fixed point theorem; (3) provide a Lipschitz-regularized network which indicates a general approach to compose the inverse for arbitrary Lipschitz-regularized networks via Banach fixed point theorem. This network is useful for image-to-image translation tasks because it could save the memory for the weights of B. Although memory can also be saved by directly coupling the weights of the forward and backward mappings, the performance of the image-to-image translation network degrades significantly. This explains why current GAN-based generative models including CycleGAN must take different parameters to compose the forward and backward mappings instead of employing the same weights to build both mappings. Taking advantage of the Lipschitz-regularized network, we not only build iFlowGAN to solve the redundancy shortcoming of CycleGAN but also assemble the corresponding iFlowGAN versions of StarGAN, AGGAN and CyCADA without breaking their network architectures. Extensive experiments show that the iFlowGAN version could produce comparable results of the original implementation while saving half parameters.	[Dai, Longquan; Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China	Nanjing University of Science & Technology	Tang, JH (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.	dailongquan@njust.edu.cn; jinhuitang@njust.edu.cn		Tang, Jinhui/0000-0001-9008-222X	National Key Research and Development Program of China [2018AAA0102002]; National Natural Science Foundation of China [61925204, 62072238]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0102002, and the National Natural Science Foundation of China under Grants 61925204 and 62072238.	Arjovsky M, 2017, PR MACH LEARN RES, V70; Behrmann J, 2019, PR MACH LEARN RES, V97; Benaim S, 2017, ADV NEUR IN, V30; Brock A., 2018, ARXIV 180911096; Carl V., 2016, ADV NEURAL INFORM PR, V29, P613, DOI DOI 10.13016/M26GIH-TNYZ; Chang B, 2018, AAAI CONF ARTIF INTE, P2811; Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168; Chen R. T., 2018, ADV NEURAL INFORM PR, P6571; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; Deco G., 1995, Advances in Neural Information Processing Systems 7, P247; Dinh L., 2015, ARXIV 14108516; Dinh L., 2017, ARXIV 160508803; Farnia F., 2019, ARXIV181107457; FEDERER H., 1969, GEOMETRIC MEASURE TH, V153, DOI [10.1007/978-3-642-62010-2, DOI 10.1007/978-3-642-62010-2]; Finlay C., 2019, ARXIV 181000953; Gomez Aidan N, 2017, ADV NEURAL INFORM PR, P2214; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gouk H, 2021, MACH LEARN, V110, P393, DOI 10.1007/s10994-020-05929-w; Gouk H, 2019, LECT NOTES ARTIF INT, V11051, P541, DOI 10.1007/978-3-030-10925-7_33; Grover A, 2018, AAAI CONF ARTIF INTE, P3069; Gulrajani I, 2017, P NIPS 2017; Haber E, 2018, INVERSE PROBL, V34, DOI 10.1088/1361-6420/aa9a90; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hensel M, 2017, ADV NEUR IN, V30; Hoffman J, 2018, PR MACH LEARN RES, V80; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jacobsen J orn-Henrik, 2018, P ICLR; Kim T, 2017, PR MACH LEARN RES, V70; Kingma DP, 2018, ADV NEUR IN, V31; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li C., 2018, PR MACH LEARN RES, P824; Liu MY, 2017, ADV NEUR IN, V30; Liu Ming-Yu, 2016, ADV NEURAL INFORM PR, P2; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Mejjati YA, 2018, ADV NEUR IN, V31; Netzer Y., 2011, NIPS WORKSH DEEP LEA, P14; Oberman A. M., 2018, ARXIV 180809540; Ochs P, 2018, LECT NOTES COMPUT SC, V11205, P53, DOI 10.1007/978-3-030-01246-5_4; Perarnau G., 2016, ARXIV 161106355; Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Tao X, 2017, IEEE I CONF COMP VIS, P222, DOI 10.1109/ICCV.2017.33; Tsuzuku Y., 2018, ARXIV 180204034; Tylecek R, 2013, LECT NOTES COMPUT SC, V8142, P364, DOI 10.1007/978-3-642-40602-7_39; van den Berg R., 2018, ARXIV 180305649; van der Ouderaa TFA, 2019, PROC CVPR IEEE, P4715, DOI 10.1109/CVPR.2019.00485; Wei X., 2018, P ICLR; Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31; Yoshida Y., 2017, ARXIV 170510941; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40; Zhou ZM, 2019, PR MACH LEARN RES, V97; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zou D., 2018, ARXIV 180801415	58	8	8	2	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 2	2021	44	8					4151	4162		10.1109/TPAMI.2021.3062849	http://dx.doi.org/10.1109/TPAMI.2021.3062849			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HV	33651682				2022-12-18	WOS:000820522500001
J	Khan, A; Maji, P				Khan, Aparajita; Maji, Pradipta			Approximate Graph Laplacians for Multimodal Data Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Laplace equations; Clustering algorithms; Cancer; Approximation algorithms; Eigenvalues and eigenfunctions; Perturbation methods; Noise measurement; Integrative clustering; low-rank approximation; graph Laplacian; spectral clustering; multi-view learning; matrix perturbation theory		One of the important approaches of handling data heterogeneity in multimodal data clustering is modeling each modality using a separate similarity graph. Information from the multiple graphs is integrated by combining them into a unified graph. A major challenge here is how to preserve cluster information while removing noise from individual graphs. In this regard, a novel algorithm, termed as CoALa, is proposed that integrates noise-free approximations of multiple similarity graphs. The proposed method first approximates a graph using the most informative eigenpairs of its Laplacian which contain cluster information. The approximate Laplacians are then integrated for the construction of a low-rank subspace that best preserves overall cluster information of multiple graphs. However, this approximate subspace differs from the full-rank subspace which integrates information from all the eigenpairs of each Laplacian. Matrix perturbation theory is used to theoretically evaluate how far approximate subspace deviates from the full-rank one for a given value of approximation rank. Finally, spectral clustering is performed on the approximate subspace to identify the clusters. Experimental results on several real-life cancer and benchmark data sets demonstrate that the proposed algorithm significantly and consistently outperforms state-of-the-art integrative clustering approaches.	[Khan, Aparajita; Maji, Pradipta] Indian Stat Inst, Machine Intelligence Unit, Biomed Imaging & Bioinformat Lab, Kolkata 700108, W Bengal, India	Indian Statistical Institute; Indian Statistical Institute Kolkata	Maji, P (corresponding author), Indian Stat Inst, Machine Intelligence Unit, Biomed Imaging & Bioinformat Lab, Kolkata 700108, W Bengal, India.	aparajitak_r@isical.ac.in; pmaji@isical.ac.in	Maji, Pradipta/HHR-9037-2022; Khan, Aparajita/AAN-9513-2020	Khan, Aparajita/0000-0003-0415-9070	Visvesvaraya PhD Scheme of Ministry of Electronics and Information Technology, Government of India	Visvesvaraya PhD Scheme of Ministry of Electronics and Information Technology, Government of India	The publication is an outcome of the R&D work undertaken in the project under the Visvesvaraya PhD Scheme of Ministry of Electronics and Information Technology, Government of India, being implemented by Digital India Corporation.	Bass AJ, 2014, NATURE, V513, P202, DOI 10.1038/nature13480; BJORCK A, 1973, MATH COMPUT, V27, P579, DOI 10.2307/2005662; Brat DJ, 2015, NEW ENGL J MED, V372, P2481, DOI 10.1056/NEJMoa1402121; Chalise P, 2014, TRANSL CANCER RES, V3, P202, DOI 10.3978/j.issn.2218-676X.2014.06.03; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; DAVIS C, 1970, SIAM J NUMER ANAL, V7, P1, DOI 10.1137/0707001; Dhanjal C, 2014, NEUROCOMPUTING, V131, P440, DOI 10.1016/j.neucom.2013.11.015; Djelouah A, 2015, IEEE T PATTERN ANAL, V37, P1890, DOI 10.1109/TPAMI.2014.2385704; Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367; Feng Q, 2018, J MULTIVARIATE ANAL, V166, P241, DOI 10.1016/j.jmva.2018.03.008; FIEDLER M, 1975, CZECH MATH J, V25, P619; Fukui K, 2015, IEEE T PATTERN ANAL, V37, P2164, DOI 10.1109/TPAMI.2015.2408358; Greene D., 2013, P WEBSCI 2013, P1; Hasin Y, 2017, GENOME BIOL, V18, DOI 10.1186/s13059-017-1215-1; Hoadley KA, 2014, CELL, V158, P929, DOI 10.1016/j.cell.2014.06.049; Huang J, 2016, FRONT GENET, V7, DOI [10.3389/fgene.2016.00084, 10.3389/fgene.2017.00084]; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Khan A, 2020, IEEE ACM T COMPUT BI, V17, P1290, DOI 10.1109/TCBB.2019.2894635; Knyazev A. V, 2012, TR2012058 MITS EL RE; Koboldt DC, 2012, NATURE, V490, P61, DOI 10.1038/nature11412; Kumar A., 2011, ADV NEURAL INFORM PR, P1413; Li J, 2017, IEEE T IMAGE PROCESS, V26, P3113, DOI 10.1109/TIP.2017.2651379; Lin YY, 2011, IEEE T PATTERN ANAL, V33, P1147, DOI 10.1109/TPAMI.2010.183; Liu XW, 2019, IEEE T PATTERN ANAL, V41, P2410, DOI 10.1109/TPAMI.2018.2879108; Lock EF, 2013, BIOINFORMATICS, V29, P2610, DOI 10.1093/bioinformatics/btt425; Lock EF, 2013, ANN APPL STAT, V7, P523, DOI 10.1214/12-AOAS597; Long B., 2008, P 8 SIAM INT C DAT M, DOI DOI 10.1137/1.9781611972788.74; Maila M, 2001, P AI STAT AISTATS JA; Meila M, 2001, ADV NEUR IN, V13, P873; Mo QX, 2013, P NATL ACAD SCI USA, V110, P4245, DOI 10.1073/pnas.1208949110; Mohar B, 1991, GRAPH THEORY COMBINA, V2, P12; Ng AY, 2002, ADV NEUR IN, V14, P849; Pepik B, 2015, IEEE T PATTERN ANAL, V37, P2232, DOI 10.1109/TPAMI.2015.2408347; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Shen RL, 2009, BIOINFORMATICS, V25, P2906, DOI 10.1093/bioinformatics/btp543; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Speicher NK, 2015, BIOINFORMATICS, V31, P268, DOI 10.1093/bioinformatics/btv244; Spielman DA, 2007, LINEAR ALGEBRA APPL, V421, P284, DOI 10.1016/j.laa.2006.07.020; Stewart G., 1990, MATRIX PERTURBATION; SUN JG, 1987, J COMPUT MATH, V5, P58; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wagner D., 1993, Mathematical Foundations of Computer Science 1993. 18th International Symposium, MFCS '93 Proceedings, P744; Wang B, 2014, NAT METHODS, V11, P333, DOI [10.1038/NMETH.2810, 10.1038/nmeth.2810]; Wu DM, 2015, BMC GENOMICS, V16, DOI 10.1186/s12864-015-2223-8; Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566; Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528; Zhang W, 2013, CELL REP, V4, P542, DOI 10.1016/j.celrep.2013.07.010; Zhang ZY, 2017, IEEE T PATTERN ANAL, V39, P1675, DOI 10.1109/TPAMI.2016.2601608; Zhou D., 2007, P 24 INT C MACHINE L, P1159, DOI DOI 10.1145/1273496.1273642	50	8	8	4	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					798	813		10.1109/TPAMI.2019.2945574	http://dx.doi.org/10.1109/TPAMI.2019.2945574			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31603770				2022-12-18	WOS:000616309900004
J	Lee, JY; Park, RH				Lee, Jae Young; Park, Rae-Hong			Complex-Valued Disparity: Unified Depth Model of Depth from Stereo, Depth from Focus, and Depth from Defocus Based on the Light Field Gradient	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Estimation; Light fields; Signal processing; Analytical models; Benchmark testing; Taxonomy; Solid modeling; Unified depth model; depth estimation; disparity; complex-valued disparity; depth from stereo; depth from focus; depth from defocus; Lambertian; in-focus plane; light field; gradient; spatial gradient; angular gradient		This paper proposes a unified depth model based on the light field gradient, in which estimated disparity is represented by the complex number. The complex-valued disparity by the proposed depth model can be represented in both the Cartesian and polar coordinates. In the Cartesian representation, the proposed depth model is represented by real and imaginary parts of the disparity. The real part can be used for disparity estimation with respect to the in-focus plane, whereas the imaginary part represents the non-Lambertian-ness. In the polar representation, the proposed depth model is expressed by the disparity magnitude and disparity angle. The disparity magnitude shows the relationship among depth from stereo, depth from focus, and depth from defocus, whereas the disparity angle shows whether or not the bundles of rays are flipped with respect to the in-focus plane. For disparity analysis, we present the real response, imaginary response, magnitude response, and angle response, which are represented by the three-dimensional volume. Experimental results on synthetic and real light field images show that the real and magnitude responses of the proposed depth model are valid for local disparity estimation.	[Lee, Jae Young; Park, Rae-Hong] Sogang Univ, Sch Engn, Dept Elect Engn, 35 Baekbeom Ro, Seoul 04107, South Korea	Sogang University	Park, RH (corresponding author), Sogang Univ, Sch Engn, Dept Elect Engn, 35 Baekbeom Ro, Seoul 04107, South Korea.	mcneato@sognag.ac.kr; rhpark@sogang.ac.kr	Park, Rae-Hong/Q-7955-2019	Park, Rae-Hong/0000-0002-4792-2980; Lee, Jae Young/0000-0002-7450-5023	Brain Korea 21 Plus	Brain Korea 21 Plus	This work was supported by the Brain Korea 21 Plus.	ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783; Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197; Cichocki A, 2015, IEEE SIGNAL PROC MAG, V32, P145, DOI 10.1109/MSP.2013.2297439; Dansereau D, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P549; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fitch A. J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P133; Hanrahan P., 2005, CSTR200502 STANFORDU; Heber S, 2017, IEEE I CONF COMP VIS, P2271, DOI 10.1109/ICCV.2017.247; Honauer K, 2017, LECT NOTES COMPUT SC, V10113, P19, DOI 10.1007/978-3-319-54187-7_2; Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156; Huang CT, 2017, IEEE I CONF COMP VIS, P11, DOI 10.1109/ICCV.2017.11; Jeon HG, 2019, IEEE T PATTERN ANAL, V41, P297, DOI 10.1109/TPAMI.2018.2794979; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Johannsen O, 2017, IEEE COMPUT SOC CONF, P1795, DOI 10.1109/CVPRW.2017.226; Johannsen O, 2016, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2016.355; Lee JY, 2018, IEEE SIGNAL PROC LET, V25, P1750, DOI 10.1109/LSP.2018.2874304; Lee JY, 2017, IEEE J-STSP, V11, P955, DOI 10.1109/JSTSP.2017.2747154; Lee JY, 2017, APPL OPTICS, V56, P1069, DOI 10.1364/AO.56.001069; Levoy M, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.270; Lin HT, 2015, IEEE I CONF COMP VIS, P3451, DOI 10.1109/ICCV.2015.394; Navarro J, 2017, IEEE T IMAGE PROCESS, V26, P1873, DOI 10.1109/TIP.2017.2666041; Pertuz S, 2013, PATTERN RECOGN, V46, P1415, DOI 10.1016/j.patcog.2012.11.011; Raj A., 2016, STANFORD LYTRO LIGHT; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Schechner YY, 2000, INT J COMPUT VISION, V39, P141, DOI 10.1023/A:1008175127327; Schilling H, 2018, PROC CVPR IEEE, P4530, DOI 10.1109/CVPR.2018.00476; Sheng H, 2018, PATTERN RECOGN, V74, P587, DOI 10.1016/j.patcog.2017.09.010; Shin C, 2018, PROC CVPR IEEE, P4748, DOI 10.1109/CVPR.2018.00499; Si L., 2016, P AS C COMP VIS, P83; Strecke M, 2017, PROC CVPR IEEE, P2529, DOI 10.1109/CVPR.2017.271; SUBBARAO M, 1994, INT J COMPUT VISION, V13, P271, DOI 10.1007/BF02028349; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Tosic I, 2014, IEEE COMPUT SOC CONF, P441, DOI 10.1109/CVPRW.2014.71; Wang TC, 2016, IEEE T PATTERN ANAL, V38, P2170, DOI 10.1109/TPAMI.2016.2515615; Wanner S., 2013, VISION MODELING VISU, P225, DOI DOI 10.2312/PE.VMV.VMV13.225-226; Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147; Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656; Williem, 2018, J VIS COMMUN IMAGE R, V56, P38, DOI 10.1016/j.jvcir.2018.08.015; Williem, 2018, IEEE T PATTERN ANAL, V40, P2484, DOI 10.1109/TPAMI.2017.2746858; Williem, 2016, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2016.476; Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126; Zhang S, 2016, COMPUT VIS IMAGE UND, V145, P148, DOI 10.1016/j.cviu.2015.12.007; Zhou CY, 2011, IEEE T IMAGE PROCESS, V20, P3322, DOI 10.1109/TIP.2011.2171700; Zhu H, 2017, IEEE J-STSP, V11, P965, DOI 10.1109/JSTSP.2017.2730818	45	8	8	3	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					830	841		10.1109/TPAMI.2019.2946159	http://dx.doi.org/10.1109/TPAMI.2019.2946159			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31603811				2022-12-18	WOS:000616309900006
J	Wu, A; Han, YH; Zhu, LC; Yang, Y				Wu, Aming; Han, Yahong; Zhu, Linchao; Yang, Yi			Instance-Invariant Domain Adaptive Object Detection Via Progressive Disentanglement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Object detection; Training; Task analysis; Optimization; Proposals; Adaptation models; Domain adaptive object detection; progressive disentanglement; detached optimization; instance-invariant features		Most state-of-the-art methods of object detection suffer from poor generalization ability when the training and test data are from different domains. To address this problem, previous methods mainly explore to align distribution between source and target domains, which may neglect the impact of the domain-specific information existing in the aligned features. Besides, when transferring detection ability across different domains, it is important to extract the instance-level features that are domain-invariant. To this end, we explore to extract instance-invariant features by disentangling the domain-invariant features from the domain-specific features. Particularly, a progressive disentangled mechanism is proposed to decompose domain-invariant and domain-specific features, which consists of a base disentangled layer and a progressive disentangled layer. Then, with the help of Region Proposal Network (RPN), the instance-invariant features are extracted based on the output of the progressive disentangled layer. Finally, to enhance the disentangled ability, we design a detached optimization to train our model in an end-to-end fashion. Experimental results on four domain-shift scenes show our method is separately 2.3, 3.6, 4.0, and 2.0 percent higher than the baseline method. Meanwhile, visualization analysis demonstrates that our model owns well disentangled ability.	[Wu, Aming; Han, Yahong] Tianjin Univ, Tianjin Key Lab Machine Learning, Coll Intelligence & Comp, Tianjin 300387, Peoples R China; [Han, Yahong] Peng Cheng Lab, Shenzhen 518066, Peoples R China; [Zhu, Linchao; Yang, Yi] Univ Technol Sydney, ReLER Lab, AAAI, Sch Comp Sci, Sydney, NSW 2007, Australia	Tianjin University; Peng Cheng Laboratory; University of Technology Sydney	Han, YH (corresponding author), Tianjin Univ, Tianjin Key Lab Machine Learning, Coll Intelligence & Comp, Tianjin 300387, Peoples R China.	tjwam@tju.edu.cn; yahong@tju.edu.cn; Linchao.Zhu@uts.edu.au; yi.yang@uts.edu.au	yang, yang/GWB-9426-2022; Yang, Yi/B-9273-2017; yang, yang/GVT-5210-2022; yang, yang/HGT-7999-2022	Yang, Yi/0000-0002-0512-880X; 	NSFC [61876130, 61932009, 61925602, 61732011, ARCDP200100938]	NSFC(National Natural Science Foundation of China (NSFC))	This work was supported by the NSFC under Grants 61876130, 61932009, 61925602, and 61732011. The work of Linchao Zhu and Yi Yangwas supported by ARCDP200100938.	Belghazi MI, 2018, PR MACH LEARN RES, V80; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Cai Q, 2019, PROC CVPR IEEE, P11449, DOI 10.1109/CVPR.2019.01172; Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516; Chen XY, 2019, PR MACH LEARN RES, V97; Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352; Cicek S, 2019, IEEE I CONF COMP VIS, P1416, DOI 10.1109/ICCV.2019.00150; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Do K., 2020, PROC INT C LEARN REP, P1; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gong R, 2019, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2019.00258; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He ZW, 2019, IEEE I CONF COMP VIS, P6667, DOI 10.1109/ICCV.2019.00677; Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378; Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11; Inoue N, 2018, PROC CVPR IEEE, P5001, DOI 10.1109/CVPR.2018.00525; Kim S, 2019, IEEE I CONF COMP VIS, P6091, DOI 10.1109/ICCV.2019.00619; Kim T, 2019, PROC CVPR IEEE, P12448, DOI 10.1109/CVPR.2019.01274; Kurmi VK, 2019, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2019.00058; Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053; Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3; Lee S, 2019, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2019.00018; Li HY, 2019, INT J COMPUT VISION, V127, P225, DOI 10.1007/s11263-018-1101-7; Li W, 2018, IEEE T PATTERN ANAL, V40, P1114, DOI 10.1109/TPAMI.2017.2704624; Li YS, 2019, PROC CVPR IEEE, P6929, DOI 10.1109/CVPR.2019.00710; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu YC, 2018, PROC CVPR IEEE, P8867, DOI 10.1109/CVPR.2018.00924; Locatello F, 2019, PR MACH LEARN RES, V97; Luo Z., 2017, P NIPS, P165; Pan Y., ARXIV 191003548; Pan YW, 2019, PROC CVPR IEEE, P2234, DOI 10.1109/CVPR.2019.00234; Peng XC, 2019, PR MACH LEARN RES, V97; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ridgeway K, 2018, ADV NEUR IN, V31; Russo P, 2018, PROC CVPR IEEE, P8099, DOI 10.1109/CVPR.2018.00845; Saito K, 2019, PROC CVPR IEEE, P6949, DOI 10.1109/CVPR.2019.00712; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Saito K, 2017, PR MACH LEARN RES, V70; Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8; Scott TR, 2018, ADV NEUR IN, V31; Simonyan K., 2014, 3 INT C LEARN REPR I; Sutskever I., 2013, P 30 INT C MACH LEAR, P1139, DOI DOI 10.1007/S00287-015-0911-Z; Vasconcelos N., 2019, PROC IEEE C COMPUT V, P5424; Wang T, 2019, PROC CVPR IEEE, P7166, DOI 10.1109/CVPR.2019.00734; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Xie RC, 2019, IEEE INT CONF COMP V, P3213, DOI 10.1109/ICCVW.2019.00401; Xudong Wang, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7281, DOI 10.1109/CVPR.2019.00746; Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271; Zhang WC, 2018, PROC CVPR IEEE, P3801, DOI 10.1109/CVPR.2018.00400; Zhang YB, 2019, PROC CVPR IEEE, P5026, DOI 10.1109/CVPR.2019.00517; Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609; Zhou JTY, 2019, J MACH LEARN RES, V20; Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953	59	8	8	13	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 24	2021	44	8					4178	4193		10.1109/TPAMI.2021.3060446	http://dx.doi.org/10.1109/TPAMI.2021.3060446			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HY	33625976	Green Submitted			2022-12-18	WOS:000820522800001
J	Ren, WQ; Zhang, JW; Pan, JS; Liu, SF; Ren, JS; Du, JP; Cao, XC; Yang, MH				Ren, Wenqi; Zhang, Jiawei; Pan, Jinshan; Liu, Sifei; Ren, Jimmy S.; Du, Junping; Cao, Xiaochun; Yang, Ming-Hsuan			Deblurring Dynamic Scenes via Spatially Varying Recurrent Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel; Dynamics; Heuristic algorithms; Motion segmentation; Image segmentation; Image restoration; Estimation; Spatially varying blur; dynamic scene deblurring; recurrent neural network	BLUR	Deblurring images captured in dynamic scenes is challenging as the motion blurs are spatially varying caused by camera shakes and object movements. In this paper, we propose a spatially varying neural network to deblur dynamic scenes. The proposed model is composed of three deep convolutional neural networks (CNNs) and a recurrent neural network (RNN). The RNN is used as a deconvolution operator on feature maps extracted from the input image by one of the CNNs. Another CNN is used to learn the spatially varying weights for the RNN. As a result, the RNN is spatial-aware and can implicitly model the deblurring process with spatially varying kernels. To better exploit properties of the spatially varying RNN, we develop both one-dimensional and two-dimensional RNNs for deblurring. The third component, based on a CNN, reconstructs the final deblurred feature maps into a restored image. In addition, the whole network is end-to-end trainable. Quantitative and qualitative evaluations on benchmark datasets demonstrate that the proposed method performs favorably against the state-of-the-art deblurring algorithms.	[Ren, Wenqi; Cao, Xiaochun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China; [Cao, Xiaochun] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100049, Peoples R China; [Cao, Xiaochun] Cyberspace Secur Res Ctr, Peng Cheng Lab, Shenzhen 518055, Guangdong, Peoples R China; [Zhang, Jiawei; Ren, Jimmy S.] SenseTime Reasearch, Shenzhen 518000, Peoples R China; [Ren, Jimmy S.] Shanghai Jiao Tong Univ, Qing Yuan Res Inst, Shanghai 200240, Peoples R China; [Pan, Jinshan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China; [Liu, Sifei] NVIDIA Learning & Percept, Santa Clara, CA 95051 USA; [Du, Junping] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China; [Yang, Ming-Hsuan] Univ Calif, Merced, CA 95344 USA; [Yang, Ming-Hsuan] Yonsei Univ, Seoul, South Korea	Chinese Academy of Sciences; Institute of Information Engineering, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Peng Cheng Laboratory; Shanghai Jiao Tong University; Nanjing University of Science & Technology; Beijing University of Posts & Telecommunications; University of California System; University of California Merced; Yonsei University	Cao, XC (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.; Cao, XC (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100049, Peoples R China.; Cao, XC (corresponding author), Cyberspace Secur Res Ctr, Peng Cheng Lab, Shenzhen 518055, Guangdong, Peoples R China.; Zhang, JW (corresponding author), SenseTime Reasearch, Shenzhen 518000, Peoples R China.	renwenqi@iie.ac.cn; zhjw1988@gmail.com; sdluran@gmail.com; sifeil@nvidia.com; jimmy.sj.ren@gmail.com; junpingd@bupt.edu.cn; caoxiaochun@iie.ac.cn; mhyang@ucmerced.edu	Liu, Sifei/AGE-1968-2022	Liu, Sifei/0000-0002-6011-3686	National Key R&D Program of China [2019YFB1406500]; National Natural Science Foundation of China [62025604, 61772083, 61802403, U1803264, U1736219]; Beijing Municipal Education Commission Cooperation Beijing Natural Science Foundation [KZ201910005007]; Beijing Nova Program [Z201100006820074]; Beijing Association for Science and Technology; Youth Innovation Promotion Association CAS; Peng Cheng Laboratory Project of Guangdong Province [PCL2018KP004]; National Science Foundation CAREER [1149783]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Municipal Education Commission Cooperation Beijing Natural Science Foundation; Beijing Nova Program(Beijing Municipal Science & Technology Commission); Beijing Association for Science and Technology; Youth Innovation Promotion Association CAS; Peng Cheng Laboratory Project of Guangdong Province; National Science Foundation CAREER(National Science Foundation (NSF))	This work was supported in part by the National Key R&D Program of China under Grant 2019YFB1406500, the National Natural Science Foundation of China under Grants 62025604, 61772083, 61802403, U1803264, U1736219, Beijing Municipal Education Commission Cooperation Beijing Natural Science Foundation under Grant KZ201910005007, Beijing Nova Program under Grant Z201100006820074, Elite Scientist Sponsorship Program by the Beijing Association for Science and Technology, Youth Innovation Promotion Association CAS, Peng Cheng Laboratory Project of Guangdong Province PCL2018KP004. M.-H. Yang is supported in part by the National Science Foundation CAREER Grant 1149783. Wenqi Ren, Jiawei Zhang contributed equally to this work.	Bar L, 2007, IEEE I CONF COMP VIS, P1410; BIEMOND J, 1990, P IEEE, V78, P856, DOI 10.1109/5.53403; Cai JR, 2020, IEEE T IMAGE PROCESS, V29, P6885, DOI 10.1109/TIP.2020.2995048; Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P1302, DOI 10.1109/TIP.2015.2400217; Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14; Cheng XJ, 2020, IEEE T PATTERN ANAL, V42, P2361, DOI [10.1109/TPAMI.2019.2947374, 10.5194/isprs-archives-XLII-3-W7-1-2019]; Cho S, 2007, IEEE I CONF COMP VIS, P596; Cho S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185560; Gao HY, 2019, PROC CVPR IEEE, P3843, DOI 10.1109/CVPR.2019.00397; Gong D., 2018, ARXIV 180403368; Gong D, 2017, PROC CVPR IEEE, P3806, DOI 10.1109/CVPR.2017.405; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Gorinevsky D, 2005, IEEE DECIS CONTR P, P615; Hradi M., 2015, BRIT MACH VIS C; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang P, 2018, ADV NEUR IN, V31; Kim TH, 2018, IEEE T PATTERN ANAL, V40, P2374, DOI 10.1109/TPAMI.2017.2761348; Kim TH, 2015, PROC CVPR IEEE, P5426, DOI 10.1109/CVPR.2015.7299181; Kim TH, 2013, IEEE I CONF COMP VIS, P3160, DOI 10.1109/ICCV.2013.392; Kim TH, 2014, PROC CVPR IEEE, P2766, DOI 10.1109/CVPR.2014.348; Kingma D.P., 2015, INT C LEARN REPR, P1; Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521; Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897; Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li YP, 2010, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2010.5539938; Liu SC, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1557, DOI 10.1145/3097983.3098011; Liu SF, 2016, LECT NOTES COMPUT SC, V9908, P560, DOI 10.1007/978-3-319-46493-0_34; Lu BY, 2019, PROC CVPR IEEE, P10217, DOI 10.1109/CVPR.2019.01047; Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141; Mildenhall B, 2018, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2018.00265; Nah S, 2019, IEEE COMPUT SOC CONF, P1974, DOI 10.1109/CVPRW.2019.00249; Nah S, 2019, PROC CVPR IEEE, P8094, DOI 10.1109/CVPR.2019.00829; Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35; Noroozi M, 2017, LECT NOTES COMPUT SC, V10496, P65, DOI 10.1007/978-3-319-66709-6_6; Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180; Pan JS, 2016, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2016.56; Proakis J.G., 1996, DIGIT SIGNAL PROCESS, V3; Ren DW, 2021, IEEE T PATTERN ANAL, V43, P284, DOI 10.1109/TPAMI.2019.2926357; Ren JS., 2015, ADV NEURAL INF PROCE, V1, P901; Ren W., 2018, PROC ADV NEURAL INF, P295; Ren WQ, 2017, IEEE I CONF COMP VIS, P1086, DOI 10.1109/ICCV.2017.123; Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418; Schuler CJ, 2013, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2013.142; Shan Q, 2007, IEEE I CONF COMP VIS, P738; Shen Z., 2018, PROC IEEE C COMPUT V, P1302; Shen ZY, 2019, IEEE I CONF COMP VIS, P5571, DOI 10.1109/ICCV.2019.00567; Shi XJ, 2015, ADV NEUR IN, V28; Sim H, 2019, IEEE COMPUT SOC CONF, P2140, DOI 10.1109/CVPRW.2019.00267; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Svoboda P, 2016, IEEE IMAGE PROC, P3832, DOI 10.1109/ICIP.2016.7533077; Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222; Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Wiener N., 1949, EXTRAPOLATION SMOOTH; Wu Junru, 2020, P IEEE WINT C APPL C, P2376; Wulff J, 2014, LECT NOTES COMPUT SC, V8694, P236, DOI 10.1007/978-3-319-10599-4_16; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Xu XY, 2018, LECT NOTES COMPUT SC, V11213, P36, DOI 10.1007/978-3-030-01240-3_3; Zhana HC, 2015, PROC CVPR IEEE, P4036, DOI 10.1109/CVPR.2015.7299030; Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613; Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267; Zhang JW, 2017, PROC CVPR IEEE, P6969, DOI 10.1109/CVPR.2017.737; Zhang KH, 2020, PROC CVPR IEEE, P2734, DOI 10.1109/CVPR42600.2020.00281; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	69	8	8	8	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 23	2021	44	8					3974	3987		10.1109/TPAMI.2021.3061604	http://dx.doi.org/10.1109/TPAMI.2021.3061604			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HN	33621173				2022-12-18	WOS:000820521700001
J	Liu, GC; Liu, QS; Yuan, XT; Wang, M				Liu, Guangcan; Liu, Qingshan; Yuan, Xiao-Tong; Wang, Meng			Matrix Completion with Deterministic Sampling: Theories and Methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Coherence; Tools; Automation; Information science; Two dimensional displays; Probabilistic logic; Data models; Matrix completion; deterministic sampling; identifiability; isomeric condition; relative well-conditionedness; Schatten quasi-norm; bilinear programming		In some significant applications such as data forecasting, the locations of missing entries cannot obey any non-degenerate distributions, questioning the validity of the prevalent assumption that the missing data is randomly chosen according to some probabilistic model. To break through the limits of random sampling, we explore in this paper the problem of real-valued matrix completion under the setup of deterministic sampling. We propose two conditions, isomeric condition and relative well-conditionedness, for guaranteeing an arbitrary matrix to be recoverable from a sampling of the matrix entries. It is provable that the proposed conditions are weaker than the assumption of uniform sampling and, most importantly, it is also provable that the isomeric condition is necessary for the completions of any partial matrices to be identifiable. Equipped with these new tools, we prove a collection of theorems for missing data recovery as well as convex/nonconvex matrix completion. Among other things, we study in detail a Schatten quasi-norm induced method termed isomeric dictionary pursuit (IsoDP), and we show that IsoDP exhibits some distinct behaviors absent in the traditional bilinear programs.	[Liu, Guangcan; Liu, Qingshan; Yuan, Xiao-Tong] Nanjing Univ Informat Sci & Technol, Sch Automat, B DAT, Nanjing 210044, Peoples R China; [Liu, Guangcan; Yuan, Xiao-Tong] Nanjing Univ Informat Sci & Technol, Sch Automat, CICAEET, Nanjing 210044, Peoples R China; [Wang, Meng] Hefei Univ Technol, Sch Comp Sci & Informat Engn, 193 Tunxi Rd, Hefei 230009, Anhui, Peoples R China	Nanjing University of Information Science & Technology; Nanjing University of Information Science & Technology; Hefei University of Technology	Liu, GC (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Automat, B DAT, Nanjing 210044, Peoples R China.; Liu, GC (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Automat, CICAEET, Nanjing 210044, Peoples R China.	gcliu@nuist.edu.cn; qsliu@nuist.edu.cn; xtyuan@nuist.edu.cn; eric.mengwang@gmail.com	Liu, Qing/GWC-9222-2022; liu, qingqing/HHD-0360-2022		national Natural Science Foundation of China (NSFC) [61622305, 61532009, 61725203, 71490725]; Natural Science Foundation of Jiangsu Province of China (NSFJPC) [BK20160040]	national Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Jiangsu Province of China (NSFJPC)(Natural Science Foundation of Jiangsu Province)	This work is supported in part national Natural Science Foundation of China (NSFC) under Grant 61622305, Grant 61532009, Grant 61725203 and Grant 71490725, in part by Natural Science Foundation of Jiangsu Province of China (NSFJPC) under Grant BK20160040, in part by SenseTime Research Fund.	[Anonymous], 2016, ADV NEURAL INFORM PR; Attouch H, 2009, MATH PROGRAM, V116, P5, DOI 10.1007/s10107-007-0133-5; Bishop W. E., 2014, ADV NEURAL INF PROCE, P2762; Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061; Candes EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Chen YD, 2015, J MACH LEARN RES, V16, P2999; Chen YD, 2015, IEEE T INFORM THEORY, V61, P2909, DOI 10.1109/TIT.2015.2415195; CHISTOV AL, 1984, LECT NOTES COMPUT SC, V176, P17; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872; Keshavan RH, 2010, IEEE T INFORM THEORY, V56, P2980, DOI 10.1109/TIT.2010.2046205; Kiraly F., 2012, P INT C MACH LEARN, P2056; Kiraly FJ, 2015, J MACH LEARN RES, V16, P1391; Lee T., 2013, ADV NEURAL INFORM PR, P1781; Liu G, 2017, ADV NEURAL INFORM PR, P785; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2016, IEEE T SIGNAL PROCES, V64, P5623, DOI 10.1109/TSP.2016.2586753; Liu GC, 2016, IEEE T PATTERN ANAL, V38, P417, DOI 10.1109/TPAMI.2015.2453969; Liu GC, 2014, IEEE T IMAGE PROCESS, V23, P5047, DOI 10.1109/TIP.2014.2362055; Mazumder R, 2010, J MACH LEARN RES, V11, P2287; Meka R., 2009, ADV NEURAL INFORM PR, P1258; Mohan K, 2010, IEEE INT SYMP INFO, P1573, DOI 10.1109/ISIT.2010.5513471; Negahban S, 2012, J MACH LEARN RES, V13, P1665; Netrapalli P., 2014, P ADV NEUR INF PROC, P1107; Pimentel-Alarcon DL, 2016, IEEE J-STSP, V10, P623, DOI 10.1109/JSTSP.2016.2537145; Recht B, 2008, IEEE DECIS CONTR P, P3065, DOI 10.1109/CDC.2008.4739332; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Rockafellar R. T., 1970, CONVEX ANAL; Shang FH, 2016, AAAI CONF ARTIF INTE, P2016; Srebro N., 2010, PROC INT C NEURAL IN, P2056; STEWART GW, 1969, SIAM J APPL MATH, V17, P33, DOI 10.1137/0117004; Sun RY, 2016, IEEE T INFORM THEORY, V62, P6535, DOI 10.1109/TIT.2016.2598574; Xu C, 2017, AAAI CONF ARTIF INTE, P926; Xu H, 2012, IEEE T INFORM THEORY, V58, P3047, DOI 10.1109/TIT.2011.2173156; ZHANG Y, 2006, TR0615 CAAM RIC U; Zheng YQ, 2012, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2012.6247828	43	8	8	3	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					549	566		10.1109/TPAMI.2019.2937869	http://dx.doi.org/10.1109/TPAMI.2019.2937869			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31478840	Green Submitted			2022-12-18	WOS:000607383300011
J	Zhou, P; Yuan, XT; Yan, SC; Feng, JS				Zhou, Pan; Yuan, Xiao-Tong; Yan, Shuicheng; Feng, Jiashi			Faster First-Order Methods for Stochastic Non-Convex Optimization on Riemannian Manifolds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimization; Complexity theory; Manifolds; Convergence; Signal processing algorithms; Stochastic processes; Minimization; Riemannian optimization; stochastic variance-reduced algorithm; non-convex optimization; online learning		First-order non-convex Riemannian optimization algorithms have gained recent popularity in structured machine learning problems including principal component analysis and low-rank matrix completion. The current paper presents an efficient Riemannian Stochastic Path Integrated Differential EstimatoR (R-SPIDER) algorithm to solve the finite-sum and online Riemannian non-convex minimization problems. At the core of R-SPIDER is a recursive semi-stochastic gradient estimator that can accurately estimate Riemannian gradient under not only exponential mapping and parallel transport, but also general retraction and vector transport operations. Compared with prior Riemannian algorithms, such a recursive gradient estimation mechanism endows R-SPIDER with lower computational cost in first-order oracle complexity. Specifically, for finite-sum problems with n components, R-SPIDER is proved to converge to an epsilon-approximate stationary point within O(min(n + root n/epsilon(2),1/epsilon(3))) stochastic gradient evaluations, beating the best-known complexity O(n+1/epsilon(4)); for online optimization, R-SPIDER is shown to converge with O(1/epsilon(3)) complexity which is, to the best of our knowledge, the first non-asymptotic result for online Riemannian optimization. For the special case of gradient dominated functions, we further develop a variant of R-SPIDER with improved linear rate of convergence. Extensive experimental results demonstrate the advantage of the proposed algorithms over the state-of-the-art Riemannian non-convex optimization methods.	[Zhou, Pan; Yan, Shuicheng; Feng, Jiashi] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore; [Yuan, Xiao-Tong] Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China	National University of Singapore; Nanjing University of Information Science & Technology	Yuan, XT (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China.	pzhou@u.nus.edu; xtyuan1980@gmail.com; eleyans@nus.edu.sg; elefjia@nus.edu.sg	Feng, Jiashi/AGX-6209-2022; Yan, Shuicheng/HCI-1431-2022		NUS [R-263-000-C67-646]; ECRA [R-263-000-C87-133]; MOE Tier-II [R-263-000-D17-112]; Natural Science Foundation of China (NSFC) [61876090]	NUS(National University of Singapore); ECRA; MOE Tier-II; Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	Jiashi Feng was partially supported by NUS IDS R-263-000-C67-646, ECRA R-263-000-C87-133 and MOE Tier-II R-263-000-D17-112. Xiao-Tong Yuan is supported by Natural Science Foundation of China (NSFC) under Grant 61876090.	Absil PA, 2012, SIAM J OPTIMIZ, V22, P135, DOI 10.1137/100802529; Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Adler RL, 2002, IMA J NUMER ANAL, V22, P359, DOI 10.1093/imanum/22.3.359; [Anonymous], 2018, P INT C MACH LEARN; [Anonymous], 1998, BALK J GEOM APPL; Badeau R, 2005, IEEE T SIGNAL PROCES, V53, P2931, DOI 10.1109/TSP.2005.850378; Bonnabel S, 2013, IEEE T AUTOMAT CONTR, V58, P2217, DOI 10.1109/TAC.2013.2254619; Boumal Nicolas, 2014, THESIS UCLOUVAIN CAT; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Cherian A, 2017, IEEE T NEUR NET LEAR, V28, P2859, DOI 10.1109/TNNLS.2016.2601307; Courbariaux M, 2015, P WORKSH INT C LEARN; De Sa C., 2018, ARXIV180303383; Fang C., 2018, ADV NEURAL INFORM PR, P689; FRANCIS J, 1961, COMPUT J, V4, P265, DOI 10.1093/comjnl/4.3.265; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Hosseini R., 2015, ADV NEURAL INFORM PR, P910; Huang W, 2015, SIAM J OPTIMIZ, V25, P1660, DOI 10.1137/140955483; Huang W, 2015, MATH PROGRAM, V150, P179, DOI 10.1007/s10107-014-0765-1; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Johnson R., 2013, ADV NEURAL INF PROCE, V26, P315, DOI DOI 10.5555/2999611.2999647; Karimi H., 2016, JOINT EUROPEAN C MAC, P795; Kasai H., 2018, PROC 21 INT C ARTIF, V84, P269; Kasai H., 2016, ARXIV160507367; Kasai H, 2016, PR MACH LEARN RES, V48; Liu Y., 2017, ADV NEURAL INFORM PR, P4868; Martinez A., 1998, 24 CVC, P24; Meyer Gilles, 2011, P INT C MACH LEARN, P545; Mishra B, 2014, IEEE DECIS CONTR P, P1137, DOI 10.1109/CDC.2014.7039534; Nesterov Y., 2006, INTRO LECT CONVEX OP; Nesterov Y, 2006, MATH PROGRAM, V108, P177, DOI 10.1007/s10107-006-0706-8; Nguyen L., 2018, P INT C MACH LEARN, P2613; Nguyen L. M., 2017, ARXIV170507261; OJA E, 1992, NEURAL NETWORKS, V5, P927, DOI 10.1016/S0893-6080(05)80089-9; Park H, 2018, ARXIV181005486; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shen J., 2017, J MACH LEARN RES, V18, P7650; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Tan MK, 2014, PR MACH LEARN RES, V32, P1539; Udriste Constantin, 1994, CONVEX FUNCTIONS OPT, V297; Vandereycken B, 2013, SIAM J OPTIMIZ, V23, P1214, DOI 10.1137/110845768; Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1; WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9; Zhang H., 2016, P C LEARN THEOR, P1617; Zhang Hongyi, 2016, ADV NEURAL INFORM PR, V29, P4592; Zhang J., 2018, ARXIV181104194; Zhou D., 2018, P 32 INT C NEUR INF, P3925; Zhou P., 2018, P ADV NEURAL INFORM, P1988; Zhou P., 2018, P C NEUTR INF PROC S, P1242; Zhou P., 2017, P IEEE C COMP VIS PA, P1; Zhou P, 2019, PR MACH LEARN RES, V89, P138; Zhou P, 2018, IEEE T IMAGE PROCESS, V27, P1152, DOI 10.1109/TIP.2017.2762595; Zhou P, 2018, NEUROCOMPUTING, V273, P414, DOI 10.1016/j.neucom.2017.07.041; Zhou P, 2017, IEEE T IMAGE PROCESS, V26, P1173, DOI 10.1109/TIP.2016.2623487	56	8	8	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					459	472		10.1109/TPAMI.2019.2933841	http://dx.doi.org/10.1109/TPAMI.2019.2933841			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31398110	Green Submitted			2022-12-18	WOS:000607383300007
J	Fan, QN; Chen, DD; Yuan, L; Hua, G; Yu, NH; Chen, BQ				Fan, Qingnan; Chen, Dongdong; Yuan, Lu; Hua, Gang; Yu, Nenghai; Chen, Baoquan			A General Decoupled Learning Framework for Parameterized Image Operators	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image processing and computer vision; filtering; restoration; smoothing	SPARSE; SUPERRESOLUTION	Many different deep networks have been used to approximate, accelerate or improve traditional image operators. Among these traditional operators, many contain parameters which need to be tweaked to obtain the satisfactory results, which we refer to as "parameterized image operators". However, most existing deep networks trained for these operators are only designed for one specific parameter configuration, which does not meet the needs of real scenarios that usually require flexible parameters settings. To overcome this limitation, we propose a new decoupled learning algorithm to learn from the operator parameters to dynamically adjust the weights of a deep network for image operators, denoted as the base network. The learned algorithm is formed as another network, namely the weight learning network, which can be end-to-end jointly trained with the base network. Experiments demonstrate that the proposed framework can be successfully applied to many traditional parameterized image operators. To accelerate the parameter tuning for practical scenarios, the proposed framework can be further extended to dynamically change the weights of only one single layer of the base network while sharing most computation cost. We demonstrate that this cheap parameter-tuning extension of the proposed decoupled learning framework even outperforms the state-of-the-art alternative approaches.	[Fan, Qingnan] Stanford Univ, Comp Sci Dept, Stanford, CA 94305 USA; [Chen, Dongdong; Yu, Nenghai] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Anhui, Peoples R China; [Yuan, Lu] Microsoft Res, Redmond, WA 98052 USA; [Hua, Gang] Wormpex AI Res, Bellevue, WA 98004 USA; [Chen, Baoquan] Peking Univ, Beijing 100871, Peoples R China	Stanford University; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Microsoft; Peking University	Fan, QN (corresponding author), Stanford Univ, Comp Sci Dept, Stanford, CA 94305 USA.	fqnchina@gmail.com; cd722522@mail.ustc.edu.cn; luyuan@microsoft.com; ganghua@gmail.com; ynh@ustc.edu.cn; baoquan@pku.edu.cn		Chen, Dongdong/0000-0002-4642-4373; Fan, Qingnan/0000-0003-1249-2826	National 973 Program [2015CB352501]; NSFC-ISF [61561146397]; Natural Science Foundation of China [U1636201, 61629301]	National 973 Program(National Basic Research Program of China); NSFC-ISF; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by: National 973 Program (2015CB352501), NSFC-ISF (61561146397), the Natural Science Foundation of China under Grant U1636201 and 61629301. Qingnan Fan and Dongdong Chen are co-first authors of this paper.	Andrychowicz M, 2016, ADV NEUR IN, V29; Aubry M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629645; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Chen QF, 2017, IEEE I CONF COMP VIS, P2516, DOI 10.1109/ICCV.2017.273; Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Fan QN, 2017, IEEE I CONF COMP VIS, P3258, DOI 10.1109/ICCV.2017.351; Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666; Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186; Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802; Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; Guo B, 2017, CHIN CONTR CONF, P7488, DOI 10.23919/ChiCC.2017.8028539; Ha David, 2017, ICLR; Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Liu SF, 2016, LECT NOTES COMPUT SC, V9908, P560, DOI 10.1007/978-3-319-46493-0_34; Lu C., 2012, P S NONPHOTOREALISTI, P65; SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P131, DOI 10.1162/neco.1992.4.1.131; Su F, 2016, 2016 16TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P280, DOI 10.1109/ISCIT.2016.7751636; Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; Tipping M.E., 2003, ADV NEURAL INFORM PR, V15, P1303; Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437; Wichrowska O, 2017, PR MACH LEARN RES, V70; Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI [10.1109/TIP.2016.2621478, 10.1109/TIP.2017.2689999]; Xu L, 2012, ACM T GRAPHIC, V31; Xu L, 2015, PR MACH LEARN RES, V37, P1669; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Yang Hong-Kai, 2016, Nanomaterials (Basel), V6, DOI 10.3390/nano6110203; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yu F., 2016, P ICLR 2016; ZHANG K, 2017, PROC CVPR IEEE, P2808, DOI DOI 10.1109/CVPR.2017.300; Zhang Q, 2014, PROC CVPR IEEE, P2830, DOI 10.1109/CVPR.2014.362; Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53	42	8	8	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					33	47		10.1109/TPAMI.2019.2925793	http://dx.doi.org/10.1109/TPAMI.2019.2925793			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31265384	Green Submitted			2022-12-18	WOS:000597206900003
J	Arnab, A; Miksik, O; Torr, PHS				Arnab, Anurag; Miksik, Ondrej; Torr, Philip H. S.			On the Robustness of Semantic Segmentation Models to Adversarial Attacks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Adversarial attacks; semantic segmentation; deep learning; convolutional neural networks; machine learning security	NETWORKS	Deep Neural Networks (DNNs) have demonstrated exceptional performance on most recognition tasks such as image classification and segmentation. However, they have also been shown to be vulnerable to adversarial examples. This phenomenon has recently attracted a lot of attention but it has not been extensively studied on multiple, large-scale datasets and structured prediction tasks such as semantic segmentation which often require more specialised networks with additional components such as CRFs, dilated convolutions, skip-connections and multiscale processing. In this paper, we present what to our knowledge is the first rigorous evaluation of adversarial attacks on modern semantic segmentation models, using two large-scale datasets. We analyse the effect of different network architectures, model capacity and multiscale processing, and show that many observations made on the task of classification do not always transfer to this more complex task. Furthermore, we show how mean-field inference in deep structured models, multiscale processing (and more generally, input transformations) naturally implement recently proposed adversarial defenses. Our observations will aid future efforts in understanding and defending against adversarial examples. Moreover, in the shorter term, we show how to effectively benchmark robustness and show which segmentation models should currently be preferred in safety-critical applications due to their inherent robustness.	[Arnab, Anurag; Miksik, Ondrej; Torr, Philip H. S.] Univ Oxford, Oxford OX1 2JD, England	University of Oxford	Arnab, A (corresponding author), Univ Oxford, Oxford OX1 2JD, England.	anurag.arnab@eng.ox.ac.uk; ondrej.miksik@eng.ox.ac.uk; philip.torr@eng.ox.ac.uk			EPSRC; Clarendon Fund; ERC [ERC-2012-AdG 321162-HELIOS]; EPSRC [Seebibyte EP/M013774/1]; EPSRC/MURI [EP/N019474/1]; EPSRC [EP/N019474/1, EP/M013774/1] Funding Source: UKRI	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Clarendon Fund; ERC(European Research Council (ERC)European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC/MURI(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by the EPSRC, Clarendon Fund, ERC grant ERC-2012-AdG 321162-HELIOS, EPSRC grant Seebibyte EP/M013774/1 and EPSRC/MURI grant EP/N019474/1. We would also like to acknowledge the Royal Academy of Engineering and FiveAI.	[Anonymous], 2012, P 29 INT COFERENCE I; [Anonymous], 2015, ICLR; Arnab A, 2018, PROC CVPR IEEE, P888, DOI 10.1109/CVPR.2018.00099; Arnab A, 2018, IEEE SIGNAL PROC MAG, V35, P37, DOI 10.1109/MSP.2017.2762355; Arnab A, 2016, LECT NOTES COMPUT SC, V9906, P524, DOI 10.1007/978-3-319-46475-6_33; Athalye A, 2018, PR MACH LEARN RES, V80; Athalye A, 2018, PR MACH LEARN RES, V80; Athalye Anish, 2018, ARXIV180403286; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; Bengio Yoshua, 2013, ARXIV; Biggio B., 2013, JOINT EUR C MACH LEA, P387, DOI DOI 10.1007/978-3-642-40994-3_25; Brown Tom B, 2017, ARXIV171209665; Buckman J., 2018, ARXIVE PRINTS; Bunel R, 2018, ADV NEUR IN, V31; Carbonetto P., 2007, P INT C NEUR INF PRO, P201; Carlini N., 2016, ARXIV160704311V1; Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49; Chalupka K, 2015, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P181; Chandra S, 2016, LECT NOTES COMPUT SC, V9911, P402, DOI 10.1007/978-3-319-46478-7_25; Chen L.-C., 2015, COMPUT SCI; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Cisse M, 2017, PR MACH LEARN RES, V70; Cisse Moustapha, 2017, P ADV NEUR INF PROC; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Cubuk E. D., 2018, P INT C LEARN REPR; Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191; Dalvi N, 2004, 10 ACM SIGKDD INT C, DOI DOI 10.1145/1014052.1014066; Dziugaite G. K., 2016, ARXIV160800853V1; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175; Fawzi A., 2015, P BRIT MACH VIS C; Feinman R., 2017, ARXIV170300410V2; Fischer V., 2017, P INT C LEARN REPR W; Forsyth David A., 1996, FINDING PICTURES OBJ; Gao J., 2017, P INT C LEARN REPR W; Goodfellow I. J., 2015, INT C LEARN REPR ICL; Grosse K., 2017, ARXIV170206280V1; Gu S., 2015, P INT C LEARN REPR W; Guo C., 2018, P INT C LEARN REPR; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He Wenjian, 2017, 2017 54 ACMEDACIEEE, P1; Henriques JF, 2017, PR MACH LEARN RES, V70; Janai J, 2020, FOUND TRENDS COMPUT, V12, P1, DOI 10.1561/0600000079; Katz G, 2017, LECT NOTES COMPUT SC, V10426, P97, DOI 10.1007/978-3-319-63387-9_5; Kerckhoffs A., 1883, J DES SCI MILITARIES, V9, P5; Koh PW, 2017, PR MACH LEARN RES, V70; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kurakin A., 2017, P INT C LEARN REPR W; Kurakin A, 2019, 5 INT C LEARNING REP, P1; Liao FZ, 2018, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR.2018.00191; Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu H, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P1, DOI 10.1109/INTMAG.2017.8007847; Lu J., 2017, ARXIV171003337V1; Lu J., 2017, P IEEE C COMP VIS PA, P1; Madry A., 2018, P INT C LEARN REPR; Metzen J. H., 2017, P INT C LEARN REPR; Metzen JH, 2017, IEEE I CONF COMP VIS, P2774, DOI 10.1109/ICCV.2017.300; Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17; Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Narodytska N, 2017, IEEE COMPUT SOC CONF, P1310, DOI 10.1109/CVPRW.2017.172; Papernot N., 2016, ARXIV160507277V1; Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41; Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36; Paszke A., 2016, ARXIV160602147V1; Pepik B, 2015, LECT NOTES COMPUT SC, V9358, P517, DOI 10.1007/978-3-319-24947-6_43; Prakash A, 2018, PROC CVPR IEEE, P8571, DOI 10.1109/CVPR.2018.00894; Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Simonyan K., 2015, INT C LEARN REPR ICL; Song Y, 2019, P COMBUST INST, V37, P667, DOI 10.1016/j.proci.2018.06.115; Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy Christian, 2014, PROC 2 INT C LEARN R; Tramonti F, 2019, PSYCHOL HEALTH MED, V24, P27, DOI 10.1080/13548506.2018.1510131; Uesato J, 2018, PR MACH LEARN RES, V80; Xie C., 2018, P INT C LEARN REPR; Xie CH, 2017, IEEE I CONF COMP VIS, P1378, DOI 10.1109/ICCV.2017.153; Xu WL, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23198; Xu XJ, 2018, PROC CVPR IEEE, P4951, DOI 10.1109/CVPR.2018.00520; Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179	90	8	8	4	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2020	42	12					3040	3053		10.1109/TPAMI.2019.2919707	http://dx.doi.org/10.1109/TPAMI.2019.2919707			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OP2KH	31150338	Green Submitted			2022-12-18	WOS:000587912800006
J	Zanca, D; Melacci, S; Gori, M				Zanca, Dario; Melacci, Stefano; Gori, Marco			Gravitational Laws of Focus of Attention	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Computational modeling; Mathematical model; Task analysis; Brightness; Predictive modeling; Gravity; Visual attention; eye movements; scanpath prediction; saliency; gravitational laws	EYE-MOVEMENTS; VISUAL-ATTENTION; MODEL; SALIENCY; MICROSACCADES; VISION	The understanding of the mechanisms behind focus of attention in a visual scene is a problem of great interest in visual perception and computer vision. In this paper, we describe a model of scanpath as a dynamic process which can be interpreted as a variational law somehow related to mechanics, where the focus of attention is subject to a gravitational field. The distributed virtual mass that drives eye movements is associated with the presence of details and motion in the video. Unlike most current models, the proposed approach does not estimate directly the saliency map, but the prediction of eye movements allows us to integrate over time the positions of interest. The process of inhibition-of-return is also supported in the same dynamic model with the purpose of simulating fixations and saccades. The differential equations of motion of the proposed model are numerically integrated to simulate scanpaths on both images and videos. Experimental results for the tasks of saliency and scanpath prediction on a wide collection of datasets are presented to support the theory. Top level performances are achieved especially in the prediction of scanpaths, which is the primary purpose of the proposed model.	[Zanca, Dario; Melacci, Stefano; Gori, Marco] Univ Siena, Dept Informat Engn & Math, I-53100 Siena, SI, Italy	University of Siena	Melacci, S (corresponding author), Univ Siena, Dept Informat Engn & Math, I-53100 Siena, SI, Italy.	dario.zanca@unifi.it; mela@diism.unisi.it; marco@dii.unisi.it		ZANCA, DARIO/0000-0001-5886-0597				BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237; Betti A., 2018, CORR; Borji A., 2015, CORR; Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Brandt SA, 1997, J COGNITIVE NEUROSCI, V9, P27, DOI 10.1162/jocn.1997.9.1.27; Bruce N., 2010, J VISION, V7, P950, DOI [10.1167/7.9.950, DOI 10.1167/7.9.950]; Bylinskii Z., 2016, MIT SALIENCY BENCHMA; Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601; Cerf M, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P143, DOI 10.1145/1344471.1344508; CHOI YS, 1995, OPTOMETRY VISION SCI, V72, P439, DOI 10.1097/00006324-199507000-00003; Collewijn H, 2008, J VISION, V8, DOI 10.1167/8.14.20; Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174; Coutrot A, 2013, P 2013 14 INT WORKSH, P1; Dalmaijer ES, 2014, BEHAV RES METHODS, V46, P913, DOI 10.3758/s13428-013-0422-2; DUPONT P, 1994, J NEUROPHYSIOL, V72, P1420, DOI 10.1152/jn.1994.72.3.1420; Elgammal A., 2000, COMPUTER VISION ECCV, P751, DOI [10.1007/3-540-45053-X_48, DOI 10.1007/3-540-45053-X_48]; Farneback G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50; Foulsham T, 2008, J VISION, V8, DOI 10.1167/8.2.6; Garcia-Diaz A, 2012, J VISION, V12, DOI 10.1167/12.6.17; Harel J, 2006, SALIENCY IMPLEMENTAT; Hirschmuller H., 2002, 2002 7th International Conference on Control, Automation, Robotics and Vision (IEEE Cat. No.02EX649), P1099; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Itti L, 2005, PROC CVPR IEEE, P631; Itti L, 2005, VIS COGN, V12, P1093, DOI 10.1080/13506280444000661; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007; Jiang M, 2016, IEEE T NEUR NET LEAR, V27, P1241, DOI 10.1109/TNNLS.2015.2496306; Judd T., 2012, MIT CSAIL TR; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Jurafsky D., 2014, SPEECH LANGUAGE PROC, V3; Ko HK, 2010, NAT NEUROSCI, V13, P1549, DOI 10.1038/nn.2663; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Kootstra G, 2011, COGN COMPUT, V3, P223, DOI 10.1007/s12559-010-9089-5; Kowler E., 2009, ENCY NEUROSCIENCE, P605; Krauzlis R. J., 2013, FUNDAMENTAL NEUROSCI, P697, DOI [DOI 10.1016/B978-0-12-385870-2.00032-9, 10.1016/B978-0-12-385870-2.00032-9]; Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620; Kummerer Matthias, 2016, ARXIV161001563; Le Meur O, 2015, VISION RES, V116, P152, DOI 10.1016/j.visres.2014.12.026; Lee TS, 2000, ADV NEUR IN, V12, P834; Liu HY, 2013, IEEE I CONF COMP VIS, P3232, DOI 10.1109/ICCV.2013.401; Martinez-Conde S, 2013, NAT REV NEUROSCI, V14, P83, DOI 10.1038/nrn3405; Mathe S, 2013, ADV NEURAL INFORM PR, P1923; POSNER MI, 1985, COGNITIVE NEUROPSYCH, V2, P211, DOI 10.1080/02643298508252866; Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372; Renninger Laura Walker, 2005, Adv Neural Inf Process Syst, V17, P1121; SCHLINGENSIEPEN KH, 1986, VISION RES, V26, P1111, DOI 10.1016/0042-6989(86)90045-3; Sunaert S, 1999, EXP BRAIN RES, V127, P355, DOI 10.1007/s002210050804; Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; TYNAN PD, 1982, VISION RES, V22, P61, DOI 10.1016/0042-6989(82)90167-5; Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358; Wang W, 2011, PROC CVPR IEEE, P441, DOI 10.1109/CVPR.2011.5995423; Zanca D., 2018, CORR; Zanca D, 2017, ADV NEUR IN, V30; Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992	56	8	8	3	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2020	42	12					2983	2995		10.1109/TPAMI.2019.2920636	http://dx.doi.org/10.1109/TPAMI.2019.2920636			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	OP2KH	31180885				2022-12-18	WOS:000587912800002
J	Wang, FD; Xue, N; Zhang, YP; Xia, GS; Pelillo, M				Wang, Fu-Dong; Xue, Nan; Zhang, Yipeng; Xia, Gui-Song; Pelillo, Marcello			A Functional Representation for Graph Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Strain; Linear programming; Time complexity; Measurement; Optimization; Pattern matching; Graph matching; functional representation; Frank-Wolfe method; geometric deformation	ALGORITHM	Graph matching is an important and persistent problem in computer vision and pattern recognition for finding node-to-node correspondence between graphs. However, graph matching that incorporates pairwise constraints can be formulated as a quadratic assignment problem (QAP), which is NP-complete and results in intrinsic computational difficulties. This paper presents a functional representation for graph matching (FRGM) that aims to provide more geometric insights on the problem and reduce the space and time complexities. To achieve these goals, we represent each graph by a linear function space equipped with a functional such as inner product or metric, that has an explicit geometric meaning. Consequently, the correspondence matrix between graphs can be represented as a linear representation map. Furthermore, this map can be reformulated as a new parameterization for matching graphs in Euclidean space such that it is consistent with graphs under rigid or nonrigid deformations. This allows us to estimate the correspondence matrix and geometric deformations simultaneously. We use the representation of edge-attributes rather than the affinity matrix to reduce the space complexity and propose an efficient optimization strategy to reduce the time complexity. The experimental results on both synthetic and real-world datasets show that the FRGM can achieve state-of-the-art performance.	[Wang, Fu-Dong; Xue, Nan] Wuhan Univ, State Key Lab LIESMARS, Wuhan 430079, Peoples R China; [Zhang, Yipeng] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China; [Xia, Gui-Song] Wuhan Univ, LIESMARS, State Key Lab, Sch Comp Sci, Wuhan 430079, Peoples R China; [Pelillo, Marcello] Ca Foscari Univ Venice, Comp Vis Lab, I-30172 Venice, Italy	Wuhan University; Wuhan University; Wuhan University; Universita Ca Foscari Venezia	Xia, GS (corresponding author), Wuhan Univ, LIESMARS, State Key Lab, Sch Comp Sci, Wuhan 430079, Peoples R China.	fudong-wang@whu.edu.cn; xuenan@whu.edu.cn; zyp91@whu.edu.cn; guisong.xia@whu.edu.cn; pelillo@unive.it	Xue, Nan/HCI-0300-2022	Xue, Nan/0000-0002-5449-8073; Xia, Gui-Song/0000-0001-7660-6090	National Natural Science Foundation of China [61771350, 61842102]; Outstanding Youth Project of Hubei Province [2017CFA037]; China Scholarship Council	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Outstanding Youth Project of Hubei Province; China Scholarship Council(China Scholarship Council)	This work was supported by the National Natural Science Foundation of China under Grant 61771350 and Grant 61842102, and partially supported by the Outstanding Youth Project of Hubei Province under Contract 2017CFA037. Nan Xue is also supported by China Scholarship Council.	Adamczewski K, 2015, IEEE I CONF COMP VIS, P109, DOI 10.1109/ICCV.2015.21; [Anonymous], 2012, INT J COMPUT VISION, DOI DOI 10.1007/s11263-011-0442-2; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bredies K, 2009, COMPUT OPTIM APPL, V42, P173, DOI 10.1007/s10589-007-9083-3; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28; Chen T, 2010, INT J COMPUT VISION, V86, P111, DOI 10.1007/s11263-009-0261-x; Cho MS, 2014, PROC CVPR IEEE, P2091, DOI 10.1109/CVPR.2014.268; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; COMINETTI R, 1994, MATH PROGRAM, V67, P169, DOI 10.1007/BF01582220; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; Cour Timothee, 2006, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0044; Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921; CUTURI M., 2013, P INT C ADV NEURAL I, V26; Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445; Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51; Garey M.R., 1979, COMPUTERS INTRACTABI; Garro V, 2016, IEEE T PATTERN ANAL, V38, P1258, DOI 10.1109/TPAMI.2015.2477823; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Goldstein A.A., 1965, J SOC IND APPL MATH, V3, P147, DOI [10.1137/0303013, DOI 10.1137/0303013]; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Jiang B, 2017, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.2017.66; JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710; KOOPMANS TC, 1957, ECONOMETRICA, V25, P53, DOI 10.2307/1907742; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Lacoste-Julien S, 2015, ADV NEURAL INFORM PR, V28, P496; Lafond J., 2016, P NIPS WORKSH NONC O; LAWLER EL, 1963, MANAGE SCI, V9, P586, DOI 10.1287/mnsc.9.4.586; Le-Huu DK, 2017, PROC CVPR IEEE, P4914, DOI 10.1109/CVPR.2017.522; Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Lin WY, 2017, IEEE T IMAGE PROCESS, V26, P2438, DOI 10.1109/TIP.2017.2683063; Liu ZY, 2014, INT J COMPUT VISION, V109, P169, DOI 10.1007/s11263-014-0707-7; Liu ZY, 2014, IEEE T PATTERN ANAL, V36, P1258, DOI 10.1109/TPAMI.2013.223; Loiola EM, 2007, EUR J OPER RES, V176, P657, DOI 10.1016/j.ejor.2005.09.032; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu Y, 2016, PATTERN RECOGN, V60, P971, DOI 10.1016/j.patcog.2016.07.015; Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526; Rodola E, 2017, COMPUT GRAPH FORUM, V36, P222, DOI 10.1111/cgf.12797; Rudin W, 2006, FUNCTIONAL ANAL; Schellewald C, 2005, LECT NOTES COMPUT SC, V3757, P171, DOI 10.1007/11585978_12; Shen TW, 2016, LECT NOTES COMPUT SC, V9907, P139, DOI 10.1007/978-3-319-46487-9_9; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x; Tian Y, 2012, LECT NOTES COMPUT SC, V7574, P821, DOI 10.1007/978-3-642-33712-3_59; Torr P.H., 2003, P INT WORKSH ART INT, P292; Torresani L, 2013, IEEE T PATTERN ANAL, V35, P259, DOI 10.1109/TPAMI.2012.105; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; Wang FD, 2018, LECT NOTES COMPUT SC, V11220, P646, DOI 10.1007/978-3-030-01270-0_38; Xiao H, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P192, DOI 10.1145/3240508.3240539; Yan JC, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P167, DOI 10.1145/2911996.2912035; Yan JC, 2015, PROC CVPR IEEE, P1520, DOI 10.1109/CVPR.2015.7298759; Yao BP, 2012, LECT NOTES COMPUT SC, V7575, P173, DOI 10.1007/978-3-642-33765-9_13; Zanfir A, 2018, PROC CVPR IEEE, P2684, DOI 10.1109/CVPR.2018.00284; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zass R, 2008, PROC CVPR IEEE, P1221; Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759; Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81; Zhou F, 2016, IEEE T PATTERN ANAL, V38, P1774, DOI 10.1109/TPAMI.2015.2501802; Zhou F, 2013, PROC CVPR IEEE, P2922, DOI 10.1109/CVPR.2013.376	63	8	8	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2737	2754		10.1109/TPAMI.2019.2919308	http://dx.doi.org/10.1109/TPAMI.2019.2919308			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NX0AD	31144627	Green Submitted			2022-12-18	WOS:000575381000001
J	Pilzer, A; Lathuiliere, S; Xu, D; Puscas, MM; Ricci, E; Sebe, N				Pilzer, Andrea; Lathuiliere, Stephane; Xu, Dan; Puscas, Mihai Marian; Ricci, Elisa; Sebe, Nicu			Progressive Fusion for Unsupervised Binocular Depth Estimation Using Cycled Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Estimation; Training; Deep learning; Cameras; Solid modeling; Predictive models; Network architecture; Stereo depth estimation; convolutional neural networks (ConvNet); deep multi-scale fusion; cycle network		Recent deep monocular depth estimation approaches based on supervised regression have achieved remarkable performance. However, they require costly ground truth annotations during training. To cope with this issue, in this paper we present a novel unsupervised deep learning approach for predicting depth maps. We introduce a new network architecture, named Progressive Fusion Network (PFN), that is specifically designed for binocular stereo depth estimation. This network is based on a multi-scale refinement strategy that combines the information provided by both stereo views. In addition, we propose to stack twice this network in order to form a cycle. This cycle approach can be interpreted as a form of data-augmentation since, at training time, the network learns both from the training set images (in the forward half-cycle) but also from the synthesized images (in the backward half-cycle). The architecture is jointly trained with adversarial learning. Extensive experiments on the publicly available datasets KITTI, Cityscapes and ApolloScape demonstrate the effectiveness of the proposed model which is competitive with other unsupervised deep learning methods for depth prediction.	[Pilzer, Andrea; Lathuiliere, Stephane; Xu, Dan; Puscas, Mihai Marian; Ricci, Elisa; Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy; [Xu, Dan] Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England; [Ricci, Elisa] Fdn Bruno Kessler, I-38122 Trento, Italy; [Sebe, Nicu] Huawei Technol Ireland, Dublin D02 R156, Ireland	University of Trento; University of Oxford; Fondazione Bruno Kessler; Huawei Technologies	Pilzer, A (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy.	andrea.pilzer@unitn.it; stephane.lathuiliere@unitn.it; danxu@robots.ox.ac.uk; mihaimarian.puscas@unitn.it; eliricci@fbk.eu; niculae.sebe@unitn.it	Puscas, Mihai/AAN-2225-2021	Puscas, Mihai/0000-0003-1440-4586; Ricci, Elisa/0000-0002-0228-1147; Sebe, Niculae/0000-0002-6597-7248				Abadi M, 2015, P 12 USENIX S OPERAT; Atapour-Abarghouei A, 2018, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2018.00296; Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Eigen David, 2014, NEURIPS; Gan YK, 2018, LECT NOTES COMPUT SC, V11207, P232, DOI 10.1007/978-3-030-01219-9_14; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Geiger A., 2012, P IEEE COMP SOC C CO; Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Huang XY, 2018, IEEE COMPUT SOC CONF, P1067, DOI 10.1109/CVPRW.2018.00141; Isola P., 2017, IMAGE TO IMAGE TRANS, P1125; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Kundu JN, 2018, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2018.00281; Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Luc P., 2016, NIPS WORKSHOP ADVERS; LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614; Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Meister S, 2018, AAAI CONF ARTIF INTE, P7251; Mohammadi-Gheidari A, 2018, RECENT TRENDS IN CHARGED PARTICLE OPTICS AND SURFACE PHYSICS INSTRUMENTATION, P50; Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108; Pilzer A, 2019, PROC CVPR IEEE, P9760, DOI 10.1109/CVPR.2019.01000; Pilzer A, 2018, INT CONF 3D VISION, P587, DOI 10.1109/3DV.2018.00073; Porzi L, 2017, IEEE ROBOT AUTOM LET, V2, P468, DOI 10.1109/LRA.2016.2637444; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Saxena Ashutosh, 2006, ADV NEURAL INFORM PR, P1, DOI [DOI 10.1109/TPAMI.2015.2505283A, 10.1109/TPAMI.2015.2505283a]; Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028; Tulyakov S, 2018, ADV NEUR IN, V31; Wang CY, 2018, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2018.00216; Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897; Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xie J., 2012, ADV NEURAL INFORM PR, P341, DOI DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605; Xu D, 2018, PROC CVPR IEEE, P3917, DOI 10.1109/CVPR.2018.00412; Xu D, 2019, IEEE T PATTERN ANAL, V41, P1426, DOI 10.1109/TPAMI.2018.2839602; Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x; Yang N, 2018, LECT NOTES COMPUT SC, V11212, P835, DOI 10.1007/978-3-030-01237-3_50; Yang ZH, 2019, LECT NOTES COMPUT SC, V11133, P691, DOI 10.1007/978-3-030-11021-5_43; Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40; Zhang WH, 2018, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2018), P22, DOI 10.1145/3205289.3205319; Zhong Yiran, 2017, ARXIV170900930; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhuo W, 2015, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2015.7298660; Zou Y, 2018, RIVER PUBL SER ELEC, P37	59	8	8	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2380	2395		10.1109/TPAMI.2019.2942928	http://dx.doi.org/10.1109/TPAMI.2019.2942928			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31545713	Green Submitted			2022-12-18	WOS:000567471300005
J	Rueda-Chacon, H; Florez-Ospina, JF; Lau, DL; Arce, GR				Rueda-Chacon, Hoover; Florez-Ospina, Juan F.; Lau, Daniel L.; Arce, Gonzalo R.			Snapshot Compressive ToF plus Spectral Imaging via Optimized Color-Coded Apertures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Apertures; Cameras; Three-dimensional displays; Lenses; Image coding; Optical imaging; Compressive spectral imaging; time-of-flight imaging; color-coded apertures; multitoning; RGB plus D; MS plus D	BLUE-NOISE; DESIGN	Compressive multispectral imaging systems comprise a new generation of spectral imagers that capture coded projections of a scene where spectral data cubes are reconstructed computationally. Separately, time-of-flight (ToF) cameras obtain 2D range images where each pixel records the distance from the camera sensor to the target surface. The demand for these imaging modalities is rapidly increasing, and thus, there is strong interest in developing new image sensors that can simultaneously acquire multispectral-color-and-depth imagery (MS+D) using a single aperture. Work in this path has been mainly developed via RGB+D imaging. However, in RGB+D, the multispectral image is limited to three spectral channels, and the imaging system often relies on two image sensors. We recently proposed a compressive MS+D imaging device that used a digital-micromirror-device, requiring a bulky double imaging-and-relay path. To overcome the bulkiness and other difficulties of our previous imaging system, this work presents a more-compact MS+D imaging device with snapshot capabilities. It provides better spectral sensing, relying on a static color-coded-aperture (CCA) and a ToF sensor. To guarantee good quality in the recovery, we develop an optimization method for CCA based-on blue-noise-multitoning, solved via the direct-binary-search algorithm. A testbed-setup is reported along with simulated and real experiments that demonstrate the MS+D capabilities of the proposed system over static and dynamic scenes.	[Rueda-Chacon, Hoover; Florez-Ospina, Juan F.; Arce, Gonzalo R.] Univ Delaware, Dept Elect & Comp Engn, Newark, DE 19716 USA; [Lau, Daniel L.] Univ Kentucky, Dept Elect & Comp Engn, Lexington, KY 40506 USA	University of Delaware; University of Kentucky	Rueda-Chacon, H (corresponding author), Univ Delaware, Dept Elect & Comp Engn, Newark, DE 19716 USA.	rueda@udel.edu; jfflorez@udel.edu; dllau@uky.edu; arce@udel.edu	Florez-Ospina, Juan Felipe/GPG-3868-2022; Lau, Daniel/O-5169-2014	Arce, Gonzalo/0000-0001-7163-7111; Lau, Daniel/0000-0003-1377-4622; Florez Ospina, Juan Felipe/0000-0001-5971-9042	Intel Corporation under the Visual and Experiential Computing initiative [1538950]; National Science Foundation under the Visual and Experiential Computing initiative [1538950]; Colciencias; Fulbright	Intel Corporation under the Visual and Experiential Computing initiative; National Science Foundation under the Visual and Experiential Computing initiative; Colciencias(Departamento Administrativo de Ciencia, Tecnologia e Innovacion Colciencias); Fulbright	The authors thank Intel Corporation and the National Science Foundation for the grant No. 1538950 under the Visual and Experiential Computing initiative. Hoover Rueda-Chacon and Juan F. Florez-Ospina acknowledge Colciencias and Fulbright for their doctoral scholarships.	Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294; Agar AU, 2005, IEEE T IMAGE PROCESS, V14, P1945, DOI 10.1109/TIP.2005.859380; Arce G. R., 2017, SNAPSHOT COMPRESSIVE; Arce GR, 2014, IEEE SIGNAL PROC MAG, V31, P105, DOI 10.1109/MSP.2013.2278763; Arguello H, 2014, IEEE T IMAGE PROCESS, V23, P1896, DOI 10.1109/TIP.2014.2310125; Arguello H, 2011, J OPT SOC AM A, V28, P2400, DOI 10.1364/JOSAA.28.002400; Barrie JD, 1995, THIN SOLID FILMS, V270, P6, DOI 10.1016/0040-6090(95)06888-0; Bhandari A, 2016, IEEE SIGNAL PROC MAG, V33, P45, DOI 10.1109/MSP.2016.2582218; Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319; Brady David J., 2009, OPTICAL IMAGING SPEC; Cao X, 2016, IEEE SIGNAL PROC MAG, V33, P95, DOI 10.1109/MSP.2016.2582378; Cao YP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182157; Conde M. Heredia, 2017, PHASE SHIFT BASED TI, P11; Correa CV, 2016, J OPT SOC AM A, V33, P2312, DOI 10.1364/JOSAA.33.002312; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Eismann M.T., 2012, HYPERSPECTRAL REMOTE; Espros Photonics Corporation, 2016, DAT EPC660 3D TOF IM; Farber V, 2016, OPT LETT, V41, P5174, DOI 10.1364/OL.41.005174; Feng WY, 2016, OPT EXPRESS, V24, P24859, DOI 10.1364/OE.24.024859; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060; Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Hagen N, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.9.090901; Hagen N, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.11.111702; Hibbard PB, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0062-7; Huang JW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130824; Ihrke I, 2016, IEEE SIGNAL PROC MAG, V33, P59, DOI 10.1109/MSP.2016.2582220; Kerl C, 2015, IEEE I CONF COMP VIS, P2264, DOI 10.1109/ICCV.2015.261; Kim MH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185534; Kittle D, 2010, APPL OPTICS, V49, P6824, DOI 10.1364/AO.49.006824; Lai K., 2013, RGB D OBJECT RECOGNI, P167; Lau D. L., 2008, MODERN DIGITAL HALFT; Lau DL, 1999, J OPT SOC AM A, V16, P1575, DOI 10.1364/JOSAA.16.001575; Lau DL, 2000, IEEE T IMAGE PROCESS, V9, P923, DOI 10.1109/83.841537; Lau DL, 2003, IEEE SIGNAL PROC MAG, V20, P28, DOI 10.1109/MSP.2003.1215229; Lin X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661262; Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901; Mejia Y, 2018, IEEE T IMAGE PROCESS, V27, P5775, DOI 10.1109/TIP.2018.2857445; Morell-Gimenez V, 2014, SENSORS-BASEL, V14, P8547, DOI 10.3390/s140508547; Nalpantidis L, 2008, INT J OPTOMECHATRONI, V2, P435, DOI 10.1080/15599610802438680; Parada-Mayorga A, 2017, IEEE T COMPUT IMAG, V3, P202, DOI 10.1109/TCI.2017.2692649; Rodriguez JB, 2008, IEEE T IMAGE PROCESS, V17, P1368, DOI 10.1109/TIP.2008.926145; Rueda H, 2017, EUR SIGNAL PR CONF, P463, DOI 10.23919/EUSIPCO.2017.8081250; Rueda H, 2017, IEEE J-STSP, V11, P992, DOI 10.1109/JSTSP.2017.2737784; Rueda H, 2016, APPL OPTICS, V55, P9584, DOI 10.1364/AO.55.009584; Rueda H, 2015, J OPT SOC AM A, V32, P80, DOI 10.1364/JOSAA.32.000080; ULICHNEY RA, 1988, P IEEE, V76, P56, DOI 10.1109/5.3288; Wang LZ, 2018, IEEE T CIRC SYST VID, V28, P812, DOI 10.1109/TCSVT.2016.2616374; WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1; Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126	51	8	8	7	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2346	2360		10.1109/TPAMI.2019.2912961	http://dx.doi.org/10.1109/TPAMI.2019.2912961			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31027042				2022-12-18	WOS:000567471300003
J	Akagunduz, E; Bors, AG; Evans, KK				Akagunduz, Erdem; Bors, Adrian G.; Evans, Karla K.			Defining Image Memorability Using the Visual Memory Schema	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Observers; Semantics; Psychology; Organizations; Image recognition; Computer vision; Image memorability; visual memory schema; memory experiments; deep features		Memorability of an image is a characteristic determined by the human observers' ability to remember images they have seen. Yet recent work on image memorability defines it as an intrinsic property that can be obtained independent of the observer. The current study aims to enhance our understanding and prediction of image memorability, improving upon existing approaches by incorporating the properties of cumulative human annotations. We propose a new concept called the Visual Memory Schema (VMS) referring to an organization of image components human observers share when encoding and recognizing images. The concept of VMS is operationalised by asking human observers to define memorable regions of images they were asked to remember during an episodic memory test. We then statistically assess the consistency of VMSs across observers for either correctly or incorrectly recognised images. The associations of the VMSs with eye fixations and saliency are analysed separately as well. Lastly, we adapt various deep learning architectures for the reconstruction and prediction of memorable regions in images and analyse the results when using transfer learning at the outputs of different convolutional network layers.	[Akagunduz, Erdem; Bors, Adrian G.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England; [Evans, Karla K.] Univ York, Dept Psychol, York YO10 5DD, N Yorkshire, England	University of York - UK; University of York - UK	Akagunduz, E (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.	akagunduz@ieee.org; adrian.bors@york.ac.uk; karla.evans@york.ac.uk	Bors, Adrian/T-3618-2019; Evans, Karla/S-5779-2018; Akagunduz, Erdem/W-1788-2018	Bors, Adrian/0000-0001-7838-0021; Evans, Karla/0000-0002-8440-1711; Akagunduz, Erdem/0000-0002-0792-7306				[Anonymous], 1996, PRESS; [Anonymous], 2013, IEEE INT VEH SYM; Bartlett F. C., 1955, REMEMBERING STUDY EX, V2nd; Brady TF, 2011, J VISION, V11, DOI 10.1167/11.5.4; Bylinskii Z, 2015, VISION RES, V116, P165, DOI 10.1016/j.visres.2015.03.005; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI [10.1145/1961189.1961199, DOI 10.1145/1961189.1961199]; Chatfield K, 2014, P BRIT MACH VIS C 20, P1; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dubey R, 2015, IEEE I CONF COMP VIS, P1089, DOI 10.1109/ICCV.2015.130; Harel J., 2006, P INT C NEUR INF PRO, P545; Isola P., 2011, P C NEUR INF PROC SY, P2429; Isola P, 2014, IEEE T PATTERN ANAL, V36, P1469, DOI 10.1109/TPAMI.2013.200; Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Khosla A., 2012, ADV NEURAL INFORM PR, P296; Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275; Long MS, 2015, PR MACH LEARN RES, V37, P97; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mancas M, 2013, IEEE IMAGE PROC, P196, DOI 10.1109/ICIP.2013.6738041; MANDLER JM, 1977, J EXP PSYCHOL-HUM L, V3, P386, DOI 10.1037/0278-7393.3.4.386; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Polyn SM, 2005, SCIENCE, V310, P1963, DOI 10.1126/science.1117645; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Simonyan K., 2015, P 3 INT C LEARN REPR; STANDING L, 1975, CAN J PSYCHOL, V29, P316, DOI 10.1037/h0082034; Tulving E., 1972, ORG MEMORY, P381; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Vogt S, 2005, BRAIN COGNITION, V58, P324, DOI 10.1016/j.bandc.2005.03.003; Wickens T. D., 2001, ELEMANTARY SIGNAL DE; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yixuan Li., 2016, P INT C LEARN REPR I; Yosinski J., 2015, P 31 INT C MACH LEAR	32	8	8	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2165	2178		10.1109/TPAMI.2019.2914392	http://dx.doi.org/10.1109/TPAMI.2019.2914392			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	31056491	Green Submitted			2022-12-18	WOS:000557354900007
J	Chen, YK; Ye, JB; Li, J				Chen, Yukun; Ye, Jianbo; Li, Jia			Aggregated Wasserstein Distance and State Registration for Hidden Markov Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hidden Markov models; Monte Carlo methods; Gaussian distribution; Measurement; Computational modeling; Approximation methods; Markov processes; Hidden Markov model; Gaussian mixture model; Wasserstein distance; optimal transport	KULLBACK-LEIBLER DIVERGENCE; HMM; RECOGNITION; TRANSPORT	We propose a framework, named Aggregated Wasserstein, for computing a dissimilarity measure or distance between two Hidden Markov Models with state conditional distributions being Gaussian. For such HMMs, the marginal distribution at any time position follows a Gaussian mixture distribution, a fact exploited to softly match, aka register, the states in two HMMs. We refer to such HMMs as HMM. The registration of states is inspired by the intrinsic relationship of optimal transport and the Wasserstein metric between distributions. Specifically, the components of the marginal GMMs are matched by solving an optimal transport problem where the cost between components is the Wasserstein metric for Gaussian distributions. The solution of the optimization problem is a fast approximation to the Wasserstein metric between two GMMs. The new Aggregated Wasserstein distance is a semi-metric and can be computed without generating Monte Carlo samples. It is invariant to relabeling or permutation of states. The distance is defined meaningfully even for two HMMs that are estimated from data of different dimensionality, a situation that can arise due to missing variables. This distance quantifies the dissimilarity of HMMs by measuring both the difference between the two marginal GMMs and that between the two transition matrices. Our new distance is tested on tasks of retrieval, classification, and t-SNE visualization of time series. Experiments on both synthetic and real data have demonstrated its advantages in terms of accuracy as well as efficiency in comparison with existing distances based on the Kullback-Leibler divergence.	[Chen, Yukun; Ye, Jianbo] Penn State Univ, Coll Informat Sci & Technol, State Coll, PA 16801 USA; [Li, Jia] Penn State Univ, Dept Stat, State Coll, PA 16801 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University	Chen, YK (corresponding author), Penn State Univ, Coll Informat Sci & Technol, State Coll, PA 16801 USA.	yzc147@psu.edu; jxy198@psu.edu; jiali@stat.psu.edu	Ye, Jianbo/Q-6990-2017	Ye, Jianbo/0000-0003-4612-6429; Chen, Yukun/0000-0002-3174-2483	National Science Foundation [ACI-1548562]	National Science Foundation(National Science Foundation (NSF))	This work used the Extreme Science and Engineering Discovery Environment (XSEDE) [55], which is supported by National Science Foundation grant number ACI-1548562.	Akama Y., 2011, ARXIV11094347; Alon J, 2003, PROC CVPR IEEE, P375; Altschuler J., 2017, P ADV NEUR INF PROC, P1964; [Anonymous], 2012, IEEE INT SYMP CIRC S; [Anonymous], 2015, JMLR WORKSH CONF PRO; [Anonymous], 2007, LECT NOTES ARTIF INT; [Anonymous], 2014, JMLR WORKSH CONF PRO; [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46466-4_27; [Anonymous], 2017, IEEE SIGNAL PROC MAG, DOI DOI 10.1109/MSP.2017.2695801; Applegate D., 2011, P 17 ACM SIGKDD INT, P636; BAKER JK, 1975, IEEE T ACOUST SPEECH, VAS23, P24, DOI 10.1109/TASSP.1975.1162650; Blanchard G, 2010, J MACH LEARN RES, V11, P2973; Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382; Chen YX, 2019, IEEE ACCESS, V7, P6269, DOI 10.1109/ACCESS.2018.2889838; COLE R, 1995, IEEE T SPEECH AUDI P, V3, P1, DOI 10.1109/89.365385; Coviello E, 2014, J MACH LEARN RES, V15, P697; Cuturi M., 2013, P ADV NEUR INF PROC, P2292; Do MN, 2003, IEEE SIGNAL PROC LET, V10, P115, DOI 10.1109/LSP.2003.809034; Fox EB, 2011, ANN APPL STAT, V5, P1020, DOI 10.1214/10-AOAS395; Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004; GIVENS CR, 1984, MICH MATH J, V31, P231; Goldberger J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P487; Gray R. M., 2013, TRANSPORTATION DISTA; Hershey JR, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, VOLS 1 AND 2, P323, DOI 10.1109/ASRU.2007.4430132; Hershey JR, 2007, INT CONF ACOUST SPEE, P317, DOI 10.1109/icassp.2007.366913; Huang G., 2016, P ADV NEUR INF PROC, P4862; Huang X. D., 1990, HIDDEN MARKOV MODELS; HUANG XD, 1992, IEEE T SIGNAL PROCES, V40, P1062, DOI 10.1109/78.134469; JUANG BH, 1985, AT&T TECH J, V64, P391, DOI 10.1002/j.1538-7305.1985.tb00439.x; Kolouri S, 2018, PROC CVPR IEEE, P3427, DOI 10.1109/CVPR.2018.00361; Kolouri S, 2017, IEEE SIGNAL PROC MAG, V34, P43, DOI 10.1109/MSP.2017.2695801; Kolouri S, 2016, PROC CVPR IEEE, P5258, DOI 10.1109/CVPR.2016.568; Kusner MJ, 2015, PR MACH LEARN RES, V37, P957; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Lee YK, 2006, ANN I STAT MATH, V58, P327, DOI 10.1007/s10463-005-0014-8; LEVINSON SE, 1983, AT&T TECH J, V62, P1035, DOI 10.1002/j.1538-7305.1983.tb03114.x; Li PH, 2013, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2013.212; Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058; Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359; Nilsson M., 2002, SPEECH RECOGNITION U; Rabiner L., 1993, FUNDAMENTALS SPEECH; Ramdas A., 2015, ENTROPY, V19; Ren L, 2005, ACM T GRAPHIC, V24, P1090, DOI 10.1145/1073204.1073316; Ren Z, 2011, P 19 ACM INT C MULT, DOI DOI 10.1145/2072298.2071946; Ross S. M., 1996, STOCHASTIC PROCESSES, V2nd; Sha F., 2007, P ADV NEUR INF PROC, P1249; Shang LF, 2009, PROC CVPR IEEE, P2090, DOI 10.1109/CVPRW.2009.5206509; Smyth P, 1997, ADV NEUR IN, V9, P648; Towns J, 2014, COMPUT SCI ENG, V16, P62, DOI 10.1109/MCSE.2014.80; van der Maaten L, 2014, J MACH LEARN RES, V15, P3221; Vasconcelos N, 2004, IEEE T INFORM THEORY, V50, P1482, DOI 10.1109/TIT.2004.830760; Villani C., 2003, GRADUATE STUDIES MAT; Ye JB, 2017, IEEE T SIGNAL PROCES, V65, P2317, DOI 10.1109/TSP.2017.2659647; Young S., 1997, HTK BOOK, V2; Zhong S, 2004, J MACH LEARN RES, V4, P1001, DOI 10.1162/1532443041827943	56	8	8	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2133	2147		10.1109/TPAMI.2019.2908635	http://dx.doi.org/10.1109/TPAMI.2019.2908635			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	30946661	hybrid			2022-12-18	WOS:000557354900005
J	Tamaazousti, Y; Le Borgne, H; Hudelot, C; Seddik, ME; Tamaazousti, M				Tamaazousti, Youssef; Le Borgne, Herve; Hudelot, Celine; Seddik, Mohamed-El-Amine; Tamaazousti, Mohamed			Learning More Universal Representations for Transfer-Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Visualization; Measurement; Semantics; Additives; Veins; Training; Universal representations; universality evaluation; transfer-learning; visual recognition	LEVEL	A representation is supposed universal if it encodes any element of the visual world (e.g., objects, scenes) in any configuration (e.g., scale, context). While not expecting pure universal representations, the goal in the literature is to improve the universality level, starting from a representation with a certain level. To improve that universality level, one can diversify the source-task, but it requires many additive annotated data that is costly in terms of manual work and possible expertise. We formalize such a diversification process then propose two methods to improve the universality of CNN representations that limit the need for additive annotated data. The first relies on human categorization knowledge and the second on re-training using fine-tuning. We propose a new aggregating metric to evaluate the universality in a transfer-learning scheme, that addresses more aspects than previous works. Based on it, we show the interest of our methods on 10 target-problems, relating to classification on a variety of visual domains.	[Tamaazousti, Youssef] MIT, CSAIL, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Le Borgne, Herve; Seddik, Mohamed-El-Amine; Tamaazousti, Mohamed] CEA, LIST, F-91120 Palaiseau, France; [Hudelot, Celine] Univ Paris Saclay, MICS Lab, Cent Supelec, F-91190 St Aubin, France	Massachusetts Institute of Technology (MIT); CEA; UDICE-French Research Universities; Universite Paris Saclay	Tamaazousti, Y (corresponding author), MIT, CSAIL, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	ytamaaz@mit.edu; herve.le-borgne@cea.fr; celine.hudelot@centralesupelec.fr; mohamedelamine.seddik@cea.fr; mohamed.tamaazousti@cea.fr		Le Borgne, Herve/0000-0003-0520-8436				Ahmed K, 2016, LECT NOTES COMPUT SC, V9911, P516, DOI 10.1007/978-3-319-46478-7_32; [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.561; [Anonymous], 2018, IEEE WINT CONF APPL, DOI DOI 10.1109/WACV.2018.00199; [Anonymous], 2015, IEEE WINT CONF APPL, DOI DOI 10.1109/WACV.2015.85; [Anonymous], 2016, 2016 INT C ROB INT, DOI DOI 10.1109/ICRIS.2016.13; [Anonymous], 2014, INT C ED SOC SCIENC; Atkinson J., 2002, DEV VISUAL BRAIN; Azizpour H, 2016, IEEE T PATTERN ANAL, V38, P1790, DOI 10.1109/TPAMI.2015.2500224; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bilen H., 2017, IEEE T PATTERN ANAL; Brodeur S., 2017, ARXIV171111017; Chami I, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P352, DOI 10.1145/3078971.3078993; Conneau A., 2018, P 11 INT C LANG RES; Conneau A., 2017, P EMNLP SEP, P670; French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2; Ginsca A. L., 2015, P INT C MULT MOD, P318; Herranz L, 2016, PROC CVPR IEEE, P571, DOI 10.1109/CVPR.2016.68; Hinton G., 2015, DISTILLING KNOWLEDGE; Huh M., 2016, ARXIV160808614; Jia D, 2012, PROC CVPR IEEE, P3450, DOI 10.1109/CVPR.2012.6248086; JOLICOEUR P, 1984, COGNITIVE PSYCHOL, V16, P243, DOI 10.1016/0010-0285(84)90009-4; Joulin A, 2016, LECT NOTES COMPUT SC, V9911, P67, DOI 10.1007/978-3-319-46478-7_5; Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Liu W., 2016, EUR C COMP VIS; Mettes P, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P175, DOI 10.1145/2911996.2912036; Murthy VN, 2016, PROC CVPR IEEE, P2240, DOI 10.1109/CVPR.2016.246; Ordonez V, 2015, INT J COMPUT VISION, V115, P29, DOI 10.1007/s11263-015-0815-z; Ouyang WL, 2016, PROC CVPR IEEE, P864, DOI 10.1109/CVPR.2016.100; Rebuffi S.-A., 2017, ADV NEURAL INFORM PR, P506; Rebuffi SA, 2018, PROC CVPR IEEE, P8119, DOI 10.1109/CVPR.2018.00847; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Rosch E., 1978, COGNITION CATEGORIZA; Rosenfeld A, 2020, IEEE T PATTERN ANAL, V42, P651, DOI 10.1109/TPAMI.2018.2884462; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Salvador A, 2017, PROC CVPR IEEE, P3068, DOI 10.1109/CVPR.2017.327; Sermanet P., 2014, ICLR; Simonyan K., 2015, P 3 INT C LEARN REPR; Subramanian S., 2018, ARXIV181100552; Tamaazousti Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P119, DOI 10.1145/2911996.2912009; Tamaazousti Y, 2017, COMPUT VIS IMAGE UND, V163, P41, DOI 10.1016/j.cviu.2017.05.017; Tamaazousti Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P63, DOI 10.1145/2911996.2912013; TANAKA JW, 1991, COGNITIVE PSYCHOL, V23, P457, DOI 10.1016/0010-0285(91)90016-H; Vo PD, 2017, COMPUT VIS IMAGE UND, V164, P68, DOI 10.1016/j.cviu.2017.01.009; Wang YX, 2017, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2017.323; Yan ZC, 2015, IEEE I CONF COMP VIS, P2740, DOI 10.1109/ICCV.2015.314; Yosinski J, 2014, ADV NEUR IN, V27	48	8	9	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2212	2224		10.1109/TPAMI.2019.2913857	http://dx.doi.org/10.1109/TPAMI.2019.2913857			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	MW9MI	31056487	Green Submitted			2022-12-18	WOS:000557354900010
J	Chiu, CY; Prayoonwong, A; Liao, YC				Chiu, Chih-Yi; Prayoonwong, Amorntip; Liao, Yin-Chih			Learning to Index for Nearest Neighbor Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Indexing; Artificial neural networks; Vector quantization; Hash functions; Binary codes; Approximate nearest neighbor; asymmetric distance computation; cluster ranking and pruning; hash-based indexing; product quantization; residual vector quantization	OPTIMIZED PRODUCT QUANTIZATION; HASH; CODES	In this study, we present a novel ranking model based on learning neighborhood relationships embedded in the index space. Given a query point, conventional approximate nearest neighbor search calculates the distances to the cluster centroids, before ranking the clusters from near to far based on the distances. The data indexed in the top-ranked clusters are retrieved and treated as the nearest neighbor candidates for the query. However, the loss of quantization between the data and cluster centroids will inevitably harm the search accuracy. To address this problem, the proposed model ranks clusters based on their nearest neighbor probabilities rather than the query-centroid distances. The nearest neighbor probabilities are estimated by employing neural networks to characterize the neighborhood relationships, i.e., the density function of nearest neighbors with respect to the query. The proposed probability-based ranking can replace the conventional distance-based ranking for finding candidate clusters, and the predicted probability can be used to determine the data quantity to be retrieved from the candidate cluster. Our experimental results demonstrated that the proposed ranking model could boost the search performance effectively in billion-scale datasets.	[Chiu, Chih-Yi; Prayoonwong, Amorntip; Liao, Yin-Chih] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 600, Taiwan	National Chiayi University	Chiu, CY (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 600, Taiwan.	cychiu@mail.ncyu.edu.tw; aprayoonwong@gmail.com; zzzzbenny6209@gmail.com		Prayoonwong, Amorntip/0000-0003-4584-6678	Ministry of Science and Technology, Taiwan, R.O.C. [MOST 106-2221-E-415-019-MY3]	Ministry of Science and Technology, Taiwan, R.O.C.(Ministry of Science and Technology, Taiwan)	This work was supported in part by Ministry of Science and Technology, Taiwan, R.O.C. under grant MOST 106-2221-E-415-019-MY3. The authors would like to thank Dmitry Baranchuk for the kindly help with figure reproducing and the reviewers for the thoughtful comments and suggestions.	Andre F, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P164, DOI 10.1145/3078971.3078992; Arampatzis A, 2018, ACM T INFORM SYST, V36, DOI 10.1145/3125620; Babenko A, 2017, IEEE I CONF COMP VIS, P4895, DOI 10.1109/ICCV.2017.523; Babenko A, 2016, PROC CVPR IEEE, P2055, DOI 10.1109/CVPR.2016.226; Babenko A, 2015, PROC CVPR IEEE, P4240, DOI 10.1109/CVPR.2015.7299052; Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124; Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38; Babenko A, 2012, PROC CVPR IEEE, P3069, DOI 10.1109/CVPR.2012.6248038; Baranchuk D, 2018, LECT NOTES COMPUT SC, V11216, P209, DOI 10.1007/978-3-030-01258-8_13; Beygelzimer A., 2006, P 23 INT C MACH LEAR, P97, DOI DOI 10.1145/1143844.1143857; Blalock DW, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P727, DOI 10.1145/3097983.3098195; Chen YJ, 2010, SENSORS-BASEL, V10, P11259, DOI 10.3390/s101211259; Chiu CY, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2990504; Ercoli S, 2017, IEEE T MULTIMEDIA, V19, P2521, DOI 10.1109/TMM.2017.2697824; Ge TZ, 2014, LECT NOTES COMPUT SC, V8695, P250, DOI 10.1007/978-3-319-10584-0_17; Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Gordo A, 2014, IEEE T PATTERN ANAL, V36, P33, DOI 10.1109/TPAMI.2013.101; Houle ME, 2015, IEEE T PATTERN ANAL, V37, P136, DOI 10.1109/TPAMI.2014.2343223; Hu MQ, 2018, IEEE T IMAGE PROCESS, V27, P545, DOI 10.1109/TIP.2017.2749147; Huang Z, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1852102.1852108; Jegou H, 2011, INT CONF ACOUST SPEE, P861; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298; Li K., 2017, ACM T MULTIM COMPUT, V14; Liu SC, 2017, IEEE T MULTIMEDIA, V19, P1785, DOI 10.1109/TMM.2017.2692181; Manning C.D., 2008, INTRO INFORM RETRIEV; Matsui Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1725, DOI 10.1145/3123266.3123430; Matsui Y, 2015, IEEE I CONF COMP VIS, P1940, DOI 10.1109/ICCV.2015.225; Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004; Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887; Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863; Silpa-Anan C, 2008, PROC CVPR IEEE, P2308; Wang J., 2014, ARXIV14082927; Wang J, 2017, IEEE INFOCOM SER, DOI 10.1007/s12083-017-0556-6; Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976; Wei BC, 2014, IEEE MULTIMEDIA, V21, P41, DOI 10.1109/MMUL.2013.65; Xia Y, 2013, IEEE I CONF COMP VIS, P3416, DOI 10.1109/ICCV.2013.424; Xu DN, 2018, IEEE T KNOWL DATA EN, V30, P2185, DOI 10.1109/TKDE.2018.2817526; Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812; Yu LT, 2017, IEEE T IMAGE PROCESS, V26, P5057, DOI 10.1109/TIP.2017.2722224; Zhang QF, 2014, INT CONF MACH LEARN, P807, DOI 10.1109/ICMLC.2014.7009713; Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508; Zheng DH, 2017, PROT CONTR MOD POW, V2, DOI 10.1186/s41601-017-0041-5; Zhong ZC, 2008, INT CONF NANO MICRO, P120	49	8	8	2	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1942	1956		10.1109/TPAMI.2019.2907086	http://dx.doi.org/10.1109/TPAMI.2019.2907086			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30908193	Green Submitted			2022-12-18	WOS:000545415400010
J	Yang, X; Liu, ZY; Qiao, H				Yang, Xu; Liu, Zhi-Yong; Qiao, Hong			A Continuation Method for Graph Matching Based Feature Correspondence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature correspondence; graph matching; continuous method; continuation method; combinatorial optimization	OPTIMIZATION	Feature correspondence lays the foundation for many computer vision and image processing tasks, which can be well formulated and solved by graph matching. Because of the high complexity, approximate methods are necessary for graph matching, and the continuous relaxation provides an efficient approximate scheme. But there are still many problems to be settled, such as the highly nonconvex objective function, the ignorance of the combinatorial nature of graph matching in the optimization process, and few attention to the outlier problem. Focusing on these problems, this paper introduces a continuation method directly targeting at the combinatorial optimization problem associated with graph matching. Specifically, first a regularization function incorporating the original objective function and the discrete constraints is proposed. Then a continuation method based on Gaussian smoothing is applied to it, in which the closed forms of relevant functions with respect to the outlier distribution are deduced. Experiments on both synthetic data and real world images validate the effectiveness of the proposed method.	[Yang, Xu; Liu, Zhi-Yong; Qiao, Hong] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China; [Liu, Zhi-Yong; Qiao, Hong] Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Shanghai 200031, Peoples R China; [Liu, Zhi-Yong; Qiao, Hong] Univ Chinese Acad Sci, Beijing 100049, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Liu, ZY (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.; Liu, ZY (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.	xu.yang@ia.ac.cn; zhiyong.liu@ia.ac.cn; hong.qiao@ia.ac.cn		Yang, Xu/0000-0003-0553-4581	National Natural Science Foundation (NSFC) of China [61633009, 61503383, U1613213, 61627808, 91648205, U1509212]; National Key R\&D Program of China [2016YFC0300801, 2017YFB1300202]; Strategic Priority Research Program of Chinese Academy of Sciences [XDB32000000]	National Natural Science Foundation (NSFC) of China(National Natural Science Foundation of China (NSFC)); National Key R\&D Program of China; Strategic Priority Research Program of Chinese Academy of Sciences(Chinese Academy of Sciences)	The authors thank the associate editor and anonymous reviewers whose comments greatly improved the manuscript. This work is supported partly by the National Natural Science Foundation (NSFC) of China (grants 61633009, 61503383, U1613213, 61627808, 91648205, and U1509212), partly by the National Key R\&D Program of China (grants 2016YFC0300801 and 2017YFB1300202), and partly by the Strategic Priority Research Program of Chinese Academy of Sciences (grant XDB32000000).	ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Cho MS, 2014, PROC CVPR IEEE, P2091, DOI 10.1109/CVPR.2014.268; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cour Timothee, 2006, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0044; Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51; Erhan D, 2009, J MACH LEARN RES, P153; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; GHAHRAMAN DE, 1980, IEEE T SYST MAN CYB, V10, P181, DOI 10.1109/TSMC.1980.4308468; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Gori M, 2005, IEEE T PATTERN ANAL, V27, P1100, DOI 10.1109/TPAMI.2005.138; Jaggi M., 2013, P 30 INT C MACHINE L, P427; Kumar M. P., 2006, CVPR; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M, 2012, INT J COMPUT VISION, V96, P28, DOI 10.1007/s11263-011-0442-2; Lian W, 2014, PROC CVPR IEEE, P352, DOI 10.1109/CVPR.2014.52; Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17; Liu ZY, 2014, IEEE T PATTERN ANAL, V36, P1258, DOI 10.1109/TPAMI.2013.223; Liu ZY, 2012, IEEE T PATTERN ANAL, V34, P1451, DOI 10.1109/TPAMI.2012.45; Loog M, 2001, LECT NOTES COMPUT SC, V2106, P183; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Mobahi H, 2015, LECT NOTES COMPUT SC, V8932, P43, DOI 10.1007/978-3-319-14612-6_4; Nielsen M., 1993, P BRIT MACH VIS C; Schellewald C, 2005, LECT NOTES COMPUT SC, V3757, P171, DOI 10.1007/11585978_12; Smalter Aaron, 2008, Proc IEEE Int Symp Bioinformatics Bioeng, V2008, P1; Tian Y, 2012, LECT NOTES COMPUT SC, V7574, P821, DOI 10.1007/978-3-642-33712-3_59; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Wang T, 2018, IEEE T PATTERN ANAL, V40, P2853, DOI 10.1109/TPAMI.2017.2767591; Yan JC, 2016, IEEE T PATTERN ANAL, V38, P1228, DOI 10.1109/TPAMI.2015.2477832; Yan JC, 2015, IEEE T IMAGE PROCESS, V24, P994, DOI 10.1109/TIP.2014.2387386; Yan JC, 2014, LECT NOTES COMPUT SC, V8689, P407, DOI 10.1007/978-3-319-10590-1_27; Yang X, 2018, IEEE T NEUR NET LEAR, V29, P2162; YUILLE AL, 1989, BIOL CYBERN, V61, P115, DOI 10.1007/BF00204595; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zhou F, 2013, PROC CVPR IEEE, P2922, DOI 10.1109/CVPR.2013.376; Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667	41	8	8	3	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1809	1822		10.1109/TPAMI.2019.2903483	http://dx.doi.org/10.1109/TPAMI.2019.2903483			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30843819				2022-12-18	WOS:000545415400001
J	Chen, Y; Shen, CH; Chen, H; Wei, XS; Liu, LQ; Yang, J				Chen, Yu; Shen, Chunhua; Chen, Hao; Wei, Xiu-Shen; Liu, Lingqiao; Yang, Jian			Adversarial Learning of Structure-Aware Fully Convolutional Networks for Landmark Localization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pose estimation; Two dimensional displays; Three-dimensional displays; Heating systems; Task analysis; Training; Pose estimation; landmark localization; structure-aware network; adversarial training; multi-task learning; deep convolutional networks	FLEXIBLE MIXTURES; POSE ESTIMATION; FACE ALIGNMENT	Landmark/pose estimation in single monocular images has received much effort in computer vision due to its important applications. It remains a challenging task when input images come with severe occlusions caused by, e.g., adverse camera views. Under such circumstances, biologically implausible pose predictions may be produced. In contrast, human vision is able to predict poses by exploiting geometric constraints of landmark point inter-connectivity. To address the problem, by incorporating priors about the structure of pose components, we propose a novel structure-aware fully convolutional network to implicitly take such priors into account during training of the deep network. Explicit learning of such constraints is typically challenging. Instead, inspired by how human identifies implausible poses, we design discriminators to distinguish the real poses from the fake ones (such as biologically implausible ones). If the pose generator G generates results that the discriminator fails to distinguish from real ones, the network successfully learns the priors. Training of the network follows the strategy of conditional Generative Adversarial Networks (GANs). The effectiveness of the proposed network is evaluated on three pose-related tasks: 2D human pose estimation, 2D facial landmark estimation and 3D human pose estimation. The proposed approach significantly outperforms several state-of-the-art methods and almost always generates plausible pose predictions, demonstrating the usefulness of implicit learning of structures using GANs.	[Chen, Yu; Yang, Jian] Nanjing Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Jiangsu, Peoples R China; [Shen, Chunhua; Chen, Hao; Liu, Lingqiao] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Shen, Chunhua; Chen, Hao; Liu, Lingqiao] Australian Ctr Robot Vis, Brisbane, Qld, Australia; [Wei, Xiu-Shen] Megvii Technol, Megvii Res Nanjing, Nanjing 210000, Jiangsu, Peoples R China	Nanjing University of Science & Technology; University of Adelaide; Australian Centre for Robotic Vision	Chen, Y; Yang, J (corresponding author), Nanjing Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Jiangsu, Peoples R China.	chenyu1523@gmail.com; chhshen@gmail.com; hao.chen01@adelaide.edu.au; weixs.gm@gmail.com; lingqiao.liu@adelaide.edu.au; csjyang@njust.edu.cn		Wei, Xiu-Shen/0000-0002-8200-1845; Shen, Chunhua/0000-0002-8648-8718; liu, lingqiao/0000-0003-3584-795X	National Science Fund of China [U1713208]; "111" Program [AH92005]; ARC Future Fellowship; ARC DECRA Fellowship; ARC [CE140100016]; Program for Changjiang Scholars	National Science Fund of China(National Natural Science Foundation of China (NSFC)); "111" Program(Ministry of Education, China - 111 Project); ARC Future Fellowship(Australian Research Council); ARC DECRA Fellowship(Australian Research Council); ARC(Australian Research Council); Program for Changjiang Scholars(Program for Changjiang Scholars & Innovative Research Team in University (PCSIRT))	This work was partially supported by the National Science Fund of China under Grant U1713208, Program for Changjiang Scholars and "111" Program AH92005. This work was in part supported by an ARC Future Fellowship to C. Shen and an ARC DECRA Fellowship to L. Liu; and ARC Grant CE140100016. Y. Chen and X.-S. Wei's contributions were made when visiting The University of Adelaide.	Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Belagiannis V, 2017, IEEE INT CONF AUTOMA, P468, DOI 10.1109/FG.2017.64; Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Buehler P, 2011, INT J COMPUT VISION, V95, P180, DOI 10.1007/s11263-011-0480-9; Bulat A., 2017, P IEEE INT C COMP VI; Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742; Chen Y, 2016, INT C PATT RECOG, P313, DOI 10.1109/ICPR.2016.7899652; Chen Y, 2015, IEEE IMAGE PROC, P2115, DOI 10.1109/ICIP.2015.7351174; Chou CJ, 2018, ASIAPAC SIGN INFO PR, P17, DOI 10.23919/APSIPA.2018.8659538; Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126; Chu X, 2016, PROC CVPR IEEE, P4715, DOI 10.1109/CVPR.2016.510; Chu Xiao, 2017, PROC CVPR IEEE, P1831, DOI DOI 10.1109/CVPR.2017.601; Collobert R., 2011, NIPS; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; Deng JK, 2016, IMAGE VISION COMPUT, V47, P19, DOI 10.1016/j.imavis.2015.11.005; Denton Emily L, 2015, NEURIPS, V2, P4; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Dong XY, 2018, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.2018.00047; Du Y, 2016, LECT NOTES COMPUT SC, V9908, P20, DOI 10.1007/978-3-319-46493-0_2; Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9; Fan HQ, 2016, IMAGE VISION COMPUT, V47, P27, DOI 10.1016/j.imavis.2015.11.004; Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256; Ghezelghieh MF, 2016, INT CONF 3D VISION, P685, DOI 10.1109/3DV.2016.75; Gkioxari G, 2016, LECT NOTES COMPUT SC, V9908, P728, DOI 10.1007/978-3-319-46493-0_44; Gkioxari G, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.458; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Hu PY, 2016, PROC CVPR IEEE, P5600, DOI 10.1109/CVPR.2016.604; Huang SL, 2017, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2017.329; Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Johnson Sam, 2010, BMVC, DOI [10.5244/C.24.12, DOI 10.5244/C.24.12]; Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; Ke LP, 2018, LECT NOTES COMPUT SC, V11206, P731, DOI 10.1007/978-3-030-01216-8_44; Kim J, 2016, CHEMNANOMAT, V2, P156, DOI 10.1002/cnma.201500171; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Kowalski M, 2017, IEEE COMPUT SOC CONF, P2034, DOI 10.1109/CVPRW.2017.254; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; LEE HJ, 1985, COMPUT VISION GRAPH, V30, P148, DOI 10.1016/0734-189X(85)90094-5; Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326; Lifshitz I, 2016, LECT NOTES COMPUT SC, V9906, P246, DOI 10.1007/978-3-319-46475-6_16; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393; Ma B, 2015, IEEE I CONF COMP VIS, P4400, DOI 10.1109/ICCV.2015.500; Martinez B, 2016, IMAGE VISION COMPUT, V47, P36, DOI 10.1016/j.imavis.2015.09.003; Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288; Mathieu Michael, 2016, ICLR; Mirza M., 2014, ARXIV; Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Pavlakos G., 2017, P IEEE INT C ROB AUT, V2017, P2011, DOI [10.1109/ICRA.2017.7989233, DOI 10.1109/ICRA.2017.7989233]; Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533; Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433; Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052; Radford A., 2016, 4 INT C LEARNING REP; Rafi U., 2016, P BRIT MACH VIS C, P1, DOI DOI 10.5244/C.30.109; Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41; Reed S., 2016, P INT C MACH LEARN, P1; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Salimans T, 2016, ADV NEUR IN, V29; Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471; Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30; Scott J A, 1999, Breastfeed Rev, V7, P5; Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Tekin B, 2016, PROC CVPR IEEE, pCP8, DOI 10.1109/CVPR.2016.113; Tekin Bugra, 2016, BRIT MACH VIS C 2016, DOI DOI 10.5244/C.30.130; Tompson J.J., 2014, ADV NEURAL INFORM PR, V27, P1799; Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453; Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989; Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996; Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126; Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551; Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144; Yang W, 2016, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2016.335; YANG Y, 2011, PROC CVPR IEEE, P1385, DOI [10.1109/CVPR.2011.5995741, DOI 10.1109/CVPR.2011.5995741]; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31; Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1; Zhao J., 2017, PROC INT CONF LEARN; Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58; Zhou XW, 2017, IEEE T PATTERN ANAL, V39, P1648, DOI 10.1109/TPAMI.2016.2605097; Zhou XY, 2016, LECT NOTES COMPUT SC, V9915, P186, DOI 10.1007/978-3-319-49409-8_17; Zhou YP, 2016, LECT NOTES COMPUT SC, V9912, P262, DOI 10.1007/978-3-319-46484-8_16; Zhu SZ, 2016, PROC CVPR IEEE, P3409, DOI 10.1109/CVPR.2016.371; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	106	8	8	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1654	1669		10.1109/TPAMI.2019.2901875	http://dx.doi.org/10.1109/TPAMI.2019.2901875			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	30835211	Green Published, Green Submitted			2022-12-18	WOS:000542967200011
J	Veksler, O				Veksler, Olga			Efficient Graph Cut Optimization for Full CRFs with Quantized Edges	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image edge detection; Labeling; Inference algorithms; Computational modeling; Optimization methods; Approximation algorithms; Discrete optimization; graph cuts; fully connected CRFs	RANDOM-FIELDS; INFERENCE	Fully connected pairwise Conditional Random Fields (Full-CRF) with Gaussian edge weights can achieve superior results compared to sparsely connected CRFs. However, traditional methods for Full-CRFs are too expensive. Previous work develops efficient approximate optimization based on mean field inference, which is a local optimization method and can be far from the optimum. We propose efficient and effective optimization based on graph cuts for Full-CRFs with quantized edge weights. To quantize edge weights, we partition the image into superpixels and assume that the weight of an edge between any two pixels depends only on the superpixels these pixels belong to. Our quantized edge CRF is an approximation to the Gaussian edge CRF, and gets closer to it as superpixel size decreases. Being an approximation, our model offers an intuition about the regularization properties of the Guassian edge Full-CRF. For efficient inference, we first consider the two-label case and develop an approximate method based on transforming the original problem into a smaller domain. Then we handle multi-label CRF by showing how to implement expansion moves. In both binary and multi-label cases, our solutions have significantly lower energy compared to that of mean field inference. We also show the effectiveness of our approach on semantic segmentation task.	[Veksler, Olga] Univ Western Ontario, Dept Comp Sci, London N6A 3K7, England		Veksler, O (corresponding author), Univ Western Ontario, Dept Comp Sci, London N6A 3K7, England.	olga@csd.uwo.ca	Veksler, Olga/B-6549-2015	Veksler, Olga/0000-0002-9664-6601	Natural Sciences and Engineering Research Council, Canada (NSERC)	Natural Sciences and Engineering Research Council, Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC))	The funding for this research was provided by Natural Sciences and Engineering Research Council, Canada (NSERC).	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; [Anonymous], 2015, P 3 INT C LEARN REPR; [Anonymous], [No title captured]; [Anonymous], [No title captured]; Barron JT, 2016, LECT NOTES COMPUT SC, V9907, P617, DOI 10.1007/978-3-319-46487-9_38; BESAG J, 1986, J R STAT SOC B, V48, P259; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chen LC, 2015, PR MACH LEARN RES, V37, P1785; Desmaison A, 2016, LECT NOTES COMPUT SC, V9906, P818, DOI 10.1007/978-3-319-46475-6_50; diaeresis>ahenb <spacing diaeresis>uhl Philipp Kr<spacing, 2013, P 30 INT C MACH LEAR, P513; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb PF, 2010, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2010.5540067; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; Jampani V, 2016, PROC CVPR IEEE, P4452, DOI 10.1109/CVPR.2016.482; Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175; Koller D., 2009, PROBABILISTIC GRAPHI; Kolmogorov V., 2012, ARXIV12056352; Kolmogorov V, 2009, DISCRETE OPTIM, V6, P378, DOI 10.1016/j.disopt.2009.04.006; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96; Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8; Rother C, 2005, PROC CVPR IEEE, P589; Schlesinger D., 2006, TUDFI0601; Vedaldi A., 2016, MATCONVNET CNNS MATL; Veksler O., 1999, THESIS; Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16; Vineet V, 2014, INT J COMPUT VISION, V110, P290, DOI 10.1007/s11263-014-0708-6; Zhang YM, 2012, PROC CVPR IEEE, P582, DOI 10.1109/CVPR.2012.6247724; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179	30	8	8	2	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					1005	1012		10.1109/TPAMI.2019.2906204	http://dx.doi.org/10.1109/TPAMI.2019.2906204			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30908257	Green Submitted			2022-12-18	WOS:000526541100015
J	Huang, Y; Wu, Q; Wang, W; Wang, L				Huang, Yan; Wu, Qi; Wang, Wei; Wang, Liang			Image and Sentence Matching via Semantic Concepts and Order Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Image representation; Task analysis; Context modeling; Logic gates; Pattern matching; Image annotation; Semantic concept; semantic order; context-modulated attention; image and sentence matching		Image and sentence matching has made great progress recently, but it remains challenging due to the existing large visual-semantic discrepancy. This mainly arises from two aspects: 1) images consist of unstructured content which is not semantically abstract as the words in the sentences, so they are not directly comparable, and 2) arranging semantic concepts in different semantic order could lead to quite diverse meanings. The words in the sentences are sequentially arranged in a grammatical manner, while the semantic concepts in the images are usually unorganized. In this work, we propose a semantic concepts and order learning framework for image and sentence matching, which can improve the image representation by first predicting semantic concepts and then organizing them in a correct semantic order. Given an image, we first use a multi-regional multi-label CNN to predict its included semantic concepts in terms of object, property and action. These word-level semantic concepts are directly comparable with the words of noun, adjective and verb in the matched sentence. Then, to organize these concepts and make them express similar meanings as the matched sentence, we use a context-modulated attentional LSTM to learn the semantic order. It regards the predicted semantic concepts and image global scene as context at each timestep, and selectively attends to concept-related image regions by referring to the context in a sequential order. To further enhance the semantic order, we perform additional sentence generation on the image representation, by using the groundtruth order in the matched sentence as supervision. After obtaining the improved image representation, we learn the sentence representation with a conventional LSTM, and then jointly perform image and sentence matching and sentence generation for model learning. Extensive experiments demonstrate the effectiveness of our learned semantic concepts and order, by achieving the state-of-the-art results on two public benchmark datasets.	[Huang, Yan] Chinese Acad Sci CASIA, CRIPAC, Inst Automat, NLPR, Beijing 100864, Peoples R China; [Wu, Qi] Univ Adelaide, ACRV, Adelaide, SA 5005, Australia; [Wang, Wei; Wang, Liang] Chinese Acad Sci CASIA, Inst Automat, NLPR, CRIPAC,CEBSIT, Beijing 100864, Peoples R China; [Wang, Wei; Wang, Liang] Univ Chinese Acad Sci, Beijing 100049, Peoples R China	University of Adelaide; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Huang, Y (corresponding author), Chinese Acad Sci CASIA, CRIPAC, Inst Automat, NLPR, Beijing 100864, Peoples R China.	yhuang@nlpr.ia.ac.cn; qi.wu01@adelaide.edu.au; wangwei@nlpr.ia.ac.cn; wangliang@nlpr.ia.ac.cn	Wu, Qi/ABD-6304-2021; Huang, Yan/HCH-6526-2022	Wu, Qi/0000-0003-3631-256X; 	National Key Research and Development Program of China [2016YFB1001000]; National Natural Science Foundation of China [61525306, 61633021, 61721004, 61420106015]; Beijing Natural Science Foundation [4162058]; Capital Science and Technology Leading Talent Training Project [Z181100006318030]; Beijing Science and Technology Project [Z181100008918010]; Chinese Academy Sciences Artificial Intelligence Research (CAS-AIR)	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation); Capital Science and Technology Leading Talent Training Project; Beijing Science and Technology Project; Chinese Academy Sciences Artificial Intelligence Research (CAS-AIR)	This work is jointly supported by National Key Research and Development Program of China (2016YFB1001000), National Natural Science Foundation of China (61525306, 61633021, 61721004, 61420106015), Beijing Natural Science Foundation (4162058), Capital Science and Technology Leading Talent Training Project (Z181100006318030), and Beijing Science and Technology Project (Z181100008918010). This work is also supported by Chinese Academy Sciences Artificial Intelligence Research (CAS-AIR).	Albright TD, 2002, ANNU REV NEUROSCI, V25, P339, DOI 10.1146/annurev.neuro.25.112701.142900; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; [Anonymous], 2015, P INT C LEARN REPR; [Anonymous], 2017, P IEEE C COMP VIS PA; [Anonymous], 2014, P INT C LEARN REPR; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Ba J., 2015, P INT C LEARN REPR; Bengio S, 2015, ADV NEUR IN, V28; Bengio Y., 2014, P INT C LEARN REPR; Bindemann M, 2010, VISION RES, V50, P2577, DOI 10.1016/j.visres.2010.08.016; Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856; Chun MM, 1999, PSYCHOL SCI, V10, P360, DOI 10.1111/1467-9280.00168; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Faghri F., 2018, BRIT MACH VIS C BMVC; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Frome Andrea, 2013, NEURIPS; Gong Y, 2013, ARXIV13124894; Graves A, 2012, STUD COMPUT INTELL, V385, P15; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang Y, 2018, PROC CVPR IEEE, P6163, DOI 10.1109/CVPR.2018.00645; Huang Y, 2015, IEEE T MULTIMEDIA, V17, P1923, DOI 10.1109/TMM.2015.2476658; Huang YF, 2017, IEEE INT CONF COMP V, P2313, DOI 10.1109/ICCVW.2017.273; Karpathy A, 2014, ADV NEUR IN, V27; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Klein E, 2015, PROC CVPR IEEE, P4437, DOI 10.1109/CVPR.2015.7299073; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lev G, 2016, LECT NOTES COMPUT SC, V9910, P833, DOI 10.1007/978-3-319-46466-4_50; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Y, 2017, IEEE I CONF COMP VIS, P4127, DOI 10.1109/ICCV.2017.442; Ma L, 2015, IEEE I CONF COMP VIS, P2623, DOI 10.1109/ICCV.2015.301; Mikolov T., 2013, 1 INT LEARN REPR ICL; Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111; Perronnin F, 2007, PROC CVPR IEEE, P2272; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320; Richard S. Zemel, 2014, Arxiv, DOI arXiv:1411.2539; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Tseng PH, 2009, J VISION, V9, DOI 10.1167/9.7.4; Vendrov I., 2016, P INT C LEARN REPR; Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251; Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541; Wang W, 2011, PROC CVPR IEEE, P441, DOI 10.1109/CVPR.2011.5995423; Wei Y., 2014, ARXIV PREPRINT ARXIV; Wu JJ, 2015, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2015.7298968; Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966; You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503; Young Peter, 2014, T ASSOC COMPUT LING, V2, P67	60	8	11	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					636	650		10.1109/TPAMI.2018.2883466	http://dx.doi.org/10.1109/TPAMI.2018.2883466			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30507493				2022-12-18	WOS:000525365300009
J	Liu, H; Lu, JW; Guo, MH; Wu, SP; Zhou, J				Liu, Hao; Lu, Jiwen; Guo, Minghao; Wu, Suping; Zhou, Jie			Learning Reasoning-Decision Networks for Robust Face Alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape; Face; Training; Neural networks; Two dimensional displays; Computer architecture; Face alignment; deep neural networks; deep reinforcement learning; policy gradient		In this paper, we propose an end-to-end reasoning-decision networks (RDN) approach for robust face alignment via policy gradient. Unlike the conventional coarse-to-fine approaches which likely lead to bias prediction due to poor initialization, our approach aims to learn a policy by leveraging raw pixels to reason a subset of shape candidates, sequentially making plausible decisions to remove outliers for robust initialization. To achieve this, we formulate face alignment as a Markov decision process by defining an agent, which typically interacts with a trajectory of states, actions, state transitions and rewards. The agent seeks an optimal shape searching policy over the whole shape space by maximizing a discounted sum of the received values. To further improve the alignment performance, we develop an LSTM-based value function to evaluate the shape quality. During the training procedure, we adjust the gradient of our value function in directions of the policy gradient. This prevents our training goal from being trapped into local optima entangled by both the pose deformations and appearance variations especially in unconstrained environments. Experimental results show that our proposed RDN consistently outperforms most state-of-the-art approaches on four widely-evaluated challenging datasets.	[Liu, Hao; Wu, Suping] Ningxia Univ, Sch Informat Engn, Yinchuan 750021, Ningxia, Peoples R China; [Liu, Hao; Lu, Jiwen; Guo, Minghao; Zhou, Jie] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Lu, Jiwen; Guo, Minghao; Zhou, Jie] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China	Ningxia University; Tsinghua University; Tsinghua University	Lu, JW (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.; Lu, JW (corresponding author), Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.	liuhao@nxu.edu.cn; lujiwen@tsinghua.edu.cn; gmh14@mails.tsinghua.edu.cn; pswuu@nxu.edu.cn; jzhou@tsinghua.edu.cn	Liu, Hao/AAE-2455-2020; Lu, Jiwen/C-5291-2009	Liu, Hao/0000-0003-0954-5405; Lu, Jiwen/0000-0002-6121-5529; Guo, Minghao/0000-0003-3408-4997	National Key Research and Development Program of China [2017YFA0700802]; National Natural Science Foundation of China [61822603, 61806104, U1713214, 61662059, 61527808]; Shenzhen fundamental research fund (subject arrangement) [JCYJ20170412170602564]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shenzhen fundamental research fund (subject arrangement)	This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFA0700802, in part by the National Natural Science Foundation of China under Grant 61822603, Grant 61806104, Grant U1713214, Grant 61662059 and Grant 61527808, and in part by Shenzhen fundamental research fund (subject arrangement) under Grant JCYJ20170412170602564.	Abadi M, 2015, P 12 USENIX S OPERAT; Abou-Moustafa KT, 2010, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2010.5539925; Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442; Baltrusaitis T, 2016, IEEE WINT CONF APPL; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cootes TF, 2012, LECT NOTES COMPUT SC, V7578, P278, DOI 10.1007/978-3-642-33786-4_21; Deng JK, 2016, IMAGE VISION COMPUT, V47, P19, DOI 10.1016/j.imavis.2015.11.005; Deng Jiankang, 2017, ARXIV170806023; Dong XY, 2018, PROC CVPR IEEE, P360, DOI 10.1109/CVPR.2018.00045; DULACARNOLD G, 2015, CORR; Fan HQ, 2016, IMAGE VISION COMPUT, V47, P27, DOI 10.1016/j.imavis.2015.11.004; Ghiasi G, 2014, PROC CVPR IEEE, P1899, DOI 10.1109/CVPR.2014.306; GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478; Guler RA, 2017, PROC CVPR IEEE, P2614, DOI 10.1109/CVPR.2017.280; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; HOSU I, 2016, CORR; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Huang ZW, 2013, IEEE I CONF COMP VIS, P3296, DOI 10.1109/ICCV.2013.409; Jie ZQ, 2016, ADV NEUR IN, V29; Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347; Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454; Jourabloo A, 2015, IEEE I CONF COMP VIS, P3694, DOI 10.1109/ICCV.2015.421; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; KHAN MH, 2017, P IEEE INT C COMP VI; Kostinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Krull A, 2017, PROC CVPR IEEE, P2566, DOI 10.1109/CVPR.2017.275; Kumar A, 2018, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2018.00052; Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Li Yuxi, 2017, ARXIV170107274; Lillicrap TP, 2016, 4 INT C LEARN REPR; Liu F, 2016, LECT NOTES COMPUT SC, V9909, P545, DOI 10.1007/978-3-319-46454-1_33; Liu H, 2018, IEEE T PATTERN ANAL, V40, P2546, DOI 10.1109/TPAMI.2017.2734779; Liu H, 2017, IEEE T IMAGE PROCESS, V26, P1666, DOI 10.1109/TIP.2017.2657118; Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100; Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; PALMER G, 2017, CORR; Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3; PINHERIO R, 2014, P INT C MACH LEARN; Pirinen A, 2018, PROC CVPR IEEE, P6945, DOI 10.1109/CVPR.2018.00726; Rao JF, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1217, DOI 10.1145/3077136.3080648; Rao YM, 2018, PROC CVPR IEEE, P6190, DOI 10.1109/CVPR.2018.00648; Rao YM, 2017, IEEE I CONF COMP VIS, P3951, DOI 10.1109/ICCV.2017.424; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Ren Zhou, 2017, PROC CVPR IEEE, P290, DOI DOI 10.1109/CVPR.2017.128; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Sanchez-Lozano E, 2016, LECT NOTES COMPUT SC, V9912, P645, DOI 10.1007/978-3-319-46484-8_39; Schaul T, 2015, P INT C LEARN REPR; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Shi B., 2014, ARXIV14095230; Silver D, 2014, PR MACH LEARN RES, V32; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; SONG G, 2018, P IEEE C COMP VIS PA; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Supancic J, 2017, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2017.43; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558; Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453; Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989; Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239; van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094; Wang Z., 2016, SER P MACHINE LEARNI, DOI DOI https://doi.org/10.1016/j.molstruc.2016.06.044; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Wu WY, 2018, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2018.00227; Wu Y, 2015, IEEE I CONF COMP VIS, P3658, DOI 10.1109/ICCV.2015.417; Wu Y, 2015, INT J COMPUT VISION, V113, P37, DOI 10.1007/s11263-014-0775-8; Xiao ST, 2016, LECT NOTES COMPUT SC, V9905, P57, DOI 10.1007/978-3-319-46448-0_4; Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yang H, 2015, IEEE T IMAGE PROCESS, V24, P2393, DOI 10.1109/TIP.2015.2421438; Yu X, 2016, LECT NOTES COMPUT SC, V9909, P52, DOI 10.1007/978-3-319-46454-1_4; Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148; Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1; Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286; Zhu SZ, 2016, PROC CVPR IEEE, P3409, DOI 10.1109/CVPR.2016.371; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	86	8	8	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					679	693		10.1109/TPAMI.2018.2885298	http://dx.doi.org/10.1109/TPAMI.2018.2885298			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30530310				2022-12-18	WOS:000525365300012
J	Liu, F; Xiang, T; Hospedales, TM; Yang, WK; Sun, CY				Liu, Feng; Xiang, Tao; Hospedales, Timothy M.; Yang, Wankou; Sun, Changyin			Inverse Visual Question Answering: A New Benchmark and VQA Diagnosis Tool	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Benchmark testing; Visualization; Predictive models; Analytical models; Image color analysis; Knowledge discovery; Task analysis; Inverse visual question answering; VQA visualisation; visuo-linguistic understanding; reinforcement learning		In recent years, visual question answering (VQA) has become topical. The premise of VQA's significance as a benchmark in AI, is that both the image and textual question need to be well understood and mutually grounded in order to infer the correct answer. However, current VQA models perhaps 'understand' less than initially hoped, and instead master the easier task of exploiting cues given away in the question and biases in the answer distribution [1] . In this paper we propose the inverse problem of VQA (iVQA). The iVQA task is to generate a question that corresponds to a given image and answer pair. We propose a variational iVQA model that can generate diverse, grammatically correct and content correlated questions that match the given answer. Based on this model, we show that iVQA is an interesting benchmark for visuo-linguistic understanding, and a more challenging alternative to VQA because an iVQA model needs to understand the image better to be successful. As a second contribution, we show how to use iVQA in a novel reinforcement learning framework to diagnose any existing VQA model by way of exposing its belief set: the set of question-answer pairs that the VQA model would predict true for a given image. This provides a completely new window into what VQA models 'believe' about images. We show that existing VQA models have more erroneous beliefs than previously thought, revealing their intrinsic weaknesses. Suggestions are then made on how to address these weaknesses going forward.	[Liu, Feng; Yang, Wankou; Sun, Changyin] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China; [Xiang, Tao] Queen Mary Univ London, Sch Elect Engn & Comp Sci, Comp Vis & Multimedia, London E1 4NS, England; [Hospedales, Timothy M.] Univ Edinburgh, Sch Informat, IPAB, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland	Southeast University - China; University of London; Queen Mary University London; University of Edinburgh	Sun, CY (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.	liufeng@seu.edu.cn; t.xiang@qmul.ac.uk; t.hospedales@ed.ac.uk; wkyang@seu.edu.cn; cysun@seu.edu.cn	SUN, CHANG/GXM-3680-2022	Yang, Wankou/0000-0002-6385-6776; Hospedales, Timothy/0000-0003-4867-7486	Natural Science Foundation of China (NSFC) [U1713209, 61520106009, 61773117]; Scientific Research Foundation of Graduate School of Southeast University [YBJJ1520]; China Scholarship Council (CSC)	Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Scientific Research Foundation of Graduate School of Southeast University; China Scholarship Council (CSC)(China Scholarship Council)	This project received support from Natural Science Foundation of China (NSFC) grant #U1713209, #61520106009, 61773117, the Scientific Research Foundation of Graduate School of Southeast University grant #YBJJ1520, and the China Scholarship Council (CSC).	Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522; Agrawal A, 2017, INT J COMPUT VISION, V123, P4, DOI 10.1007/s11263-016-0966-6; Agrawal Aishwarya, 2016, ARXIV160607356; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; [Anonymous], 2018, P INT C LEARN REPR; [Anonymous], 2017, P INT C LEARN REPR; [Anonymous], ABS171101732 CORR; [Anonymous], 2016, ARXIV160808974; Bilen H, 2016, ADV NEUR IN, V29; Chen X, 2015, CORR, V1504, P325; Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121; Das Abhishek, 2016, P C EMP METH NAT LAN, P932; Devlin J., 2015, ARXIV PREPRINT ARXIV; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; FESTINGER L, 1962, SCI AM, V207, P93, DOI 10.1038/scientificamerican1062-93; Fukui Akira, 2016, ARXIV160601847; Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Goodfellow I. J., 2015, INT C LEARN REPR ICL; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu RH, 2017, IEEE I CONF COMP VIS, P804, DOI 10.1109/ICCV.2017.93; Ilievski I, 2017, ADV NEUR IN, V30; Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44; Jain U, 2017, PROC CVPR IEEE, P5415, DOI 10.1109/CVPR.2017.575; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, P787, DOI DOI 10.3115/V1/D14-1086; Liu F, 2017, PROC CVPR IEEE, P4160, DOI 10.1109/CVPR.2017.443; Liu FC, 2018, COMPLEXITY, DOI 10.1155/2018/7875460; Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51; Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345; Mahendru Aroma, 2017, ARXIV170500601, P926; Malinowski M., 2014, ADV NEURAL INFORM PR, V27, P1682; Malinowski M., 2014, ABS14108027 CORR; Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9; Mostafazadeh N, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1802; Mostafazadeh Nasrin, 2017, P 8 INT JOINT C NAT, V1, P462; Papernot N, 2016, IEEE MILIT COMMUN C, P49, DOI 10.1109/MILCOM.2016.7795300; Pfungst O., 1911, CLEVER HANS THE HORS, DOI 10.5962/bhl.title.56164; Ray Arijit, 2016, ARXIV160606622; Ren MY, 2015, ADV NEUR IN, V28; Settles B., 2012, SYNTH LECT ARTIF INT, V6, P1; Szegedy C., 2014, ICLR 2014; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246; Wang P, 2017, PROC CVPR IEEE, P3909, DOI 10.1109/CVPR.2017.416; Welling M, 2014, AUTOENCODING VARIATI; Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67; Yosinski J., 2015, ICML DEEP LEARN WORK; Yu LT, 2017, AAAI CONF ARTIF INTE, P2852; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang SJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4235; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	61	8	8	2	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					460	474		10.1109/TPAMI.2018.2880185	http://dx.doi.org/10.1109/TPAMI.2018.2880185			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	30418897	Green Submitted			2022-12-18	WOS:000508386100016
J	Roth, W; Pernkopf, F				Roth, Wolfgang; Pernkopf, Franz			Bayesian Neural Networks with Weight Sharing Using Dirichlet Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Artificial neural networks; Bayes methods; Computational modeling; Task analysis; Monte Carlo methods; Memory management; Dirichlet processes; Bayesian neural networks; weight sharing; Gibbs sampling; hybrid Monte-Carlo; non-conjugate models	UNCERTAINTY; DROPOUT	We extend feed-forward neural networks with a Dirichlet process prior over the weight distribution. This enforces a sharing on the network weights, which can reduce the overall number of parameters drastically. We alternately sample from the posterior of the weights and the posterior of assignments of network connections to the weights. This results in a weight sharing that is adopted to the given data. In order to make the procedure feasible, we present several techniques to reduce the computational burden. Experiments show that our approach mostly outperforms models with random weight sharing. Our model is capable of reducing the memory footprint substantially while maintaining a good performance compared to neural networks without weight sharing.	[Roth, Wolfgang; Pernkopf, Franz] Graz Univ Technol, Signal Proc & Speech Commun Lab, A-8010 Graz, Styria, Austria	Graz University of Technology	Roth, W (corresponding author), Graz Univ Technol, Signal Proc & Speech Commun Lab, A-8010 Graz, Styria, Austria.	roth@tugraz.at; pernkopf@tugraz.at		Pernkopf, Franz/0000-0002-6356-3367	Austrian Science Fund (FWF) [P27803-N15, I2706-N31]	Austrian Science Fund (FWF)(Austrian Science Fund (FWF))	This work was supported by the Austrian Science Fund (FWF) under the project numbers P27803-N15 and I2706-N31.	Ahn S., 2012, P 29 INT C MACH LEAR; [Anonymous], 1992, CRGTR921 U TOR DEP C; ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871; Balan Anoop Korattikara, 2015, ADV NEURAL INFORM PR, P3; Bengio Y., 2007, P 24 INT C MACH LEAR, P473, DOI DOI 10.1145/1273496.1273556; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; Blundell C, 2015, PR MACH LEARN RES, V37, P1613; Chang J., 2013, ADV NEURAL INFORM PR, P620; Chen TQ, 2014, PR MACH LEARN RES, V32, P1683; Chen WL, 2015, PR MACH LEARN RES, V37, P2285; DUANE S, 1987, PHYS LETT B, V195, P216, DOI 10.1016/0370-2693(87)91197-X; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; FRITSCH FN, 1980, SIAM J NUMER ANAL, V17, P238, DOI 10.1137/0717021; Gal Y, 2016, PR MACH LEARN RES, V48; Gershman SJ, 2012, J MATH PSYCHOL, V56, P1, DOI 10.1016/j.jmp.2011.08.004; Graves A., 2011, ADV NEURAL INFORM PR, P2348, DOI DOI 10.5555/2986459.2986721; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hernandez-Lobato JM, 2015, PR MACH LEARN RES, V37, P1861; Hinton G. E., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, P5, DOI 10.1145/168304.168306; Jain S, 2004, J COMPUT GRAPH STAT, V13, P158, DOI 10.1198/1061860043001; Kingma D.P., 2015, ICLR, P1; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; Nair V., 2010, ICML, P807; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; NOWLAN SJ, 1992, NEURAL COMPUT, V4, P473, DOI 10.1162/neco.1992.4.4.473; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Wang Z., 2013, ICML, P1462; Welling M., 2011, P 28 INT C INT C MAC, P681, DOI DOI 10.4310/CIS.2012.V12.N3.A3	33	8	9	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					246	252		10.1109/TPAMI.2018.2884905	http://dx.doi.org/10.1109/TPAMI.2018.2884905			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30530353				2022-12-18	WOS:000502294300019
J	Su, B; Hua, G				Su, Bing; Hua, Gang			Order-Preserving Optimal Transport for Distances between Sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape; Distortion; Legged locomotion; Distortion measurement; Indexes; Supervised learning; Optimal transport; sequence matching; order-preserving Wasserstein distance; temporal regularization; inverse difference moment	EARTH-MOVERS-DISTANCE; DIMENSIONALITY REDUCTION; DIAGONAL EQUIVALENCE; ACTION RECOGNITION; TIME; ALGORITHM; MATRIX	We present new distance measures between sequences that can tackle local temporal distortion and periodic sequences with arbitrary starting points. Through viewing the instances of each sequence as empirical samples of an unknown distribution, we cast the calculations of distances between sequences as optimal transport problems. To preserve the inherent temporal relationships of the instances in sequences, we propose two methods through incorporating the temporal information into the spatial ground metric and concentrating the transport with two novel temporal regularization terms, respectively. The inverse difference moment regularization enforces local homogeneous structures in the transport, and the KL-divergence with a prior distribution regularization prevents transport between instances with far temporal positions. We show that the resulting problems can be efficiently solved by the matrix scaling algorithm. Extensive experiments on eight datasets with different classifiers and performance measures show the effectiveness and generality of the proposed distances.	[Su, Bing] Chinese Acad Sci, Inst Software, Sci & Technol Integrated Informat Syst Lab, Beijing 100190, Peoples R China; [Hua, Gang] Microsoft Res, Redmond, WA 98052 USA	Chinese Academy of Sciences; Institute of Software, CAS; Microsoft	Su, B (corresponding author), Chinese Acad Sci, Inst Software, Sci & Technol Integrated Informat Syst Lab, Beijing 100190, Peoples R China.	subingats@gmail.com; ganghua@gmail.com	Su, Bing/ABC-4813-2020		National Natural Science Foundation of China (NSFC) [61603373, 61629301]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	The authors would like to thank the anonymous reviewers for their valuable comments. This work was supported by the National Natural Science Foundation of China (NSFC) under Grant No.61603373 and No.61629301.	Al-Naymat G., 2009, AUSTRALASIAN DATA MI, V101, P117, DOI DOI 10.1007/s10115-004-0154-9; Albregtsen Fritz, 2008, STAT TEXTURE MEASURE, V5; Araya M., 2015, P ADV NEUR INF PROC, P2053; Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257; Borobia A, 1998, LINEAR ALGEBRA APPL, V268, P1, DOI 10.1016/S0024-3795(97)00010-4; BRUALDI RA, 1966, J MATH ANAL APPL, V16, P31, DOI 10.1016/0022-247X(66)90184-3; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; Chen Y, 2015, UCR TIME SERIES CLAS; Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921; CUTURI M., 2013, P INT C ADV NEURAL I, V26; Cuturi M, 2017, PR MACH LEARN RES, V70; Cuturi M, 2014, PR MACH LEARN RES, V32, P685; Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; Flamary R, 2018, MACH LEARN, V107, P1923, DOI 10.1007/s10994-018-5717-1; FRANKLIN J, 1989, LINEAR ALGEBRA APPL, V114, P717, DOI 10.1016/0024-3795(89)90490-4; Genevay A., 2016, P NEUR INF PROC SYST, P3440; Grauman K., 2004, P IEEE COMP SOC C CO, V1, pI; Kadous M.W., 2002, THESIS; Kolouri S., 2016, ARXIV160904767; Kolouri S, 2017, IEEE SIGNAL PROC MAG, V34, P43, DOI 10.1109/MSP.2017.2695801; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lajugie R., 2014, ADV NEURAL INFORM PR, P1817; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Lichman M, 2013, UCI MACHINE LEARNING; Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Ratanamahatana CA, 2004, SIAM PROC S, P11; Ren Z, 2011, P 19 ACM INT C MULT, DOI DOI 10.1145/2072298.2071946; Rodriguez-Serrano JA, 2012, IEEE T PATTERN ANAL, V34, P2108, DOI 10.1109/TPAMI.2012.25; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508; SEGUY V, 2015, ADV NEURAL INFORM PR, V28, P3312; SINKHORN R, 1967, AM MATH MON, V74, P402, DOI 10.2307/2314570; Su B, 2018, IEEE T IMAGE PROCESS, V27, P4052, DOI 10.1109/TIP.2018.2836312; Su B, 2017, PROC CVPR IEEE, P2906, DOI 10.1109/CVPR.2017.310; Su B, 2018, IEEE T PATTERN ANAL, V40, P77, DOI 10.1109/TPAMI.2017.2665545; Su B, 2017, IEEE T IMAGE PROCESS, V26, P3579, DOI 10.1109/TIP.2017.2704438; Su B, 2016, LECT NOTES COMPUT SC, V9908, P202, DOI 10.1007/978-3-319-46493-0_13; Su B, 2015, PROC CVPR IEEE, P4539, DOI 10.1109/CVPR.2015.7299084; Su B, 2013, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2013.115; Su JY, 2014, ANN APPL STAT, V8, P530, DOI 10.1214/13-AOAS701; Thorpe M, 2017, J MATH IMAGING VIS, V59, P187, DOI 10.1007/s10851-017-0726-4; Villani C, 2009, GRUNDLEHR MATH WISS, V338, P5; Wang J, 2013, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2013.334; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Zhou F., 2009, ADV NEURAL INFORM PR, V22, P2286; Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812	50	8	8	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2961	2974		10.1109/TPAMI.2018.2870154	http://dx.doi.org/10.1109/TPAMI.2018.2870154			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30235117				2022-12-18	WOS:000498677600013
J	Tian, T; Jun, Z; You, QB				Tian Tian; Jun Zhu; You Qiaoben			Max-Margin Majority Voting for Learning from Crowds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Max-margin learning; crowdsourcing; online learning; regularized Bayesian inference	POSTERIOR REGULARIZATION	Learning-from-crowds aims to design proper aggregation strategies to infer the unknown true labels from the noisy labels provided by ordinary web workers. This paper presents max-margin majority voting ((MV)-V-3) to improve the discriminative ability of majority voting and further presents a Bayesian generalization to incorporate the flexibility of generative methods on modeling noisy observations with worker confusion matrices for different application settings. We first introduce the crowdsourcing margin of majority voting, then we formulate the joint learning as a regularized Bayesian inference (RegBayes) problem, where the posterior regularization is derived by maximizing the margin between the aggregated score of a potential true label and that of any alternative label. Our Bayesian model naturally covers the Dawid-Skene estimator and (MV)-V-3 as its two special cases. Due to the flexibility of our model, we extend it to handle crowdsourced labels with an ordinal structure with the main ideas about the crowdsourcing margin unchanged. Moreover, we consider an online learning-from-crowds setting where labels coming in a stream. Empirical results demonstrate that our methods are competitive, often achieving better results than state-of-the-art estimators.	[Tian Tian; Jun Zhu; You Qiaoben] Tsinghua Univ, Dept Comp Sci & Technol, Inst Artificial Intelligence,Tsinghua Lab Brain &, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China	Tsinghua University	Jun, Z (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Inst Artificial Intelligence,Tsinghua Lab Brain &, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.	rossowhite@163.com; dcszj@tsinghua.edu.cn; qby_222@126.com			NSFC [61620106010, 61621136008, 61332007]; Beijing NSF [L172037]; MIIT Grant of Int. Man. Comp. Stan [2016ZXFB00001]; Youth Top-notch Talent Support Program; Tiangong Institute for Intelligent Computing; NVIDIA NVAIL Program; Siemens; Intel	NSFC(National Natural Science Foundation of China (NSFC)); Beijing NSF(National Natural Science Foundation of China (NSFC)); MIIT Grant of Int. Man. Comp. Stan; Youth Top-notch Talent Support Program; Tiangong Institute for Intelligent Computing; NVIDIA NVAIL Program; Siemens(Siemens AG); Intel(Intel Corporation)	This work was supported by NSFC Projects (Nos. 61620106010, 61621136008, 61332007), Beijing NSF Project (No. L172037), MIIT Grant of Int. Man. Comp. Stan (No. 2016ZXFB00001), the Youth Top-notch Talent Support Program, Tiangong Institute for Intelligent Computing, NVIDIA NVAIL Program, Siemens and Intel.	Carlson A, 2010, AAAI CONF ARTIF INTE, P1306; Cauwenberghs G, 2001, ADV NEUR IN, V13, P409; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen CY, 2014, ADV NEUR IN, V27; Chen X, 2016, J MACH LEARN RES, V17; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Dawid A.P., 1979, APPL STAT, V28, P20, DOI [10.2307/2346806, DOI 10.2307/2346806]; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Duchi J, 2011, J MACH LEARN RES, V12, P2121; Dudik M, 2007, J MACH LEARN RES, V8, P1217; Ganchev K, 2010, J MACH LEARN RES, V11, P2001; Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759; Jagabathula S., 2014, ADV NEURAL INFORM PR, P2492; Jing L, 2012, INT J PHOTOENERGY, V2012, DOI 10.1155/2012/630692; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kajino Hiroshi, 2012, P HUM COMP WORKSH, P107; Karger D. R., 2011, ADV NEURAL INFORM PR, P1953; Li C, 2014, 2014 IEEE 17th International Conference on Computational Science and Engineering (CSE), P1758, DOI 10.1109/CSE.2014.322; Li H., 2014, ARXIV14114086; MICHAEL JR, 1976, AM STAT, V30, P88, DOI 10.2307/2683801; Hung NQV, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P999, DOI 10.1145/2723372.2723731; PeterWelinder Steve Branson, 2010, P NIPS, V23, P1; Polson NG, 2011, BAYESIAN ANAL, V6, P1, DOI 10.1214/11-BA601; Qingyang Hu, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference (PAKDD 2014). Proceedings: LNCS 8443, P200, DOI 10.1007/978-3-319-06608-0_17; Raykar VC, 2010, J MACH LEARN RES, V11, P1297; Settles B., 2010, 1648 U WISC MAD DEP, DOI DOI 10.1016/J.MATLET.2010.11.072; Shah NB, 2015, ADV NEURAL INFORM PR, V28, P1; Shi T., 2014, P 31 INT C MACH LEAR, P595; Snow Rion, 2008, P 2008 C EMP METH NA, P254, DOI DOI 10.3115/1613715.1613751; Tian T, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1100, DOI 10.1145/2736277.2741136; Tian T, 2015, ADV NEUR IN, V28; Tian T, 2015, LECT NOTES ARTIF INT, V9077, P392, DOI 10.1007/978-3-319-18038-0_31; Venanzi M, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P155, DOI 10.1145/2566486.2567989; Wang L., 2016, P 25 INT JOINT C ART, P2111; Wauthier F.L., 2011, ADV NEURAL INFORM PR, P1800; Whitehill J., 2009, ADV NEURAL INFORM PR, P2035; Xu L., 2005, P 20 NAT C ART INT, V2, P904; Xu M, 2013, P 30 INT C MACH LEAR, P978; Yin M, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P1293, DOI 10.1145/2872427.2883036; Zaidan Omar F., 2011, P 49 ANN M ASS COMP, P1220; Zhou DY, 2014, PR MACH LEARN RES, V32, P262; Zhou Dengyong, 2012, ADV NEURAL INFORM PR, P2204; Zhu J, 2014, J MACH LEARN RES, V15, P1799; Zhu J, 2014, J MACH LEARN RES, V15, P1073	44	8	8	3	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2480	2494		10.1109/TPAMI.2018.2860987	http://dx.doi.org/10.1109/TPAMI.2018.2860987			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30072312				2022-12-18	WOS:000489763000015
J	Heo, JP; Lin, Z; Yoon, SE				Heo, Jae-Pil; Lin, Zhe; Yoon, Sung-Eui			Distance Encoded Product Quantization for Approximate K-Nearest Neighbor Search in High-Dimensional Space	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Vector quantization; nearest neighbor search; image retrieval; compact code; high-dimensional search		Approximate K-nearest neighbor search is a fundamental problem in computer science. The problem is especially important for high-dimensional and large-scale data. Recently, many techniques encoding high-dimensional data to compact codes have been proposed. The product quantization and its variations that encode the cluster index in each subspace have been shown to provide impressive accuracy. In this paper, we explore a simple question: is it best to use all the bit-budget for encoding a cluster index? We have found that as data points are located farther away from the cluster centers, the error of estimated distance becomes larger. To address this issue, we propose a novel compact code representation that encodes both the cluster index and quantized distance between a point and its cluster center in each subspace by distributing the bit-budget. We also propose two distance estimators tailored to our representation. We further extend our method to encode global residual distances in the original space. We have evaluated our proposed methods on benchmarks consisting of GIST, VLAD, and CNN features. Our extensive experiments show that the proposed methods significantly and consistently improve the search accuracy over other tested techniques. This result is achieved mainly because our methods accurately estimate distances.	[Heo, Jae-Pil] Sungkyunkwan Univ, Suwon 16419, South Korea; [Lin, Zhe] Adobe Res, San Jose, CA 95110 USA; [Yoon, Sung-Eui] Korea Adv Inst Sci & Technol, Daejeon 34141, South Korea	Sungkyunkwan University (SKKU); Adobe Systems Inc.; Korea Advanced Institute of Science & Technology (KAIST)	Heo, JP (corresponding author), Sungkyunkwan Univ, Suwon 16419, South Korea.	jaepilheo@gmail.com; zlin@adobe.com; sungeui@kaist.edu	Yoon, Sung-eui/C-1678-2011		Basic Science Research Program [NRF-2017R1D1A1B03036330]; SW Starlab [IITP-2015-0-00199]; Grand Information Technology Research Center support program [IITP-2018-2015-000742]	Basic Science Research Program; SW Starlab; Grand Information Technology Research Center support program	The authors would like to think anonymous reviewers for constructive comments. This work was supported in part by Basic Science Research Program (NRF-2017R1D1A1B03036330), SW Starlab (IITP-2015-0-00199), and Grand Information Technology Research Center support program (IITP-2018-2015-000742). This manuscript is extended from the conference paper version [35].	Ai L., 2015, MULTIMEDIA SYST, V23, P169; Banerjee A, 2002, SIAM PROC S, P333; Blum A., 2010, FDN DATA SCI; Brandt J, 2010, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2010.5539852; Cai T, 2013, J MACH LEARN RES, V14, P1837; Charikar M.S., 2002, P 34 ANN ACM S THEOR, V34, P380, DOI DOI 10.1145/509907.509965; Chen YJ, 2010, SENSORS-BASEL, V10, P11259, DOI 10.3390/s101211259; Chum O, 2008, P BRIT MACH VIS C, V1, P493; cker Chiueh T., 1994, P 20 INT C VER LARG, P582; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240; Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379; Gersho A., 1991, VECTOR QUANTIZATION; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266; He JF, 2011, PROC CVPR IEEE, P753, DOI 10.1109/CVPR.2011.5995518; Heo JP, 2015, IEEE T PATTERN ANAL, V37, P2304, DOI 10.1109/TPAMI.2015.2408363; Heo JP, 2014, PROC CVPR IEEE, P2139, DOI 10.1109/CVPR.2014.274; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jia Y, 2010, PROC CVPR IEEE, P3392, DOI 10.1109/CVPR.2010.5540006; Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451; Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824	35	8	8	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2084	2097		10.1109/TPAMI.2018.2853161	http://dx.doi.org/10.1109/TPAMI.2018.2853161			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	29994392				2022-12-18	WOS:000480343900004
J	Pillonetto, G; Schenato, L; Varagnolo, D				Pillonetto, Gianluigi; Schenato, Luca; Varagnolo, Damiano			Distributed Multi-Agent Gaussian Regression via Finite-Dimensional Approximations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian processes; sensor networks; distributed estimation; kernel-based regularization; nonparametric estimation; average consensus	NYSTROM METHOD; REGULARIZATION; PREDICTION; SELECTION; NETWORKS; MODELS; BOUNDS; SPEED	We consider the problem of distributedly estimating Gaussian processes in multi-agent frameworks. Each agent collects few measurements and aims to collaboratively reconstruct a common estimate based on all data. Agents are assumed with limited computational and communication capabilities and to gather M noisy measurements in total on input locations independently drawn from a known common probability density. The optimal solution would require agents to exchange all the M input locations and measurements and then invert an M x M matrix, a non-scalable task. Differently, we propose two suboptimal approaches using the first E orthonormal eigenfunctions obtained from the Karhunen-Loeve (KL) expansion of the chosen kernel, where typically E << M. The benefits are that the computation and communication complexities scale with E and not with M, and computing the required statistics can be performed via standard average consensus algorithms. We obtain probabilistic non-asymptotic bounds that determine a priori the desired level of estimation accuracy, and new distributed strategies relying on Stein's unbiased risk estimate (SURE) paradigms for tuning the regularization parameters and applicable to generic basis functions (thus not necessarily kernel eigenfunctions) and that can again be implemented via average consensus. The proposed estimators and bounds are finally tested on both synthetic and real field data.	[Pillonetto, Gianluigi; Schenato, Luca] Univ Padua, Dept Informat Engn, I-35122 Padua, Italy; [Varagnolo, Damiano] Lulea Univ Technol, Dept Comp Sci Elect & Space Engn, S-97187 Lulea, Sweden	University of Padua; Lulea University of Technology	Varagnolo, D (corresponding author), Lulea Univ Technol, Dept Comp Sci Elect & Space Engn, S-97187 Lulea, Sweden.	giapi@dei.unipd.it; schenato@dei.unipd.it; damvar@ltu.se	Varagnolo, Damiano/ABD-8302-2020	Varagnolo, Damiano/0000-0002-4310-7938; SCHENATO, LUCA/0000-0003-2544-2553	Swedish research council Norrbottens Forskningsrad	Swedish research council Norrbottens Forskningsrad	The research leading to these results has received funding from the Swedish research council Norrbottens Forskningsrad.	Ambikasaran S, 2016, IEEE T PATTERN ANAL, V38, P252, DOI 10.1109/TPAMI.2015.2448083; Aravkin A, 2014, J MACH LEARN RES, V15, P217; Bach F.R., 2005, P 22 INT C MACH LEAR, P33, DOI DOI 10.1145/1102351.1102356; Bell BM, 2004, INVERSE PROBL, V20, P627, DOI 10.1088/0266-5611/20/3/001; Bof N, 2017, IFAC PAPERSONLINE, V50, P601, DOI 10.1016/j.ifacol.2017.08.093; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Choi J, 2009, AUTOMATICA, V45, P2802, DOI 10.1016/j.automatica.2009.09.025; Cortes J, 2009, IEEE T AUTOMAT CONTR, V54, P2816, DOI 10.1109/TAC.2009.2034192; Cucker F, 2002, B AM MATH SOC, V39, P1; Datta A, 2016, J AM STAT ASSOC, V111, P800, DOI 10.1080/01621459.2015.1044091; De Nicolao G, 1999, IEEE T AUTOMAT CONTR, V44, P2045, DOI 10.1109/9.802913; DeNicolao G, 1997, AUTOMATICA, V33, P851, DOI 10.1016/S0005-1098(96)00254-3; Drineas P, 2005, J MACH LEARN RES, V6, P2153; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; Garin F, 2010, LECT NOTES CONTR INF, V406, P75; Gelfand AE, 2005, ENVIRONMETRICS, V16, P465, DOI 10.1002/env.715; Gilks WR, 1996, MARKOV CHAIN MONTE C; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Honeine P., 2008, P IEEE GLOBECOM, P1; KIMELDOR.GS, 1970, ANN MATH STAT, V41, P495, DOI 10.1214/aoms/1177697089; Kulis B., 2006, P 23 INT C MACH LEAR, P505; Lazaro-Gredilla M, 2010, J MACH LEARN RES, V11, P1865; Levy B. C., 2008, PRINCIPLES SIGNAL DE, P1; Ma L, 2009, RENEW SUST ENERG REV, V13, P915, DOI 10.1016/j.rser.2008.02.002; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; Magni P, 1998, IEEE T PATTERN ANAL, V20, P1319, DOI 10.1109/34.735805; Maritz J.S., 1989, EMPIRICAL BAYES METH, V2nd ed.; Martinez S, 2010, IEEE T CONTR SYST T, V18, P491, DOI 10.1109/TCST.2009.2017028; Meinshausen N, 2009, ANN STAT, V37, P246, DOI 10.1214/07-AOS582; Parolini L, 2012, P IEEE, V100, P254, DOI 10.1109/JPROC.2011.2161244; Perez-Cruz F, 2010, IEEE SIGNAL PROC LET, V17, P355, DOI 10.1109/LSP.2010.2040926; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Predd JB, 2009, IEEE T INFORM THEORY, V55, P1856, DOI 10.1109/TIT.2009.2012992; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Rasmussen C. E., 2006, GAUSSIAN PROCESSES M, V14; Rice J., 1986, CONT MATH, V59, P137; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416, DOI 10.1007/3-540-44581-1_27; Scholkopf B., 2001, LEARNING KERNELS SUP; Smola A. J., 2000, P 17 INT C MACH LEAR, P911; Snelson Edward, 2006, ADV NEURAL INFORM PR, V3; Snoek J., 2012, P 25 INT C NEUR INF, V2, P2951, DOI DOI 10.48550/ARXIV.1206.2944; STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Trecate GF, 1999, ADV NEUR IN, V11, P218; Varagnolo D, 2012, AUTOMATICA, V48, P2468, DOI 10.1016/j.automatica.2012.06.080; Wahba G., 1990, SPLINE MODELS OBSERV; Williams CKI, 2001, ADV NEUR IN, V13, P682; Wipf DP, 2007, ADV NEURAL INFORM PR, P1625; Xiao L., 1998, SYST CONTROL LETT, P65; Xu YF, 2013, AUTOMATICA, V49, P3520, DOI 10.1016/j.automatica.2013.09.008; Xu YF, 2012, IEEE T AUTOMAT CONTR, V57, P2078, DOI 10.1109/TAC.2011.2179430; Xu YF, 2011, SENSORS-BASEL, V11, P3051, DOI 10.3390/s110303051; Yang T., 2012, ADV NEURAL INFORM PR, P476; Zhang K, 2010, IEEE T NEURAL NETWOR, V21, P1576, DOI 10.1109/TNN.2010.2064786; Zhang T, 2005, NEURAL COMPUT, V17, P2077, DOI 10.1162/0899766054323008; Zhu H., 1998, NEURAL NETWORKS MACH; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	57	8	8	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2098	2111		10.1109/TPAMI.2018.2836422	http://dx.doi.org/10.1109/TPAMI.2018.2836422			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	29994651	Green Submitted, Bronze			2022-12-18	WOS:000480343900005
J	Lim, J; Lee, S				Lim, Jaeseung; Lee, Sankeun			Patchmatch-Based Robust Stereo Matching Under Radiometric Changes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereoscopic image; disparity map; radiometric change; coherency sensitive hashing; convex plane refinement		In the real world, the two challenges of stereo vision system include a robust system under various radiometric changes and real-time process. To extract depth information from stereoscopic images, this paper proposes Patchmatch-based robust and fast stereo matching under radiometric changes. For this, a cost function was designed and minimized for estimating an accurate disparity map. Specifically, we used a prior probability to minimize the occlusion region and a smoothness term that considers convexity of objects to extract a fine disparity map. For evaluating the performance of the proposed scheme, we used Middlebury stereo data sets with radiometric changes. The experimental result showed that the proposed method outperforms state-of-the-art methods by up to 3.35 percent better and a range of 4.71 - 27.24 times faster result in terms of bad pixel error and processing time, respectively. Therefore, we believe that the proposed scheme can be a useful tool for computer vision-based applications.	[Lim, Jaeseung; Lee, Sankeun] Chung Ang Univ, Grad Sch Adv Imaging Multimedia & Film, Seoul 156756, South Korea	Chung Ang University	Lim, J (corresponding author), Chung Ang Univ, Grad Sch Adv Imaging Multimedia & Film, Seoul 156756, South Korea.	wanicono@gmail.com; sankny@gmail.com		Lim, Jaeseung/0000-0002-4194-0301	Institute for Information & communications Technology Promotion(IITP); Commercializations Promotion Agency for R&D Outcomes(COMPA); National Research Foundation of Korea - Korea government (MSIP) [R0190-16-2034, 2016K000202, NRF-2014R1A2A1A11049986]	Institute for Information & communications Technology Promotion(IITP); Commercializations Promotion Agency for R&D Outcomes(COMPA); National Research Foundation of Korea - Korea government (MSIP)	This work was partially supported by Institute for Information & communications Technology Promotion(IITP), the Commercializations Promotion Agency for R&D Outcomes(COMPA), and the National Research Foundation of Korea grant funded by the Korea government (MSIP) (R0190-16-2034, No. 2016K000202, and No. NRF-2014R1A2A1A11049986).	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Ambrosch K., 2010, 2010 IEEE 26th Convention of Electrical & Electronics Engineers in Israel (IEEEI 2010), P786, DOI 10.1109/EEEI.2010.5662105; Ansar A, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P455, DOI 10.1109/TDPVT.2004.1335273; Ben-Artzi G, 2007, IEEE T PATTERN ANAL, V29, P382, DOI 10.1109/TPAMI.2007.62; Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Guney F, 2015, PROC CVPR IEEE, P4165, DOI 10.1109/CVPR.2015.7299044; Heo YS, 2013, IEEE T PATTERN ANAL, V35, P1094, DOI 10.1109/TPAMI.2012.167; Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hirschmuller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221; Jung IL, 2013, IEEE IMAGE PROC, P2082, DOI 10.1109/ICIP.2013.6738429; Kim YH, 2016, PATTERN RECOGN LETT, V78, P41, DOI 10.1016/j.patrec.2016.04.015; Korman S, 2016, IEEE T PATTERN ANAL, V38, P1099, DOI 10.1109/TPAMI.2015.2477814; Li Ma, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P533, DOI 10.1109/ICIG.2013.113; Lim J., 2016, 2016 ASIA PACIFIC SI, P1, DOI [10.1109/APSIPA.2016.7820770, DOI 10.1109/APSIPA.2016.7820770]; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Nair R, 2015, IEEE I CONF COMP VIS, P2291, DOI 10.1109/ICCV.2015.264; Park MG, 2015, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2015.7298605; Phuc Nguyen Hong, 2015, International Journal of Computer and Electrical Engineering, V7, P19, DOI 10.17706/ijcee.2015.v7.874; Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345	26	8	9	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1203	1212		10.1109/TPAMI.2018.2819662	http://dx.doi.org/10.1109/TPAMI.2018.2819662			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993771				2022-12-18	WOS:000463607400013
J	Li , X; Zhao, LM; Ji, W; Wu, YM; Wu, F; Yang, MH; Tao, DC; Reid, I				Li, Xi; Zhao, Liming; Ji, Wei; Wu, Yiming; Wu, Fei; Yang, Ming-Hsuan; Tao, Dacheng; Reid, Ian			Multi-Task Structure-Aware Context Modeling for Robust Keypoint-Based Object Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Keypoint tracking; context modeling; structure learning; multi-task learning; metric learning	APPEARANCE MODELS; VISUAL TRACKING; CLASSIFICATION; CONSENSUS	In the fields of computer vision and graphics, keypoint-based object tracking is a fundamental and challenging problem, which is typically formulated in a spatio-temporal context modeling framework. However, many existing keypoint trackers are incapable of effectively modeling and balancing the following three aspects in a simultaneous manner: temporal model coherence across frames, spatial model consistency within frames, and discriminative feature construction. To address this problem, we propose a robust keypoint tracker based on spatio-temporal multi-task structured output optimization driven by discriminative metric learning. Consequently, temporal model coherence is characterized by multi-task structured keypoint model learning over several adjacent frames; spatial model consistency is modeled by solving a geometric verification based structured learning problem; discriminative feature construction is enabled by metric learning to ensure the intra-class compactness and inter-class separability. To achieve the goal of effective object tracking, we jointly optimize the above three modules in a spatio-temporal multi-task learning scheme. Furthermore, we incorporate this joint learning scheme into both single-object and multi-object tracking scenarios, resulting in robust tracking results. Experiments over several challenging datasets have justified the effectiveness of our single-object and multi-object trackers against the state-of-the-art.	[Li, Xi; Zhao, Liming; Ji, Wei; Wu, Yiming; Wu, Fei] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China; [Yang, Ming-Hsuan] Univ Calif Merced, Elect Engn & Comp Sci, Merced, CA 95344 USA; [Tao, Dacheng] Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia; [Reid, Ian] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	Zhejiang University; University of California System; University of California Merced; University of Sydney; University of Adelaide	Zhao, LM; Ji, W; Wu, YM (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.	xilizju@zju.edu.cn; zhaoliming@zju.edu.cn; jiwei@zju.edu.cn; ymw@zju.edu.cn; wufeij@zju.edu.cn; mhyang@ucmerced.edu; dacheng.tao@sydney.edu.au; ian.reid@adelaide.edu.au	Li, Xi/L-1234-2013; Yang, Ming-Hsuan/AAE-7350-2019; Yang, Ming-Hsuan/T-9533-2019; Zhao, Liming/I-8253-2016	Li, Xi/0000-0003-3023-1662; Yang, Ming-Hsuan/0000-0003-4848-2304; Zhao, Liming/0000-0002-1467-1230; Reid, Ian/0000-0001-7790-6423; Ji, Wei/0000-0002-8106-9768; Wu, Yiming/0000-0002-9866-669X	National Natural Science Foundation of China [U1509206, 61472353, 61751209]; National Basic Research Program of China [2015CB352302]; MOE-Microsoft Key Laboratory of Visual Perception, Zhejiang University	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China); MOE-Microsoft Key Laboratory of Visual Perception, Zhejiang University	We greatly appreciate Yueting Zhuang and Jun Xiao for their valuable comments and suggestions on this work. This work was supported in part by the National Natural Science Foundation of China under Grants (U1509206, 61472353, and 61751209), in part by the National Basic Research Program of China under Grant Grant 2015CB352302, and partially funded by the MOE-Microsoft Key Laboratory of Visual Perception, Zhejiang University.	Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Argyriou A., 2007, NIPS, V19, P41, DOI DOI 10.1007/S10994-007-5040-8; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Bai YC, 2012, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2012.6247884; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Blaschko MB, 2008, LECT NOTES COMPUT SC, V5302, P2, DOI 10.1007/978-3-540-88682-2_2; Bouachir W, 2014, IEEE WINT CONF APPL, P877, DOI 10.1109/WACV.2014.6836011; Branson S, 2011, IEEE I CONF COMP VIS, P1832, DOI 10.1109/ICCV.2011.6126450; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Duy-Nguyen Ta, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2937, DOI 10.1109/CVPRW.2009.5206831; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frederick R., 1994, P PACK VID WORKSH, P26; Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5; Grabner M, 2007, PROC CVPR IEEE, P200; Gross R, 2006, IMAGE VISION COMPUT, V24, P593, DOI 10.1016/j.imavis.2005.08.001; Han ZJ, 2011, COMPUT VIS IMAGE UND, V115, P69, DOI 10.1016/j.cviu.2010.09.004; Hare S, 2012, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2012.6247889; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Huang Y, 2005, PROC CVPR IEEE, P1051; Javed O, 2002, LECT NOTES COMPUT SC, V2353, P343; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Klein George, 2007, P1; Kwon J, 2014, IEEE T PATTERN ANAL, V36, P625, DOI 10.1109/TPAMI.2013.170; Lebeda K, 2015, LECT NOTES COMPUT SC, V9006, P642, DOI [10.1007/978-3-319-16817-3-42, 10.1007/978-3-319-16817-3_42]; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Li Z., 2012, PROC NATL CONF ARTIF, V2, P1026; Lin Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4429, DOI 10.1109/ICRA.2017.7989512; Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133; Lin Y. D., 2017, P IEEE C COMP VIS PA, P4857; Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B. D., 1981, INT JOINT C ART INT, P674, DOI DOI 10.5555/1623264.1623280; Malis E, 2004, IEEE INT CONF ROBOT, P1843, DOI 10.1109/ROBOT.2004.1308092; Maresca ME, 2013, LECT NOTES COMPUT SC, V8157, P419, DOI 10.1007/978-3-642-41184-7_43; MAYO M, 2008, P 23 INT C IM VIS CO, P1; Nebehay G, 2014, IEEE WINT CONF APPL, P862, DOI 10.1109/WACV.2014.6836013; NG KC, 1998, P ISPRS INT S REAL T, P356; Nowak T, 2014, LECT NOTES ARTIF INT, V8468, P639, DOI 10.1007/978-3-319-07176-3_56; Ozuysal M, 2006, LECT NOTES COMPUT SC, V3953, P592, DOI 10.1007/11744078_46; Park K., 2011, P AAAI C ART INT; Perera A. A., 2006, 2006 IEEE COMPUTER S, V1, P666; Pernici F, 2014, IEEE T PATTERN ANAL, V36, P2538, DOI 10.1109/TPAMI.2013.250; Petit A, 2014, IEEE INT CONF ROBOT, P4115, DOI 10.1109/ICRA.2014.6907457; Quattoni A., 2009, P 26 ANN INT C MACH, P857, DOI DOI 10.1145/1553374.1553484; Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Song XA, 2008, LECT NOTES COMPUT SC, V5304, P642, DOI 10.1007/978-3-540-88690-7_48; Suna Kim, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P98, DOI 10.1007/978-3-642-37431-9_8; Taskar B, 2004, ADV NEUR IN, V16, P25; Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649; Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P727, DOI 10.1109/ICCV.1998.710798; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Uchida S, 2011, PROC INT CONF DOC, P819, DOI 10.1109/ICDAR.2011.168; Vojfr T., 2014, REGISTRATION RECOGNI, P113, DOI DOI 10.1007/978-3-642-44907-9_6; Wang T, 2018, IEEE T PATTERN ANAL, V40, P1494, DOI 10.1109/TPAMI.2017.2716350; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wen LY, 2012, LECT NOTES COMPUT SC, V7575, P716, DOI 10.1007/978-3-642-33765-9_51; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Xiao Cai, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P91, DOI 10.1109/ICDM.2011.105; Yang B, 2014, INT J COMPUT VISION, V107, P203, DOI 10.1007/s11263-013-0666-4; Yao R, 2012, LECT NOTES COMPUT SC, V7574, P158, DOI 10.1007/978-3-642-33712-3_12; Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96; Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006; Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908; Zhao LM, 2015, AAAI CONF ARTIF INTE, P3864; Zheng J., 2013, P AAAI C ART INT, P1048	76	8	8	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					915	927		10.1109/TPAMI.2018.2818132	http://dx.doi.org/10.1109/TPAMI.2018.2818132			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29993768				2022-12-18	WOS:000460583500010
J	Hoyos-Idrobo, A; Varoquaux, G; Kahn, J; Thirion, B				Hoyos-Idrobo, Andres; Varoquaux, Gael; Kahn, Jonas; Thirion, Bertrand			Recursive Nearest Agglomeration (ReNA): Fast Clustering for Approximation of Structured Signals	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering; dimensionality reduction; matrix sketching; classification; neuroimaging; approximation	JOHNSON-LINDENSTRAUSS; SERIES; FMRI	In this work, we revisit fast dimension reduction approaches, as with random projections and random sampling. Our goal is to summarize the data to decrease computational costs and memory footprint of subsequent analysis. Such dimension reduction can be very efficient when the signals of interest have a strong structure, such as with images. We focus on this setting and investigate feature clustering schemes for data reductions that capture this structure. An impediment to fast dimension reduction is then that good clustering comes with large algorithmic costs. We address it by contributing a linear-time agglomerative clustering scheme, Recursive Nearest Agglomeration (ReNA). Unlike existing fast agglomerative schemes, it avoids the creation of giant clusters. We empirically validate that it approximates the data as well as traditional variance-minimizing clustering schemes that have a quadratic complexity. In addition, we analyze signal approximation with feature clustering and show that it can remove noise, improving subsequent analysis steps. As a consequence, data reduction by clustering features with ReNA yields very fast and accurate models, enabling to process large datasets on budget. Our theoretical analysis is backed by extensive experiments on publicly-available data that illustrate the computation efficiency and the denoising properties of the resulting dimension reduction scheme.	[Hoyos-Idrobo, Andres; Varoquaux, Gael; Thirion, Bertrand] Univ Paris Saclay, CEA, INRIA, Parietal Team, F-91191 Gif Sur Yvette, France; [Kahn, Jonas] Univ Toulouse, CNRS, UMR5219, Inst Math Toulouse, F-31062 Toulouse, France	CEA; Inria; UDICE-French Research Universities; Universite Paris Saclay; Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute for Mathematical Sciences (INSMI); Universite de Toulouse; Universite Toulouse 1 Capitole; Universite Toulouse III - Paul Sabatier; Universite de Toulouse - Jean Jaures; Institut National des Sciences Appliquees de Toulouse; Universite Federale Toulouse Midi-Pyrenees (ComUE)	Hoyos-Idrobo, A (corresponding author), Univ Paris Saclay, CEA, INRIA, Parietal Team, F-91191 Gif Sur Yvette, France.	ahoyosidrobo@gmail.com; gael.varoquaux@normalesup.org; jonas.kahn@math.univ-oulouse.fr; bertrand.thirion@inria.fr		Thirion, Bertrand/0000-0001-5018-7895	16 NIH Institutes and Centers [1U54MH091657]; McDonnell Center for Systems Neuroscience at Washington University; European Union's Horizon 2020 Framework Programme for Research and Innovation [720270]	16 NIH Institutes and Centers(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH Clinical Center (CC)); McDonnell Center for Systems Neuroscience at Washington University; European Union's Horizon 2020 Framework Programme for Research and Innovation	Data were provided in part by the Human Connectome Project, WU-Minn Consortium (Principal Investigators: D. Van Essen and K. Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research; and by the McDonnell Center for Systems Neuroscience at Washington University. Research leading to these results has received funding from the European Union's Horizon 2020 Framework Programme for Research and Innovation under Grant Agreement No 720270 (Human Brain Project SGA1).	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4; Addair TG, 2014, COMPUT GEOSCI-UK, V66, P145, DOI 10.1016/j.cageo.2014.01.014; Ailon N, 2009, SIAM J COMPUT, V39, P302, DOI 10.1137/060673096; Amat F, 2013, BIOINFORMATICS, V29, P373, DOI 10.1093/bioinformatics/bts706; Arthur D., 2006, Proceedings of the Twenty-Second Annual Symposium on Computational Geometry (SCG'06), P144, DOI 10.1145/1137856.1137880; Barch DM, 2013, NEUROIMAGE, V80, P169, DOI 10.1016/j.neuroimage.2013.05.033; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Buhlmann P, 2013, J STAT PLAN INFER, V143, P1835, DOI 10.1016/j.jspi.2013.05.019; Chakrabarti K, 2002, ACM T DATABASE SYST, V27, P188, DOI 10.1145/568518.568520; Chau W, 2005, NEUROIMAGE, V25, P408, DOI 10.1016/j.neuroimage.2004.12.007; Cole JR, 2014, NUCLEIC ACIDS RES, V42, pD633, DOI 10.1093/nar/gkt1244; Eppstein D, 1997, DISCRETE COMPUT GEOM, V17, P263, DOI 10.1007/PL00009293; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Gittens A., 2013, INT C MACHINE LEARNI, P567; Glasser MF, 2013, NEUROIMAGE, V80, P105, DOI 10.1016/j.neuroimage.2013.04.127; Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806; Hastie T, 2009, ELEMENTS STAT LEARNI; Hegde C, 2015, IEEE T SIGNAL PROCES, V63, P6109, DOI 10.1109/TSP.2015.2452228; Hoyos-Idrobo A, 2015, 2015 INTERNATIONAL WORKSHOP ON PATTERN RECOGNITION IN NEUROIMAGING (PRNI) 2015, P73, DOI 10.1109/PRNI.2015.30; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Johnson W. B., 1984, CONT MATH, V26, P189, DOI DOI 10.1090/CONM/026/737400; Jones E., 2001, SCIPY OPEN SOURCE SC; Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669; Le Magoarou L, 2016, IEEE J-STSP, V10, P688, DOI 10.1109/JSTSP.2016.2543461; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; Lu Yichao, 2013, ADV NEURAL INFORM PR, P369; Mahoney MW, 2009, P NATL ACAD SCI USA, V106, P697, DOI [10.1073/pnas.0803205105, 10.1073/pnas.0803205106]; Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498; Mensch A, 2016, PR MACH LEARN RES, V48; Mirkin B., 1998, CLASSIFICATION DATA, P172, DOI [10.1007/978-3-642-72087-1_20, DOI 10.1007/978-3-642-72087-1_20]; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Mullner Daniel, 2011, ARXIV11092378; Overbeek R, 2000, NUCLEIC ACIDS RES, V28, P123, DOI 10.1093/nar/28.1.123; Pearce DJ, 2005, IMPROVED ALGORITHM F; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; PENROSE MD, 1995, J MULTIVARIATE ANAL, V53, P94, DOI 10.1006/jmva.1995.1026; Rahimi A, 2007, PROC 20 INT C NEURAL, P1177, DOI DOI 10.5555/2981562.2981710; ROSENFEL.A, 1966, J ACM, V13, P471; Rudi A, 2015, ADV NEUR IN, V28; Schwartz Y., 2013, NIPS 13, V2, P1673; Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192; Smith SM, 2013, NEUROIMAGE, V80, P144, DOI 10.1016/j.neuroimage.2013.05.039; Stauffer D., 1971, INTRO PERCOLATION TH; Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010; Teng SH, 2007, ALGORITHMICA, V49, P192, DOI 10.1007/s00453-007-9040-7; Thirion B, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00167; Tropp JA, 2011, ADV DATA SCI ADAPT, V3, P115, DOI 10.1142/S1793536911000787; van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453; Van Essen DC, 2012, NEUROIMAGE, V62, P2222, DOI 10.1016/j.neuroimage.2012.02.018; Varoquaux G., 2012, P 29 INT C MACH LEAR, P1375; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Williams CKI, 2001, ADV NEUR IN, V13, P682; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xiang Z., 2011, ADV NEURAL INFORM PR, V24, P900	57	8	8	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					669	681		10.1109/TPAMI.2018.2815524	http://dx.doi.org/10.1109/TPAMI.2018.2815524			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29993861	Green Submitted			2022-12-18	WOS:000458168800011
J	Durand, T; Thome, N; Cord, M				Durand, Thibaut; Thome, Nicolas; Cord, Matthieu			Exploiting Negative Evidence for Deep Latent Structured Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weakly supervised learning; convolutional networks; structured outputs; image classification; ranking; localization	CONVOLUTIONAL NETWORKS	The abundance of image-level labels and the lack of large scale detailed annotations (e.g. bounding boxes, segmentation masks) promotes the development of weakly supervised learning (WSL) models. In this work, we propose a novel framework for WSL of deep convolutional neural networks dedicated to learn localized features from global image-level annotations. The core of the approach is a new latent structured output model equipped with a pooling function which explicitly models negative evidence, e.g. a cow detector should strongly penalize the prediction of the bedroom class. We show that our model can be trained end-to-end for different visual recognition tasks: multi-class and multi-label classification, and also structured average precision (AP) ranking. Extensive experiments highlight the relevance of the proposed method: our model outperforms state-of-the art results on six datasets. We also show that our framework can be used to improve the performance of state-of-the-art deep models for large scale image classification on ImageNet. Finally, we evaluate our model for weakly supervised tasks: in particular, a direct adaptation for weakly supervised segmentation provides a very competitive model.	[Durand, Thibaut; Cord, Matthieu] UPMC Univ Paris 06, Sorbonne Univ, CNRS, LIP6 UMR 7606, 4 Pl Jussieu, F-75005 Paris, France; [Thome, Nicolas] CEDRIC Conservatoire Natl Arts & Metiers, 292 Rue St Martin, F-75003 Paris, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Sorbonne Universite; Universite Paris Cite; heSam Universite; Conservatoire National Arts & Metiers (CNAM)	Durand, T (corresponding author), UPMC Univ Paris 06, Sorbonne Univ, CNRS, LIP6 UMR 7606, 4 Pl Jussieu, F-75005 Paris, France.	thibaut.durand@lip6.fr; nicolas.thome@cnam.fr; matthieu.cord@lip6.fr						Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Andrews S., 2002, SUPPORT VECTOR MACHI, P561; [Anonymous], P EUR C COMPUT VIS; [Anonymous], P INT C LEARN REPR W; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Azizpour H., 2015, BRIT MACH VIS C, P1; Azizpour H, 2016, IEEE T PATTERN ANAL, V38, P1790, DOI 10.1109/TPAMI.2015.2500224; Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34; Behl A, 2015, IEEE T PATTERN ANAL, V37, P2545, DOI 10.1109/TPAMI.2015.2414435; Belanger D, 2016, PR MACH LEARN RES, V48; Bency AJ, 2016, LECT NOTES COMPUT SC, V9905, P714, DOI 10.1007/978-3-319-46448-0_43; Blaschko M., 2013, P IEEE C COMP VIS PA; Bouchacourt D, 2016, ADV NEURAL INFORM PR, P352; Bouchacourt D, 2015, IEEE I CONF COMP VIS, P2920, DOI 10.1109/ICCV.2015.334; Chatfield K., 2014, P BRIT MACH VIS C, P75; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LC, 2015, PR MACH LEARN RES, V37, P1785; Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231; Dai JF, 2016, LECT NOTES COMPUT SC, V9910, P534, DOI 10.1007/978-3-319-46466-4_32; Dai Jifeng, 2016, ADV NEURAL INFORM PR, P379, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Durand T, 2016, PROC CVPR IEEE, P4743, DOI 10.1109/CVPR.2016.513; Durand T, 2015, IEEE I CONF COMP VIS, P2713, DOI 10.1109/ICCV.2015.311; Everingham M., 2012, PASCAL VISUAL OBJECT; Everingham M., 2007, PASCAL VISUAL OBJECT, DOI DOI 10.1007/S11263-014-0733-5; Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; jia Li L., 2010, NIPS, DOI [10.1184/R1/6475985.v1, DOI 10.1184/R1/6475985.V1]; Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulkarni P, 2016, LECT NOTES COMPUT SC, V9912, P329, DOI 10.1007/978-3-319-46484-8_20; Lai KT, 2014, PROC CVPR IEEE, P2251, DOI 10.1109/CVPR.2014.288; Li WX, 2015, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2015.7299056; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Miller K., 2012, P 15 INT C ART INT S, P779; Mohapatra P., 2014, P ADV NEUR INF PROC, P2312; OQUAB M, 2015, PROC CVPR IEEE, P685, DOI DOI 10.1109/CVPR.2015.7298668; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Papandreou G, 2015, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2015.7298636; Parizi S. N., 2015, P INT C LEARN REPR; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Ping W., 2014, P 29 INT C MACH LEAR; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schwing A., 2012, ICML; Sharma G, 2015, IEEE I CONF COMP VIS, P1296, DOI 10.1109/ICCV.2015.153; Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136; Song Y, 2016, PR MACH LEARN RES, V48; Sun C, 2016, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2016.379; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Wah C., 2011, TECH REP; Wang S., 2016, ADV NEURAL INFORM PR, V29, P865; Wei Y., 2014, ARXIV PREPRINT ARXIV; Wei ZJ, 2016, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2016.326; Wu RB, 2015, IEEE I CONF COMP VIS, P1287, DOI 10.1109/ICCV.2015.152; Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Yisong Yue, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P271; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]; Yu Felix X., 2013, P 30 INT C MACH LEAR, P504; Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881	79	8	8	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					337	351		10.1109/TPAMI.2017.2788435	http://dx.doi.org/10.1109/TPAMI.2017.2788435			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29990283	Green Submitted			2022-12-18	WOS:000456150600006
J	Heim, E; Seitel, A; Andrulis, J; Isensee, F; Stock, C; Ross, T; Maier-Hein, L				Heim, Eric; Seitel, Alexander; Andrulis, Jonas; Isensee, Fabian; Stock, Christian; Ross, Tobias; Maier-Hein, Lena			Clickstream Analysis for Crowd-Based Object Segmentation with Confidence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Crowdsourcing; quality control; object segmentation; confidence estimation; clickstream analysis	PERFORMANCE PARAMETERS; VALIDATION	With the rapidly increasing interest in machine learning based solutions for automatic image annotation, the availability of reference annotations for algorithm training is one of the major bottlenecks in the field. Crowdsourcing has evolved as a valuable option for low-cost and large-scale data annotation; however, quality control remains a major issue which needs to be addressed. To our knowledge, we are the first to analyze the annotation process to improve crowd-sourced image segmentation. Our method involves training a regressor to estimate the quality of a segmentation from the annotator's clickstream data. The quality estimation can be used to identify spam and weight individual annotations by their (estimated) quality when merging multiple segmentations of one image. Using a total of 29,000 crowd annotations performed on publicly available data of different object classes, we show that (1) our method is highly accurate in estimating the segmentation quality based on clickstream data, (2) outperforms state-of-the-art methods for merging multiple annotations. As the regressor does not need to be trained on the object class that it is applied to it can be regarded as a low-cost option for quality control and confidence analysis in the context of crowd-based image annotation.	[Heim, Eric; Seitel, Alexander; Ross, Tobias; Maier-Hein, Lena] German Canc Res Ctr, Div Comp Assisted Med Intervent, D-69120 Heidelberg, Germany; [Isensee, Fabian] German Canc Res Ctr, Div Med Image Comp, D-69120 Heidelberg, Germany; [Andrulis, Jonas] Pallas Ludens GmbH, D-69126 Heidelberg, Germany; [Stock, Christian] German Canc Res Ctr, Div Clin Epidemiol & Aging Res, D-69120 Heidelberg, Germany; [Stock, Christian] Univ Hosp Heidelberg, Inst Med Biometry & Informat, D-69120 Heidelberg, Germany	Helmholtz Association; German Cancer Research Center (DKFZ); Helmholtz Association; German Cancer Research Center (DKFZ); Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht Karls University Heidelberg	Heim, E (corresponding author), German Canc Res Ctr, Div Comp Assisted Med Intervent, D-69120 Heidelberg, Germany.	e.heim@dkfz.de; a.seitel@dkfz.de; jonas.andrulis@pallas-ludens.com; f.isensee@dkfz.de; stock@imbi.uni-heidelberg.de; t.ross@dkfz.de; l.maier-hein@dkfz.de	Maier-Hein, Klaus Hermann/AAF-8487-2020; Seitel, Alexander/AAR-2520-2021	Maier-Hein, Klaus Hermann/0000-0002-6626-2463; Seitel, Alexander/0000-0002-5919-9646; Ross, Tobias/0000-0002-7094-4926	Klaus Tschira Foundation; SFB/TRR 125 -Cognition-Guided Surgery; Pallas Ludens GmbH	Klaus Tschira Foundation; SFB/TRR 125 -Cognition-Guided Surgery; Pallas Ludens GmbH	The authors would like to thank Caroline Feldmann for her help with the figures and Pallas Ludens GmbH for supporting us with their crowdsourcing platform. This work has been financed by the Klaus Tschira Foundation (project: "Endoskopie meets Informatik -Prazise Navigation fur die minimalinvasive Chirurgie") and SFB/TRR 125 -Cognition-Guided Surgery. Finally, the authors would like to thank Esther Stenau, Sebastian Wirkert, Caroline Feldmann, Janek Grohl, Annika Reinke, Hellena Hempe, Sarina Thomas, Clemens Hentschke and Matthias Baumhauer for helping with the data acquisition as well as Tsung-Yi Lin from Cornell Tech, Cornell University for providing further statistics on the COCO data set.	Ahmed AAE, 2007, IEEE T DEPEND SECURE, V4, P165, DOI 10.1109/TDSC.2007.70207; Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Bragg J, 2016, AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P966; Cabezas F, 2015, IEEE IMAGE PROC, P4243, DOI 10.1109/ICIP.2015.7351606; Carlos A. F. A, 2014, PRODUCELO ESPACO AGE, P53; Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063; Commowick O, 2012, IEEE T MED IMAGING, V31, P1593, DOI 10.1109/TMI.2012.2197406; Commowick O, 2010, LECT NOTES COMPUT SC, V6363, P25; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; DERICHE R, 1993, RR1893 INRIA; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Feher C, 2012, INFORM SCIENCES, V201, P19, DOI 10.1016/j.ins.2012.02.066; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Gottlieb L., 2012, P ACM MULT 2012 WORK, P23; Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401; Gunduz S., 2003, P 9 ACM SIGKDD INT C, P535, DOI DOI 10.1145/956750.956815; Gurari D, 2016, PROC CVPR IEEE, P382, DOI 10.1109/CVPR.2016.48; Gurari D, 2015, IEEE WINT CONF APPL, P1169, DOI 10.1109/WACV.2015.160; Hazzard E., 2011, OPENLAYERS 2 10 BEGI; Heer J., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P243, DOI 10.1145/503376.503420; Ibanez L, 2005, ITK SOFTWARE GUIDE; Jain SD, 2016, PROC CVPR IEEE, P2864, DOI 10.1109/CVPR.2016.313; Jain SD, 2013, IEEE I CONF COMP VIS, P1313, DOI 10.1109/ICCV.2013.166; Jakulin A., 2005, MACHINE LEARNING BAS; Kazai Gabriella, 2011, P 20 ACM INT C INFOR, P1941, DOI [10.1145/2063576.2063860, DOI 10.1145/2063576.2063860]; Kittur A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P453; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kondermann D., 2014, P AS C COMP VIS, P595; Kraskov A, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066138; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lee K, 2015, SOC NETW ANAL MIN, V5, DOI 10.1007/s13278-014-0241-1; Lin DH, 2006, LECT NOTES COMPUT SC, V3951, P68; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long CJ, 2016, INT J COMPUT VISION, V116, P136, DOI 10.1007/s11263-015-0834-9; Luckow A, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P1201, DOI 10.1109/BigData.2015.7363874; Maier-Hein L., 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P616, DOI 10.1007/978-3-319-46723-8_71; Maier-Hein L, 2015, INT J COMPUT ASS RAD, V10, P1201, DOI 10.1007/s11548-015-1168-3; Maier-Hein L, 2014, LECT NOTES COMPUT SC, V8674, P438, DOI 10.1007/978-3-319-10470-6_55; Mao A., 2013, 1 AAAI C HUMAN COMPU, V1, P94; Obendorf H, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P597; Oleson David, 2011, HUMAN COMPUTATION, P43; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; PeterWelinder Steve Branson, 2010, P NIPS, V23, P1; Raykar VC, 2010, J MACH LEARN RES, V11, P1297; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Rzeszotarski Jeffrey M., 2011, P 24 ANN ACM S USER, P13, DOI [10.1145/2047196.2047199, DOI 10.1145/2047196.2047199]; Sameki M., 2015, P AAAI C HUM COMP CR, P30; Srivastava J., 2000, SIGKDD EXP, V1, P12, DOI DOI 10.1145/846183.846188; Su Q, 2015, ELECTRON COMMER R A, V14, P1, DOI 10.1016/j.elerap.2014.10.002; Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994; Ting IH, 2005, 2005 IEEE/WIC/ACM International Conference on Web Intelligence, Proceedings, P179; Vijayanarasimhan S, 2014, INT J COMPUT VISION, V108, P97, DOI 10.1007/s11263-014-0721-9; Vittayakorn S, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.109; von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379; von Ahn Luis, 2004, P SIGCHI C HUM FACT, DOI [10.1145/985692.985733, DOI 10.1145/985692.985733]; Wang G., 2013, SYBIL, V9, P1, DOI DOI 10.1007/S00521-013-1485-9; Wang G, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P225, DOI 10.1145/2858036.2858107; Wang W, 2009, I S BIOMED IMAGING, P342, DOI 10.1109/ISBI.2009.5193054; Welinder P., 2010, 2010 IEEE COMPUTER S, P25, DOI [10.1109/CVPRW.2010.5543189, DOI 10.1109/CVPRW.2010.5543189]; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; Yang H., 1999, P INT ICSC S ADV INT, P22; Zhou L., 2015, MACHINE LEARNING MED	66	8	8	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2814	2826		10.1109/TPAMI.2017.2777967	http://dx.doi.org/10.1109/TPAMI.2017.2777967			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29989983	Green Submitted			2022-12-18	WOS:000449355500002
J	Wang, MJ; Panagakis, Y; Snape, P; Zafeiriou, SP				Wang, Mengjiao; Panagakis, Yannis; Snape, Patrick; Zafeiriou, Stefanos P.			Disentangling the Modes of Variation in Unlabelled Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised multilinear decomposition; tensor decomposition; shape from shading; expression transfer	FACE RECOGNITION; PHOTOMETRIC STEREO; ILLUMINATION; IMAGES; SHAPE; PCA	Statistical methods are of paramount importance in discovering the modes of variation in visual data. The Principal Component Analysis (PCA) is probably the most prominent method for extracting a single mode of variation in the data. However, in practice, several factors contribute to the appearance of visual objects including pose, illumination, and deformation, to mention a few. To extract these modes of variations from visual data, several supervised methods, such as the TensorFaces relying on multilinear (tensor) decomposition have been developed. The main drawbacks of such methods is that they require both labels regarding the modes of variations and the same number of samples under all modes of variations (e.g., the same face under different expressions, poses etc.). Therefore, their applicability is limited to well-organised data, usually captured in well-controlled conditions. In this paper, we propose a novel general multilinear matrix decomposition method that discovers the multilinear structure of possibly incomplete sets of visual data in unsupervised setting (i.e., without the presence of labels). We also propose extensions of the method with sparsity and low-rank constraints in order to handle noisy data, captured in unconstrained conditions. Besides that, a graph-regularised variant of the method is also developed in order to exploit available geometric or label information for some modes of variations. We demonstrate the applicability of the proposed method in several computer vision tasks, including Shape from Shading (SfS) (in the wild and with occlusion removal), expression transfer, and estimation of surface normals from images captured in the wild.	[Wang, Mengjiao; Panagakis, Yannis; Snape, Patrick; Zafeiriou, Stefanos P.] Imperial Coll London, Dept Comp, London SW7 2AZ, England; [Panagakis, Yannis] Middlesex Univ London, Dept Comp Sci, London NW4 4BT, England; [Snape, Patrick] Apple, Cupertino, CA 95014 USA	Imperial College London; Middlesex University; Apple Inc	Wang, MJ (corresponding author), Imperial Coll London, Dept Comp, London SW7 2AZ, England.	m.wang15@imperial.ac.uk; i.panagakis@imperial.ac.uk; patrick.snape08@imperial.ac.uk; s.zafeiriou@imperial.ac.uk	Panagakis, Yannis/AAZ-8090-2020; Wang, Mengjiao/AAC-9034-2019	Wang, Mengjiao/0000-0002-4873-5677; Panagakis, Ioannis/0000-0003-0153-5210	EPSRC DTA from Imperial College London; EPSRC project FACER2VM; EPSRC [EP/N007743/1, EP/J017787/1, EP/H016988/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [1675289, EP/J017787/1, EP/N007743/1, EP/H016988/1] Funding Source: researchfish	EPSRC DTA from Imperial College London(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC project FACER2VM(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The work of Mengjiao Wang was funded by an EPSRC DTA from Imperial College London. The work of Dr. Zafeiriou was partially funded by EPSRC project FACER2VM.	Adelson E. H., 1996, PERCEPTION BAYESIAN, P409, DOI DOI 10.1017/CBO9780511984037.014; Alex M, 2002, LECT NOTES COMPUT SC, V2350, P447; Bansal A, 2016, PROC CVPR IEEE, P5965, DOI 10.1109/CVPR.2016.642; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Basri R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICCV.2001.937651; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Bertsekas D. P., 2014, CONSTRAINED OPTIMIZA; Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7; Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; Fabrigar L. R., 2011, EXPLORATORY FACTOR A; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Gandy S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/2/025010; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; GOWER JC, 2004, OX STAT SCI, V30, pR13; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Kemelmacher-Shlizerman I, 2013, IEEE I CONF COMP VIS, P3256, DOI 10.1109/ICCV.2013.404; Kemelmacher-Shlizerman I, 2012, PROC CVPR IEEE, P1792, DOI 10.1109/CVPR.2012.6247876; Khatri C. G., 1968, SANKHYA, V30, P167, DOI DOI 10.2307/25049527; Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; KROONENBERG PM, 1980, PSYCHOMETRIKA, V45, P69, DOI 10.1007/BF02293599; Kruskal Joseph B., 1989, MULTIWAY DATA ANAL P, V4; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Qiu Q, 2015, IEEE T IMAGE PROCESS, V24, P5152, DOI 10.1109/TIP.2015.2479456; Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448; Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204; Roemer F, 2010, IEEE T SIGNAL PROCES, V58, P5720, DOI 10.1109/TSP.2010.2062179; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Signoretto M., 2010, LINEAR ALGEBRA ITS A, V43; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Snape P, 2015, PROC CVPR IEEE, P91, DOI 10.1109/CVPR.2015.7298604; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Wang MJ, 2017, PROC CVPR IEEE, P6053, DOI 10.1109/CVPR.2017.641; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Zafeiriou S, 2013, IEEE T INF FOREN SEC, V8, P121, DOI 10.1109/TIFS.2012.2224109; Zhu Xiaojin., 2003, P ICLR, P912	47	8	8	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2682	2695		10.1109/TPAMI.2017.2783940	http://dx.doi.org/10.1109/TPAMI.2017.2783940			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29990016	Green Accepted, Green Submitted			2022-12-18	WOS:000446683700012
J	Wang, W; Tulyakov, S; Sebe, N				Wang, Wei; Tulyakov, Sergey; Sebe, Nicu			Recurrent Convolutional Shape Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Recurrent neural network; gated recurrent unit; shape regression; facial landmarks	FACE ALIGNMENT; DESCENT	The mainstream direction in face alignment is now dominated by cascaded regression methods. These methods start from an image with an initial shape and build a set of shape increments based on features with respect to the current estimated shape. These shape increments move the initial shape to the desired location. Despite the advantages of the cascaded methods, they all share two major limitations: (i) shape increments are learned independently from each other in a cascaded manner, (ii) the use of standard generic computer vision features such SIFT, HOG, does not allow these methods to learn problem-specific features. In this work, we propose a novel Recurrent Convolutional Shape Regression (RCSR) method that overcomes these limitations. We formulate the standard cascaded alignment problem as a recurrent process and learn all shape increments jointly, by using a recurrent neural network with a gated recurrent unit. Importantly, by combining a convolutional neural network with a recurrent one we avoid hand-crafted features, widely adopted in the literature and thus we allow the model to learn task-specific features. Besides, we employ the convolutional gated recurrent unit which takes as input the feature tensors instead of flattened feature vectors. Therefore, the spatial structure of the features can be better preserved in the memory of the recurrent neural network. Moreover, both the convolutional and the recurrent neural networks are learned jointly. Experimental evaluation shows that the proposed method has better performance than the state-of-the-art methods, and further supports the importance of learning a single end-to-end model for face alignment.	[Wang, Wei; Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci DISI, I-38123 Trento, Italy; [Tulyakov, Sergey] Snap Res, 63 Market St, Venice, CA 90291 USA	University of Trento	Wang, W (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci DISI, I-38123 Trento, Italy.	wei.wang@unitn.it; stulyakov@snap.com; sebe@disi.unitn.it	Wang, Wei/AAK-5521-2021	Wang, Wei/0000-0002-5477-1017; Sebe, Niculae/0000-0002-6597-7248				Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442; Auli M., 2013, P 2013 C EMPIRICAL M, P1044; Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bengio Y., 2014, ARXIV14061078; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao C., 2014, P ACM SIGGRAPH; Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Chung Junyoung, 2014, NIPS 2014 WORKSH DEE; Coates Adam, 2011, AISTATS, V6, DOI DOI 10.1177/1753193410390845; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cootes Timothy F, 1992, BMVC, DOI DOI 10.1007/978-1-4471-3201-1_28; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; Khorrami P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P19, DOI 10.1109/ICCVW.2015.12; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Koutnik J., 2014, P 31 INT C MACH LEAR; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MAITRE G., 1999, P 2 INT C AUD VID BA; Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3; PINHERIO R, 2014, P INT C MACH LEARN; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Smith BM, 2014, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2014.225; Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453; Tulyakov S, 2018, IEEE T PATTERN ANAL, V40, P2250, DOI 10.1109/TPAMI.2017.2750687; Tulyakov S, 2015, IEEE I CONF COMP VIS, P3748, DOI 10.1109/ICCV.2015.427; Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989; Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239; Wang N, 2013, ADV NEURAL INFORM PR, DOI DOI 10.5555/2999611.2999702; Wang NN, 2018, NEUROCOMPUTING, V275, P50, DOI 10.1016/j.neucom.2017.05.013; Wang W., 2016, P ACCV, P104; Wang W, 2019, IEEE T PATTERN ANAL, V41, P654, DOI 10.1109/TPAMI.2018.2803166; Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261; Wang WQ, 2018, PROC CVPR IEEE, P9329, DOI 10.1109/CVPR.2018.00972; Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1; Zhao XW, 2014, PROC CVPR IEEE, P1765, DOI 10.1109/CVPR.2014.228; Zhou SK, 2007, LECT NOTES COMPUT SC, V4584, P13; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	58	8	8	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2569	2582		10.1109/TPAMI.2018.2810881	http://dx.doi.org/10.1109/TPAMI.2018.2810881			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29994580				2022-12-18	WOS:000446683700004
J	Zhang, QG; Chin, TJ				Zhang, Qianggong; Chin, Tat-Jun			Coresets for Triangulation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Coresets; approximation; generalised linear programming; multiple view geometry; triangulation	MULTIPLE-VIEW GEOMETRY; OPTIMIZATION	Multiple-view triangulation by l(infinity) minimisation has become established in computer vision. State-of-the-art l(infinity) triangulation algorithms exploit the quasiconvexity of the cost function to derive iterative update rules that deliver the global minimum. Such algorithms, however, can be computationally costly for large problem instances that contain many image measurements, e.g., from web-based photo sharing sites or long-term video recordings. In this paper, we prove that l(infinity) triangulation admits a coreset approximation scheme, which seeks small representative subsets of the input data called coresets. A coreset possesses the special property that the error of the l(infinity) solution on the coreset is within known bounds from the global minimum. We establish the necessary mathematical underpinnings of the coreset algorithm, specifically, by enacting the stopping criterion of the algorithm and proving that the resulting coreset gives the desired approximation accuracy. On large-scale triangulation problems, our method provides theoretically sound approximate solutions. Iterated until convergence, our coreset algorithm is also guaranteed to reach the true optimum. On practical datasets, we show that our technique can in fact attain the global minimiser much faster than current methods.	[Zhang, Qianggong; Chin, Tat-Jun] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5000, Australia	University of Adelaide	Zhang, QG (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5000, Australia.	qianggong.zhang@adelaide.edu.au; tat-jun.chin@adelaide.edu.au			ARC [DP160103490]	ARC(Australian Research Council)	This work was supported by ARC grant DP160103490.	Agarwal P, 2005, COMBINATORIAL COMPUT, P1; Alcantarilla P. F., 2013, LARGE SCALE DENSE 3D; AMENTA N, 1994, DISCRETE COMPUT GEOM, V12, P241, DOI 10.1007/BF02574379; [Anonymous], 2008, IEEE C COMP VIS PATT; Badoiu M, 2008, COMP GEOM-THEOR APPL, V40, P14, DOI 10.1016/j.comgeo.2007.04.002; CLARKSON KL, 1995, J ASSOC COMPUT MACH, V42, P488, DOI 10.1145/201019.201036; D. P. Systems, 2014, 3D SCANN; Dai ZJ, 2012, LECT NOTES COMPUT SC, V7576, P116, DOI 10.1007/978-3-642-33715-4_9; Dinkelbach W., 1967, MANAGE SCI, V13, P492, DOI 10.1287/mnsc.13.7.492; Donne S, 2015, IEEE I CONF COMP VIS, P792, DOI 10.1109/ICCV.2015.97; Enqvist O., 2011, STABLE STRUCTURE MOT; Eriksson A, 2014, PROC CVPR IEEE, P4066, DOI 10.1109/CVPR.2014.518; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Gugat M, 1996, MANAGE SCI, V42, P1493, DOI 10.1287/mnsc.42.10.1493; Hartley R, 2004, PROC CVPR IEEE, P504; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; Hongdong Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2695, DOI 10.1109/CVPRW.2009.5206653; Kahl F, 2005, IEEE I CONF COMP VIS, P1002; Kahl F, 2008, IEEE T PATTERN ANAL, V30, P1603, DOI 10.1109/TPAMI.2007.70824; Ke Q, 2007, IEEE T PATTERN ANAL, V29, P1834, DOI 10.1109/TPAMI.2007.1083; Matousek J, 1996, ALGORITHMICA, V16, P498, DOI 10.1007/BF01940877; Mur-Artal R., 2015, ROBOTICS SCI SYSTEMS, P1; Olsson C., 2007, P IEEE 11 INT C COMP, P1; Olsson C, 2011, LECT NOTES COMPUT SC, V6688, P524, DOI 10.1007/978-3-642-21227-7_49; SEIDEL R, 1991, DISCRETE COMPUT GEOM, V6, P423, DOI 10.1007/BF02574699; Seo Y., 2007, P S CRYPT INF SEC, P1; Sim Kristy, 2006, IEEE COMP SOC C COMP, P485; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766	29	8	8	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2095	2108		10.1109/TPAMI.2017.2750672	http://dx.doi.org/10.1109/TPAMI.2017.2750672			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28910756				2022-12-18	WOS:000440868400005
J	Zhang, Y; Ye, M; Manocha, D; Yang, RG				Zhang, Yu; Ye, Mao; Manocha, Dinesh; Yang, Ruigang			3D Reconstruction in the Presence of Glass and Mirrors by Acoustic and Visual Fusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; sensor fusion; ultrasonic range finding; transparent/mirrored surface modeling	SHAPE	We present a practical and inexpensive method to reconstruct 3D scenes that include transparent and mirror objects. Our work is motivated by the need for automatically generating 3D models of interior scenes, which commonly include glass. These large structures are often invisible to cameras or even to our human visual system. Existing 3D reconstruction methods for transparent objects are usually not applicable in such a room-sized reconstruction setting. Our simple hardware setup augments a regular depth camera (e.g., the Microsoft Kinect camera) with a single ultrasonic sensor, which is able to measure the distance to any object, including transparent surfaces. The key technical challenge is the sparse sampling rate from the acoustic sensor, which only takes one point measurement per frame. To address this challenge, we take advantage of the fact that the large scale glass structures in indoor environments are usually either piece-wise planar or a simple parametric surface. Based on these assumptions, we have developed a novel sensor fusion algorithm that first segments the (hybrid) depth map into different categories such as opaque/transparent/infinity (e.g., too far to measure) and then updates the depth map based on the segmentation outcome. We validated our algorithms with a number of challenging cases, including multiple panes of glass, mirrors, and even a curved glass cabinet.	[Zhang, Yu] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210008, Peoples R China; [Ye, Mao; Yang, Ruigang] Univ Kentucky, Lexington, KY 40506 USA; [Manocha, Dinesh] Univ Maryland, Comp Sci & Elect & Comp Engn, College Pk, MD 20742 USA	Nanjing University; University of Kentucky; University System of Maryland; University of Maryland College Park	Yang, RG (corresponding author), Univ Kentucky, Lexington, KY 40506 USA.	zhangyu606@gmail.com; mao.ye@uky.edu; dm@cs.umd.edu; ryang@cs.uky.edu		Manocha, Dinesh/0000-0001-7047-9801; Yang, Ruigang/0000-0001-5296-6307	US National Science Foundation [IIS-1231545, IIP-1543172]; Army Research grant [W911NF-14-1-0437]; Natural Science Foundation of China [61332017]	US National Science Foundation(National Science Foundation (NSF)); Army Research grant; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported in part by US National Science Foundation grants IIS-1231545, IIP-1543172, Army Research grant W911NF-14-1-0437 and Natural Science Foundation of China grant 61332017. Yu Zhang and Mao Ye contributed equally to this work.	Aldrich JE, 2007, CRIT CARE MED, V35, pS131, DOI 10.1097/01.CCM.0000260624.99430.22; Ben-Ezra M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1025; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; CRYER JE, 1995, PATTERN RECOGN, V28, P1033, DOI 10.1016/0031-3203(94)00183-M; Eren G, 2009, OPT EXPRESS, V17, P11457, DOI 10.1364/OE.17.011457; Fusiello A, 2004, IEEE T VIS COMPUT GR, V10, P625, DOI 10.1109/TVCG.2004.38; Goesele M, 2004, ACM T GRAPHIC, V23, P835, DOI 10.1145/1015706.1015807; Hendrik M. T., 2002, P SIGGRAPH C ABSTR A; Hullin M. B., 2008, ACM T GRAPHICS SIGGR, V87, P10; Hurtos N., 2009, INSTRUMENTATION VIEW; Ihrke I., 2008, P EUROGRAPHICS 2008; Ihrke N, 2005, IEEE I CONF COMP VIS, P1055; Izadi Shahram, 2011, UIST, DOI [10.1145/2047196.2047270, DOI 10.1145/2047196.2047270]; Kuttruff H., 2007, ACOUSTICS INTRO; Lysenkov Ilya, 2013, 2012 Robotics: Science and Systems, P273; Ma CG, 2014, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2014.420; Manocha D., 2009, SIGGRAPH 2009 COURSE, P82; MARANDA BH, 2008, HDB SIGNAL PROCESSIN, P01757; Miyazaki D, 2004, IEEE T PATTERN ANAL, V26, P73, DOI 10.1109/TPAMI.2004.1261080; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Patel RC, 1998, OCEANS'98 - CONFERENCE PROCEEDINGS, VOLS 1-3, P577, DOI 10.1109/OCEANS.1998.725812; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; Qian YM, 2016, PROC CVPR IEEE, P4369, DOI 10.1109/CVPR.2016.473; Saito M., 2001, Systems and Computers in Japan, V32, P64, DOI 10.1002/scj.1027; Saygili G, 2014, INT C PATT RECOG, P2751, DOI 10.1109/ICPR.2014.474; Schuon S, 2009, PROC CVPR IEEE, P343, DOI 10.1109/CVPRW.2009.5206804; Shen J, 2013, PROC CVPR IEEE, P1187, DOI 10.1109/CVPR.2013.157; Sinha SN, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185596; Svilainis L., 2004, ULTRAGARSAS, V63, P12; Tanaka K, 2016, PROC CVPR IEEE, P4387, DOI 10.1109/CVPR.2016.475; Wolf E., 1969, Optics Communications, V1, P153, DOI 10.1016/0030-4018(69)90052-2; Yang SW, 2008, IEEE INT CONF ROBOT, P3009, DOI 10.1109/ROBOT.2008.4543667; Ye M, 2015, PROC CVPR IEEE, P4885, DOI 10.1109/CVPR.2015.7299122; Yu J., 2013, 3D RECONSTRUCTION IN; Zhang Q, 2012, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2012.6247962; Zhu JJ, 2011, IEEE T PATTERN ANAL, V33, P1400, DOI 10.1109/TPAMI.2010.172; Zickler TE, 2002, INT J COMPUT VISION, V49, P215, DOI 10.1023/A:1020149707513	38	8	9	2	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					1785	1798		10.1109/TPAMI.2017.2723883	http://dx.doi.org/10.1109/TPAMI.2017.2723883			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28692965	hybrid			2022-12-18	WOS:000437271100001
J	Kovacs, G				Kovacs, Gyorgy			Matching by Monotonic Tone Mapping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Template matching; monotonic tone mapping; dissimilarity function	IMAGE REGISTRATION; VESSEL SEGMENTATION; SIMILARITY MEASURE; TEMPLATE; INFORMATION; ROTATION; RECOGNITION	In this paper, a novel dissimilarity measure called Matching by Monotonic Tone Mapping (MMTM) is proposed. The MMTM technique allows matching under non-linear monotonic tone mappings and can be computed efficiently when the tone mappings are approximated by piecewise constant or piecewise linear functions. The proposed method is evaluated in various template matching scenarios involving simulated and real images, and compared to other measures developed to be invariant to monotonic intensity transformations. The results show that the MMTM technique is a highly competitive alternative of conventional measures in problems where possible tone mappings are close to monotonic.	[Kovacs, Gyorgy] Analyt Minds Ltd, H-4933 Beregsurany, Hungary		Kovacs, G (corresponding author), Analyt Minds Ltd, H-4933 Beregsurany, Hungary.	gyuriofkovacs@gmail.com	Kovács, György/T-3437-2019	Kovács, György/0000-0003-1736-0988				AYER M, 1955, ANN MATH STAT, V26, P641, DOI 10.1214/aoms/1177728423; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275; Brunelli R., 2009, TEMPLATE MATCHING TE; CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715; COLLIGNON A, 1995, COMP IMAG VIS, V3, P263; de Leeuw J, 2009, J STAT SOFTW, V32, P1; Elboher E, 2013, IEEE T IMAGE PROCESS, V22, P3062, DOI 10.1109/TIP.2013.2257811; Floudas A. C., 2009, ENCY OPTIMIZATION; Flusser J, 2006, IEEE T IMAGE PROCESS, V15, P3784, DOI 10.1109/TIP.2006.884913; Fredriksson K, 2007, INFORM COMPUT, V205, P1096, DOI 10.1016/j.ic.2007.03.002; GIDEON RA, 1987, J AM STAT ASSOC, V82, P656; Goshtasby AA, 2011, IMAGE REGISTRATION FOR REMOTE SENSING, P153; Hel-Or Y, 2014, IEEE T PATTERN ANAL, V36, P317, DOI 10.1109/TPAMI.2013.138; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Kaneko S, 2002, PATTERN RECOGN, V35, P2223, DOI 10.1016/S0031-3203(01)00177-7; Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226; Kovacs G, 2016, MED IMAGE ANAL, V29, P24, DOI 10.1016/j.media.2015.12.003; Kozlov M.K., 1980, USSR COMP MATH MATH, V20, P223, DOI [DOI 10.1016/0041-5553(80)90098-1, 10.1016/0041-5553(80)90098-1]; Lau YH, 2001, PHYS MED BIOL, V46, P1297, DOI 10.1088/0031-9155/46/4/326; Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682; Lin YH, 2008, PATTERN RECOGN, V41, P2413, DOI 10.1016/j.patcog.2008.01.017; Liu LF, 2006, IEEE T IMAGE PROCESS, V15, P1100, DOI 10.1109/TIP.2005.864161; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Mahmood A, 2012, IEEE T IMAGE PROCESS, V21, P2099, DOI 10.1109/TIP.2011.2171696; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mattoccia S, 2008, IEEE T IMAGE PROCESS, V17, P528, DOI 10.1109/TIP.2008.919362; Mellor M, 2005, MED IMAGE ANAL, V9, P330, DOI 10.1016/j.media.2005.01.002; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Omachi S, 2007, IEEE T IMAGE PROCESS, V16, P2139, DOI 10.1109/TIP.2007.901243; Pearson K., 1905, P DRAP CO RES MEM BI; Pluim JPW, 2004, IEEE T MED IMAGING, V23, P1508, DOI 10.1109/TMI.2004.836872; Rougon NF, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P703; SARFRAZ AS, 2008, PROC INT CONF COMP, P235; Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967; Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159; Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627; Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1; Tombari F, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P473; VENOT A, 1988, IEEE T MED IMAGING, V7, P298, DOI 10.1109/42.14512; Venot A, 1984, IEEE Trans Med Imaging, V3, P179, DOI 10.1109/TMI.1984.4307678; Wachowiak MP, 2003, PROC SPIE, V5032, P1090, DOI 10.1117/12.480867; WOODS RP, 1993, J COMPUT ASSIST TOMO, V17, P536, DOI 10.1097/00004728-199307000-00004; Xu WC, 2013, SIGNAL PROCESS, V93, P261, DOI 10.1016/j.sigpro.2012.08.005; Yoo J, 2014, PATTERN RECOGN, V47, P3006, DOI 10.1016/j.patcog.2014.02.016	47	8	8	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1424	1436		10.1109/TPAMI.2017.2711613	http://dx.doi.org/10.1109/TPAMI.2017.2711613			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28622669				2022-12-18	WOS:000431524700011
J	Zheng, JJ; Jiang, ZL; Chellappa, R				Zheng, Jingjing; Jiang, Zhuolin; Chellappa, Rama			Submodular Attribute Selection for Visual Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Attribute selection; submodular optimization; entropy rate; maximum coverage function	OBJECT CLASSES; K-SVD	In real-world visual recognition problems, low-level features cannot adequately characterize the semantic content in images, or the spatio-temporal structure in videos. In this work, we encode objects or actions based on attributes that describe them as high-level concepts. We consider two types of attributes. One type of attributes is generated by humans, while the second type is data-driven attributes extracted from data using dictionary learning methods. Attribute-based representation may exhibit variations due to noisy and redundant attributes. We propose a discriminative and compact attribute-based representation by selecting a subset of discriminative attributes from a large attribute set. Three attribute selection criteria are proposed and formulated as a submodular optimization problem. A greedy optimization algorithm is presented and its solution is guaranteed to be at least (1-1/e)-approximation to the optimum. Experimental results on four public datasets demonstrate that the proposed attribute-based representation significantly boosts the performance of visual recognition and outperforms most recently proposed recognition approaches.	[Zheng, Jingjing] Gen Elect Global Res, 1 Res Circle, Niskayuna, NY 12309 USA; [Jiang, Zhuolin] Raytheon BBN Technol, 10 Moulton St, Cambridge, MA 02138 USA; [Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA	General Electric; Raytheon Technologies; Raytheon BBN Technologies; University System of Maryland; University of Maryland College Park	Zheng, JJ (corresponding author), Gen Elect Global Res, 1 Res Circle, Niskayuna, NY 12309 USA.	jingjing.zheng@ge.com; zjiang@bbn.com; rama@umiacs.umd.edu	Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020		MURI from the Office of Naval research [N00014-10-1-0934]	MURI from the Office of Naval research	The identification of any commercial product or trade name does not imply endorsement or recommendation by NIST. This research was partially supported by a MURI from the Office of Naval research under the Grant N00014-10-1-0934.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Al-Halah Z, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P48; Berg TL, 2010, LECT NOTES COMPUT SC, V6311, P663, DOI 10.1007/978-3-642-15549-9_48; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Branson S, 2010, LECT NOTES COMPUT SC, V6314, P438, DOI 10.1007/978-3-642-15561-1_32; Cover TM, 2006, ELEMENTS INFORM THEO; Das  A., 2012, P ADV NEUR INF PROC, V2, P1583; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; FISHER ML, 1978, MATH PROGRAM STUD, V8, P73, DOI 10.1007/BFb0121195; Fu J., 2014, P 12 AS C COMP VIS S, P243; Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38; Guestrin C., 2005, P 22 INT C MACH LEAR, P265, DOI DOI 10.1145/1102351.1102385; Jiang ZL, 2013, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR.2013.266; Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Leskovec J, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P420; Li W., 2012, P ADV NEURAL INFORM, P1106; Lin Hui, 2011, P 49 ANN M ASS COMP, P510; Liu MY, 2014, IEEE T PATTERN ANAL, V36, P99, DOI 10.1109/TPAMI.2013.107; Liu YZ, 2013, INT CONF ACOUST SPEE, P7184, DOI 10.1109/ICASSP.2013.6639057; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Parikh D, 2011, PROC CVPR IEEE, P1681, DOI 10.1109/CVPR.2011.5995451; Parkash A, 2012, LECT NOTES COMPUT SC, V7574, P354, DOI 10.1007/978-3-642-33712-3_26; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Rastegari M, 2012, LECT NOTES COMPUT SC, V7577, P876, DOI 10.1007/978-3-642-33783-3_63; Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121; Russakovsky O., 2012, TRENDS TOPICS COMPUT, P1; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Sharmanska V, 2012, LECT NOTES COMPUT SC, V7576, P242, DOI 10.1007/978-3-642-33715-4_18; Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329; Soomro K., ARXIV12120402; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; Wang G, 2009, IEEE I CONF COMP VIS, P537, DOI 10.1109/ICCV.2009.5459194; Wang H., 2013, P ICCV WORKSH ACT RE, P8; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang YJ, 2010, PRODUCTION GRIDS IN ASIA: APPLICATIONS, DEVELOPMENTS AND GLOBAL TIES, P155, DOI 10.1007/978-1-4419-0046-3_13; Wu J., 2013, P IEEE C COMP VIS PA, P2577; Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386; Yu FLX, 2013, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2013.105; Zhu F, 2014, PROC CVPR IEEE, P2457, DOI 10.1109/CVPR.2014.315; Zhu J, 2013, IEEE I CONF COMP VIS, P3559, DOI 10.1109/ICCV.2013.442	51	8	8	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2242	2255		10.1109/TPAMI.2016.2636827	http://dx.doi.org/10.1109/TPAMI.2016.2636827			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	28114004				2022-12-18	WOS:000412028600010
J	Willcocks, CG; Jackson, PTG; Nelson, CJ; Obara, B				Willcocks, Chris G.; Jackson, Philip T. G.; Nelson, Carl J.; Obara, Boguslaw			Extracting 3D Parametric Curves from 2D Images of Helical Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Helical curves; shape analysis; feature extraction; geometry; modeling; skeletonization	CURVATURE; MINIMIZATION; INFERENCE	Helical objects occur in medicine, biology, cosmetics, nanotechnology, and engineering. Extracting a 3D parametric curve from a 2D image of a helical object has many practical applications, in particular being able to extract metrics such as tortuosity, frequency, and pitch. We present a method that is able to straighten the image object and derive a robust 3D helical curve from peaks in the object boundary. The algorithm has a small number of stable parameters that require little tuning, and the curve is validated against both synthetic and real-world data. The results show that the extracted 3D curve comes within close Hausdorff distance to the ground truth, and has near identical tortuosity for helical objects with a circular profile. Parameter insensitivity and robustness against high levels of image noise are demonstrated thoroughly and quantitatively.	[Willcocks, Chris G.; Jackson, Philip T. G.; Nelson, Carl J.; Obara, Boguslaw] Univ Durham, Sch Engn & Comp Sci, South Rd, Durham DH1 3LE, England	Durham University	Willcocks, CG (corresponding author), Univ Durham, Sch Engn & Comp Sci, South Rd, Durham DH1 3LE, England.	christopher.g.willcocks@durham.ac.uk; p.t.g.jackson@durham.ac.uk; carl.nelson@durham.ac.uk; boguslaw.obara@durham.ac.uk	Willcocks, Chris G/F-9253-2015; Nelson, Chas/F-5524-2015	Willcocks, Chris G/0000-0001-6821-3924; Nelson, Chas/0000-0002-4114-1710	Dyson Ltd, United Kingdom [RF080296]; Royal Society, UK [RF080232]	Dyson Ltd, United Kingdom; Royal Society, UK(Royal Society of London)	This work was supported by research grants from Dyson Ltd, United Kingdom (RF080296) and The Royal Society, UK (RF080232).	Amenta N, 2001, COMP GEOM-THEOR APPL, V19, P127, DOI 10.1016/S0925-7721(01)00017-7; [Anonymous], 2015, SPRING PLUNGERS GRUB; [Anonymous], 2015, ZINC PLATED COUNTERS; [Anonymous], 2007, IMAGING BACTERIA BIO; Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59; Bandaru PR, 2007, J APPL PHYS, V101, DOI 10.1063/1.2723189; Bulterman RW, 2002, INFORM PROCESS LETT, V81, P93, DOI 10.1016/S0020-0190(01)00198-3; Canero C, 2000, INT C PATT RECOG, P563, DOI 10.1109/ICPR.2000.902982; Chen Joseph, 2012, PDA J Pharm Sci Technol, V66, P580, DOI 10.5731/pdajpst.2012.00892; Cherin N, 2014, COMPUT AIDED DESIGN, V46, P258, DOI 10.1016/j.cad.2013.08.042; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; Cohen J. M., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P17, DOI 10.1145/300523.300655; Cordier F, 2007, IEEE COMPUT GRAPH, V27, P50, DOI 10.1109/MCG.2007.8; Cordier F, 2016, COMPUT AIDED GEOM D, V46, P1, DOI 10.1016/j.cagd.2016.04.004; Derouet-Jourdan A, 2013, COMPUT AIDED GEOM D, V30, P490, DOI 10.1016/j.cagd.2013.02.007; Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195; Vazquez SG, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0035477; Gentile F, 2012, NANO LETT, V12, P6453, DOI 10.1021/nl3039162; Ghoreishi SR, 2007, INT J SOLIDS STRUCT, V44, P2924, DOI 10.1016/j.ijsolstr.2006.08.033; Ghosh S., 2010, THESIS; Goriely A, 1998, PHYS LETT A, V250, P311, DOI 10.1016/S0375-9601(98)00822-6; Goriely Alain, 2009, Int J Bioinform Res Appl, V5, P118, DOI 10.1504/IJBRA.2009.024032; GOSHTASBY A, 1988, IMAGE VISION COMPUT, V6, P255, DOI 10.1016/0262-8856(88)90016-9; Hassouna MS, 2009, IEEE T PATTERN ANAL, V31, P2257, DOI 10.1109/TPAMI.2008.271; Hassouna MS, 2005, PROC CVPR IEEE, P458; Kruchten AE, 2006, J CELL SCI, V119, P1683, DOI 10.1242/jcs.02963; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; LEE ETY, 1989, COMPUT AIDED DESIGN, V21, P363, DOI 10.1016/0010-4485(89)90003-1; Lewiner T, 2005, COMPUT GRAPH-UK, V29, P641, DOI 10.1016/j.cag.2005.08.004; Li C, 2008, J BACTERIOL, V190, P5607, DOI 10.1128/JB.00319-08; Li R. Y., 1895, 30 AS C REM SEN BEIJ, V3; Loader C., 2006, LOCAL REGRESSION LIK; MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959; Migliaccio F., 2007, PLANT SIGNAL BEHAV, V4, P183; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Piuze E, 2011, COMPUT GRAPH FORUM, V30, P247, DOI 10.1111/j.1467-8659.2011.01856.x; Savadjiev P, 2006, MED IMAGE ANAL, V10, P799, DOI 10.1016/j.media.2006.06.009; Shoji K, 2001, PROC CVPR IEEE, P90; Slamti L, 2011, J BACTERIOL, V193, P6266, DOI 10.1128/JB.05695-11; Soille P., 2004, MORPHOLOGICAL IMAGE, P267, DOI [10.1007/978-3-662-05088-0_9, DOI 10.1007/978-3-662-05088-0, 10.1007/978-3-662-05088-0]; Steger C, 1998, IEEE T PATTERN ANAL, V20, P113, DOI 10.1109/34.659930; Wang WP, 2006, ACM T GRAPHIC, V25, P214, DOI 10.1145/1138450.1138453; Wither J, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P33, DOI 10.1109/SMI.2007.31; Wu D, 2012, BIOSYST ENG, V112, P35, DOI 10.1016/j.biosystemseng.2012.02.002; Yao JH, 2010, IEEE T BIO-MED ENG, V57, P2861, DOI 10.1109/TBME.2010.2052255	47	8	8	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1757	1769		10.1109/TPAMI.2016.2613866	http://dx.doi.org/10.1109/TPAMI.2016.2613866			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	28114058	Green Accepted, Green Submitted			2022-12-18	WOS:000406840800005
J	Kwon, J; Lee, KM				Kwon, Junseok; Lee, Kyoung Mu			Adaptive Visual Tracking with Minimum Uncertainty Gap Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object tracking; lower and upper bounds of likelihood; minimum uncertainty gap; adaptive model update	NONRIGID OBJECT; OCCLUSION	A novel tracking algorithm is proposed, which robustly tracks a target by finding the state that minimizes the likelihood uncertainty. Likelihood uncertainty is estimated by determining the gap between the lower and upper bounds of likelihood. By minimizing the gap between the two bounds, the proposed method identifies the confident and reliable state of the target. In this study, the state that provides the Minimum Uncertainty Gap (MUG) between likelihood bounds is shown to be more reliable than the state that provides the maximum likelihood only, especially when severe illumination changes, occlusions, and pose variations occur. A rigorous derivation of the lower and upper bounds of the likelihood for the visual tracking problem is provided to address this issue. Additionally, an efficient inference algorithm that uses Interacting Markov Chain Monte Carlo (IMCMC) approach is presented to find the best state that maximizes the average of the lower and upper bounds of likelihood while minimizing the gap between the two bounds. We extend our method to update the target model adaptively. To update the model, the current observation is combined with a previous target model with the adaptive weight, which is calculated according to the goodness of the current observation. The goodness of the observation is measured using the proposed uncertainty gap estimation of likelihood. Experimental results demonstrate that the proposed method robustly tracks the target in realistic videos and outperforms conventional tracking methods.	[Kwon, Junseok] Chung Ang Univ, Sch Engn & Comp Sci, Seoul, South Korea; [Lee, Kyoung Mu] Seoul Natl Univ, Dept Elect & Comp Engn, Automat & Syst Res Inst, 599 Gwanak Ro, Seoul 151744, South Korea	Chung Ang University; Seoul National University (SNU)	Kwon, J (corresponding author), Chung Ang Univ, Sch Engn & Comp Sci, Seoul, South Korea.	jskwon@cau.ac.kr; kyoungmu@snu.ac.kr	Lee, Kyoung Mu/AAC-4063-2020	Lee, Kyoung Mu/0000-0001-7210-1036; kwon, junseok/0000-0001-9526-7549				Adam A., 2006, IEEE C COMP VIS PATT; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; BAO CL, 2012, PROC CVPR IEEE, P1830, DOI DOI 10.1109/CVPR.2012.6247881; Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614; Brhard T., 2004, 5074 INRIA; Byrnes CI, 2003, TRENDS MATH, P3; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Han BY, 2005, IEEE I CONF COMP VIS, P1492; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Isard M., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P893, DOI 10.1007/BFb0055711; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Jia C., 2010, TECH REP; Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kwak S, 2011, IEEE I CONF COMP VIS, P1551, DOI 10.1109/ICCV.2011.6126414; Kwon J, 2013, PROC CVPR IEEE, P2355, DOI 10.1109/CVPR.2013.305; Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32; Kwon J, 2013, IEEE T PATTERN ANAL, V35, P1011, DOI 10.1109/TPAMI.2012.161; Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502; Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170; Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313; Liang FM, 2007, J AM STAT ASSOC, V102, P305, DOI 10.1198/016214506000001202; MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; Mei X, 2011, PROC CVPR IEEE, P1257; Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292; NejhumShahed S. M., 2008, IEEE C COMP VIS PATT, P1; Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895; Park DW, 2012, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR.2012.6247898; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Perlovsky LI, 1997, PATTERN RECOGN LETT, V18, P283, DOI 10.1016/S0167-8655(97)00009-3; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145; Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891; Smith K, 2005, PROC CVPR IEEE, P962; Stalder S, 2010, LECT NOTES COMPUT SC, V6311, P369, DOI 10.1007/978-3-642-15549-9_27; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yoon JH, 2012, LECT NOTES COMPUT SC, V7575, P28, DOI 10.1007/978-3-642-33765-9_3; Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0; Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34; Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908	49	8	8	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					18	31		10.1109/TPAMI.2016.2537330	http://dx.doi.org/10.1109/TPAMI.2016.2537330			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26955017				2022-12-18	WOS:000390421300004
J	Rodriguez-Serrano, JA; Larlus, D; Dai, ZW				Rodriguez-Serrano, Jose A.; Larlus, Diane; Dai, Zhenwen			Data-Driven Detection of Prominent Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; object detection; metric learning; fine-grained visual recognition; object part localization	IMAGE; SEGMENTATION; GRADIENTS; VISION	This article deals with the detection of prominent objects in images. As opposed to the standard approaches based on sliding windows, we study a fundamentally different solution by formulating the supervised prediction of a bounding box as an image retrieval task. Indeed, given a global image descriptor, we find the most similar images in an annotated dataset, and transfer the object bounding boxes. We refer to this approach as data-driven detection (DDD). Our key novelty is to design or learn image similarities that explicitly optimize some aspect of the transfer unlike previous work which uses generic representations and unsupervised similarities. In a first variant, we explicitly learn to transfer, by adapting a metric learning approach to work with image and bounding box pairs. Second, we use a representation of images as object probability maps computed from low-level patch classifiers. Experiments show that these two contributions yield in some cases comparable or better results than standard sliding window detectors - despite its conceptual simplicity and run-time efficiency. Our third contribution is an application of prominent object detection, where we improve fine-grained categorization by pre-cropping images with the proposed approach. Finally, we also extend the proposed approach to detect multiple parts of rigid objects.	[Rodriguez-Serrano, Jose A.; Larlus, Diane] Xerox Res Ctr Europe, Meylan, France; [Dai, Zhenwen] Univ Sheffield, Sheffield S10 2TN, S Yorkshire, England	Xerox; University of Sheffield	Rodriguez-Serrano, JA (corresponding author), Xerox Res Ctr Europe, Meylan, France.	jose-antonio.rodriguez@xrce.xerox.com; diane.larlus@xrce.xerox.com; z.dai@sheffield.ac.uk			French ANR project FIRE-ID	French ANR project FIRE-ID(French National Research Agency (ANR))	This work partially supported by the French ANR project FIRE-ID.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; [Anonymous], 2012, ADV NEURAL INF PROCE; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Baak A, 2011, IEEE I CONF COMP VIS, P1092, DOI 10.1109/ICCV.2011.6126356; Bai B., 2009, P CIKM 2009, P187; Bai B, 2010, INFORM RETRIEVAL, V13, P291, DOI 10.1007/s10791-009-9117-9; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bottou L., 2003, ADV LECT MACHINE LEA, P146; Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47; Chechik G, 2010, J MACH LEARN RES, V11, P1109; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Cinbis RG, 2013, IEEE I CONF COMP VIS, P2968, DOI 10.1109/ICCV.2013.369; Csurka G, 2011, INT J COMPUT VISION, V95, P198, DOI 10.1007/s11263-010-0344-8; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089; Dubout C., 2012, P EUR C COMPUT VIS, P301; Everingham M., PASCAL VOC CHALLENGE; Gavves E, 2013, IEEE I CONF COMP VIS, P1713, DOI 10.1109/ICCV.2013.215; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Girshick R., DISCRIMINATIVELY TRA; Gosselin PH, 2014, PATTERN RECOGN LETT, V49, P92, DOI 10.1016/j.patrec.2014.06.011; Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266; Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197; Guo RQ, 2012, LECT NOTES COMPUT SC, V7576, P761, DOI 10.1007/978-3-642-33715-4_55; Haase D, 2014, PROC CVPR IEEE, P1426, DOI 10.1109/CVPR.2014.185; Halevy A, 2009, IEEE INTELL SYST, V24, P8, DOI 10.1109/MIS.2009.36; Hays James, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587784; Hertz T, 2004, PROC CVPR IEEE, P570; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318; Kang H, 2015, IEEE T PATTERN ANAL, V37, P189, DOI 10.1109/TPAMI.2014.2315811; Kuettel D, 2012, LECT NOTES COMPUT SC, V7578, P459, DOI 10.1007/978-3-642-33786-4_34; Kuettel D, 2012, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2012.6247721; Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Li L.-J., 2010, NEURAL INFORM PROCES, P1378; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467; Murray N, 2014, PROC CVPR IEEE, P2473, DOI 10.1109/CVPR.2014.317; Pedersoli M, 2011, PROC CVPR IEEE, P1353, DOI 10.1109/CVPR.2011.5995668; PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Rodriguez-Serrano JA, 2015, INT J COMPUT VISION, V113, P193, DOI 10.1007/s11263-014-0793-6; Rodriguez-Serrano JA, 2013, IEEE I CONF COMP VIS, P1729, DOI 10.1109/ICCV.2013.217; Rodriguez-Serrano JA, 2012, LECT NOTES COMPUT SC, V7584, P536, DOI 10.1007/978-3-642-33868-7_53; Rosenfeld A, 2011, IEEE I CONF COMP VIS, P1371, DOI 10.1109/ICCV.2011.6126391; Russell B., 2008, ADV NEURAL INFORM PR, V20, P1241; Russell Bryan, 2009, NIPS; Shen XH, 2012, LECT NOTES COMPUT SC, V7575, P114, DOI 10.1007/978-3-642-33765-9_9; Stark M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.36; Sun J, 2013, INT J COMPUT VISION, V104, P135, DOI 10.1007/s11263-013-0618-z; Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Weinberger KQ, 2007, P 11 INT C ARTIFICIA, P612; Yao BP, 2012, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2012.6248088; Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368; Zhang MJ, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P438; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	75	8	8	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2016	38	10					1969	1982		10.1109/TPAMI.2015.2509988	http://dx.doi.org/10.1109/TPAMI.2015.2509988			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DX2YV	26700971				2022-12-18	WOS:000384240600004
J	Tumpach, AB; Drira, H; Daoudi, M; Srivastava, A				Tumpach, Alice Barbara; Drira, Hassen; Daoudi, Mohamed; Srivastava, Anuj			Gauge Invariant Framework for Shape Analysis of Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D surfaces; Riemannian metric; geodesics	METRICS; SPACE; HYPERSURFACES	This paper describes a novel framework for computing geodesic paths in shape spaces of spherical surfaces under an elastic Riemannian metric. The novelty lies in defining this Riemannian metric directly on the quotient ( shape) space, rather than inheriting it from pre-shape space, and using it to formulate a path energy that measures only the normal components of velocities along the path. In other words, this paper defines and solves for geodesics directly on the shape space and avoids complications resulting from the quotient operation. This comprehensive framework is invariant to arbitrary parameterizations of surfaces along paths, a phenomenon termed as gauge invariance. Additionally, this paper makes a link between different elastic metrics used in the computer science literature on one hand, and the mathematical literature on the other hand, and provides a geometrical interpretation of the terms involved. Examples using real and simulated 3D objects are provided to help illustrate the main ideas.	[Tumpach, Alice Barbara] Univ Lille 1, Lab Paul Painleve, CNRS, UMR 8524, F-59655 Villeneuve Dascq, France; [Drira, Hassen; Daoudi, Mohamed] Inst Mines Telecom Telecom Lille, CRIStAL UMR CNRS 9189, Lille, France; [Srivastava, Anuj] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA	Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute for Mathematical Sciences (INSMI); Universite de Lille - ISITE; Universite de Lille; State University System of Florida; Florida State University	Tumpach, AB (corresponding author), Univ Lille 1, Lab Paul Painleve, CNRS, UMR 8524, F-59655 Villeneuve Dascq, France.	Barbara.Tumpach@math.univ-lille1.fr; hassen.drira@telecom-lille.fr; mohamed.daoudi@telecom-lille.fr; anuj@fsu.edu	Tumpach, Alice Barbara/AAH-3639-2020; Drira, Hassen/AAG-9736-2020; Srivastava, Anuj/L-4705-2019; Daoudi, Mohammed/H-5935-2013	Tumpach, Alice Barbara/0000-0002-7771-6758; Drira, Hassen/0000-0003-1052-4353; Daoudi, Mohammed/0000-0003-4219-7860; Srivastava, Anuj/0000-0001-7406-0338	Labex CEMPI [ANR-11-LABX-0007-01]; Equipex IrDIVE [ANR-11-EQPX-23 IrDIVE]; CNRS; Direct For Mathematical & Physical Scien [1208959] Funding Source: National Science Foundation	Labex CEMPI; Equipex IrDIVE; CNRS(Centre National de la Recherche Scientifique (CNRS)); Direct For Mathematical & Physical Scien(National Science Foundation (NSF)NSF - Directorate for Mathematical & Physical Sciences (MPS))	The authors would like to thank the anonymous reviewers for valuable comments that helped improve the paper significantly. The spherical parameterizations of the surfaces used in this paper were implemented by H. Laga. The authors would like to thank S. Kurtek for his help, and J.-C. Alvarez-Paiva and M. Bauer for fruitful discussions. This work was supported in part by the Labex CEMPI (ANR-11-LABX-0007-01), the Equipex IrDIVE (ANR-11-EQPX-23 IrDIVE) and was made possible by a visit of ABT to Telecom-Lille CRIStAL financed by the CNRS. During the reviewing process, ABT enjoyed excellent working conditions at the Pauli Institute, Vienna, Austria. Both ABT and AS benefitted from the program on Shape Analysis held in 2015 at the ESI, Wien, Austria.	Bauer M., 2014, GEOM IMAGING COMPUT, V1, P1, DOI DOI 10.4310/GIC.2014.v1.n1.a1; Bauer M, 2014, DIFFER GEOM APPL, V34, P139, DOI 10.1016/j.difgeo.2014.04.008; Bauer M, 2012, SIAM J IMAGING SCI, V5, P244, DOI 10.1137/100807983; Bauer M, 2011, J GEOM MECH, V3, P389, DOI 10.3934/jgm..2011.3.389; Bauer M, 2012, DIFFER GEOM APPL, V30, P33, DOI 10.1016/j.difgeo.2011.10.002; Binz E., 1981, DIFFERENTIAL GEOMETR; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Ciarlet PG, 2005, J ELASTICITY, V78-79, P5; Clarke B, 2010, CALC VAR PARTIAL DIF, V39, P533, DOI 10.1007/s00526-010-0323-5; Courant R., 1962, METHODS MATH PHYS, V1; do Carmo M. P., 1976, INTRO DIFFERENTIAL G; FREED DS, 1989, MICH MATH J, V36, P323; Fuchs M, 2009, J MATH IMAGING VIS, V35, P86, DOI 10.1007/s10851-009-0156-z; GILMEDRANO O, 1991, Q J MATH, V42, P183, DOI 10.1093/qmath/42.1.183; Heeren B, 2012, COMPUT GRAPH FORUM, V31, P1755, DOI 10.1111/j.1467-8659.2012.03180.x; Ivanova-Karatopraklieva I., 1994, J MATH SCI, V70, P1685, DOI DOI 10.1007/BF02110596); Jermyn IH, 2012, LECT NOTES COMPUT SC, V7576, P804, DOI 10.1007/978-3-642-33715-4_58; Kilian M, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276457, 10.1145/1239451.1239515]; Klingenberg W., 1973, VORLESUNG DIFFERENTI; Koenderink J., 1990, SOLID SHAPE; Kurtek S, 2013, COMPUT GRAPH FORUM, V32, P429, DOI 10.1111/cgf.12063; Kurtek S, 2012, IEEE T PATTERN ANAL, V34, P1717, DOI 10.1109/TPAMI.2011.233; Kurtek S, 2010, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2010.5539778; Lahiri S., 2015, PRECISE MATCHING PL; Litke N., 2005, S GEOM PROC, P207; Michor PW, 2005, DOC MATH, V10, P217; Michor PW., 1980, MANIFOLDS DIFFERENTI; Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184; Windheuser T, 2011, IEEE I CONF COMP VIS, P2134, DOI 10.1109/ICCV.2011.6126489; Xie Q, 2013, IEEE I CONF COMP VIS, P865, DOI 10.1109/ICCV.2013.112; Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685	32	8	8	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2016	38	1					46	59		10.1109/TPAMI.2015.2430319	http://dx.doi.org/10.1109/TPAMI.2015.2430319			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CY8OW	26656577	Green Submitted			2022-12-18	WOS:000366669200004
J	Piuze, E; Sporring, J; Siddiqi, K				Piuze, Emmanuel; Sporring, Jon; Siddiqi, Kaleem			Maurer-Cartan Forms for Fields on Surfaces: Application to Heart Fiber Geometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Differential geometry; moving frames; Maurer-Cartan form; diffusion MRI; heart wall myofibers	CARDIAC FIBER; SHEET STRUCTURE; ARCHITECTURE; ORIENTATION	We study the space of first order models of smooth frame fields using the method of moving frames. By exploiting the Maurer-Cartan matrix of connection forms we develop geometrical embeddings for frame fields which lie on spherical, ellipsoidal and generalized helicoid surfaces. We design methods for optimizing connection forms in local neighborhoods and apply these to a statistical analysis of heart fiber geometry, using diffusion magnetic resonance imaging. This application of moving frames corroborates and extends recent characterizations of muscle fiber orientation in the heart wall, but also provides for a rich geometrical interpretation. In particular, we can now obtain direct local measurements of the variation of the helix and transverse angles, of fiber fanning and twisting, and of the curvatures of the heart wall in which these fibers lie.	[Piuze, Emmanuel; Siddiqi, Kaleem] McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada; [Piuze, Emmanuel; Siddiqi, Kaleem] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada; [Sporring, Jon] Univ Copenhagen, Dept Comp Sci, DK-2100 Copenhagen, Denmark	McGill University; McGill University; University of Copenhagen	Piuze, E (corresponding author), McGill Univ, Comp Sci, Montreal, PQ H3A 2A7, Canada.	epiuze@cim.mcgill.ca; sporring@diku.dk; siddiqi@cim.mcgill.ca	Sporring, Jon/L-4499-2016	Sporring, Jon/0000-0003-1261-6702; Siddiqi, Kaleem/0000-0002-7347-9716	FQRNT (Quebec); NSERC (Canada); Villum Fonden [00008721] Funding Source: researchfish	FQRNT (Quebec)(FQRNT); NSERC (Canada)(Natural Sciences and Engineering Research Council of Canada (NSERC)); Villum Fonden(Villum Fonden)	The authors are grateful to FQRNT (Quebec) and NSERC (Canada) for research funding. Emmanuel Piuze is the corresponding author.	Bazin PL, 2004, SIAM J APPL MATH, V64, P1156, DOI 10.1137/S003613990340246X; Ben-Shahar O, 2003, IEEE T PATTERN ANAL, V25, P401, DOI 10.1109/TPAMI.2003.1190568; Calabi E, 1998, INT J COMPUT VISION, V26, P107, DOI 10.1023/A:1007992709392; CARTAN E, 1937, THEORIE GROUPES FINI, V18; Chen JJ, 2005, AM J PHYSIOL-HEART C, V289, pH1898, DOI 10.1152/ajpheart.00041.2005; Faugeras O., 1994, CARTANS MOVING FRAME; Flanders H, 2012, DIFFERENTIAL FORMS A; Flash T, 2007, BIOL CYBERN, V96, P577, DOI 10.1007/s00422-007-0145-5; Geerts L, 2002, AM J PHYSIOL-HEART C, V283, pH139, DOI 10.1152/ajpheart.00968.2001; Gilbert SH, 2007, EUR J CARDIO-THORAC, V32, P231, DOI 10.1016/j.ejcts.2007.03.032; HOROWITZ A, 1993, BASIC RES CARDIOL, V88, P67; Hsu EW, 1998, AM J PHYSIOL-HEART C, V274, pH1627, DOI 10.1152/ajpheart.1998.274.5.H1627; LEGRICE IJ, 1995, AM J PHYSIOL-HEART C, V269, pH571, DOI 10.1152/ajpheart.1995.269.2.H571; Lombaert H, 2012, IEEE T MED IMAGING, V31, P1436, DOI 10.1109/TMI.2012.2192743; Martin-Fernandez M, 2009, MED IMAGE ANAL, V13, P19, DOI 10.1016/j.media.2008.05.004; Needham Tristan, 1998, VISUAL COMPLEX ANAL; Olver PJ, 2005, SEL MATH-NEW SER, V11, P99, DOI 10.1007/s00029-005-0008-7; Olver PJ, 2001, FOUND COMPUT MATH, V1, P3, DOI 10.1007/s102080010001; Peskin C. S., 1975, COURANT LECT NOTES; Piuze Emmanuel, 2013, Inf Process Med Imaging, V23, P524, DOI 10.1007/978-3-642-38868-2_44; Piuze E, 2013, LECT NOTES COMPUT SC, V7945, P442, DOI 10.1007/978-3-642-38899-6_52; Piuze E, 2011, COMPUT GRAPH FORUM, V30, P247, DOI 10.1111/j.1467-8659.2011.01856.x; Powell MJD, 2009, BOBYQA ALGORITHM BOU, P39; Savadjiev P, 2007, IEEE I CONF COMP VIS, P2017; Savadjiev P, 2012, P NATL ACAD SCI USA, V109, P9248, DOI 10.1073/pnas.1120785109; Savadjiev P, 2010, NEUROIMAGE, V49, P3175, DOI 10.1016/j.neuroimage.2009.10.073; Scollan DF, 1998, AM J PHYSIOL-HEART C, V275, pH2308, DOI 10.1152/ajpheart.1998.275.6.H2308; Streeter D., 2005, ANAT REC, V155, P503; Streeter D.D., 1979, HDB PHYSL, VVolume 1, P61; Tschumperle D, 2002, IEEE SIGNAL PROC MAG, V19, P16, DOI 10.1109/MSP.2002.1028349; Walker JC, 2005, J THORAC CARDIOV SUR, V129, P382, DOI 10.1016/j.jtcvs.2004.06.006	32	8	8	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2492	2504		10.1109/TPAMI.2015.2408352	http://dx.doi.org/10.1109/TPAMI.2015.2408352			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539853				2022-12-18	WOS:000364831700011
J	Komodakis, N; Xiang, B; Paragios, N				Komodakis, Nikos; Xiang, Bo; Paragios, Nikos			A Framework for Efficient Structured Max-Margin Learning of High-Order MRF Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							MARKOV RANDOM-FIELDS; SEGMENTATION	We present a very general algorithm for structured prediction learning that is able to efficiently handle discrete MRFs/CRFs (including both pairwise and higher-order models) so long as they can admit a decomposition into tractable subproblems. At its core, it relies on a dual decomposition principle that has been recently employed in the task of MRF optimization. By properly combining such an approach with a max-margin learning method, the proposed framework manages to reduce the training of a complex high-order MRF to the parallel training of a series of simple slave MRFs that are much easier to handle. This leads to a very efficient and general learning scheme that relies on solid mathematical principles. We thoroughly analyze its theoretical properties, and also show that it can yield learning algorithms of increasing accuracy since it naturally allows a hierarchy of convex relaxations to be used for loss-augmented MAP-MRF inference within a max-margin learning approach. Furthermore, it can be easily adapted to take advantage of the special structure that may be present in a given class of MRFs. We demonstrate the generality and flexibility of our approach by testing it on a variety of scenarios, including training of pairwise and higher-order MRFs, training by using different types of regularizers and/or different types of dissimilarity loss functions, as well as by learning of appropriate models for a variety of vision tasks (including high-order models for compact pose-invariant shape priors, knowledge-based segmentation, image denoising, stereo matching as well as high-order Potts MRFs).	[Xiang, Bo; Paragios, Nikos] Ecole Cent Paris, Chatenay Malabry, France	UDICE-French Research Universities; Universite Paris Saclay		nikos.komodakis@enpc.fr; bo.xiang@ecp.fr; nikos.paragios@ecp.fr						Alahari K, 2010, PROC CVPR IEEE, P895, DOI 10.1109/CVPR.2010.5540123; Anguelov D, 2005, PROC CVPR IEEE, P169; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; BESAG J, 1977, BIOMETRIKA, V64, P616, DOI 10.1093/biomet/64.3.616; Blake A., 2011, ADV MARKOV RANDOM FI; Censor Y. A., PARALLEL OPTIMIZATIO; Chekuri C, 2001, SIAM PROC S, P109; Domke J, 2013, IEEE T PATTERN ANAL, V35, P2454, DOI 10.1109/TPAMI.2013.31; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Finley T., 2008, INT C MACHINE LEARNI, P304, DOI DOI 10.1145/1390156.1390195; Franc V, 2008, J MACH LEARN RES, V9, P67; Gould S., 2011, P INT C MACH LEARN, P193; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Hazan T., 2010, ADV NEURAL INFORM PR, P838; Hazan Tamir, 2010, NEURIPS; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175; Kohli P., 2007, P IEEE C COMP VIS PA, P1; Komodakis N., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1841, DOI 10.1109/CVPR.2011.5995375; Komodakis Nikos, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2985, DOI 10.1109/CVPRW.2009.5206846; Komodakis N, 2007, IEEE I CONF COMP VIS, P488; Komodakis N, 2011, IEEE I CONF COMP VIS, P73, DOI 10.1109/ICCV.2011.6126227; Komodakis N, 2011, IEEE T PATTERN ANAL, V33, P531, DOI 10.1109/TPAMI.2010.108; Kumar M.P., 2012, P INT C MACH LEARN, P465; Kumar S, 2005, LECT NOTES COMPUT SC, V3757, P153, DOI 10.1007/11585978_11; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; Li S, 2009, MARKOV RANDOM FIELD; Li Yingying, 2008, P IEEE C COMP VIS PA; Meshi O., 2010, P 27 INT C MACH LEAR, P783; Miller K, 2012, TLS-TIMES LIT SUPPL, P15; Munoz D, 2010, LECT NOTES COMPUT SC, V6316, P57, DOI 10.1007/978-3-642-15567-3_5; Munoz D, 2009, PROC CVPR IEEE, P975, DOI 10.1109/CVPRW.2009.5206590; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; Nedic A, 2001, SIAM J OPTIMIZ, V12, P109, DOI 10.1137/S1052623499362111; Nowozin S, 2011, IEEE I CONF COMP VIS, P1668, DOI 10.1109/ICCV.2011.6126429; Papandreou G, 2011, IEEE I CONF COMP VIS, P193, DOI 10.1109/ICCV.2011.6126242; Park K, 2012, LECT NOTES COMPUT SC, V7573, P202, DOI 10.1007/978-3-642-33709-3_15; Pletscher P., 2012, P INT C ART INT STAT, P886; Ratliff N. D., 2007, J MACHINE LEARNING R, P380; Samuel KGG, 2009, PROC CVPR IEEE, P477, DOI 10.1109/CVPRW.2009.5206774; Schlesinger M. I., 2007, Upravlyayushchie Sistemy i Mashiny, P3; Schwing A., 2012, ICML; SHALEV- SHWARTZ S., 2007, P 24 INT C MACH LEAR, P807, DOI [DOI 10.1145/1273496.1273598, 10.1145/1273496.1273598]; Sontag David, 2010, ADV NEURAL INFORM PR, P2181; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Szummer M, 2008, LECT NOTES COMPUT SC, V5303, P582, DOI 10.1007/978-3-540-88688-4_43; Tappen M. F., 2008, P IEEE C COMP VIS PA, P1; TARLOW D, 2012, AISTATS, P21; Tarlow D., 2012, INT C ART INT STAT, P1212; Taskar B, 2004, ADV NEUR IN, V16, P25; Wang HB, 2010, LECT NOTES COMPUT SC, V6470, P92, DOI 10.1007/978-3-642-17358-5_7; Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036; Xiang B, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P1425, DOI 10.1109/ISBI.2012.6235836; Xiang B, 2011, I S BIOMED IMAGING, P1706, DOI 10.1109/ISBI.2011.5872733; Yadollahpour P., 2013, P INT C ART INT STAT, P316; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]	59	8	8	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2015	37	7					1425	1441		10.1109/TPAMI.2014.2368990	http://dx.doi.org/10.1109/TPAMI.2014.2368990			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CK0YG	26352450	Green Submitted			2022-12-18	WOS:000355931100010
J	Uematsu, K; Lee, Y				Uematsu, Kazuki; Lee, Yoonkyung			Statistical Optimality in Multipartite Ranking and Ordinal Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes optimality; consistency; convex risk; multipartite ranking; ordinal regression	GENERALIZATION BOUNDS; CLASSIFICATION; AREA	Statistical optimality in multipartite ranking is investigated as an extension of bipartite ranking. We consider the optimality of ranking algorithms through minimization of the theoretical risk which combines pairwise ranking errors of ordinal categories with differential ranking costs. The extension shows that for a certain class of convex loss functions including exponential loss, the optimal ranking function can be represented as a ratio of weighted conditional probability of upper categories to lower categories, where the weights are given by the misranking costs. This result also bridges traditional ranking methods such as proportional odds model in statistics with various ranking algorithms in machine learning. Further, the analysis of multipartite ranking with different costs provides a new perspective on non-smooth listwise ranking measures such as the discounted cumulative gain and preference learning. We illustrate our findings with simulation study and real data analysis.	[Uematsu, Kazuki] Chemitox Inc, Yamanashi Testing Ctr, Hokuto, Yamanashi 4080103, Japan; [Lee, Yoonkyung] Ohio State Univ, Dept Stat, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Uematsu, K (corresponding author), Chemitox Inc, Yamanashi Testing Ctr, Hokuto, Yamanashi 4080103, Japan.	uematsu.1@buckeyemail.osu.edu; yklee@stat.osu.edu	Lee, Yoonkyung/K-4360-2015	Lee, Yoonkyung/0000-0002-5756-6588	National Science Foundation [DMS-12-09194]	National Science Foundation(National Science Foundation (NSF))	Lee's research was supported in part by National Science Foundation grant DMS-12-09194. This paper was presented in part at the Joint Statistical Meetings in Montreal, Canada in 2013.	Agarwal S, 2005, J MACH LEARN RES, V6, P393; Agarwal S, 2005, LECT NOTES COMPUT SC, V3559, P32, DOI 10.1007/11503415_3; Agarwal S., 2013, J MACH LEARN RES WOR, V30, P1; Agarwal S, 2009, J MACH LEARN RES, V10, P441; [Anonymous], [No title captured]; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Brefeld U., 2005, P ICML 2005 WORKSH R, P92; Chen W., 2009, MSRTR2009141 MICR RE; Chris Burges T.S., 2005, P 22 INT MACH LEARN, DOI 10.1145/1102351.1102363; Chu W, 2007, NEURAL COMPUT, V19, P792, DOI 10.1162/neco.2007.19.3.792; Clemencon S, 2008, ANN STAT, V36, P844, DOI 10.1214/009052607000000910; Clemencon S, 2007, J MACH LEARN RES, V8, P2671; Clemencon Stephan, 2008, P 21 INT C NEUR INF, P305; Clemencon Stephan, 2011, RANKING MULTICLASS D; Cortes C., 2004, ADV NEURAL INFORM PR, V16, P323; Cossock D, 2008, IEEE T INFORM THEORY, V54, P5140, DOI 10.1109/TIT.2008.929939; Duchi J., 2012, ASYMPTOTICS RANKING; Duchi John C., 2010, P 27 INT C MACH LEAR, P327; Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747; Herbrich R, 2000, ADV NEUR IN, P115; Jarvelin K., 2000, SIGIR Forum, V34, P41; Jun Xu, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P391; Kotlowski Wojciech, 2011, P 28 INT C MACH LEAR, P1113; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; Li Ping, 2007, ADV NEURAL INFORM PR, P897; Lin HT, 2006, LECT NOTES ARTIF INT, V4264, P319; MCCULLAGH P, 1980, J ROY STAT SOC B MET, V42, P109; RAJARAM S, 2005, P NIPS 2005 WORKSH L, P28; Rakotomamonyj, 2004, ROCAI, P71; Rennie J., 2006, COMP MCCULLAGHS PROP; Rudin C, 2009, J MACH LEARN RES, V10, P2233; Shashua A., 2003, ADV NEURAL INFORM PR, P961; Smola, 2007, DIRECT OPTIMIZATION; Tewari A, 2007, J MACH LEARN RES, V8, P1007; Uematsu K, 2011, 863 OH STAT U DEP ST; Uematsu K., 2013, 873 OH STAT U DEP ST; Waegeman W, 2008, PATTERN RECOGN LETT, V29, P1, DOI 10.1016/j.patrec.2007.07.019; Waegeman W, 2011, ARTIF INTELL, V175, P1223, DOI 10.1016/j.artint.2010.11.006; Yisong Yue, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P271; Zhang T, 2004, J MACH LEARN RES, V5, P1225	42	8	8	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					1080	1094		10.1109/TPAMI.2014.2360397	http://dx.doi.org/10.1109/TPAMI.2014.2360397			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353330				2022-12-18	WOS:000352533000014
J	Arandjelovic, R; Zisserman, A				Arandjelovic, Relja; Zisserman, Andrew			Extremely Low Bit-Rate Nearest Neighbor Search Using a Set Compression Tree	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Approximate search; large-scale image search; image indexing; very large databases; quantization	QUANTIZATION; RECOGNITION; APPROXIMATE; OBJECT; SCENE; SHAPE	The goal of this work is a data structure to support approximate nearest neighbor search on very large scale sets of vector descriptors. The criteria we wish to optimize are: (i) that the memory footprint of the representation should be very small (so that it fits into main memory); and (ii) that the approximation of the original vectors should be accurate. We introduce a novel encoding method, named a Set Compression Tree (SCT), that satisfies these criteria. It is able to accurately compress 1 million descriptors using only a few bits per descriptor. The large compression rate is achieved by not compressing on a per-descriptor basis, but instead by compressing the set of descriptors jointly. We describe the encoding, decoding and use for nearest neighbor search, all of which are quite straightforward to implement. The method, tested on standard benchmarks (SIFT1M and 80 Million Tiny Images), achieves superior performance to a number of state-of-the-art approaches, including Product Quantization, Locality Sensitive Hashing, Spectral Hashing, and Iterative Quantization. For example, SCT has a lower error using 5 bits than any of the other approaches, even when they use 16 or more bits per descriptor. We also include a comparison of all the above methods on the standard benchmarks.	[Arandjelovic, Relja; Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	University of Oxford	Arandjelovic, R (corresponding author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.	relja@robots.ox.ac.uk; az@robots.ox.ac.uk			ERC [228180]	ERC(European Research Council (ERC)European Commission)	The authors are grateful for financial suport from ERC grant VisRec no. 228180.	Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494; [Anonymous], [No title captured]; Babenko A, 2012, PROC CVPR IEEE, P3069, DOI 10.1109/CVPR.2012.6248038; Bosch A, 2007, IEEE I CONF COMP VIS, P1863; Chandrasekhar V., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P32, DOI 10.1109/ICCVW.2011.6130219; Cormen C., 1990, INTRO ALGORITHMS; Ge T., 2013, P IEEE C COMP VIS PA, P744; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Rastegari M, 2011, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2011.6126556; Sanchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504; Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205; Simonyan K, 2012, LECT NOTES COMPUT SC, V7572, P243, DOI 10.1007/978-3-642-33718-5_18; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Weiss Y., 2008, ADV NEURAL INFORM PR, V21, P1753; Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25; Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749	27	8	8	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2396	2406		10.1109/TPAMI.2014.2339821	http://dx.doi.org/10.1109/TPAMI.2014.2339821			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353147				2022-12-18	WOS:000344988000006
J	Li, HS; Huang, XL; Huang, JZ; Zhang, ST				Li, Hongsheng; Huang, Xiaolei; Huang, Junzhou; Zhang, Shaoting			Feature Matching with Affine-Function Transformation Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature matching; object matching; convex optimization; convex composition		Feature matching is an important problem and has extensive uses in computer vision. However, existing feature matching methods support either a specific or a small set of transformation models. In this paper, we propose a unified feature matching framework which supports a large family of transformation models. We call the family of transformation models the affine-function family, in which all transformations can be expressed by affine functions with convex constraints. In this framework, the goal is to recover transformation parameters for every feature point in a template point set to calculate their optimal matching positions in an input image. Given pairwise feature dissimilarity values between all points in the template set and the input image, we create a convex dissimilarity function for each template point. Composition of such convex functions with any transformation model in the affine-function family is shown to have an equivalent convex optimization form that can be optimized efficiently. Four example transformation models in the affine-function family are introduced to show the flexibility of our proposed framework. Our framework achieves 0.0 percent matching errors for both CMU House and Hotel sequences following the experimental setup in [6].	[Li, Hongsheng] Univ Elect Sci & Technol China, Dept Informat Engn, Chengdu 610054, Peoples R China; [Huang, Xiaolei] Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA 18015 USA; [Huang, Junzhou] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA; [Zhang, Shaoting] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08855 USA	University of Electronic Science & Technology of China; Lehigh University; University of Texas System; University of Texas Arlington; Rutgers State University New Brunswick	Li, HS (corresponding author), Univ Elect Sci & Technol China, Dept Informat Engn, Chengdu 610054, Peoples R China.				National Natural Science Foundation of China [61301269]; PhD Programs Foundation of Ministry of Education of China [20130185120039]; Sichuan Provincial Key Technology Research and Development Program [2014GZX0009]; Fundamental Research Funds for the Central Universities [2672014ZYGX2013J017]; China Postdoctoral Science Foundation [2014M552339]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); PhD Programs Foundation of Ministry of Education of China(Ministry of Education, China); Sichuan Provincial Key Technology Research and Development Program; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation)	This work was supported in part by National Natural Science Foundation of China (No. 61301269), in part by the PhD Programs Foundation of Ministry of Education of China (No. 20130185120039), in part by Sichuan Provincial Key Technology Research and Development Program (No. 2014GZX0009), in part by the Fundamental Research Funds for the Central Universities (No. 2672014ZYGX2013J017), and in part by China Postdoctoral Science Foundation (No. 2014M552339).	Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2005, PROC CVPR IEEE, P26; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28; Choi S., 1997, P BRIT MACH VIS C, V24, P271; Cour Timothee, 2006, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0044; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445; Duchenne O, 2009, PROC CVPR IEEE, P1980, DOI 10.1109/CVPRW.2009.5206619; Felzenszwalb PF, 2000, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.2000.854739; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hao Jiang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2473, DOI 10.1109/CVPR.2011.5995580; Hao Jiang, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2474, DOI 10.1109/CVPRW.2009.5206776; Jiang H, 2007, IEEE T PATTERN ANAL, V29, P959, DOI 10.1109/TPAMI.2007.1048; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M, 2009, PROC CVPR IEEE, P864, DOI 10.1109/CVPRW.2009.5206533; Li HS, 2013, IEEE T PATTERN ANAL, V35, P411, DOI 10.1109/TPAMI.2012.99; Ling HB, 2005, IEEE I CONF COMP VIS, P1466; Liu HR, 2010, PROC CVPR IEEE, P1609, DOI 10.1109/CVPR.2010.5539780; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Payet N, 2011, IEEE I CONF COMP VIS, P983, DOI 10.1109/ICCV.2011.6126342; Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37; Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Torki M, 2010, PROC CVPR IEEE, P3058, DOI 10.1109/CVPR.2010.5540059; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; Yang J., 2006, P IEEE C COMP VIS PA, P825; Zass R., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587500; Zheng YJ, 2011, LECT NOTES COMPUT SC, V6801, P674, DOI 10.1007/978-3-642-22092-0_55	30	8	9	2	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2407	2422		10.1109/TPAMI.2014.2324568	http://dx.doi.org/10.1109/TPAMI.2014.2324568			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353148	Green Published			2022-12-18	WOS:000344988000007
J	Liu, SB; Cooper, DB				Liu, Shubao; Cooper, David B.			Statistical Inverse Ray Tracing for Image-Based 3D Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-view stereo; image-based 3D modeling; inverse ray tracing; Markov random fields; optimization; belief propagation; dynamic programming; photo-realistic reconstruction	MULTIVIEW STEREO; GRAPH-CUTS; RECONSTRUCTION; SHAPE; SILHOUETTE	This paper proposes a new formulation and solution to image-based 3D modeling (aka "multi-view stereo") based on generative statistical modeling and inference. The proposed new approach, named statistical inverse ray tracing, models and estimates the occlusion relationship accurately through optimizing a physically sound image generation model based on volumetric ray tracing. Together with geometric priors, they are put together into a Bayesian formulation known as Markov random field (MRF) model. This MRF model is different from typical MRFs used in image analysis in the sense that the ray clique, which models the ray-tracing process, consists of thousands of random variables instead of two to dozens. To handle the computational challenges associated with large clique size, an algorithm with linear computational complexity is developed by exploiting, using dynamic programming, the recursive chain structure of the ray clique. We further demonstrate the benefit of exact modeling and accurate estimation of the occlusion relationship by evaluating the proposed algorithm on several challenging data sets.	[Liu, Shubao] GE Global Res, Image Analyt Lab, Niskayuna, NY 12309 USA; [Cooper, David B.] Brown Univ, Div Engn, Providence, RI 02912 USA	General Electric; Brown University	Liu, SB (corresponding author), GE Global Res, Image Analyt Lab, Niskayuna, NY 12309 USA.	sbliu@lems.brown.edu; cooper@lems.brown.edu			US National Science Foundation (NSF) IIS Program [0808718]	US National Science Foundation (NSF) IIS Program(National Science Foundation (NSF))	The authors would like to thank J. Mundy for providing suggestions and the capitol-40 data set, D. Scharstein and V. Jain for helping us run the comparison experiments, and S. Geman and G. Taubin for helpful discussions. We also thank the anonymous reviewers for their invaluable comments, which helped us significantly improve the paper's readability. This work was supported by the US National Science Foundation (NSF) IIS Program Grant 0808718. This work was done while the first author was a graduate student at Brown University.	Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Bradley D., 2008, P IEEE C COMP VIS PA, P1; Broadhurst A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P388, DOI 10.1109/ICCV.2001.937544; Broadhurst A., 2001, THESIS U CAMBRIDGE C; Campbell NDF, 2008, LECT NOTES COMPUT SC, V5302, P766, DOI 10.1007/978-3-540-88682-2_58; Chauve AL, 2010, PROC CVPR IEEE, P1261, DOI 10.1109/CVPR.2010.5539824; Cremers D, 2011, IEEE T PATTERN ANAL, V33, P1161, DOI 10.1109/TPAMI.2010.174; Crispell D. E., 2010, THESIS BROWN U PROVI; DELAUNOY A, 2008, P BRIT MACH VIS C; Duan Y, 2004, LECT NOTES COMPUT SC, V3023, P238; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Furukawa Y, 2006, LECT NOTES COMPUT SC, V3951, P564; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Gargallo P, 2007, LECT NOTES COMPUT SC, V4844, P373; Goesele M., 2006, PROC IEEE COMPUT SOC, V2, P2402, DOI [10.1109/CVPR.2006.199, DOI 10.1109/CVPR.2006.199]; Hiep VH, 2009, PROC CVPR IEEE, P1430, DOI 10.1109/CVPRW.2009.5206617; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; Kazhdan M., POISSON SURFACE RECO; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Kindermann R., 1980, MARKOV RANDOM FIELDS, DOI [10.1090/conm/001, DOI 10.1090/CONM/001]; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Labatut P., 2007, P INT C COMP VIS OCT, P1, DOI [10.1109/iccv.2007.4408892, DOI 10.1109/ICCV.2007.4408892, 10.1109/ICCV.2007.4408892]; LEVOY M, 1990, IEEE COMPUT GRAPH, V10, P33, DOI 10.1109/38.50671; LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965; Li JG, 2010, PROC CVPR IEEE, P2769, DOI 10.1109/CVPR.2010.5540004; Liu SB, 2011, PROC CVPR IEEE, P913, DOI 10.1109/CVPR.2011.5995334; Liu SB, 2010, PROC CVPR IEEE, P1530, DOI 10.1109/CVPR.2010.5539790; Liu YB, 2009, PROC CVPR IEEE, P2121, DOI [10.1109/CVPRW.2009.5206712, 10.1109/CVPR.2009.5206712]; Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422; Miller A., 2011, P 4 WORKSH GEN PURP, P8; Pollard T., 2007, 2007 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2007.383073; PONS JP, 2007, P CVPR 07, P1; Rousson M, 2002, LECT NOTES COMPUT SC, V2351, P78; Sapiro G., 2001, GEOMETRIC PARTIAL DI; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; Seitz S. M., MIDDLEBURY MULTIVIEW; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; Shubao Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2334, DOI 10.1109/CVPRW.2009.5206589; Snavely Noah, BUNDLER STRUCTURE MO; Strecha C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1194; Sudderth E. B., 2003, CVPR, P95; Tran S, 2006, LECT NOTES COMPUT SC, V3952, P219; Vogiatzis G, 2005, PROC CVPR IEEE, P391; Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712; Yezzi AJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P59, DOI 10.1109/ICCV.2001.937499	48	8	8	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					2074	2088		10.1109/TPAMI.2014.2315820	http://dx.doi.org/10.1109/TPAMI.2014.2315820			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352636				2022-12-18	WOS:000341981300013
J	Kwak, S; Han, B; Han, JH				Kwak, Suha; Han, Bohyung; Han, Joon Hee			On-Line Video Event Detection by Constraint Flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video event detection; activity recognition; temporal logic; dynamic programming; constraint flow	RECOGNITION; REPRESENTATION	We present a novel approach in describing and detecting the composite video events based on scenarios, which constrain the configurations of target events by temporal-logical structures of primitive events. We propose a new scenario description method to represent composite events more fluently and efficiently, and discuss an on-line event detection algorithm based on a combinatorial optimization. For this purpose, constraint flow-a dynamic configuration of scenario constraints-is first generated automatically by our scenario parsing algorithm. Then, composite event detection is formulated by a constrained discrete optimization problem, whose objective is to find the best video interpretation with respect to the constraint flow. Although the search space for the optimization problem is prohibitively large, our on-line event detection algorithm based on constraint flow using dynamic programming reduces the search space dramatically, handles preprocessing errors effectively, and guarantees a globally optimal solution. Experimental results on natural videos demonstrate the effectiveness of our algorithm.	[Kwak, Suha; Han, Bohyung; Han, Joon Hee] POSTECH, Dept Comp Sci & Engn, Pohang 790784, South Korea	Pohang University of Science & Technology (POSTECH)	Kwak, S (corresponding author), POSTECH, Dept Comp Sci & Engn, Pohang 790784, South Korea.	mercury3@postech.ac.kr; bhhan@postech.ac.kr; joonhan@postech.ac.kr			MEST Basic Science Research Program through the NRF of Korea [NRF-2012R1A1A1043658]; IT R&D Program of MKE/KEIT [10040246]	MEST Basic Science Research Program through the NRF of Korea(Ministry of Education, Science & Technology (MEST), Republic of Korea); IT R&D Program of MKE/KEIT	This work was supported by MEST Basic Science Research Program through the NRF of Korea (NRF-2012R1A1A1043658) and the IT R&D Program of MKE/KEIT (10040246).	Allen J. E., 1994, Journal of Logic and Computation, V4, P531, DOI 10.1093/logcom/4.5.531; Bandouch J., 2009, P IEEE INT WORKSH HU; Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892; Brendel W., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3329, DOI 10.1109/CVPR.2011.5995491; Gong SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P742, DOI 10.1109/ICCV.2003.1238423; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492; Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869; Kwon J, 2012, PROC CVPR IEEE, P1266, DOI 10.1109/CVPR.2012.6247810; Lavee G, 2009, IEEE T SYST MAN CY C, V39, P489, DOI 10.1109/TSMCC.2009.2023380; Laxton B., 2007, P IEEE C COMP VIS PA, P1; Li K, 2012, LECT NOTES COMPUT SC, V7572, P286, DOI 10.1007/978-3-642-33718-5_21; Lin Z, 2009, IEEE I CONF COMP VIS, P444; Loy CC, 2012, IEEE T PATTERN ANAL, V34, P1799, DOI 10.1109/TPAMI.2011.246; Minnen D, 2003, PROC CVPR IEEE, P626; Moore D, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P770; Morariu V. I., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3289, DOI 10.1109/CVPR.2011.5995386; Pei MT, 2013, COMPUT VIS IMAGE UND, V117, P1369, DOI 10.1016/j.cviu.2012.12.003; Pinhanez CS, 1998, PROC CVPR IEEE, P898, DOI 10.1109/CVPR.1998.698711; ROTA N, 2002, P EUR C A I, P673; Ryoo MS, 2009, INT J COMPUT VISION, V82, P1, DOI 10.1007/s11263-008-0181-1; Shi Y, 2006, P IEEE C COMP VIS PA, P1631; Shi Y., 2004, P IEEE C COMP VIS PA, V2, P1631; Siskind JM, 2001, J ARTIF INTELL RES, V15, P31, DOI 10.1613/jair.790; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Suha Kwak, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3345, DOI 10.1109/CVPR.2011.5995435; Tenorth M., 2009, P IEEE 12 ICCV WORKS; Thinh Vu V., 2003, P 8 INT JOINT C ART, P9; Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42; Tran SD, 2008, LECT NOTES COMPUT SC, V5303, P610, DOI 10.1007/978-3-540-88688-4_45; Weinberger Kilian Q, 2006, ADV NEURAL INFORM PR, P1473, DOI DOI 10.1007/978-3-319-13168-9_; Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731; Zhang YM, 2013, IEEE T PATTERN ANAL, V35, P2468, DOI 10.1109/TPAMI.2013.33	37	8	8	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1174	1186		10.1109/TPAMI.2013.245	http://dx.doi.org/10.1109/TPAMI.2013.245			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353279				2022-12-18	WOS:000337124200010
J	Senelle, M; Garcia-Diez, S; Mantrach, A; Shimbo, M; Saerens, M; Fouss, F				Senelle, Mathieu; Garcia-Diez, Silvia; Mantrach, Amin; Shimbo, Masashi; Saerens, Marco; Fouss, Francois			The Sum-over-Forests Density Index: Identifying Dense Regions in a Graph	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph mining; density index; dense regions on graphs; matrix-forest theorem		This work introduces a novel nonparametric density index defined on graphs, the Sum-over-Forests (SoF) density index. It is based on a clear and intuitive idea: high-density regions in a graph are characterized by the fact that they contain a large amount of low-cost trees with high outdegrees while low-density regions contain few ones. Therefore, a Boltzmann probability distribution on the countable set of forests in the graph is defined so that large (high-cost) forests occur with a low probability while short (low-cost) forests occur with a high probability. Then, the SoF density index of a node is defined as the expected outdegree of this node on the set of forests, thus providing a measure of density around that node. Following the matrix-forest theorem and a statistical physics framework, it is shown that the SoF density index can be easily computed in closed form through a simple matrix inversion. Experiments on artificial and real datasets show that the proposed index performs well on finding dense regions, for graphs of various origins.	[Senelle, Mathieu; Garcia-Diez, Silvia; Saerens, Marco; Fouss, Francois] Catholic Univ Louvain, Inst Informat & Commun Technol Elect & Appl Math, LSM, B-7000 Mons, Hainaut, Belgium; [Senelle, Mathieu; Garcia-Diez, Silvia; Saerens, Marco; Fouss, Francois] Catholic Univ Louvain, MLG, B-7000 Mons, Hainaut, Belgium; [Mantrach, Amin] Yahoo Labs, Barcelona 08018, Spain; [Shimbo, Masashi] Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara, Ikoma 6300192, Japan	Nara Institute of Science & Technology	Senelle, M (corresponding author), Catholic Univ Louvain, Inst Informat & Commun Technol Elect & Appl Math, LSM, B-7000 Mons, Hainaut, Belgium.	m.senelle@uclouvain-mons.be; silvia.garciadiez@uclouvain.be; amantrac@yahoo-inc.com; shimbo@is.naist.jp; marco.saerens@uclouvain.be; francois.fouss@uclouvain.be		Fouss, Francois/0000-0001-6383-9514	Region wallonne; JSPS [24300057]	Region wallonne; JSPS(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science)	Part of this work has been funded by projects with the "Region wallonne". We thank this institution for giving us the opportunity to conduct both fundamental and applied research. M. Shimbo was supported by JSPS Grant-in-Aid for Scientific Research (B) 24300057.	Akamatsu T, 1996, TRANSPORT RES B-METH, V30, P369, DOI 10.1016/0191-2615(96)00003-3; Barrat A, 2004, P NATL ACAD SCI USA, V101, P3747, DOI 10.1073/pnas.0400087101; Batagelj V, 2011, ADV DATA ANAL CLASSI, V5, P129, DOI 10.1007/s11634-010-0079-y; Brandes U., 2005, NETWWORK ANAL METHOL; Chebotarev P, 2002, LINEAR ALGEBRA APPL, V356, P253, DOI 10.1016/S0024-3795(02)00388-9; Chebotarev P, 2012, DISCRETE APPL MATH, V160, P1484, DOI 10.1016/j.dam.2012.02.015; Chebotarev P, 2011, DISCRETE APPL MATH, V159, P295, DOI 10.1016/j.dam.2010.11.017; Chebotarev PY, 1997, AUTOMAT REM CONTR+, V58, P1505; Cho MS, 2012, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2012.6247727; Duff I., 2017, DIRECT METHODS SPARS; ERISMAN AM, 1975, COMMUN ACM, V18, P177, DOI 10.1145/360680.360704; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Falkowski T., P 2007 IEEE WIC ACM, P112; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P150, DOI 10.1145/347090.347121; Franti P, 2006, PATTERN RECOGN, V39, P761, DOI 10.1016/j.patcog.2005.09.012; Harville D.A., 1997, MATRIX ALGEBRA STATI; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; Jouili Salim, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P950, DOI 10.1109/ICPR.2010.238; KOONTZ WLG, 1976, IEEE T COMPUT, V25, P936, DOI 10.1109/TC.1976.1674719; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Li Xiao-Li, 2007, Comput Syst Bioinformatics Conf, V6, P157; Liu H., 2010, P 27 INT C MACH LEAR, P671; Luce R. D., 1949, PSYCHOMETRIKA, V14, P95; Mantrach A, 2011, PATTERN RECOGN, V44, P1212, DOI 10.1016/j.patcog.2010.11.019; Mantrach A, 2010, IEEE T PATTERN ANAL, V32, P1112, DOI 10.1109/TPAMI.2009.78; Nadler B., 2005, ADV NEURAL INFORM PR, P955; Newman M., 2010, NETWORKS INTRO, DOI [DOI 10.1093/ACPROF:OSO/9780199206650.001.0001, 10.1162/artl_r_00062., 10.1162/artl_r_00062]; Radovanovic M, 2010, J MACH LEARN RES, V11, P2487; Reichl LE., 1980, MODERN COURSE STAT P; Saerens M, 2009, NEURAL COMPUT, V21, P2363, DOI 10.1162/neco.2009.11-07-643; SCHOTT J. R., 2005, MATRIX ANAL STAT; Schrodinger E, 1952, STAT THERMODYNAMICS; SEIDMAN SB, 1978, J MATH SOCIOL, V6, P139, DOI 10.1080/0022250X.1978.9989883; Suzuki I., 2012, P 26 AAAI C ART INT, P1112; Tang JM, 2012, NUMER LINEAR ALGEBR, V19, P485, DOI 10.1002/nla.779; Tutte W., 2002, GRAPH THEORY; Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Webb A.R., 2011, STAT PATTERN RECOGNI; Yen L., 2008, P 14 ACM SIGKDD, P785, DOI DOI 10.1145/1401890.1401984; Yen L, 2011, IEEE T KNOWL DATA EN, V23, P481, DOI 10.1109/TKDE.2010.142; Yen L, 2009, DATA KNOWL ENG, V68, P338, DOI 10.1016/j.datak.2008.10.006	42	8	8	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1268	1274		10.1109/TPAMI.2013.227	http://dx.doi.org/10.1109/TPAMI.2013.227			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353286	Green Submitted			2022-12-18	WOS:000337124200017
J	Mohedano, R; Cavallaro, A; Garcia, N				Mohedano, Raul; Cavallaro, Andrea; Garcia, Narciso			Camera Localization Using Trajectories and Maps	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Vision and scene understanding; camera calibration; Markov processes; tracking	CALIBRATION; TRACKING; VIDEO	We propose a new Bayesian framework for automatically determining the position (location and orientation) of an uncalibrated camera using the observations of moving objects and a schematic map of the passable areas of the environment. Our approach takes advantage of static and dynamic information on the scene structures through prior probability distributions for object dynamics. The proposed approach restricts plausible positions where the sensor can be located while taking into account the inherent ambiguity of the given setting. The proposed framework samples from the posterior probability distribution for the camera position via data driven MCMC, guided by an initial geometric analysis that restricts the search space. A Kullback-Leibler divergence analysis is then used that yields the final camera position estimate, while explicitly isolating ambiguous settings. The proposed approach is evaluated in synthetic and real environments, showing its satisfactory performance in both ambiguous and unambiguous settings.	[Mohedano, Raul; Garcia, Narciso] Univ Politecn Madrid, ETSI Telecomunicac, Grp Tratamiento Imagenes, E-28040 Madrid, Spain; [Cavallaro, Andrea] Queen Mary Univ London, Ctr Intelligent Sensing, London E1 4NS, England	Universidad Politecnica de Madrid; University of London; Queen Mary University London	Mohedano, R (corresponding author), Univ Politecn Madrid, ETSI Telecomunicac, Grp Tratamiento Imagenes, E-28040 Madrid, Spain.	rmp@gti.ssr.upm.es; andrea.cavallaro@eecs.qmul.ac.uk; narciso@gti.ssr.upm.es	García, Narciso/E-8603-2011	García, Narciso/0000-0002-0397-894X	Ministerio de Economia y Competitividad of the Spanish Government [TEC2010-20412]; UK Technology Strategy Board as part of the Cognitive & Perceptive Cameras (COPCAMS) project [332913]; Comunidad de Madrid; Artemis JU	Ministerio de Economia y Competitividad of the Spanish Government(Spanish Government); UK Technology Strategy Board as part of the Cognitive & Perceptive Cameras (COPCAMS) project; Comunidad de Madrid(Comunidad de Madrid); Artemis JU	This work was partially supported by the Ministerio de Economia y Competitividad of the Spanish Government under project TEC2010-20412 (Enhanced 3DTV) and by the Artemis JU and UK Technology Strategy Board as part of the Cognitive & Perceptive Cameras (COPCAMS) project under GA number 332913. Also, Raul Mohedano wishes to thank the Comunidad de Madrid for a personal research grant, which allowed him to do several parts of this work while visiting Queen Mary University of London.	Andreasson H, 2008, IEEE T ROBOT, V24, P991, DOI 10.1109/TRO.2008.2004642; Anjum N, 2008, IEEE T CIRC SYST VID, V18, P1555, DOI 10.1109/TCSVT.2008.2005603; Anjum N, 2012, IEEE INTELL SYST, V27, P10, DOI 10.1109/MIS.2010.92; Caspi Y, 2002, INT J COMPUT VISION, V48, P39, DOI 10.1023/A:1014803327923; Cesetti A, 2011, J INTELL ROBOT SYST, V61, P157, DOI 10.1007/s10846-010-9489-5; Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15; Deutscher J, 2002, LECT NOTES COMPUT SC, V2353, P175; Devroye L., 1986, NONUNIFORM RANDOM VA, P61; Fisher RB, 2002, LECT NOTES COMPUT SC, V2353, P146; Floros G., 2013, IEEE INT C ROB AUT I, P146; Golden SA, 2007, IEEE T MOBILE COMPUT, V6, P1185, DOI 10.1109/TMC.2007.1002; Hartley R., 2004, ROBOTICA; Hastie DI, 2012, STAT NEERL, V66, P309, DOI 10.1111/j.1467-9574.2012.00516.x; Hershberger J, 2007, ACM T ALGORITHMS, V3, DOI 10.1145/1186810.1186815; Hong MY, 2010, IEEE J-STSP, V4, P526, DOI 10.1109/JSTSP.2010.2048385; Javed O, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P649; John V, 2012, LECT NOTES COMPUT SC, V7585, P141, DOI 10.1007/978-3-642-33885-4_15; Junejo I. N., 2009, MACH VISION APPL, V22, P137; Junejo IN, 2007, IEEE T SYST MAN CY B, V37, P803, DOI 10.1109/TSMCB.2007.895366; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Krahnstoever N., 2006, BRIT MACH VIS C, P107; Leow W.-K., 2008, P ACM INT C MULT, P369; Lothe P, 2010, PROC CVPR IEEE, P863, DOI 10.1109/CVPR.2010.5540127; Lou Y., 2009, P 17 ACM SIGSPATIAL, P352, DOI DOI 10.1145/1653771.1653820; Lv FJ, 2006, IEEE T PATTERN ANAL, V28, P1513, DOI 10.1109/TPAMI.2006.178; Micusik B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3105, DOI 10.1109/CVPR.2011.5995534; Mohedano R., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1873, DOI 10.1109/ICIP.2011.6115833; Mohedano R, 2010, IEEE T CONSUM ELECTR, V56, P1, DOI 10.1109/TCE.2010.5439118; Noguchi M., 2007, IEEE WORKSH APPL COM, P20; Olson CF, 2000, IEEE T ROBOTIC AUTOM, V16, P55, DOI 10.1109/70.833191; Pink Oliver, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563135; Rahimi A, 2004, PROC CVPR IEEE, P187; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Rudoy MB, 2006, CONF REC ASILOMAR C, P513; Se S, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P226, DOI 10.1109/IRDS.2002.1041393; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Vaca-Castano G, 2012, PROC CVPR IEEE, P1186, DOI 10.1109/CVPR.2012.6247800; Velaga N.R., 2009, TRANSPORT RES C-EMER, V17, P113; Wang XG, 2010, IEEE T PATTERN ANAL, V32, P56, DOI 10.1109/TPAMI.2008.241; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; YEN JY, 1971, MANAGE SCI, V17, P712, DOI 10.1287/mnsc.17.11.712; Zou DP, 2013, IEEE T PATTERN ANAL, V35, P354, DOI 10.1109/TPAMI.2012.104	42	8	8	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					684	697		10.1109/TPAMI.2013.243	http://dx.doi.org/10.1109/TPAMI.2013.243			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353193	Green Accepted			2022-12-18	WOS:000334109000005
J	Zach, C; Hane, C; Pollefeys, M				Zach, Christopher; Hane, Christian; Pollefeys, Marc			What Is Optimized in Convex Relaxations for Multilabel Problems: Connecting Discrete and Continuously Inspired MAP Inference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; continuous labeling problems; convex relaxation; approximate inference	MINIMIZATION; ALGORITHM	In this work, we present a unified view on Markov random fields (MRFs) and recently proposed continuous tight convex relaxations for multilabel assignment in the image plane. These relaxations are far less biased toward the grid geometry than Markov random fields on grids. It turns out that the continuous methods are nonlinear extensions of the well-established local polytope MRF relaxation. In view of this result, a better understanding of these tight convex relaxations in the discrete setting is obtained. Further, a wider range of optimization methods is now applicable to find a minimizer of the tight formulation. We propose two methods to improve the efficiency of minimization. One uses a weaker, but more efficient continuously inspired approach as initialization and gradually refines the energy where it is necessary. The other one reformulates the dual energy enabling smooth approximations to be used for efficient optimization. We demonstrate the utility of our proposed minimization schemes in numerical experiments. Finally, we generalize the underlying energy formulation from isotropic metric smoothness costs to arbitrary nonmetric and orientation dependent smoothness terms.	[Zach, Christopher] Microsoft Res Cambridge, Cambridge CB1 2FB, England; [Hane, Christian; Pollefeys, Marc] ETH, Comp Vis & Geometry Grp, CH-8092 Zurich, Switzerland	Microsoft; Swiss Federal Institutes of Technology Domain; ETH Zurich	Zach, C (corresponding author), Microsoft Res Cambridge, 21 Stn Rd, Cambridge CB1 2FB, England.	chzach@microsoft.com	Pollefeys, Marc/I-7607-2013					Alberti G, 2003, CALC VAR PARTIAL DIF, V16, P299, DOI 10.1007/s005260100152; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Borwein J., 2006, CONVEX ANAL NONLINEA, DOI [10.1007/978-0-387-31256-9, DOI 10.1007/978-0-387-31256-9]; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boyle J. P., 1986, ADV ORDER RESTRICTED, P28, DOI DOI 10.1007/978-1-4613-9940-7_3; Chambolle A., 2010, J MATH IMAGING VIS, P1; Chambolle A., 2008, TECHNICAL REPORT; Combettes PL, 2011, SPRINGER SER OPTIM A, V49, P185, DOI 10.1007/978-1-4419-9569-8_10; CREMERS D., 2011, P IEEE INT C COMP VI; ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204; Esedoglu S, 2004, COMMUN PUR APPL MATH, V57, P1609, DOI 10.1002/cpa.20045; Hane C., 2013, P IEEE C COMP VIS PA; Hazan T, 2010, IEEE T INFORM THEORY, V56, P6294, DOI 10.1109/TIT.2010.2079014; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; Jojic V., 2010, P 27 INT C MACH LEAR, P503; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; KOMODAKIS N, 2007, P IEEE INT C COMP VI; Lellmann J., 2010, TECHNICAL REPORT; Lellmann J., 2010, P 11 EUR C COMP VIS; Melonakos J, 2008, IEEE T PATTERN ANAL, V30, P412, DOI 10.1109/TPAMI.2007.70713; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Pock T., 2009, P IEEE C COMP VIS PA; ROCKAFELLAR R.T., 1996, CONVEX ANAL PRINCETO; Savchynskyy Bogdan, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1817, DOI 10.1109/CVPR.2011.5995652; Scharstein D, 2003, PROC CVPR IEEE, P195; Schlesinger D, 2007, LECT NOTES COMPUT SC, V4679, P28; Sontag D., 2008, P 24 C ANN C UNC ART; Wainwright MJ, 2006, IEEE T SIGNAL PROCES, V54, P2099, DOI 10.1109/TSP.2006.874409; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Weiss Y., 2007, P 23 ANN C UNC ART I; Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036; Werner T, 2010, IEEE T PATTERN ANAL, V32, P1474, DOI 10.1109/TPAMI.2009.134; Zach C., 2012, P IEEE C COMP VIS PA; Zach C., 2008, P VIS MOD VIS WORKSH; Zach C, 2009, LECT NOTES COMPUT SC, V5748, P552, DOI 10.1007/978-3-642-03798-6_56; Zach C, 2009, PROC CVPR IEEE, P1911, DOI 10.1109/CVPRW.2009.5206565; [No title captured]; [No title captured]	41	8	8	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					157	170		10.1109/TPAMI.2013.105	http://dx.doi.org/10.1109/TPAMI.2013.105			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231873				2022-12-18	WOS:000327965100013
J	Farhadi, A; Sadeghi, MA				Farhadi, Ali; Sadeghi, Mohammad Amin			Phrasal Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual phrase; phrasal recognition; visual composites; object recognition; object interactions; scene understanding; single image activity recognition; object subcategories		In this paper, we introduce visual phrases, complex visual composites like "a person riding a horse." Visual phrases often display significantly reduced visual complexity compared to their component objects because the appearance of those objects can change profoundly when they participate in relations. We introduce a dataset suitable for phrasal recognition that uses familiar PASCAL object categories, and demonstrate significant experimental gains resulting from exploiting visual phrases. We show that a visual phrase detector significantly outperforms a baseline which detects component objects and reasons about relations, even though visual phrase training sets tend to be smaller than those for objects. We argue that any multiclass detection system must decode detector outputs to produce final results; this is usually done with nonmaximum suppression. We describe a novel decoding procedure that can account accurately for local context without solving difficult inference problems. We show this decoding procedure outperforms the state of the art. Finally, we show that decoding a combination of phrasal and object detectors produces real improvements in detector results.	[Farhadi, Ali] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA; [Sadeghi, Mohammad Amin] Univ Illinois, Dept Comp Sci, Urbana, IL USA	University of Washington; University of Washington Seattle; University of Illinois System; University of Illinois Urbana-Champaign	Farhadi, A (corresponding author), Univ Washington, Dept Comp Sci & Engn, AC101 Paul G Allen Ctr,Box 352350,185 Stevens Way, Seattle, WA 98195 USA.	ali@cs.uw.edu; msadegh2@illinois.edu			US National Science Foundation (NSF) [IIS-0803603]; US Office of Naval Research (ONR) [N00014-01-1-0890, N00014-10-1-0934]; MURI program; Google PhD fellowship	US National Science Foundation (NSF)(National Science Foundation (NSF)); US Office of Naval Research (ONR)(Office of Naval Research); MURI program(MURI); Google PhD fellowship(Google Incorporated)	This work was supported in part by the US National Science Foundation (NSF) under IIS-0803603 and in part by the US Office of Naval Research (ONR) under N00014-01-1-0890 and under N00014-10-1-0934 as part of the MURI program. Ali Farhadi was supported by a Google PhD fellowship. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of NSF, ONR, or Google.	Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9; Aytar Y., 2011, P IEEE INT C COMP VI; Bilen H., 2012, P DAGM OAGM JOINT PA; Bourdev L., 2010, P EUR C COMP VIS; Chum 0., 2007, P IEEE C COMP VIS PA; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Coughlan J., 1998, P IEEE C COMP VIS PA; Crandall D., 2005, P IEEE C COMP VIS PA; Delaitre V., 2010, RECOGNIZING HUMAN AC; Deng J., 2010, P EUR C COMP VIS; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Desai C., 2012, P EUR C COMP VIS; Desai C., 2010, P IEEE C COMP VIS PA; Desai C., 2010, P IEEE INT C COMP VI; Deselaers T., 2011, P IEEE C COMP VIS PA; Divvala S.K., 2012, P IEEE C COMP VIS PA; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farhadi A., 2010, P EUR C COMP VIS; Felzenszwalb P.F., 2013, DISCRIMINATIVELY TRA; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118; Fergus R., 2003, P IEEE C COMP VIS PA; Gu C., 2010, P 11 EUR C COMP VI 5; Gupta A., 2008, P EUR C COMP VIS; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Hoiem D., 2012, P EUR C COMP VIS; Koehn Philipp, 2010, STAT MACHINE TRANSLA; Lazebnik S., 2006, P IEEE C COMP VIS PA; Li C., 2011, P IEEE INT C COMP VI; Li C., 2012, P IEEE C COMP VIS PA; Li XR, 2012, IEEE T MULTIMEDIA, V14, P1091, DOI 10.1109/TMM.2012.2191943; Lim J., 2011, P C NEUR INF PROC SY; Loeff N., 2008, P EUR C COMP VIS; Maji S., 2011, P IEEE C COMP VIS PA; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Park D., 2010, P 11 EUR C COMP VI 4; Pirsiavash H., 2012, P IEEE C COMP VIS PA; Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158; Sadeghi M. A., 2011, P IEEE C COMP VIS PA; Singh S., 2012, P IEEE C COMP VIS PA; Siyahjani F., 2012, P AS C COMP VIS; Ushiku Y., 2012, P 20 ACM INT C MULT; Yang W., 2010, P IEEE C COMP VIS PA; Yang W., 2011, P IEEE C COMP VIS PA; Yang Y., 2012, P IEEE C COMP VIS PA; Yao B., 2010, P IEEE C COMP VIS PA; Zhu X., 2012, P BRIT MACH VIS C	47	8	8	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2854	2865		10.1109/TPAMI.2013.168	http://dx.doi.org/10.1109/TPAMI.2013.168			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136426				2022-12-18	WOS:000326502200004
J	Liu, XB; Lin, L; Jin, H				Liu, Xiaobai; Lin, Liang; Jin, Hai			Contextualized Trajectory Parsing with Spatiotemporal Graph	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video analysis; visual tracking; spatiotemporal graph; composite cluster sampling	TRACKING; SEGMENTATION	This work investigates how to automatically parse object trajectories in surveillance videos, which aims at jointly solving three subproblems: 1) spatial segmentation, 2) temporal tracking, and 3) object categorization. We present a novel representation spatiotemporal graph (ST-Graph) in which: 1) Graph nodes express the motion primitives, each representing a short sequence of small-size patches over consecutive images, and 2) every two neighbor nodes are linked with either a positive edge or a negative edge to describe their collaborative or exclusive relationship of belonging to the same object trajectory. Phrasing the trajectory parsing as a graph multicoloring problem, we propose a unified probabilistic formulation to integrate various types of context knowledge as informative priors. An efficient composite cluster sampling algorithm is employed in search of the optimal solution by exploiting both the collaborative and the exclusive relationships between nodes. The proposed framework is evaluated over challenging videos from public datasets, and results show that it can achieve state-of-the-art tracking accuracy.	[Liu, Xiaobai; Jin, Hai] Huazhong Univ Sci Technol, SCTS, Wuhan 430074, Peoples R China; [Liu, Xiaobai; Jin, Hai] Huazhong Univ Sci Technol, CGCL, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China; [Lin, Liang] Sun Yat Sen Univ, Guangzhou 510275, Guangdong, Peoples R China	Huazhong University of Science & Technology; Huazhong University of Science & Technology; Sun Yat Sen University	Liu, XB (corresponding author), Huazhong Univ Sci Technol, SCTS, Wuhan 430074, Peoples R China.	xbliu.lhi@gmail.com			National Science Foundation [0917141]; Hi-Tech Research and Development (863) Program of China [2013AA013801]; National Natural Science Foundation of China [61173082]	National Science Foundation(National Science Foundation (NSF)); Hi-Tech Research and Development (863) Program of China(National High Technology Research and Development Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The datasets used in this work were provided by the Lotus Hill Institute. The authors would like to thank Professor Song-chun Zhu (UCLA) and Professor Alan Yuille (UCLA) for their constructive comments. This work was supported by the National Science Foundation (no. 0917141), the Hi-Tech Research and Development (863) Program of China (no. 2013AA013801), and the National Natural Science Foundation of China (no. 61173082).	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Andriyenko A., 2011, P IEEE C COMP VIS PA; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Barbu A, 2007, J COMPUT GRAPH STAT, V16, P877, DOI 10.1198/106186007X255144; Basharat A, 2008, COMPUT VIS IMAGE UND, V110, P360, DOI 10.1016/j.cviu.2007.09.016; Birchfield S., 2008, IEEE COMP SOC C COMP, V1, P1; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Bugeau A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/317278; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dalal N., 2006, EUR C COMP VIS, p[7, 1]; Edwards R., 1998, PHYS REV, V38, P2009; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Fisher R., 2004, P IEEE INT WORKSH PE; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Hoiem D, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.232; Hu W, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587541; Junejo Imran N., 2007, 2007 11th IEEE International Conference on Computer Vision, P1; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kompatsiaris I, 2000, IEEE T CIRC SYST VID, V10, P1388, DOI 10.1109/76.889030; Kuo C. -H, 2010, P IEEE C COMP VIS PA; Lin L., 2009, P IEEE C COMP VIS PA, V1, P1351; Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3; Liu XB, 2011, IEEE T CIRC SYST VID, V21, P1588, DOI 10.1109/TCSVT.2011.2129410; Liu XB, 2009, PROC CVPR IEEE, P739, DOI 10.1109/CVPRW.2009.5206688; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Porway J, 2011, IEEE T PATTERN ANAL, V33, P1713, DOI 10.1109/TPAMI.2011.27; Rasmussen C, 1998, PROC CVPR IEEE, P16, DOI 10.1109/CVPR.1998.698582; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Song B., 2010, P EUR C COMP VIS; SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86; Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9; Wu YN, 2008, Q APPL MATH, V66, P81; Wu Z., 2011, P IEEE C COMP VIS PA; Xiaobai Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2249, DOI 10.1109/CVPR.2011.5995497; Yang B., 2012, P IEEE C COMP VIS PA; Yang B., 2011, P IEEE C COMP VIS PA; Yang M., 2007, P IEEE C COMP VIS PA, P1; Yu Q., 2007, P IEEE COMP SOC C CO, P1; Yu T., 2007, P IEEE WORKSH MOT VI; Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006; Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770	43	8	8	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					3010	3024		10.1109/TPAMI.2013.84	http://dx.doi.org/10.1109/TPAMI.2013.84			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136437				2022-12-18	WOS:000326502200016
J	Leong, MC; Lee, YT; Fang, F				Leong, Mei Chee; Lee, Yong Tsui; Fang, Fen			A Search-and-Validate Method for Face Identification from Single Line Drawings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; breadth-first search; face identification; single line drawing	MANIFOLD OBJECT; RECONSTRUCTION	Several studies have been made in finding the faces of an object depicted in a line drawing, but the problem has not been completely solved. Although existing methods can find the correct faces in most cases, there is no mechanism to ascertain that they are indeed correct, leaving the human user to do so. This paper uses a two-stage approach-find potential faces, then validate their correctness-to ensure that only correct faces are delivered ultimately. The face finding itself uses a double breadth-first search algorithm, which yields the shortest path, to find the potential faces. The basic premise is that the smallest faces found are more likely the correct ones. They serve as the "seed" potential faces, from which the algorithm proceeds to search for more faces. If the potential faces found satisfy the validation rules, then they are accepted as correct. Otherwise, the wrong potential faces are identified and removed, and new ones found in their place. The validation process is then repeated. The algorithm is fast and reliable, can deal with planar-faced manifold and nonmanifold objects, and can deliver the different results when a drawing has multiple interpretations. Our extensive tests show that the method can deal with most cases efficiently, including those that previous methods cannot solve.	[Leong, Mei Chee; Lee, Yong Tsui; Fang, Fen] Nanyang Technol Univ, Sch Mech & Aerosp Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Leong, MC (corresponding author), Nanyang Technol Univ, Sch Mech & Aerosp Engn, 50 Nanyang Ave,N3-02A-08, Singapore 639798, Singapore.	leongmc@ntu.edu.sg; mytlee@ntu.edu.sg; ffang1@e.ntu.edu.sg	Lee, Yong Tsui/A-1373-2011	Lee, Yong Tsui/0000-0003-1285-4217	Nanyang Technological University	Nanyang Technological University(Nanyang Technological University)	The authors would like to thank Nanyang Technological University for grants that support the work in this project. They also thank the reviewers for their substantive and penetrating comments which helped to improve the paper.	Argawal S. C., 1992, COMPUT AIDED DESIGN, V24, P123; Bondy J., 2008, GRAPH THEORY; Coppin B., 2004, ARTIF INTELL; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390; Heissermann J. A., 1991, GEN EULER POINCARE; Li HB, 2005, LECT NOTES COMPUT SC, V3519, P363; Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X; Liu J., 2003, TECHNICAL REPORT; Liu JZ, 2011, IEEE T PATTERN ANAL, V33, P3, DOI 10.1109/TPAMI.2010.49; Liu JZ, 2005, IEEE T PATTERN ANAL, V27, P861, DOI 10.1109/TPAMI.2005.119; Liu JZ, 2002, IEEE T PATTERN ANAL, V24, P1579, DOI 10.1109/TPAMI.2002.1114850; Liu JZ, 2001, IEEE T PATTERN ANAL, V23, P1106; MARKOWSKY G, 1980, IBM J RES DEV, V24, P582, DOI 10.1147/rd.245.0582; Shpitalni M, 1996, IEEE T PATTERN ANAL, V18, P1000, DOI 10.1109/34.541409; Sun Y., 2004, P 2 INT C COMP GRAPH, P167; Varley PAC, 2010, COMPUT AIDED DESIGN, V42, P279, DOI 10.1016/j.cad.2009.11.008	16	8	8	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2576	2591		10.1109/TPAMI.2013.82	http://dx.doi.org/10.1109/TPAMI.2013.82			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051721				2022-12-18	WOS:000324830900002
J	Morariu, VI; Harwood, D; Davis, LS				Morariu, Vlad I.; Harwood, David; Davis, Larry S.			Tracking People's Hands and Feet Using Mixed Network AND/OR Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tracking; motion; pictorial structures	INTEGRATION	We describe a framework that leverages mixed probabilistic and deterministic networks and their AND/OR search space to efficiently find and track the hands and feet of multiple interacting humans in 2D from a single camera view. Our framework detects and tracks multiple people's heads, hands, and feet through partial or full occlusion; requires few constraints (does not require multiple views, high image resolution, knowledge of performed activities, or large training sets); and makes use of constraints and AND/OR Branch-and-Bound with lazy evaluation and carefully computed bounds to efficiently solve the complex network that results from the consideration of interperson occlusion. Our main contributions are: 1) a multiperson part-based formulation that emphasizes extremities and allows for the globally optimal solution to be obtained in each frame, and 2) an efficient and exact optimization scheme that relies on AND/OR Branch-and-Bound, lazy factor evaluation, and factor cost sensitive bound computation. We demonstrate our approach on three datasets: the public single person HumanEva dataset, outdoor sequences where multiple people interact in a group meeting scenario, and outdoor one-on-one basketball videos. The first dataset demonstrates that our framework achieves state-of-the-art performance in the single person setting, while the last two demonstrate robustness in the presence of partial and full occlusion and fast nontrivial motion.	[Morariu, Vlad I.; Harwood, David; Davis, Larry S.] Univ Maryland, Dept Comp Sci, Inst Adv Comp Studies, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Morariu, VI (corresponding author), Univ Maryland, Dept Comp Sci, Inst Adv Comp Studies, AV Williams Bldg, College Pk, MD 20742 USA.	morariu@cs.umd.edu; harwood@umiacs.umd.edu; lsd@cs.umd.edu			US Office of Naval Research [N00014-09-10044]; DARPA Mind's Eye grant [W911NF-10-C-0083]	US Office of Naval Research(Office of Naval Research); DARPA Mind's Eye grant	This research was partially supported by US Office of Naval Research surveillance grant N00014-09-10044 and DARPA Mind's Eye grant W911NF-10-C-0083.	Andriluka M., 2008, P IEEE C COMP VIS PA; Bergtholdt Martin, 2010, International Journal of Computer Vision, V87, P93, DOI 10.1007/s11263-009-0209-1; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; Comaniciu D., 1999, P IEEE INT C COMP VI; Dechter R, 1999, ARTIF INTELL, V113, P41, DOI 10.1016/S0004-3702(99)00059-4; Dechter R., 2003, CONSTRAINT PROCESSIN; Dechter R, 2007, ARTIF INTELL, V171, P73, DOI 10.1016/j.artint.2006.11.003; del Rincon J. Martinez, 2008, P BRIT MACH VIS C; Eichner M., 2010, P EUR C COMP VIS; Elwert F., 2010, HEURISTICS PROBABILI, P327; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; GAMMETER S, 2008, P EUR C COMP VIS; Gupta A, 2008, IEEE T PATTERN ANAL, V30, P493, DOI 10.1109/TPAMI.2007.1173; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Howe N., 2006, P WORKSH EV ART HUM; HUA G, 2005, P IEEE C COMP VIS PA; Huang C., 2008, P EUR C COMP VIS; Jiang H., 2008, P IEEE C COMP VIS PA; Jiang H., 2009, P IEEE INT C COMP VI; Kask K, 2001, ARTIF INTELL, V129, P91, DOI 10.1016/S0004-3702(01)00107-2; Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004; LAMPERT C. H., 2008, P IEEE C COMP VIS PA; Lee C.-S., 2006, P WORKSH EV ART HUM; Lempitsky V., 2008, P EUR C COMP VIS; Marinescu R, 2009, ARTIF INTELL, V173, P1457, DOI 10.1016/j.artint.2009.07.003; Mateescu R, 2008, ANN MATH ARTIF INTEL, V54, P3, DOI 10.1007/s10472-009-9132-y; Mooij JM, 2010, J MACH LEARN RES, V11, P2169; Morariu V. I., 2008, ADV NEURAL INFORM PR, V21; Ogale AS, 2007, INT J COMPUT VISION, V72, P9, DOI 10.1007/s11263-006-8890-9; Park S, 2006, COMPUT VIS IMAGE UND, V102, P1, DOI 10.1016/j.cviu.2005.07.011; POPPE R, 2007, P WORKSH EV ART HUM; Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600; Ren X., 2005, P IEEE INT C COMP VI; RONFARD R, 2002, P EUR C COMP VIS; Schwartz W., 2009, P IEEE INT C COMP VI; Sidenbladh H., 2001, P IEEE INT C COMP VI; Sigal L., 2006, P IEEE C COMP VIS PA; Sudderth E.B., 2004, P ADV NEUR INF PROC; Tian T., 2010, P IEEE C COMP VIS PA; ULLMAN S., 2010, P IEEE C COMP VIS PA; Urtasun R., 2008, P IEEE C COMP VIS PA; Yanover C., 2004, P ADV NEUR INF PROC; Yu T., 2005, P IEEE C COMP VIS PA; Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73; Zhu L., 2008, P IEEE C COMP VIS PA; Zisserman, 2006, P 17 BRIT MACH VIS C, V2, P6	49	8	8	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1248	1262		10.1109/TPAMI.2012.187	http://dx.doi.org/10.1109/TPAMI.2012.187			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520262				2022-12-18	WOS:000316126800017
J	Ben Salah, M; Ben Ayed, I; Mitiche, A				Ben Salah, Mohamed; Ben Ayed, Ismail; Mitiche, Amar			Active Curve Recovery of Region Boundary Patterns	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; boundary patterns; boundary feature distributions; active curves; level sets; similarity measures	IMAGE SEGMENTATION; SHAPE PRIORS; CONTOURS; TEXTURE; MINIMIZATION; MOTION; COLOR	This study investigates the recovery of region boundary patterns in an image by a variational level set method which drives an active curve to coincide with boundaries on which a feature distribution matches a reference distribution. We formulate the scheme for both the Kullback-Leibler and the Bhattacharyya similarities, and apply it in two conditions: the simultaneous recovery of all region boundaries consistent with a given outline pattern, and segmentation in the presence of faded boundary segments. The first task uses an image-based geometric feature, and the second a photometric feature. In each case, the corresponding curve evolution equation can be viewed as a geodesic active contour (GAC) flow having a variable stopping function which depends on the feature distribution on the active curve. This affords a potent global representation of the target boundaries, which can effectively drive active curve segmentation in a variety of otherwise adverse conditions. Detailed experimentation shows that the scheme can significantly improve on current region and edge-based formulations.	[Ben Salah, Mohamed] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada; [Ben Ayed, Ismail] GE Healthcare, London, ON N6A 4V2, Canada; [Mitiche, Amar] INRS EMT, Inst Natl Rech Sci, Bur 6900, Montreal, PQ H5A 1K6, Canada	University of Alberta; General Electric; University of Quebec; Institut national de la recherche scientifique (INRS)	Ben Salah, M (corresponding author), Univ Alberta, Dept Comp Sci, 221 Athabasca Hall, Edmonton, AB T6G 2E8, Canada.	bensala@ualberta.ca; ismail.benayed@ge.com; mitiche@emt.inrs.ca						Ayed IB, 2009, IEEE T MED IMAGING, V28, P1902, DOI 10.1109/TMI.2009.2022087; Ben Ayed I, 2005, IEEE T PATTERN ANAL, V27, P793, DOI 10.1109/TPAMI.2005.106; Ben Ayed I., 2010, P IEEE C COMP VIS PA; Ben Ayed I, 2006, IEEE T PATTERN ANAL, V28, P1493, DOI 10.1109/TPAMI.2006.191; Ben Ayed I, 2010, PROC CVPR IEEE, P3225, DOI 10.1109/CVPR.2010.5540069; Ben Ayed I, 2009, INT J COMPUT VISION, V85, P115, DOI 10.1007/s11263-009-0249-6; Ben Salah M, 2010, IEEE T IMAGE PROCESS, V19, P220, DOI 10.1109/TIP.2009.2032940; BERG AC, 2005, P IEEE CS C COMP VIS; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; BOYKOV Y., 2005, P 10 IEEE INT C COMP; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chan T, 2005, PROC CVPR IEEE, P1164; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Cremers D, 2003, LECT NOTES COMPUT SC, V2695, P388; Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; DYER C. R., 2009, P IEEE C COMP VIS PA; Ferrari V., 2006, P EUR C COMP VIS MAY; FERRARI V, 2009, INT J COMPUTER VISIO; Foulonneau A, 2006, IEEE T PATTERN ANAL, V28, P1352, DOI 10.1109/TPAMI.2006.154; Foulonneau A, 2009, INT J COMPUT VISION, V81, P68, DOI 10.1007/s11263-008-0163-3; Freedman D, 2004, IEEE T IMAGE PROCESS, V13, P518, DOI 10.1109/TIP.2003.821445; Goudail F, 2004, J OPT SOC AM A, V21, P1231, DOI 10.1364/JOSAA.21.001231; Guichard F., 2001, IMAGE ANAL PDES; Holtzman-Gazit M, 2006, IEEE T IMAGE PROCESS, V15, P354, DOI [10.1109/TIP.2005.860624, 10.1109/tip.2005.860624]; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Kimmel R, 2003, INT J COMPUT VISION, V53, P225, DOI 10.1023/A:1023030907417; Lecellier F, 2009, LECT NOTES COMPUT SC, V5567, P137, DOI 10.1007/978-3-642-02256-2_12; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; Li C, 2005, P IEEE C COMP VIS PA; Lynch M, 2008, IEEE T MED IMAGING, V27, P195, DOI 10.1109/TMI.2007.904681; Mansouri AR, 2006, COMPUT VIS IMAGE UND, V101, P137, DOI 10.1016/j.cviu.2005.07.008; Mansouri AR, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P605, DOI 10.1109/ICIP.2002.1039043; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073; Mitiche A, 2010, SPRINGER TOP SIGN PR, V5, P1; Monteiro G., 2008, P 15 IEEE INT C IM P; Mortensen F.N., 2008, PROGR AUTONOMOUS ROB; Myronenko A, 2009, PROC CVPR IEEE, P2790; Papademetris X, 2002, IEEE T MED IMAGING, V21, P786, DOI 10.1109/TMI.2002.801163; Paragios N, 2004, IEEE T PATTERN ANAL, V26, P402, DOI 10.1109/TPAMI.2004.1262337; Paragios N, 2002, LECT NOTES COMPUT SC, V2351, P775; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; Plueimpitiwiriyawej C, 2005, IEEE T MED IMAGING, V24, P593, DOI 10.1109/TMI.2005.843740; Pock T., 2009, P IEEE C COMP VIS PA; ROTHER C., 2009, P 12 IEEE INT C COMP; Rousson M, 2005, LECT NOTES COMPUT SC, V3750, P757, DOI 10.1007/11566489_93; ROUSSON M, 2002, P EUR C COMP VIS; Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594; Sethian J. A., 1999, LEVEL SET METHODS FA; Steiner A, 1998, GRAPH MODEL IM PROC, V60, P112, DOI 10.1006/gmip.1998.0461; Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849; Vazquez C, 2006, IEEE T PATTERN ANAL, V28, P782, DOI 10.1109/TPAMI.2006.97; Xie XH, 2008, IEEE T PATTERN ANAL, V30, P632, DOI 10.1109/TPAMI.2007.70737; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	61	8	8	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					834	849		10.1109/TPAMI.2011.201	http://dx.doi.org/10.1109/TPAMI.2011.201			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	22442119				2022-12-18	WOS:000301747400001
J	Kim, M; Pavlovic, V				Kim, Minyoung; Pavlovic, Vladimir			Central Subspace Dimensionality Reduction Using Covariance Operators	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; supervised learning; kernel methods; regression	SLICED INVERSE REGRESSION; KERNEL	We consider the task of dimensionality reduction informed by real-valued multivariate labels. The problem is often treated as Dimensionality Reduction for Regression (DRR), whose goal is to find a low-dimensional representation, the central subspace, of the input data that preserves the statistical correlation with the targets. A class of DRR methods exploits the notion of inverse regression (IR) to discover central subspaces. Whereas most existing IR techniques rely on explicit output space slicing, we propose a novel method called the Covariance Operator Inverse Regression (COIR) that generalizes IR to nonlinear input/output spaces without explicit target slicing. COIR's unique properties make DRR applicable to problem domains with high-dimensional output data corrupted by potentially significant amounts of noise. Unlike recent kernel dimensionality reduction methods that employ iterative nonconvex optimization, COIR yields a closed-form solution. We also establish the link between COIR, other DRR techniques, and popular supervised dimensionality reduction methods, including canonical correlation analysis and linear discriminant analysis. We then extend COIR to semi-supervised settings where many of the input points lack their labels. We demonstrate the benefits of COIR on several important regression problems in both fully supervised and semi-supervised settings.	[Kim, Minyoung] Seoul Natl Univ Sci & Technol, Dept Elect & Informat Engn, Seoul 139743, South Korea; [Pavlovic, Vladimir] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA	Seoul National University of Science & Technology; Rutgers State University New Brunswick	Kim, M (corresponding author), Seoul Natl Univ Sci & Technol, Dept Elect & Informat Engn, Seoul 139743, South Korea.	mikim21@gmail.com; vladimir@cs.rutgers.edu						[Anonymous], 2002, LEARNING KERNELS; Antonov J. I., 2006, NOAA ATLAS NESDIS, V62, P1; Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M., 2005, P ART INT STAT; Cook R., 1998, WILEY PROB STAT; GARCIA HE, 2006, NOAA ATLAS NESDIS, V63, P1; Garcia HE., 2006, NOAA ATLAS NESDIS; Globerson A., 2005, P NEUR INF PROC SYST; GOLDBERGER J, 2004, P NEUR INF PROC SYST; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; HUANG SY, 2006, K FISHERS DISC UNPUB; KANAUJIA A, 2006, P COMP VIS GRAPH IM; Lawrence Neil D., 2006, CS0603 U SHEFF DEP C; LeCun Y., 1989, P NEUR INF PROC SYST; LEWIS JM, 2008, P INT C MACH LEARN A; LI KC, 1991, J AM STAT ASSOC, V86, P316, DOI 10.2307/2290563; Locarnini R.A., 2006, NOAA ATLAS NESDIS, V1, P1; NILSSON J, 2007, P INT C MACH LEARN; NILSSON J, 2008, THESIS LUND U; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vakhaniia N.N., 1987, PROBABILITY DISTRIBU; Wahba G., 1990, SPLINE MODELS OBSERV; Weinberger K., 2005, P NEUR INF PROC SYST; WILLIAMS CKI, 1996, P NEUR INF PROC SYST; Wu HM, 2008, J COMPUT GRAPH STAT, V17, P590, DOI 10.1198/106186008X345161; Xing E. P., 2002, P NEUR INF PROC SYST; Zhu X., 2003, ICML	33	8	9	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					657	670		10.1109/TPAMI.2010.111	http://dx.doi.org/10.1109/TPAMI.2010.111			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	20513923				2022-12-18	WOS:000287370400001
J	McCloskey, S; Langer, M; Siddiqi, K				McCloskey, Scott; Langer, Michael; Siddiqi, Kaleem			Removal of Partial Occlusion from Single Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Focus; matting; partial occlusion; curve evolution	CURVES	This paper examines large partial occlusions in an image which occur near depth discontinuities when the foreground object is severely out of focus. We model these partial occlusions using matting, with the alpha value determined by the convolution of the blur kernel with a pinhole projection of the occluder. The main contribution is a method for removing the image contribution of the foreground occluder in regions of partial occlusion, which improves the visibility of the background scene. The method consists of three steps. First, the region of complete occlusion is estimated using a curve evolution method. Second, the alpha value at each pixel in the partly occluded region is estimated. Third, the intensity contribution of the foreground occluder is removed in regions of partial occlusion. Experiments demonstrate the method's ability to remove the effects of partial occlusion in single images with minimal user input.	[McCloskey, Scott; Langer, Michael; Siddiqi, Kaleem] McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada	McGill University	McCloskey, S (corresponding author), McGill Univ, Sch Comp Sci, 3480 Univ St, Montreal, PQ H3A 2A7, Canada.	scott@cim.mcgill.ca; langer@cim.mcgill.ca; siddiqi@cim.mcgill.ca	Hansen, Peter C/F-3163-2010	Hansen, Peter C/0000-0002-4948-1007; Siddiqi, Kaleem/0000-0002-7347-9716	NSERC (Canada); FQRNT (Quebec)	NSERC (Canada)(Natural Sciences and Engineering Research Council of Canada (NSERC)); FQRNT (Quebec)(FQRNT)	The authors thank NSERC (Canada) and FQRNT (Quebec) for their support. They also thank the reviewers and Kyros Kutulatkos, who was an associate editor for an earlier version of this manuscript, for their helpful comments and suggestions.	Asada N, 1998, IEEE T PATTERN ANAL, V20, P155, DOI 10.1109/34.659933; Bhasin SS, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P488, DOI 10.1109/ICCV.2001.937556; Chaudhuri S., 1998, DEPTH DEFOCUS REAL A; Chuang YY, 2001, PROC CVPR IEEE, P264; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Favaro P, 2003, PROC CVPR IEEE, P579; GRAYSON MA, 1987, J DIFFER GEOM, V26, P285; GU J, 2009, P ACM SIGGRAPH DEC; Hasinoff SW, 2007, IEEE I CONF COMP VIS, P550; KIMIA BB, 1992, J MATH ANAL APPL, V163, P438, DOI 10.1016/0022-247X(92)90260-K; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; MCCLOSKEY S, 2007, P 8 AS C COMP VIS, P271; McGuire M, 2005, ACM T GRAPHIC, V24, P567, DOI 10.1145/1073204.1073231; NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Reinhard E., 2005, P 2 S APPL PERC GRAP, P95; SAPIRO G, 1993, PATTERN RECOGN, V26, P1363, DOI 10.1016/0031-3203(93)90142-J; Schechner YY, 2000, INT J COMPUT VISION, V39, P141, DOI 10.1023/A:1008175127327; SMITH AR, 1996, P INT C COMP GRAPH I, V30, P259; Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721; Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849; Zhang Y, 2008, PROC CVPR IEEE, P125	24	8	8	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					647	654		10.1109/TPAMI.2010.187	http://dx.doi.org/10.1109/TPAMI.2010.187			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	21252401				2022-12-18	WOS:000286204700016
J	Xu, SG; Zhang, YX; Yong, JH				Xu, Song-Gang; Zhang, Yun-Xiang; Yong, Jun-Hai			A Fast Sweeping Method for Computing Geodesics on Triangular Manifolds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Geodesics; fast sweeping methods; fast marching methods; Eikonal equation; triangular manifold	DISTANCE MAPS; SHAPE	A wide range of applications in computer intelligence and computer graphics require computing geodesics accurately and efficiently. The fast marching method (FMM) is widely used to solve this problem, of which the complexity is O(N log N), where N is the total number of nodes on the manifold. A fast sweeping method ( FSM) is proposed and applied on arbitrary triangular manifolds of which the complexity is reduced to O(N). By traversing the undigraph, four orderings are built to produce two groups of interfering waves, which cover all directions of characteristics. The correctness of this method is proved by analyzing the coverage of characteristics. The convergence and error estimation are also presented.	[Xu, Song-Gang; Zhang, Yun-Xiang; Yong, Jun-Hai] Tsinghua Univ, Sch Software, Inst Comp Graph, Beijing 100084, Peoples R China; [Xu, Song-Gang; Zhang, Yun-Xiang; Yong, Jun-Hai] Tsinghua Univ, Sch Software, Comp Aided Design Lab, Beijing 100084, Peoples R China; [Xu, Song-Gang; Zhang, Yun-Xiang; Yong, Jun-Hai] Minist Educ China, Key Lab Informat Syst Secur, Beijing 100084, Peoples R China	Tsinghua University; Tsinghua University; Ministry of Education, China	Xu, SG (corresponding author), Tsinghua Univ, Sch Software, Inst Comp Graph, Room 824,Main Bldg, Beijing 100084, Peoples R China.	xsg06@mails.tsinghua.edu.cn; zhangyunxiang06@mails.tsinghua.edu.cn; yongjh@tsinghua.edu.cn			Chinese 973 Program [2004CB719400]; National Science Foundation of China [60625202, 60533070, 90715043, 60911130368]; Chinese 863 Program [2007AA040401]; Fok Ying Tung Education Foundation [111070]; INRIA; IMATI; AIM@SHAPE Shape Repository	Chinese 973 Program(National Basic Research Program of China); National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Chinese 863 Program(National High Technology Research and Development Program of China); Fok Ying Tung Education Foundation(Fok Ying Tung Education Foundation); INRIA; IMATI; AIM@SHAPE Shape Repository	This research was supported by the Chinese 973 Program (2004CB719400), the National Science Foundation of China (60625202, 60533070, 90715043, 60911130368), and the Chinese 863 Program (2007AA040401). J.-H. Yong was supported by the Fok Ying Tung Education Foundation (111070). Furthermore, in Fig. 12, Model Bunny was courteously provided by MPII, Model Hand was courteously provided by INRIA and IMATI, and Model Kitty was courteously provided by Frank_ter_Haar, from the AIM@SHAPE Shape Repository.	ABGRALL R, 1998, COMMUN PUR APPL MATH, V9, P1339; Augoula S., 2000, Journal of Scientific Computing, V15, P197, DOI 10.1023/A:1007633810484; BARDI M, 1984, NONLINEAR ANAL-THEOR, V8, P1373, DOI 10.1016/0362-546X(84)90020-8; Bronstein AM, 2007, J COMPUT PHYS, V225, P771, DOI 10.1016/j.jcp.2007.01.009; BRONSTEIN AM, 2007, PARALLEL ALGORITHMS; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; HASSOUNA M, 2005, P IEEE INT C IM PROC; Hassouna MS, 2007, IEEE T PATTERN ANAL, V29, P1563, DOI 10.1109/TPAMI.2007.1154; Kao CY, 2005, SIAM J NUMER ANAL, V42, P2612, DOI 10.1137/S0036142902419600; Kao CY, 2004, J COMPUT PHYS, V196, P367, DOI 10.1016/j.jcp.2003.11.007; KIM S, 2000, GROUP MARCHING METHO; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P382, DOI 10.1006/cviu.1995.1062; Kimmel R, 2001, J MATH IMAGING VIS, V14, P237, DOI 10.1023/A:1011234012449; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; KIRSHNAMURTHY V, 1996, P SIGGRAPH 96 NEW OR, P313; QIAN J, 2005, SIAM J NUMER ANAL, V45, P83; Qian JL, 2007, J SCI COMPUT, V31, P237, DOI 10.1007/s10915-006-9124-6; Rawlinson N, 2004, GEOPHYS J INT, V156, P631, DOI 10.1111/j.1365-246X.2004.02153.x; RICKETT J, 2000, 2 ORDER FAST MARCHIN; Sethian J., P 29 COMP FLUID DYN; Sethian J. A., 1999, LEVEL SET METHODS FA; Sethian JA, 1999, SIAM REV, V41, P199, DOI 10.1137/S0036144598347059; Sethian JA, 2003, SIAM J NUMER ANAL, V41, P325, DOI 10.1137/S0036142901392742; SETHIAN JA, 1996, P NAT ACAD SCI, V93, P4; Tsai YHR, 2003, SIAM J NUMER ANAL, V41, P673, DOI 10.1137/S0036142901396533; TSITSIKLIS JN, 1995, IEEE T AUTOMAT CONTR, V40, P1528, DOI 10.1109/9.412624; VANTRIER J, 1991, GEOPHYSICS, V56, P812, DOI 10.1190/1.1443099; Yatziv L, 2006, J COMPUT PHYS, V212, P393, DOI 10.1016/j.jcp.2005.08.005; Zhang YT, 2006, J SCI COMPUT, V29, P25, DOI 10.1007/s10915-005-9014-3; Zhao HK, 2005, MATH COMPUT, V74, P603; Zhao HK, 2000, COMPUT VIS IMAGE UND, V80, P295, DOI 10.1006/cviu.2000.0875	31	8	8	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					231	241		10.1109/TPAMI.2008.272	http://dx.doi.org/10.1109/TPAMI.2008.272			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075455				2022-12-18	WOS:000272741500004
J	Jamieson, M; Fazly, A; Stevenson, S; Dickinson, S; Wachsmuth, S				Jamieson, Michael; Fazly, Afsaneh; Stevenson, Suzanne; Dickinson, Sven; Wachsmuth, Sven			Using Language to Learn Structured Appearance Models for Image Annotation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Language-vision integration; image annotation; perceptual grouping; appearance models; object recognition		Given an unstructured collection of captioned images of cluttered scenes featuring a variety of objects, our goal is to simultaneously learn the names and appearances of the objects. Only a small fraction of local features within any given image are associated with a particular caption word, and captions may contain irrelevant words not associated with any image object. We propose a novel algorithm that uses the repetition of feature neighborhoods across training images and a measure of correspondence with caption words to learn meaningful feature configurations (representing named objects). We also introduce a graph-based appearance model that captures some of the structure of an object by encoding the spatial relationships among the local visual features. In an iterative procedure, we use language (the words) to drive a perceptual grouping process that assembles an appearance model for a named object. Results of applying our method to three data sets in a variety of conditions demonstrate that, from complex, cluttered, real-world scenes with noisy captions, we can learn both the names and appearances of objects, resulting in a set of models invariant to translation, scale, orientation, occlusion, and minor changes in viewpoint or articulation. These named models, in turn, are used to automatically annotate new, uncaptioned images, thereby facilitating keyword-based image retrieval.	[Jamieson, Michael; Fazly, Afsaneh; Stevenson, Suzanne; Dickinson, Sven] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; [Wachsmuth, Sven] Univ Bielefeld, D-33501 Bielefeld, Germany	University of Toronto; University of Bielefeld	Jamieson, M (corresponding author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd,Room 3302, Toronto, ON M5S 3G4, Canada.	jamieson@cs.toronto.edu; afsaneh@cs.toronto.edu; suzanne@cs.toronto.edu; sven@cs.toronto.edu; swachsmu@techfak.uni-bielefelf.de		Wachsmuth, Sven/0000-0001-5371-7214	Idee, Inc.; CITO; NSERC Canada	Idee, Inc.; CITO; NSERC Canada(Natural Sciences and Engineering Research Council of Canada (NSERC))	The authors gratefully acknowledge the support of Idee, Inc., CITO, and NSERC Canada.	Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; BARNARD K, 2003, P IEEE CS C COMP VIS; BARNARD K, 2007, P IEEE CS C COMP VIS; Berg T.L., 2004, P IEEE CS C COMP VIS; BERG TL, 2006, P IEEE CS C COMP VIS; BLEI DM, 2003, P ACM SIGIR; CARBONETTO P, 2004, P EUR C COMP VIS; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P2089, DOI 10.1109/TPAMI.2007.1126; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; CASCIA ML, 1998, P IEEE WORKSH CONT B; CRANDALL DJ, 2006, P EUR C COMP VIS; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; FENG S, 2004, P IEEE CS C COMP VIS; FERGUS R, 2005, P IEEE INT C COMP VI; JAMIESON M, 2006, P IEEE CS C COMP VIS; JAMIESON M, 2007, P IEEE INT C COMP VI; Jeon J., 2003, P ACM SIGIR; KE Y, 2004, P IEEE CS C COMP VIS; Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097; PHILBIN J, 2007, P IEEE CS C COMP VIS; QUATTONI A, 2007, P IEEE CS C COMP VIS; Simon I, 2007, P IEEE INT C COMP VI; SIVIC J, 2004, P IEEE CS C COMP VIS	25	8	10	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					148	164		10.1109/TPAMI.2008.283	http://dx.doi.org/10.1109/TPAMI.2008.283			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926905				2022-12-18	WOS:000271826700012
J	Tong, L; Tai, CL; Yang, HF; Cai, SJ				Tong Lu; Tai, Chiew-Lan; Yang, Huafei; Cai, Shijie			A Novel Knowledge-Based System for Interpreting Complex Engineering Drawings: Theory, Representation, and Implementation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Knowledge representation; interpretation; engineering drawings; high-level analysis; graphics recognition	DOCUMENT RECOGNITION METHOD; ARC SEGMENTATION; ALGORITHM; VECTORIZATION; CONVERSION; MODEL; DMOS	We present a novel knowledge-based system to automatically convert real-life engineering drawings to content-oriented high-level descriptions. The proposed method essentially turns the complex interpretation process into two parts: knowledge representation and knowledge-based interpretation. We propose a new hierarchical descriptor-based knowledge representation method to organize the various types of engineering objects and their complex high-level relations. The descriptors are defined using an Extended Backus Naur Form (EBNF), facilitating modification and maintenance. When interpreting a set of related engineering drawings, the knowledge-based interpretation system first constructs an EBNF-tree from the knowledge representation file, then searches for potential engineering objects guided by a depth-first order of the nodes in the EBNF-tree. Experimental results and comparisons with other interpretation systems demonstrate that our knowledge-based system is accurate and robust for high-level interpretation of complex real-life engineering projects.	[Tong Lu; Yang, Huafei; Cai, Shijie] Nanjing Univ, Dept Comp Sci & Technol, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China; [Tai, Chiew-Lan] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China	Nanjing University; Hong Kong University of Science & Technology	Tong, L (corresponding author), Nanjing Univ, Dept Comp Sci & Technol, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.	luton@nju.edu.cn; taicl@cse.ust.hk; yanghfnju@hotmail.com; sjcai@nju.edu.cn			National Natural Science Foundation of China [60603086, 60723003, 60721002]; National High-Tech Research and Development Program of China [2007AA01Z334]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National High-Tech Research and Development Program of China(National High Technology Research and Development Program of China)	This project was supported by the National Natural Science Foundation of China (Grants 60603086, 60723003, and 60721002) and the National High-Tech Research and Development Program of China ( Grant 2007AA01Z334).	AHONEY J. V, 2002, P AAAI SPRING S, P105; [Anonymous], 2002, SSS 02; [Anonymous], J CONTEXT BEHAV SCI, V17, P109, DOI [10.1016/j, DOI 10.1016/J, DOI 10.1115/1.1577356]; [Anonymous], P 1 IARP WORKSH GRAP; Bimber O, 2000, COMPUT GRAPH-UK, V24, P851, DOI 10.1016/S0097-8493(00)00088-1; Bodansky E., 2000, International Journal on Document Analysis and Recognition, V3, P67, DOI 10.1007/s100320000034; Chen Y, 1996, COMPUT VIS IMAGE UND, V63, P273, DOI 10.1006/cviu.1996.0019; CHENG YQ, 1990, P 1 INT C SYST INT, P302; Cherneff J., 1992, RES ENG DES, V3, P195; Chiang JY, 1998, PATTERN RECOGN, V31, P1541, DOI 10.1016/S0031-3203(97)00157-X; Couasnon B, 2004, LECT NOTES COMPUT SC, V3088, P38; Couasnon B, 2006, INT J DOC ANAL RECOG, V8, P111, DOI 10.1007/s10032-005-0148-5; Couasnon B, 2007, INT J DOC ANAL RECOG, V9, P223, DOI 10.1007/s10032-007-0044-2; Crevier D, 1997, COMPUT VIS IMAGE UND, V67, P161, DOI 10.1006/cviu.1996.0520; Dori D, 1999, IEEE T PATTERN ANAL, V21, P202, DOI 10.1109/34.754586; Dori D, 1999, IEEE T SYST MAN CY A, V29, P411, DOI 10.1109/3468.769761; Dosch P., 2000, International Journal on Document Analysis and Recognition, V3, P102, DOI 10.1007/PL00010901; Hilaire X, 2006, IEEE T PATTERN ANAL, V28, P890, DOI 10.1109/TPAMI.2006.127; HORIUCHI A, 1993, MOL PHARMACOL, V43, P281; Janssen RDT, 1997, COMPUT VIS IMAGE UND, V65, P38, DOI 10.1006/cviu.1996.0484; Ji Q, 1997, ACM COMPUT SURV, V29, P264, DOI 10.1145/262009.262012; JOSEPH SH, 1992, IEEE T PATTERN ANAL, V14, P928, DOI 10.1109/34.161351; KASTURI R, 1990, IEEE T PATTERN ANAL, V12, P978, DOI 10.1109/34.58870; Lee BS, 2000, KOREAN J GENETIC, V22, P11; Liu WY, 1998, IEEE T PATTERN ANAL, V20, P424, DOI 10.1109/34.677280; Lu T, 2005, COMPUT AIDED DESIGN, V37, P1053, DOI 10.1016/j.cad.2004.11.004; LU T, 2005, COMPUT AIDED DESIGN, V2, P527; Lu T, 2007, INT J DOC ANAL RECOG, V9, P31, DOI 10.1007/s10032-006-0029-6; Prabhu BS, 1999, COMPUT GRAPH-UK, V23, P25, DOI 10.1016/S0097-8493(98)00114-9; Pridmore TP, 2002, LECT NOTES COMPUT SC, V2390, P245; Ramel JY, 2004, LECT NOTES COMPUT SC, V3088, P1; ROSEBOROUGH JB, 1995, PATTERN RECOGN, V28, P421, DOI 10.1016/0031-3203(94)00113-Z; SMITH H, 1987, J INFECTION, V15, P1, DOI 10.1016/S0163-4453(87)91276-X; Song JQ, 2000, PATTERN ANAL APPL, V3, P142, DOI 10.1007/s100440070019; Song JQ, 2004, IEEE T PATTERN ANAL, V26, P1491, DOI 10.1109/TPAMI.2004.103; Song JQ, 2002, IEEE T PATTERN ANAL, V24, P1048, DOI 10.1109/TPAMI.2002.1023802; Song JQ, 2000, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2000.855844; SONG JQ, 1999, P 3 IAPR INT WORKSH, P32; Su CJ, 1998, COMPUT IND ENG, V35, P635, DOI 10.1016/S0360-8352(98)00177-6; SU F, 2001, P IEEE C COMP VIS PA, P710; Tombre K, 1998, LECT NOTES COMPUT SC, V1389, P257; Tombre K., 1998, P 10 PORT C PATT REC, P11; Ullman D., 1997, CLASSIC MACGRAW HILL; VAXIVIERE P, 1992, P IEEE INT C SYST EN, P242; YANG HF, 2005, P 6 IAPR INT WORKSH, P46; Yu YH, 1997, IEEE T PATTERN ANAL, V19, P868, DOI 10.1109/34.608290; Zheng YF, 2005, IEEE T PATTERN ANAL, V27, P777, DOI 10.1109/TPAMI.2005.89; Zhi GS, 2003, COMPUT AIDED DESIGN, V35, P1, DOI 10.1016/S0010-4485(01)00171-3	48	8	17	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1444	1457		10.1109/TPAMI.2008.161	http://dx.doi.org/10.1109/TPAMI.2008.161			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542578	Green Submitted			2022-12-18	WOS:000267050600008
J	Fang, YC; Wu, BW				Fang, Yi-Chin; Wu, Bo-Wen			Prediction of the Thermal Imaging Minimum Resolvable (Circle) Temperature Difference with Neural Network Application	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Thermal imaging; MRTD; image recognition; neural network; temperature prediction	PATTERN-RECOGNITION; SYSTEMS; PERFORMANCE; MOMENTS	Thermal imaging is an important technology in both national defense and the private sector. An advantage of thermal imaging is its ability to be deployed while fully engaged in duties, not limited by weather or the brightness of indoor or outdoor conditions. However, in an outdoor environment, many factors, including atmospheric decay, target shape, great distance, fog, temperature out of range, and diffraction limits can lead to bad image formation, which directly affects the accuracy of object recognition. The visual characteristics of the human eye mean that it has a much better capacity for picture recognition under normal conditions than artificial intelligence does. However, conditions of interference significantly reduce this capacity for picture recognition, for instance, fatigue impairs human eyesight. Hence, psychological and physiological factors can affect the result when the human eye is adopted to measure minimum resolvable temperature difference (MRTD) and minimum resolvable circle temperature difference (MRCTD). This study explores thermal imaging recognition and presents a method for effectively choosing the characteristic values and processing the images fully. Neural network technology is successfully applied to recognize thermal imaging and predict MRTD and MRCTD, exceeding thermal imaging recognition under fatigue and the limits of the human eye.	[Fang, Yi-Chin] Natl Kaohsiung First Univ Sci, Kaohsiung 811, Taiwan; Inst Engn Sci & Technol, Kaohsiung 811, Taiwan	National Kaohsiung University of Science & Technology	Fang, YC (corresponding author), Natl Kaohsiung First Univ Sci, 2 Jhuoyue Rd, Kaohsiung 811, Taiwan.	yfang@ccms.nkfust.edu.tw; u9115907@ccms.nkfust.edu.tw		Fang, Yi chin/0000-0003-2098-6869				BURR DJ, 1988, IEEE T ACOUST SPEECH, V36, P1162, DOI 10.1109/29.1643; CASH GL, 1987, COMPUT VISION GRAPH, V39, P291, DOI 10.1016/S0734-189X(87)80183-4; Fairhurst AM, 2000, J MOD OPTIC, V47, P1435, DOI 10.1080/09500340008235114; Fairhurst AM, 1998, OPT ENG, V37, P744, DOI 10.1117/1.601906; Head JF, 2002, IEEE ENG MED BIOL, V21, P80, DOI 10.1109/MEMB.2002.1175142; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; LEE DH, 1994, IEEE T INSTRUM MEAS, V43, P824, DOI 10.1109/19.368060; LEONID IP, 2000, NEURLA NETWORKS INTE; Lettington AH, 2001, J MOD OPTIC, V48, P115, DOI 10.1080/09500340108235159; LETTINGTON AH, 1993, MEAS SCI TECHNOL, V4, P1106, DOI 10.1088/0957-0233/4/10/013; LETTINGTON AH, 1993, J MOD OPTIC, V40, P203, DOI 10.1080/09500349314550221; LETTINGTON AH, 1993, P SPIE INT SOC OPTIC, P217; LI YJ, 1992, PATTERN RECOGN, V25, P723, DOI 10.1016/0031-3203(92)90135-6; Lind-Nielsen J, 2001, FORM METHOD SYST DES, V18, P5, DOI 10.1023/A:1008736219484; MCAULAY A, 1991, PROC NAECON IEEE NAT, P743, DOI 10.1109/NAECON.1991.165835; Merryman SA, 1995, IEEE T IND ELECTRON, V42, P615, DOI 10.1109/41.475502; Moore P. J., 1998, P EMPD, V2, P589; Nigel L., 1998, THESIS U READING, P48; Pavlidis I, 2002, IEEE ENG MED BIOL, V21, P56, DOI 10.1109/MEMB.2002.1175139; UMANSKY MS, 1992, ANAL METHODS OPTICAL, V1843, P344; YEH IC, 2002, J COMPUT, V14, P16; YICHIN F, 2000, THESIS U READING, P61; Yuan T. C., 2002, J MED BIOL ENG, V22, P97	23	8	8	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2008	30	12					2218	2228		10.1109/TPAMI.2007.70839	http://dx.doi.org/10.1109/TPAMI.2007.70839			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	360CF	18988953				2022-12-18	WOS:000260033900011
J	Min, C; Medioni, G				Min, Changki; Medioni, Gerard			Inferring segmented dense motion layers using 5D tensor voting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis; tensor voting; optical flow; segmentation; mosaicking	PLANE IMAGE-ANALYSIS; MOSAICS	We present a novel local spatiotemporal approach to produce motion segmentation and dense temporal trajectories from an image sequence. A common representation of image sequences is a 3D spatiotemporal volume (x, y, t), and its corresponding mathematical formalism is the fiber bundle. However, directly enforcing the spatiotemporal smoothness constraint is difficult in the fiber bundle representation. Thus, we convert the representation into a new 5D space (x, y, t, v(x), v(y)) with an additional velocity domain, where each moving object produces a separate 3D smooth layer. The smoothness constraint is now enforced by extracting 3D layers using the tensor voting framework in a single step that solves both correspondence and segmentation simultaneously. Motion segmentation is achieved by identifying those layers and the dense temporal trajectories are obtained by converting the layers back into the fiber bundle representation. We proceed to address three applications (tracking, mosaic, and 3D reconstruction) that are hard to solve from the video stream directly because of the segmentation and dense matching steps but become straightforward with our framework. The approach does not make restrictive assumptions about the observed scene or camera motion and is therefore generally applicable. We present results on a number of data sets.	[Min, Changki] Apple Comp Inc, Cupertino, CA 95014 USA; [Medioni, Gerard] Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA	Apple Inc; University of Southern California	Min, C (corresponding author), Apple Comp Inc, 6 Infinite Loop,MS 306-2CW, Cupertino, CA 95014 USA.	changkimin@gmail.com; medioni@usc.edu						AMIAZ T, 2005, P ICIP 2005 GEN IT S, V3, P1264; AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; BAKER HH, 1989, INT J COMPUT VISION, V3, P33, DOI 10.1007/BF00054837; Bleyer M, 2004, IEEE IMAGE PROC, P2997; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; BROX T, 2006, P EUR C COMP VIS MAY, P471; BROX T, 2004, P 8 EUR C COMP VIS, V4, P25; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4; Davis J, 1998, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.1998.698630; HIRSCHMULLER H., 2006, P IEEE C COMP VIS PA, V2, P2386, DOI DOI 10.1109/CVPR.2006.294; Husemoller D., 1993, FIBRE BUNDLES; Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679; KLAUS A, 2006, P 18 INT C PATT REC; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Medioni G., 2000, COMPUTATIONAL FRAMEW; Memin E, 2002, INT J COMPUT VISION, V46, P129, DOI 10.1023/A:1013539930159; *MIDDL COLL, 2008, MIDDL COLL STER EV W; MIN C, 2006, P 18 INT C PATT REC; MIN C, 2006, P 5 IEEE WORKSH PERC; Nicolescu M, 2003, IEEE T PATTERN ANAL, V25, P492, DOI 10.1109/TPAMI.2003.1190574; SCHNORR C, 1991, INT J COMPUT VISION, V6, P25, DOI 10.1007/BF00127124; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; Sun J, 2005, PROC CVPR IEEE, P399; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Uyttendaele M, 2001, PROC CVPR IEEE, P509; Vidal R, 2004, PROC CVPR IEEE, P310; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; Xiao JJ, 2005, IEEE T PATTERN ANAL, V27, P1644, DOI 10.1109/TPAMI.2005.202; Yang Q., 2006, P IEEE C COMP VIS PA, P2347; Zelnik-Manor L, 2003, PROC CVPR IEEE, P287	35	8	9	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1589	1602		10.1109/TPAMI.2007.70802	http://dx.doi.org/10.1109/TPAMI.2007.70802			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	324FZ	18617717				2022-12-18	WOS:000257504400007
J	Penna, MA; Dines, KA				Penna, Michael A.; Dines, Kris A.			A simple method for fitting sphere-like surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						sphere-like surface; spherical harmonics; data fitting	SHAPE; HARMONICS; TOMOGRAPHY; RECOVERY	In this paper, we present a new and simple method for fitting a sphere-like surface to a set of data points in 3-space. In comparison to the standard method that involves using spherical harmonics, this method is conceptually simpler and computationally less complex and intensive, especially when used to address problems in which data is sparse or nonuniform.	Indiana Univ, Dept Math Sci, Indianapolis, IN 46202 USA; XDATA Corp, Indianapolis, IN 46220 USA	Indiana University System; Indiana University-Purdue University Indianapolis	Penna, MA (corresponding author), Indiana Univ, Dept Math Sci, 402 N Blackford St, Indianapolis, IN 46202 USA.	mpenna@math.iupui.edu; krisdines@mac.com						Arfken G. B., 2012, MATH METHODS PHYS; Ballard D.H., 1982, COMPUTER VISION; BARTH V, 1991, ATLAS BREAST DIS; BRECHBUHLER C, 1992, P SOC PHOTO-OPT INS, V1808, P80, DOI 10.1117/12.131069; BURNS A, 1997, ADV ASTRONAUTICAL SC, V97, P529; Cardenosa G., 2001, BREAST IMAGING COMPA; CASOTTO S, 2003, ADV ASTRONAUTICAL SC, V114, P1787; Chai XJ, 2005, LECT NOTES COMPUT SC, V3546, P956; CHEN CW, 1994, IEEE T PATTERN ANAL, V16, P342, DOI 10.1109/34.277589; Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669; Coppini G, 1995, COMPUT CARDIOL, P71, DOI 10.1109/CIC.1995.482574; Erturk S, 1998, ELECTRON LETT, V34, P1657, DOI 10.1049/el:19981196; Erturk S, 1997, ELECTRON LETT, V33, P951, DOI 10.1049/el:19970659; Garboczi EJ, 2002, CEMENT CONCRETE RES, V32, P1621, DOI 10.1016/S0008-8846(02)00836-0; GastelluEtchegorry JP, 1996, REMOTE SENS ENVIRON, V58, P131, DOI 10.1016/0034-4257(95)00253-7; Groemer H., 1996, GEOMETRIC APPL FOURI; Guillaume H, 2004, P ANN INT IEEE EMBS, V26, P1699; Hall JA, 2003, ATLAS BREAST DIS; Huang H, 2004, P ANN INT IEEE EMBS, V26, P3250; Huang H, 2005, PROC SPIE, V5747, P1384, DOI 10.1117/12.595954; KONOPLIV A, 1991, P AAS AIAA ASTR C AU, P941; KOPANS DB, 1998, ATLAS BREAST IMAGING; Kumar S, 1996, P SOC PHOTO-OPT INS, V2709, P373, DOI 10.1117/12.237879; Lefaix G, 1997, P ANN INT IEEE EMBS, V19, P422, DOI 10.1109/IEMBS.1997.754568; Liu Y, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P3; MARTIN J, 1988, ATLAS MAMMOGRAPHY HI; MATHENY A, 1995, IEEE T PATTERN ANAL, V17, P967, DOI 10.1109/34.464561; MAX NL, 1988, IEEE COMPUT GRAPH, V8, P42, DOI 10.1109/38.7748; Millman R.S., 1977, ELEMENTS DIFFERENTIA; Qing LY, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P296; SANCHEZMONDRAGO.J, 2003, P SPIE INT SOC OPT E, V2, P51; Schudy, 1979, P 6 C COMP APPL RAD; SCHUDY R, 1978, 12 U ROCH COMP SCI D; Silverberg SG, 2002, ATLAS BREAST PATHOLO; SOUSSEN C, 2001, P IEEE INT C IMAGE P, V1, P718; Stewart J., 2003, CALCULUS; TamezPena JG, 1996, P SOC PHOTO-OPT INS, V2727, P904, DOI 10.1117/12.233307; Tao YF, 2003, J AUDIO ENG SOC, V51, P799; TRAAS CR, 1987, COMPUTING, V38, P177, DOI 10.1007/BF02240181; TU HK, 1995, COMPUT MED IMAG GRAP, V19, P27, DOI 10.1016/0895-6111(94)00033-6; WANG S, 2005, P AUD VID BAS BIOM P, P91; Weisstein E. W., 2007, MATHWORLD WOLFRAM WE; WEISSTEIN EW, 2007, BOOKS SPHERICAL HARM; WEN Z, 2002, P IEEE INT C IMAGE P, V1, P1185; WOODHOUSE JH, 1984, J GEOPHYS RES, V89, P5953, DOI 10.1029/JB089iB07p05953; Zhang L, 2005, PROC CVPR IEEE, P209	46	8	10	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1673	1678		10.1109/TPAMI.2007.1114	http://dx.doi.org/10.1109/TPAMI.2007.1114			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627055				2022-12-18	WOS:000247965600017
J	Cula, OG; Dana, KJ; Pai, DK; Wang, DS				Cula, Oana G.; Dana, Kristin J.; Pai, Dinesh K.; Wang, Dongsheng			Polarization multiplexing and demultiplexing for appearance-based modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						reflectance; surface reflectance; specular reflectance; body reflectance; diffuse reflectance; polarization; multiplexing; appearance; appearance-based modeling	TEXTURE; REFLECTANCE; COLOR; SKIN	Polarization has been used in numerous prior studies for separating diffuse and specular reflectance components, but in this work we show that it also can be used to separate surface reflectance contributions from individual light sources. Our approach is called polarization multiplexing and it has a significant impact in appearance modeling where the image as a function of illumination direction is needed. Multiple unknown light sources can illuminate the scene simultaneously, and the individual contributions to the overall surface reflectance are estimated. Polarization multiplexing relies on the relationship between the light source direction and the intensity modulation. Inverting this transformation enables the individual intensity contributions to be estimated. In addition to polarization multiplexing, we show that phase histograms from the intensity modulations can be used to estimate scene properties including the number of light sources.	Johnson & Johnson, CPCW, Skillman, NJ 08558 USA; Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA; Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada; Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA	Johnson & Johnson; Johnson & Johnson USA; Rutgers State University New Brunswick; University of British Columbia; Rutgers State University New Brunswick	Cula, OG (corresponding author), Johnson & Johnson, CPCW, 199 Grandview Rd, Skillman, NJ 08558 USA.	oanacula@caip.rutgers.edu; kdana@ece.rutgers.edu; pai@cs.ubc.ca; dswang@cs.rutgers.edu						Cula OG, 2005, INT J COMPUT VISION, V62, P97, DOI 10.1007/s11263-005-4637-2; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; DeBecker G, 1997, ADV EXP MED BIOL, V417, P369; Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855; DONNER C, 2005, P ACM SIGGRAPH, P1208; Hanrahan P., 1993, P 20 ANN C COMPUTER, P165; HARO A, 2001, P EUR WORKSH REND TE, P53; Hawkins Tim, 2004, P 15 EUROGRAPHICS C, P309, DOI [10.2312/EGWR/EGSR04/309-319, DOI 10.2312/EGWR/EGSR04/309-319]; Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319; JENSEN HW, 2003, P ACM SIGGRAPH JUL; KOUDELKA ML, 2003, P 3 INT WORKSH TEXT, P59; Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891; Miyazaki D, 2002, J OPT SOC AM A, V19, P687, DOI 10.1364/JOSAA.19.000687; MIYAZAKI D, 1997, P INT C COMP VIS, P982; Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113; Ng CSL, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P249, DOI 10.1109/CGI.2001.934681; Nishino K, 2001, IEEE T PATTERN ANAL, V23, P1257, DOI 10.1109/34.969116; Rahmann S, 2001, PROC CVPR IEEE, P149; SAITO M, 1999, P IEEE C COMP VIS PA, V1, P381; Schechner Y. Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P814, DOI 10.1109/ICCV.1999.790305; Schechner YY, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P808; Tsumura N, 2003, ACM T GRAPHIC, V22, P770, DOI 10.1145/882262.882344; Vasilescu MAO, 2004, ACM T GRAPHIC, V23, P336, DOI 10.1145/1015706.1015725; WILLIAMS L, 2005, P ACM SIGGRAPH DIG F; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; WOLFF LB, 1990, IEEE T PATTERN ANAL, V12, P1059, DOI 10.1109/34.61705	26	8	8	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					362	367		10.1109/TPAMI.2007.39	http://dx.doi.org/10.1109/TPAMI.2007.39			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV	17170488				2022-12-18	WOS:000242826900016
J	Solem, JE; Aanaes, H; Heyden, A				Solem, Jan Erik; Aanaes, Henrik; Heyden, Anders			Variational surface interpolation from sparse point and normal data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						variational methods; computer vision; level set method; shape from specularities; multiple view stereo; surface interpolation	SHAPE	Many visual cues for surface reconstruction from known views are sparse in nature, e.g., specularities, surface silhouettes, and salient features in an otherwise textureless region. Often, these cues are the only information available to an observer. To allow these constraints to be used either in conjunction with dense constraints such as pixel-wise similarity, or alone, we formulate such constraints in a variational framework. We propose a sparse variational constraint in the level set framework, enforcing a surface to pass through a specific point, and a sparse variational constraint on the surface normal along the observed viewing direction, as is the nature of, e.g., specularities. These constraints are capable of reconstructing surfaces from extremely sparse data. The approach has been applied and validated on the shape from specularities problem.	Malmo Univ Hosp, Sch Technol & Soc, SE-20506 Malmo, Sweden; Tech Univ Denmark, Informat & Math Modelling Dept, DK-2800 Lyngby, Denmark	Lund University; Skane University Hospital; Technical University of Denmark	Solem, JE (corresponding author), Malmo Univ Hosp, Sch Technol & Soc, SE-20506 Malmo, Sweden.	jes@ts.mah.se; haa@imm.dtu.dk; heyden@ts.mah.se		Aanaes, Henrik/0000-0001-7547-4743				Bonfort T, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P591; DERVIEUX A, 1979, APPROXIMATION METHOD, P145; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; HALSTEAD MA, 1996, P ACM SIGGRAPH, P335; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; JIN H, 2004, P C COMP VIS PATT RE; JIN H, 2001, TR010017 U CAL; Museth K, 2002, ACM T GRAPHIC, V21, P330, DOI 10.1145/566570.566585; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osher S., 2002, APPL MATH SCI, V44, P685; Savarese S, 2005, INT J COMPUT VISION, V64, P31, DOI 10.1007/s11263-005-1086-x; SHI Y, 2004, P IEEE INT C AC SPEE, V3, P13; SOLEM JE, 2003, P SCAL SPAC THEOR CO; SOLEM JE, 2005, P 5 INT C SCAL SPAC, P419; SOLEM JE, 2004, P 2 INT S 3D DAT PRO; THORPE JA, 1985, ELEMENTARY TOPICS DI; Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234; Zhao HK, 2000, COMPUT VIS IMAGE UND, V80, P295, DOI 10.1006/cviu.2000.0875	18	8	8	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					181	184		10.1109/TPAMI.2007.250610	http://dx.doi.org/10.1109/TPAMI.2007.250610			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108394				2022-12-18	WOS:000241988300016
J	Ayala, G; Sebastian, R; Diaz, ME; Diaz, E; Zoncu, R; Toomre, D				Ayala, Guillermo; Sebastian, Rafael; Diaz, Maria Elena; Diaz, Ester; Zoncu, Roberto; Toomre, Derek			Analysis of spatially and temporally overlapping events with application to image sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						temporal Boolean model; 3D Boolean models; germ-grain models; coverage processes; functional data analysis; endocytosis; total internal reflection fluorescence microscopy	ENDOCYTOSIS	Counting spatially and temporally overlapping events in image sequences and estimating their shape-size and duration features are important issues in some applications. We propose a stochastic model, a particular case of the nonisotropic 3D Boolean model, for performing this analysis: the temporal Boolean model. Some probabilistic properties are derived and a methodology for parameter estimation from time-lapse image sequences is proposed using an explicit treatment of the temporal dimension. We estimate the mean number of germs per unit area and time, the mean grain size and the duration distribution. A wide simulation study in order to assess the proposed estimators showed promising results. The model was applied on biological image sequences of in-vivo cells in order to estimate new parameters such as the mean number and duration distribution of endocytic events. Our results show that the proposed temporal Boolean model is effective for obtaining information about dynamic processes which exhibit short-lived, but spatially and temporally overlapping events.	Univ Valencia, Dept Estadist & Invest Operat, Burjassot 46100, Spain; Univ Valencia, Dept Comp Sci, E-46100 Burjassot, Spain; Yale Univ, Dept Cell Biol, New Haven, CT 06520 USA	University of Valencia; University of Valencia; Yale University	Ayala, G (corresponding author), Univ Valencia, Dept Estadist & Invest Operat, Avda Vicent Andres Estelles, Burjassot 46100, Spain.	guillermo.ayala@uv.es; rafa.sebastian@uv.es; elena.diaz@uv.es; ester.diaz@uv.es; roberto.zoncu@yale.edu; derek.toomre@yale.edu	Ayala, Guillermo/A-8077-2008; Diaz, Maria Elena/H-5996-2011; Ayala, Guillermo/N-5766-2019; Sebastian, Rafael/E-9386-2011	Ayala, Guillermo/0000-0002-6231-2865; Diaz, Maria Elena/0000-0002-6818-6943; Ayala, Guillermo/0000-0002-6231-2865; Sebastian, Rafael/0000-0001-6746-5740				Cressie N., 2011, STAT SPATIO TEMPORAL; Diggle P., 2014, STAT ANAL SPATIAL SP; DOUSSE O, 2004, P 5 ACM INT S MOB AD; Ehrlich M, 2004, CELL, V118, P591, DOI 10.1016/j.cell.2004.08.017; GOUTSIAS J, 1997, IMA VOLUMES MATH ITS, V97; Grigoryan AM, 2002, P SOC PHOTO-OPT INS, V4667, P170, DOI 10.1117/12.467979; Kaksonen M, 2005, CELL, V123, P305, DOI 10.1016/j.cell.2005.09.024; Law AM, 1991, SIMULATION MODELING; Matheron G., 1975, RANDOM SETS INTEGRAL; Matheron G, 1967, ELEMENTS THEORIE MIL; MOLCHANOV I, 2005, THEORY RANDOM SETS P; Molchanov I., 1997, STAT BOOLEAN MODEL P; MOLCHANOV IS, 1995, ADV APPL PROBAB, V27, P63, DOI 10.2307/1428096; QUENECH JL, 1992, J MICROSC-OXFORD, V168, P3, DOI 10.1111/j.1365-2818.1992.tb03245.x; Ramsay J.O., 1997, FUNCTIONAL DATA ANAL; SCHLADITZ K, 2005, 72 IWTM; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; Stoyan, 1994, FRACTALS RANDOM SHAP, V302; Stoyan D., 1995, STOCHASTIC GEOMETRY; Toomre D, 2001, TRENDS CELL BIOL, V11, P298, DOI 10.1016/S0962-8924(01)02027-X	20	8	8	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2006	28	10					1707	1712		10.1109/TPAMI.2006.199	http://dx.doi.org/10.1109/TPAMI.2006.199			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	071ME	16986551				2022-12-18	WOS:000239605500014
J	Miyazawa, M; Zeng, PF; Iso, N; Hirata, T				Miyazawa, M; Zeng, PF; Iso, N; Hirata, T			A systolic algorithm for Euclidean distance transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Euclidean distance transform; systolic array; hardware algorithm; image processing	LINEAR-TIME ALGORITHM; COMPUTATION; MAPS; MESH	The Euclidean distance transform is one of the fundamental operations in image processing. It has been widely used in computer vision, pattern recognition, morphological filtering, and robotics. This paper proposes a systolic algorithm that computes the Euclidean distance map of an N x N binary image in 3N clocks on 2N(2) processing cells. The algorithm is designed so that the hardware resources are reduced; especially no mulitipliers are used and, thus, it facilitates VLSI implementation.	Brother Ind Ltd, Naka Ku, Nagoya, Aichi, Japan; Donghua Univ, Sch Comp Sci, Shanghai 200051, Peoples R China; Chukyo Univ, Sch Informat Sci & Technol, Chikusa Ku, Nagoya, Aichi, Japan; Nagoya Univ, Grad Sch Informat Sci, Chikusa Ku, Nagoya, Aichi 4648601, Japan	Brother Industries Ltd; Donghua University; Chukyo University; Nagoya University	Miyazawa, M (corresponding author), Brother Ind Ltd, Naka Ku, 3-17-1 Osu, Nagoya, Aichi, Japan.	miyazawa@nuee.nagoya-u.ac.jp; zengpf@ieee.org; fmiso@nuee.nagoya-u.ac.jp; hirata@is.nagoya-u.ac.jp						BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; BRUE H, 1995, IEEE T PATTERN ANAL, V17, P529; CHEN L, 1995, J VLSI SIGNAL PROC, V10, P169, DOI 10.1007/BF02407034; CHEN L, 1994, INFORM PROCESS LETT, V51, P25, DOI 10.1016/0020-0190(94)00062-X; CHEN L, 1995, PARALLEL COMPUT, V21, P841, DOI 10.1016/0167-8191(94)00103-H; Cuisenaire O, 1999, DISTANCE TRANSFORMAT; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; Fujiwara S, 1995, J PHYS IV, V5, P295, DOI 10.1051/jp4:1995735; Hirata T, 1996, INFORM PROCESS LETT, V58, P129, DOI 10.1016/0020-0190(96)00049-X; KOLOUNTZAKIS MN, 1992, INFORM PROCESS LETT, V43, P181, DOI 10.1016/0020-0190(92)90197-4; Lee YH, 1997, COMPUT VIS IMAGE UND, V68, P109, DOI 10.1006/cviu.1997.0539; LEYMARIE F, 1992, CVGIP-IMAG UNDERSTAN, V55, P84, DOI 10.1016/1049-9660(92)90008-Q; Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156; Meijster A, 2000, COMP IMAG VIS, V18, P331; Paglieroni D. W., 1992, Machine Vision and Applications, V5, P47, DOI 10.1007/BF01213529; RAGNEMALM I, 1992, CVGIP-IMAG UNDERSTAN, V56, P399, DOI 10.1016/1049-9660(92)90050-D; ROSENFEL.A, 1966, J ACM, V13, P471; YAMADA H, 1984, P 7 INT C PATT REC, V1, P69	18	8	8	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2006	28	7					1127	1134		10.1109/TPAMI.2006.133	http://dx.doi.org/10.1109/TPAMI.2006.133			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	041AG	16792101				2022-12-18	WOS:000237424400009
J	Staal, J; Kalitzin, SN; Viergever, MA				Staal, J; Kalitzin, SN; Viergever, MA			A trained spin-glass model for grouping of image primitives	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical pattern recognition; spin-glass model; statistical learning; Bayesian grouping	OPTIMIZATION; RELAXATION; CONTOURS; CUTS	A method is presented that uses grouping to improve local classification of image primitives. The grouping process is based upon a spin- glass system, where the image primitives are treated as possessing a spin. The system is subject to an energy functional consisting of a local and a bilocal part, allowing interaction between the image primitives. Instead of defining the state of lowest energy as the grouping result, the mean state of the system is taken. In this way, instabilities caused by multiple minima in the energy are being avoided. The means of the spins are taken as the a posteriori probabilities for the grouping result. In the paper, it is shown how the energy functional can be learned from example data. The energy functional is defined in such a way that, in case of no interactions between the elements, the means of the spins equal the a priori local probabilities. The grouping process enables the fusion of the a priori local and bilocal probabilities into the a posteriori probabilities. The method is illustrated both on grouping of line elements in synthetic images and on vessel detection in retinal fundus images.	Univ Utrecht, Ctr Med, Image Sci Inst, NL-3584 CX Utrecht, Netherlands; Dutch Epilepsy Clin Fdn, NL-2103 SW Heemstede, Netherlands	Utrecht University	Staal, J (corresponding author), Univ Utrecht, Ctr Med, Image Sci Inst, Heidelberglaan 100,E01-335, NL-3584 CX Utrecht, Netherlands.	joes@isi.uu.nl; skalitzin@sein.nl; max@isi.uu.nl	Viergever, Max A/J-1215-2014	Staal, Joes/0000-0002-4410-8318; Kalitzin, Stiliyan/0000-0002-7028-7778				Aarts E., 1989, SIMULATED ANNEALING; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Bishop, 1995, NEURAL NETWORKS PATT; CAPUTO B, 2001, P IEEE WORKSH STAT C; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Eberly D., 1996, RIDGES IMAGE DATA AN; Florack LMJ, 1997, IMAGE STRUCTURE; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Kalitzin SN, 2001, IEEE T PATTERN ANAL, V23, P447, DOI 10.1109/34.922704; KALITZIN SN, 2000, P IEEE INT C IM PROC; KHAN GN, 1992, IMAGE VISION COMPUT, V10, P77, DOI 10.1016/0262-8856(92)90002-K; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MARROQUIN JL, 1989, BIOL CYBERN, V61, P457, DOI 10.1007/BF02414907; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; PERONA P, 1998, P EUR C COMP VIS, V1, P655; Pilu M, 1997, ROBOT AUTON SYST, V21, P107, DOI 10.1016/S0921-8890(97)00010-9; PUN T, 1992, ADV MACHINE VISION S; Robles-Kelly A., 2001, Proceedings of 12th Scandinavian Conference on Image Analysis, P214; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837	30	8	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1172	1182		10.1109/TPAMI.2005.131	http://dx.doi.org/10.1109/TPAMI.2005.131			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013762				2022-12-18	WOS:000229024300014
J	Park, LAF; Palaniswami, M; Ramamohanarao, K				Park, LAF; Palaniswami, M; Ramamohanarao, K			A novel document ranking method using the discrete cosine transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						indexing methods; information search and retrieval; fast fourier transforms	COMPRESSION	We propose a new Spectral text retrieval method using the Discrete Cosine Transform ( DCT). By taking advantage of the properties of the DCT and by employing the fast query and compression techniques found in vector space methods ( VSM), we show that we can process queries as fast as VSM and achieve a much higher precision.	Univ Melbourne, ARC Ctr Percet & Intelligent Machines Complex Env, Parkville, Vic 3010, Australia; Univ Melbourne, Dept Elect & Elect Engn, Parkville, Vic 3010, Australia; Univ Melbourne, ARC Special Res Ctr Ultrabroadband Informat Netwo, Dept Comp Sci & Software Engn, Parkville, Vic 3010, Australia	University of Melbourne; University of Melbourne; University of Melbourne	Park, LAF (corresponding author), Univ Melbourne, ARC Ctr Percet & Intelligent Machines Complex Env, Parkville, Vic 3010, Australia.	lapark@csse.unimelb.edu.au; swami@ee.mu.oz.au; rao@cs.mu.oz.au	Palaniswami, Marimuthu/AAE-2179-2022	KOTAGIRI, RAMAMOHANARAO/0000-0003-3304-9268				AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784; AREF WG, 1995, PROC INT CONF DATA, P147, DOI 10.1109/ICDE.1995.380398; BUCKLEY C, 2000, NIST SPECIAL PUBLICA, P577; GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907; HAMIDI M, 1976, IEEE T ACOUST SPEECH, V24, P428, DOI 10.1109/TASSP.1976.1162839; JAIN AK, 1979, IEEE T PATTERN ANAL, V1, P356, DOI 10.1109/TPAMI.1979.4766944; Moffat A, 1996, ACM T INFORM SYST, V14, P349, DOI 10.1145/237496.237497; *NATL I STAND TECH, 1999, NATL I STAND TECHN S; Park LAF, 2004, IEEE T KNOWL DATA EN, V16, P529, DOI 10.1109/TKDE.2004.1277815; PARK LAF, 2001, PRINCIPLES DATA MINI, P362; ROBERTSON SE, 2000, NIST SPECIAL PUBLICA, P151; Sikora T, 1997, IEEE SIGNAL PROC MAG, V14, P82, DOI 10.1109/79.618010; Vo Ngoc Anh, 2001, SIGIR Forum, P35; WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089; Zobel J., 1998, SIGIR Forum, V32, P18, DOI 10.1145/281250.281256	15	8	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2005	27	1					130	135		10.1109/TPAMI.2005.2	http://dx.doi.org/10.1109/TPAMI.2005.2			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	870BE	15628274				2022-12-18	WOS:000225028200012
J	Rao, NSV; Reister, DB; Barhen, J				Rao, NSV; Reister, DB; Barhen, J			Information fusion methods based on physical laws	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						information fusion; distribution free bounds; covering numbers; sensor fusion; Vapnik-Chervonenkis theory; physical laws; methane hydrates exploration	SENSOR	We consider systems whose parameters satisfy certain easily computable physical laws. Each parameter is directly measured by a number of sensors, or estimated using measurements, or both. The measurement process may introduce both systematic and random errors which may then propagate into the estimates. Furthermore, the actual parameter values are not known since every parameter is measured or estimated, which makes the existing sample-based fusion methods inapplicable. We propose a fusion method for combining the measurements and estimators based on the least violation of physical laws that relate the parameters. Under fairly general smoothness and nonsmoothness conditions on the physical laws, we show the asymptotic convergence of our method and also derive distribution-free performance bounds based on finite samples. For suitable choices of the fuser classes, we show that for each parameter the fused estimate is probabilistically at least as good as its best measurement as well as best estimate. We illustrate the effectiveness of this method for a practical problem of fusing well-log data in methane hydrate exploration.	Oak Ridge Natl Lab, Ctr Engn Sci Adv Res, Div Math & Comp Sci, Oak Ridge, TN 37831 USA	United States Department of Energy (DOE); Oak Ridge National Laboratory	Rao, NSV (corresponding author), Oak Ridge Natl Lab, Ctr Engn Sci Adv Res, Div Math & Comp Sci, Mailstop 6061,Bldg 5600, Oak Ridge, TN 37831 USA.	raons@ornl.gov; reisterdb@ornl.gov; barhenj@ornl.gov	Rao, Nageswara/H-8707-2019	Rao, Nageswara/0000-0002-3408-5941				Anthony M., 1999, NEURAL NETWORK LEARN, V9; Apostol T. M., 1974, MATH ANAL; Billingsley P., 1986, PROBABILITY MEASURE; Dasarathy B.V, 1994, DECISION FUSION; *GEOL SURV CAN, 1999, GEOL SURV CAN B, V544; HAUSSLER D, 1992, INFORM COMPUT, V100, P78, DOI 10.1016/0890-5401(92)90010-D; Kittler J., 2002, MULTIPLE CLASSIFIER; Krzyzak A, 1996, IEEE T NEURAL NETWOR, V7, P475, DOI 10.1109/72.485681; Kvenvolden KA, 1998, GEOL SOC SPEC PUBL, V137, P9, DOI 10.1144/GSL.SP.1998.137.01.02; Mavko G., 1998, ROCK PHYS HDB TOOLS; MIYAIRI M, 1999, GEOLOGICAL SURVEY CA, V544, P281; Pollard David, 1984, CONVERGENCE STOCHAST; Prakasa Rao B. L. S, 1983, NONPARAMETRIC FUNCTI; Rao N. S. V., 1999, Proceedings. 1999 IEEE/SICE/RSJ. International Conference on Multisensor Fusion and Integration for Intelligent Systems. MFI'99 (Cat. No.99TH8480), P1, DOI 10.1109/MFI.1999.815955; Rao N. S. V., 2000, Information Fusion, V1, P35, DOI 10.1016/S1566-2535(00)00004-X; Rao NSV, 1999, NEUROCOMPUTING, V29, P115, DOI 10.1016/S0925-2312(99)00113-7; RAO NSV, 1994, IEEE T SYST MAN CYB, V24, P319, DOI 10.1109/21.281430; Rao NSV, 1999, J FRANKLIN I, V336, P285, DOI 10.1016/S0016-0032(98)00022-2; Rao NSV, 2001, IEEE T PATTERN ANAL, V23, P904, DOI 10.1109/34.946993; RAO NSV, 2002, P INT C INF FUS; RAO NSV, 2001, P WORKSH EST TRACK F, P259; RAO NSV, 2002, MULTISENSOR FUSION; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Varshney P. K., 1997, DISTRIBUTED DETECTIO	26	8	8	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2005	27	1					66	77		10.1109/TPAMI.2005.12	http://dx.doi.org/10.1109/TPAMI.2005.12			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	870BE	15628269				2022-12-18	WOS:000225028200007
J	Wu, YH; Hu, ZY				Wu, YH; Hu, ZY			The invariant representations of a quadric cone and a twisted cubic	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automated theorem proving; computer vision; invariant representation; quadric cone; twisted cubic		Up to now, the shortest invariant representation of a quadric has 138 summands and there has been no invariant representation of a twisted cubic in 3D projective space, which limit to some extent the applications of invariants in 3D space. In this paper, we give a very short invariant representation of a quadric cone, a special quadric, which has only two summands similar to the invariant representation of a planar conic, and give a short invariant representation of a twisted cubic. Then, a completely linear algorithm for generating the parametric equations of a twisted cubic is provided also. Finally, we exemplify some applications of our proposed invariant representations in the fields of computer vision and automated geometric theorem proving.	Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Wu, YH (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, POB 2728, Beijing 100080, Peoples R China.	yhwu@nlpr.ia.ac.cn; huzy@nlpr.ia.ac.cn						BUCHANAN T, 1988, COMPUT VISION GRAPH, V42, P130, DOI 10.1016/0734-189X(88)90146-6; Hartley RI, 2000, PROC CVPR IEEE, P480, DOI 10.1109/CVPR.2000.854888; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Kahl F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P184, DOI 10.1109/ICCV.2001.937516; Lei C., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P664; LI HB, 2002, UNPUB J SYMBOLIC COM; LI HB, 2002, J SYMBOLIC COMPUTATI; MAYBANK S, 1993, THEORY RECONSTRUCTIO; MAYBANK S, 1995, P IEEE WORKSH REPR V; MAYBANK SJ, 1995, PROCEEDINGS OF EUROPE-CHINA WORKSHOP ON GEOMETRICAL MODELING & INVARIANTS FOR COMPUTER VISION, P158; Meer P, 1998, INT J COMPUT VISION, V26, P137, DOI 10.1023/A:1007944826230; MUNDY J, 1992, GOMETRIC INVARIANCE; QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34; SCHAFFALITZKY F, 2000, P EUR C COMP VIS, V1, P632; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; STURMFELS B, 1993, ALGORITHM INVARIANT; Turnbull H, 1926, T CAMB PHILOS SOC, V23, P265; WHITE N, 1989, INVARIANT THEORY TAB, V19; WU YH, 2001, THESIS U SYSTEMS SCI	19	8	10	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1329	1332		10.1109/TPAMI.2003.1233907	http://dx.doi.org/10.1109/TPAMI.2003.1233907			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE					2022-12-18	WOS:000185460800013
J	Faber, P				Faber, P			Theoretical framework for relaxation processes in pattern recognition: Application to robust nonparametric contour generalization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						generalization; compatibility function; support function; relaxation operator; significance measure; information theoretic model selection	PROBABILISTIC RELAXATION; SEGMENTATION; FOUNDATIONS; SELECTION; IMAGES; MODEL	While various approaches are suggested in the literature to describe and generalize relaxation processes concerning to several objectives, the wider problem addressed here is to find the best-suited relaxation process for a given assignment problem, or better still, to construct a task-dependent relaxation process. For this, we develop a general framework for the theoretical foundations of relaxation processes in pattern recognition. The resulting structure enables 1) a description of all known relaxation processes in general terms and 2) the design of task-dependent relaxation processes. We show that the well-known standard relaxation formulas verify our approach. Referring to the common problem of generating a generalized description of a contour we demonstrate the applicability of the suggested generalization in detail. Important characteristics of the constructed task-dependent relaxation process are: 1) the independency of the segmentation from any parameters, 2) the invariance to geometric transformations, 3) the simplicity, and 4) efficiency.	Robert Bosch GmbH, Stuttgart, Germany	Bosch	Faber, P (corresponding author), Robert Bosch GmbH, Stuttgart, Germany.	petko.faber@de.bosch.com	Faber, Pamela/K-1687-2014	Faber, Pamela/0000-0003-0581-0005				[Anonymous], 1985, PERCEPTUAL ORG VISUA; Ballard D.H., 1982, COMPUTER VISION; Bonnet N., 2001, P IASTED INT C VIS I, P477; BOROTSCHNIG H, 1998, P 6 INT C FUZZ SYST, P1417; CAUFIELD HJ, 1990, APPL OPTICS, V29, P2600; Christmas WJ, 1996, ELECTRON LETT, V32, P312, DOI 10.1049/el:19960278; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DAVIS LS, 1981, ARTIF INTELL, V17, P245, DOI 10.1016/0004-3702(81)90026-6; Douglas DH, 1973, CARTOGR INT J GEOGR, V10, P112, DOI [10.3138/fm57-6770-u75u-7727, DOI 10.3138/FM57-6770-U75U-7727]; Duda R.O., 1973, J ROYAL STAT SOC SER; FABER P, 2001, EDIINFRR0057 U ED; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GUAN JW, 1993, P IJCAI, P592; HANCOCK ER, 1990, PATTERN RECOGN, V23, P711, DOI 10.1016/0031-3203(90)90094-2; HANCOCK ER, 1994, INT C PATT RECOG, P7, DOI 10.1109/ICPR.1994.576866; HARALICK RM, 1983, COMPUT VISION GRAPH, V22, P388, DOI 10.1016/0734-189X(83)90083-X; HARALICK RM, 1983, IEEE T PATTERN ANAL, V5, P417, DOI 10.1109/TPAMI.1983.4767411; HARALICK RM, 1980, P INT C COL GRAPH IM, V13, P242; HENDERSON TC, 1984, P C COMP VIS GRAPH I, V28, P384; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; KIRBY RL, 1979, 772 U MAR; KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5; KITTLER J, 1993, P 4 INT C COMP VIS, P666; LOHMANN G, 1991, DLRFB9129 DTSCH FORS; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; OGAWA H, 1994, PATTERN RECOGN LETT, V15, P349, DOI 10.1016/0167-8655(94)90083-3; PRICE KE, 1985, IEEE T PATTERN ANAL, V7, P617, DOI 10.1109/TPAMI.1985.4767709; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; Shafer G., 1990, International Journal of Approximate Reasoning, V4, P323, DOI 10.1016/0888-613X(90)90012-Q; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; SMETS P, 1990, IEEE T PATTERN ANAL, V12, P447, DOI 10.1109/34.55104; SOO VW, 1993, J INFORMATION SCI EN, V9, P153; SOUTHWELL RV, 1935, P ROY SOC LOND A MAT, V151, P56; Stoddart AJ, 1998, J MATH IMAGING VIS, V9, P29, DOI 10.1023/A:1008218126123; Temple G, 1939, PROC R SOC LON SER-A, V169, P0476, DOI 10.1098/rspa.1939.0012; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; VOSSELMANN G, 1992, RELATIONAL MATCHING; Wang Z., 1992, FUZZY MEASURE THEORY; WINKLER G., 1995, IMAGE ANAL RANDOM FI; WU QX, 1995, IEEE T PATTERN ANAL, V17, P843, DOI 10.1109/34.406650; WUENSCHER DM, 1991, IEEE T PATTERN ANAL, V13, P41; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P117, DOI 10.1109/TPAMI.1981.4767069	45	8	8	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2003	25	8					1021	1027		10.1109/TPAMI.2003.1217606	http://dx.doi.org/10.1109/TPAMI.2003.1217606			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	702XJ					2022-12-18	WOS:000184249800008
J	Luo, JB; Etz, SP; Gray, RT; Singhal, A				Luo, JB; Etz, SP; Gray, RT; Singhal, A			Normalized Kemeny and Snell distance: A novel metric for quantitative evaluation of rank-order similarity of images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image similarity; rank ordering; spatial layout; Kemeny and Snell distance		There are needs for evaluating rank order-based similarity between images. Region importance maps from image understanding algorithms or human observer studies are ordered rankings of the pixel locations. We address three problems with Kemeny and Snell's distance (d(KS)) an existing measure from ordinal ranking theory, when applied to images: its high-computational cost, its bias in favor of images with sparse histograms, and its image-size dependent range of values. We present a novel computationally efficient algorithm for computing d(KS) between two images and we derive a normalized form (d) over cap (KS) with no bias whose range is independent of image size. For evaluating similarity between images that can be considered as ordered rankings of pixels, (d) over cap (KS) is subjectively superior to cross correlation.	Eastman Kodak Co, Imaging Sci Technol Lab, Imaging Mat & Media R&D, Rochester, NY 14650 USA; Acterna Corp, Bradenton, FL 34203 USA	Eastman Kodak	Luo, JB (corresponding author), Eastman Kodak Co, Imaging Sci Technol Lab, Imaging Mat & Media R&D, Rochester, NY 14650 USA.		Luo, Jiebo/AAI-7549-2020	Luo, Jiebo/0000-0002-4516-9729				COOK WD, 1992, ORDINAL INFORMATION; ETZ S, 2000, HUMAN VISION ELECT I; Kemeny J., 1978, MATH MODELS SOCIAL S; LUO J, 2000, P IEEE INT C COMP VI; LUO J, 2000, P IEEE INT C IMAG PR; MARICHAL X, 1996, P IEEE INT C IM PROC; Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520; ZHAO J, 1996, P INT S SIGN PROC IT	8	8	8	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2002	24	8					1147	1151		10.1109/TPAMI.2002.1023811	http://dx.doi.org/10.1109/TPAMI.2002.1023811			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	578JY					2022-12-18	WOS:000177115100013
J	Hashimoto, RF; Barrera, J				Hashimoto, RF; Barrera, J			A note on Park and Chin's algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						simply connected set; structuring element; decomposition; Minkowski addition	MORPHOLOGICAL STRUCTURING ELEMENTS; DECOMPOSITION	A finite subset of Z(2) is called a structuring element. A decomposition of a structuring element A is a sequence of subsets of the elementary square (i.e., the 3 x 3 square centered at the origin) such that the Minkowski addition of them is equal to A. Park and Chin [1] developed an algorithm for finding the optimal decomposition of simply connected structuring elements (i.e., 8-connected structuring elements that contain no holes), imposing the restriction that all subsets in this decomposition are also simply connected. In this paper, we show that there exist infinite families of simply connected structuring elements that have decompositions but are not decomposable according to Park and Chin's definition.	Univ Sao Paulo, Inst Matemat & Estatist, Dept Ciencia Computacaao, BR-05508900 Sao Paulo, Brazil; Texas A&M Univ, Natl Genome Res Inst, College Stn, TX 77840 USA	Universidade de Sao Paulo; Texas A&M University System; Texas A&M University College Station	Hashimoto, RF (corresponding author), Univ Sao Paulo, Inst Matemat & Estatist, Dept Ciencia Computacaao, Rua do Matao 1010, BR-05508900 Sao Paulo, Brazil.		Hashimoto, Ronaldo F/B-6544-2013	Hashimoto, Ronaldo F/0000-0002-6399-8790				Anelli G, 1998, IEEE T PATTERN ANAL, V20, P217, DOI 10.1109/34.659943; Hashimoto RF, 2000, J MATH IMAGING VIS, V13, P17, DOI 10.1023/A:1008373522375; Heijmans H., 1994, MORPHOLOGICAL IMAGE; Kanungo T., 1992, Journal of Mathematical Imaging and Vision, V2, P51, DOI 10.1007/BF00123881; PARK HH, 1995, ETRI J, V17, P1; PARKMAN R, 1994, AM J PEDIAT HEMATOL, V16, P3; RICHARDSON CH, 1991, IEEE T PATTERN ANAL, V13, P365, DOI 10.1109/34.88571; SCHRIJVER A, 1986, WILEYINTERSCIENCE SE; SERRA I, 1982, IMAGE ANAL MATH MORP; XU JN, 1991, IEEE T PATTERN ANAL, V13, P153, DOI 10.1109/34.67644; ZHUANG XH, 1986, COMPUT VISION GRAPH, V35, P370, DOI 10.1016/0734-189X(86)90006-X; [No title captured]	12	8	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2002	24	1					139	144		10.1109/34.982891	http://dx.doi.org/10.1109/34.982891			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	506FZ					2022-12-18	WOS:000172960300011
J	Omachi, S; Inoue, M; Aso, H				Omachi, S; Inoue, M; Aso, H			Structure extraction from decorated characters using multiscale images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						character recognition; OCR; decorated character; structure extraction	RECOGNITION; MODELS	Decorated characters are widely used in various documents. Practical optical character reader is required to deal with not only common fonts but also complex designed fonts. However, since the appearances of decorated characters are complicated, most general character recognition systems cannot give good performances on decorated characters. In this paper. an algorithm that can extract character's essential structure from a decorated character is proposed. This algorithm is applied in preprocessing of character recognition. The proposed algorithm consists of three procedures: global structure extraction, interpolation of structure, and smoothing. By using multiscale images, topographical features, such as ridges and ravines are detected for structure extraction. Ridges are used for extracting global structure and ravines are used for interpolation. Experimental results show character structures are clearly extracted from very complex decorated characters.	Tohoku Univ, Dept Elect Commun, Grad Sch Engn, Aoba Ku, Sendai, Miyagi 9808579, Japan; Hitachi Software Engn Co Ltd, Dev Div, Naka Ku, Yokohama, Kanagawa 2318475, Japan	Tohoku University; Hitachi Limited	Omachi, S (corresponding author), Tohoku Univ, Dept Elect Commun, Grad Sch Engn, Aoba Ku, Aoba 05, Sendai, Miyagi 9808579, Japan.	machi.@aso.ecei.tohoku.ac.jp; m-inoue@cap.hitachi-sk.co.jp; aso@ecei.tohoku.ac.jp		Omachi, Shinichiro/0000-0001-7706-9995				Cheng FH, 1998, PATTERN RECOGN, V31, P401, DOI 10.1016/S0031-3203(97)00053-8; Chou TR, 1997, PROC INT CONF DOC, P608, DOI 10.1109/ICDAR.1997.620575; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; HILDEBRANDT TH, 1993, PATTERN RECOGN, V26, P205, DOI 10.1016/0031-3203(93)90030-Z; Hobby JD, 1997, PROC INT CONF DOC, P394, DOI 10.1109/ICDAR.1997.619877; Hontani H, 1998, INT C PATT RECOG, P1470, DOI 10.1109/ICPR.1998.711983; Impedovo S., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P1, DOI 10.1142/S0218001491000041; Kato N, 1999, IEEE T PATTERN ANAL, V21, P258, DOI 10.1109/34.754617; LIANG S, 1994, CVGIP-GRAPH MODEL IM, V56, P402; Lindeberg T, 1996, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.1996.517113; Lindeberg T., 1994, SCALE SPACE THEORY C; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; Nishida H, 1996, IEEE T PATTERN ANAL, V18, P400, DOI 10.1109/34.491621; Omachi S, 2000, INT C PATT RECOG, P455, DOI 10.1109/ICPR.2000.902956; Ozawa H., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P58, DOI 10.1109/ICDAR.1993.395782; Revow M, 1996, IEEE T PATTERN ANAL, V18, P592, DOI 10.1109/34.506410; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; Rodriguez C, 1998, INT C PATT RECOG, P1101, DOI 10.1109/ICPR.1998.711886; Sawaki M, 1998, IEEE T PATTERN ANAL, V20, P1103, DOI 10.1109/34.722625; Schurmann J, 1996, PATTERN CLASSIFICATI; Tang YY, 1998, IEEE T PATTERN ANAL, V20, P556, DOI 10.1109/34.682186; WAKAHARA T, 1994, IEEE T PATTERN ANAL, V16, P618, DOI 10.1109/34.295906; WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062; YAMAMOTO K, 1982, T IEICE D, V65, P1167	24	8	8	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2001	23	3					315	322		10.1109/34.910884	http://dx.doi.org/10.1109/34.910884			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407MW					2022-12-18	WOS:000167276200008
J	Sogo, T; Ishiguro, H; Ishida, T				Sogo, T; Ishiguro, H; Ishida, T			Acquisition and propagation of spatial constraints based on qualitative information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						qualitative spatial representation; qualitative observation; spatially classified pair; three point constraint; constraint propagation; map building		In robot navigation, one of the important and fundamental issues is to find positions of landmarks or vision sensors located around the robot. This paper proposes a method for reconstructing qualitative positions of multiple vision sensors from qualitative information observed by the vision sensors, i.e., motion directions of moving objects. In order to directly acquire the qualitative positions of points, the method proposed in this paper iterates the following steps: 1) observing motion directions (left or right) of moving objects with the vision sensors, 2) classifying the vision sensors into spatially classified pairs based on the motion directions, 3) acquiring three point constraints, and 4) propagating the constraints. Compared with the previous methods, which reconstruct the environment structure from quantitative measurements and acquire qualitative representations by abstracting it, this paper focuses on how to acquire qualitative positions of landmarks from low-level, simple, and reliable information (that is, "qualitative"). The method has been evaluated with simulations and also verified with observation errors.	Kyoto Univ, Dept Social Informat, Sakyo Ku, Kyoto 6068501, Japan; Wakayama Univ, Dept Comp & Commun Sci, Wakayama 6408510, Japan	Kyoto University; Wakayama University	Sogo, T (corresponding author), Kyoto Univ, Dept Social Informat, Sakyo Ku, Kyoto 6068501, Japan.	sogo@kuis.kyoto-u.ac.jp; ishiguro@sys.wakayama-u.ac.jp; ishida@i.kyoto-u.ac.jp	Ishida, Toru/AAI-2102-2020; Ishida, Toru/H-5553-2017	Ishida, Toru/0000-0002-0479-4990; Ishida, Toru/0000-0002-0479-4990				ALON N, 1986, J COMB THEORY A, V41, P154, DOI 10.1016/0097-3165(86)90122-6; AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; Dey TK, 1998, DISCRETE COMPUT GEOM, V19, P373, DOI 10.1007/PL00009354; FORBUS KD, 1991, ARTIF INTELL, V51, P417, DOI 10.1016/0004-3702(91)90116-2; FREKSA C, 1992, LECT NOTES COMPUT SC, V639, P162; Ishiguro H, 1997, INT JOINT CONF ARTIF, P36; Ishiguro H., 1998, P INT C INF SYST AN, P433; Isli A, 2000, ARTIF INTELL, V122, P137, DOI 10.1016/S0004-3702(00)00044-8; KIM HK, 1992, RECENT ADV QUALITATI, P137; Kuipers B., 1991, Robotics and Autonomous Systems, V8, P47, DOI 10.1016/0921-8890(91)90014-C; LATECKI L, 1993, P IJCAI 93, P1544; LEVITT TS, 1990, ARTIF INTELL, V44, P305, DOI 10.1016/0004-3702(90)90027-W; Madsen CB, 1998, ROBOT AUTON SYST, V23, P277, DOI 10.1016/S0921-8890(98)00014-1; MATTHIES L, 1987, IEEE T ROBOTIC AUTOM, V3, P239, DOI 10.1109/JRA.1987.1087097; Nagel H., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1174; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SCHLIEDER C, 1995, P INT C SPAT INF THE, P341; Sogo T, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1054; Sogo T., 1999, Approaches to intelligent Agents. Second Pacific Rim International Workshop on Multi-Agents, PRIMA'99. Proceedings (Lecture Notes in Artificial Intelligence Vol.1733), P96; YEAP WK, 1988, ARTIF INTELL, V34, P297, DOI 10.1016/0004-3702(88)90064-1; Yokoo M, 1999, MULTIAGENT SYSTEMS, P165; Yokoo M, 1998, IEEE T KNOWL DATA EN, V10, P673, DOI 10.1109/69.729707	23	8	8	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2001	23	3					268	278		10.1109/34.910879	http://dx.doi.org/10.1109/34.910879			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407MW		Green Published			2022-12-18	WOS:000167276200003
J	Omachi, S; Sun, F; Aso, H				Omachi, S; Sun, F; Aso, H			A noise-adaptive discriminant function and its application to blurred machine-printed Kanji recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						discriminant function; Mahalanobis distance; Bayes classifier; distribution of feature vectors; noise; blurred character recognition	CHARACTERS	Accurate recognition of blurred images is a practical but previously to mostly overlooked problem. in this paper. we quantify the level of noise in blurred images and propose a new modification of discriminant functions that adapts to the lever of noise. Experimental results indicate that the proposed method actually enhances the existing statistical methods and has impressive ability to recognize blurred image patterns.	Tohoku Univ, Grad Sch Engn, Sendai, Miyagi 9808579, Japan; Tohoku Bunka Gakuen Univ, Fac Sci & Technol, Aoba Ku, Sendai, Miyagi 9818551, Japan	Tohoku University	Omachi, S (corresponding author), Tohoku Univ, Grad Sch Engn, Sendai, Miyagi 9808579, Japan.	machi@ecei.tohoku.ac.jp; fan@ait.tbgu.ac.jp; aso@ecei.tohoku.ac.jp		Omachi, Shinichiro/0000-0001-7706-9995				Aso H., 1993, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ76D-II, P2148; Bishop, 1995, NEURAL NETWORKS PATT; CASEY R, 1966, IEEE TRANS ELECTRON, VEC15, P91, DOI 10.1109/PGEC.1966.264379; Chou TR, 1997, PROC INT CONF DOC, P608, DOI 10.1109/ICDAR.1997.620575; Duda R.O., 1973, J ROYAL STAT SOC SER; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; HILDEBRANDT TH, 1993, PATTERN RECOGN, V26, P205, DOI 10.1016/0031-3203(93)90030-Z; Hilditch C.J., 1969, MACH INTELL, P403; Hobby JD, 1997, PROC INT CONF DOC, P394, DOI 10.1109/ICDAR.1997.619877; Kato N., 1996, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ79D-II, P45; KOSAI J, 1998, P M IMAGE RECOGNITIO, V2, P257; KURITA M, 1983, PRL8279 IEICE, P105; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; OJA E, 1983, SUBSPACE METHODS PAT; Omachi S, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P501; OMACHI S, 1999, P 11 SCAND C IM AN S, P793; OMACHI S, 1998, PRMU97226 IEICE, P69; Raudys S, 1998, NEURAL NETWORKS, V11, P283, DOI 10.1016/S0893-6080(97)00135-4; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Rodriguez C, 1998, INT C PATT RECOG, P1101, DOI 10.1109/ICPR.1998.711886; SAITO T, 1985, IEICE T D, V68, P757; Sakai N, 1998, INT C PATT RECOG, P99; Sawa K, 1997, PROC INT CONF DOC, P475, DOI 10.1109/ICDAR.1997.620543; Sawaki M, 1998, INT C PATT RECOG, P1117, DOI 10.1109/ICPR.1998.711890; Sun F, 1996, IEICE T INF SYST, VE79D, P510; SUN N, 1990, P PAC RIM INT C ART, P546; Takeshita T., 1987, Transactions of the Institute of Electronics, Information and Communication Engineers D, VJ70D, P567	27	8	8	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2000	22	3					314	319		10.1109/34.841761	http://dx.doi.org/10.1109/34.841761			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	306EJ					2022-12-18	WOS:000086584100008
J	Yanez-Suarez, O; Azimi-Sadjadi, MR				Yanez-Suarez, O; Azimi-Sadjadi, MR			Unsupervised clustering in hough space for identification of partially occluded objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image analysis; occluded objects; unsupervised clustering SOM network; Hough space	ALGORITHM; RECOGNITION	An automated approach for template-free identification of partially occluded objects is presented. The contour of each relevant object in the analyzed scene is modeled with an approximating polygon whose edges are then projected into the Hough space. A structurally adaptive self-organizing map neural network generates clusters of collinear and/or parallel edges, which are used as the basis for identifying the partially occluded objects within each polygonal approximation. Results on a number of cases under different conditions are provided.	Colorado State Univ, Dept Elect Engn, Ft Collins, CO 80523 USA	Colorado State University	Yanez-Suarez, O (corresponding author), Colorado State Univ, Dept Elect Engn, Ft Collins, CO 80523 USA.			Yanez-Suarez, Oscar/0000-0002-4249-8877				BHANU B, 1987, PATTERN RECOGN, V20, P199, DOI 10.1016/0031-3203(87)90054-9; Bose N.K., 1996, NEURAL NETWORK FUNDA; DECO G, 1997, INFORMATION THEORETI, P7; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DUDA R, 1972, COMM ACM, V15; FAHN CS, 1989, IEEE T PATTERN ANAL, V11; JAIN AK, 1989, FUNDAMENTALS DIGITAL, P362; KOCH MW, 1987, IEEE T PATTERN ANAL, V9, P483, DOI 10.1109/TPAMI.1987.4767936; Kohonen T., 1995, SELF ORG MAPS, V30, DOI 10.1007/978-3-642-97610-0; LEE JSJ, 1987, IEEE T ROBOTIC AUTOM, V3, P142, DOI 10.1109/JRA.1987.1087088; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; SVALBE JD, 1989, IEEE T PATTERN ANAL, V11; ULLMANN JR, 1993, PATTERN RECOGN, V26, P1771, DOI 10.1016/0031-3203(93)90175-V; XIE X, 1993, PATTERN RECOGN, V26, P1235, DOI 10.1016/0031-3203(93)90208-E; YanezSuarez O, 1997, REV PROG Q, V16, P1463; YANEZSUAREZ O, 1997, P INT C NEUR NETW HO, P287; YUAN JX, 1995, PATTERN RECOGN, V28, P635, DOI 10.1016/0031-3203(94)00132-6	17	8	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1999	21	9					946	950		10.1109/34.790436	http://dx.doi.org/10.1109/34.790436			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	234TZ		Green Submitted			2022-12-18	WOS:000082501600012
J	Voss, K; Suesse, H				Voss, K; Suesse, H			A new one-parametric fitting method for planar objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fitting; canonical frame; moments; ellipses; normalization		This paper is an extension of the already published paper by Voss and Suesse [11]. In that paper, we developed a new region-based fitting method using the method of normalization. There we demonstrated the zero-parametric fitting of lines, triangles, parallelograms, circles, and ellipses. In the present paper, we discuss this normalization idea for fitting of closed regions using circular segments, elliptical segments, and super-ellipses. As features, we use the area-based low order moments. We show that we have to solve only one-dimensional optimization problems in these cases.	Univ Jena, Dept Comp Sci, D-07743 Jena, Germany	Friedrich Schiller University of Jena	Voss, K (corresponding author), Univ Jena, Dept Comp Sci, D-07743 Jena, Germany.	nkv@uni-jena.de; nbs@uni-jena.de						BROOKSTEIN F, 1979, COMPUTERS GRAPHICS I, V9, P56; Fitzgibbon A. W., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P253, DOI 10.1109/ICPR.1996.546029; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P987; HAALICK RM, 1993, COMPUTER ROBOT VISIO, V1; KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P320, DOI 10.1109/34.276132; Kanazawa Y, 1996, IEICE T INF SYST, VE79D, P1323; KAPUR D, 1992, ARTIF INT, P252; ROSIN PL, 1993, PATTERN RECOGN LETT, V14, P799, DOI 10.1016/0167-8655(93)90062-I; Rothe I, 1996, IEEE T PATTERN ANAL, V18, P366, DOI 10.1109/34.491618; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; Voss K, 1997, IEEE T PATTERN ANAL, V19, P80, DOI 10.1109/34.566815; WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536	12	8	9	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1999	21	7					646	651		10.1109/34.777376	http://dx.doi.org/10.1109/34.777376			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	216YT					2022-12-18	WOS:000081472600008
J	Chung, YW; Prasanna, VK				Chung, YW; Prasanna, VK			Parallelizing image feature extraction on coarse-grain machines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing; parallel algorithms; message-passing machines; MIMD machines; parallel implementations	ALGORITHM	In this paper, we present a fast parallel algorithm for feature extraction on coarse-grain MIMD machines. By maintaining algorithmic threads at each node, our algorithm enhances processor utilization and obtains large speed-ups. Our implementations show that, given a 1,024 x 1,024 image, speed-ups of 27.6 and 56.0 on a 32-node SP2 and a 64-node T3D can be achieved.	Elect & Telecommun Res Inst, Performance Evaluat Team, Taejon 305606, South Korea; Univ So Calif, Dept EE Syst, EEB 200C, Los Angeles, CA 90089 USA	Electronics & Telecommunications Research Institute - Korea (ETRI); University of Southern California	Chung, YW (corresponding author), Elect & Telecommun Res Inst, Performance Evaluat Team, Taejon 305606, South Korea.							Agha G. A, 1985, ACTORS MODEL CONCURR; BADER D, 1994, PARALLEL ALGORITHMS; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; CHOUDHARY A, 1994, J PARALLEL DISTR COM, V20, P78, DOI 10.1006/jpdc.1994.1007; CHUNG Y, 1997, UNPUB PARALLEL ALGOR; CHUNG Y, 1995, P C COMP ARCH MACH P, P294; COPTY N, 1994, J PARALLEL DISTR COM, V21, P160, DOI 10.1006/jpdc.1994.1049; Foster I, 1995, DESIGNING BUILDING P; Fox G.C., 1988, SOLVING PROBLEMS CON; GEROGIANNIS D, 1993, IEEE T PARALL DISTR, V4, P994, DOI 10.1109/71.243527; Huertas A., 1993, P IM UND WORKSH, P253; LIN C, 1995, P WORKSH SOLV IRR PR, P35; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; PRASANNA V, 1991, PARALLEL ARCHITECTUR; ROBERGE J, 1985, COMPUT VISION GRAPH, V29, P168, DOI 10.1016/0734-189X(85)90117-3; YANG T, 1993, PARALLEL COMPUT, V19, P1321, DOI 10.1016/0167-8191(93)90079-Z	16	8	8	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1998	20	12					1389	1394		10.1109/34.735814	http://dx.doi.org/10.1109/34.735814			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	147QV					2022-12-18	WOS:000077578300013
J	Bischoff, WF; Caelli, T				Bischoff, WF; Caelli, T			Scene understanding by rule evaluation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						conditional rule generation; machine learning; object recognition; scene understanding; visual learning	RECOGNITION	We consider how machine learning can be used to help solve the problem of identifying objects or structures composed of parts in complex scenes. We first discuss a conditional rule generation technique (CRG) that is designed to describe structures using part attributes and their relations. We then show how the resultant rules can be used for region labeling and examine constraint propagation techniques for improving rule-based object classification.	CURTIN UNIV TECHNOL,SCH COMP,GPO BOX U1987,PERTH,WA 6001,AUSTRALIA	Curtin University	Bischoff, WF (corresponding author), UNIV ALBERTA,DEPT PSYCHOL,EDMONTON,AB T6G 2E9,CANADA.			Caelli, Terry/0000-0001-9281-2556; Bischof, Walter/0000-0001-5508-0421				[Anonymous], 1985, PERCEPTUAL ORG VISUA; [Anonymous], 1992, INDUCTIVE LOGIC PROG; BISCHOF WF, IN PRESS IEEE T SYST; CAELLI T, 1994, PATTERN RECOGN, V27, P185, DOI 10.1016/0031-3203(94)90053-1; CAELLI T, 1997, P 3 INT C VIS FORM I; FLYNN PJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P119, DOI 10.1016/1049-9660(92)90012-R; Grimson W. E. L., 1990, OBJECT RECOGNITION C; HANSEN C, 1989, IEEE T PATTERN ANAL, V11, P1181, DOI 10.1109/34.42856; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; TSAI FCD, 1994, PATTERN RECOGN, V27, P377, DOI 10.1016/0031-3203(94)90115-5	12	8	8	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1284	1288		10.1109/34.632987	http://dx.doi.org/10.1109/34.632987			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585					2022-12-18	WOS:A1997YG58500009
J	Dunmur, AP; Titterington, DM				Dunmur, AP; Titterington, DM			Computational Bayesian analysis of hidden Markov mesh models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian inference; Gibbs sampling; hidden Markov Mesh random field; Markov chain Monte Carlo	DISTRIBUTIONS; RESTORATION; IMAGES; CHAINS	Versions of the Gibbs Sampler are derived for the analysis of data from the hidden Markov Mesh random fields sometimes used in image analysis. This provides a numerical approach to the otherwise intractable Bayesian analysis of these problems. Detailed formulation is provided for particular examples based on Devijver's [4] Markov Mesh model, and the BUGS [20] package is used to do the computations. Theoretical aspects are discussed and a numerical study, based on image analysis, is reported.			Dunmur, AP (corresponding author), UNIV GLASGOW, DEPT STAT, GLASGOW G12 8QQ, LANARK, SCOTLAND.							ABEND K, 1965, IEEE T INFORM THEORY, V11, P538, DOI 10.1109/TIT.1965.1053827; BESAG J, 1995, STAT SCI, V10, P3, DOI 10.1214/ss/1177010123; BEST N, 1995, CODA MANUAL VERSION; DEVIJVER PA, 1988, LECT NOTES COMPUT SC, V301, P131; DIEBOLT J, 1994, J ROY STAT SOC B MET, V56, P363; DUNMER AP, 1996, 9616 U GLASG DEP STA; DUNMUR AP, 1996, 962 U GLASG DEP STAT; FRIGESSI A, 1993, J R STAT SOC B, V55, P205; GELFAND AE, 1990, J AM STAT ASSOC, V85, P398, DOI 10.2307/2289776; GELFAND AE, 1990, J AM STAT ASSOC, V85, P972, DOI 10.2307/2289594; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GILKS WR, 1986, PRACTICAL MRKOV CHAI; GRAY AJ, 1994, IEEE T PATTERN ANAL, V16, P507, DOI 10.1109/34.291447; HEIKKINEN J, 1994, APPL STAT-J ROY ST C, V43, P569, DOI 10.2307/2986258; HIGDON DM, 1996, FULLY BAYESIAN ESTIM; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; QIAN W, 1991, SIGNAL PROCESS, V22, P313, DOI 10.1016/0165-1684(91)90018-E; ROBERT CP, 1993, STAT PROBABIL LETT, V16, P77, DOI 10.1016/0167-7152(93)90127-5; RYDEN T, 1998, IN PRESS J COMPUTATI; Spiegelhalter D.J., 1995, BUGS BAYESIAN INFERE; Thomas A, 1992, BAYESIAN STATISTICS, P837; TIERNEY L, 1994, ANN STAT, V22, P1701, DOI 10.1214/aos/1176325750; Weir IS, 1997, J AM STAT ASSOC, V92, P49, DOI 10.2307/2291449; Whittaker J., 1990, GRAPHICAL MODELS APP	24	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1296	1300		10.1109/34.632989	http://dx.doi.org/10.1109/34.632989			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585					2022-12-18	WOS:A1997YG58500011
J	Priebe, CE; Marchette, DJ; Rogers, GW				Priebe, CE; Marchette, DJ; Rogers, GW			Segmentation of random fields via borrowed strength density estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mixture model; profile likelihood; image analysis; digital mammography	CLASSIFICATION; ALGORITHM; TISSUE	In many applications, spatial observations must be segmented into homogeneous regions and the number, positions, and shapes of the regions are unknown a priori. information about the underlying probability distributions for observations in the various regions can be useful in such a procedure, but these distributions are often unknown. Furthermore, while there may be a large number of observations overall, the anticipated regions of interest maybe small with few observations from the individual regions. This paper presents a technique designed to address these difficulties. A simple segmentation procedure can be obtained as a clustering of the disjoint subregions obtained through an initial low-level partitioning procedure. Clustering of these subregions based upon a similarity matrix derived from estimates of their marginal probability density functions yields the resultant segmentation. It is shown that this segmentation is improved through the use of a ''borrowed strength'' density estimation procedure wherein potential similarities between the density functions for the subregions are exploited. The borrowed strength technique is described and the performance of segmentation based on these estimates is investigated through an example from statistical image analysis.	USN, CTR SURFACE WARFARE, DAHLGREN, VA 22448 USA	United States Department of Defense; United States Navy	Priebe, CE (corresponding author), JOHNS HOPKINS UNIV, DEPT MATH SCI, BALTIMORE, MD 21218 USA.		Priebe, Carey E./A-3305-2010					COX DR, 1987, J ROY STAT SOC B MET, V49, P1; Cressie N., 2011, STAT SPATIO TEMPORAL; Everitt B., 1981, FINITE MIXTURE DISTR, P143; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; HSIAO JY, 1989, IEEE T PATTERN ANAL, V11, P1279, DOI 10.1109/34.41366; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; Jain R., 1995, MACHINE VISION; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; MILLER P, 1992, IMAGE VISION COMPUT, V10, P277, DOI 10.1016/0262-8856(92)90042-2; Priebe CE, 1996, J AM STAT ASSOC, V91, P1497, DOI 10.2307/2291575; PRIEBE CE, 1994, CANCER LETT, V77, P183, DOI 10.1016/0304-3835(94)90101-5; PRIEBE CE, 1994, J AM STAT ASSOC, V89, P796; Priebe CE, 1997, J STAT PLAN INFER, V59, P45, DOI 10.1016/S0378-3758(96)00095-X; PRIEBE CE, 1996, DIGITAL MAMMOGRAPHY; PRIEBE CE, 1996, 547 J HOPK U DEP MAT; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Serra J, 1982, IMAGE ANAL MATH MORP; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344	19	8	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					494	499		10.1109/34.589209	http://dx.doi.org/10.1109/34.589209			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163		Green Published			2022-12-18	WOS:A1997XB16300008
J	Zmuda, MA; Tamburino, LA				Zmuda, MA; Tamburino, LA			Efficient algorithms for the soft: Morphological operators	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mathematical morphology; soft morphology; image processing algorithms; efficient algorithms		This correspondence presents two soft morphological algorithms that process multiple images simultaneously. The first algorithm performs best when the structuring elements contain less than 19 points; whereas, the second algorithm should be used for larger structuring elements. Theoretical and experimental analyses show these algorithms are faster than the conventional algorithm.	USAF,WRIGHT LAB,AACA,WRIGHT PATTERSON AFB,OH 45433	United States Department of Defense; United States Air Force; US Air Force Research Laboratory	Zmuda, MA (corresponding author), UMI,3155 RES BLVD,KETTERING,OH 45420, USA.							Brassard G., 1988, ALGORITHMICS; Dougherty E. R., 1992, INTRO MORPHOLOGICAL; Graham R.L., 1989, CONCRETE MATH; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; KOSKINEN L, 1991, SPIE IMAGE ALGEBRA M, V2, P262; PRESTON K, 1983, IEEE T ACOUST SPEECH, V31, P861, DOI 10.1109/TASSP.1983.1164148; Sedgewick R., 1983, ALGORITHMS; Serra J, 1982, IMAGE ANAL MATH MORP; WILSON S, 1989, IEEE T SYST MAN CYB, P1636; ZMUDA Z, 1991, SPIE DATA STRUCTURES, P183	10	8	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1996	18	11					1142	1147		10.1109/34.544086	http://dx.doi.org/10.1109/34.544086			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VU159					2022-12-18	WOS:A1996VU15900012
J	Picard, RW; Pentland, AP				Picard, RW; Pentland, AP			Introduction to the special section on digital libraries: Representation and retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material											Picard, RW (corresponding author), MIT, MEDIA LAB, CAMBRIDGE, MA 02139 USA.		Picard, Rosalind/A-5095-2009	Picard, Rosalind/0000-0002-5661-0022				MINKA TP, 1996, IN PRESS PATTERN REC; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; Pentland A., 1996, INT J COMPUTER VISIO, V18; ZHANG HJ, 1994, VIDEO DATABASE SYSTE	4	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1996	18	8					769	770		10.1109/TPAMI.1996.531797	http://dx.doi.org/10.1109/TPAMI.1996.531797			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VE318					2022-12-18	WOS:A1996VE31800001
J	Bogen, DK; Rahdert, DA				Bogen, DK; Rahdert, DA			A strain energy approach to regularization in displacement field fits of elastically deforming bodies	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						smoothing; smoothness; regularization; strain; constraints; deformation; energy; hyperelasticity; reconstruction; elasticity		Current methods for regularizing displacement fields in deformation-fitting problems are sensitive to rotation. We propose a rotation-insensitive regularization functional which is the true strain energy for a rubberlike material. The deformation-fitting problem is solved iteratively using successive approximations of the body's rotation, which may be nonuniform.	UNIV PENN,DEPT MECH ENGN & APPL MECH,PHILADELPHIA,PA 19104	University of Pennsylvania	Bogen, DK (corresponding author), UNIV PENN,DEPT BIOENGN,220 S 33RD ST,PHILADELPHIA,PA 19104, USA.							Bookstein F. L., 1989, IEEE T PATTERN ANAL, V11; GRIMSON WEL, 1983, COMPUTER VISION GRAP, V22; LOVE AEH, 1944, TREATISE MATH THEORY, P499; Spencer A. J. M., 1980, CONTINUUM MECH; SZELISKI R, 1990, IEEE T PATTERN ANAL, V12; Terzopoulos D., 1988, ARTIFICIAL INTELLIGE, V36; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8; Tikhonov A., 1977, SOLUTIONS ILL POSED; YOUNG AA, 1992, IEEE T BIOMEDICAL EN, V39	9	8	8	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					629	635		10.1109/34.506413	http://dx.doi.org/10.1109/34.506413			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UR254					2022-12-18	WOS:A1996UR25400006
J	Nishida, H				Nishida, H			Automatic construction of structural models incorporating discontinuous transformations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						character recognition; handwriting recognition; learning; shape analysis; shape transformation; structural model	RECOGNITION	We present an approach to automatic construction of structural models incorporating discontinuous transformations, with emphasis on application to unconstrained handwritten character recognition. We consider this problem as constructing inductively, from the data set, some shape descriptions that tolerate certain types of shape transformations. The approach is based on the exploration of complete, systematic, high-level models on the effects of the transformations, and the generalization process is controlled and supported by the high-level transformation models. An analysis of the a priori effects of commonly occurring discontinuous transformations is carried out completely and systematically, leading to a small, tractable number of distinct cases. Based on this analysis. an algorithm for the inference of super-classes under these transformations is designed. Furthermore, through examples and experiments, we show that the proposed algorithm can generalize unconstrained handwritten characters into a small number of classes, and that one class can represent various deformed patterns.			Nishida, H (corresponding author), RICOH INFORMAT & COMMUN, RES & DEV, LAB 452, KOHOKU KU, 3-2-3 SHIN YOKOHAMA, YOKOHAMA, KANAGAWA 222, JAPAN.							BAIRD HS, 1988, COMPUT VISION GRAPH, V42, P318, DOI 10.1016/S0734-189X(88)80042-2; CAMILLERAP J, 1992, PIXELS FEATURES FRON, P273; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; CONNELL JH, 1987, ARTIF INTELL, V31, P159, DOI 10.1016/0004-3702(87)90018-X; DIETTERICH TG, 1983, MACHINE LEARNING; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; LAM L, 1988, PATTERN RECOGN, V21, P19, DOI 10.1016/0031-3203(88)90068-4; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; NISHIDA H, 1992, IEEE T PATTERN ANAL, V14, P516, DOI 10.1109/34.134057; NISHIDA H, 1995, PATTERN RECOGN, V28, P1045, DOI 10.1016/0031-3203(94)00177-N; NISHIDA H, 1993, IEEE T PATTERN ANAL, V15, P1298, DOI 10.1109/34.250847; NISHIDA H, 1995, IEEE T PATTERN ANAL, V17, P315, DOI 10.1109/34.368198; NISHIDA H, 1995, PATTERN RECOGN LETT, V16, P1213, DOI 10.1016/0167-8655(95)00071-N; NISHIDA H, 1995, PATTERN RECOGN, V28, P1611, DOI 10.1016/0031-3203(94)00025-H; NISHIDA H, 1995, COMPUT VIS IMAGE UND, V62, P78, DOI 10.1006/cviu.1995.1043; NISHIDA H, IN PRESS COMPUTER VI; NISHIDA H, 1996, GRAPHICAL MODELS IMA, V58; Pavlidis T., 1977, STRUCTURAL PATTERN R; Poston T., 2014, CATASTROPHE THEORY I; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; SEALES WB, 1995, COMPUT VIS IMAGE UND, V61, P308, DOI 10.1006/cviu.1995.1025; SENGUPTA K, 1995, IEEE T PATTERN ANAL, V17, P321, DOI 10.1109/34.385984; SHAPIRO LG, 1982, IEEE T PATTERN ANAL, V4, P595, DOI 10.1109/TPAMI.1982.4767312; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; Suzuki T., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P1055, DOI 10.1142/S0218001493000534; Thom R., 1977, STABILITE STRUCTUREL; UEDA N, 1993, IEEE T PATTERN ANAL, V15, P337, DOI 10.1109/34.206954; WAKAHARA T, 1992, P IEEE, V80, P1181, DOI 10.1109/5.156478; WINSTON PH, 1980, COMMUN ACM, V23, P689, DOI 10.1145/359038.359042; WINSTON PH, 1975, PSYCHOL COMPUTER VIS, pCH5; YAMAMOTO K, 1980, PATTERN RECOGN, V12, P229, DOI 10.1016/0031-3203(80)90062-X; YAMAMOTO K, 1982, 6TH P INT C PATT REC, P395; YUAN XB, 1995, IEEE T PATTERN ANAL, V17, P307, DOI 10.1109/34.368196; ZHANG SJ, 1993, IEEE T PATTERN ANAL, V15, P531, DOI 10.1109/34.216723	36	8	8	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					400	411		10.1109/34.491621	http://dx.doi.org/10.1109/34.491621			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500005
J	OSMAN, H; FAHMY, MM				OSMAN, H; FAHMY, MM			ON THE DISCRIMINATORY POWER OF ADAPTIVE FEEDFORWARD LAYERED NETWORKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						ADAPTIVE LAYERED NETWORKS; PATTERN CLASSIFICATION; LEAST-MEAN-SQUARE OPTIMIZATION; DISCRIMINANT ANALYSIS; BAYES RISK	CLASSIFIER NETWORKS	This correspondence expands the available theoretical framework that establishes a link between discriminant analysis and adaptive feed-forward layered linear-output networks used as mean-square classifiers. This has the advantages of providing more theoretical justification for the use of these nets in pattern classification and gaining a better insight into their behavior and about their use. We prove that, under reasonable assumptions, minimizing the mean-square error at the network output is equivalent to minimizing the following: 1) the difference between the optimum value of a familiar discriminant criterion and the value of this criterion evaluated in the space spanned by the outputs of the final hidden layer, and 2) the difference between the values of the same discriminant criterion evaluated in desired-output and actual-output subspaces. We also illustrate, under specific constraints, how to solve the following problem: given a feature extraction criterion, how the target coding scheme can be selected such that this criterion is maximized at the output of the network final hidden layer. Other properties for these networks are explored.			OSMAN, H (corresponding author), QUEENS UNIV,DEPT ELECT & COMP ENGN,KINGSTON K7L 3N6,ONTARIO,CANADA.							ASOH H, 1990, P INT JOINT C NEUR N, V3, P211; Devijver P. A., 1973, 1st International Joint Conference on Pattern Recognition, P139; Duda R.O., 1973, J ROYAL STAT SOC SER; FUKUNAGA K, 1977, IEEE T INFORM THEORY, V23, P453, DOI 10.1109/TIT.1977.1055755; FUKUNAGA K, 1978, IEEE T INFORM THEORY, V24, P600, DOI 10.1109/TIT.1978.1055942; FUKUNAGA K, 1980, IEEE T INFORM THEORY, V26, P59, DOI 10.1109/TIT.1980.1056140; FUKUNAGA K, 1990, INTRO STATISTICAL PA; GALLINARI P, 1991, NEURAL NETWORKS, V4, P349, DOI 10.1016/0893-6080(91)90071-C; GALLINARI P, 1988, P IJCNN, V1, P391; GORMAN RP, 1988, IEEE T ACOUST SPEECH, V36, P1135, DOI 10.1109/29.1640; Huang W. Y., 1988, NEURAL INFORMATION P, P387; LEE Y, 1989, NEUR INF PROC SYST N, P168; LIPPMANN RP, 1989, IEEE COMMUN MAG, V27, P47, DOI 10.1109/35.41401; LOWE D, 1991, IEEE T PATTERN ANAL, V13, P355, DOI 10.1109/34.88570; Searle S.R, MATRIX ALGEBRA USEFU; WEBB AR, 1990, NEURAL NETWORKS, V3, P367, DOI 10.1016/0893-6080(90)90019-H; WEE WG, 1968, IEEE T COMPUT, VC 17, P1157, DOI 10.1109/TC.1968.226881	17	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					837	842		10.1109/34.308481	http://dx.doi.org/10.1109/34.308481			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500011
J	SINCLAIR, D; BLAKE, A				SINCLAIR, D; BLAKE, A			ISOPERIMETRIC NORMALIZATION OF PLANAR CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						OBJECT RECOGNITION; PERSPECTIVE PROJECTION; ISOPERIMETRIC PROBLEM; NORMALIZATION	SHAPE	This paper presents an algorithm for transforming closed planar curves into a canonical form, independent of the viewpoint from which the original image of the contour was taken. The transformation that takes the contour to its canonical form is a member of the projective group PGL(2), chosen because PGL(2) contains all possible transformations of a plane curve under central projection onto another plane. The scheme relies on solving computationally an ''isoperimetric'' problem in which a transformation is sought which maximises the area of a curve given unit perimeter. In the case that the transformation is restricted to the affine subgroup there is a unique extremising transformation for any piecewise smooth closed curve. Uniqueness holds, almost always, even for curves that are not closed. In the full projective case, isoperimetric normalization is well-defined only for closed curves. The question of uniqueness is more complex: we have found computational counterexamples for which there is more than one extremal transformation. Numerical algorithms are described and demonstrated both for the affine and the projective cases. Once a canonical curve is obtained, its isoperimetric area can be regarded as an invariant descriptor of shape. Methods for discrimination of nonconvex shapes are already known. Our invariant descriptor is the first example, to our knowledge, of practical discrimination, up to projectivity, of convex, closed curves.			SINCLAIR, D (corresponding author), UNIV OXFORD,DEPT ENGN SCI,ROBOT RES GRP,19 PARKS RD,OXFORD OX1 3PJ,ENGLAND.							ASTROM K, 1993, FUNDAMENTAL DIFFICUL; BLAKE A, 1990, ARTIF INTELL, V45, P323, DOI 10.1016/0004-3702(90)90011-N; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; CARLSSON S, 1992, GEOMETRIC INVARIANCE, P267; FORSYTH DA, 1990, 1ST P EUR C COMP VIS, P427; GRIMSON WEL, 1991, OBJECT RECOGNITION G, V1; Horn B., 1986, ROBOT VISION, P1; HUTTENLOCHER DP, 1990, 1ST P ACM SIAM S DIS, P147; LAMDAN Y, 1988, JUN P CVPR C ANN ARB, P335; ROTHWELL C, 1992, GEOMETRIC INVARIANCE, P398; ROTHWELL C, 1992, 2ND P EUR C COMP VIS, P757; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; SPRINGER CE, 1964, GEOMETRY ANAL PROJEC, V1; Troutman J.L., 1983, VARIATIONAL CALCULUS	14	8	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					769	777		10.1109/34.308471	http://dx.doi.org/10.1109/34.308471			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500001
J	NACKEN, PFM				NACKEN, PFM			OPENINGS CAN INTRODUCE ZERO CROSSINGS IN BOUNDARY CURVATURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter								In a recent paper, Chen and Yan presented a result on zero crossings of boundary curvature under morphological openings. In this correspondence, it is shown, by means of a counter example, that this result is not correct. An analysis of the counter example shows where Chen and Yan go wrong and determines a class of images for which their theorem holds.			NACKEN, PFM (corresponding author), TNO,INST HUMAN FACTORS IZF,KAMPWEG 5,3769 DE SOESTERBERG,NETHERLANDS.							ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464; Serra J, 1982, IMAGE ANAL MATH MORP; Witkin AP, 1983, 8 INT JOINT C ART IN, P1019	5	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					656	658		10.1109/34.295918	http://dx.doi.org/10.1109/34.295918			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200011
J	MAIO, D; RIZZI, S				MAIO, D; RIZZI, S			MAP LEARNING AND CLUSTERING IN AUTONOMOUS SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AUTONOMOUS SYSTEMS; CLUSTERING ALGORITHMS; ENVIRONMENTAL MAPS; LEARNING; MAP EXPLORATION	3 DIMENSIONS; OBJECTS; FIT	Building autonomous systems, self-learning while moving in an unknown environment, finds a variety of challenging applications. This paper presents a new approach, called clustering by discovery, for identification of clusters in a map which is being learned by exploration. The concomitance of exploration and clustering, we argue, is a mandatory feature for an autonomous system, hence the clustering technique we propose is an incremental process performed while the system is learning the map. Clusters supply an abstract description of the environment and can be used to decrease the complexity of the navigational tasks. The environment is viewed as a map of distinctive places which we assume to be sensed and recognized by the system. The presence of distinctive places and the environment scale are the only facts which we assume known a priori to the system. Clustering by discovery is based on a heuristic indicator called scattering, whose increment is minimized at each exploration step compatibly with a connectivity constraint imposed on clusters. Scattering is defined according to a number of functional and structural requirements. Two variants are presented, and their performance is discussed on a sample of maps including a real urban map and some randomly generated ones. In particular, one of the variants shows robust behaviour in terms of independence of the exploration strategy adopted.	UNIV BOLOGNA,CORSO LAUREA SCI INFORMAZ,I-47023 CESENA,ITALY	University of Bologna	MAIO, D (corresponding author), UNIV BOLOGNA,FAC INGN,DEIS,CIOC,CNR,VIALE RISORGIMENTO 2,I-40136 BOLOGNA,ITALY.							CHAUDHURI BB, 1990, PATTERN RECOGN LETT, V11, P571, DOI 10.1016/0167-8655(90)90028-Z; CHAUDHURI BB, 1991, PATTERN RECOGN LETT, V12, P1, DOI 10.1016/0167-8655(91)90021-D; Ciaccia P., 1991, Proceedings. Advanced Computer Technology, Reliable Systems and Applications. 5th Annual European Computer Conference CompEuro '91 (Cat. No.91CH3001-5), P652, DOI 10.1109/CMPEUR.1991.257466; Davis E, 1981, 193 YAL U DEP COMP S, V193; Garey M., 1979, GUIDE NP COMPLETENES; HAASE KW, 1987, ADV ARTIFICIAL INTEL, V2, P111; HOUTSMA MAW, 1990, P ICDT 90 PARIS, P470; JOLION JM, 1991, IEEE T PATTERN ANAL, V13, P791, DOI 10.1109/34.85669; KUIPERS BJ, 1988, P AAAI88 ST PAUL, V2, P774; LENAT DB, 1983, ARTIFICIAL INTELL; MAIO D, 1992, PATTERN RECOGN LETT, V13, P89, DOI 10.1016/0167-8655(92)90038-2; MCDERMOTT D, 1980, 173 YAL U DEP COMP S; NIEMANN H, 1988, PATTERN RECOGN LETT, V7, P67, DOI 10.1016/0167-8655(88)90120-1; Nitzan D., 1985, IEEE Journal of Robotics and Automation, VRA-1, P3, DOI 10.1109/JRA.1985.1086994; RAO NSV, 1989, IEEE T COMPUT, V38, P37; ROSE K, 1990, PATTERN RECOGN LETT, V11, P589, DOI 10.1016/0167-8655(90)90010-Y; Tou JT, 1974, PATTERN RECOGN; WEISBIN CR, 1989, IEEE T COMPUT, V38, P29; YAO FF, 1990, HDB THEORETICAL COMP, VA, P345; Zipser D, 1986, PARALLEL DISTRIBUTED, V2, P432	20	8	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1286	1297		10.1109/34.250846	http://dx.doi.org/10.1109/34.250846			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176					2022-12-18	WOS:A1993MP17600006
J	HALL, RW				HALL, RW			OPTIMALLY SMALL OPERATOR SUPPORTS FOR FULLY PARALLEL THINNING ALGORITHMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CONNECTIVITY PRESERVATION; IMAGE PROCESSING; OPTIMALLY SMALL OPERATOR SUPPORTS; PARALLEL THINNING; REDUCTION OPERATORS; SUPPORT CONSTRAINTS	CONNECTIVITY PRESERVATION; PICTURES	Requirements on the support size and shape are investigated for the class of all adequate fully parallel thinning operators. Eleven pixel supports are shown to be the smallest possible supports, and the possible positions of the support pixels are shown to be well constrained. Constraints on support positions are also demonstrated for operators with supports that are larger than optimal, and a sufficient test for connectivity preservation is reviewed. These results allow algorithm designers looking for small support operators to focus on a relatively small set of acceptable supports.			HALL, RW (corresponding author), UNIV PITTSBURGH,DEPT ELECT ENGN,PITTSBURGH,PA 15261, USA.							ARCELLI C, 1975, ELECTRON LETT, V11, P148, DOI 10.1049/el:19750113; CHIN RT, 1987, COMPUT VISION GRAPH, V40, P30, DOI 10.1016/0734-189X(87)90054-5; DUFF MJB, 1986, CELLULAR LOGIC IMAGE; FOUNTAIN TJ, 1990, MULTIPROCESSOR COMPU; GOKMEN M, 1990, COMPUT VISION GRAPH, V52, P191, DOI 10.1016/0734-189X(90)90054-Y; GUO ZC, 1989, COMMUN ACM, V32, P359, DOI 10.1145/62065.62074; GUO ZC, 1992, CVGIP-IMAG UNDERSTAN, V55, P317, DOI 10.1016/1049-9660(92)90029-3; HALL RW, 1992, TOPOL APPL, V46, P199, DOI 10.1016/0166-8641(92)90015-R; HALL RW, 1989, COMMUN ACM, V32, P124, DOI 10.1145/63238.63248; HALL RW, TRSP9101 U PITTSB DE; HOLT CM, 1987, COMMUN ACM, V30, P156, DOI 10.1145/12527.12531; KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3; ORSENFELD A, 1982, DIGITAL PICTURE PROC, V2; PRESTON K, 1984, MODERN CELULAR AUTOM; RONSE C, 1986, THEOR COMPUT SCI, V43, P31, DOI 10.1016/0304-3975(86)90164-7; RONSE C, 1988, DISCRETE APPL MATH, V21, P67, DOI 10.1016/0166-218X(88)90034-0; ROSENFELD A, 1975, INFORM CONTROL, V29, P286, DOI 10.1016/S0019-9958(75)90448-9; STEFANELLI R, 1971, J ACM, V18, P255, DOI 10.1145/321637.321646	18	8	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1993	15	8					828	833		10.1109/34.236245	http://dx.doi.org/10.1109/34.236245			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR948					2022-12-18	WOS:A1993LR94800009
J	WHITTEN, G				WHITTEN, G			SCALE-SPACE TRACKING AND DEFORMABLE SHEET MODELS FOR COMPUTATIONAL VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTATIONAL VISION; CONSTRAINED OPTIMIZATION; MOTION ANALYSIS; OPTICAL FLOW; REGULARIZATION; SCALE SPACE TRAJECTORY; SMOOTHNESS CONSTRAINT; STEREO CORRESPONDENCE	POSED PROBLEMS	Many problems in computational vision (including stereo correspondence, motion analysis and surface reconstruction) can be solved effectively using a constrained optimization approach, where smoothness is the common constraint. Moreover, these problems can be cast in a variational form that minimizes an energy functional. Unfortunately, standard optimization techniques tend to find only local energy minima. Coarse to fine scale space tracking (where energy minima at reduced resolution are found and successively tracked to higher resolution) has been demonstrated to find solutions of practical value. For smoothness-constrained optimization problems, we show that scale space tracking can be implicitly implemented by appropriately adjusting the smoothness constraint. A useful physical model for controlled smoothness (deformable sheets) provides a natural framework for scale space tracking and addressing many vision problems that can be solved by appealing to a smoothness constraint. Deformable sheets are characterized by a global energy functional, and the smoothness constraint is represented by a linear internal energy term. In analogy to physical sheets, the model sheets are deformed by problem specific external forces and, in turn, impose smoothness on the applied forces. We have related deformable sheet smoothness properties to Gaussian blurring (the common expression of scale) and used this relationship to unify the concepts of scale and smoothness. In our formulation, the smoothness/scale state is controlled by a single parameter in the deformable sheet model. This single parameter control of scale makes it possible to perform scale space tracking by solving the differential equation that describes the trajectory of energy minima through scale space. Further, it permits adaptive scale step size selection based on the local properties of scale space, which allows for much larger steps than would be possible with the conservative step size required by nonadaptive techniques. We show that this process is characterized by a sparse linear system and prove that the associated matrix is positive definite and, consequently, nonsingular. Our analysis also provides for the determination of scale-dependent parameters, which is useful for efficient multiresolution processing. We have applied the deformable sheet model described to different problems in computational vision using real imagery with encouraging results, which are presented here.	FAIRCHILD WESTON SYST INC,ADV DEV GRP,SYOSSET,NY 11791									BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; COURANT R, 1953, METHODS MATH PHYSICS, V1; Gear CW., 1971, NUMERICAL INITIAL VA; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRIMSON WEL, 1981, IMAGES SURFACES; Horn B., 1986, ROBOT VISION, P1; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Marr D., 1982, VISION; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Press WH, 1986, NUMERICAL RECIPES C, V818; STRANG G, INTRO APPLIED MATH; SZELISKI R, 1987, 1ST P INT C COMP VIS; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TERZOPOULOS D, 1987, JAN P SPIE C OPT DIG; Tikhonov A., 1977, SOLUTIONS ILL POSED; WAHBA G, 1990, SERIES APPLIED MATH, V59; WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162	21	8	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1993	15	7					697	706		10.1109/34.221170	http://dx.doi.org/10.1109/34.221170			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LM185					2022-12-18	WOS:A1993LM18500004
J	DANJOU, A; GRANA, M; TORREALDEA, FJ; HERNANDEZ, MC				DANJOU, A; GRANA, M; TORREALDEA, FJ; HERNANDEZ, MC			SOLVING SATISFIABILITY VIA BOLTZMANN MACHINES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						BOLTZMANN MACHINES; SATISFIABILITY; SIMULATED ANNEALING	ALGORITHMS; OPTIMIZATION; LESS	Boltzmann machines (BM's) are proposed as a computational model for the solution of the satisfiability (SAT) problem in the propositional calculus setting. Conditions that guarantee consensus function maxima for configurations of the BM associated with solutions to the satisfaction problem are given. Experimental results that show a linear behavior of BM's solving the satisfiability problem are presented and discussed.			DANJOU, A (corresponding author), UPV, EHU, FAC INFORMAT, SAN SEBASTIAN, SPAIN.		Hernández Gómez, Carmen/S-1239-2018; d'Anjou, Alicia/O-1304-2013; Romay, Manuel M. Graña/L-1341-2014	Romay, Manuel M. Graña/0000-0001-7373-4097; Hernandez Gomez, Carmen/0000-0002-6645-9880				Aarts E., 1988, SIMULATED ANNEALING; AARTS EHL, 1989, EUR J OPER RES, V39, P79, DOI 10.1016/0377-2217(89)90355-X; AARTS EHL, 1991, ALGORITHMICA, V6, P437, DOI 10.1007/BF01759053; AARTS EHL, 1989, PARALLEL COMPUT, V9, P129, DOI 10.1016/0167-8191(89)90124-5; AARTS EHL, 1987, LECT NOTES COMPUT SC, V258, P34; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; [Anonymous], 1987, SIMULATED ANNEALING; DANJOU A, 1991, REV ESP AUTOM INF, V24, P24; DAVIS M, 1960, J ACM, V7, P201, DOI 10.1145/321033.321034; Dowling W. F., 1984, Journal of Logic Programming, V1, P267, DOI 10.1016/0743-1066(84)90014-1; GALLO G, 1989, J LOGIC PROGRAM, V7, P45, DOI 10.1016/0743-1066(89)90009-5; HANSEN P, 1990, COMPUTING, V44, P279, DOI 10.1007/BF02241270; JOHNSON DS, 1989, OPER RES, V37, P865, DOI 10.1287/opre.37.6.865; JOHNSON DS, 1974, J COMPUT SYST SCI, V9, P256, DOI 10.1016/S0022-0000(74)80044-9; KIRPATRICK S, 1983, SCIENCE, V220, P671; LIEBERHERR KJ, 1982, J ALGORITHM, V3, P225, DOI 10.1016/0196-6774(82)90022-0; MONIEN B, 1985, DISCRETE APPL MATH, V10, P287, DOI 10.1016/0166-218X(85)90050-2; PINKAS G, 1990, 1990 P CONN SUMM SCH; PURDOM PW, 1984, IEEE T PATTERN ANAL, V6, P510, DOI 10.1109/TPAMI.1984.4767555; SEJNOWSKI TJ, 1984, NEURAL NETWORKS COMP, P398; VANGELDER A, 1988, INFORM COMPUT, V79, P1, DOI 10.1016/0890-5401(88)90014-4; ZWIETERING PJ, 1990, PARALLEL PROCESSING IN NEURAL SYSTEMS AND COMPUTERS, P277	22	8	8	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					514	521		10.1109/34.211473	http://dx.doi.org/10.1109/34.211473			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470					2022-12-18	WOS:A1993LB47000011
J	LIU, ZQ; RANGAYYAN, RM; FRANK, CB				LIU, ZQ; RANGAYYAN, RM; FRANK, CB			DIRECTIONAL ANALYSIS OF IMAGES IN SCALE SPACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							ZERO CROSSINGS; GAUSSIAN KERNEL; EDGE-DETECTION; CONVOLUTION; EXTRACTION; ACCURACY; MASKS; MODEL; FIELD	In this paper, we propose a computational technique for the directional analysis of piecewise linear patterns in images based on the notion of zero crossings in gradient images. A given image is preprocessed by a sequence of filters that are second derivatives of 2-D Gaussian functions with different scales. This gives a set of zero-crossing maps (the scale space) from which a stability map is generated. Significant linear patterns are detected from measurements on the stability map. Information regarding orientation of the linear patterns in the image and the area covered by the patterns in specific directions is then computed. The performance of the method is illustrated through applications to a simple test image made up of straight bar patterns as well as to scanning electron microscope images of collagen fibrils in rabbit ligaments. The method has significant applications in quantitative analysis of ligament healing and in comparison of treatment methods for ligament injuries.			LIU, ZQ (corresponding author), UNIV CALGARY, DEPT ELECT ENGN, CALGARY T2N 1N4, ALBERTA, CANADA.							ARSENAULT HH, 1974, APPL OPTICS, V13, P1013, DOI 10.1364/AO.13.001013; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; Bezvoda V., 1981, Gerlands Beitraege zur Geophysik, V90, P133; BINFORD T, 1987, FEB P DARPA IM UND W, V1, P18; BISCHOF WF, 1988, J COMPUT VISION GRAP, V42, P192; BRUTON LT, 1985, ADV GEOPHYSICAL DATA, V2, P223; CAELLI TM, 1988, PATTERN RECOGN, V21, P639, DOI 10.1016/0031-3203(88)90036-2; CAELLI TM, 1984, FIGURAL SYNTHESIS; CHAUDHURI S, 1987, IEEE T BIO-MED ENG, V34, P509, DOI 10.1109/TBME.1987.325980; CHAUDHURI S, 1987, 13TH P CAN MED BIOL, P109; CHAUDHURI S, 1987, JUN P SUP S 87 CALG, P5; CHEN JS, 1989, IEEE T PATTERN ANAL, V11, P191, DOI 10.1109/34.16714; CHEN JS, 1987, IEEE T PATTERN ANAL, V9, P584, DOI 10.1109/TPAMI.1987.4767946; CLARK JJ, 1989, IEEE T PATTERN ANAL, V11, P43, DOI 10.1109/34.23112; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; Deriche R., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P434, DOI 10.1109/ICPR.1988.28260; DOBRIN MB, 1965, GEOPHYSICS, V30, P1144, DOI 10.1190/1.1439705; DUVERNOY J, 1981, APPL OPTICS, V20, P136, DOI 10.1364/AO.20.000136; DZIEDZICGOCLAWS.A, 1987, IEEE T PATTERN ANAL, V8, P523; Embree P., 1963, GEOPHYSICS, V28, P948, DOI [10.1190/1.1439310, DOI 10.1190/1.1439310]; FRANK C, 1991, J ORTHOP RES, V9, P219, DOI 10.1002/jor.1100090210; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P121, DOI 10.1109/TPAMI.1985.4767628; Hall E. L., 1979, COMPUTER IMAGE PROCE; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; HUMMEL RA, 1986, IEEE P COMPUT VISION, P204; Ikonomopoulos A., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P87; IKONOMOPOULOS A, 1983, SIGNAL PROCESS, V2, P203; KASS M, 1985, 9TH P INT JOINT C AR, P944; KATZ I, 1985, 8513 U BRIT COL DEP; LIM HS, 1987, FEB P DARPA IM UND W, V2, P644; LIMB JO, 1977, VISION RES, V17, P571, DOI 10.1016/0042-6989(77)90056-6; LIU ZQ, 1991, IEEE T BIO-MED ENG, V38, P580, DOI 10.1109/10.81583; LIU ZQ, 1988, NOV P CAN C EL COMP, P755; LIU ZQ, 1989, JUN P SUP S 89 TOR, P111; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARR D, 1980, MIT558 ART INT LAB M; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; MOORE GK, 1983, PHOTOGRAMM ENG REM S, V49, P641; RANGANATHAN N, 1988, COMPUT VISION GRAPH, V43, P178, DOI 10.1016/0734-189X(88)90060-6; RICHTER J, 1986, BIOL CYBERN, V53, P195, DOI 10.1007/BF00342887; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; ROTEM D, 1986, IEEE T ACOUST SPEECH, V34, P1269, DOI 10.1109/TASSP.1986.1164922; SOTAK GE, 1989, COMPUT VISION GRAPH, V48, P147, DOI 10.1016/S0734-189X(89)80036-2; STEVENS KA, 1978, BIOL CYBERN, V29, P19, DOI 10.1007/BF00365232; Takahashi H., 1981, Seventh International Symposium on Machine Processing of Remotely Sensed Data with Special Emphasis on Range, Forest, and Wetlands Assessment, P103; TREITEL S, 1967, GEOPHYSICS, V32, P789, DOI 10.1190/1.1439889; WITKIN AP, 1983, AUG P INT JOINT C AR, P1019; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]; ZHOU YT, 1989, IEEE T PATTERN ANAL, V11, P84, DOI 10.1109/34.23115; ZUCKER SW, 1985, COMPUT VISION GRAPH, V32, P74, DOI 10.1016/0734-189X(85)90003-9	52	8	8	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1991	13	11					1185	1192		10.1109/34.103277	http://dx.doi.org/10.1109/34.103277			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GN338					2022-12-18	WOS:A1991GN33800006
J	LI, ZC; BUI, TD; SUEN, CY; TANG, YY				LI, ZC; BUI, TD; SUEN, CY; TANG, YY			SPLITTING-SHOOTING METHODS FOR NONLINEAR TRANSFORMATIONS OF DIGITIZED PATTERNS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									CONCORDIA UNIV,DEPT COMP SCI,CTR PATTERN RECOGNIT & MACHINE INTELLIGENCE,MONTREAL H3G 1M8,QUEBEC,CANADA	Concordia University - Canada	LI, ZC (corresponding author), CONCORDIA UNIV,CTR RECH INFORMAT MONTREAL,MONTREAL H3G 1M8,QUEBEC,CANADA.							Burden RL, 1981, NUMERICAL ANAL; Lang S., 1973, CALCULUS SEVERAL VAR; LEE SY, 1987, PATTERN RECOGN, V20, P115, DOI 10.1016/0031-3203(87)90022-7; Strang G., 1973, ANAL FINITE ELEMENT; Tang YY, 1989, COMPUTER TRANSFORMAT; Zienkiewicz OC, 1977, FINITE ELEMENT METHO	6	8	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1990	12	7					671	682		10.1109/34.56210	http://dx.doi.org/10.1109/34.56210			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DK894					2022-12-18	WOS:A1990DK89400007
J	BELL, ZW				BELL, ZW			A BAYESIAN MONTE-CARLO SEGMENTATION METHOD FOR IMAGES DOMINATED BY GAUSSIAN-NOISE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											BELL, ZW (corresponding author), MARTIN MARIETTA ENERGY SYST INC,DIV COMP & TELECOMMUN,OAK RIDGE Y-12 PLANT,OAK RIDGE,TN 37831, USA.		Bell, Zane/ABG-5701-2020	Bell, Zane/0000-0003-1115-8674				BHANU B, 1982, IEEE T PATTERN ANAL, V4, P408, DOI 10.1109/TPAMI.1982.4767273; CHOW CK, 1972, COMPUT BIOMED RES, V5, P388, DOI 10.1016/0010-4809(72)90070-5; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; GEMAN D, 1986, NATO ASI SERIES F, V20, P301; HALL EL, 1971, IEEE T COMPUT, VC 20, P1032, DOI 10.1109/T-C.1971.223399; HALMSHAW R, 1971, IND RADIOGRAPHY TECH, pCH6; HANSEN FR, 1982, COMPUT VISION GRAPH, V20, P101, DOI 10.1016/0146-664X(82)90040-5; HARALICK RM, 1985, P SOC PHOTO-OPT INST, V548, P2; KITTLER J, 1985, COMPUT VISION GRAPH, V30, P125, DOI 10.1016/0734-189X(85)90093-3; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Sadjadi F., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V726, P110, DOI 10.1117/12.937717; WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8	12	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					985	990		10.1109/34.35502	http://dx.doi.org/10.1109/34.35502			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800009
J	WECHSLER, H; ZIMMERMAN, GL				WECHSLER, H; ZIMMERMAN, GL			DISTRIBUTED ASSOCIATIVE MEMORY (DAM) FOR BIN-PICKING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MINNESOTA,DEPT ELECT ENGN,MINNEAPOLIS,MN 55455	University of Minnesota System; University of Minnesota Twin Cities	WECHSLER, H (corresponding author), GEORGE MASON UNIV,SCH INFORMAT TECHNOL & ENGN,FAIRFAX,VA 22030, USA.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; Ballard D.H., 1982, COMPUTER VISION; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P137, DOI 10.1109/TPAMI.1984.4767499; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bolles R. C., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P498; CASASENT D, 1977, P IEEE, V65, P77, DOI 10.1109/PROC.1977.10432; CHAKRAVARTY I, 1982, P SOC PHOTO-OPT INST, V336, P37, DOI 10.1117/12.933609; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; CROWLEY JL, 1984, CMURITR841 CARN MELL; DAVIS LS, 1981, ARTIF INTELL, V17, P245, DOI 10.1016/0004-3702(81)90026-6; DESSIMOZ JD, 1984, IEEE T PATTERN ANAL, V6, P686, DOI 10.1109/TPAMI.1984.4767593; GRIMSON WEL, 1986, TECHNIQUES 3 D MACHI, P113; HORN BKP, 1984, SCI AM           AUG, P100; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KOHONEN T, 1984, SELF ORG ASS MEMORIE; MASSONE L, 1985, COMPUT VISION GRAPH, V30, P169, DOI 10.1016/0734-189X(85)90095-7; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; REITBOECK HJ, 1984, BIOL CYBERN, V51, P113, DOI 10.1007/BF00357924; Roberts L. G., 1965, OPTICAL ELECTRO OPTI; SKLANSKY J, 1978, IEEE T COMPUT, V27, P923, DOI 10.1109/TC.1978.1674971; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; ULLMAN S, 1980, BEHAV BRAIN SCI, V3, P373, DOI 10.1017/S0140525X0000546X; WECHSLER H, 1988, IEEE T PATTERN ANAL, V10, P811, DOI 10.1109/34.9104; WEIMAN CFR, 1979, COMPUT VISION GRAPH, V11, P197, DOI 10.1016/0146-664X(79)90089-3; YANG HS, 1985, 3RD P IEEE WORKSH CO	26	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1989	11	8					814	822		10.1109/34.31444	http://dx.doi.org/10.1109/34.31444			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH079					2022-12-18	WOS:A1989AH07900003
J	CHENG, YC; LU, SY				CHENG, YC; LU, SY			THE BINARY CONSISTENCY CHECKING SCHEME AND ITS APPLICATIONS TO SEISMIC HORIZON DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											CHENG, YC (corresponding author), EXXON PROD RES CO, HOUSTON, TX 77001 USA.							Aho A.V., 1972, THEORY PARSING TRANS; CHENG YC, 1985, IEEE T PATTERN ANAL, V7, P299, DOI 10.1109/TPAMI.1985.4767658; CHENG YC, 1986, 56TH SOC EXPL GEOPH; DECHTER R, 1987, ART INTELL, V34; HARALICK RM, 1980, IEEE T PATTERN ANAL, V2, P193, DOI 10.1109/TPAMI.1980.4767007; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HUANG KY, 1985, 55TH SOC EXPL GEOPH, P585; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; KERZNER MG, 1982, LOG ANAL         SEP; KESKES N, 1983, 53RD SOC EXPL GEOPH, P557; KESKES N, 1982, 52NS SOC EXPL GEOPH, P220; KESKES N, 1984, 54TH SOC EXPL GEOPH, P477; LOVE PL, 1984, 54TH SOC EXPL GEOPH, P536; LU SY, 1984, IEEE T PATTERN ANAL, V6, P249, DOI 10.1109/TPAMI.1984.4767511; LU SY, 1982, OCT P INT JOINT C PA, P178; SIMMONS RG, 1983, MIT AITR749 ART INT; VAIL PR, 1977, AAPG26 MEM; VINCENT P, 1977, 52ND ANN FALL TECH C; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811	19	8	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1989	11	4					439	447		10.1109/34.19043	http://dx.doi.org/10.1109/34.19043			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T9100					2022-12-18	WOS:A1989T910000012
J	REEVES, AP; TAYLOR, RW				REEVES, AP; TAYLOR, RW			IDENTIFICATION OF 3-DIMENSIONAL OBJECTS USING RANGE INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									IBM RES,YORKTOWN HTS,NY 10598	International Business Machines (IBM)	REEVES, AP (corresponding author), CORNELL UNIV,SCH ELECT ENGN,ITHACA,NY 14853, USA.							Andersson R. L., 1985, IEEE Journal of Robotics and Automation, VRA-1, P79; Ballard D.H., 1982, COMPUTER VISION; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; IKEUCHI K, 1984, 7TH P IJCAI, P595; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; MITCHELL OR, 1982, P SOC PHOTO-OPT INST, V360, P190; REEVES AP, 1988, IEEE T PATTERN ANAL, V10, P937, DOI 10.1109/34.9115; REEVES AP, 1982, 6TH P INT C PATT REC, P465; REEVES AP, 1983, JUN P IEEE COMP SOC, P20; REEVES AP, 1981 P PATT REC IM P, P171; WALLACE TP, 1980, COMPUT GRAPHICS IMAG, V3, P99; Yang H. S., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P199; YANG HS, 1985, 3RD P WORKSH COMP VI, P38	15	8	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1989	11	4					403	410		10.1109/34.19036	http://dx.doi.org/10.1109/34.19036			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T9100					2022-12-18	WOS:A1989T910000005
J	ACAMPORA, AS; WINTERS, JH				ACAMPORA, AS; WINTERS, JH			3-DIMENSIONAL ULTRASONIC VISION FOR ROBOTIC APPLICATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											ACAMPORA, AS (corresponding author), AT&T BELL LABS,NETWORK SYST RES DEPT,HOLMDEL,NJ 07733, USA.							BLACHMAN NM, 1963, AM MATH MON, V70, P526, DOI 10.2307/2312064; BROWN MK, 1985 P IEEE INT C RO; BRYANT RC, 1984, IEEE T SON ULTRASON, V31, P373, DOI 10.1109/T-SU.1984.31518; BUCKLEY S, 1980, P AUTOFACT W CAD CAM, V1, P571; Gallager R. G., 1968, INFORM THEORY RELIAB, P344; KENDALL MG, 1961, COURSE GEOMETRY N DI; LANDAU HJ, 1962, BELL SYST TECH J, V41, P1295, DOI 10.1002/j.1538-7305.1962.tb03279.x; MARSH KA, 1984, 4TH P INT C ROB VIS; MORAVEC HP, 1985 P IEEE INT C RO; NITZAN D, 1985, IEEE J ROB AUTOMAT, V1; RICHARDSON JM, 1984 P IEEE ULTR S; SCHOENWALD JS, 1982 P IEEE ULTR S; SLEPIAN D, 1978, BELL SYST TECH J, V57, P1371, DOI 10.1002/j.1538-7305.1978.tb02104.x; VANTREES HL, 1968, DETECTION ESTIMATI 1, P193; WYNER AD, 1978, AT&T TECH J, V57, P3277, DOI 10.1002/j.1538-7305.1978.tb02204.x	15	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					291	303		10.1109/34.21798	http://dx.doi.org/10.1109/34.21798			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840					2022-12-18	WOS:A1989T384000009
J	YANNAKOUDAKIS, EJ; ANGELIDAKIS, G				YANNAKOUDAKIS, EJ; ANGELIDAKIS, G			AN INSIGHT INTO THE ENTROPY AND REDUNDANCY OF THE ENGLISH-DICTIONARY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											YANNAKOUDAKIS, EJ (corresponding author), UNIV BRADFORD, COMP SCI POSTGRAD SCH, BRADFORD BD7 1DP, W YORKSHIRE, ENGLAND.							LYNCH MF, 1973, INFORM STORAGE RET, V9, P331, DOI 10.1016/0020-0271(73)90072-7; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x; SUEN CY, 1979, IEEE T PATTERN ANAL, V1, P164, DOI 10.1109/TPAMI.1979.4766902; YANNAKOUDAKIS EJ, 1982, COMPUT J, V25, P183, DOI 10.1093/comjnl/25.2.183; YANNAKOUDAKIS EJ, 1982, INFORM PROCESS MANAG, V18, P15, DOI 10.1016/0306-4573(82)90047-4; YANNAKOUDAKIS EJ, 1979, J INFORMATICS, V3, P7; YANNAKOUDAKIS EJ, UNPUB EFFECTIVENESS; ZIPF GK, 1949, HUMAN BEHAVIOR PRINC	10	8	8	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					960	970		10.1109/34.9119	http://dx.doi.org/10.1109/34.9119			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100019
J	IRANI, KB; YOO, SI				IRANI, KB; YOO, SI			A METHODOLOGY FOR SOLVING PROBLEMS - PROBLEM MODELING AND HEURISTIC GENERATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SEOUL NATL UNIV,DEPT COMP SCI & STAT,SEOUL 151,SOUTH KOREA	Seoul National University (SNU)	IRANI, KB (corresponding author), UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,CTR RES INTEGRATED MFG,DIV ROBOT SYST,ANN ARBOR,MI 48109, USA.							[Anonymous], 1980, PRINCIPLES ARTIFICIA; GASCHNIG J, 1977, AUG P IJCAI, P434; GASCHNIG J, 1979, P IJCAI; GUIDA G, 1979, INFORM SCIENCES, V19, P251, DOI 10.1016/0020-0255(79)90024-0; HARALICK RM, 1978, INFORM SCIENCES, V14, P199, DOI 10.1016/0020-0255(78)90043-9; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1; HARRIS L, 1974, ARTIF INTELL, V5; HART P, 1968, IEEE T SYST SCI CYBE, V4; HELD M, 1971, OPER RES, V19; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; PEARL J, 1983, AI MAG, V4; Pearl J., 1984, INTELLIGENT SEARCH S; POHL I, 1973, P IJCAI; RENDELL L, 1983, ARTIF INTELL, V21; YOO S, 1985, THESIS U MICH ANN AR	15	8	8	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					676	686		10.1109/34.6776	http://dx.doi.org/10.1109/34.6776			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500007
J	FANG, ZX; LI, XB; NI, LM				FANG, ZX; LI, XB; NI, LM			PARALLEL ALGORITHMS FOR IMAGE TEMPLATE MATCHING ON HYPERCUBE SIMD COMPUTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV ALBERTA,DEPT COMP SCI,EDMONTON T6G 2H1,ALBERTA,CANADA; MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824	University of Alberta; Michigan State University	FANG, ZX (corresponding author), WICHITA STATE UNIV,DEPT COMP SCI,WICHITA,KS 67208, USA.							DEKEL E, 1981, SIAM J COMPUT, V10; FOX G, 1984, PHYS TODAY, P50; Hillis W., 1985, CONNECTION MACHINE; HWANG K, 1984, COMPUTER ARCHITECTUR; PREPARATA FP, 1979, P 20 S FDN COMP SCI, P140; Reeves A. P., 1985, 1985 IEEE Computer Society Workshop on Computer Architecture for Pattern Analysis and Image Database Management (Cat. No.85CH2229-3), P412; SEITZ CL, 1985, COMMUN ACM, V28; SIEGEL HT, 1981, IEEE T COMPUT, V30; SIEGEL L, 1982, IEEE T COMPUT, V31; 1986, 280273001 INT CORP	10	8	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1987	9	6					835	841		10.1109/TPAMI.1987.4767990	http://dx.doi.org/10.1109/TPAMI.1987.4767990			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	K6735	21869445				2022-12-18	WOS:A1987K673500011
J	KALAYEH, HM; LANDGREBE, DA				KALAYEH, HM; LANDGREBE, DA			ADAPTIVE RELAXATION LABELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									PURDUE UNIV,ENGN EXPT STN,W LAFAYETTE,IN 47906	Purdue University System; Purdue University; Purdue University West Lafayette Campus	KALAYEH, HM (corresponding author), OBJECT RECOGNIT SYST INC,PRINCETON,NJ 08540, USA.							EKLUNDH J, 1978, 662 U MAR COMP SCI C; EKLUNDH JO, 1978, 701 U MAR COMP SCI C; FAUGERAS O, 1979, PATTERN RECOGNITION, V12, P339; HUMMEL R, 1980 P IEEE C PATT R, V1, P50; KALAYEH HM, 1982, LARS082782 PURD U TE; LEV A, 1977, IEEE T SYST MAN CYB, V7, P435, DOI 10.1109/TSMC.1977.4309740; MCLEAN CR, 1980, DEC P IEEE C PATT RE, V1, P58; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; Peleg S., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P337; PELEG S, 1979, 842 U MAR COMP SCI C; PELEG S, 1980, IEEE T PATTERN ANAL, V2; RICHARDSON J, 1981, J TECH WRIT COMMUN, V11, P303, DOI 10.2190/VM1Q-PC9R-5XA3-M9MQ; ROBERT HM, 1980, COMPUT GRAPHICS IMAG, V3, P242; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SCHACHTER BJ, 1977, IEEE T SYST MAN CYB, V7, P813; Zucker S. W., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P307; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P117, DOI 10.1109/TPAMI.1981.4767069	19	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					369	372		10.1109/TPAMI.1984.4767530	http://dx.doi.org/10.1109/TPAMI.1984.4767530			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SR542	21869204				2022-12-18	WOS:A1984SR54200013
J	WU, LD				WU, LD			A PIECEWISE LINEAR-APPROXIMATION BASED ON A STATISTICAL-MODEL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WU, LD (corresponding author), FUDAN UNIV,DEPT COMP SCI,SHANGHAI,PEOPLES R CHINA.							Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; Gasser TaM HG., 1979, SMOOTHING TECHNIQUES; GEMAN S, 1981, 99 BROWN U DIV APPL; Grenander U., 1981, ABSTRACT INFERENCE; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; MCCLURE DE, 1975, Q APPL MATH, V33, P1; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; Pavlidis T., 1977, STRUCTURAL PATTERN R; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; SKLANSKY J, 1980, PATTERN RECOGN, V12, P327, DOI 10.1016/0031-3203(80)90031-X; TOMEK I, 1974, IEEE T COMPUT, VC 23, P445, DOI 10.1109/T-C.1974.223961	13	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	1					41	45		10.1109/TPAMI.1984.4767473	http://dx.doi.org/10.1109/TPAMI.1984.4767473			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SB213	21869163				2022-12-18	WOS:A1984SB21300004
J	LEE, HC; FU, KS				LEE, HC; FU, KS			GENERATING OBJECT DESCRIPTIONS FOR MODEL RETRIEVAL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	LEE, HC (corresponding author), EASTMAN KODAK CO,RES LABS,ROCHESTER,NY 14650, USA.							[Anonymous], 1975, PSYCHOL COMPUTER VIS; BARROW HG, 1980, 1ST P ANN NAT C ART; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; DAVIS LS, 1981, ARTIF INTELL, V17, P245, DOI 10.1016/0004-3702(81)90026-6; DOUGLASS RJ, 1981, COMPUT GRAPHICS IMAG, V16, P91; GUZMAN A, 1968, FAL AFIPS P JOINT CO, V33, P291; HU MK, 1962, IEEE T INFORM THEORY, V8, P169; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; LEE HC, 1983, COMPUT VISION GRAPH, V22, P177, DOI 10.1016/0734-189X(83)90100-7; LEE HC, 1982, JUN P C PATT REC IM, P466; LEE HC, 1981, AUG P IEEE C PATT RE, P256; MACKWORTH AK, 1977, MACHINE INTELLIGENCE, V8; MARR D, 1977, PROC R SOC SER B-BIO, V197, P441, DOI 10.1098/rspb.1977.0080; Marr D., 1982, VISION; MCKEE JW, 1977, IEEE T COMPUT, V26, P790, DOI 10.1109/TC.1977.1674917; MULGAONKAR PG, 1982, JUN P C PATT REC IM, P479; PERKINS DN, 1976, PERCEPTION, V5, P393, DOI 10.1068/p050393; STEVENS KA, 1980, MIT AITR512 ART INT; TENENBAUM JM, 1977, ARTIF INTELL, V8, P241, DOI 10.1016/0004-3702(77)90031-5; WALLACE TP, 1980, IEEE T PATTERN ANAL, V2, P583, DOI 10.1109/TPAMI.1980.6447707; [No title captured]	21	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					462	471		10.1109/TPAMI.1983.4767425	http://dx.doi.org/10.1109/TPAMI.1983.4767425			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	RM118	21869131				2022-12-18	WOS:A1983RM11800002
J	YUM, YH; PARK, SB				YUM, YH; PARK, SB			OPTIMUM RECURSIVE FILTERING OF NOISY TWO-DIMENSIONAL DATA WITH SEQUENTIAL PARAMETER-IDENTIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											YUM, YH (corresponding author), KOREA ADV INST SCI & TECHNOL,DEPT ELECT SCI,SEOUL,SOUTH KOREA.							AASNAES HB, 1973, IEEE T AUTOMAT CONTR, VAC18, P601, DOI 10.1109/TAC.1973.1100412; Andrews H.C., 1977, DIGITAL IMAGE RESTOR; ATTASI S, 1976, SYSTEM IDENTIFICATIO; Chen C. H., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P32; EKSTROM MP, 1976, IEEE T ACOUST SPEECH, V24, P115, DOI 10.1109/TASSP.1976.1162785; Goodwin G., 1977, DYNAMIC SYSTEM IDENT; HABIBI A, 1972, PR INST ELECTR ELECT, V60, P878, DOI 10.1109/PROC.1972.8787; HUANG TS, 1971, PR INST ELECTR ELECT, V59, P1586, DOI 10.1109/PROC.1971.8491; Jain A. K., 1981, P IEEE INT C AC SPEE, P1113; JAIN AK, 1981, P IEEE, V69, P502, DOI 10.1109/PROC.1981.12021; JAIN AK, 1978, IEEE T AUTOMAT CONTR, V23, P817, DOI 10.1109/TAC.1978.1101881; JURY EI, 1978, P IEEE, V66, P1018, DOI 10.1109/PROC.1978.11079; KESHAVAN HR, 1978, IEEE T SYST MAN CYB, V8, P247, DOI 10.1109/TSMC.1978.4309945; MARZETTA TL, 1980, IEEE T ACOUST SPEECH, V28, P725, DOI 10.1109/TASSP.1980.1163468; MURPHY MS, 1978, IEEE T AUTOMAT CONTR, V23, P809, DOI 10.1109/TAC.1978.1101864; NAHI NE, 1972, PR INST ELECTR ELECT, V60, P872, DOI 10.1109/PROC.1972.8786; PANDA DP, 1977, IEEE T ACOUST SPEECH, V25, P520, DOI 10.1109/TASSP.1977.1162994; PISTOR P, 1974, IBM J RES DEV, V18, P59, DOI 10.1147/rd.181.0059; SARIDIS GN, 1974, IEEE T AUTOMAT CONTR, VAC19, P798, DOI 10.1109/TAC.1974.1100716; SARIDIS GN, 1968, IEEE T AUTOMAT CONTR, VAC13, P515, DOI 10.1109/TAC.1968.1098997; SCHOUTE FC, 1977, IEEE T CIRCUITS SYST, V24, P67, DOI 10.1109/TCS.1977.1084310; STRINTZIS MG, 1978, IEEE T AUTOMAT CONTR, V23, P801, DOI 10.1109/TAC.1978.1101859; SURESH BR, 1981, IEEE T CIRCUITS SYST, V28, P307, DOI 10.1109/TCS.1981.1084992; WASAN M., 1969, STOCHASTIC APPROXIMA; WONG E, 1978, IEEE T INFORM THEORY, V24, P50, DOI 10.1109/TIT.1978.1055818; WOODS JW, 1977, IEEE T INFORM THEORY, V23, P473, DOI 10.1109/TIT.1977.1055750; WOODS JW, 1981, IEEE T ACOUST SPEECH, V29, P188, DOI 10.1109/TASSP.1981.1163533; 1972, P IEEE, V60	28	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	3					337	344		10.1109/TPAMI.1983.4767396	http://dx.doi.org/10.1109/TPAMI.1983.4767396			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QS785	21869117				2022-12-18	WOS:A1983QS78500009
J	CADZOW, JA				CADZOW, JA			ARMA MODELING OF TIME-SERIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CADZOW, JA (corresponding author), ARIZONA STATE UNIV, DEPT ELECT & COMP ENGN, TEMPE, AZ 85287 USA.							Box G.E.P., 2015, TIME SERIES ANAL FOR; BRUZZONE S, 1980, IEEE T ACOUST SPEECH, V28, P753, DOI 10.1109/TASSP.1980.1163462; CADZOW JA, 1980, IEEE T ACOUST SPEECH, V28, P524, DOI 10.1109/TASSP.1980.1163440; CADZOW JA, 1979, P RADC SPECTR EST WO, P81; CADZOW JA, 1981, 1ST IEEE ASSP WORKSH; CHEN CH, 1973, STATISTICAL PATTERN; Childers D, 1978, MODERN SPECTRAL ANAL; Duda R.O., 1973, J ROYAL STAT SOC SER; FRANK L, 1969, SIGNAL THEORY; Fu K. S., 1968, SEQUENTIAL METHODS P, V240, P241; GUTOWSKI PR, 1978, IEEE T GEOSCI REMOTE, V16, P80, DOI 10.1109/TGE.1978.294568; Haykin S, 1979, NONLINEAR METHODS SP; KAVEH M, 1979, IEEE T ACOUST SPEECH, V27, P286, DOI 10.1109/TASSP.1979.1163243; KAY SM, 1980, IEEE T ACOUST SPEECH, V28, P585, DOI 10.1109/TASSP.1980.1163448; KINKEL JF, 1979, IEEE T ACOUST SPEECH, V27, P200, DOI 10.1109/TASSP.1979.1163220; OGINO K, 1981, THESIS VIRGINIA POLY; PAO Y, 1981, 1ST IEEE ASSP WORKSH; ROBINSON E, 1980, PHYSICAL APPLICATION; TRETTER SA, 1967, IEEE T AUTOMAT CONTR, VAC12, P185, DOI 10.1109/TAC.1967.1098544	19	8	8	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					124	128		10.1109/TPAMI.1982.4767216	http://dx.doi.org/10.1109/TPAMI.1982.4767216			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869015				2022-12-18	WOS:A1982NE95700005
J	WATSON, LT; SHAPIRO, LG				WATSON, LT; SHAPIRO, LG			IDENTIFICATION OF SPACE-CURVES FROM TWO-DIMENSIONAL PERSPECTIVE VIEWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WATSON, LT (corresponding author), VIRGINIA POLYTECH INST & STATE UNIV,DEPT COMP SCI,BLACKSBURG,VA 24061, USA.		Rohlf, F J/A-8710-2008					ALT FL, 1962, J ASS COMPUT MACH, P240; [Anonymous], 1975, PSYCHOL COMPUTER VIS; BADLER N, 1978, COMPUT GRAPHICS, V12, P153; BROWN KM, 1972, NUMER MATH, V18, P289; CARL JW, 1972, IEEE T COMPUT, VC 21, P785, DOI 10.1109/T-C.1972.223582; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; Coxeter HSM., 1969, INTRO GEOMETRY; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; DIRILTEN H, 1977, IEEE T COMPUT, V26, P314, DOI 10.1109/TC.1977.1674832; FREEMAN H, 1979, AUG P IEEE C PATT RE; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; HEMAMI H, 1975, MAY P C COMP GRAPH P, P273; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; KANADE T, 1978, CMUCS78144 CARN MELL; KANADE T, 1979, CMUCS79153 CARN MELL; KOLERS PA, 1970, PICTURE PROCESSING P, P181; MORE JJ, 1979, MINPACK DOCUMENTATIO; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990; SHAPIRO LG, 1980, 2ND IEEE WORKSH PICT; WITKIN A, 1981, SHAPE CONTOUR; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949; 1979, MAY WORKSH REPR 3 DI	25	8	8	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	5					469	475		10.1109/TPAMI.1982.4767290	http://dx.doi.org/10.1109/TPAMI.1982.4767290			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PG894	21869065	Green Submitted			2022-12-18	WOS:A1982PG89400002
J	ITOGA, SY				ITOGA, SY			A NEW HEURISTIC FOR INFERRING REGULAR GRAMMARS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											ITOGA, SY (corresponding author), UNIV HAWAII,DEPT INFORMAT & COMP SCI,HONOLULU,HI 96822, USA.							BIERMANN AW, 1972, IEEE T COMPUT, VC 21, P592, DOI 10.1109/TC.1972.5009015; BIERMANN AW, 1972, FRONTIERS PATTERN RE, P31; FELDMAN JA, 1969, CS125 STANF ART INT; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95, DOI 10.1109/TSMC.1975.5409159; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; VEELENTURF LPJ, 1978, IEEE T COMPUT, V27, P167, DOI 10.1109/TC.1978.1675053; WHARTON RM, 1977, INFORM CONTR, V23, P253	9	8	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					191	197		10.1109/TPAMI.1981.4767078	http://dx.doi.org/10.1109/TPAMI.1981.4767078			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN968	21868935				2022-12-18	WOS:A1981MN96800010
J	SMITH, AR; ERMAN, LD				SMITH, AR; ERMAN, LD			NOAH - A BOTTOM-UP WORD HYPOTHESIZER FOR LARGE-VOCABULARY SPEECH UNDERSTANDING SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,INST INFORMAT SCI,MARINA DEL REY,CA 90291	University of Southern California	SMITH, AR (corresponding author), INT TEL & TELEG,DIV DEF COMMUN,SAN DIEGO,CA 92131, USA.							Bahl L. R., 1976, 1976 IEEE International Conference on Acoustics, Speech and Signal Processing, P425; DENES P, 1960, J ACOUST SOC AM, V32, P1450, DOI 10.1121/1.1907936; ERMAN LD, 1980, TRENDS SPEECH RECOGN, pCH16; FEIGENBAUM EA, 1977, 5TH P INT JOINT C AR, P1014; FORGIE JW, 1974, SPEECH UNDERSTANDING; GILL G, 1978, CMUCS78134 CARN MELL; GOLDBERG H, 1977, ZAPDASH PARAMETERS F, P10; KING JH, 1966, IBM J RES DEV, V10, P65, DOI 10.1147/rd.101.0065; KLOVSTAD JW, 1976, 6 SPEECH UND SYST TE, P68; Knuth D., 1973, ART COMPUTER PROGRAM, V3; Lowerre Bruce T., 1976, THESIS; LOWERRE BT, 1980, TRENDS SPEECH RECOGN, pCH15; MCKEOWN DM, 1977, P IEEE INT C ACOUSTI, P795; MILLER GA, 1963, J VERB LEARN VERB BE, V2, P217, DOI 10.1016/S0022-5371(63)80087-0; NEWELL A, 1975, SPEECH RECOGNITION, P3; REDDY DR, 1973, IEEE T ACOUST SPEECH, VAU21, P229, DOI 10.1109/TAU.1973.1162456; REDDY DR, 1976, P IEEE, V64, P501, DOI 10.1109/PROC.1976.10158; REDDY DR, 1973, 3RD P INT JOINT C AR, P185; SMITH A, 1976, P IEEE INT C ASSP, P549; SMITH AR, 1977, THESIS CARNEGIE MELL; STEVENS KN, 1964, MODELS PERCEPTION SP; VICENS P, 1969, THESIS STANFORD U ST; WOODS WA, 1976, 3438 TECH REP; 1977, SUMMARY CMU 5 YEAR A	24	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					41	51		10.1109/TPAMI.1981.4767049	http://dx.doi.org/10.1109/TPAMI.1981.4767049			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LK116					2022-12-18	WOS:A1981LK11600005
J	SCHUTTEN, RW; VERMEIJ, GF				SCHUTTEN, RW; VERMEIJ, GF			APPROXIMATION OF IMAGE BLUR RESTORATION FILTERS BY FINITE IMPULSE RESPONSES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											SCHUTTEN, RW (corresponding author), TWENTE UNIV TECHNOL,DEPT ELECT ENGN,MEASUREMENT SCI & INSTRUMENTAT GRP,ENSCHEDE,NETHERLANDS.							ANDREWS HC, 1976, DIGITAL IMAGE RESTOR; Gelb A., 1974, APPL OPTIMAL ESTIMAT; HUANG TS, 1975, PICTURE PROCESSING D, V6; SCHUTTEN RW, TM77020 TWENT U TECH	4	8	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	2					176	180		10.1109/TPAMI.1980.4766997	http://dx.doi.org/10.1109/TPAMI.1980.4766997			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JH803	21868890				2022-12-18	WOS:A1980JH80300011
J	Chen, GY; Peng, PX; Wang, XQ; Tian, YH				Chen, Guangyao; Peng, Peixi; Wang, Xiangqian; Tian, Yonghong			Adversarial Reciprocal Points Learning for Open Set Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Cats; Prototypes; Task analysis; Pattern recognition; Deep learning; Uncertainty; Open set recognition; out-of-distribution detection; reciprocal points; generative adversarial learning	CLASSIFICATION; ALGORITHMS	Open set recognition (OSR), aiming to simultaneously classify the seen classes and identify the unseen classes as 'unknown', is essential for reliable machine learning. The key challenge of OSR is how to reduce the empirical classification risk on the labeled known data and the open space risk on the potential unknown data simultaneously. To handle the challenge, we formulate the open space risk problem from the perspective of multi-class integration, and model the unexploited extra-class space with a novel concept Reciprocal Point. Follow this, a novel learning framework, termed Adversarial Reciprocal Point Learning (ARPL), is proposed to minimize the overlap of known distribution and unknown distributions without loss of known classification accuracy. Specifically, each reciprocal point is learned by the extra-class space with the corresponding known category, and the confrontation among multiple known categories are employed to reduce the empirical classification risk. Then, an adversarial margin constraint is proposed to reduce the open space risk by limiting the latent open space constructed by reciprocal points. To further estimate the unknown distribution from open space, an instantiated adversarial enhancement method is designed to generate diverse and confusing training samples, based on the adversarial mechanism between the reciprocal points and known classes. This can effectively enhance the model distinguishability to the unknown classes. Extensive experimental results on various benchmark datasets indicate that the proposed method is significantly superior to other existing approaches and achieves state-of-the-art performance. The code is released on github.com/iCGY96/ARPL.	[Chen, Guangyao; Peng, Peixi; Tian, Yonghong] Peking Univ, Dept Comp Sci & Technol, Beijing 100871, Peoples R China; [Peng, Peixi; Tian, Yonghong] Peng Cheng Lab, Shenzhen 518066, Peoples R China; [Wang, Xiangqian] Huawei, AI Applicat Res Ctr, Shenzhen 518129, Peoples R China	Peking University; Peng Cheng Laboratory; Huawei Technologies	Tian, YH (corresponding author), Peking Univ, Dept Comp Sci & Technol, Beijing 100871, Peoples R China.; Tian, YH (corresponding author), Peng Cheng Lab, Shenzhen 518066, Peoples R China.	gy.chen@pku.edu.cn; pxpeng@pku.edu.cn; basileus.wang@huawei.com; yhtian@pku.edu.cn			Key-Area Research and Development Program of Guangdong Province [2019B010153002]; National Natural Science Foundation of China [61825101, 62088102]	Key-Area Research and Development Program of Guangdong Province; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the Key-Area Research and Development Program of Guangdong Province under Grant 2019B010153002 and in part by the National Natural Science Foundation of China under Grants 61825101 and 62088102.	[Anonymous], 2011, P NIPS WORKSHOP DEEP; Bartlett PL, 2008, J MACH LEARN RES, V9, P1823; Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173; Bonilla E. V., 2012, PROC INT C MACH LEAR, P1187; Da Q, 2014, AAAI CONF ARTIF INTE, P1760; Dai Z., 2017, ADV NEURAL INFORM PR, P6510; Hendrycks D, 2019, Arxiv, DOI arXiv:1907.07174; Davis J., 2006, 23 INT C MACH LEARN, P233, DOI [10.1145/1143844.1143874, DOI 10.1145/1143844.1143874]; Dhamija A. R., 2018, ADV NEURAL INFORM PR, P9175; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Ge ZongYuan, 2017, BMVC; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guangyao Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P507, DOI 10.1007/978-3-030-58580-8_30; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hendrycks D., 2018, PROC INT C LEARN REP; Hongjie Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P102, DOI 10.1007/978-3-030-58580-8_7; Ioffe S., 2015, P 32 INT C MACH LEAR; Jain LP, 2014, LECT NOTES COMPUT SC, V8691, P393, DOI 10.1007/978-3-319-10578-9_26; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Kumaran D, 2016, TRENDS COGN SCI, V20, P512, DOI 10.1016/j.tics.2016.05.004; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee Kimin, 2018, ICLR; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Mendes PR, 2017, MACH LEARN, V106, P359, DOI 10.1007/s10994-016-5610-8; Neal L, 2018, LECT NOTES COMPUT SC, V11210, P620, DOI 10.1007/978-3-030-01231-1_38; Oza P, 2019, PROC CVPR IEEE, P2302, DOI 10.1109/CVPR.2019.00241; Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149; Perera P, 2019, PROC CVPR IEEE, P2893, DOI 10.1109/CVPR.2019.00301; Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6; Rozsa A., 2017, PROC BRIT MACH VIS C; Rudd EM, 2018, IEEE T PATTERN ANAL, V40, P762, DOI 10.1109/TPAMI.2017.2707495; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sato A, 1998, INT C PATT RECOG, P322, DOI 10.1109/ICPR.1998.711145; Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Shu L., 2017, P 2017 C EMP METH NA, P2911; Sun Xin, 2020, CVPR; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Xie C, 2020, PROC CVPR IEEE, P816, DOI 10.1109/CVPR42600.2020.00090; Yang HM, 2022, IEEE T PATTERN ANAL, V44, P2358, DOI 10.1109/TPAMI.2020.3045079; Yang HM, 2018, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2018.00366; Yen-Chang Hsu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10948, DOI 10.1109/CVPR42600.2020.01096; Yoshihashi R, 2019, PROC CVPR IEEE, P4011, DOI 10.1109/CVPR.2019.00414; Yuan M, 2010, J MACH LEARN RES, V11, P111; Zhang H, 2017, IEEE T PATTERN ANAL, V39, P1690, DOI 10.1109/TPAMI.2016.2613924	51	7	7	4	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					8065	8081		10.1109/TPAMI.2021.3106743	http://dx.doi.org/10.1109/TPAMI.2021.3106743			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34428133	Green Submitted			2022-12-18	WOS:000864325900057
J	Zhang, BF; Xiao, JM; Jiao, JB; Wei, YC; Zhao, Y				Zhang, Bingfeng; Xiao, Jimin; Jiao, Jianbo; Wei, Yunchao; Zhao, Yao			Affinity Attention Graph Neural Network for Weakly Supervised Semantic Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weakly supervised; semantic segmentation; graph neural network		Weakly supervised semantic segmentation is receiving great attention due to its low human annotation cost. In this paper, we aim to tackle bounding box supervised semantic segmentation, i.e., training accurate semantic segmentation models using bounding box annotations as supervision. To this end, we propose affinity attention graph neural network (A(2)GNN). Following previous practices, we first generate pseudo semantic-aware seeds, which are then formed into semantic graphs based on our newly proposed affinity Convolutional Neural Network (CNN). Then the built graphs are input to our A2GNN, in which an affinity attention layer is designed to acquire the short- and long- distance information from soft graph edges to accurately propagate semantic labels from the confident seeds to the unlabeled pixels. However, to guarantee the precision of the seeds, we only adopt a limited number of confident pixel seed labels for A2GNN, which may lead to insufficient supervision for training. To alleviate this issue, we further introduce a new loss function and a consistency-checking mechanism to leverage the bounding box constraint, so that more reliable guidance can be included for the model optimization. Experiments show that our approach achieves new state-of-the-art performances on Pascal VOC 2012 datasets (val: 76.5 percent, test: 75.2 percent). More importantly, our approach can be readily applied to bounding box supervised instance segmentation task or other weakly supervised semantic segmentation tasks, with state-of-the-art or comparable performance among almot all weakly supervised tasks on PASCALVOC or COCO dataset. Our source code will be available at https://github.com/ zbf1991/A2GNN.	[Zhang, Bingfeng] Univ Liverpool, Liverpool L69 3BX, Merseyside, England; [Zhang, Bingfeng; Xiao, Jimin] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou 215123, Jiangsu, Peoples R China; [Jiao, Jianbo] Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England; [Wei, Yunchao] Univ Technol Sydney, Ultimo, NSW 2007, Australia; [Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China	University of Liverpool; Xi'an Jiaotong-Liverpool University; University of Oxford; University of Technology Sydney; Beijing Jiaotong University	Xiao, JM (corresponding author), Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou 215123, Jiangsu, Peoples R China.	bingfeng.zhang@liverpool.ac.uk; jimin.xiao@xjtlu.edu.cn; jianbo@robots.ox.ac.uk; yunchao.wei@uts.edu.au; yzhao@bjtu.edu.cn		Zhao, Yao/0000-0002-8581-9554; Zhang, Bingfeng/0000-0001-5751-2873; Jiao, Jianbo/0000-0003-0833-5115	National Key Research and Development of China [2018AAA0102100]; National Natural Science Foundation of China [61972323, U1936212, 62120106009]; KSF fund in XJTLU [KSF-T-02, KSF-P-02]; EPSRC [EP/M013774/1, EP/T028572/1]	National Key Research and Development of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); KSF fund in XJTLU; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported in part by the National Key Research and Development of China under Grant 2018AAA0102100, in part by the National Natural Science Foundation of China under Grants 61972323, U1936212, and 62120106009, in part by the KSF fund in XJTLU under Grants KSF-T-02 and KSF-P-02, and in part by the EPSRC Programme Grants Seebibyte EP/M013774/1 and Visual AI EP/T028572/1.	Abu-El-Haija S, 2020, PR MACH LEARN RES, V115, P841; Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Ahn J, 2019, PROC CVPR IEEE, P2204, DOI 10.1109/CVPR.2019.00231; Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34; Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236; Chen L.-C., 2015, P INT C LEARNING REP; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen Liyi, 2020, P EUR C COMP VIS, P347, DOI DOI 10.1007/978-3-030-58574-7_21; Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532; Chong Wang, 2018, Arxiv, DOI arXiv:1803.03735; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191; diaeresis>ahenb <spacing diaeresis>uhl Philipp Kr<spacing, 2013, P 30 INT C MACH LEAR, P513; Dong Z., 2020, P ADV NEUR INF PROC; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan JS, 2020, AAAI CONF ARTIF INTE, V34, P10762; Fan JS, 2020, PROC CVPR IEEE, P4282, DOI 10.1109/CVPR42600.2020.00434; Fan Junsong, 2020, ECCV, DOI DOI 10.1007/978-3-030-58520-4_20; Fan RC, 2018, LECT NOTES COMPUT SC, V11213, P371, DOI 10.1007/978-3-030-01240-3_23; Fan RC, 2019, PROC CVPR IEEE, P6096, DOI 10.1109/CVPR.2019.00626; Florian Schroff, 2017, Arxiv, DOI arXiv:1706.05587; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Guo ZJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P241; Guolei Sun, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P347, DOI 10.1007/978-3-030-58536-5_21; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He K., 2017, IEEE INT C COMP VIS, P2961; Hirotaka Akita, 2018, Arxiv, DOI arXiv:1810.02080; Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563; Hou QB, 2018, ADV NEUR IN, V31; Hsu CC, 2019, ADV NEUR IN, V32; Huang ZL, 2018, PROC CVPR IEEE, P7014, DOI 10.1109/CVPR.2018.00733; Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181; Kingma D.P., 2015, INT C LEARN REPR, P1; Kipf T.N., 2017, INT C LEARN REPR; Kulharia Viveka, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P290, DOI 10.1007/978-3-030-58583-9_18; Lee J, 2019, PROC CVPR IEEE, P5262, DOI 10.1109/CVPR.2019.00541; Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34; Li QZ, 2018, LECT NOTES COMPUT SC, V11219, P106, DOI 10.1007/978-3-030-01267-0_7; Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404; Liu Y, 2022, IEEE T PATTERN ANAL, V44, P1415, DOI 10.1109/TPAMI.2020.3023152; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lovasz L, 1993, BOLYAI MATH STUD, V1, P9; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481406; Pu MY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P483, DOI 10.1145/3240508.3240542; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Song CF, 2019, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2019.00325; Song L., 2019, PROC NEURIPS, P1711; Tang M, 2018, LECT NOTES COMPUT SC, V11220, P524, DOI 10.1007/978-3-030-01270-0_31; Tang M, 2018, PROC CVPR IEEE, P1818, DOI 10.1109/CVPR.2018.00195; Tianyi Zhang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P663, DOI 10.1007/978-3-030-58542-6_40; Velickovic P., 2018, P INT C LEARN REPR, DOI DOI 10.17863/CAM.48429; Vernaza P, 2017, PROC CVPR IEEE, P2953, DOI 10.1109/CVPR.2017.315; Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933; Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Wu B., 2019, IMPROVING SEMANTIC S; Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26; Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226; Yu-Ting Chang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8988, DOI 10.1109/CVPR42600.2020.00901; Yude Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12272, DOI 10.1109/CVPR42600.2020.01229; Zhang BF, 2020, AAAI CONF ARTIF INTE, V34, P12765; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou YZ, 2018, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2018.00399	73	7	7	18	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					8082	8096		10.1109/TPAMI.2021.3083269	http://dx.doi.org/10.1109/TPAMI.2021.3083269			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34033532	Green Submitted			2022-12-18	WOS:000864325900058
J	Zheng, BL; Yuan, SX; Yan, CG; Tian, X; Zhang, JY; Sun, YQ; Liu, L; Leonardis, A; Slabaugh, G				Zheng, Bolun; Yuan, Shanxin; Yan, Chenggang; Tian, Xiang; Zhang, Jiyong; Sun, Yaoqi; Liu, Lin; Leonardis, Ales; Slabaugh, Gregory			Learning Frequency Domain Priors for Image Demoireing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image color analysis; Image restoration; Frequency-domain analysis; Discrete cosine transforms; Task analysis; Degradation; Wavelet domain; Image demoireing; frequency domain prior; learnable bandpass filter; dilated advanced sobel loss; degradation model; learnable orthogonal transform; two-step color restoration	NETWORK	Image demoireing is a multi-faceted image restoration task involving both moire pattern removal and color restoration. In this paper, we raise a general degradation model to describe an image contaminated by moire patterns, and propose a novel multi-scale bandpass convolutional neural network (MBCNN) for single image demoireing. For moire pattern removal, we propose a multi-block-size learnable bandpass filters (M-LBFs), based on a block-wise frequency domain transform, to learn the frequency domain priors of moire patterns. We also introduce a new loss function named Dilated Advanced Sobel loss (D-ASL) to better sense the frequency information. For color restoration, we propose a two-step tone mapping strategy, which first applies a global tone mapping to correct for a global color shift, and then performs local fine tuning of the color per pixel. To determine the most appropriate frequency domain transform, we investigate several transforms including DCT, DFT, DWT, learnable non-linear transform and learnable orthogonal transform. We finally adopt the DCT. Our basic model won the AIM2019 demoireing challenge. Experimental results on three public datasets show that our method outperforms state-of-the-art methods by a large margin.	[Zheng, Bolun; Yan, Chenggang; Zhang, Jiyong; Sun, Yaoqi] Hangzhou Dianzi Univ, Hangzhou 310018, Zhejiang, Peoples R China; [Yuan, Shanxin; Leonardis, Ales] Huawei Noahs Ark Lab, Montreal, PQ H3N 1X9, Canada; [Tian, Xiang] Zhejiang Univ, Hangzhou 310027, Zhejiang, Peoples R China; [Liu, Lin] Univ Sci & Technol China, Hefei 230052, Anhui, Peoples R China; [Liu, Lin] Huawei Noah Arks Lab, Montreal, PQ H3N 1X9, Canada; [Slabaugh, Gregory] Queen Mary Univ London, London E1 4NS, England	Hangzhou Dianzi University; Zhejiang University; Chinese Academy of Sciences; University of Science & Technology of China, CAS; University of London; Queen Mary University London	Yan, CG (corresponding author), Hangzhou Dianzi Univ, Hangzhou 310018, Zhejiang, Peoples R China.	blzheng@hdu.edu.cn; shanxinyuan@gmail.com; cgyan@hdu.edu.cn; tianx@mail.zju.edu.cn; jzhang@hdu.edu.cn; syq@hdu.edu.cn; ll0825@mail.ustc.edu.cn; leonardis@huawei.com; gslabaugh@qmul.ac.uk		Slabaugh, Greg/0000-0003-4060-5226; Zhang, Jiyong/0000-0001-9600-8477; Sun, Yaoqi/0000-0001-8874-241X; Leonardis, Ales/0000-0003-0773-3277; Zheng, Bolun/0000-0001-8788-1725	National Key Research and Development Program of China [2020YFB1406604]; National Nature Science Foundation of China [62001146, 61931008, 61671196, 61701149, 61801157, 61971268, 61901145, 61901150, 61972123]; National Natural Science Major Foundation of Research Instrumentation of PR China [61427808]; Zhejiang Province Nature Science Foundation of China [LR17F030006, Q19F010030]; 111 Project [D17019]	National Key Research and Development Program of China; National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Major Foundation of Research Instrumentation of PR China; Zhejiang Province Nature Science Foundation of China; 111 Project(Ministry of Education, China - 111 Project)	This work was supported in part by the National Key Research and Development Program of China under Grant 2020YFB1406604, in part by the National Nature Science Foundation of China under Grants 62001146, 61931008, 61671196, 61701149, 61801157, 61971268, 61901145, 61901150, and 61972123, in part by the National Natural Science Major Foundation of Research Instrumentation of PR China under Grant 61427808, in part by the Zhejiang Province Nature Science Foundation of China under Grants LR17F030006 and Q19F010030, and in part by the 111 Project under Grant D17019.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652; Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158; Cavigelli L, 2017, IEEE IJCNN, P752, DOI 10.1109/IJCNN.2017.7965927; Cheng X, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107970; Cheng X, 2019, IEEE INT CONF COMP V, P3486, DOI 10.1109/ICCVW.2019.00432; Cheon M, 2019, LECT NOTES COMPUT SC, V11133, P51, DOI 10.1007/978-3-030-11021-5_4; Cho H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601188; Cho TS, 2012, IEEE T PATTERN ANAL, V34, P683, DOI 10.1109/TPAMI.2011.166; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Dong JF, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3006; Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816; Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362; Gao TY, 2019, IEEE INT CONF MULTI, P240, DOI 10.1109/ICMEW.2019.00048; Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592; Guo J, 2017, PROC CVPR IEEE, P4867, DOI 10.1109/CVPR.2017.517; Guo J, 2016, LECT NOTES COMPUT SC, V9905, P628, DOI 10.1007/978-3-319-46448-0_38; He B, 2019, IEEE I CONF COMP VIS, P2424, DOI 10.1109/ICCV.2019.00251; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; He KM, 2010, LECT NOTES COMPUT SC, V6311, P1; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Joshi N, 2009, PROC CVPR IEEE, P1550, DOI 10.1109/CVPRW.2009.5206802; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kingma D.P., 2015, INT C LEARN REPR ICL; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Lin Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P86, DOI 10.1007/978-3-030-58601-0_6; Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121; Liu XM, 2017, IEEE T IMAGE PROCESS, V26, P509, DOI 10.1109/TIP.2016.2627807; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luo XT, 2020, IEEE COMPUT SOC CONF, P1687, DOI 10.1109/CVPRW50498.2020.00218; Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804; Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343; Ronneberger O., 2015, P INT C MED IM COMP; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saxe A., 2014, INT C LEARNING REPRE; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Svoboda P., 2016, J WSCG, V24, P63; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Vien AG, 2020, IEEE COMPUT SOC CONF, P1934, DOI 10.1109/CVPRW50498.2020.00243; Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002; Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wu HK, 2018, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2018.00197; Xu K, 2020, PROC CVPR IEEE, P1737, DOI 10.1109/CVPR42600.2020.00181; Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798; Yan CG, 2020, IEEE T MULTIMEDIA, V22, P3014, DOI 10.1109/TMM.2020.2967645; Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576; Yu Fisher, 2016, MULTISCALE CONTEXT A; Yuan SX, 2019, IEEE INT CONF COMP V, P3526, DOI 10.1109/ICCVW.2019.00437; Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhang XS, 2018, IEEE IMAGE PROC, P390, DOI 10.1109/ICIP.2018.8451694; Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI [10.1007/978-3-030-01234-2_18, 10.1007/978-3-030-01240-3_22]; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865; Zheng BL, 2020, IEEE T CIRC SYST VID, V30, P3982, DOI 10.1109/TCSVT.2019.2931045; Zheng BL, 2020, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR42600.2020.00369	70	7	7	5	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					7705	7717		10.1109/TPAMI.2021.3115139	http://dx.doi.org/10.1109/TPAMI.2021.3115139			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34559636	Green Submitted			2022-12-18	WOS:000864325900033
J	Kansizoglou, I; Bampis, L; Gasteratos, A				Kansizoglou, Ioannis; Bampis, Loukas; Gasteratos, Antonios			Deep Feature Space: A Geometrical Perspective	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Standards; Physics; Deep learning; feature vector; sensor fusion; transfer learning		One of the most prominent attributes of Neural Networks (NNs) constitutes their capability of learning to extract robust and descriptive features from high dimensional data, like images. Hence, such an ability renders their exploitation as feature extractors particularly frequent in an abundance of modern reasoning systems. Their application scope mainly includes complex cascade tasks, like multi-modal recognition and deep Reinforcement Learning (RL). However, NNs induce implicit biases that are difficult to avoid or to deal with and are not met in traditional image descriptors. Moreover, the lack of knowledge for describing the intra-layer properties -and thus their general behavior- restricts the further applicability of the extracted features. With the paper at hand, a novel way of visualizing and understanding the vector space before the NNs' output layer is presented, aiming to enlighten the deep feature vectors' properties under classification tasks. Main attention is paid to the nature of overfitting in the feature space and its adverse effect on further exploitation. We present the findings that can be derived from our model's formulation and we evaluate them on realistic recognition scenarios, proving its prominence by improving the obtained results.	[Kansizoglou, Ioannis; Bampis, Loukas; Gasteratos, Antonios] Democritus Univ Thrace, Dept Prod & Management Engn, Xanthi 67100, Greece	Democritus University of Thrace	Kansizoglou, I (corresponding author), Democritus Univ Thrace, Dept Prod & Management Engn, Xanthi 67100, Greece.	ikansizo@pme.duth.gr; lbampis@pme.duth.gr; agaster@pme.duth.gr		Kansizoglou, Ioannis/0000-0003-2064-6442				Abadi M, 2015, P 12 USENIX S OPERAT; Adeli E, 2019, IEEE T PATTERN ANAL, V41, P515, DOI 10.1109/TPAMI.2018.2794470; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Anima Anandkumar, 2020, Arxiv, DOI arXiv:1912.02279; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Boyu Lu, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P42, DOI 10.1109/TBIOM.2018.2890577; Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6; Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286; Carlos D. Castillo, 2017, Arxiv, DOI arXiv:1703.09507; Clifford W.K., 1882, MATH PAPERS, P397; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632; Franchini S., 2010, BRIEF INTRO CLIFFORD; Frank Hutter, 2017, Arxiv, DOI arXiv:1707.08819; Gallier J, 2011, TEXTS APPL MATH, V38, P65; Hawkins J, 2004, INTELLIGENCE; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246; Kansizoglou I, 2022, IEEE T AFFECT COMPUT, V13, P756, DOI 10.1109/TAFFC.2019.2961089; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Lin RM, 2020, PROC CVPR IEEE, P6916, DOI 10.1109/CVPR42600.2020.00695; Liu W., 2017, PROC 31 INT C NEURAL, P3950; Liu WY, 2018, ADV NEUR IN, V31; Liu WY, 2018, PROC CVPR IEEE, P2771, DOI 10.1109/CVPR.2018.00293; Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713; Liu WY, 2016, PR MACH LEARN RES, V48; Ma YX, 2019, INFORM FUSION, V46, P184, DOI 10.1016/j.inffus.2018.06.003; Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI 10.1109/ICDEW.2006.145; Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923; Mroueh Y, 2015, INT CONF ACOUST SPEE, P2130, DOI 10.1109/ICASSP.2015.7178347; Paszke A., 2017, PROC INT C NEURAL IN; Purwins H, 2019, IEEE J-STSP, V13, P206, DOI 10.1109/JSTSP.2019.2908700; Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16; Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/neco_a_00990, 10.1162/NECO_a_00990]; Rodriguez-Mier P, 2017, P FUZZ IEEE 17 IEEE, P1; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2798; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Suter J., 2003, GEOMETRIC ALGEBRA PR; Thomson JJ, 1904, PHILOS MAG, V7, P237, DOI 10.1080/14786440409463107; Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Wang YJ, 2008, IEEE T MULTIMEDIA, V10, P936, DOI 10.1109/TMM.2008.927665; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238; Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738; Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038; Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043; Zhang ZW, 2022, IEEE T KNOWL DATA EN, V34, P249, DOI 10.1109/TKDE.2020.2981333	58	7	7	3	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6823	6838		10.1109/TPAMI.2021.3094625	http://dx.doi.org/10.1109/TPAMI.2021.3094625			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34232863	Green Submitted			2022-12-18	WOS:000853875300071
J	Pan, YS; Liu, MX; Xia, Y; Shen, DG				Pan, Yongsheng; Liu, Mingxia; Xia, Yong; Shen, Dinggang			Disease-Image-Specific Learning for Diagnosis-Oriented Neuroimage Synthesis With Incomplete Multi-Modality Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Diseases; Magnetic resonance imaging; Medical diagnosis; Image synthesis; Generative adversarial networks; Task analysis; Neuroimaging; Multi-modality neuroimaging; generative adversarial network; missing image synthesis; brain disease diagnosis	GRAY-MATTER; CLASSIFICATION; ASYMMETRIES; FUSION; CT	Incomplete data problem is commonly existing in classification tasks with multi-source data, particularly the disease diagnosis with multi-modality neuroimages, to track which, some methods have been proposed to utilize all available subjects by imputing missing neuroimages. However, these methods usually treat image synthesis and disease diagnosis as two standalone tasks, thus ignoring the specificity conveyed in different modalities, i.e., different modalities may highlight different disease-relevant regions in the brain. To this end, we propose a disease-image-specific deep learning (DSDL) framework for joint neuroimage synthesis and disease diagnosis using incomplete multi-modality neuroimages. Specifically, with each whole-brain scan as input, we first design a Disease-image-Specific Network (DSNet) with a spatial cosine module to implicitly model the disease-image specificity. We then develop a Feature-consistency Generative Adversarial Network (FGAN) to impute missing neuroimages, where feature maps (generated by DSNet) of a synthetic image and its respective real image are encouraged to be consistent while preserving the disease-image-specific information. Since our FGAN is correlated with DSNet, missing neuroimages can be synthesized in a diagnosis-oriented manner. Experimental results on three datasets suggest that our method can not only generate reasonable neuroimages, but also achieve state-of-the-art performance in both tasks of Alzheimer's disease identification and mild cognitive impairment conversion prediction.	[Pan, Yongsheng; Xia, Yong] Northwestern Polytech Univ, Sch Comp Sci & Engn, Natl Engn Lab Integrated AeroSp Ground Ocean Big, Xian 710072, Peoples R China; [Liu, Mingxia; Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA; [Liu, Mingxia; Shen, Dinggang] Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA; [Shen, Dinggang] ShanghaiTech Univ, Sch Biomed Engn, Shanghai 201210, Peoples R China; [Shen, Dinggang] Korea Univ, Dept Artificial Intelligence, Seoul 02841, South Korea	Northwestern Polytechnical University; University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill; ShanghaiTech University; Korea University	Xia, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, Natl Engn Lab Integrated AeroSp Ground Ocean Big, Xian 710072, Peoples R China.; Liu, MX; Shen, DG (corresponding author), Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA.; Liu, MX; Shen, DG (corresponding author), Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA.	yspan@mail.nwpu.edu.cn; mxliu@ined.unc.edu; yxia@nwpu.edu.cn; Dinggang.Shen@gmail.com		Liu, Mingxia/0000-0002-0166-0807; Pan, Yongsheng/0000-0002-8067-1132	National Natural Science Foundation of China [61771397]; Science and Technology Innovation Committee of Shenzhen Municipality, China [JCYJ20180306171334997]; NIH [AG041721]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science and Technology Innovation Committee of Shenzhen Municipality, China; NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Yongsheng Pan and Yong Xia was partially supported by the National Natural Science Foundation of China under Grant 61771397, the Science and Technology Innovation Committee of Shenzhen Municipality, China, under Grant JCYJ20180306171334997. M. Liu was partially supported by NIH under Grant AG041721. Part of the data used in this paper were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. The investigators within the ADNI contributed to the design and implementation of ADNI and provided data but did not participate in analysis or writing of this article.	Arjovsky M, 2017, PR MACH LEARN RES, V70; Bano S, 2018, LECT NOTES COMPUT SC, V11121, P129, DOI 10.1007/978-3-030-00320-3_16; Baron JC, 2001, NEUROIMAGE, V14, P298, DOI 10.1006/nimg.2001.0848; Ben-Cohen A, 2019, ENG APPL ARTIF INTEL, V78, P186, DOI 10.1016/j.engappai.2018.11.013; Calhoun Vince D, 2016, Biol Psychiatry Cogn Neurosci Neuroimaging, V1, P230; Chen X, 2016, ADV NEUR IN, V29; Cheng B, 2015, IEEE T BIO-MED ENG, V62, P1805, DOI 10.1109/TBME.2015.2404809; Cohen JP, 2018, LECT NOTES COMPUT SC, V11070, P529, DOI 10.1007/978-3-030-00928-1_60; Coupe P, 2012, NEUROIMAGE, V59, P3736, DOI 10.1016/j.neuroimage.2011.10.080; Cui RX, 2019, IEEE J BIOMED HEALTH, V23, P2099, DOI 10.1109/JBHI.2018.2882392; Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013; Ellis KA, 2009, INT PSYCHOGERIATR, V21, P672, DOI 10.1017/S1041610209009405; Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049; Jog A, 2013, I S BIOMED IMAGING, P350; Kingma D.P, P 3 INT C LEARNING R; Koyejo O., 2014, ADV NEURAL INFORM PR, V3, P2744; Kurth F, 2015, NAT PROTOC, V10, P293, DOI 10.1038/nprot.2015.014; Li GN, 2018, LECT NOTES COMPUT SC, V11046, P303, DOI 10.1007/978-3-030-00919-9_35; Li RJ, 2014, LECT NOTES COMPUT SC, V8675, P305, DOI 10.1007/978-3-319-10443-0_39; Lian CF, 2020, IEEE T PATTERN ANAL, V42, P880, DOI 10.1109/TPAMI.2018.2889096; Liu MH, 2014, HUM BRAIN MAPP, V35, P1305, DOI 10.1002/hbm.22254; Liu MH, 2012, NEUROIMAGE, V60, P1106, DOI 10.1016/j.neuroimage.2012.01.055; Liu MY, 2016, ADV NEUR IN, V29; Liu MX, 2018, IEEE J BIOMED HEALTH, V22, P1476, DOI 10.1109/JBHI.2018.2791863; Liu MX, 2018, MED IMAGE ANAL, V43, P157, DOI 10.1016/j.media.2017.10.005; Liu MX, 2017, MED IMAGE ANAL, V36, P123, DOI 10.1016/j.media.2016.11.002; Long MS, 2018, ADV NEUR IN, V31; Olut S, 2018, LECT NOTES COMPUT SC, V11121, P147, DOI 10.1007/978-3-030-00320-3_18; Pan YS, 2018, LECT NOTES COMPUT SC, V11072, P455, DOI 10.1007/978-3-030-00931-1_52; Parker R., 2010, MISSING DATA PROBLEM; Qiao T., 2019, PROC CVPR IEEE; RUSINEK H, 1991, RADIOLOGY, V178, P109, DOI 10.1148/radiology.178.1.1984287; Suk HI, 2014, NEUROIMAGE, V101, P569, DOI 10.1016/j.neuroimage.2014.06.077; Sun H., 2019, ARXIV; Thung KH, 2014, NEUROIMAGE, V91, P386, DOI 10.1016/j.neuroimage.2014.01.033; Huynh T, 2016, IEEE T MED IMAGING, V35, P174, DOI 10.1109/TMI.2015.2461533; Wachinger C, 2016, BRAIN, V139, P3253, DOI 10.1093/brain/aww243; Wang ML, 2020, IEEE T MED IMAGING, V39, P644, DOI 10.1109/TMI.2019.2933160; Wang ML, 2019, MED IMAGE ANAL, V53, P111, DOI 10.1016/j.media.2019.01.007; Wolterink J. M., 2018, ARXIV; Xiang S, 2014, NEUROIMAGE, V102, P192, DOI 10.1016/j.neuroimage.2013.08.015; Yang HR, 2018, LECT NOTES COMPUT SC, V11045, P174, DOI 10.1007/978-3-030-00889-5_20; Yi X., 2018, ARXIV; Yu LT, 2017, AAAI CONF ARTIF INTE, P2852; Yuan L, 2012, NEUROIMAGE, V61, P622, DOI 10.1016/j.neuroimage.2012.03.059; Zhang DQ, 2012, NEUROIMAGE, V59, P895, DOI 10.1016/j.neuroimage.2011.09.069; Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008; Zhang J, 2017, IEEE J BIOMED HEALTH, V21, P1607, DOI 10.1109/JBHI.2017.2704614; Zhang J, 2016, IEEE T MED IMAGING, V35, P2524, DOI 10.1109/TMI.2016.2582386; Zhou J., 2011, P 17 ACM SIGKDD INT, P814, DOI [10.1145/2020408.2020549, DOI 10.1145/2020408.2020549]; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	56	7	7	18	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6839	6853		10.1109/TPAMI.2021.3091214	http://dx.doi.org/10.1109/TPAMI.2021.3091214			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4O3KZ	34156939	Green Accepted			2022-12-18	WOS:000854602700002
J	Cao, JL; Pang, YW; Xie, J; Khan, FS; Shao, L				Cao, Jiale; Pang, Yanwei; Xie, Jin; Khan, Fahad Shahbaz; Shao, Ling			From Handcrafted to Deep Features for Pedestrian Detection: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Proposals; Cameras; Deep learning; Task analysis; Object detection; Support vector machines; Pedestrian detection; handcrafted features based methods; deep features based methods; multi-spectral pedestrian detection	NEURAL-NETWORKS; SCALE; CLASSIFICATION; LEVEL; INFORMATION; REGIONLETS; GRADIENTS; OCCLUSION; PROPOSAL; FUSION	Pedestrian detection is an important but challenging problem in computer vision, especially in human-centric tasks. Over the past decade, significant improvement has been witnessed with the help of handcrafted features and deep features. Here we present a comprehensive survey on recent advances in pedestrian detection. First, we provide a detailed review of single-spectral pedestrian detection that includes handcrafted features based methods and deep features based approaches. For handcrafted features based methods, we present an extensive review of approaches and find that handcrafted features with large freedom degrees in shape and space have better performance. In the case of deep features based approaches, we split them into pure CNN based methods and those employing both handcrafted and CNN based features. We give the statistical analysis and tendency of these methods, where feature enhanced, part-aware, and post-processing methods have attracted main attention. In addition to single-spectral pedestrian detection, we also review multi-spectral pedestrian detection, which provides more robust features for illumination variance. Furthermore, we introduce some related datasets and evaluation metrics, and a deep experimental analysis. We conclude this survey by emphasizing open problems that need to be addressed and highlighting various future directions. Researchers can track an up-to-date list at https://github.com/JialeCao001/PedSurvey.	[Cao, Jiale; Pang, Yanwei; Xie, Jin] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China; [Khan, Fahad Shahbaz] Mohamed bin Zayed Univ Artificial Intelligence, Abu Dhabi 51133, U Arab Emirates; [Khan, Fahad Shahbaz] Linkoping Univ, S-58183 Linkoping, Sweden; [Shao, Ling] Incept Inst Artificial Intelligence, Abu Dhabi 51133, U Arab Emirates	Tianjin University; Mohamed Bin Zayed University of Artificial Intelligence; Linkoping University	Pang, YW (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.	connor@tju.edu.cn; pyw@tju.edu.cn; jinxie@tju.edu.cn; fithad.khan@mbzuainc.ae; ling.shao@ieee.org	Khan, Fahad Shahbaz/ABD-6646-2021	Khan, Fahad Shahbaz/0000-0002-4263-3143; Chan, Samantha Wei Ting/0000-0003-1159-0467; Xie, Jin/0000-0001-6978-8834	National Key Research and Development Program of China [2018AAA0102800]; National Natural Science Foundation of China [61906131, 61632018]; VR starting grant [2016-05543]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); VR starting grant	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0102800 and in part by the National Natural Science Foundation of China under Grants 61906131 and 61632018, and in part by VR starting grant (2016-05543).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Angelova A., 2015, PROC BRIT MACH VIS C, P1, DOI DOI 10.5244/C.29.32; Baek J, 2020, IEEE T INTELL TRANSP, V21, P1216, DOI 10.1109/TITS.2019.2904836; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47; Benenson R, 2013, PROC CVPR IEEE, P3666, DOI 10.1109/CVPR.2013.470; Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593; Boxun Li, 2018, Arxiv, DOI arXiv:1805.00123; Brazil G, 2019, PROC CVPR IEEE, P7224, DOI 10.1109/CVPR.2019.00740; Brazil G, 2017, IEEE I CONF COMP VIS, P4960, DOI 10.1109/ICCV.2017.530; Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516; Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22; Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384; Cao JL, 2020, IEEE T CIRC SYST VID, V30, P3372, DOI 10.1109/TCSVT.2019.2950526; Cao JL, 2020, IEEE T IMAGE PROCESS, V29, P3143, DOI 10.1109/TIP.2019.2957927; Cao JL, 2017, IEEE T IMAGE PROCESS, V26, P3210, DOI 10.1109/TIP.2017.2694224; Cao JL, 2016, IEEE T IMAGE PROCESS, V25, P5538, DOI 10.1109/TIP.2016.2609807; Cao YP, 2019, ISPRS J PHOTOGRAMM, V150, P70, DOI 10.1016/j.isprsjprs.2019.02.005; Cao YP, 2019, INFORM FUSION, V46, P206, DOI 10.1016/j.inffus.2018.06.005; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Chen R, 2019, IEEE IMAGE PROC, P1645, DOI 10.1109/ICIP.2019.8803079; Chen T, 2018, IEEE T PATTERN ANAL, V40, P2522, DOI 10.1109/TPAMI.2017.2756936; Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352; Chen Z., 2019, ARXIV; Chen ZC, 2019, IEEE ACCESS, V7, P21981, DOI 10.1109/ACCESS.2019.2896201; Chen ZL, 2019, IEEE T INTELL VEHICL, V4, P211, DOI 10.1109/TIV.2019.2904389; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Chenhongyi Yang, 2020, Arxiv, DOI arXiv:1912.01674; Chi C, 2020, AAAI CONF ARTIF INTE, V34, P10647; Chi C, 2020, AAAI CONF ARTIF INTE, V34, P10639; Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Costea AD, 2017, PROC CVPR IEEE, P993, DOI 10.1109/CVPR.2017.112; Costea AD, 2016, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2016.259; Dai JF, 2016, ADV NEUR IN, V29; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Dollar P., 2010, P BRIT MACH VIS C, DOI [10.5244/C.24.68, DOI 10.5244/C.24.68]; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2012, LECT NOTES COMPUT SC, V7573, P645, DOI 10.1007/978-3-642-33709-3_46; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Du XZ, 2017, IEEE WINT CONF APPL, P953, DOI 10.1109/WACV.2017.111; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Ess A, 2007, IEEE I CONF COMP VIS, P2065; Fahad Shahbaz Khan, 2020, Arxiv, DOI arXiv:2001.09252; Fei C, 2019, IEEE ACCESS, V7, P94944, DOI 10.1109/ACCESS.2019.2928879; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fu XC, 2018, IEEE ACCESS, V6, P14223, DOI 10.1109/ACCESS.2018.2803160; Gajjar V, 2018, IEEE COMPUT SOC CONF, P1989, DOI 10.1109/CVPRW.2018.00256; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Geronimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122; Ghose D, 2019, IEEE COMPUT SOC CONF, P988, DOI 10.1109/CVPRW.2019.00130; Girshick R., 2014, PROC IEEE C COMPUT V; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gonzalez A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060820; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gualdi G, 2012, IEEE T PATTERN ANAL, V34, P1589, DOI 10.1109/TPAMI.2011.247; Guan DY, 2019, IEEE COMPUT SOC CONF, P434, DOI 10.1109/CVPRW.2019.00057; Guan DY, 2019, INFORM FUSION, V50, P148, DOI 10.1016/j.inffus.2018.11.017; Guo TT, 2019, IEEE IMAGE PROC, P1660, DOI 10.1109/ICIP.2019.8803104; Han B, 2020, IEEE T INTELL TRANSP, V21, P3046, DOI 10.1109/TITS.2019.2923752; Han CC, 2019, IEEE I CONF COMP VIS, P9813, DOI 10.1109/ICCV.2019.00991; Hasan I, 2021, PROC CVPR IEEE, P11323, DOI 10.1109/CVPR46437.2021.01117; Hattori H, 2018, INT J COMPUT VISION, V126, P1027, DOI 10.1007/s11263-018-1077-3; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685; Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034; Hsu HK, 2020, IEEE WINT CONF APPL, P738, DOI 10.1109/WACV45572.2020.9093358; Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hu QC, 2018, IEEE T CIRC SYST VID, V28, P1358, DOI 10.1109/TCSVT.2017.2648850; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huimin Ma, 2019, Arxiv, DOI arXiv:1911.11985; Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706; Jafari OH, 2016, IEEE INT CONF ROBOT, P5520, DOI 10.1109/ICRA.2016.7487767; Jialian Wu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13427, DOI 10.1109/CVPR42600.2020.01344; Jiang XH, 2018, IEEE T NEUR NET LEAR, V29, P2684, DOI 10.1109/TNNLS.2017.2689098; Jiang XH, 2016, NEUROCOMPUTING, V185, P163, DOI 10.1016/j.neucom.2015.12.042; Jin Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P88, DOI 10.1007/978-3-030-58520-4_6; Jun-Jie Huang, 2019, Arxiv, DOI arXiv:1912.08661; Jung SI, 2017, IEEE IMAGE PROC, P156; Jung SI, 2017, PATTERN RECOGN LETT, V90, P43, DOI 10.1016/j.patrec.2017.02.018; Junhao Hu, 2019, 2019 IEEE International Conference on Multimedia and Expo (ICME). Proceedings, P1138, DOI 10.1109/ICME.2019.00199; Kailai Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P787, DOI 10.1007/978-3-030-58523-5_46; Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450; Khan FS, 2015, IEEE T IMAGE PROCESS, V24, P4422, DOI 10.1109/TIP.2015.2465147; Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068; Khodabandeh M, 2019, IEEE I CONF COMP VIS, P480, DOI 10.1109/ICCV.2019.00057; Kim T, 2019, PROC CVPR IEEE, P12448, DOI 10.1109/CVPR.2019.01274; Kishore P., 2019, P BMVC, P245; Koenig D, 2017, IEEE COMPUT SOC CONF, P243, DOI 10.1109/CVPRW.2017.36; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Ku J, 2019, PROC CVPR IEEE, P11859, DOI 10.1109/CVPR.2019.01214; Li C., 2018, P BRIT MACH VIS C BM; Li C, 2017, NEUROCOMPUTING, V238, P420, DOI 10.1016/j.neucom.2017.01.084; Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005; Li GF, 2020, IEEE T IND ELECTRON, V67, P8889, DOI 10.1109/TIE.2019.2945295; Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520; Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508; Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211; Li QM, 2017, IEEE T INTELL TRANSP, V18, P1549, DOI 10.1109/TITS.2016.2612705; Li QQ, 2017, PROC CVPR IEEE, P7341, DOI 10.1109/CVPR.2017.776; Li XZ, 2018, IEEE IMAGE PROC, P958, DOI 10.1109/ICIP.2018.8451791; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Lin CY, 2019, IEEE ACCESS, V7, P47687, DOI 10.1109/ACCESS.2019.2910201; Lin CZ, 2018, LECT NOTES COMPUT SC, V11213, P745, DOI 10.1007/978-3-030-01240-3_45; Lin CZ, 2019, IEEE T CIRC SYST VID, V29, P3608, DOI 10.1109/TCSVT.2018.2883558; Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu J., 2016, ARXIV PREPRINT ARXIV, DOI DOI 10.5244/C.30.73; Liu ST, 2019, PROC CVPR IEEE, P6452, DOI [10.1109/CVPR.2019.00662, 10.1109/CVPR.2019.01055]; Liu T, 2018, ARXIV180802246; Liu W, 2018, LECT NOTES COMPUT SC, V11218, P643, DOI 10.1007/978-3-030-01264-9_38; Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533; Liu X, 2020, IEEE T INTELL TRANSP, V21, P1441, DOI 10.1109/TITS.2019.2910093; Lopez A., 2019, DOMAIN ADAPTATION OB; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu RQ, 2019, IEEE IMAGE PROC, P1640, DOI 10.1109/ICIP.2019.8803090; Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374; Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120; Luo Y., 2020, PROC EUR C COMPUT VI, P14065; Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639; Mathias M, 2013, IEEE I CONF COMP VIS, P1505, DOI 10.1109/ICCV.2013.190; Lin MTU, 2020, Arxiv, DOI arXiv:2012.06785; My Kieu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P546, DOI 10.1007/978-3-030-58542-6_33; Nam W, 2014, ADV NEUR IN, V27; NEUMANN L, 2019, LECT NOTES COMPUT SC, V1361, P691, DOI DOI 10.1007/978-3-030-20887-5_43; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Noh J, 2018, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2018.00107; Oh SJ, 2020, IEEE T PATTERN ANAL, V42, P203, DOI 10.1109/TPAMI.2018.2877588; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ouyang WL, 2018, IEEE T PATTERN ANAL, V40, P1874, DOI 10.1109/TPAMI.2017.2738645; Ouyang WL, 2017, IEEE T PATTERN ANAL, V39, P1320, DOI 10.1109/TPAMI.2016.2587642; Ouyang WL, 2015, IEEE T PATTERN ANAL, V37, P1875, DOI 10.1109/TPAMI.2014.2377734; Ouyang WL, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.299; Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257; Ouyang WL, 2013, PROC CVPR IEEE, P3198, DOI 10.1109/CVPR.2013.411; Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062; Paisitkriangkrai S, 2016, IEEE T PATTERN ANAL, V38, P1243, DOI 10.1109/TPAMI.2015.2474388; Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36; Pang YW, 2021, IEEE T IMAGE PROCESS, V30, P207, DOI 10.1109/TIP.2020.3034487; Pang YW, 2019, IEEE I CONF COMP VIS, P4229, DOI 10.1109/ICCV.2019.00433; Pang YW, 2019, IEEE T INF FOREN SEC, V14, P3322, DOI 10.1109/TIFS.2019.2916592; Pang YW, 2017, IEEE T CYBERNETICS, V47, P117, DOI 10.1109/TCYB.2015.2508603; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Park D, 2013, PROC CVPR IEEE, P2882, DOI 10.1109/CVPR.2013.371; Park D, 2010, LECT NOTES COMPUT SC, V6314, P241, DOI 10.1007/978-3-642-15561-1_18; Park K, 2018, PATTERN RECOGN, V80, P143, DOI 10.1016/j.patcog.2018.03.007; Peng XS, 2019, IEEE WINT CONF APPL, P561, DOI 10.1109/WACV.2019.00065; Qian YQ, 2020, IEEE T MULTIMEDIA, V22, P421, DOI 10.1109/TMM.2019.2929949; Radosavovic I., 2020, 2020 IEEE CVF C COMP, P10428, DOI 10.1109/cvpr42600.2020.01044; Ragesh NK, 2019, IEEE ACCESS, V7, P47864, DOI 10.1109/ACCESS.2019.2909992; Rajaram RN, 2016, IEEE T INTELL TRANSP, V17, P3565, DOI 10.1109/TITS.2016.2561262; Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren J, 2017, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2017.87; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ribeiro D, 2017, PATTERN RECOGN, V61, P641, DOI 10.1016/j.patcog.2016.05.027; Rogez G, 2020, IEEE T PATTERN ANAL, V42, P1146, DOI 10.1109/TPAMI.2019.2892985; RuihaoYin, 2019, IEEE IMAGE PROC, P1665, DOI 10.1109/ICIP.2019.8803030; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saito K, 2019, PROC CVPR IEEE, P6949, DOI 10.1109/CVPR.2019.00712; Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465; Shang C., 2018, PROC ASIAN C MACH LE, P486; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shen JF, 2019, IEEE T INTELL TRANSP, V20, P2913, DOI 10.1109/TITS.2018.2869087; Shen JF, 2019, IEEE T INTELL TRANSP, V20, P2085, DOI 10.1109/TITS.2018.2857814; Shen JF, 2017, PATTERN RECOGN, V63, P127, DOI 10.1016/j.patcog.2016.09.010; Sheng BY, 2017, NEUROCOMPUTING, V249, P19, DOI 10.1016/j.neucom.2017.03.007; Song T, 2018, LECT NOTES COMPUT SC, V11211, P554, DOI 10.1007/978-3-030-01234-2_33; Song X., 2020, P ECCV, P32; Stewart R, 2016, PROC CVPR IEEE, P2325, DOI 10.1109/CVPR.2016.255; Tesema FB, 2020, NEUROCOMPUTING, V389, P1, DOI 10.1016/j.neucom.2019.12.110; Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221; Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143; Trichet R, 2018, IEEE WINT CONF APPL, P1066, DOI 10.1109/WACV.2018.00122; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Ujjwal, 2020, IEEE WINT CONF APPL, P765, DOI 10.1109/WACV45572.2020.9093477; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Vobecky A, 2019, IEEE INT CONF COMP V, P2367, DOI 10.1109/ICCVW.2019.00290; Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102; Wang H, 2020, IEEE T INTELL TRANSP, V21, P5086, DOI 10.1109/TITS.2019.2948398; Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308; Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686; Wang L, 2016, IEEE IMAGE PROC, P1210, DOI 10.1109/ICIP.2016.7532550; Wang SG, 2018, IEEE T MULTIMEDIA, V20, P3148, DOI 10.1109/TMM.2018.2829602; Wang SL, 2017, ADV SOC SCI EDUC HUM, V101, P341; Wang T, 2019, PROC CVPR IEEE, P7166, DOI 10.1109/CVPR.2019.00734; Wang X, 2020, IEEE T CIRC SYST VID, V30, P3332, DOI 10.1109/TCSVT.2019.2913114; Wang XY, 2015, IEEE T PATTERN ANAL, V37, P2071, DOI 10.1109/TPAMI.2015.2389830; Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Wang XL, 2018, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2018.00811; Wang XY, 2020, IEEE T CIRC SYST VID, V30, P2663, DOI 10.1109/TCSVT.2019.2924912; Wei J, 2020, IEEE T INTELL TRANSP, V21, P1572, DOI 10.1109/TITS.2019.2910643; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638; Wu, 2015, PROC BRIT MACH VIS C; Wu CH, 2017, IEEE WINT CONF APPL, P540, DOI 10.1109/WACV.2017.66; Wu J., 2019, BRIT MACH VIS C; Wu JL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2012, DOI 10.1145/3394171.3413634; Wu S, 2020, IEEE T IMAGE PROCESS, V29, P1562, DOI 10.1109/TIP.2019.2944306; Wu S, 2018, IEEE T IMAGE PROCESS, V27, P1418, DOI 10.1109/TIP.2017.2779271; Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108; Xie RC, 2019, IEEE INT CONF COMP V, P3213, DOI 10.1109/ICCVW.2019.00401; Xin Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10747, DOI 10.1109/CVPR42600.2020.01076; Xu D, 2017, PROC CVPR IEEE, P4236, DOI 10.1109/CVPR.2017.451; Xu M., 2019, PROC IEEE C COMPUT V, P45; Xuangeng Chu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12211, DOI 10.1109/CVPR42600.2020.01223; Yan JJ, 2013, PROC CVPR IEEE, P3033, DOI 10.1109/CVPR.2013.390; Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226; Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18; Yang F, 2019, IEEE ACCESS, V7, P15478, DOI 10.1109/ACCESS.2019.2895376; Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596; Ye M, 2020, IEEE T INF FOREN SEC, V15, P2655, DOI 10.1109/TIFS.2020.2970590; Ye M, 2018, LECT NOTES COMPUT SC, V11211, P176, DOI 10.1007/978-3-030-01234-2_11; You MY, 2018, IEEE T INTELL TRANSP, V19, P1640, DOI 10.1109/TITS.2018.2807199; Yu XH, 2020, IEEE WINT CONF APPL, P1246, DOI 10.1109/WACV45572.2020.9093394; Yun I, 2019, IEEE ACCESS, V7, P23027, DOI 10.1109/ACCESS.2019.2899105; Zhang C, 2019, PROC CVPR IEEE, P9444, DOI 10.1109/CVPR.2019.00968; Zhang H, 2018, IEEE T VEH TECHNOL, V67, P8019, DOI 10.1109/TVT.2018.2843394; Zhang K., 2019, ARXIV; Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28; Zhang L, 2019, IEEE I CONF COMP VIS, P5126, DOI 10.1109/ICCV.2019.00523; Zhang L, 2019, INFORM FUSION, V50, P20, DOI 10.1016/j.inffus.2018.09.015; Zhang SS, 2018, IEEE T PATTERN ANAL, V40, P973, DOI 10.1109/TPAMI.2017.2700460; Zhang SS, 2017, PROC CVPR IEEE, P4457, DOI 10.1109/CVPR.2017.474; Zhang SS, 2016, PROC CVPR IEEE, P1259, DOI 10.1109/CVPR.2016.141; Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784; Zhang SS, 2015, IEEE T CIRC SYST VID, V25, P1709, DOI 10.1109/TCSVT.2015.2397199; Zhang SS, 2014, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2014.126; Zhang SF, 2020, IEEE T MULTIMEDIA, V22, P380, DOI 10.1109/TMM.2019.2929005; Zhang SF, 2018, LECT NOTES COMPUT SC, V11207, P657, DOI 10.1007/978-3-030-01219-9_39; Zhang SQ, 2018, IEEE IMAGE PROC, P584, DOI 10.1109/ICIP.2018.8451206; Zhang TL, 2020, IEEE T INTELL TRANSP, V21, P4593, DOI 10.1109/TITS.2019.2942045; Zhang XW, 2018, IEEE T IMAGE PROCESS, V27, P3703, DOI 10.1109/TIP.2018.2818018; Zhao C., 2019, PATTERN RECOGN, V100; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zhao Y., 2018, PROC BRIT MACH VIS C; Zhao Y, 2020, IEEE T INTELL TRANSP, V21, P3777, DOI 10.1109/TITS.2019.2933581; Zhao Y, 2020, IEEE T IMAGE PROCESS, V29, P1591, DOI 10.1109/TIP.2019.2942686; Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644; Zhou CJ, 2020, IEEE T INTELL TRANSP, V21, P5022, DOI 10.1109/TITS.2019.2948044; Zhou CL, 2019, IEEE I CONF COMP VIS, P9556, DOI 10.1109/ICCV.2019.00965; Zhou CL, 2017, IEEE I CONF COMP VIS, P3506, DOI 10.1109/ICCV.2017.377; Zhu C, 2017, NEUROCOMPUTING, V238, P126, DOI 10.1016/j.neucom.2017.01.043; Zhu XG, 2019, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2019.00078; Zhu Y., 2016, P AS C COMP VIS, P416; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26; Zou TT, 2020, PATTERN RECOGN LETT, V131, P91, DOI 10.1016/j.patrec.2019.12.010	264	7	7	16	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4913	4934		10.1109/TPAMI.2021.3076733	http://dx.doi.org/10.1109/TPAMI.2021.3076733			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33929956	Green Submitted			2022-12-18	WOS:000836666600033
J	Wang, WH; Xie, EZ; Li, X; Liu, XB; Liang, D; Zhibo, Y; Lu, T; Shen, CH				Wang, Wenhai; Xie, Enze; Li, Xiang; Liu, Xuebo; Liang, Ding; Zhibo, Yang; Lu, Tong; Shen, Chunhua			PAN plus plus : Towards Efficient and Accurate End-to-End Spotting of Arbitrarily-Shaped Text	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel; Text recognition; Feature extraction; Head; Magnetic heads; Electronic mail; Detectors; End-to-end text spotting; text detection; kernel representation; segmentation		Scene text detection and recognition have been well explored in the past few years. Despite the progress, efficient and accurate end-to-end spotting of arbitrarily-shaped text remains challenging. In this work, we propose an end-to-end text spotting framework, termed PAN++, which can efficiently detect and recognize text of arbitrary shapes in natural scenes. PAN++ is based on the kernel representation that reformulates a text line as a text kernel (central region) surrounded by peripheral pixels. By systematically comparing with existing scene text representations, we show that our kernel representation can not only describe arbitrarily-shaped text but also well distinguish adjacent text. Moreover, as a pixel-based representation, the kernel representation can be predicted by a single fully convolutional network, which is very friendly to real-time applications. Taking the advantages of the kernel representation, we design a series of components as follows: 1) a computationally efficient feature enhancement network composed of stacked Feature Pyramid Enhancement Modules (FPEMs); 2) a lightweight detection head cooperating with Pixel Aggregation (PA); and 3) an efficient attention-based recognition head with Masked RoI. Benefiting from the kernel representation and the tailored components, our method achieves high inference speed while maintaining competitive accuracy. Extensive experiments show the superiority of our method. For example, the proposed PAN++ achieves an end-to-end text spotting F-measure of 64.9 at 29.2 FPS on the Total-Text dataset, which significantly outperforms the previous best method. Code will be available at: git.io/PAN.	[Wang, Wenhai; Lu, Tong] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China; [Xie, Enze] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; [Li, Xiang] Nanjing Univ Sci & Technol, Pattern Recognit & Intelligent Syst, Nanjing 210094, Jiangsu, Peoples R China; [Liu, Xuebo; Liang, Ding] SenseTime Grp Ltd, Beijing 100080, Peoples R China; [Zhibo, Yang] Alibaba Grp, Machine Intelligence Technol Dept, DAMO, Hangzhou 310052, Zhejiang, Peoples R China; [Shen, Chunhua] Monash Univ, Clayton, Vic 3800, Australia	Nanjing University; University of Hong Kong; Nanjing University of Science & Technology; Alibaba Group; Monash University	Lu, T (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.	wangwenhai362@smail.nju.edu.cn; xieenze@hku.hk; xiang.li.implus@njust.edu.cn; liuxuebo@sensetime.com; liangding@sensetime.com; zhibo.yzb@alibaba-inc.com; lutong@nju.edu.cn; chunhua@me.com	wang, wenhai/GUX-3226-2022		Natural Science Foundation of China [61672273, 61832008]; Science Foundation for Distinguished Young Scholars of Jiangsu [BK20160021]; Alibaba Group through Alibaba Innovative Research (AIR) Program	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science Foundation for Distinguished Young Scholars of Jiangsu(National Natural Science Foundation of China (NSFC)National Science Fund for Distinguished Young Scholars); Alibaba Group through Alibaba Innovative Research (AIR) Program	This work was supported by the Natural Science Foundation of China under Grant 61672273 and Grant 61832008, the Science Foundation for Distinguished Young Scholars of Jiangsu under Grant BK20160021. This work was also supported in part by Alibaba Group through Alibaba Innovative Research (AIR) Program. W. Wang and E. Xie contributed equally to this work.	Andrew G. Howard, 2017, Arxiv, DOI arXiv:1704.04861; Ba J., 2017, P 3 INT C LEARN REPR; Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959; Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102; Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242; Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157; Cheng ZZ, 2018, PROC CVPR IEEE, P5571, DOI 10.1109/CVPR.2018.00584; Deng D, 2018, AAAI CONF ARTIF INTE, P6773; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; NguyenVan D, 2019, PATTERN RECOGN, V87, P118, DOI 10.1016/j.patcog.2018.10.012; Feng W, 2019, IEEE I CONF COMP VIS, P9075, DOI 10.1109/ICCV.2019.00917; Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720; Gomez R, 2017, PROC INT CONF DOC, P1435, DOI 10.1109/ICDAR.2017.234; Graves A., 2006, P INT C MACH LEARN I; Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331; He P, 2016, AAAI CONF ARTIF INTE, P3501; He T, 2018, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR.2018.00527; He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Ioffe S., 2015, JMLR; Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34; Jin Lianwen, 2017, Arxiv, DOI arXiv:1712.02170; Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li H, 2019, AAAI CONF ARTIF INTE, P8610; Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560; Liao MH, 2021, IEEE T PATTERN ANAL, V43, P532, DOI 10.1109/TPAMI.2019.2937086; Liao MH, 2018, PROC CVPR IEEE, P5909, DOI 10.1109/CVPR.2018.00619; Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107; Liao MH, 2017, AAAI CONF ARTIF INTE, P4161; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595; Liu ZC, 2018, PROC CVPR IEEE, P6936, DOI 10.1109/CVPR.2018.00725; Long J., 2015, P IEEE C COMPUTER VI, P3431, DOI DOI 10.1109/CVPR.2015.7298965; Long SB, 2018, LECT NOTES COMPUT SC, V11206, P19, DOI 10.1007/978-3-030-01216-8_2; Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788; Lyu PY, 2018, LECT NOTES COMPUT SC, V11218, P71, DOI 10.1007/978-3-030-01264-9_5; Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; Nayef N, 2017, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2017.237; Qin SY, 2019, IEEE I CONF COMP VIS, P4703, DOI 10.1109/ICCV.2019.00480; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939; Shi BG, 2017, PROC INT CONF DOC, P1429, DOI 10.1109/ICDAR.2017.233; Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371; Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Simonyan Karen, 2015, VERY DEEP CONVOLUTIO; Su BL, 2017, PATTERN RECOGN, V63, P397, DOI 10.1016/j.patcog.2016.10.016; Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3; Sun YP, 2019, LECT NOTES COMPUT SC, V11363, P83, DOI 10.1007/978-3-030-20893-6_6; Tian SX, 2015, IEEE I CONF COMP VIS, P4651, DOI 10.1109/ICCV.2015.528; Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4; Vaswani A, 2017, ADV NEUR IN, V30; VATTI BR, 1992, COMMUN ACM, V35, P56, DOI 10.1145/129902.129906; Wang WH, 2019, IEEE I CONF COMP VIS, P8439, DOI 10.1109/ICCV.2019.00853; Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956; Xing LJ, 2019, IEEE I CONF COMP VIS, P9125, DOI 10.1109/ICCV.2019.00922; Xu YC, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2900589; Xue CH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P989; Yang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3280; Yao C, 2014, IEEE T IMAGE PROCESS, V23, P4737, DOI 10.1109/TIP.2014.2353813; Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787; Yuliang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9806, DOI 10.1109/CVPR42600.2020.00983; Zhan FN, 2019, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2019.00216; Zhang CQ, 2019, PROC CVPR IEEE, P10544, DOI 10.1109/CVPR.2019.01080; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283	74	7	7	13	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5349	5367		10.1109/TPAMI.2021.3077555	http://dx.doi.org/10.1109/TPAMI.2021.3077555			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN		Green Submitted			2022-12-18	WOS:000836666600061
J	Zhou, OETY; Le, Z; Du, JW; Xi, P; Fang, ZW; Zhe, X; Zhu, HY				Zhou, Joey Tianyi; Le Zhang; Du Jiawei; Xi Peng; Fang, Zhiwen; Zhe Xiao; Zhu, Hongyuan			Locality-Aware Crowd Counting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Training data; Computer architecture; Task analysis; Feature extraction; Data models; Optimization; Long-tail distribution; data-imbalance learning; data augmentation; crowd counting; adversarial defense	SEGMENTATION; TRACKING; MULTIPLE; HUMANS; PEOPLE	Imbalanced data distribution in crowd counting datasets leads to severe under-estimation and over-estimation problems, which has been less investigated in existing works. In this paper, we tackle this challenging problem by proposing a simple but effective locality-based learning paradigm to produce generalizable features by alleviating sample bias. Our proposed method is locality-aware in two aspects. First, we introduce a locality-aware data partition (LADP) approach to group the training data into different bins via locality-sensitive hashing. As a result, a more balanced data batch is then constructed by LADP. To further reduce the training bias and enhance the collaboration with LADP, a new data augmentation method called locality-aware data augmentation (LADA) is proposed where the image patches are adaptively augmented based on the loss. The proposed method is independent of the backbone network architectures, and thus could be smoothly integrated with most existing deep crowd counting approaches in an end-to-end paradigm to boost their performance. We also demonstrate the versatility of the proposed method by applying it for adversarial defense. Extensive experiments verify the superiority of the proposed method over the state of the arts.	[Zhou, Joey Tianyi; Du Jiawei; Zhe Xiao] ASTAR, Inst High Performance Comp IHPC, Singapore 138632, Singapore; [Le Zhang; Zhu, Hongyuan] ASTAR, Inst Infoccmun Res I2R, Singapore 138632, Singapore; [Xi Peng] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China; [Fang, Zhiwen] Southern Med Univ, Sch Biomed Engn, Guangzhou 510515, Peoples R China	Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC); Agency for Science Technology & Research (A*STAR); Sichuan University; Southern Medical University - China	Le, Z (corresponding author), ASTAR, Inst Infoccmun Res I2R, Singapore 138632, Singapore.	joey.tianyi.zhou@gmail.com; lzhang027@ntu.edu.sg; dujw@ihpc.a-star.edu.sg; pengx.gm@gmail.com; fzw310@sina.com; xiaoz@ihpc.a-star.edu.sg; zhuh@i2r.a-star.edu.sg			Fundamental Research Funds for the Central Universities [YJ201949]; Singapore government's Research, Innovation and Enterprise 2020 plan (Advanced Manufacturing and Engineering domain) [A18A1b0045, A1687b0033]; NFSC [61702182, U19A2081, 61625204, 61836006]	Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Singapore government's Research, Innovation and Enterprise 2020 plan (Advanced Manufacturing and Engineering domain); NFSC(National Natural Science Foundation of China (NSFC))	This work was supported by the Fundamental Research Funds for the Central Universities under Grant YJ201949, programmatic Grants A18A1b0045 and A1687b0033 from the Singapore government's Research, Innovation and Enterprise 2020 plan (Advanced Manufacturing and Engineering domain), and by NFSC under Grants 61702182, U19A2081, 61625204, and 61836006.	Andoni Alexandr, 2015, ADV NEURAL INFORM PR, P1225; Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300; Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45; Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569; Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21; Coates Adam, 2011, AISTATS, V6, DOI DOI 10.1177/1753193410390845; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deb D, 2018, IEEE COMPUT SOC CONF, P308, DOI 10.1109/CVPRW.2018.00057; Dong YP, 2020, PROC CVPR IEEE, P318, DOI 10.1109/CVPR42600.2020.00040; Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kumagai S, 2018, MACH VISION APPL, V29, P1119, DOI 10.1007/s00138-018-0955-6; Lempitsky V., 2010, NIPS, V23, P1324; LEONE FC, 1961, TECHNOMETRICS, V3, P543, DOI 10.2307/1266560; Li M, 2008, INT C PATT RECOG, P1998; Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120; Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545; Liu LB, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P849; Liu XL, 2018, PROC CVPR IEEE, P7661, DOI 10.1109/CVPR.2018.00799; Liu ZH, 2017, AAAI CONF ARTIF INTE, P2301; Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624; Madry A., 2018, ARXIV PREPRINT ARXIV; MANDELBROT B, 1960, INT ECON REV, V1, P79, DOI 10.2307/2525289; Onoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38; Prakash A, 2018, PROC CVPR IEEE, P8571, DOI 10.1109/CVPR.2018.00894; Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17; Ryan D, 2015, COMPUT VIS IMAGE UND, V130, P1, DOI 10.1016/j.cviu.2014.07.008; Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381; Shang C, 2016, IEEE IMAGE PROC, P1215, DOI 10.1109/ICIP.2016.7532551; Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550; Sheng BY, 2018, IEEE T CIRC SYST VID, V28, P1788, DOI 10.1109/TCSVT.2016.2637379; Shi ZL, 2018, PROC CVPR IEEE, P5382, DOI 10.1109/CVPR.2018.00564; Shi ZL, 2018, IEEE T IND INFORM, V14, P4953, DOI 10.1109/TII.2018.2852481; Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206; Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372; Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41; Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01; Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839; Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920; Wang Y, 2016, IEEE IMAGE PROC, P3653, DOI 10.1109/ICIP.2016.7533041; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Xie CY, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2809731; Yu Fisher, 2016, MULTISCALE CONTEXT A; Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684; Zhang L, 2021, IEEE T PATTERN ANAL, V43, P982, DOI 10.1109/TPAMI.2019.2943860; Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70; Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770	53	7	7	8	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3602	3613		10.1109/TPAMI.2021.3056518	http://dx.doi.org/10.1109/TPAMI.2021.3056518			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33534703				2022-12-18	WOS:000805820500020
J	Lin, J; Gan, C; Wang, K; Han, S				Lin, Ji; Gan, Chuang; Wang, Kuan; Han, Song			TSM: Temporal Shift Module for Efficient and Scalable Video Understanding on Edge Devices	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Two dimensional displays; Computational modeling; Three-dimensional displays; Convolution; Streaming media; Training; Solid modeling; Temporal shift module; video recognition; video object detection; distributed training; edge device; network dissection		The explosive growth in video streaming requires video understanding at high accuracy and low computation cost. Conventional 2D CNNs are computationally cheap but cannot capture temporal relationships; 3D CNN based methods can achieve good performance but are computationally intensive. In this paper, we propose a generic and effective Temporal Shift Module (TSM) that enjoys both high efficiency and high performance. The key idea of TSM is to shift part of the channels along the temporal dimension, thus facilitate information exchanged among neighboring frames. It can be inserted into 2D CNNs to achieve temporal modeling at zero computation and zero parameters. TSM offers several unique advantages. First, TSM has high performance; it ranks the first on the Something-Something leaderboard upon submission. Second, TSM has high efficiency; it achieves a high frame rate of 74fps and 29fps for online video recognition on Jetson Nano and Galaxy Note8. Third, TSM has higher scalability compared to 3D networks, enabling large-scale Kinetics training on 1,536 GPUs in 15 minutes. Lastly, TSM enables action concepts learning, which 2D networks cannot model; we visualize the category attention map and find that spatial-temporal action detector emerges during the training of classification tasks. The code is publicly available at https://github.com/mit-han-lab/temporal-shift-module.	[Lin, Ji; Wang, Kuan; Han, Song] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA; [Gan, Chuang] MIT, IBM Watson AI Lab, Cambridge, MA 02142 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Gan, C (corresponding author), MIT, IBM Watson AI Lab, Cambridge, MA 02142 USA.	jilin@mit.edu; ganchuang@csail.mit.edu; kuanwang@mit.edu; songhan@mit.edu			MIT Quest for Intelligence; MIT-IBM Watson AI Lab; MIT-SenseTime Alliance; Samsung; SONY; AWS; Google	MIT Quest for Intelligence; MIT-IBM Watson AI Lab(International Business Machines (IBM)); MIT-SenseTime Alliance; Samsung(Samsung); SONY; AWS; Google(Google Incorporated)	We thank MIT Quest for Intelligence, MIT-IBM Watson AI Lab, MIT-SenseTime Alliance, Samsung, SONY, AWS, Google for supporting this research. We thank Oak Ridge National Lab for Summit supercomputer. We thank John Cohn for the support for our work.	Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354; Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331; Cai Han, 2019, INT C LEARN REPR; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579; Chetlur S., 2014, ARXIV; Dai Jifeng, 2016, ADV NEURAL INFORM PR, P379, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Feichtenhofer Christoph, 2016, P ADV NEUR INF PROC; Gan C, 2016, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2016.106; Gan C, 2016, LECT NOTES COMPUT SC, V9907, P849, DOI 10.1007/978-3-319-46487-9_52; Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872; Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337; Goyal P., 2017, ARXIV 170602677; Goyal R., 2017, PROC IEEE INT C COMP; Han S., 2016, P 4 INT C LEARN REPR, P1; Han Song, 2015, ADV NEURAL INFORM PR, P1135, DOI DOI 10.5555/2969239.2969366; Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48; He YH, 2019, IEEE WINT CONF APPL, P1213, DOI 10.1109/WACV.2019.00134; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Howard A.G., 2017, MOBILENETS EFFICIENT; Iandola Forrest N., 2016, SQUEEZENET ALEXNET L; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kay W., 2017, ARXIV PREPRINT ARXIV; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Lee MG, 2018, LECT NOTES COMPUT SC, V11214, P392, DOI 10.1007/978-3-030-01249-6_24; Lin J., 2019, ARXIV 191000932; Lin J, 2017, ADV NEUR IN, V30; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu C., 2018, P EUR C COMP VIS ECC, P19, DOI DOI 10.1007/978-3-030-01246-5_2; Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817; Materzynska J, 2019, IEEE INT CONF COMP V, P2874, DOI 10.1109/ICCVW.2019.00349; Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Sergeev A., 2018, ARXIV 180205799; Sharma S., 2016, P INT C LEARN REPR W; Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Soomro K., 2012, ARXIV; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2019.00293; Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675; Vazhkudai SS, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18); Wang K, 2019, PROC CVPR IEEE, P8604, DOI 10.1109/CVPR.2019.00881; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wu BC, 2018, PROC CVPR IEEE, P9127, DOI 10.1109/CVPR.2018.00951; Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhu Chenzhuo, 2016, ARXIV161201064; Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52; Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	74	7	7	5	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2760	2774		10.1109/TPAMI.2020.3029799	http://dx.doi.org/10.1109/TPAMI.2020.3029799			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33035158	Green Submitted			2022-12-18	WOS:000792921400039
J	Zhao, J				Zhao, Ji			An Efficient Solution to Non-Minimal Case Essential Matrix Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Relative pose estimation; essential manifold; non-minimal solver; robust estimation; quadratically constrained quadratic program; semidefinite programming; convex optimization	GEOMETRY; OPTIMIZATION; CONSENSUS; MOTION; SPACE	Finding relative pose between two calibrated images is a fundamental task in computer vision. Given five point correspondences, the classical five-point methods can be used to calculate the essential matrix efficiently. For the case of N (N > 5) inlier point correspondences, which is called N-point problem, existing methods are either inefficient or prone to local minima. In this paper, we propose a certifiably globally optimal and efficient solver for the N-point problem. First we formulate the problem as a quadratically constrained quadratic program (QCQP). Then a certifiably globally optimal solution to this problem is obtained by semidefinite relaxation. This allows us to obtain certifiably globally optimal solutions to the original non-convex QCQPs in polynomial time. The theoretical guarantees of the semidefinite relaxation are also provided, including tightness and local stability. To deal with outliers, we propose a robust N-point method using M-estimators. Though global optimality cannot be guaranteed for the overall robust framework, the proposed robust N-point method can achieve good performance when the outlier ratio is not high. Extensive experiments on synthetic and real-world datasets demonstrated that our N-point method is 2 similar to 3 orders of magnitude faster than state-of-the-art methods. Moreover, our robust N-point method outperforms state-of-the-art methods in terms of robustness and accuracy.	[Zhao, Ji] TuSimple, Beijing 100000, Peoples R China		Zhao, J (corresponding author), TuSimple, Beijing 100000, Peoples R China.	zhaoji84@gmail.com						Aholt C, 2012, LECT NOTES COMPUT SC, V7572, P654, DOI 10.1007/978-3-642-33718-5_47; Andersen M. S., 2015, FDN TRENDS OPTIMIZAT, V1, P241, DOI DOI 10.1561/2400000006; Anstreicher KM, 2009, J GLOBAL OPTIM, V43, P471, DOI 10.1007/s10898-008-9372-0; Black A., 1987, VISUAL RECONSTRUCTIO; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Boyd S, 2004, CONVEX OPTIMIZATION; Briales J, 2018, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2018.00023; Bugarin F, 2015, J MATH IMAGING VIS, V53, P42, DOI 10.1007/s10851-014-0545-9; Cai Q, 2019, INT J COMPUT VISION, V127, P163, DOI 10.1007/s11263-018-1136-9; Cai ZP, 2018, LECT NOTES COMPUT SC, V11216, P699, DOI 10.1007/978-3-030-01258-8_42; Chesi G, 2002, IEEE T PATTERN ANAL, V24, P397, DOI 10.1109/34.990139; Chesi G, 2009, IEEE T PATTERN ANAL, V31, P370, DOI 10.1109/TPAMI.2008.198; Chin T.-J., 2017, THEMAXIMUMCONSENSUS; Chin TJ, 2020, INT J COMPUT VISION, V128, P575, DOI 10.1007/s11263-019-01207-y; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Cifuentes D., 2018, ARXIV 171004287V2; Cifuentes D, 2018, POLYNOMIAL SYSTEMS G; Enqvist O., 2009, PROC BRIT MACH VIS C, P1; Enqvist O, 2008, LECT NOTES COMPUT SC, V5302, P141, DOI 10.1007/978-3-540-88682-2_12; Eriksson A, 2021, IEEE T PATTERN ANAL, V43, P256, DOI 10.1109/TPAMI.2019.2930051; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fredriksson J, 2016, PROC CVPR IEEE, P1728, DOI 10.1109/CVPR.2016.191; Fukuda M, 2001, SIAM J OPTIMIZ, V11, P647, DOI 10.1137/S1052623400366218; Geman S, 1987, B INT STAT I, V4, P5; Hartley R., 2003, MULTIPLE VIEW GEOMET; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064; Hartley RI, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P469, DOI 10.1109/ICCV.1998.710760; Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9; Helmke U, 2007, INT J COMPUT VISION, V74, P117, DOI 10.1007/s11263-006-0005-0; Huber P., 1981, ROBUST STAT; Kahl F, 2007, INT J COMPUT VISION, V74, P3, DOI 10.1007/s11263-006-0015-y; Kanatani K, 2010, J MATH IMAGING VIS, V38, P1, DOI 10.1007/s10851-010-0206-6; Kneip L, 2014, IEEE INT CONF ROBOT, P1, DOI 10.1109/ICRA.2014.6906582; Kneip L, 2013, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2013.292; Kneip L, 2012, LECT NOTES COMPUT SC, V7577, P696, DOI 10.1007/978-3-642-33783-3_50; Le H, 2021, IEEE T PATTERN ANAL, V43, P842, DOI 10.1109/TPAMI.2019.2939307; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Li HD, 2009, IEEE I CONF COMP VIS, P1074, DOI 10.1109/ICCV.2009.5459398; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma Y, 2001, INT J COMPUT VISION, V44, P219, DOI 10.1023/A:1012276232049; MAYBANK SJ, 1990, PHILOS T ROY SOC A, V332, P1, DOI 10.1098/rsta.1990.0099; Mevissen M, 2010, ASIA PAC J OPER RES, V27, P15, DOI 10.1142/S0217595910002533; Migita T., 2007, PROC IEEE C COMPUT V, P1; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Olsson C, 2008, INT C PATT RECOG, P2469; Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257; Shah SA, 2017, P NATL ACAD SCI USA, V114, P9814, DOI 10.1073/pnas.1700770114; Speciale P, 2017, PROC CVPR IEEE, P5048, DOI 10.1109/CVPR.2017.536; Stewenius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005; Strecha C., 2008, PROC IEEE C COMPUT V; Tron R, 2017, SIAM J IMAGING SCI, V10, P1416, DOI 10.1137/16M1091332; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; Yang H, 2019, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2019.00175; Yang H, 2020, IEEE ROBOT AUTOM LET, V5, P1127, DOI 10.1109/LRA.2020.2965893; Yang JL, 2014, LECT NOTES COMPUT SC, V8689, P111, DOI 10.1007/978-3-319-10590-1_8; Ye Y., 1997, INTERIOR POINT ALGOR; Yinqiang Zheng, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPR.2011.5995352; Zach C., 2017, PROC BRIT MACH VIS C, P1; Zach C, 2014, LECT NOTES COMPUT SC, V8693, P772, DOI 10.1007/978-3-319-10602-1_50; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; Zheng YQ, 2013, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2013.291; Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47	66	7	7	3	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1777	1792		10.1109/TPAMI.2020.3030161	http://dx.doi.org/10.1109/TPAMI.2020.3030161			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33044931	Green Submitted			2022-12-18	WOS:000764815300011
J	Ci, H; Ma, XX; Wang, CY; Wang, YZ				Ci, Hai; Ma, Xiaoxuan; Wang, Chunyu; Wang, Yizhou			Locally Connected Network for Monocular 3D Human Pose Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Two dimensional displays; Pose estimation; Feature extraction; Solid modeling; Training; Task analysis; 3D human pose estimation; locally connected network; graph convolution	MOTION; SHAPE	We present an approach for 3D human pose estimation from monocular images. The approach consists of two steps: it first estimates a 2D pose from an image and then estimates the corresponding 3D pose. This paper focuses on the second step. Graph convolutional network (GCN) has recently become the de facto standard for human pose related tasks such as action recognition. However, in this work, we show that GCN has critical limitations when it is used for 3D pose estimation due to the inherent weight sharing scheme. The limitations are clearly exposed through a novel reformulation of GCN, in which both GCN and Fully Connected Network (FCN) are its special cases. In addition, on top of the formulation, we present locally connected network (LCN) to overcome the limitations of GCN by allocating dedicated rather than shared filters for different joints. We jointly train the LCN network with a 2D pose estimator such that it can handle inaccurate 2D poses. We evaluate our approach on two benchmark datasets and observe that LCN outperforms GCN, FCN, and the state-of-the-art methods by a large margin. More importantly, it demonstrates strong cross-dataset generalization ability because of sparse connections among body joints.	[Ci, Hai; Ma, Xiaoxuan; Wang, Yizhou] Peking Univ, Dept Comp Sci, Beijing 100871, Peoples R China; [Ci, Hai] Beijing Film Acad, Adv Innovat Ctr Future Visual Entertainment AICFV, Beijing 100088, Peoples R China; [Ma, Xiaoxuan] Deepwise AI Lab, Beijing 100080, Peoples R China; [Wang, Yizhou] Ctr Frontiers Comp Studies, Beijing 100871, Peoples R China; [Wang, Yizhou] Adv Inst Informat Technol, Hangzhou 311200, Peoples R China; [Wang, Chunyu] Microsoft Res Asia, Beijing 100080, Peoples R China	Peking University; Microsoft; Microsoft Research Asia	Wang, CY (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.	cihai@pku.edu.cn; maxiaoxuan@pku.edu.cn; chnuwa@microsoft.com; yizhou.wang@pku.edu.cn		Ci, Hai/0000-0001-7170-277X; Wang, Chunyu/0000-0002-9400-9107; Ma, Xiaoxuan/0000-0003-0571-2659	DFG [TRR169/NSFC];  [MOST-2018AAA0102004];  [NSFC-61625201]	DFG(German Research Foundation (DFG)); ; 	Thisworkwas supported in part byMOST-2018AAA0102004, NSFC-61625201 and DFG TRR169/NSFC Major International Collaboration Project "Crossmodal Learning." Hai Ci and Xiaoxuan Ma have contributed equally to this work.	Agarwal A, 2004, PROC CVPR IEEE, P882; Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236; Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257; Chen Y, 2020, IEEE T PATTERN ANAL, V42, P1654, DOI 10.1109/TPAMI.2019.2901875; Choo K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P321, DOI 10.1109/ICCV.2001.937643; Ci H, 2019, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2019.00235; diaeresis>el Defferrard Micha<spacing, 2016, NEURIPS, DOI DOI 10.5555/3157382.3157527; Elgammal A, 2008, COMPUT IMAGING VIS, V36, P25; Fang HS, 2018, AAAI CONF ARTIF INTE, P6821; Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Iskakov K, 2019, IEEE I CONF COMP VIS, P7717, DOI 10.1109/ICCV.2019.00781; Johnson Sam, 2010, BMVC, DOI [10.5244/C.24.12, DOI 10.5244/C.24.12]; Kipf T. N., 2017, 5 INT C LEARN REPR; Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8; Lee MW, 2004, PROC CVPR IEEE, P334; Lee MW, 2004, LECT NOTES COMPUT SC, V3022, P126; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013; Luo Chenxu, 2018, ARXIV181104989, P92; Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539; Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288; Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064; Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170; Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149; Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343; Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763; Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055; Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139; Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794; Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41; Rhodin H, 2018, LECT NOTES COMPUT SC, V11214, P765, DOI 10.1007/978-3-030-01249-6_46; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Sminchisescu C, 2001, PROC CVPR IEEE, P447; Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33; Suwajanakorn S, 2018, ADV NEUR IN, V31; Taylor CJ, 2000, COMPUT VIS IMAGE UND, V80, P349, DOI 10.1006/cviu.2000.0878; Tekin Bugra, 2016, BRIT MACH VIS C BMVC, P2; Tresadern P, 2005, PROC CVPR IEEE, P1110; Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492; Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303; Wang J, 2019, IEEE I CONF COMP VIS, P7770, DOI 10.1109/ICCV.2019.00786; Wei XLK, 2009, IEEE I CONF COMP VIS, P1873, DOI 10.1109/ICCV.2009.5459415; Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29; Yan JY, 2008, IEEE T PATTERN ANAL, V30, P865, DOI 10.1109/TPAMI.2007.70739; Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551; Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354; Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537; Zhou XW, 2015, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2015.7299074; Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51	53	7	7	12	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1429	1442		10.1109/TPAMI.2020.3019139	http://dx.doi.org/10.1109/TPAMI.2020.3019139			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32833628				2022-12-18	WOS:000752018000026
J	Chakraborty, R; Bouza, J; Manton, J; Vemuri, BC				Chakraborty, Rudrasis; Bouza, Jose; Manton, Jonathan; Vemuri, Baba C.			ManifoldNet: A Deep Neural Network for Manifold-Valued Data With Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weighted frechet mean; equivariance; group action; riemannian manifolds		Geometric deep learning is a relatively nascent field that has attracted significant attention in the past few years. This is partly due to the availability of data acquired from non-euclidean domains or features extracted from euclidean-space data that reside on smooth manifolds. For instance, pose data commonly encountered in computer vision reside in Lie groups, while covariance matrices that are ubiquitous in many fields and diffusion tensors encountered in medical imaging domain reside on the manifold of symmetric positive definite matrices. Much of this data is naturally represented as a grid of manifold-valued data. In this paper we present a novel theoretical framework for developing deep neural networks to cope with these grids of manifold-valued data inputs. We also present a novel architecture to realize this theory and call it the ManifoldNet. Analogous to vector spaces where convolutions are equivalent to computing weighted sums, manifold-valued data 'convolutions' can be defined using the weighted Frechet Mean (wFM). (This requires endowing the manifold with a Riemannian structure if it did not already come with one.) The hidden layers of ManifoldNet compute wFMs of their inputs, where the weights are to be learnt. This means the data remain manifold-valued as they propagate through the hidden layers. To reduce computational complexity, we present a provably convergent recursive algorithm for computing the wFM. Further, we prove that on non-constant sectional curvature manifolds, each wFM layer is a contraction mapping and provide constructive evidence for its non-collapsibility when stacked in layers. This captures the two fundamental properties of deep network layers. Analogous to the equivariance of convolution in euclidean space to translations, we prove that the wFM is equivariant to the action of the group of isometries admitted by the Riemannian manifold on which the data reside. To showcase the performance of ManifoldNet, we present several experiments using both computer vision and medical imaging data sets.	[Chakraborty, Rudrasis] Univ Calif Berkeley, Berkeley, CA 94720 USA; [Bouza, Jose; Vemuri, Baba C.] Univ Florida, Gainesville, FL 32611 USA; [Manton, Jonathan] Univ Melbourne, Parkville, Vic 013, Australia	University of California System; University of California Berkeley; State University System of Florida; University of Florida; University of Melbourne	Vemuri, BC (corresponding author), Univ Florida, Gainesville, FL 32611 USA.	rudrasischa@gmail.com; josejbouw@gmail.com; j.manton@ieee.org; vemuri@cise.ufl.edu		Vemuri, Baba/0000-0002-1400-5844	NSF [IIS-1724174]	NSF(National Science Foundation (NSF))	This work was supported in part by the NSF Grant IIS-1724174 to BCV. The authors would like to thank Dr. David Vaillancourt of UFL for providing the diffusion MRI data.	Afsari B, 2011, P AM MATH SOC, V139, P655, DOI 10.1090/S0002-9939-2010-10541-5; Alexander DC, 2005, ANN NY ACAD SCI, V1064, P113, DOI 10.1196/annals.1340.018; Archer DB, 2018, CEREB CORTEX, V28, P1685, DOI 10.1093/cercor/bhx066; Banerjee M, 2016, PROC CVPR IEEE, P4424, DOI 10.1109/CVPR.2016.479; BASSER PJ, 1994, BIOPHYS J, V66, P259, DOI 10.1016/S0006-3495(94)80775-1; Berger Marcel, 2012, PANORAMIC VIEW RIEMA; Brooks D, 2019, ADV NEUR IN, V32; Chakraborty R., 2018, ADV NEURAL INFORM PR, P8883; Chakraborty R, 2019, LECT NOTES COMPUT SC, V11492, P112, DOI 10.1007/978-3-030-20351-1_9; Chakraborty R, 2019, ANN STAT, V47, P415, DOI 10.1214/18-AOS1692; Chakraborty R, 2017, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2017.92; Cheng G, 2009, LECT NOTES COMPUT SC, V5761, P190, DOI 10.1007/978-3-642-04268-3_24; Defferrard M., 2016, P ADV NEURAL INFORM, P3844; Dummit D. S., 2004, ABSTRACT ALGEBRA, V3; Frechet M., 1948, ANN I H POINCARE, V10, P215; Garyfallidis E, 2014, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00008; Goh A, 2011, NEUROIMAGE, V56, P1181, DOI 10.1016/j.neuroimage.2011.01.053; Hauberg S, 2016, IEEE T PATTERN ANAL, V38, P2298, DOI 10.1109/TPAMI.2015.2511743; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Helgason S, 1979, DIFFERENTIAL GEOMETR, V80; Henaff M, 2015, ARXIV150605163; Hinton GE, 2000, ADV NEUR IN, V12, P463; Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Huang ZW, 2018, AAAI CONF ARTIF INTE, P3279; Huang ZW, 2017, AAAI CONF ARTIF INTE, P2036; Jian B, 2007, IEEE T MED IMAGING, V26, P1464, DOI 10.1109/TMI.2007.907552; Kingma D. P, 2014, ARXIV13126114; Kingma Diederik P, 2018, ADV NEURAL INFORM PR; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lim Y, 2014, LINEAR ALGEBRA APPL, V453, P59, DOI 10.1016/j.laa.2014.04.002; Luo WJ, 2016, ADV NEUR IN, V29; Mallat S, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0203; Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112; Minh H. Q., 2016, ALGORITHMIC ADV RIEM; Moakher M, 2005, SIAM J MATRIX ANAL A, V26, P735, DOI 10.1137/S0895479803436937; Oliva JB, 2017, PR MACH LEARN RES, V70; Ramaker C, 2002, MOVEMENT DISORD, V17, P867, DOI 10.1002/mds.10248; Sabour Sara, 2017, PROC 31 INT C NEURAL; Salehian H., 2015, MATH FDN COMPUTATION, V3, P143; Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051; Srivastava A., 2007, IEEE C COMP VIS PATT, P1; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Tuch DS, 2003, NEURON, V40, P885, DOI 10.1016/S0896-6273(03)00758-X; van den Oord A, 2016, PR MACH LEARN RES, V48; van den Oord Aaron, 2016, ARXIV160605328; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386; Yang YC, 2017, PR MACH LEARN RES, V70; Yu K., 2017, ARXIV170306817; Zhang T, 2018, IEEE IMAGE PROC, P4098, DOI 10.1109/ICIP.2018.8451626	52	7	7	2	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					799	810		10.1109/TPAMI.2020.3003846	http://dx.doi.org/10.1109/TPAMI.2020.3003846			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32750791				2022-12-18	WOS:000740006100020
J	Akolkar, H; Leng, SH; Benosman, R				Akolkar, Himanshu; Leng, Sio-Hoi; Benosman, Ryad			Real-Time High Speed Motion Prediction Using Fast Aperture-Robust Event-Driven Visual Flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Event driven; neuromorphic; optical flow; motion prediction	VISION	Optical flow is a crucial component of the feature space for early visual processing of dynamic scenes especially in new applications such as self-driving vehicles, drones and autonomous robots. The dynamic vision sensors are well suited for such applications because of their asynchronous, sparse and temporally precise representation of the visual dynamics. Many algorithms proposed for computing visual flow for these sensors suffer from the aperture problem as the direction of the estimated flow is governed by the curvature of the object rather than the true motion direction. Some methods that do overcome this problem by temporal windowing under-utilize the true precise temporal nature of the dynamic sensors. In this paper, we propose a novel multi-scale plane fitting based visual flow algorithm that is robust to the aperture problem and also computationally fast and efficient. Our algorithm performs well in many scenarios ranging from fixed camera recording simple geometric shapes to real world scenarios such as camera mounted on a moving car and can successfully perform event-by-event motion estimation of objects in the scene to allow for predictions of upto 500 ms i.e., equivalent to 10 to 25 frames with traditional cameras.	[Akolkar, Himanshu; Benosman, Ryad] Univ Pittsburgh, Pittsburgh, PA 15260 USA; [Leng, Sio-Hoi; Benosman, Ryad] Sorbonne Univ, Inst Vis, CNRS, INSERM, F-75012 Paris, France; [Benosman, Ryad] Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Centre National de la Recherche Scientifique (CNRS); Institut National de la Sante et de la Recherche Medicale (Inserm); UDICE-French Research Universities; Sorbonne Universite; Universite Paris Cite; Carnegie Mellon University	Akolkar, H (corresponding author), Univ Pittsburgh, Pittsburgh, PA 15260 USA.	akolkar@pitt.edu; sio-hoi.ieng@upmc.fr; ryad.benosman@upmc.fr						Akolkar H., 2015, P INT C EV BAS CONTR, P1; Bai M, 2016, LECT NOTES COMPUT SC, V9910, P154, DOI 10.1007/978-3-319-46466-4_10; Bailer C, 2017, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2017.290; Benosman R, 2014, IEEE T NEUR NET LEAR, V25, P407, DOI 10.1109/TNNLS.2013.2273537; Benosman R, 2012, NEURAL NETWORKS, V27, P32, DOI 10.1016/j.neunet.2011.11.001; Bonneel N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818107; Brosch T, 2015, FRONT NEUROSCI-SWITZ, V9, DOI [10.3389/fnins.7015.00137, 10.3389/fnins.2015.00137]; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T, 2009, PROC CVPR IEEE, P41, DOI 10.1109/CVPRW.2009.5206697; Glover A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2203, DOI 10.1109/IROS.2016.7759345; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Lichtsteiner Patrick, 2008, IEEE Journal of Solid-State Circuits, V43, P566, DOI 10.1109/JSSC.2007.914337; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Maqueda AI, 2018, PROC CVPR IEEE, P5419, DOI 10.1109/CVPR.2018.00568; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Mueggler E, 2017, INT J ROBOT RES, V36, P142, DOI 10.1177/0278364917691115; Posch C, 2011, IEEE J SOLID-ST CIRC, V46, P259, DOI 10.1109/JSSC.2010.2085952; Rea F, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00234; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Seifozzakerini, ANAL OBJECT ITS MOTI, DOI [10.32657/10220/46126, DOI 10.32657/10220/46126]; Serrano-Gotarredona T, 2013, IEEE J SOLID-ST CIRC, V48, P827, DOI 10.1109/JSSC.2012.2230553; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Stoffregen T, 2019, IEEE I CONF COMP VIS, P7243, DOI 10.1109/ICCV.2019.00734; Stoffregen T, 2019, PROC CVPR IEEE, P12292, DOI 10.1109/CVPR.2019.01258; Valeiras DR, 2019, IEEE T NEUR NET LEAR, V30, P1218, DOI 10.1109/TNNLS.2018.2807983; Vasco V, 2016, IEEE-RAS INT C HUMAN, P732, DOI 10.1109/HUMANOIDS.2016.7803355; Vidal AR, 2018, IEEE ROBOT AUTOM LET, V3, P994, DOI 10.1109/LRA.2018.2793357; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; Zhu AZ, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV	30	7	7	3	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					361	372		10.1109/TPAMI.2020.3010468	http://dx.doi.org/10.1109/TPAMI.2020.3010468			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750822	Green Submitted, Green Published, hybrid			2022-12-18	WOS:000728561300026
J	Zhu, CZ; Cao, LB; Yin, JP				Zhu, Chengzhang; Cao, Longbing; Yin, Jianping			Unsupervised Heterogeneous Coupling Learning for Categorical Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Coupling learning; heterogeneity learning; Non-IID learning; representation learning; similarity learning; categorical data; categorical data representation; unsupervised categorical representation; unsupervised learning	DISSIMILARITY MEASURE; ATTRIBUTE; IMPACT	Complex categorical data is often hierarchically coupled with heterogeneous relationships between attributes and attribute values and the couplings between objects. Such value-to-object couplings are heterogeneous with complementary and inconsistent interactions and distributions. Limited research exists on unlabeled categorical data representations, ignores the heterogeneous and hierarchical couplings, underestimates data characteristics and complexities, and overuses redundant information, etc. The deep representation learning of unlabeled categorical data is challenging, overseeing such value-to-object couplings, complementarity and inconsistency, and requiring large data, disentanglement, and high computational power. This work introduces a shallow but powerful UNsupervised heTerogeneous couplIng lEarning (UNTIE) approach for representing coupled categorical data by untying the interactions between couplings and revealing heterogeneous distributions embedded in each type of couplings. UNTIE is efficiently optimized w.r.t. a kernel k-means objective function for unsupervised representation learning of heterogeneous and hierarchical value-to-object couplings. Theoretical analysis shows that UNTIE can represent categorical data with maximal separability while effectively represent heterogeneous couplings and disclose their roles in categorical data. The UNTIE-learned representations make significant performance improvement against the state-of-the-art categorical representations and deep representation models on 25 categorical data sets with diversified characteristics.	[Zhu, Chengzhang; Cao, Longbing] Univ Technol Sydney, Adv Analyt Inst, Ultimo, NSW 2007, Australia; [Yin, Jianping] Dongguan Univ Technol, Dongguan 523106, Peoples R China	University of Technology Sydney; Dongguan University of Technology	Zhu, CZ (corresponding author), Univ Technol Sydney, Adv Analyt Inst, Ultimo, NSW 2007, Australia.	kevin.zhu.china@gmail.com; Longbing.Cao@gmail.com; jpyin@dgut.edu.cn		Zhu, Chengzhang/0000-0003-0495-1981; cao, longbing/0000-0003-1562-9429; Yin, Jianping/0000-0002-5474-4764	Australian Research Council [DP190101079, FT190100734]	Australian Research Council(Australian Research Council)	This work was supported in part by the Australian Research Council under Grant DP190101079 and FT190100734.	Ahmad A, 2007, PATTERN RECOGN LETT, V28, P110, DOI 10.1016/j.patrec.2006.06.006; Bai L, 2013, IEEE T PATTERN ANAL, V35, P1509, DOI 10.1109/TPAMI.2012.228; Balcan MF, 2008, MACH LEARN, V72, P89, DOI 10.1007/s10994-008-5059-5; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Boriah S., 2008, P 8 SIAM INT C DAT M, P243, DOI 10.1137/1.9781611972788.22; Br~emaud P, 2017, COUPLING METHOD, P397; Bucak SS, 2014, IEEE T PATTERN ANAL, V36, P1354, DOI 10.1109/TPAMI.2013.212; Cao FY, 2012, KNOWL-BASED SYST, V26, P120, DOI 10.1016/j.knosys.2011.07.011; Cao LB, 2015, INFORM PROCESS MANAG, V51, P167, DOI 10.1016/j.ipm.2014.08.007; Cao LB, 2014, COMPUT J, V57, P1358, DOI 10.1093/comjnl/bxt084; Cao Longbing, 2018, DATA SCI THINKING NE; Cheng H., 2016, DLRS 2016PROCEEDINGS, P7, DOI [10.1145/2988450.2988454, DOI 10.1145/2988450.2988454]; Demsar J, 2006, J MACH LEARN RES, V7, P1; Donahue Jeff, 2017, INT C LEARN REPR ICL; Duchi J, 2011, J MACH LEARN RES, V12, P2121; Dunson DB, 2009, J AM STAT ASSOC, V104, P1042, DOI 10.1198/jasa.2009.tm08439; Ienco D, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2133360.2133361; Jegelka S, 2009, LECT NOTES ARTIF INT, V5803, P144, DOI 10.1007/978-3-642-04617-9_19; Jia H, 2016, IEEE T NEUR NET LEAR, V27, P1065, DOI 10.1109/TNNLS.2015.2436432; Jian SL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1937; Jian SL, 2018, AAAI CONF ARTIF INTE, P3318; Kingma D.P, P 3 INT C LEARNING R; Kulis B., 2004, P 10 ACM SIGKDD INT, P551, DOI DOI 10.1145/1014052.1014118; Le SQ, 2005, PATTERN RECOGN LETT, V26, P2549, DOI 10.1016/j.patrec.2005.06.002; Ng MK, 2007, IEEE T PATTERN ANAL, V29, P503, DOI 10.1109/TPAMI.2007.53; Pang G., 2016, P 25 INT JOINT C ART, P1902; Pang GS, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2585; Qian YH, 2016, IEEE T NEUR NET LEAR, V27, P2047, DOI 10.1109/TNNLS.2015.2451151; Ralaivola L, 2010, J MACH LEARN RES, V11, P1927; Seth S, 2016, IEEE T PATTERN ANAL, V38, P849, DOI 10.1109/TPAMI.2015.2470655; Do TDT, 2018, ADV NEUR IN, V31; Tutz G, 2016, STAT MODEL, V16, P161, DOI 10.1177/1471082X16642560; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wang C., 2011, P 20 ACM INT C INF K, P973, DOI DOI 10.1145/2063576.2063715; Wang C., 2013, PROC INT JOINT C ART, P1736; Wang C, 2015, AAAI CONF ARTIF INTE, P1861; Wang C, 2015, IEEE T NEUR NET LEAR, V26, P781, DOI 10.1109/TNNLS.2014.2325872; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361; Zhang Kai, 2015, P 2015 SIAM INT C DA, P46; Zhu CZ, 2018, IEEE T KNOWL DATA EN, V30, P1254, DOI 10.1109/TKDE.2018.2791525	42	7	7	6	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					533	549		10.1109/TPAMI.2020.3010953	http://dx.doi.org/10.1109/TPAMI.2020.3010953			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750827	Green Submitted, Green Published			2022-12-18	WOS:000728561300038
J	Cheng, M; Ma, Z; Asif, MS; Xu, YL; Liu, HJ; Bao, WB; Sun, J				Cheng, Ming; Ma, Zhan; Asif, M. Salman; Xu, Yiling; Liu, Haojie; Bao, Wenbo; Sun, Jun			A Dual Camera System for High Spatiotemporal Resolution Video Acquisition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Spatial resolution; Spatiotemporal phenomena; Data models; Dual camera system; high spatiotemporal resolution; super-resolution; optical flow; spatial information; end-to-end learning		This paper presents a dual camera system for high spatiotemporal resolution (HSTR) video acquisition, where one camera shoots a video with high spatial resolution and low frame rate (HSR-LFR) and another one captures a low spatial resolution and high frame rate (LSR-HFR) video. Our main goal is to combine videos from LSR-HFR and HSR-LFR cameras to create an HSTR video. We propose an end-to-end learning framework, AWnet, mainly consisting of a FlowNet and a FusionNet that learn an adaptive weighting function in pixel domain to combine inputs in a frame recurrent fashion. To improve the reconstruction quality for cameras used in reality, we also introduce noise regularization under the same framework. Our method has demonstrated noticeable performance gains in terms of both objective PSNR measurement in simulation with different publicly available video and light-field datasets and subjective evaluation with real data captured by dual iPhone 7 and Grasshopper3 cameras. Ablation studies are further conducted to investigate and explore various aspects, such as reference structure, camera parallax, exposure time, etc) of our system to fully understand its capability for potential applications.	[Cheng, Ming] Nanjing Univ, Nanjing 210023, Jiangsu, Peoples R China; [Cheng, Ming; Bao, Wenbo] Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Elect Engn, Shanghai 200240, Peoples R China; [Ma, Zhan; Liu, Haojie] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China; [Asif, M. Salman] Univ Calif Riverside, Dept Elect & Comp Engn, Riverside, CA 92521 USA; [Xu, Yiling] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China; [Sun, Jun] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China	Nanjing University; Shanghai Jiao Tong University; Nanjing University; University of California System; University of California Riverside; Shanghai Jiao Tong University; Shanghai Jiao Tong University	Ma, Z (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China.	ming_cheng@sjtu.edu.cn; mazhan@nju.edu.cn; sasif@ece.ucr.edu; yl.xu@sjtu.edu.cn; haojie@smail.nju.edu.cn; baowenbo@sjtu.edu.cn; junsun@sjtu.edu.cn		Asif, Salman/0000-0001-5993-3903	National Natural Science Foundation of China [61971282]; National Key Research and Development Project of China Science and Technology Exchange Center [2018YFE0206700]; Scientific Research Plan of the Science and Technology Commission of Shanghai Municipality [18511105402]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Project of China Science and Technology Exchange Center; Scientific Research Plan of the Science and Technology Commission of Shanghai Municipality	This paper was supported in part by the National Natural Science Foundation of China (61971282), National Key Research and Development Project of China Science and Technology Exchange Center (2018YFE0206700) and Scientific Research Plan of the Science and Technology Commission of Shanghai Municipality (18511105402). M. Salman Asif and Yiling Xu are co-first authors.	[Anonymous], 2008, NEW STANFORD LIGHT F; Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2; Bao WB, 2019, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2019.00382; Bao WB, 2021, IEEE T PATTERN ANAL, V43, P933, DOI 10.1109/TPAMI.2019.2941941; Bao WB, 2018, IEEE T IMAGE PROCESS, V27, P3813, DOI 10.1109/TIP.2018.2825100; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Boominathan V, 2014, IEEE INT CONF COMPUT; Brady DJ, 2012, NATURE, V486, P386, DOI 10.1038/nature11150; Brady DJ, 2018, OPTICA, V5, P127, DOI 10.1364/OPTICA.5.000127; Burton A., 1978, THINKING PERSPECTIVE; Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304; Cao X, 2016, IEEE SIGNAL PROC MAG, V33, P95, DOI 10.1109/MSP.2016.2582378; Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347; De Brabandere B, 2016, ADV NEUR IN, V29; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Eilertsen G, 2019, PROC CVPR IEEE, P11168, DOI 10.1109/CVPR.2019.01143; Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; Fujii T., 2019, ELECT IMAG, V2019; Gu JJ, 2019, PROC CVPR IEEE, P1604, DOI 10.1109/CVPR.2019.00170; Han S., 2016, P INT C LEARNING REP; Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jaderberg M, 2015, ADV NEUR IN, V28; Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938; Jin MG, 2019, PROC CVPR IEEE, P8104, DOI 10.1109/CVPR.2019.00830; Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kingma D.P, P 3 INT C LEARNING R; Lane, 2016, 2016 15 ACM IEEE INT, P1; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li F., 2011, THESIS INFORM SCI U; Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995; Lu S, 2019, IEEE WINT CONF APPL, P2196, DOI 10.1109/WACV.2019.00237; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Niklaus S, 2018, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2018.00183; Noh H, 2017, ADV NEUR IN, V30; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693; Srinivasan PP, 2017, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2017.246; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Wang TC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073614; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126; Xie Qizhe, 2019, ARXIV191104252; Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2; Zhang K, 2019, PROC CVPR IEEE, P1671, DOI 10.1109/CVPR.2019.00177; Zheng H., 2017, P BMVC, P2; Zheng HT, 2018, LECT NOTES COMPUT SC, V11210, P87, DOI 10.1007/978-3-030-01231-1_6; Zheng HT, 2017, IEEE INT CONF COMP V, P2481, DOI 10.1109/ICCVW.2017.292; Zheng S, 2016, PROC CVPR IEEE, P4480, DOI 10.1109/CVPR.2016.485	52	7	7	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3275	3291		10.1109/TPAMI.2020.2983371	http://dx.doi.org/10.1109/TPAMI.2020.2983371			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG		Green Submitted			2022-12-18	WOS:000692232400005
J	Gao, JY; Zhang, TZ; Xu, CS				Gao, Junyu; Zhang, Tianzhu; Xu, Changsheng			Learning to Model Relationships for Zero-Shot Video Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Zero-shot video classification; graph neural networks; zero-shot learning; deep attention model		With the explosive growth of video categories, zero-shot learning (ZSL) in video classification has become a promising research direction in pattern analysis and machine learning. Based on some auxiliary information such as word embeddings and attributes, the key to a robust ZSL method is to transfer the learned knowledge from seen classes to unseen classes, which requires relationship modeling between these concepts (e.g., categories and attributes). However, most existing approaches ignore to model the explicit relationships in an end-to-end manner, resulting in low effectiveness of knowledge transfer. To tackle this problem, we reconsider the video ZSL task as a task-driven message passing process to jointly enjoy several merits including alleviated heterogeneity gap, low domain shift, and robust temporal modeling. Specifically, we propose a prototype-sample GNN (PS-GNN) consisting of a prototype branch and a sample branch to directly and adaptively model all the relationships between category-attribute, category-category, and attribute-attribute. The prototype branch aims to learn robust representations of video categories, which takes as input a set of word-embedding vectors corresponding to the concepts. The sample branch is designed to generate features of a video sample by leveraging its object semantics. With the co-adaption and cooperation between both branches, a unified and robust ZSL framework is achieved. Extensive experiments strongly evidence that PS-GNN obtains favorable performance on five popular video benchmarks consistently.	[Gao, Junyu; Xu, Changsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Gao, Junyu; Xu, Changsheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China; [Zhang, Tianzhu] Univ Sci & Technol China, Hefei 230052, Anhui, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; University of Science & Technology of China, CAS	Xu, CS (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.; Xu, CS (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.	junyu.gao@nlpr.ia.ac.cn; tzzhang10@gmail.com; csxu@nlpr.ia.ac.cn	Xu, Chang/GQP-7280-2022; Gao, Junyu/HDO-5516-2022; Zhang, Tianzhu/AGY-9389-2022	Zhang, Tianzhu/0000-0003-0764-6106; zhang, tian zhu/0000-0003-1856-9564	National Key Research and Development Program of China [2018AAA0102200]; National Natural Science Foundation of China [61720106006, 61721004, 61832002, 61532009, U1705262, U1836220, 61702511]; Key Research Program of Frontier Sciences, CAS [QYZDJSSWJSC039]; Research Program of National Laboratory of Pattern Recognition [Z-2018007]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Research Program of Frontier Sciences, CAS; Research Program of National Laboratory of Pattern Recognition	This work was supported in part by the National Key Research and Development Program of China under Grants 2018AAA0102200, in part by the National Natural Science Foundation of China under Grants 61720106006, 61721004, 61832002, 61532009, U1705262, U1836220, and 61702511, in part by the Key Research Program of Frontier Sciences, CAS, under Grant QYZDJSSWJSC039, and in part by the Research Program of National Laboratory of Pattern Recognition under Grant Z-2018007.	Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911; Alexiou I, 2016, IEEE IMAGE PROC, P4190, DOI 10.1109/ICIP.2016.7533149; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Bond Francis, 2013, LONG PAPERS, V1, P1352; Bruna Joan, 2014, ICLR, DOI DOI 10.1145/3170427.3188467; Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Defferrard M., 2016, P ADV NEURAL INFORM, P3844; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Fang Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1661; Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630; Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128; Fu ZY, 2018, IEEE T PATTERN ANAL, V40, P2009, DOI 10.1109/TPAMI.2017.2737007; Gan C, 2016, AAAI CONF ARTIF INTE, P3487; Gan C, 2015, AAAI CONF ARTIF INTE, P3769; Gan C, 2016, PROC CVPR IEEE, P87, DOI 10.1109/CVPR.2016.17; Gao JY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P690, DOI 10.1145/3240508.3240566; Gao JY, 2019, AAAI CONF ARTIF INTE, P8303; Garcia V., 2018, ICLR; Girdhar R, 2017, ADV NEUR IN, V30; Jain M, 2015, PROC CVPR IEEE, P46, DOI 10.1109/CVPR.2015.7298599; Jiang Y.G, 2011, PROC 1 ACM INT C MUL, P29; Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; King DB, 2015, ACS SYM SER, V1214, P1; Kipf TN, 2016, P INT C LEARN REPR; Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Lee CW, 2018, PROC CVPR IEEE, P1576, DOI 10.1109/CVPR.2018.00170; Li QM, 2018, AAAI CONF ARTIF INTE, P3538; Li Yujia, 2016, P INT C LEARN REPR I, P2; Long Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P636, DOI 10.1145/3123266.3123323; Mandal D, 2019, PROC CVPR IEEE, P9977, DOI 10.1109/CVPR.2019.01022; Marino K, 2017, PROC CVPR IEEE, P20, DOI 10.1109/CVPR.2017.10; Mettes P, 2017, IEEE I CONF COMP VIS, P4453, DOI 10.1109/ICCV.2017.476; Mettes P, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P175, DOI 10.1145/2911996.2912036; Mikolov T., 2013, WORKSHOP TRACK P; Mishra A, 2018, IEEE WINT CONF APPL, P372, DOI 10.1109/WACV.2018.00047; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Norouzi Mohammad, 2014, ICLR; Pennington J., 2014, P 2014 C EMPIRICAL M, P1532; Qin J, 2017, PROC CVPR IEEE, P1042, DOI 10.1109/CVPR.2017.117; Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590; Rohrbach M, 2016, INT J COMPUT VISION, V119, P346, DOI 10.1007/s11263-015-0851-8; Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113; Soomro K., 2012, ARXIV; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Tian Y, 2020, IEEE T CIRC SYST VID, V30, P1597, DOI 10.1109/TCSVT.2019.2908487; Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318; Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25; Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386; Wu ZX, 2016, PROC CVPR IEEE, P3112, DOI 10.1109/CVPR.2016.339; Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581; Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768; Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093; Xu X, 2017, INT J COMPUT VISION, V123, P309, DOI 10.1007/s11263-016-0983-5; Xu X, 2016, LECT NOTES COMPUT SC, V9906, P343, DOI 10.1007/978-3-319-46475-6_22; Xu X, 2015, IEEE IMAGE PROC, P63, DOI 10.1109/ICIP.2015.7350760; Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444; Yang Z., 2018, NEURIPS; Zhang CR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1128; Zhou J., 2020, OPEN, V1, DOI [10.1016/j.aiopen.2021.01.001, DOI 10.1016/J.AIOPEN.2021.01.001]; Zhu Y, 2018, PROC CVPR IEEE, P9436, DOI 10.1109/CVPR.2018.00983	78	7	7	4	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3476	3491		10.1109/TPAMI.2020.2985708	http://dx.doi.org/10.1109/TPAMI.2020.2985708			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32305892				2022-12-18	WOS:000692232400017
J	Tang, YS; Lu, JW; Zhou, J				Tang, Yansong; Lu, Jiwen; Zhou, Jie			Comprehensive Instructional Video Analysis: The COIN Dataset and Performance Evaluation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Tires; YouTube; Automobiles; Fasteners; Benchmark testing; Computed tomography; Instructional video; activity understanding; video analysis; deep learning; large-scale benchmark	RECOGNITION	Thanks to the substantial and explosively increased instructional videos on the Internet, novices are able to acquire knowledge for completing various tasks. Over the past decade, growing efforts have been devoted to investigating the problem on instructional video analysis. However, most existing instructional video datasets have limitations in diversity and scale, which makes them far from many real-world applications where more diverse activities occur. To address this, in this article, we propose a large-scale dataset called "COIN" for COmprehensive INstructional video analysis. Organized with a hierarchical structure, the COIN dataset contains 11,827 videos of 180 tasks in 12 domains (e.g., vehicles, gadgets, etc.) related to our daily life. With a new developed toolbox, all the videos are annotated efficiently with a series of step labels and the corresponding temporal boundaries. In order to provide a benchmark for instructional video analysis, we evaluate plenty of approaches on our COIN dataset under five different settings. Furthermore, we exploit two important characteristics (i.e., task-consistency and ordering-dependency) for localizing important steps in instructional videos. Accordingly, we propose two simple yet effective methods, which can be easily plugged into conventional proposal-based action detection models. We believe the introduction of the COIN dataset will promote the future in-depth research on instructional video analysis for the community. Our dataset, annotation toolbox and source codes are available at http://coin-dataset.github.io.	[Tang, Yansong; Lu, Jiwen] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Tang, Yansong; Lu, Jiwen] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Zhou, Jie] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Zhou, Jie] Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen 518055, Peoples R China	Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University	Lu, JW (corresponding author), Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.; Lu, JW (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	tys15@mails.tsinghua.edu.cn; lujiwen@tsinghua.edu.cn; jzhou@tsinghua.edu.cn	Lu, Jiwen/C-5291-2009	Lu, Jiwen/0000-0002-6121-5529	National Key Research and Development Program of China [2017YFA0700802]; National Natural Science Foundation of China [61822603, U1813218, U1713214, 61672306]; Beijing Academy of Artificial Intelligence (BAAI) [BAAI2020ZJ0202]; Shenzhen Fundamental Research Fund [JCYJ20170 412170602564]; Tsinghua University Initiative Scientific Research Program	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Academy of Artificial Intelligence (BAAI); Shenzhen Fundamental Research Fund; Tsinghua University Initiative Scientific Research Program	This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFA0700802, in part by the National Natural Science Foundation of China under Grant 61822603, Grant U1813218, Grant U1713214, and Grant 61672306, in part by the Beijing Academy of Artificial Intelligence (BAAI) under Grant BAAI2020ZJ0202, in part by the Shenzhen Fundamental Research Fund (Subject Arrangement) under Grant JCYJ20170 412170602564, and in part by Tsinghua University Initiative Scientific Research Program. The authors would like to thank Dajun Ding and Lili Zhao from Meitu Inc. for their helps on computing resources and annotation, Danyang Zhang, Yu Zheng and Xumin Yu for conducting partial experiments, and Yongming Rao for valuable discussion.	Aakur SN, 2019, PROC CVPR IEEE, P1197, DOI 10.1109/CVPR.2019.00129; Abu Farha Y, 2018, PROC CVPR IEEE, P5343, DOI 10.1109/CVPR.2018.00560; Alayrac JB, 2018, IEEE T PATTERN ANAL, V40, P2194, DOI 10.1109/TPAMI.2017.2749223; Alayrac JB, 2016, PROC CVPR IEEE, P4575, DOI 10.1109/CVPR.2016.495; Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2019, INSTRUCTION N; [Anonymous], 2016, P ECCV; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chang CY, 2019, PROC CVPR IEEE, P3541, DOI 10.1109/CVPR.2019.00366; Chang CH, 2019, IEEE INT C ELECTR TA; Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44; Das P, 2013, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2013.340; De la Torre Frade F, 2008, GUIDE C MELLON U MUL, P1; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Ding L, 2018, PROC CVPR IEEE, P6508, DOI 10.1109/CVPR.2018.00681; Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174; Doughty H, 2019, PROC CVPR IEEE, P7854, DOI 10.1109/CVPR.2019.00805; Doughty H, 2018, PROC CVPR IEEE, P6057, DOI 10.1109/CVPR.2018.00634; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Elhamifar E, 2016, IEEE T PATTERN ANAL, V38, P2182, DOI 10.1109/TPAMI.2015.2511748; Farha Y.A., 2019, PROC CVPR IEEE, P3575, DOI DOI 10.1109/CVPR.2019.00369; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004; Gao Y., 2014, MICCAI WORKSH M2CAI, P3; Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633; Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33; Huang DA, 2018, PROC CVPR IEEE, P5948, DOI 10.1109/CVPR.2018.00623; Huang DA, 2017, PROC CVPR IEEE, P1032, DOI 10.1109/CVPR.2017.116; Jiang Y.-G., 2014, ECCV WORKSH; Jiaying, 2017, ACM MULT WORKSH; Koedinger KR, 2012, COGNITIVE SCI, V36, P757, DOI 10.1111/j.1551-6709.2012.01245.x; Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83; Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105; Kukleva A, 2019, PROC CVPR IEEE, P12058, DOI 10.1109/CVPR.2019.01234; Lei P, 2018, PROC CVPR IEEE, P6742, DOI 10.1109/CVPR.2018.00705; Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399; Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1; Liu DC, 2019, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2019.00139; Liu Y, 2019, PROC CVPR IEEE, P3599, DOI 10.1109/CVPR.2019.00372; Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043; Marin J, 2021, IEEE T PATTERN ANAL, V43, P187, DOI 10.1109/TPAMI.2019.2927476; Miech A., 2020, P IEEE C COMP VIS PA, P1; Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272; Misra DK, 2016, INT J ROBOT RES, V35, P281, DOI 10.1177/0278364915602060; Nadolski RJ, 2005, BRIT J EDUC PSYCHOL, V75, P223, DOI 10.1348/000709904X22403; Panda R, 2017, IEEE T IMAGE PROCESS, V26, P4712, DOI 10.1109/TIP.2017.2708902; Parmar P, 2017, IEEE COMPUT SOC CONF, P76, DOI 10.1109/CVPRW.2017.16; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Richard A, 2018, PROC CVPR IEEE, P7386, DOI 10.1109/CVPR.2018.00771; Richard A, 2018, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2018.00627; Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187; Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801; Salvador A, 2017, PROC CVPR IEEE, P3068, DOI 10.1109/CVPR.2017.327; Sener F, 2018, PROC CVPR IEEE, P8368, DOI 10.1109/CVPR.2018.00873; Sener O, 2015, IEEE I CONF COMP VIS, P4480, DOI 10.1109/ICCV.2015.509; Simonyan K, 2014, ADV NEUR IN, V27; Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216; Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154; Soomro K., 2012, ARXIVPREPRINT, P2556; Stein S, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P729, DOI 10.1145/2493432.2493482; Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756; Tang YJ, 2021, PEDIATR HEMAT ONCOL, V38, P97, DOI 10.1080/08880018.2020.1820649; Tang YS, 2019, PROC CVPR IEEE, P1207, DOI 10.1109/CVPR.2019.00130; Tang YS, 2019, IEEE T IMAGE PROCESS, V28, P4997, DOI 10.1109/TIP.2019.2914577; Toyer S., 2017, DICTA, V2017, P1; U.S. Department of Labor, 2013, AM TIM US SURV; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617; Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571; Yosinski J, 2014, ADV NEUR IN, V27; Yu HY, 2018, PROC CVPR IEEE, P6006, DOI 10.1109/CVPR.2018.00629; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47; Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317; Zhou LW, 2018, AAAI CONF ARTIF INTE, P7590; Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911; Zhukov D, 2019, PROC CVPR IEEE, P3532, DOI 10.1109/CVPR.2019.00365	80	7	9	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					3138	3153		10.1109/TPAMI.2020.2980824	http://dx.doi.org/10.1109/TPAMI.2020.2980824			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	32175857	Green Submitted			2022-12-18	WOS:000681124300022
J	Zhang, XB; Huang, ZH; Wang, NY; Xiang, SM; Pan, CH				Zhang, Xinbang; Huang, Zehao; Wang, Naiyan; Xiang, Shiming; Pan, Chunhong			You Only Search Once: Single Shot Neural Architecture Search via Direct Sparse Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer architecture; Optimization; Learning (artificial intelligence); Task analysis; Acceleration; Evolutionary computation; Convolution; Neural architecture search(NAS); convolution neural network; sparse optimization	NETWORKS; ALGORITHM; GAME; GO	Recently neural architecture search (NAS) has raised great interest in both academia and industry. However, it remains challenging because of its huge and non-continuous search space. Instead of applying evolutionary algorithm or reinforcement learning as previous works, this paper proposes a direct sparse optimization NAS (DSO-NAS) method. The motivation behind DSO-NAS is to address the task in the view of model pruning. To achieve this goal, we start from a completely connected block, and then introduce scaling factors to scale the information flow between operations. Next, sparse regularizations are imposed to prune useless connections in the architecture. Lastly, an efficient and theoretically sound optimization method is derived to solve it. Our method enjoys both advantages of differentiability and efficiency, therefore it can be directly applied to large datasets like ImageNet and tasks beyond classification. Particularly, on the CIFAR-10 dataset, DSO-NAS achieves an average test error 2.74 percent, while on the ImageNet dataset DSO-NAS achieves 25.4 percent test error under 600M FLOPs with 8 GPUs in 18 hours. As for semantic segmentation task, DSO-NAS also achieve competitive result compared with manually designed architectures on the PASCAL VOC dataset. Code is available at https://github.com/XinbangZhang/DSO-NAS.	[Zhang, Xinbang; Xiang, Shiming; Pan, Chunhong] Chinese Acad Sci, Inst Automat, Dept Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Zhang, Xinbang; Xiang, Shiming] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China; [Huang, Zehao; Wang, Naiyan] Tusimple, Beijing 100020, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Zhang, XB (corresponding author), Chinese Acad Sci, Inst Automat, Dept Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	xinbang.zhang@nlpr.ia.ac.cn; zehaohuang18@gmail.com; winsty@gmail.com; smxiang@nlpr.ia.ac.cn; chpan@nlpr.ia.ac.cn			Major Project for New Generation of AI [2018AAA0100400]; National Natural Science Foundation of China [91646207, 61976208]	Major Project for New Generation of AI; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the Major Project for New Generation of AI under Grant No. 2018AAA0100400, and the National Natural Science Foundation of China under Grants 91646207 and 61976208.	ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; [Anonymous], 2018, P INT C LEARN REPR; [Anonymous], 2016, P INT C LEARN REPR; Bender G, 2018, PR MACH LEARN RES, V80; Bengio Y, 2013, INT CONF ACOUST SPEE, P8624, DOI 10.1109/ICASSP.2013.6639349; Cai Han, 2019, INT C LEARN REPR; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen Liang-Chieh, 2017, 170605587 ARXIV; Chen Shi, 2019, IEEE Trans Pattern Anal Mach Intell, V41, P3048, DOI 10.1109/TPAMI.2018.2874634; Chen T, 2015, COMPUTER SCI; Chen Tianqi, 2016, TRAINING DEEP NETS S, V6, P6; Colson B, 2007, ANN OPER RES, V153, P235, DOI 10.1007/s10479-007-0176-2; Cun YL., 1990, ADV NEURAL INF PROCE, P598, DOI DOI 10.5555/109230.109298; DeVries T., 2017, P 2017 COMPUTER VISI; Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186; Elsken Thomas, 2019, INT C LEARN REPR; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Gong MG, 2015, IEEE T NEUR NET LEAR, V26, P3263, DOI 10.1109/TNNLS.2015.2469673; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Guo YW, 2016, ADV NEUR IN, V29; Han Song, 2015, ADV NEURAL INFORM PR, P1135, DOI DOI 10.5555/2969239.2969366; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Howard A.G, 2017, ARXIV170404861; Hu H., 2016, ARXIV PREPRINT ARXIV; Huang G., 2019, P INT C LEARN REPR; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang ZH, 2018, LECT NOTES COMPUT SC, V11220, P317, DOI 10.1007/978-3-030-01270-0_19; Jastrzebski S., 2018, P INT C LEARN REPR; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Larsson G., 2017, INT C LEARN REPR ICL; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Leung FHF, 2003, IEEE T NEURAL NETWOR, V14, P79, DOI 10.1109/TNN.2002.804317; Li H., 2017, INT C LEARN REPR; Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI 10.1007/978-3-030-01240-3_21; Liang H., ARXIV190906035; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2; Liu Hanxiao, 2018, ICLR; Liu Hanxiao, 2019, INTERNATIONAL CONFER; Liu J, 2018, IEEE T NEUR NET LEAR, V29, P2450, DOI 10.1109/TNNLS.2017.2695223; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; Loshchilov I., 2017, P INT C LEARNING REP; Luo JH, 2019, IEEE T PATTERN ANAL, V41, P2525, DOI 10.1109/TPAMI.2018.2858232; Ma JQ, 2019, AAAI CONF ARTIF INTE, P216; Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8; NESTEROV IE, 1983, DOKL AKAD NAUK SSSR+, V269, P543; Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003; Pham H, 2018, PR MACH LEARN RES, V80; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Real E, 2017, PR MACH LEARN RES, V70; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Shao L, 2014, IEEE T NEUR NET LEAR, V25, P1359, DOI 10.1109/TNNLS.2013.2293418; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Stork D.G., 1993, ADV NEURAL INF PROCE, P164; Sun K., ARXIV190404514 ARXIV190404514, V2019; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2019.00293; Wang J, 2018, IEEE T NEUR NET LEAR, V29, P2012, DOI 10.1109/TNNLS.2017.2748585; Wen W., 2016, ADV NEURAL INFORM PR, P2074; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xie Sirui, 2019, INT C LEARN REPR; Ye J., 2018, P INT C LEARN REPR P INT C LEARN REPR; Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	81	7	7	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					2891	2904		10.1109/TPAMI.2020.3020300	http://dx.doi.org/10.1109/TPAMI.2020.3020300			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH		Green Submitted			2022-12-18	WOS:000681124300006
J	Bai, S; Li, YW; Zhou, YY; Li, QZ; Torr, PHS				Bai, Song; Li, Yingwei; Zhou, Yuyin; Li, Qizhu; Torr, Philip H. S.			Adversarial Metric Attack and Defense for Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Probes; Perturbation methods; Loss measurement; Video surveillance; Testing; Person re-identification; adversarial attack; metric learning	NETWORK	Person re-identification (re-ID) has attracted much attention recently due to its great importance in video surveillance. In general, distance metrics used to identify two person images are expected to be robust under various appearance changes. However, our work observes the extreme vulnerability of existing distance metrics to adversarial examples, generated by simply adding human-imperceptible perturbations to person images. Hence, the security danger is dramatically increased when deploying commercial re-ID systems in video surveillance. Although adversarial examples have been extensively applied for classification analysis, it is rarely studied in metric analysis like person re-identification. The most likely reason is the natural gap between the training and testing of re-ID networks, that is, the predictions of a re-ID network cannot be directly used during testing without an effective metric. In this work, we bridge the gap by proposing Adversarial Metric Attack, a parallel methodology to adversarial classification attacks. Comprehensive experiments clearly reveal the adversarial effects in re-ID systems. Meanwhile, we also present an early attempt of training a metric-preserving network, thereby defending the metric against adversarial attacks. At last, by benchmarking various adversarial settings, we expect that our work can facilitate the development of adversarial attack and defense in metric-based applications.	[Bai, Song; Li, Qizhu; Torr, Philip H. S.] Univ Oxford6396, Oxford OX1 2JD, England; [Li, Yingwei; Zhou, Yuyin] Johns Hopkins University1466, Baltimore, MD 21218 USA		Bai, S (corresponding author), Univ Oxford6396, Oxford OX1 2JD, England.	songbai.site@gmail.com; yingwei.li@jhu.edu; zhouyuyiner@gmail.com; qizhu.li@eng.ox.ac.uk; philip.torr@eng.ox.ac.uk		Li, Yingwei/0000-0002-0711-7004; Zhou, Yuyin/0000-0003-2232-9563	EPSRC [Seebibyte EP/M013774/1]; EPSRC/MURI [EP/N019474/1]; EPSRC [EP/N019474/1] Funding Source: UKRI	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC/MURI(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was by EPSRC Grant Seebibyte EP/M013774/1 and EPSRC/MURI Grant EP/N019474/1.	Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142; Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764; Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145; Christian Szegedy, 2014, Arxiv, DOI arXiv:1312.6199; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957; Duan YQ, 2018, PROC CVPR IEEE, P2780, DOI 10.1109/CVPR.2018.00294; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Fu Y, 2019, AAAI CONF ARTIF INTE, P8295; Garcia J, 2015, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2015.154; Ge YX, 2018, ADV NEUR IN, V31; Goodfellow I.J., 2015, ARXIV PREPRINT ARXIV; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Hadsell R, 2006, IEEE C COMP VIS PATT, V2, P1735; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hermans Alexander, 2017, ARXIV170307737; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535; Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450; Kaziakhmedov Edgar, 2019, 2019 International Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON). Proceedings, P0422, DOI 10.1109/SIBIRCON48586.2019.8958122; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Kurakin A., 2016, ARXIV PREPRINT ARXIV; Kurakin A, 2018, ICLR, P99, DOI DOI 10.1201/9781351251389-8; Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058; Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li X, 2018, LECT NOTES COMPUT SC, V11206, P287, DOI [10.1007/978-3-030-01216-8_18, 10.1007/978-3-030-01267-0_22]; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Liu CX, 2013, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2013.62; Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431; Liu Y., P INT C LEARN REPR; Liu Z, 2019, IEEE INT CON MULTI, P700, DOI 10.1109/ICME.2019.00126; Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152; Prosser B. J., 2010, PROC BRIT MACH VIS C, P6, DOI DOI 10.5244/C.24.21; Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40; Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23; Wang Z., 2018, IJCAI, P3891; Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42; Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148; Ye M, 2018, LECT NOTES COMPUT SC, V11211, P176, DOI 10.1007/978-3-030-01234-2_11; Ye M, 2017, IEEE I CONF COMP VIS, P5152, DOI 10.1109/ICCV.2017.550; Yin Z., 2018, IJCAI; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405	52	7	10	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2119	2126		10.1109/TPAMI.2020.3031625	http://dx.doi.org/10.1109/TPAMI.2020.3031625			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	33064650	Green Submitted			2022-12-18	WOS:000649590200021
J	Ban, YT; Alameda-Pineda, X; Girin, L; Horaud, R				Ban, Yutong; Alameda-Pineda, Xavier; Girin, Laurent; Horaud, Radu			Variational Bayesian Inference for Audio-Visual Tracking of Multiple Speakers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Target tracking; Acoustics; Bayes methods; Cameras; Object tracking; Direction-of-arrival estimation; Audio-visual tracking; multiple object tracking; dynamic Bayesian networks; variational inference; expectation-maximization; speaker diarization	LOCALIZATION; DIARIZATION	In this article, we address the problem of tracking multiple speakers via the fusion of visual and auditory information. We propose to exploit the complementary nature and roles of these two modalities in order to accurately estimate smooth trajectories of the tracked persons, to deal with the partial or total absence of one of the modalities over short periods of time, and to estimate the acoustic status-either speaking or silent-of each tracked person over time. We propose to cast the problem at hand into a generative audio-visual fusion (or association) model formulated as a latent-variable temporal graphical model. This may well be viewed as the problem of maximizing the posterior joint distribution of a set of continuous and discrete latent variables given the past and current observations, which is intractable. We propose a variational inference model which amounts to approximate the joint distribution with a factorized distribution. The solution takes the form of a closed-form expectation maximization procedure. We describe in detail the inference algorithm, we evaluate its performance and we compare it with several baseline methods. These experiments show that the proposed audio-visual tracker performs well in informal meetings involving a time-varying number of people.	[Ban, Yutong; Alameda-Pineda, Xavier; Horaud, Radu] Inria Grenoble Rhone Alpes, Montbonnot St Martin, France; [Girin, Laurent] Univ Grenoble Alpes, GIPSA Lab, F-38400 St Martin Dheres, France	UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA); Centre National de la Recherche Scientifique (CNRS)	Alameda-Pineda, X (corresponding author), Inria Grenoble Rhone Alpes, Montbonnot St Martin, France.	yutong.ban@inria.fr; Xavier.Alameda-Pineda@inria.fr; Laurent.Girin@gipsa-lab.grenoble-inp.fr; radu.horaud@inria.fr	Horaud, Radu/AAR-5982-2021; Ban, Yutong/D-9340-2019	Horaud, Radu/0000-0001-5232-024X; Alameda-Pineda, Xavier/0000-0002-5354-1084; Ban, Yutong/0000-0001-5396-9251	European Union via the FP7 ERC Advanced Grant VHIA [340113]	European Union via the FP7 ERC Advanced Grant VHIA	Funding from the European Union via the FP7 ERC Advanced Grant VHIA #340113 is greatly acknowledged.	Alameda-Pineda X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P5, DOI 10.1145/2733373.2806238; Alameda-Pineda X, 2016, IEEE T PATTERN ANAL, V38, P1707, DOI 10.1109/TPAMI.2015.2496269; Alameda-Pineda X, 2014, IEEE-ACM T AUDIO SPE, V22, P1082, DOI 10.1109/TASLP.2014.2317989; Miro XA, 2012, IEEE T AUDIO SPEECH, V20, P356, DOI 10.1109/TASL.2011.2125954; Ba S, 2016, COMPUT VIS IMAGE UND, V153, P64, DOI 10.1016/j.cviu.2016.07.006; Bae SH, 2018, IEEE T PATTERN ANAL, V40, P595, DOI 10.1109/TPAMI.2017.2691769; Ban YT, 2019, IEEE SIGNAL PROC LET, V26, P798, DOI 10.1109/LSP.2019.2908376; Ban YT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6553; Ban YT, 2017, IEEE INT CONF COMP V, P446, DOI 10.1109/ICCVW.2017.60; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; Bishop C.M, 2006, PATTERN RECOGN; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Checka N, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P881; Deleforge A, 2015, STAT COMPUT, V25, P893, DOI 10.1007/s11222-014-9461-5; Deleforge A, 2015, IEEE-ACM T AUDIO SPE, V23, P718, DOI 10.1109/TASLP.2015.2405475; Dorfan Y, 2015, IEEE-ACM T AUDIO SPE, V23, P1692, DOI 10.1109/TASLP.2015.2444654; Gatica-Perez D, 2007, IEEE T AUDIO SPEECH, V15, P601, DOI 10.1109/TASL.2006.881678; Gebru ID, 2018, IEEE T PATTERN ANAL, V40, P1086, DOI 10.1109/TPAMI.2017.2648793; Gebru ID, 2016, IEEE T PATTERN ANAL, V38, P2402, DOI 10.1109/TPAMI.2016.2522425; Gold B., 2011, SPEECH AUDIO SIGNAL, DOI 10.1002/9781118142882; Hospedales TM, 2008, IEEE T PATTERN ANAL, V30, P2140, DOI 10.1109/TPAMI.2008.25; Kilic V, 2016, IEEE T MULTIMEDIA, V18, P2417, DOI 10.1109/TMM.2016.2599150; Kilic V, 2015, IEEE T MULTIMEDIA, V17, P186, DOI 10.1109/TMM.2014.2377515; Lathoud G, 2005, LECT NOTES COMPUT SC, V3361, P182; Lathoud G, 2005, INT CONF ACOUST SPEE, P265; Li XF, 2019, IEEE J-STSP, V13, P88, DOI 10.1109/JSTSP.2019.2903472; Li XF, 2017, IEEE-ACM T AUDIO SPE, V25, P1997, DOI 10.1109/TASLP.2017.2740001; Li XF, 2016, IEEE-ACM T AUDIO SPE, V24, P2171, DOI 10.1109/TASLP.2016.2598319; Liu Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4304; Liu Y, 2017, LECT NOTES COMPUT SC, V10169, P344, DOI 10.1007/978-3-319-53547-0_33; Lombard A, 2011, IEEE T AUDIO SPEECH, V19, P1490, DOI 10.1109/TASL.2010.2092765; Milan Anton, 2016, ARXIV PREPRINT ARXIV; Minotto VP, 2015, IEEE T MULTIMEDIA, V17, P1694, DOI 10.1109/TMM.2015.2463722; Naqvi SM, 2010, IEEE J-STSP, V4, P895, DOI 10.1109/JSTSP.2010.2057198; Noulas A, 2012, IEEE T PATTERN ANAL, V34, P79, DOI 10.1109/TPAMI.2011.47; Qian XY, 2017, INT CONF ACOUST SPEE, P2896, DOI 10.1109/ICASSP.2017.7952686; Ristic B, 2011, IEEE T SIGNAL PROCES, V59, P3452, DOI 10.1109/TSP.2011.2140111; Schult N, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137057; Valin JM, 2007, ROBOT AUTON SYST, V55, P216, DOI 10.1016/j.robot.2006.08.004; Vijayasenan D, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P2167; Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749	41	7	7	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1761	1776		10.1109/TPAMI.2019.2953020	http://dx.doi.org/10.1109/TPAMI.2019.2953020			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31751223	Green Submitted			2022-12-18	WOS:000637533800020
J	Wang, JY; Chakraborty, R; Yu, SX				Wang, Jiayun; Chakraborty, Rudrasis; Yu, Stella X.			Transformer for 3D Point Clouds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Convolution; Feature extraction; Shape; Semantics; Task analysis; Measurement; point cloud; transformation; deformable; segmentation; 3D detection	NETWORKS	Deep neural networks are widely used for understanding 3D point clouds. At each point convolution layer, features are computed from local neighbourhoods of 3D points and combined for subsequent processing in order to extract semantic information. Existing methods adopt the same individual point neighborhoods throughout the network layers, defined by the same metric on the fixed input point coordinates. This common practice is easy to implement but not necessarily optimal. Ideally, local neighborhoods should be different at different layers, as more latent information is extracted at deeper layers. We propose a novel end-to-end approach to learn different non-rigid transformations of the input point cloud so that optimal local neighborhoods can be adopted at each layer. We propose both linear (affine) and non-linear (projective and deformable) spatial transformers for 3D point clouds. With spatial transformers on the ShapeNet part segmentation dataset, the network achieves higher accuracy for all categories, with 8 percent gain on earphones and rockets in particular. Our method also outperforms the state-of-the-art on other point cloud tasks such as classification, detection, and semantic segmentation. Visualizations show that spatial transformers can learn features more efficiently by dynamically altering local neighborhoods according to the geometry and semantics of 3D shapes in spite of their within-category variations.	[Wang, Jiayun; Chakraborty, Rudrasis; Yu, Stella X.] UC Berkeley ICSI, Berkeley, CA 94704 USA		Yu, SX (corresponding author), UC Berkeley ICSI, Berkeley, CA 94704 USA.	peterwg@berkeley.edu; rudra@berkeley.edu; stellayu@berkeley.edu			Berkeley Deep Drive; DARPA	Berkeley Deep Drive; DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This work was supported in part by Berkeley Deep Drive and DARPA. The authors thank Utkarsh Singhal and Daniel Zeng for proofreading, and anonymous reviewers for their insightful comments. Our code is publicly available at http://pwang.pw/spn.html.	Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x; Armeni I, 2016, PROC CVPR IEEE, P1534, DOI 10.1109/CVPR.2016.170; Chang Angel X., 2015, ARXIV151203012CSGR P; Chen YP, 2018, PROC CVPR IEEE, P5870, DOI 10.1109/CVPR.2018.00615; Dai A, 2018, PROC CVPR IEEE, P4578, DOI 10.1109/CVPR.2018.00481; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035; Gadelha M, 2018, LECT NOTES COMPUT SC, V11211, P105, DOI 10.1007/978-3-030-01234-2_7; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P658, DOI 10.1109/TIP.2018.2868426; Huang Q, 2019, VOXELNET END TO END; Jaderberg M, 2015, ADV NEUR IN, V28; Jampani V, 2016, PROC CVPR IEEE, P4452, DOI 10.1109/CVPR.2016.482; Kalogerakis E, 2017, PROC CVPR IEEE, P6630, DOI 10.1109/CVPR.2017.702; Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479; Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979; Li PL, 2018, LECT NOTES COMPUT SC, V11206, P664, DOI 10.1007/978-3-030-01216-8_40; Li YY, 2018, ADV NEUR IN, V31; Lin CH, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P1075; Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481; Qi CR, 2017, ADV NEUR IN, V30; Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609; Rambach JR, 2016, INT SYM MIX AUGMENT, P71, DOI 10.1109/ISMAR.2016.19; Rethage D, 2018, LECT NOTES COMPUT SC, V11208, P625, DOI 10.1007/978-3-030-01225-0_37; Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701; Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268; Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114; Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409; Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230; Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651; Tulsiani S, 2018, PROC CVPR IEEE, P302, DOI 10.1109/CVPR.2018.00039; Vasu S, 2018, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2018.00073; Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362; Wu BC, 2018, IEEE INT CONF ROBOT, P1887; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571; Zhou L, 2018, LECT NOTES COMPUT SC, V11219, P527, DOI 10.1007/978-3-030-01267-0_31; Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472	44	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	44	8					4419	4431		10.1109/TPAMI.2021.3070341	http://dx.doi.org/10.1109/TPAMI.2021.3070341			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HQ	33793397	Green Submitted			2022-12-18	WOS:000820522000001
J	Ye, KR; Nazari, NH; Hahn, J; Hussain, Z; Zhang, MD; Kovashka, A				Ye, Keren; Nazari, Narges Honarvar; Hahn, James; Hussain, Zaeem; Zhang, Mingda; Kovashka, Adriana			Interpreting the Rhetoric of Visual Advertisements	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Task analysis; Media; Rhetoric; Cognition; Decoding; Computer vision; Visual reasoning; vision and language; video understanding; representation learning; visual rhetoric; atypicality		Visual media have important persuasive power, but prior computer vision approaches have predominantly ignored the persuasive aspects of images. In this work, we propose a suite of data and techniques that enable progress on understanding the messages that visual advertisements convey. We make available a dataset of 64,832 image ads and 3,477 video ads, annotated with ten types of information: the topic and sentiment of the ad; whether it is funny, exciting, or effective; what action it prompts the viewer to do, and what arguments it provides for why this action should be taken; symbolic associations that the ad relies on; the metaphorical object transformations on which especially creative ads rely; and the climax in video ads. We develop methods that use multimodal cues, i.e., both visuals and slogans, for both the image and video domains. Our methods rely on finding poignant content spatially and temporally. We also examine the creative story construction in ads: for videos, we learn to predict when the climax occurs (if any), and how effective the story is; for images, we analyze how object transformations in ads metaphorically depict product properties.	[Ye, Keren; Nazari, Narges Honarvar; Hahn, James; Hussain, Zaeem; Zhang, Mingda; Kovashka, Adriana] Univ Pittsburgh, Pittsburgh, PA 15260 USA; [Hahn, James] Georgia Tech, Atlanta, GA 30332 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; University System of Georgia; Georgia Institute of Technology	Kovashka, A (corresponding author), Univ Pittsburgh, Pittsburgh, PA 15260 USA.	yekeren@cspitt.edu; nah114@pitt.edu; jrh160@pitt.edu; zaeem@cspitt.edu; mzhang@cspitt.edu; kovashka@cspitt.edu		Hahn, James/0000-0003-1950-4914	US National Science Foundation [1566270]; Google Faculty Research Awards; NVIDIA	US National Science Foundation(National Science Foundation (NSF)); Google Faculty Research Awards(Google Incorporated); NVIDIA	The authors would like to thank Christopher Thomas, Xiaozhong Zhang, Zuha Agha, Nathan Ong, and Kyle Buettner for early work on this project, and Sanchayan Sarkar for help with the face data. This material is based upon work supported by the US National Science Foundation under Grant 1566270. It was also supported by Google Faculty Research Awards and an NVIDIA hardware grant.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Agrela F, 2018, NEW TRENDS ECO EFFIC; Amos B, 2016, CMU SCH COMPUTER SCI, V6; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Azimi J., 2012, P ACM INT C INF KNOW, P495; Bakshy E, 2015, SCIENCE, V348, P1130, DOI 10.1126/science.aaa1160; Battista J., 2014, R GOODELL NFL RIGHTL; Boneh D., 2019, P ACM SIGSAC C COMP; Bylinskii Z., 2017, ARXIV170909215; Castellano B., PYSCENEDETECT; Cheng H., 2012, P ACM SIGKDD INT C K, P777; Chilton L. B., 2019, P ACM C HUM FACT COM; Choi J, 2016, PROC CVPR IEEE, P3122, DOI 10.1109/CVPR.2016.340; Choi MJ, 2012, PATTERN RECOGN LETT, V33, P853, DOI 10.1016/j.patrec.2011.12.004; Cosgrove B., 2014, PHOTOCHANGED FACE AI; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Eisenschtat A, 2017, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2017.201; Faghri Fartash, 2018, BMVC, P12; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gauch JM, 2006, COMPUT VIS IMAGE UND, V103, P80, DOI 10.1016/j.cviu.2006.03.002; Groden C., THIS IS MUCH 2016 SU; Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750; Gurari D, 2018, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR.2018.00380; Harwath D, 2018, LECT NOTES COMPUT SC, V11210, P659, DOI 10.1007/978-3-030-01231-1_40; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hendricks LA, 2018, LECT NOTES COMPUT SC, V11207, P793, DOI 10.1007/978-3-030-01219-9_47; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hollis N., 2011, WHY GOOD ADVERTISING; Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351; Hussain Z, 2017, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.2017.123; Iyyer M, 2017, PROC CVPR IEEE, P6478, DOI 10.1109/CVPR.2017.686; Johnson J, 2017, IEEE I CONF COMP VIS, P3008, DOI 10.1109/ICCV.2017.325; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Joo J, 2015, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2015.423; Joo J, 2014, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2014.35; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kembhavi A, 2016, LECT NOTES COMPUT SC, V9908, P235, DOI 10.1007/978-3-319-46493-0_15; Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Li H, 2015, J ADVERTISING, V44, P208, DOI 10.1080/00913367.2014.956376; Liebhart K, 2017, MEDIA COMMUN-LISBON, V5, P15, DOI 10.17645/mac.v5i4.1062; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu A, 2008, IEEE WORK APP COMP, P223; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; McDuff D, 2015, IEEE T AFFECT COMPUT, V6, P223, DOI 10.1109/TAFFC.2014.2384198; Mei T, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071402; Messaris P., 1997, VISUAL PERSUASION RO; Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923; Munoz CL, 2017, J POLITICAL MARKETIN, V16, P290, DOI 10.1080/15377857.2017.1334254; ONeill M., 2015, OLD SPICE RESPONSE C; Peng YL, 2018, J COMMUN, V68, P920, DOI 10.1093/joc/jqy041; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; Poels K, 2006, J ADVERTISING RES, V46, P18, DOI 10.2501/S0021849906060041; Ramalingam V, 2006, EXPERT SYST APPL, V31, P159, DOI 10.1016/j.eswa.2005.09.014; Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291; Rasheed Z, 2002, INT C PATT RECOG, P1086, DOI 10.1109/ICPR.2002.1048494; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Resnick P, 2013, P 2013 C COMP SUPP C, P95, DOI [10.1145/2441955.2441981, DOI 10.1145/2441955.2441981]; Saleh B, 2016, AAAI CONF ARTIF INTE, P3588; Sanchez JM, 2002, MULTIMED TOOLS APPL, V18, P233, DOI 10.1023/A:1019996817159; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sethi R. J., 2013, P ACM INT C MULT, P813; Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499; SINGH SN, 1993, J MARKETING RES, V30, P91, DOI 10.2307/3172516; Soomro K., 2012, ARXIV; Stip H, 2018, J ADVERTISING RES, V58, P138, DOI 10.2501/JAR-2018-022; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501; Teixeira T, 2012, J MARKETING RES, V49, P144, DOI 10.1509/jmr.10.0207; Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444; Vicol P, 2018, PROC CVPR IEEE, P8581, DOI 10.1109/CVPR.2018.00895; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang P, 2016, PROC CVPR IEEE, P1573, DOI 10.1109/CVPR.2016.174; Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684; Williamson J., 1978, DECODING ADVERTISEME; Winslow D. R., 2011, PULITZER EDDIE ADAMS; Won D, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P786, DOI 10.1145/3123266.3123282; Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309; Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500; Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28; Xu X, 2015, AM J PREV MED, V48, P318, DOI 10.1016/j.amepre.2014.10.011; Yadati K, 2014, IEEE T MULTIMEDIA, V16, P15, DOI 10.1109/TMM.2013.2282128; Ye K., 2018, P BRIT MACH VIS C; Ye KR, 2018, LECT NOTES COMPUT SC, V11219, P868, DOI 10.1007/978-3-030-01267-0_51; Young C. E., 2008, ADVERTISING RES HDB; Zauner C., 2010, IMPLEMENTATION BENCH; [Zhang Haihui 张海辉], 2005, [兰州大学学报. 自然科学版, Journal of Lanzhou University.Natural Science], V41, P93; Zhao J., 2017, P C EMP METH NAT LAN, P2941; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009	93	7	7	2	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1308	1323		10.1109/TPAMI.2019.2947440	http://dx.doi.org/10.1109/TPAMI.2019.2947440			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	QT3YJ	31634123				2022-12-18	WOS:000626525300015
J	Turkoglu, MO; D'Aronco, S; Wegner, J; Schindler, K				Turkoglu, Mehmet Ozgur; D'Aronco, Stefano; Wegner, Jan; Schindler, Konrad			Gating Revisited: Deep Multi-Layer RNNs That can be Trained	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer architecture; Microprocessors; Training; Logic gates; Recurrent neural networks; Task analysis; Lattices; Recurrent neural network; deep RNN; multi-layer RNN		We propose a new STAckable Recurrent cell (STAR) for recurrent neural networks (RNNs), which has fewer parameters than widely used LSTM [16] and GRU [10] while being more robust against vanishing or exploding gradients. Stacking recurrent units into deep architectures suffers from two major limitations: (i) many recurrent cells (e.g., LSTMs) are costly in terms of parameters and computation resources; and (ii) deep RNNs are prone to vanishing or exploding gradients during training. We investigate the training of multi-layer RNNs and examine the magnitude of the gradients as they propagate through the network in the "vertical" direction. We show that, depending on the structure of the basic recurrent unit, the gradients are systematically attenuated or amplified. Based on our analysis we design a new type of gated cell that better preserves gradient magnitude. We validate our design on a large number of sequence modelling tasks and demonstrate that the proposed STAR cell allows to build and train deeper recurrent architectures, ultimately leading to improved performance while being computationally more efficient.	[Turkoglu, Mehmet Ozgur; D'Aronco, Stefano; Wegner, Jan; Schindler, Konrad] Swiss Fed Inst Technol, EcoVis Lab, Photogrammetry & Remote Sensing, CH-8092 Zurich, Switzerland; [Wegner, Jan] Univ Zurich, Inst Computat Sci, CH-8006 Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich; Universita della Svizzera Italiana; University of Zurich	Turkoglu, MO (corresponding author), Swiss Fed Inst Technol, EcoVis Lab, Photogrammetry & Remote Sensing, CH-8092 Zurich, Switzerland.	ozgur.turkoglu@geod.baug.ethz.ch; stefano.daronco@geod.baug.ethz.ch; jan.wegner@geod.baug.ethz.ch; konrad.schindler@geod.baug.ethz.ch			Swiss Federal Office for Agriculture (FOAG)	Swiss Federal Office for Agriculture (FOAG)	The author would like to thank the Swiss Federal Office for Agriculture (FOAG) for partially funding this research project through the DeepField Project.	Arjovsky M, 2016, PR MACH LEARN RES, V48; Bai S., 2018, ARXIV PREPRINT ARXIV; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Campos V., 2018, PROC INT C LEARN REP; Chang B., 2019, INT C LEARN REPR; Chung JY, 2015, PR MACH LEARN RES, V37, P2067; Cooijmans T., 2017, P INT C LEARN REPR; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Gulehre C, 2014, NETWORKS SEQUENCE MO; Henaff M, 2016, PR MACH LEARN RES, V48; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hochreiter S., 1991, THESIS TU MUNCHEN; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Kim J, 2017, INTERSPEECH, P1591, DOI 10.21437/Interspeech.2017-477; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Le Q.V., 2015, ABS150400941 CORR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee J, 2020, J STAT MECH-THEORY E, V2020, DOI 10.1088/1742-5468/abc62b; Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572; Materzynska J, 2019, IEEE INT CONF COMP V, P2874, DOI 10.1109/ICCVW.2019.00349; Mhammedi Z, 2017, PR MACH LEARN RES, V70; Moray A., 2005, ADV NEURAL INF PROCE, V17, P25; Poliner G. E., 2006, EURASIP J ADV SIG PR, P1; Pradhan S., 2016, EXPLORING DEPTHS REC; Russwurm M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7040129; Russwurm M, 2017, IEEE COMPUT SOC CONF, P1496, DOI 10.1109/CVPRW.2017.193; Ruwurm M., 2019, ARXIV190511893; Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115; Shi XJ, 2015, ADV NEUR IN, V28; Simonyan K., 2014, 3 INT C LEARN REPR I; Subakan YC, 2017, IEEE WORK APPL SIG, P354; Sutskever I, 2014, ADV NEUR IN, V27; Van Der Westhuizen J., 2018, ARXIV 180404849; Vaswani A, 2017, ADV NEUR IN, V30; Vinyals O, 2015, ICML DEEP LEARN WORK; Vorontsov E, 2017, PR MACH LEARN RES, V70; Wang Z., 2019, ARXIV 190705572; Wisdom S, 2016, ADV NEUR IN, V29; Zhang L, 2018, ADV NEUR IN, V31; Zhang S., 2016, PROC INT C NEURAL IN	47	7	6	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 9	2021	44	8					4081	4092		10.1109/TPAMI.2021.3064878	http://dx.doi.org/10.1109/TPAMI.2021.3064878			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HO	33687837	Green Submitted			2022-12-18	WOS:000820521800003
J	Hou, JY; Zhang, F; Qiu, HQ; Wang, JJ; Wang, Y; Meng, DY				Hou, Jingyao; Zhang, Feng; Qiu, Haiquan; Wang, Jianjun; Wang, Yao; Meng, Deyu			Robust Low-Tubal-Rank Tensor Recovery From Binary Measurements	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						One-bit tensor recovery; low-tubal-rank tensor; tensor hard singular tube thresholding; tensor nuclear norm minimization; adaptivity	MATRIX RECOVERY; FACTORIZATION; REGRESSION; ALGORITHM; FRAMEWORK; NOISY	Low-rank tensor recovery (LRTR) is a natural extension of low-rank matrix recovery (LRMR) to high-dimensional arrays, which aims to reconstruct an underlying tensor X from incomplete linear measurements M (X). However, LRTR ignores the error caused by quantization, limiting its application when the quantization is low-level. In this work, we take into account the impact of extreme quantization and suppose the quantizer degrades into a comparator that only acquires the signs of M (X). We still hope to recover X from these binary measurements. Under the tensor Singular Value Decomposition (t-SVD) framework, two recovery methods are proposed-the first is a tensor hard singular tube thresholding method; the second is a constrained tensor nuclear norm minimization method. These methods can recover a real n(1) x n(2) x n(3) tensor X with tubal rank r from m random Gaussian binary measurements with errors decaying at a polynomial speed of the oversampling factor lambda := m/((n(1) + n(2)) n(3)r). To improve the convergence rate, we develop a new quantization scheme under which the convergence rate can be accelerated to an exponential function of lambda. Numerical experiments verify our results, and the applications to real-world data demonstrate the promising performance of the proposed methods.	[Hou, Jingyao; Zhang, Feng; Wang, Jianjun] Southwest Univ, Sch Math & Stat, Chongqing 400715, Peoples R China; [Qiu, Haiquan; Meng, Deyu] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China; [Wang, Jianjun] Southwest Univ, Res Inst Intelligent Finance & Digital Econ, Chongqing 400715, Peoples R China; [Wang, Yao] Xi An Jiao Tong Univ, Sch Management, Ctr Intelligent Decis Making & Machine Learning, Xian 710049, Shaanxi, Peoples R China; [Meng, Deyu] Macau Univ Sci & Technol, Fac Informat Technol, Taipa, Macau, Peoples R China	Southwest University - China; Xi'an Jiaotong University; Southwest University - China; Xi'an Jiaotong University; Macau University of Science & Technology	Wang, JJ (corresponding author), Southwest Univ, Sch Math & Stat, Chongqing 400715, Peoples R China.; Wang, Y (corresponding author), Xi An Jiao Tong Univ, Sch Management, Ctr Intelligent Decis Making & Machine Learning, Xian 710049, Shaanxi, Peoples R China.	houjingyao@email.swu.edu.cn; zhangf@email.swu.edu.cn; qiuhaiquan@stu.xjtu.edu.cn; wjj@swu.edu.cn; yao.s.wang@gmail.com; dymeng@mail.xjtu.edu.cn		Hou, Jingyao/0000-0002-7539-8207	National Key Research and Development Program of China [2018YFB1402600]; National Natural Science Foundation of China [12071380, 11761003, 11901476, 11971374, 61773367]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China under Grant 2018YFB1402600 and in part the National Natural Science Foundation of China under Grants 12071380, 11761003, 11901476, 11971374, and 61773367.	Aidini A., 2018, ELECT IMAG, V13, P1; Aidini A, 2020, INT CONF ACOUST SPEE, P2453, DOI 10.1109/ICASSP40776.2020.9053151; Ameri A, 2019, IEEE T SIGNAL PROCES, V67, P5297, DOI 10.1109/TSP.2019.2939086; Bach F, 2010, ELECTRON J STAT, V4, P384, DOI 10.1214/09-EJS521; Baraniuk RG, 2017, IEEE T INFORM THEORY, V63, P3368, DOI 10.1109/TIT.2017.2688381; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Boufounos PT, 2008, 2008 42ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-3, P16, DOI 10.1109/CISS.2008.4558487; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Boyd S, 2003, STANFORD U LECT NOTE; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204; Foucart S, 2019, INVERSE PROBL IMAG, V13, P703, DOI 10.3934/ipi.2019032; Gandy S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/2/025010; Gao PZ, 2018, IEEE T SIGNAL PROCES, V66, P2918, DOI 10.1109/TSP.2018.2821648; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Ghadermarzy N, 2019, IEEE T SIGNAL PROCES, V67, P29, DOI 10.1109/TSP.2018.2879031; Hillar CJ, 2013, J ACM, V60, DOI 10.1145/2512329; Hou JY, 2020, INT CONF ACOUST SPEE, P3302, DOI 10.1109/ICASSP40776.2020.9054163; Hou JY, 2020, INVERSE PROBL, V36, DOI 10.1088/1361-6420/ab779b; Jacques L, 2013, IEEE T INFORM THEORY, V59, P2082, DOI 10.1109/TIT.2012.2234823; Jiang TX, 2019, IEEE T IMAGE PROCESS, V28, P2089, DOI 10.1109/TIP.2018.2880512; Khobahi S, 2019, INT CONF ACOUST SPEE, P2987, DOI 10.1109/ICASSP.2019.8683876; Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711; Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020; Knudson K, 2016, IEEE T INFORM THEORY, V62, P2748, DOI 10.1109/TIT.2016.2527637; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Le B, 2005, IEEE SIGNAL PROC MAG, V22, P69, DOI 10.1109/MSP.2005.1550190; Li BH, 2019, IEEE T IMAGE PROCESS, V28, P170, DOI 10.1109/TIP.2018.2865837; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Lu CY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2504; Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760; Lukic T, 2014, INVERSE PROBL, V30, DOI 10.1088/0266-5611/30/9/095007; Negahban SN, 2012, STAT SCI, V27, P538, DOI 10.1214/12-STS400; Peng Y, 2014, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2014.377; Plan Y, 2014, DISCRETE COMPUT GEOM, V51, P438, DOI 10.1007/s00454-013-9561-6; Plan Y, 2013, IEEE T INFORM THEORY, V59, P482, DOI 10.1109/TIT.2012.2207945; Pu W, 2021, IEEE T NEUR NET LEAR, V32, P188, DOI 10.1109/TNNLS.2020.2978017; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Semerci O, 2014, IEEE T IMAGE PROCESS, V23, P1678, DOI 10.1109/TIP.2014.2305840; Shashua A, 2001, PROC CVPR IEEE, P42; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Wang H, 2016, IEICE T FUND ELECTR, VE99A, P647, DOI 10.1587/transfun.E99.A.647; Xie Q, 2018, IEEE T PATTERN ANAL, V40, P1888, DOI 10.1109/TPAMI.2017.2734888; Xiong SJ, 2016, INT CONF ACOUST SPEE, P2189, DOI 10.1109/ICASSP.2016.7472065; Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811; Zhang F., 2020, SCI CHINA INFORM SCI, V64; Zhang F, 2021, IEEE T PATTERN ANAL, V43, P3492, DOI 10.1109/TPAMI.2020.2986773; Zhang F, 2020, J COMPUT APPL MATH, V374, DOI 10.1016/j.cam.2020.112767; Zhang ZM, 2017, IEEE T SIGNAL PROCES, V65, P1511, DOI 10.1109/TSP.2016.2639466; Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485; Zhao B, 2010, I S BIOMED IMAGING, P996, DOI 10.1109/ISBI.2010.5490156; Zhou P, 2018, IEEE T IMAGE PROCESS, V27, P1152, DOI 10.1109/TIP.2017.2762595	54	7	7	14	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 3	2021	44	8					4355	4373		10.1109/TPAMI.2021.3063527	http://dx.doi.org/10.1109/TPAMI.2021.3063527			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6IC	33656988				2022-12-18	WOS:000820523200002
J	Le, H; Chin, TJ; Eriksson, A; Do, TT; Suter, D				Le, Huu; Chin, Tat-Jun; Eriksson, Anders; Do, Thanh-Toan; Suter, David			Deterministic Approximate Methods for Maximum Consensus Robust Fitting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Approximation algorithms; Optimization; Computer vision; Mathematical model; Estimation; Computational modeling; Data models; Maximum consensus; robust fitting; deterministic algorithm; approximate algorithm		Maximum consensus estimation plays a critically important role in several robust fitting problems in computer vision. Currently, the most prevalent algorithms for consensus maximization draw from the class of randomized hypothesize-and-verify algorithms, which are cheap but can usually deliver only rough approximate solutions. On the other extreme, there are exact algorithms which are exhaustive search in nature and can be costly for practical-sized inputs. This paper fills the gap between the two extremes by proposing deterministic algorithms to approximately optimize the maximum consensus criterion. Our work begins by reformulating consensus maximization with linear complementarity constraints. Then, we develop two novel algorithms: one based on non-smooth penalty method with a Frank-Wolfe style optimization scheme, the other based on the Alternating Direction Method of Multipliers (ADMM). Both algorithms solve convex subproblems to efficiently perform the optimization. We demonstrate the capability of our algorithms to greatly improve a rough initial estimate, such as those obtained using least squares or a randomized algorithm. Compared to the exact algorithms, our approach is much more practical on realistic input sizes. Further, our approach is naturally applicable to estimation problems with geometric residuals. Matlab code and demo program for our methods can be downloaded from https://goo.gl/FQcxpi.	[Le, Huu] Chalmers Univ Technol, S-41296 Gothenburg, Sweden; [Chin, Tat-Jun] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Eriksson, Anders] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia; [Do, Thanh-Toan] Univ Liverpool, Dept Comp Sci, Liverpool L69 3BX, Merseyside, England; [Suter, David] Edith Cowan Univ, Sch Sci, Joondalup, WA 6027, Australia	Chalmers University of Technology; University of Adelaide; University of Queensland; University of Liverpool; Edith Cowan University	Le, H (corresponding author), Chalmers Univ Technol, S-41296 Gothenburg, Sweden.	huul@chalmers.se; tat-jun.chin@adelaide.edu.au; a.eriksson@uq.edu.au; thanh-toan.do@liverpool.ac.uk; david.suter@adelaide.edu.au		Suter, David/0000-0001-6306-3023; Le, Huu/0000-0001-7562-7180	 [DP160103490];  [FT170100072];  [CE140100016]	; ; 	Chin and Suter were supported by DP160103490. Eriksson was supported by FT170100072. The authors are also grateful to CE140100016 which funded this collaborative work.	Aftab K, 2015, IEEE WINT CONF APPL, P480, DOI 10.1109/WACV.2015.70; Agarwal S, 2008, PROC CVPR IEEE, P2894, DOI 10.1109/CVPR.2008.4587713; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Chin TJ, 2015, PROC CVPR IEEE, P2413, DOI 10.1109/CVPR.2015.7298855; Choi S., 1997, P BRIT MACH VIS C, V24, P271; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Enqvist O, 2012, LECT NOTES COMPUT SC, V7572, P738, DOI 10.1007/978-3-642-33718-5_53; Eriksson A, 2016, PROC CVPR IEEE, P1754, DOI 10.1109/CVPR.2016.194; Eriksson A, 2015, IEEE WINT CONF APPL, P310, DOI 10.1109/WACV.2015.48; Eriksson A, 2014, PROC CVPR IEEE, P4066, DOI 10.1109/CVPR.2014.518; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; Hartley R, 2007, LECT NOTES COMPUT SC, V4843, P13; Hong MY, 2016, SIAM J OPTIMIZ, V26, P337, DOI 10.1137/140990309; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Kahl F, 2005, IEEE I CONF COMP VIS, P1002; Ke Q, 2007, IEEE T PATTERN ANAL, V29, P1834, DOI 10.1109/TPAMI.2007.1083; Le H, 2017, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.2017.48; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; Li HD, 2009, IEEE I CONF COMP VIS, P1074, DOI 10.1109/ICCV.2009.5459398; MANGASARIAN OL, 1978, MATH PROGRAM STUD, V7, P74, DOI 10.1007/BFb0120783; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Olsson C, 2008, PROC CVPR IEEE, P3230; Olsson C, 2010, PROC CVPR IEEE, P1450, DOI 10.1109/CVPR.2010.5539800; Raguram R, 2009, IEEE I CONF COMP VIS, P2074, DOI 10.1109/ICCV.2009.5459456; Sim Kristy, 2006, IEEE COMP SOC C COMP, P485; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Tordoff BJ, 2005, IEEE T PATTERN ANAL, V27, P1523, DOI 10.1109/TPAMI.2005.199; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z; Wong HS, 2011, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2011.6126350; Yinqiang Zheng, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1825, DOI 10.1109/CVPR.2011.5995640; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	35	7	7	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					842	857		10.1109/TPAMI.2019.2939307	http://dx.doi.org/10.1109/TPAMI.2019.2939307			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31494545	Green Submitted			2022-12-18	WOS:000616309900007
J	Tang, SL; Huang, XL; Chen, MJ; Sun, CJ; Yang, J				Tang, Sanli; Huang, Xiaolin; Chen, Mingjian; Sun, Chengjin; Yang, Jie			Adversarial Attack Type I: Cheat Classifiers by Significant Changes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Neural networks; Training; Aerospace electronics; Toy manufacturing industry; Sun; Face recognition; Task analysis; Adversarial attack; type I error; supervised variational autoencoder		Despite the great success of deep neural networks, the adversarial attack can cheat some well-trained classifiers by small permutations. In this paper, we propose another type of adversarial attack that can cheat classifiers by significant changes. For example, we can significantly change a face but well-trained neural networks still recognize the adversarial and the original example as the same person. Statistically, the existing adversarial attack increases Type II error and the proposed one aims at Type I error, which are hence named as Type II and Type I adversarial attack, respectively. The two types of attack are equally important but are essentially different, which are intuitively explained and numerically evaluated. To implement the proposed attack, a supervised variation autoencoder is designed and then the classifier is attacked by updating the latent variables using gradient information. Besides, with pre-trained generative models, Type I attack on latent spaces is investigated as well. Experimental results show that our method is practical and effective to generate Type I adversarial examples on large-scale image datasets. Most of these generated examples can pass detectors designed for defending Type II attack and the strengthening strategy is only efficient with a specific type attack, both implying that the underlying reasons for Type I and Type II attack are different.	[Tang, Sanli; Huang, Xiaolin; Chen, Mingjian; Sun, Chengjin; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China; [Tang, Sanli; Huang, Xiaolin; Chen, Mingjian; Sun, Chengjin; Yang, Jie] Shanghai Jiao Tong Univ, Inst Med Robot, Shanghai 200240, Peoples R China; [Tang, Sanli; Huang, Xiaolin; Chen, Mingjian; Sun, Chengjin; Yang, Jie] Shanghai Jiao Tong Univ, MOE Key Lab Syst Control & Informat Proc, Shanghai 200240, Peoples R China	Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University	Huang, XL; Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.; Huang, XL; Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Med Robot, Shanghai 200240, Peoples R China.; Huang, XL; Yang, J (corresponding author), Shanghai Jiao Tong Univ, MOE Key Lab Syst Control & Informat Proc, Shanghai 200240, Peoples R China.	tangsanli@sjtu.edu.cn; xiaolinhuang@sjtu.edu.cn; w179261466@sjtu.edu.cn; sunchengjin@sjtu.edu.cn; jieyang@sjtu.edu.cn		Sun, Chengjin/0000-0002-9992-7919	National Natural Science Foundation of China [61977046, 61603248, 61876107, U1803261]; Committee of Science and Technology, Shanghai, China [19510711200]; 1000-Talent Plan (Young Program)	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Committee of Science and Technology, Shanghai, China; 1000-Talent Plan (Young Program)	This work was partially supported by National Natural Science Foundation of China (61977046, 61603248, 61876107, U1803261), Committee of Science and Technology, Shanghai, China (No.19510711200), and 1000-Talent Plan (Young Program). The authors thank Mr. Sizhe Chen and Mr. Haoyuan Chi in Shanghai Jiao Tong University for helpful discussions. The authors are grateful to the anonymous reviewers for their insightful comments. (S. Tang and X. Huang contributed equally to this work.)	Abadi M., TENSORFLOW LARGE SCA; Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640; [Anonymous], 2016, 2016 IEEE C COMPUTER, DOI [DOI 10.1109/CVPR.2016.90, 10.1109/CVPR.2016.90]; Baluja S, 2018, AAAI CONF ARTIF INTE, P2687; Berthelot D., 2017, BEGAN BOUNDARY EQUIL; Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49; Chen PY, 2018, AAAI CONF ARTIF INTE, P10; Dai Z., 2017, ADV NEURAL INFORM PR, P6510; Evans D., 2018, P NETW DISTR SYST SE; Gilmer J., 2018, INT C LEARN REPR WOR; Goodfellow I. J., 2015, INT C LEARN REPR ICL; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Huang G.B., 2008, WORKSHOP FACESREAL L; Huang H., 2018, P ADV NEURAL INFORM, P52; Kannan Harini, 2018, ARXIV180306373; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Katz G, 2017, ELECTRON P THEOR COM, P19, DOI 10.4204/EPTCS.257.3; Kingma D.P., 2015, ICLR, P1; Kingma DP, 2014, ADV NEUR IN, P3581, DOI DOI 10.5555/2969033.2969226; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kurakin A., 2018, ARTIF INTELL, P99, DOI DOI 10.1201/9781351251389-8; Lample G., 2017, FADER NETWORKS MANIP; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2017, GENERATIVE ADVERSARI; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Madry A., 2018, P INT C LEARN REPR; Makhzani A., 2015, ICLR WORKSH, DOI DOI 10.3389/FPHAR.2020.565644; Mirza M., 2014, ARXIV PREPRINT ARXIV; Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282; Odena A, 2017, PR MACH LEARN RES, V70; Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Song Y., 2018, ADV NEURAL INFORM PR, P8312; Szegedy C., 2014, ICLR 2014; Tramer F., 2018, P INT C LEARN REPR; Upchurch P, 2017, PROC CVPR IEEE, P6090, DOI 10.1109/CVPR.2017.645; Wang B., 2017, P INT C LEARN REPR; Welling M, 2014, AUTOENCODING VARIATI; Xiao CW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3905; Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660	41	7	7	3	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					1100	1109		10.1109/TPAMI.2019.2936378	http://dx.doi.org/10.1109/TPAMI.2019.2936378			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31442970	Green Submitted			2022-12-18	WOS:000616309900025
J	Chrysos, GG; Moschoglou, S; Bouritsas, G; Deng, JK; Panagakis, Y; Zafeiriou, S				Chrysos, Grigorios G.; Moschoglou, Stylianos; Bouritsas, Giorgos; Deng, Jiankang; Panagakis, Yannis; Zafeiriou, Stefanos			Deep Polynomial Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Polynomial neural networks; tensor decompositions; high-order polynomials; generative models; discriminative models; face verification	RECOGNITION; MODEL	Deep convolutional neural networks (DCNNs) are currently the method of choice both for generative, as well as for discriminative learning in computer vision and machine learning. The success of DCNNs can be attributed to the careful selection of their building blocks (e.g., residual blocks, rectifiers, sophisticated normalization schemes, to mention but a few). In this paper, we propose pi-Nets, a new class of function approximators based on polynomial expansions. pi-Nets are polynomial neural networks, i.e., the output is a high-order polynomial of the input. The unknown parameters, which are naturally represented by high-order tensors, are estimated through a collective tensor factorization with factors sharing. We introduce three tensor decompositions that significantly reduce the number of parameters and show how they can be efficiently implemented by hierarchical neural networks. We empirically demonstrate that pi-Nets are very expressive and they even produce good results without the use of non-linear activation functions in a large battery of tasks and signals, i.e., images, graphs, and audio. When used in conjunction with activation functions, pi-Nets produce state-of-the-art results in three challenging tasks, i.e., image generation, face verification and 3D mesh representation learning. The source code is available at https://github.com/grigorisg9gr/polynomial_nets.	[Chrysos, Grigorios G.] Ecole Polytech Fed Lausanne EPFL, Dept Elect Engn, CH-1015 Lausanne, Switzerland; [Moschoglou, Stylianos; Bouritsas, Giorgos; Deng, Jiankang; Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, London SW7 2AZ, England; [Panagakis, Yannis] Univ Athens, Dept Informat & Telecommun, Athens 15772, Greece	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Imperial College London; National & Kapodistrian University of Athens	Chrysos, GG (corresponding author), Ecole Polytech Fed Lausanne EPFL, Dept Elect Engn, CH-1015 Lausanne, Switzerland.	grigorios.chrysos@epfl.ch; s.moschoglou@imperial.ac.uk; gbouritsas@gmail.com; j.deng16@imperial.ac.uk; i.panagakis@imperial.ac.uk; s.zafeiriou@imperial.ac.uk	Chrysos, Grigorios/ABE-2026-2021	Chrysos, Grigorios/0000-0002-0650-1856; Bouritsas, Giorgos/0000-0002-8476-4918; Panagakis, Ioannis/0000-0003-0153-5210	Imperial College DTA; Imperial President's PhD Scholarship; EPSRC Fellowship DEFORM: Large Scale Shape Analysis of Deformable Models of Humans [EP/S010203/1]; Google Faculty Award	Imperial College DTA; Imperial President's PhD Scholarship; EPSRC Fellowship DEFORM: Large Scale Shape Analysis of Deformable Models of Humans(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Google Faculty Award(Google Incorporated)	Grigorios G. Chrysos conducted this work while at Imperial College London. The work of Stylianos Moschoglou, and Giorgos Bouritsas was supported in part by an Imperial College DTA. The work of Jiankang Deng was supported in part by Imperial President's PhD Scholarship. The work of Stefanos Zafeiriou was partially funded by the EPSRC Fellowship DEFORM: Large Scale Shape Analysis of Deformable Models of Humans (EP/S010203/1) and a Google Faculty Award.	Arora S., 2019, PROC 5 INT C LEARNIN, P1; Bahdanau D., 2015, P 3 INT C LEARNING R; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bogo F, 2017, PROC CVPR IEEE, P5573, DOI 10.1109/CVPR.2017.591; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); Bouritsas G, 2019, IEEE I CONF COMP VIS, P7212, DOI 10.1109/ICCV.2019.00731; Brock AM, 2018, PROCEEDINGS PERVASIVE DISPLAYS 2018: THE 7TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, DOI 10.1145/3205873.3205877; Chen T, 2016, PROC ADV C NEURAL IN; Chrysanidis Georgios, 2019, 2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI), P1, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00046; Chrysos G., 2020, PROC C COMPUT VIS PA, P1; Chrysos G., 2019, ARXIV 190806571; Cohen N., 2016, C LEARNING THEORY, V49, P698; Cohen N, 2016, PR MACH LEARN RES, V48; Defferrard M, 2016, ADV NEUR IN, V29; Deng J., 2019, PROC CVPRW, P0; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Denil Misha, 2013, NIPS, DOI DOI 10.5555/2999792.2999852; Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552; Du Y., 2019, PROC INT C NEURAL IN, P1; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Glorot X., 2010, PROC MACH LEARN RES, P249; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goyal P., 2017, ARXIV 170602677; Grinblat G. L., 2017, ARXIV 170907359; Gulrajani I, 2017, P NIPS 2017; Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6; Han S, 2015, ADV NEUR IN, V28; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hensel M, 2017, ADV NEUR IN, V30; Hoshen Y, 2019, PROC CVPR IEEE, P5804, DOI 10.1109/CVPR.2019.00596; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang Gary B., 2007, 0749 U MASS, P7; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; IVAKHNENKO AG, 1971, IEEE T SYST MAN CYB, VSMC1, P364, DOI 10.1109/TSMC.1971.4308320; Jayakumar S. M., 2020, P INT C LEARN REPR I, P1; Karras T., 2019, C COMPUTER VISION PA, P1; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; Kileel J., 2019, PROC INT C NEURAL IN, P1; Kingma D.P., 2015, INT C LEARN REPR, P1; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Krizhevsky A., 2010, THE CIFAR 10 DATASET; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li CK, 2003, NEURAL PROCESS LETT, V17, P1, DOI 10.1023/A:1022967523886; Liang Y, 2018, ADV NEURAL INFORM PR, P3845; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Lucas T., 2019, ARXIV 190101091; Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033; Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576; Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250; Nair V., 2010, ICML, P807; Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068; Nikolskii S, 2013, ANAL 3 SPAC DIFF FUN; Oh SK, 2003, COMPUT ELECTR ENG, V29, P703, DOI 10.1016/S0045-7906(02)00045-9; Ramachandran P., 2017, ARXIV 171005941; Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43; Reddi Sashank J., 2018, INT C LEARN REPR; Reed S, 2014, PR MACH LEARN RES, V32, P1431; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Salimans T, 2016, ADV NEUR IN, V29; Saxe A., 2014, INT C LEARNING REPRE; Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003; Sengupta S, 2016, IEEE WINT CONF APPL; Shin Y., 1991, IJCNN-91-Seattle: International Joint Conference on Neural Networks (Cat. No.91CH3049-4), P13, DOI 10.1109/IJCNN.1991.155142; Sidiropoulos ND, 2017, IEEE T SIGNAL PROCES, V65, P3551, DOI 10.1109/TSP.2017.2690524; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Stone MH., 1948, MATH MAG, V21, P148, DOI [DOI 10.2307/3029750, DOI 10.2307/3029337]; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tokui Seiya, 2015, P WORKSH MACH LEARN, V5, P1; Ulyanov D., 2016, ARXIV160708022; Velickovic P., 2018, P INT C LEARN REPR; Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275; Voutriaridis C, 2003, PROCEEDINGS EC-VIP-MC 2003, VOLS 1 AND 2, P519; Wang M, 2019, IEEE I CONF COMP VIS, P692, DOI 10.1109/ICCV.2019.00078; Wang WH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2819; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87; Xiao H., 2017, ARXIV 170807747; Xiong Y, 2007, NEURAL COMPUT, V19, P3356, DOI 10.1162/neco.2007.19.12.3356; Yunpeng C., 2018, PROC INT JOINT C ART, P635; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zhang K, 2018, IEEE T CIRC SYST VID, V28, P1303, DOI 10.1109/TCSVT.2017.2654543; Zhao SJ, 2017, PR MACH LEARN RES, V70; Zheng T., 2018, 5 U POSTS TEL; Zheng Tianyue, 2017, ARXIV170808197	95	7	7	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 11	2021	44	8					4021	4034		10.1109/TPAMI.2021.3058891	http://dx.doi.org/10.1109/TPAMI.2021.3058891			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HZ	33571091	Green Submitted			2022-12-18	WOS:000820522900001
J	Cevikalp, H; Saglamlar, H				Cevikalp, Hakan; Saglamlar, Halil			Polyhedral Conic Classifiers for Computer Vision Applications and Open Set Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Support vector machines; Training; Object detection; Visualization; Neural networks; Face; Dogs; Polyhedral conic classifiers; object detection; large margin classifiers; open set recognition	SUPPORT; CLASSIFICATION	This paper introduces a family of quasi-linear discriminants that outperform current large-margin methods in sliding window visual object detection and open set recognition tasks. In these applications, the classification problems are both numerically imbalanced - positive (object class) training and test windows are much rarer than negative (non-class) ones - and geometrically asymmetric - the positive samples typically form compact, visually-coherent groups while negatives are much more diverse, including anything at all that is not a well-centered sample from the target class. For such tasks, there is a need for discriminants whose decision regions focus on tightly circumscribing the positive class, while still taking account of negatives in zones where the two classes overlap. To this end, we propose a family of quasi-linear "polyhedral conic" discriminants whose positive regions are distorted L-1 or L-2 balls. In addition, we also integrated the proposed classification loss into deep neural networks so that both the features and classifier can be learned simultaneously end-to-end fashion to improve the classification accuracies. The methods have properties and run-time complexities comparable to linear Support Vector Machines (SVMs), and they can be trained from either binary or positive-only samples using constrained quadratic programs related to SVMs. Our experiments show that they significantly outperform linear SVMs, deep neural networks using softmax loss function and existing one-class discriminants on a wide range of object detection, face verification, open set recognition and conventional closed-set classification tasks.	[Cevikalp, Hakan; Saglamlar, Halil] Eskisehir Osmangazi Univ, Elect & Elect Engn, TR-26040 Eskisehir, Turkey	Eskisehir Osmangazi University	Cevikalp, H (corresponding author), Eskisehir Osmangazi Univ, Elect & Elect Engn, TR-26040 Eskisehir, Turkey.	hakan.cevikalp@gmail.com; hsaglamlar@gmail.com	; Cevikalp, Hakan/R-1300-2016	Saglamlar, Halil/0000-0003-2805-1929; Cevikalp, Hakan/0000-0002-1708-8817	Scientific and Technological Research Council of Turkey (TUB_ ITAK) [EEEAG-116E080]	Scientific and Technological Research Council of Turkey (TUB_ ITAK)(Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK))	This work was funded in part by the Scientific and Technological Research Council of Turkey (TUB_ ITAK) under Grant number EEEAG-116E080.	Astorino A, 2002, J OPTIMIZ THEORY APP, V112, P265, DOI 10.1023/A:1013649822153; Bagirov AM, 2013, TOP, V21, P3, DOI 10.1007/s11750-011-0241-5; Bagirov AM, 2005, OPTIM METHOD SOFTW, V20, P271, DOI 10.1080/10556780512331318263; Bennett K.P., 2000, ICML, P57; Beveridge J. R., 2013, P 6 INT C BIOMETRICS, P1; Cevikalp H., 2013, 2013 10 IEEE INT C W, P1; Cevikalp H, 2017, PROC CVPR IEEE, P4114, DOI 10.1109/CVPR.2017.438; Cevikalp H, 2017, INT J COMPUT VISION, V123, P334, DOI 10.1007/s11263-016-0986-2; Cevikalp H, 2017, IEEE T PATTERN ANAL, V39, P1076, DOI 10.1109/TPAMI.2016.2587647; Cevikalp H, 2013, PATTERN RECOGN, V46, P1523, DOI 10.1016/j.patcog.2012.11.004; Cevikalp H, 2012, PROC CVPR IEEE, P3138, DOI 10.1109/CVPR.2012.6248047; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dundar M. M., 2008, P 25 INT C MACHINE L, P288; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Franc V, 2009, J MACH LEARN RES, V10, P2157; Fung G., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P77, DOI 10.1145/502512.502527; Gasimov RN, 2006, OPTIM METHOD SOFTW, V21, P527, DOI 10.1080/10556780600723252; Gastaldi Xavier, 2017, ARXIV170507485; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Graham B, 2014, ARXIV14126071; Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7; Hosang Jan, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Huang ZW, 2018, IEEE T PATTERN ANAL, V40, P2827, DOI 10.1109/TPAMI.2017.2776154; Hussain S., THESIS LAB J KUNTZMA, P61; Hussain S., 2010, P BMVC, P1, DOI DOI 10.5244/C.24.112; Ioffe S., 2014, ICLR, P1; Jain V., 2010, UMCS2010009; Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kalal Z., 2008, P BRIT MACH VIS C, P1, DOI DOI 10.5244/C.22.42; Kantchelian A, 2014, ADV NEUR IN, V27; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Mangasarian OL, 2006, IEEE T PATTERN ANAL, V28, P69, DOI 10.1109/TPAMI.2006.17; Manwani N, 2010, JMLR WORKSH CONF PRO, V13, P17; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Rahimi A, 2007, PROC 20 INT C NEURAL, P1177, DOI DOI 10.5555/2981562.2981710; Rao YM, 2017, IEEE I CONF COMP VIS, P3801, DOI 10.1109/ICCV.2017.408; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rudd EM, 2018, IEEE T PATTERN ANAL, V40, P762, DOI 10.1109/TPAMI.2017.2707495; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Sastry P. S., 2011, ABS11071564 CORR; Satpathy A, 2014, IEEE T IMAGE PROCESS, V23, P287, DOI 10.1109/TIP.2013.2264677; Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shalev-Shwartz S, 2011, MATH PROGRAM, V127, P3, DOI 10.1007/s10107-010-0420-4; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31	56	7	7	5	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					608	622		10.1109/TPAMI.2019.2934455	http://dx.doi.org/10.1109/TPAMI.2019.2934455			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31425019				2022-12-18	WOS:000607383300015
J	Frohlich, R; Tamas, L; Kato, Z				Frohlich, Robert; Tamas, Levente; Kato, Zoltan			Absolute Pose Estimation of Central Cameras Using Planar Regions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Calibration; Three-dimensional displays; Pose estimation; Two dimensional displays; Mathematical model; Laser radar; Pose estimation; calibration; data fusion; registration; Lidar; omnidirectional camera	REGISTRATION; COMPUTATION; MOMENTS; IMAGES	A novel method is proposed for the absolute pose estimation of a central 2D camera with respect to 3D depth data without the use of any dedicated calibration pattern or explicit point correspondences. The proposed method has no specific assumption about the data source: plain depth information is expected from the 3D sensing device and a central camera is used to capture the 2D images. Both the perspective and omnidirectional central cameras are handled within a single generic camera model. Pose estimation is formulated as a 2D-3D nonlinear shape registration task which is solved without point correspondences or complex similarity metrics. It relies on a set of corresponding planar regions, and the pose parameters are obtained by solving an overdetermined system of nonlinear equations. The efficiency and robustness of the proposed method were confirmed on both large scale synthetic data and on real data acquired from various types of sensors.	[Frohlich, Robert; Kato, Zoltan] Univ Szeged, Dept Image Proc & Comp Graph, POB 652, H-6701 Szeged, Hungary; [Kato, Zoltan] J Selye Univ, Dept Math & Informat, Komarno 94501, Slovakia; [Tamas, Levente] Tech Univ Cluj Napoca, Automat Dept, Memorandumului St 28, Cluj Napoca 400114, Romania; [Tamas, Levente] Univ Pannonia, Dept Elect Engn & Informat Syst, H-8200 Veszprem, Hungary	Szeged University; J. Selye University; Technical University of Cluj Napoca; University of Pannonia	Tamas, L (corresponding author), Tech Univ Cluj Napoca, Automat Dept, Memorandumului St 28, Cluj Napoca 400114, Romania.	frohlich@inf.u-szeged.hu; Levente.Tamas@aut.utcluj.ro; kato@inf.u-szeged.hu	Tamas, Levente/AAX-7309-2020; Kato, Zoltan/AAD-6406-2019	Tamas, Levente/0000-0002-8583-8296; Frohlich, Robert/0000-0002-7053-9365	NKFI-6 fund [K120366]; Integrated program for training new generation of scientists in the fields of computer science [EFOP-3.6.3-VEKOP-16-2017-0002]; Research & Development Operational Programme for the project "Modernization and Improvement of Technical Infrastructure for Research and Development of J. Selye University in the Fields of Nanotechnology and Intelligent Space" [ITMS 26210120042]; European Regional Development Fund; Romanian National Authority for Scientific Research and Innovation [PN-III-P1-1.1-TE-2016-0670]; Bolyai Scholarship of the Hungarian Academy of Sciences	NKFI-6 fund(National Research, Development & Innovation Office (NRDIO) - Hungary); Integrated program for training new generation of scientists in the fields of computer science; Research & Development Operational Programme for the project "Modernization and Improvement of Technical Infrastructure for Research and Development of J. Selye University in the Fields of Nanotechnology and Intelligent Space"; European Regional Development Fund(European Commission); Romanian National Authority for Scientific Research and Innovation; Bolyai Scholarship of the Hungarian Academy of Sciences	This work was partially supported by the NKFI-6 fund through project K120366; "Integrated program for training new generation of scientists in the fields of computer science", EFOP-3.6.3-VEKOP-16-2017-0002; the Research & Development Operational Programme for the project "Modernization and Improvement of Technical Infrastructure for Research and Development of J. Selye University in the Fields of Nanotechnology and Intelligent Space", ITMS 26210120042, co-funded by the European Regional Development Fund; the Romanian National Authority for Scientific Research and Innovation under Grant number PN-III-P1-1.1-TE-2016-0670; and Bolyai Scholarship of the Hungarian Academy of Sciences. The authors gratefully acknowledge the help of Csaba Benedek from SZTAKI in providing us with the preprocessed Velodyne Lidar scans in Fig. 11; as well as the discussions with Radu Orghidan and Cedric Demonceaux in the early stage of this work.	Akkiraju N, 1996, DISCRETE APPL MATH, V71, P5, DOI 10.1016/S0166-218X(96)00054-6; Alismail H, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P286, DOI 10.1109/3DIMPVT.2012.52; Arth C., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P37, DOI 10.1109/ISMAR.2011.6092368; Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Banno A, 2010, COMPUT VIS IMAGE UND, V114, P491, DOI 10.1016/j.cviu.2009.12.005; BEST GC, 1964, MATH COMPUT, V18, P310, DOI 10.2307/2003308; Camposeco F, 2016, LECT NOTES COMPUT SC, V9909, P202, DOI 10.1007/978-3-319-46454-1_13; Corsini M, 2013, INT J COMPUT VISION, V102, P91, DOI 10.1007/s11263-012-0552-5; Dai A, 2018, LECT NOTES COMPUT SC, V11214, P458, DOI 10.1007/978-3-030-01249-6_28; Domokos C, 2012, IEEE T PATTERN ANAL, V34, P943, DOI 10.1109/TPAMI.2011.200; Franken T, 2005, VISUAL COMPUT, V21, P619, DOI 10.1007/s00371-005-0309-z; Frohlich R, 2016, INT C PATT RECOG, P2404, DOI 10.1109/ICPR.2016.7899996; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; GEYER C, 2000, EUR C COMP VIS ECCV, V2, P445; Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125; Hesch JA, 2014, INT J ROBOT RES, V33, P182, DOI 10.1177/0278364913509675; Horanyi N, 2017, INT CONF 3D VISION, P244, DOI 10.1109/3DV.2017.00036; Ioannou Y, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P501, DOI 10.1109/3DIMPVT.2012.12; Iyer G, 2018, IEEE INT C INT ROBOT, P1110, DOI 10.1109/IROS.2018.8593693; JIANG XY, 1991, PATTERN RECOGN, V24, P801, DOI 10.1016/0031-3203(91)90047-9; Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153; Kneip L, 2014, LECT NOTES COMPUT SC, V8689, P127, DOI 10.1007/978-3-319-10590-1_9; Koehl P, 2012, IEEE T PATTERN ANAL, V34, P2158, DOI 10.1109/TPAMI.2012.23; Lee GH, 2016, LECT NOTES COMPUT SC, V9909, P170, DOI 10.1007/978-3-319-46454-1_11; Lee HS, 2018, IEEE T INTELL TRANSP, V19, P1652, DOI 10.1109/TITS.2018.2801560; Lensch HPA, 2001, GRAPH MODELS, V63, P245, DOI 10.1006/gmod.2001.0554; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; LEU JG, 1991, PATTERN RECOGN, V24, P949, DOI 10.1016/0031-3203(91)90092-J; Li SQ, 2012, IEEE T PATTERN ANAL, V34, P1444, DOI 10.1109/TPAMI.2012.41; Liu LY, 2005, PROC CVPR IEEE, P137; Liu Y., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P82, DOI 10.1109/CVPR.1988.196218; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Pozo JM, 2011, IEEE T PATTERN ANAL, V33, P471, DOI 10.1109/TPAMI.2010.139; Mastin Andrew, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2639, DOI 10.1109/CVPRW.2009.5206539; Mathias M, 2016, INT J COMPUT VISION, V118, P22, DOI 10.1007/s11263-015-0868-z; Meng Zhang, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P585, DOI 10.1109/ICIG.2013.122; Mi B., 2004, P AS C COMP VIS JAN, P748; Mirzaei FM, 2012, INT J ROBOT RES, V31, P452, DOI 10.1177/0278364911435689; Naroditsky Oleg, 2011, IEEE International Conference on Robotics and Automation, P3429; Nister D, 2004, PROC CVPR IEEE, P652; Nunez P., 2009, PROC EUR C MOBILE RO, P31; Nurunnabi A, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA); ORourke J. E. G. Joseph, 2004, DISCRETE MATH ITS AP; Pandey G., 2012, AAAI C ART INT; Paudel DP, 2014, INT C PATT RECOG, P196, DOI 10.1109/ICPR.2014.43; Persson PO, 2004, SIAM REV, V46, P329, DOI 10.1137/S0036144503429121; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Preetha M. Mary Synthuja Jain, 2012, 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET 2012), P576, DOI 10.1109/ICCEET.2012.6203897; Scaramuzza D, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P4170, DOI 10.1109/iros.2007.4399276; Scaramuzza D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5695, DOI 10.1109/IROS.2006.282372; Scaramuzza Davide, 2006, IEEE INT C COMP VIS; Schneider N, 2017, IEEE INT VEH SYM, P1803, DOI 10.1109/IVS.2017.7995968; SINGER MH, 1993, PATTERN RECOGN, V26, P1019, DOI 10.1016/0031-3203(93)90003-F; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28; Tamas L, 2015, LECT NOTES COMPUT SC, V8926, P640, DOI 10.1007/978-3-319-16181-5_49; Tamas L, 2014, ENG APPL ARTIF INTEL, V32, P76, DOI 10.1016/j.engappai.2014.03.001; Tamas L, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P668, DOI 10.1109/ICCVW.2013.92; Taneja A, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P479, DOI 10.1109/3DIMPVT.2012.45; Taylor Z, 2012, AUSTR C ROBOTICS AUT, P3; Taylor Z, 2015, J FIELD ROBOT, V32, P675, DOI 10.1002/rob.21523; Thrun S., 2013, ROB SCI SYST BERL GE; Unnikrishnan R., 2005, CMURITR0509; Vantaram SR, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.4.040901; Xu C, 2017, IEEE T PATTERN ANAL, V39, P1209, DOI 10.1109/TPAMI.2016.2582162; Zhang Q., 2004, P INT C INT ROB SYST, P2301; Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0; Zolanvari SMI, 2018, ISPRS J PHOTOGRAMM, V143, P134, DOI 10.1016/j.isprsjprs.2018.04.004	68	7	7	2	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					377	391		10.1109/TPAMI.2019.2931577	http://dx.doi.org/10.1109/TPAMI.2019.2931577			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31369371	Green Published			2022-12-18	WOS:000607383300001
J	Tao, J; Zhang, JY; Deng, BL; Fang, Z; Peng, Y; He, Y				Tao, Jiong; Zhang, Juyong; Deng, Bailin; Fang, Zheng; Peng, Yue; He, Ying			Parallel and Scalable Heat Methods for Geodesic Distance Computation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimization; Linear systems; Memory management; Computational modeling; Heat recovery; Approximation algorithms; Heat method; heat diffusion; poisson equation; scalability; parallel algorithm	CONTOURS	In this paper, we propose a parallel and scalable approach for geodesic distance computation on triangle meshes. Our key observation is that the recovery of geodesic distance with the heat method [1] can be reformulated as optimization of its gradients subject to integrability, which can be solved using an efficient first-order method that requires no linear system solving and converges quickly. Afterward, the geodesic distance is efficiently recovered by parallel integration of the optimized gradients in breadth-first order. Moreover, we employ a similar breadth-first strategy to derive a parallel Gauss-Seidel solver for the diffusion step in the heat method. To further lower the memory consumption from gradient optimization on faces, we also propose a formulation that optimizes the projected gradients on edges, which reduces the memory footprint by about 50 percent. Our approach is trivially parallelizable, with a low memory footprint that grows linearly with respect to the model size. This makes it particularly suitable for handling large models. Experimental results show that it can efficiently compute geodesic distance on meshes with more than 200 million vertices on a desktop PC with 128 GB RAM, outperforming the original heat method and other state-of-the-art geodesic distance solvers.	[Tao, Jiong; Zhang, Juyong; Peng, Yue] Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Anhui, Peoples R China; [Deng, Bailin] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales; [Fang, Zheng; He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Cardiff University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Zhang, JY (corresponding author), Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Anhui, Peoples R China.	taojiong@mail.ustc.edu.cn; juyong@ustc.edu.cn; DengB3@cardiff.ac.uk; fz0420@hotmail.com; echoyue@mail.ustc.edu.cn; yhe@ntu.edu.sg	He, Ying/A-3708-2011	He, Ying/0000-0002-6749-4485; Fang, Zheng/0000-0003-2601-8148; Deng, Bailin/0000-0002-0158-7670; Peng, Yue/0000-0002-8415-9128	National Natural Science Foundation of China [61672481]; Youth Innovation Promotion Association CAS [2018495]; Singapore MOE [RG26/17]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Youth Innovation Promotion Association CAS; Singapore MOE(Ministry of Education, Singapore)	The authors are supported by National Natural Science Foundation of China (No. 61672481), Youth Innovation Promotion Association CAS (No. 2018495), and Singapore MOE RG26/17.	Belyaev AG, 2015, COMPUT GRAPH FORUM, V34, P104, DOI 10.1111/cgf.12611; Bobenko AI, 2007, DISCRETE COMPUT GEOM, V38, P740, DOI 10.1007/s00454-007-9006-1; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Bryner D, 2014, IEEE T PATTERN ANAL, V36, P998, DOI 10.1109/TPAMI.2013.199; Campagna S., 1998, J GRAPH TOOLS, V3, P1, DOI [10.1080/10867651.1998.10487494, DOI 10.1080/10867651.1998.10487494]; CHEN JD, 1990, PROCEEDINGS OF THE SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P360, DOI 10.1145/98524.98601; Crane K, 2013, ACM SIGGRAPH 2013 CO, DOI [10.1145/2504435.2504442, DOI 10.1145/2504435.2504442]; Crane K, 2017, COMMUN ACM, V60, P90, DOI 10.1145/3131280; Crane K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516977; Crane K, 2010, COMPUT GRAPH FORUM, V29, P1525, DOI 10.1111/j.1467-8659.2010.01761.x; Desbrun M., 2008, DISCRETE DIFFERENTIA, P287; Eppstein D, 2003, SIAM PROC S, P599; Ghadimi E, 2015, IEEE T AUTOMAT CONTR, V60, P644, DOI 10.1109/TAC.2014.2354892; Giselsson P, 2017, IEEE T AUTOMAT CONTR, V62, P532, DOI 10.1109/TAC.2016.2564160; Goldstein T, 2014, SIAM J IMAGING SCI, V7, P1588, DOI 10.1137/120896219; GREENBAUM A, 1989, COMPUT PHYS COMMUN, V53, P295, DOI 10.1016/0010-4655(89)90167-7; Heide F, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925875; Hogg JD, 2010, SIAM J SCI COMPUT, V32, P3627, DOI 10.1137/090757216; HSL, COLL FORTR COD LARG; Kettner L, 1999, COMP GEOM-THEOR APPL, V13, P65, DOI 10.1016/S0925-7721(99)00007-3; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Ng MK, 2010, SIAM J SCI COMPUT, V32, P2710, DOI 10.1137/090774823; Overby M, 2017, IEEE T VIS COMPUT GR, V23, P2222, DOI 10.1109/TVCG.2017.2730875; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; Pebay PP, 2003, MATH COMPUT, V72, P1817, DOI 10.1090/S0025-5718-03-01485-6; Peyre G, 2009, FOUND TRENDS COMPUT, V5, DOI 10.1561/0600000029; Qin YP, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925930; Sethian J. A., 1999, LEVEL SET METHODS FA; Sethian JA, 1999, SIAM REV, V41, P199, DOI 10.1137/S0036144598347059; Sharp N, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3243651; Sharp N, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322979; Surazhsky V, 2005, ACM T GRAPHIC, V24, P553, DOI 10.1145/1073204.1073228; VARADHAN SR, 1967, COMMUN PUR APPL MATH, V20, P431; Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005; Wang XN, 2017, COMPUT AIDED GEOM D, V52-53, P262, DOI 10.1016/j.cagd.2017.03.010; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Weber O, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409626; Xin SQ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559761; Xin SQ, 2018, COMPUT AIDED DESIGN, V102, P128, DOI 10.1016/j.cad.2018.04.021; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Ying X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2534161; Ying X, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508379; Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671	47	7	7	3	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					579	594		10.1109/TPAMI.2019.2933209	http://dx.doi.org/10.1109/TPAMI.2019.2933209			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31398106	Green Accepted, Green Submitted			2022-12-18	WOS:000607383300013
J	Ben Tanfous, A; Drira, H; Ben Amor, B				Ben Tanfous, Amor; Drira, Hassen; Ben Amor, Boulbaba			Sparse Coding of Shape Trajectories for Facial Expression and Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manifolds; Two dimensional displays; Shape; Three-dimensional displays; Face recognition; Trajectory; Encoding; Kendall's shape space; shape trajectories; sparse coding and dictionary learning; action recognition; facial expression recognition	CLASSIFICATION; REPRESENTATION; MANIFOLDS	The detection and tracking of human landmarks in video streams has gained in reliability partly due to the availability of affordable RGB-D sensors. The analysis of such time-varying geometric data is playing an important role in the automatic human behavior understanding. However, suitable shape representations as well as their temporal evolution, termed trajectories, often lie to nonlinear manifolds. This puts an additional constraint (i.e., nonlinearity) in using conventional Machine Learning techniques. As a solution, this paper accommodates the well-known Sparse Coding and Dictionary Learning approach to study time-varying shapes on the Kendall shape spaces of 2D and 3D landmarks. We illustrate effective coding of 3D skeletal sequences for action recognition and 2D facial landmark sequences for macro- and micro-expression recognition. To overcome the inherent nonlinearity of the shape spaces, intrinsic and extrinsic solutions were explored. As main results, shape trajectories give rise to more discriminative time-series with suitable computational properties, including sparsity and vector space structure. Extensive experiments conducted on commonly-used datasets demonstrate the competitiveness of the proposed approaches with respect to state-of-the-art.	[Ben Tanfous, Amor; Drira, Hassen] IMT Lille Douai, CRIStAL Lab, CNRS, UMR, F-59650 Villeneuve Dascq, France; [Ben Amor, Boulbaba] Incept Inst Artificial Intelligence IIAI, Abu Dhabi, U Arab Emirates	Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; IMT Nord Europe; Universite de Lille - ISITE; Centrale Lille	Ben Tanfous, A (corresponding author), IMT Lille Douai, CRIStAL Lab, CNRS, UMR, F-59650 Villeneuve Dascq, France.	omar.bentanfous@imt-lille-douai.fr; hassen.drira@imt-lille-douai.fr; boulbaba.amor@inceptioniai.org	Ben Amor, Boulbaba/K-7066-2018	Ben Amor, Boulbaba/0000-0002-4176-9305; Drira, Hassen/0000-0003-1052-4353				Anirudh R, 2015, PROC CVPR IEEE, P3147, DOI 10.1109/CVPR.2015.7298934; Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240; Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019; Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257; Ben Tanfous A, 2018, PROC CVPR IEEE, P2840, DOI 10.1109/CVPR.2018.00300; Breuer Ran, 2017, ARXIV170501842; Bryner D, 2014, IEEE T PATTERN ANAL, V36, P998, DOI 10.1109/TPAMI.2013.199; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Cetingul HE, 2011, I S BIOMED IMAGING, P1750, DOI 10.1109/ISBI.2011.5872744; Cetingul HE, 2009, PROC CVPR IEEE, P1896, DOI 10.1109/CVPRW.2009.5206806; Cetingul HE, 2014, IEEE T MED IMAGING, V33, P301, DOI 10.1109/TMI.2013.2284360; Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153; Cherian A, 2017, IEEE T NEUR NET LEAR, V28, P2859, DOI 10.1109/TNNLS.2016.2601307; Choi DY, 2018, IEEE IMAGE PROC, P1962, DOI 10.1109/ICIP.2018.8451359; Diamond S, 2016, J MACH LEARN RES, V17; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Dryden I. L., 2016, R WILEY SERIES PROBA, V2nd; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Elaiwat S, 2016, PATTERN RECOGN, V49, P152, DOI 10.1016/j.patcog.2015.07.006; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; Garcia-Hernando G, 2017, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.2017.51; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253; Guo F, 2016, ONCOGENE, V35, P816, DOI 10.1038/onc.2015.139; Guo K, 2013, IEEE T IMAGE PROCESS, V22, P2479, DOI 10.1109/TIP.2013.2252622; Harandi M, 2015, PROC CVPR IEEE, P3926, DOI 10.1109/CVPR.2015.7299018; Harandi M, 2015, INT J COMPUT VISION, V114, P113, DOI 10.1007/s11263-015-0833-x; Harandi MT, 2016, IEEE T NEUR NET LEAR, V27, P1294, DOI 10.1109/TNNLS.2014.2387383; Harandi MT, 2012, LECT NOTES COMPUT SC, V7573, P216, DOI 10.1007/978-3-642-33709-3_16; Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096; Jain S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1642, DOI 10.1109/ICCVW.2011.6130446; Jayasumana S, 2013, IEEE I CONF COMP VIS, P1249, DOI 10.1109/ICCV.2013.158; Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341; Kacem A, 2020, IEEE T PATTERN ANAL, V42, P1, DOI 10.1109/TPAMI.2018.2872564; Kacem A, 2017, IEEE I CONF COMP VIS, P3199, DOI 10.1109/ICCV.2017.345; Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596; Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Kim DH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P382, DOI 10.1145/2964284.2967247; Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207; Koniusz P, 2016, LECT NOTES COMPUT SC, V9908, P37, DOI 10.1007/978-3-319-46493-0_3; Li PH, 2013, IEEE I CONF COMP VIS, P1601, DOI 10.1109/ICCV.2013.202; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Liong ST, 2016, SIGNAL PROCESS-IMAGE, V47, P170, DOI 10.1016/j.image.2016.06.004; Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10; Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226; Liu ZW, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P997, DOI 10.1145/3077136.3080700; Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Lui YM, 2012, IMAGE VISION COMPUT, V30, P380, DOI 10.1016/j.imavis.2011.08.002; Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007; Oh YH, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01128; Peters J, 2017, ADAPT COMPUT MACH LE; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416, DOI 10.1007/3-540-44581-1_27; Scovanner P., 2007, ACM MM, P357; Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77; Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Shuilong T, 2010, PROCEEDINGS OF THE 36TH INTERNATIONAL MATADOR CONFERENCE, P343, DOI 10.1007/978-1-84996-432-6_78; Su JY, 2014, ANN APPL STAT, V8, P530, DOI 10.1214/13-AOAS701; Taheri S., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P306, DOI 10.1109/FG.2011.5771415; Valstar M., 2010, P 3 INT WORKSH EMOTI, P65; Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460; Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Wang CY, 2016, PROC CVPR IEEE, P2639, DOI 10.1109/CVPR.2016.289; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang P, 2016, LECT NOTES COMPUT SC, V9911, P370, DOI 10.1007/978-3-319-46478-7_23; Wang ZH, 2013, PROC CVPR IEEE, P3422, DOI 10.1109/CVPR.2013.439; Xia L., 2012, IEEE COMP SOC C COMP, V2012, P20, DOI DOI 10.1109/CVPRW.2012.6239233; Xie Yuchen, 2013, JMLR Workshop Conf Proc, V28, P1480; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041; Yang HY, 2012, APPL SOFT COMPUT, V12, P872, DOI 10.1016/j.asoc.2011.09.014; Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342; Zhang F, 2018, CHIN CONTR CONF, P10032; Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24; Zhang Y, 2017, IEEE I CONF COMP VIS, P2116, DOI 10.1109/ICCV.2017.231; Zhang ZW, 2015, J STAT PLAN INFER, V166, P171, DOI 10.1016/j.jspi.2015.04.007; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zheng H, 2016, LECT NOTES COMPUT SC, V9810, P692, DOI 10.1007/978-3-319-42911-3_58; Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974; Zhu WT, 2016, AAAI CONF ARTIF INTE, P3697	83	7	8	2	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2594	2607		10.1109/TPAMI.2019.2932979	http://dx.doi.org/10.1109/TPAMI.2019.2932979			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31395537	Green Submitted			2022-12-18	WOS:000567471300020
J	Hu, P; Wang, G; Kong, XF; Kuen, J; Tan, YP				Hu, Ping; Wang, Gang; Kong, Xiangfei; Kuen, Jason; Tan, Yap-Peng			Motion-Guided Cascaded Refinement Network for Video Object Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion segmentation; Active contours; Optical imaging; Image segmentation; Optical propagation; Task analysis; Object segmentation; Video object segmentation; motion segmentation; convolutional neural networks; spatial-temporal embedding	ACTIVE CONTOURS; EVOLUTION; TRACKING	In this work, we propose a motion-guided cascaded refinement network for video object segmentation. By assuming the foreground objects show different motion patterns from the background, for each video frame we apply an active contour model on optical flow to coarsely segment the foreground. The proposed Cascaded Refinement Network (CRN) then takes as guidance the coarse segmentation to generate an accurate segmentation in full resolution. In this way, the motion information and the deep CNNs can complement each other well to accurately segment the foreground objects from video frames. To deal with multi-instance cases, we extend our method with a spatial-temporal instance embedding model that further segments the foreground regions into instances and propagates instance labels. We further introduce a single-channel residual attention module in CRN to incorporate the coarse segmentation map as attention, which makes the network effective and efficient in both training and testing. We perform experiments on popular benchmarks and the results show that our method achieves state-of-the-art performance with high time efficiency.	[Hu, Ping] Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA; [Wang, Gang] Alibaba Grp, Hangzhou 310052, Peoples R China; [Kong, Xiangfei] Alibaba Grp, Ant Financial, Singapore 189969, Singapore; [Kuen, Jason; Tan, Yap-Peng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Boston University; Alibaba Group; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Hu, P (corresponding author), Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA.	pinghu@bu.edu; gangwang6@gmail.com; xiangfei.kong@antfin.com; jason7fd@gmail.com; eyptan@ntu.edu.sg						[Anonymous], P BRIT MACH VIS C; [Anonymous], 2017, PRACTICAL GUIDE; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Bao LC, 2018, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2018.00626; Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chen YH, 2018, PROC CVPR IEEE, P1189, DOI 10.1109/CVPR.2018.00130; Cheng JC, 2018, PROC CVPR IEEE, P7415, DOI 10.1109/CVPR.2018.00774; Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81; Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883; Galasso F., 2013, P AS C COMP VIS ACCV, P760, DOI 10.1007/978-3-642-37331-2_57; Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Hu P, 2018, PROC CVPR IEEE, P1400, DOI 10.1109/CVPR.2018.00152; Hu P, 2017, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.2017.65; HuilingWang Tapani Raiko, 2016, ASIA C COMPUTER VISI, P163; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228; Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43; Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336; Jang WD, 2017, PROC CVPR IEEE, P7474, DOI 10.1109/CVPR.2017.790; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Khoreva A, 2019, INT J COMPUT VISION, V127, P1175, DOI 10.1007/s11263-019-01164-6; Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784; Li CM, 2005, PROC CVPR IEEE, P430; Li J, 2017, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2017.158; Li SY, 2018, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2018.00683; Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735; Marki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87; Maninis KK, 2019, IEEE T PATTERN ANAL, V41, P1515, DOI 10.1109/TPAMI.2018.2838670; Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372; Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369; Pont-Tuset J., 2017, CORR; Ramakanth SA, 2014, PROC CVPR IEEE, P376, DOI 10.1109/CVPR.2014.55; Rematas K, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCV.2011.6126455; Riklin-Raviv T, 2008, INT J COMPUT VISION, V79, P231, DOI 10.1007/s11263-007-0115-3; Shi JB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1154, DOI 10.1109/ICCV.1998.710861; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Shi YG, 2005, PROC CVPR IEEE, P34; Sun X, 2015, IEEE T IMAGE PROCESS, V24, P3386, DOI 10.1109/TIP.2015.2447213; Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480; Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64; Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033; Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Wang WG, 2017, IEEE I CONF COMP VIS, P1680, DOI 10.1109/ICCV.2017.185; Wen LY, 2015, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2015.7298835; Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961; Xiao FY, 2016, PROC CVPR IEEE, P933, DOI 10.1109/CVPR.2016.107; Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680; Yang X, 2014, IEEE T IMAGE PROCESS, V23, P2854, DOI 10.1109/TIP.2014.2321506; Yoon JS, 2017, IEEE I CONF COMP VIS, P2186, DOI 10.1109/ICCV.2017.238; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87; Zhou XW, 2013, PROC CVPR IEEE, P2969, DOI 10.1109/CVPR.2013.382	65	7	7	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1957	1967		10.1109/TPAMI.2019.2906175	http://dx.doi.org/10.1109/TPAMI.2019.2906175			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30908256				2022-12-18	WOS:000545415400011
J	Albl, C; Kukelova, Z; Larsson, V; Pajdla, T				Albl, Cenek; Kukelova, Zuzana; Larsson, Viktor; Pajdla, Tomas			Rolling Shutter Camera Absolute Pose	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Mathematical model; Optimization; Computational modeling; Data models; Analytical models; Standards; Computer vision; camera absolute pose; rolling shutter; minimal problems		We present minimal, non-iterative solutions to the absolute pose problem for images from rolling shutter cameras. The absolute pose problem is a key problem in computer vision and rolling shutter is present in a vast majority of today's digital cameras. We discuss several camera motion models and propose two feasible rolling shutter camera models for a polynomial solver. In previous work a linearized camera model was used that required an initial estimate of the camera orientation. We show how to simplify the system of equations and make this solver faster. Furthermore, we present a first solution of the non-linearized camera orientation model using the Cayley parameterization. The new solver does not require any initial camera orientation estimate and therefore serves as a standalone solution to the rolling shutter camera pose problem from six 2D-to-3D correspondences. We show that our algorithms outperform P3P followed by a non-linear refinement using a rolling shutter model.	[Albl, Cenek; Pajdla, Tomas] Czech Tech Univ, Czech Inst Informat Robot & Cybernet, Prague 16000, Czech Republic; [Kukelova, Zuzana] Czech Tech Univ, Dept Cybernet, Fac Elect Engn, Prague 16000, Czech Republic; [Larsson, Viktor] Lund Univ, S-22100 Lund, Sweden; [Larsson, Viktor] Swiss Fed Inst Technol, Dept Comp Sci, CH-8092 Zurich, Switzerland	Czech Technical University Prague; Czech Technical University Prague; Lund University; Swiss Federal Institutes of Technology Domain; ETH Zurich	Albl, C (corresponding author), Czech Tech Univ, Czech Inst Informat Robot & Cybernet, Prague 16000, Czech Republic.	cenek.albl@gmail.com; kukelova@cmp.felk.cvut.cz; vlarsson@inf.ethz.ch; pajdla@cvut.cz	Kukelova, Zuzana/GXG-1671-2022	Kukelova, Zuzana/0000-0002-1916-8829; Albl, Cenek/0000-0003-4412-1026	European Regional Development Fund [CZ.02.1.01/0.0/0.0/15_003/0000468, EC H2020-ICT-731970 LADIO, CZ.02.2.69/0.0/0.0/17_050/0008025]; Grant Agency of the CTUPrague [SGS18/104/OHK3/1T/37]	European Regional Development Fund(European Commission); Grant Agency of the CTUPrague	This research was supported by the European Regional Development Fund under the project IMPACT (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000468), EC H2020-ICT-731970 LADIO project and ESI Fund, OP RDE programme under the project International Mobility of Researchers MSCA-IF at CTU No. CZ.02.2.69/0.0/0.0/17_050/0008025 and by Grant Agency of the CTUPrague project SGS18/104/OHK3/1T/37.	Ait-Aider O, 2006, LECT NOTES COMPUT SC, V3952, P56; Albl C, 2015, PROC CVPR IEEE, P2292, DOI 10.1109/CVPR.2015.7298842; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; Bujnak M, 2012, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2012.6247840; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Cox D. A., 2005, USING ALGEBRAIC GEOM, V185; Danilevsky A., 1937, MAT SBORNIK, V44, P169; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759; Hazewinkel M., 2002, ENCY MATH; Hedborg J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P17, DOI 10.1109/ICCVW.2011.6130217; Hedborg J, 2012, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2012.6247831; Henrion D, 2009, OPTIM METHOD SOFTW, V24, P761, DOI 10.1080/10556780802699201; Hesch JA, 2011, IEEE I CONF COMP VIS, P383, DOI 10.1109/ICCV.2011.6126266; Hook D., 1990, GRAPHICS GEMS, P416; Jia C, 2012, IEEE INT WORKSH MULT, P203, DOI 10.1109/MMSP.2012.6343441; Klein G, 2009, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2009.5336495; Kukelova Z, 2008, LECT NOTES COMPUT SC, V5304, P302, DOI 10.1007/978-3-540-88690-7_23; Larsson V, 2017, PROC CVPR IEEE, P2383, DOI 10.1109/CVPR.2017.256; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Magerand L, 2012, LECT NOTES COMPUT SC, V7572, P456, DOI 10.1007/978-3-642-33718-5_33; Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291; Ringaby E, 2012, INT J COMPUT VISION, V96, P335, DOI 10.1007/s11263-011-0465-8; Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662; Saurer O, 2013, IEEE I CONF COMP VIS, P465, DOI 10.1109/ICCV.2013.64; Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Shoemake K., 1985, ACM SIGGRAPH COMPUTE, V19, P245, DOI DOI 10.1145/325165.325242; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Triggs B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P278, DOI 10.1109/ICCV.1999.791231; Ventura J, 2015, IEEE I CONF COMP VIS, P747, DOI 10.1109/ICCV.2015.92; Wu YH, 2006, J MATH IMAGING VIS, V24, P131, DOI 10.1007/s10851-005-3617-z	36	7	7	2	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1439	1452		10.1109/TPAMI.2019.2894395	http://dx.doi.org/10.1109/TPAMI.2019.2894395			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30676945				2022-12-18	WOS:000535615700011
J	Li, D; Huang, JB; Li, YL; Wang, SJ; Yang, MH				Li, Dong; Huang, Jia-Bin; Li, Yali; Wang, Shengjin; Yang, Ming-Hsuan			Progressive Representation Adaptation for Weakly Supervised Object Localization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Proposals; Detectors; Training; Feature extraction; Clutter; Noise measurement; Adaptation models; Weakly supervised learning; object localization; domain adaptation		We address the problem of weakly supervised object localization where only image-level annotations are available for training object detectors. Numerous methods have been proposed to tackle this problem through mining object proposals. However, a substantial amount of noise in object proposals causes ambiguities for learning discriminative object models. Such approaches are sensitive to model initialization and often converge to undesirable local minimum solutions. In this paper, we propose to overcome these drawbacks by progressive representation adaptation with two main steps: 1) classification adaptation and 2) detection adaptation. In classification adaptation, we transfer a pre-trained network to a multi-label classification task for recognizing the presence of a certain object in an image. Through the classification adaptation step, the network learns discriminative representations that are specific to object categories of interest. In detection adaptation, we mine class-specific object proposals by exploiting two scoring strategies based on the adapted classification network. Class-specific proposal mining helps remove substantial noise from the background clutter and potential confusion from similar objects. We further refine these proposals using multiple instance learning and segmentation cues. Using these refined object bounding boxes, we fine-tune all the layer of the classification network and obtain a fully adapted detection network. We present detailed experimental validation on the PASCAL VOC and ILSVRC datasets. Experimental results demonstrate that our progressive representation adaptation algorithm performs favorably against the state-of-the-art methods.	[Li, Dong; Li, Yali; Wang, Shengjin] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China; [Huang, Jia-Bin] Virginia Tech, Dept Elect & Comp Engn, Blacksburg, VA 24060 USA; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95344 USA	Tsinghua University; Virginia Polytechnic Institute & State University; University of California System; University of California Merced	Yang, MH (corresponding author), Univ Calif Merced, Sch Engn, Merced, CA 95344 USA.	lidong12@tsinghua.org.cn; jbhuang@vt.edu; liyali@ocrserv.ee.tsinghua.edu.cn; wgsgj@tsinghua.edu.cn; mhyang@ucmerced.edu	Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Li, Dong/0000-0001-7369-1445	NationalNatural Science Foundation of China [61701277, 61771288]; state key development programin 13th Five-Year [2016YFB0801301]; NSF CAREER Grant [1149783]; NSF [1755785]	NationalNatural Science Foundation of China(National Natural Science Foundation of China (NSFC)); state key development programin 13th Five-Year; NSF CAREER Grant(National Science Foundation (NSF)NSF - Office of the Director (OD)); NSF(National Science Foundation (NSF))	Thiswork is supported by theNationalNatural Science Foundation of China under Grant Nos.61701277, 61771288 and the state key development programin 13th Five-Year underGrant No. 2016YFB0801301. This work is also supported in part to Dr. Ming-Hsuan Yang by NSF CAREER Grant (1149783) and toDr. Jia-BinHuang byNSF under GrantNo. (1755785).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34; Bency AJ, 2016, LECT NOTES COMPUT SC, V9905, P714, DOI 10.1007/978-3-319-46448-0_43; Bilen H., 2014, P 25 BRIT MACH VIS C; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711; Bosi I, 2016, 2016 INTERNATIONAL MULTIDISCIPLINARY CONFERENCE ON COMPUTER AND ENERGY SCIENCE (SPLITECH), P1; Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231; Dai QY, 2012, PROC CVPR IEEE, P3322, DOI 10.1109/CVPR.2012.6248070; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Diba A, 2017, PROC CVPR IEEE, P5131, DOI 10.1109/CVPR.2017.545; Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Gao MF, 2018, LECT NOTES COMPUT SC, V11205, P155, DOI 10.1007/978-3-030-01246-5_10; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266; Hoffman J, 2015, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2015.7298906; Hoffman Judy, 2014, NIPS; Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918; Jie ZQ, 2017, PROC CVPR IEEE, P4294, DOI 10.1109/CVPR.2017.457; Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22; Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lee YJ, 2011, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2011.5995523; Li QN, 2013, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2013.115; OQUAB M, 2015, PROC CVPR IEEE, P685, DOI DOI 10.1109/CVPR.2015.7298668; Redmon J., 2016, IEEE C COMPUTER VISI, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rochan M, 2015, PROC CVPR IEEE, P4315, DOI 10.1109/CVPR.2015.7299060; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sermanet P., 2013, ARXIV PREPRINT ARXIV; Shi MJ, 2017, IEEE I CONF COMP VIS, P3401, DOI 10.1109/ICCV.2017.366; Shi MJ, 2016, LECT NOTES COMPUT SC, V9909, P105, DOI 10.1007/978-3-319-46454-1_7; Shi Z, 2013, IEEE I CONF COMP VIS, P2984, DOI 10.1109/ICCV.2013.371; Simonyan K., 2013, DEEP INSIDE CONVOLUT; Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381; Singh KK, 2016, PROC CVPR IEEE, P3548, DOI 10.1109/CVPR.2016.386; Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416; Siva P, 2012, LECT NOTES COMPUT SC, V7574, P594, DOI 10.1007/978-3-642-33712-3_43; Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261; Song HO., 2014, ADV NEURAL INFORM PR, V2, P1637; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tang M, 2015, IEEE I CONF COMP VIS, P1555, DOI 10.1109/ICCV.2015.182; Tang P, 2018, LECT NOTES COMPUT SC, V11215, P370, DOI 10.1007/978-3-030-01252-6_22; Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326; Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28; Wang J, 2012, INT J MOD PHYS, V11, P1, DOI 10.1142/S2010194512006113; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wei Y., 2014, ARXIV PREPRINT ARXIV; Wei YC, 2018, LECT NOTES COMPUT SC, V11215, P454, DOI 10.1007/978-3-030-01252-6_27; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhang XL, 2018, LECT NOTES COMPUT SC, V11216, P610, DOI 10.1007/978-3-030-01258-8_37; Zhang XP, 2018, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR.2018.00448; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zhang YT, 2015, PROC CVPR IEEE, P249, DOI 10.1109/CVPR.2015.7298621; ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	68	7	7	4	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1424	1438		10.1109/TPAMI.2019.2899839	http://dx.doi.org/10.1109/TPAMI.2019.2899839			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30794167	hybrid, Green Submitted			2022-12-18	WOS:000535615700010
J	Yeh, MC; Li, YN				Yeh, Mei-Chen; Li, Yi-Nan			Multilabel Deep Visual-Semantic Embedding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Computational modeling; Visualization; Training; Task analysis; Convolutional neural networks; Redundancy; Multilabel classification; visual semantic embedding; convolutional neural networks		Inspired by the great success from deep convolutional neural networks (CNNs) for single-label visual-semantic embedding, we exploit extending these models for multilabel images. We propose a new learning paradigm for multilabel image classification, in which labels are ranked according to its relevance to the input image. In contrast to conventional CNN models that learn a latent vector representation (i.e., the image embedding vector), the developed visual model learns a mapping (i.e., a transformation matrix) from an image in an attempt to differentiate between its relevant and irrelevant labels. Despite the conceptual simplicity of our approach, the proposed model achieves state-of-the-art results on three public benchmark datasets.	[Yeh, Mei-Chen] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan; [Li, Yi-Nan] ASUS Corp, Taipei 112, Taiwan	National Taiwan Normal University; ASUSTek Computer	Yeh, MC (corresponding author), Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.	myeh@csie.ntnu.edu.tw; eric11519@gmail.com		Yeh, Mei-Chen/0000-0001-8665-7860	Ministry of Science and Technology of Taiwan [MOST 106-2221-E-003-031-MY2]	Ministry of Science and Technology of Taiwan(Ministry of Science and Technology, Taiwan)	The authors would like to thank the reviewers for their helpful comments. The authors would also like to thank Fang Li for her help in conducting the experiments. This work was supported by the Ministry of Science and Technology of Taiwan (MOST 106-2221-E-003-031-MY2).	Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; [Anonymous], 2014, P INT C LEARN REPR; [Anonymous], 2014, P INT C LEARN REPR; [Anonymous], P INT C LEARN REPR; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Chen Q, 2015, IEEE T PATTERN ANAL, V37, P13, DOI 10.1109/TPAMI.2014.2343217; Chua T.-S., 2009, P ACM INT C IM VID R, P1, DOI 10.1145/1646396.1646452; Dean J, 2013, OC INT C LEARN REPR; Dong J, 2013, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2013.112; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Frome Andrea, 2013, NEURIPS; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266; Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; LeCun Y, 2004, PROC CVPR IEEE, P97; LeCun Y., 1990, ADV NEURAL INFORM PR, P396, DOI DOI 10.1111/DSU.12130; Lee H., 2009, P ANN INT C MACH LEA, P609; Li YC, 2017, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2017.199; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Ren Z, 2017, P BRIT MACH VIS C; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schultz M, 2004, ADV NEUR IN, V16, P41; Simonyan K, 2015, 3 INT C LEARN REPR I; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Weston Jason, 2011, 22 INT JOINT C ART I; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang Y, 2016, PROC CVPR IEEE, P5985, DOI 10.1109/CVPR.2016.644	37	7	7	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1530	1536		10.1109/TPAMI.2019.2911065	http://dx.doi.org/10.1109/TPAMI.2019.2911065			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30990418				2022-12-18	WOS:000535615700018
J	Hemrit, G; Finlayson, GD; Gijsenij, A; Gehler, P; Bianco, S; Drew, MS; Funt, B; Shi, LL				Hemrit, Ghalia; Finlayson, Graham D.; Gijsenij, Arjan; Gehler, Peter; Bianco, Simone; Drew, Mark S.; Funt, Brian; Shi, Lilong			Providing a Single Ground-Truth for Illuminant Estimation for the ColorChecker Dataset	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color constancy; illuminant estimation; algorithms evaluation		The ColorChecker dataset is one of the most widely used image sets for evaluating and ranking illuminant estimation algorithms. However, this single set of images has at least 3 different sets of ground-truth (i.e., correct answers) associated with it. In the literature it is often asserted that one algorithm is better than another when the algorithms in question have been tuned and tested with the different ground-truths. In this short correspondence we present some of the background as to why the 3 existing ground-truths are different and go on to make a new single and recommended set of correct answers. Experiments reinforce the importance of this work in that we show that the total ordering of a set of algorithms may be reversed depending on whether we use the new or legacy ground-truth data.	[Hemrit, Ghalia; Finlayson, Graham D.] Univ East Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England; [Gijsenij, Arjan] AkzoNobel, NL-1077 Amsterdam, Netherlands; [Gehler, Peter] Amazon, Seattle, WA 98109 USA; [Bianco, Simone] Univ Milano Bicocca, I-20126 Milan, Italy; [Drew, Mark S.; Funt, Brian] Simon Fraser Univ, Burnaby, BC V5A 156, Canada; [Shi, Lilong] Samsung Semicond Inc, San Jose, CA 95134 USA	University of East Anglia; Amazon.com; University of Milano-Bicocca; Simon Fraser University	Hemrit, G (corresponding author), Univ East Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.	g.hemrit@uea.ac.uk; g.finlayson@uea.ac.uk; arjan.gijsenij@gmail.com; pgehler@amazon.com; simone.bianco@disco.unimib.it; mark@cs.sfu.ca; funt@sfu.ca; lilong10@gmail.com		Gijsenij, Arjan/0000-0003-4926-3672; Bianco, Simone/0000-0002-7070-1545	EPSRC [M001768]; UEA [EP/P007910/1]; Apple Inc.; EPSRC [EP/M001768/1] Funding Source: UKRI	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); UEA; Apple Inc.; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This research was supported by EPSRC Grant M001768; UEA grant EP/P007910/1; and Apple Inc.	[Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; Finlayson G. D., 2017, COLOR IMAGING C, P64; Gehler PV, 2008, PROC CVPR IEEE, P3291; Hemrit G., 2018, PROC COLOR IMAG C CI, P350; Ramanath R, 2005, IEEE SIGNAL PROC MAG, V22, P34, DOI 10.1109/MSP.2005.1407713	7	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1286	1287		10.1109/TPAMI.2019.2919824	http://dx.doi.org/10.1109/TPAMI.2019.2919824			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	31265383	Green Submitted, hybrid, Green Accepted			2022-12-18	WOS:000523685800021
J	Szeto, R; Sun, XM; Lu, KY; Corso, JJ				Szeto, Ryan; Sun, Ximeng; Lu, Kunyi; Corso, Jason J.			A Temporally-Aware Interpolation Network for Video Frame Inpainting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Interpolation; Task analysis; Predictive models; Data models; Sun; Computer science; Video inpainting; video prediction; frame interpolation; temporal upsampling	COMPLETION; CAMERA	In this work, we explore video frame inpainting, a task that lies at the intersection of general video inpainting, frame interpolation, and video prediction. Although our problem can be addressed by applying methods from other video interpolation or extrapolation tasks, doing so fails to leverage the additional context information that our problem provides. To this end, we devise a method specifically designed for video frame inpainting that is composed of two modules: a bidirectional video prediction module and a temporally-aware frame interpolation module. The prediction module makes two intermediate predictions of the missing frames, each conditioned on the preceding and following frames respectively, using a shared convolutional LSTM-based encoder-decoder. The interpolation module blends the intermediate predictions by using time information and hidden activations from the video prediction module to resolve disagreements between the predictions. Our experiments demonstrate that our approach produces smoother and more accurate results than state-of-the-art methods for general video inpainting, frame interpolation, and video prediction.	[Szeto, Ryan; Lu, Kunyi; Corso, Jason J.] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA; [Sun, Ximeng] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA	University of Michigan System; University of Michigan; Boston University	Szeto, R (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.	szetor@umich.edu; sunxm@bu.edu; lukunyi@umich.edu; jjcorso@umich.edu		Sun, Ximeng/0000-0003-2187-0657; Lu, Kunyi/0000-0002-3491-3313	ARO [W911NF-15-1-0354]; DARPA [FA8750-16-C-0168]	ARO; DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This work is partly supported by ARO W911NF-15-1-0354, DARPA FA8750-17-2-0112 and DARPA FA8750-16-C-0168. It reflects the opinions and conclusions of its authors, but not necessarily the funding agents.	Abadi M., 2015, TENSORFLOW LARGE SCA; [Anonymous], 2018, P INT C LEARN REPR; [Anonymous], [No title captured]; [Anonymous], 2017, P INT C LEARN REPR; Borzi A, 2002, SIAM J SCI COMPUT, V24, P818, DOI 10.1137/S1064827501386481; Chen KL, 2011, J MATH IMAGING VIS, V41, P222, DOI 10.1007/s10851-011-0274-2; Cheung V, 2008, INT J COMPUT VISION, V76, P141, DOI 10.1007/s11263-006-0001-4; Ebdelli M, 2015, IEEE T IMAGE PROCESS, V24, P3034, DOI 10.1109/TIP.2015.2437193; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Granados M, 2012, LECT NOTES COMPUT SC, V7572, P682, DOI 10.1007/978-3-642-33718-5_49; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jia YT, 2005, VISUAL COMPUT, V21, P601, DOI 10.1007/s00371-005-0313-3; Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938; Kalchbrenner N, 2017, PR MACH LEARN RES, V70; Kingma D.P., 2015, ICLR, P1; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; LeCun Y, 2016, P INT C LEARN REPR; Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI 10.1109/ICCV.2017.478; Long GC, 2016, LECT NOTES COMPUT SC, V9910, P434, DOI 10.1007/978-3-319-46466-4_26; Lotter W., 2017, P INT C LEARN REPR; Miyato T., 2018, CGANS PROJECTION DIS, DOI [10.48550/arxiv.1802.05637, DOI 10.48550/ARXIV.1802.05637]; Newson A, 2014, SIAM J IMAGING SCI, V7, P1993, DOI 10.1137/140954933; Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37; Paszke A, 2017, NIPS 2017 WORKSHOP; Patwardhan KA, 2007, IEEE T IMAGE PROCESS, V16, P545, DOI 10.1109/TIP.2006.888343; Ranzato M., 2014, ARXIV14126604CSLG; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Shen YP, 2006, INT C PATT RECOG, P63; Shi XJ, 2015, ADV NEUR IN, V28; Simonyan K, 2015, 3 INT C LEARN REPR I; Soomro K., CORR; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453; Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Werlberger Manuel, 2011, INT WORKSH EN MIN ME, P273; Wexler Y, 2004, PROC CVPR IEEE, P120; Zeng KH, 2017, IEEE I CONF COMP VIS, P3018, DOI 10.1109/ICCV.2017.326; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068	41	7	7	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1053	1068		10.1109/TPAMI.2019.2951667	http://dx.doi.org/10.1109/TPAMI.2019.2951667			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	31714216	Green Submitted			2022-12-18	WOS:000523685800004
J	Zhao, J; Kneip, L; He, YJ; Ma, JY				Zhao, Ji; Kneip, Laurent; He, Yijia; Ma, Jiayi			Minimal Case Relative Pose Computation Using Ray-Point-Ray Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Transmission line matrix methods; Cameras; Pose estimation; Feature extraction; Geometry; Computer vision; Structure-from-motion; visual odometry; minimal relative pose; automatic solver generation; Grobner bases; ray-point-ray structures	CLOSED-FORM SOLUTION; EGOMOTION ESTIMATION; MOTION	Corners are popular features for relative pose computation with 2D-2D point correspondences. Stable corners may be formed by two 3D rays sharing a common starting point. We call such elements ray-point-ray (RPR) structures. Besides a local invariant keypoint given by the lines' intersection, their reprojection also defines a corner orientation and an inscribed angle in the image plane. The present paper investigates such RPR features, and aims at answering the fundamental question of what additional constraints can be formed from correspondences between RPR features in two views. In particular, we show that knowing the value of the inscribed angle between the two 3D rays poses additional constraints on the relative orientation. Using the latter enables the solution of the relative pose problem with as few as 3 correspondences across the two images. We provide a detailed analysis of all minimal cases distinguishing between 90-degree RPR-structures and structures with an arbitrary, known inscribed angle. We furthermore investigate the special cases of a known directional correspondence and planar motion, the latter being solvable with only a single RPR correspondence. We complete the exposition by outlining an image processing technique for robust RPR-feature extraction. Our results suggest high practicality in man-made environments, where 90-degree RPR-structures naturally occur.	[Zhao, Ji] TuSimple, Beijing 100020, Peoples R China; [Kneip, Laurent] ShanghaiTech Univ, Shanghai 201210, Peoples R China; [He, Yijia] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China; [Ma, Jiayi] Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China	ShanghaiTech University; Chinese Academy of Sciences; Institute of Automation, CAS; Wuhan University	Kneip, L (corresponding author), ShanghaiTech Univ, Shanghai 201210, Peoples R China.	zhaoji84@gmail.com; lkneip@shanghaitech.edu.cn; heyijia2016@gmail.com; jyma2010@gmail.com	Ma, Jiayi/Y-2470-2019	Ma, Jiayi/0000-0003-3264-3265	National Natural Science Foundation of China [61773295]; ShanghaiTech University	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); ShanghaiTech University	We would like to thank Dr. Viktor Larsson at Lund University for valuable suggestions on automatic generators. We also thank Mr. Ding Yang at Motovis for his help in the experiments. This work was supported by National Natural Science Foundation of China under Grant no. 61773295. The authors also acknowledge the generous startup support provided by ShanghaiTech University.	[Anonymous], 2017, P IEEE INT C COMP VI; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; Bentolila J, 2014, COMPUT VIS IMAGE UND, V122, P105, DOI 10.1016/j.cviu.2014.02.004; Briales J, 2016, J MATH IMAGING VIS, V55, P266, DOI 10.1007/s10851-015-0620-x; Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033; Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222; Camposeco F, 2016, LECT NOTES COMPUT SC, V9909, P202, DOI 10.1007/978-3-319-46454-1_13; Cayley Arthur, 1846, REINE ANGEW MATH, V32; Choi S, 2018, IMAGE VISION COMPUT, V69, P103, DOI 10.1016/j.imavis.2017.08.007; Chou CC, 2018, J FIELD ROBOT, V35, P779, DOI 10.1002/rob.21778; Corke P, 2007, INT J ROBOT RES, V26, P519, DOI 10.1177/0278364907079279; Cox D. A., 2007, IDEALS VARIETIES ALG; Diebel J, 2006, REPRESENTING ATTITUD; Elqursh A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3049, DOI 10.1109/CVPR.2011.5995512; Fallon M, 2013, INT J ROBOT RES, V32, P1695, DOI 10.1177/0278364913509035; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fousse L, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1236463.1236468; Fraundorfer F, 2010, LECT NOTES COMPUT SC, V6314, P269, DOI 10.1007/978-3-642-15561-1_20; Goshen L, 2008, IEEE T PATTERN ANAL, V30, P1230, DOI 10.1109/TPAMI.2007.70768; Grayson Daniel R, 2002, MACAULAY 2 SOFTWARE, P4; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022; Heikkila J, 2017, IEEE I CONF COMP VIS, P76, DOI 10.1109/ICCV.2017.18; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Kalantari M, 2011, J MATH IMAGING VIS, V39, P259, DOI 10.1007/s10851-010-0234-2; Kalantari M, 2009, LECT NOTES COMPUT SC, V5414, P215, DOI 10.1007/978-3-540-92957-4_19; Kileel J, 2017, SIAM J APPL ALGEBR G, V1, P575, DOI 10.1137/16M1104482; Kim H, 2010, IEEE INT CONF ROBOT, P1014, DOI 10.1109/ROBOT.2010.5509472; Kneip L, 2014, IEEE INT CONF ROBOT, P1, DOI 10.1109/ICRA.2014.6906582; Kneip L, 2012, LECT NOTES COMPUT SC, V7577, P696, DOI 10.1007/978-3-642-33783-3_50; Kosecka J, 2005, COMPUT VIS IMAGE UND, V100, P274, DOI 10.1016/j.cviu.2005.04.005; Kuang YB, 2014, INT C PATT RECOG, P2419, DOI 10.1109/ICPR.2014.419; Kuang YB, 2013, IEEE I CONF COMP VIS, P529, DOI 10.1109/ICCV.2013.71; Kukelova Z, 2008, LECT NOTES COMPUT SC, V5304, P302, DOI 10.1007/978-3-540-88690-7_23; Kukelova Z, 2012, IEEE T PATTERN ANAL, V34, P1381, DOI 10.1109/TPAMI.2011.230; Larsson V, 2017, PROC CVPR IEEE, P2383, DOI 10.1109/CVPR.2017.256; Li HD, 2006, INT C PATT RECOG, P630; Li K, 2017, ISPRS J PHOTOGRAMM, V125, P33, DOI 10.1016/j.isprsjprs.2017.01.006; Liwicki S., 2017, BRIT MACH VIS C, P1; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Naroditsky O, 2012, IEEE T PATTERN ANAL, V34, P818, DOI 10.1109/TPAMI.2011.226; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Nister D, 2004, PROC CVPR IEEE, P652; Ortin D, 2001, ROBOTICA, V19, P331, DOI 10.1017/S0263574700003143; Pradeep V, 2012, INT J COMPUT VISION, V98, P202, DOI 10.1007/s11263-011-0504-5; Raposo C, 2016, PROC CVPR IEEE, P5470, DOI 10.1109/CVPR.2016.590; Salaun Y, 2016, LECT NOTES COMPUT SC, V9911, P801, DOI 10.1007/978-3-319-46478-7_49; Saurer O, 2017, IEEE T PATTERN ANAL, V39, P327, DOI 10.1109/TPAMI.2016.2545663; Scaramuzza D, 2011, INT J COMPUT VISION, V95, P74, DOI 10.1007/s11263-011-0441-3; Stewenius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005; Strecha C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587706; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Sweeney Chris, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P483, DOI 10.1109/3DV.2014.66; von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300; Zheng YQ, 2013, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2013.291	58	7	7	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1176	1190		10.1109/TPAMI.2019.2892372	http://dx.doi.org/10.1109/TPAMI.2019.2892372			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30640599				2022-12-18	WOS:000523685800012
J	Spigler, G				Spigler, Giacomo			Denoising Autoencoders for Overgeneralization in Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Overgeneralization; fooling; autoencoder; open set recognition; open world recognition; 1-class recognition; confidence score; neural networks	SUPPORT; LEARN	Despite recent developments that allowed neural networks to achieve impressive performance on a variety of applications, these models are intrinsically affected by the problem of overgeneralization, due to their partitioning of the full input space into the fixed set of target classes used during training. Thus it is possible for novel inputs belonging to categories unknown during training or even completely unrecognizable to humans to fool the system into classifying them as one of the known classes, even with a high degree of confidence. This problem can lead to security problems in critical applications, and is closely linked to open set recognition and 1-class recognition. This paper presents a novel way to compute a confidence score using the reconstruction error of denoising autoencoders and shows how it can correctly identify the regions of the input space close to the training distribution. The proposed solution is tested on benchmarks of 'fooling', open set recognition and 1-class recognition constructed from the MNIST and Fashion-MNIST datasets.	[Spigler, Giacomo] Scuola Super Sant Anna, Biorobot Inst, I-56025 Pisa, Italy	Scuola Superiore Sant'Anna	Spigler, G (corresponding author), Scuola Super Sant Anna, Biorobot Inst, I-56025 Pisa, Italy.	giacomo.spigler@santannapisa.it		Spigler, Giacomo/0000-0002-8274-2117	Microsoft Azure	Microsoft Azure(Microsoft)	The author sincerely thanks the reviewers and editor of IEEE TPAMI for their work and useful comments, from which this manuscript has benefited. This work was partially supported via a Microsoft Azure for Research award (2017/2018).	Abadi M., TENSORFLOW LARGE SCA; Ahmad A, 2007, DATA KNOWL ENG, V63, P503, DOI 10.1016/j.datak.2007.03.016; Alain G, 2014, J MACH LEARN RES, V15, P3563; Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640; [Anonymous], 2017, ICLR; Barakat H, 2001, PROC INT CONF DOC, P1017, DOI 10.1109/ICDAR.2001.953939; Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173; Bendale A, 2015, PROC CVPR IEEE, P1893, DOI 10.1109/CVPR.2015.7298799; Bengio Y., 2013, P 26 INT C NEUR INF, P899; Domingues R, 2018, PATTERN RECOGN, V74, P406, DOI 10.1016/j.patcog.2017.09.037; Hautamaki V, 2004, INT C PATT RECOG, P430, DOI 10.1109/ICPR.2004.1334558; Hendrycks D., 2017, ICLR; Kardan N, 2017, IEEE IJCNN, P518, DOI 10.1109/IJCNN.2017.7965897; King DB, 2015, ACS SYM SER, V1214, P1; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018; Munz G., 2007, GIITG WORKSHOP MMBNE, V7, P13; Park C, 2010, OPER RES, V58, P1469, DOI 10.1287/opre.1100.0825; Parvin H., 2013, J BIONANOSCIENCE, V7, P673, DOI DOI 10.1166/JBNS.2013.1162; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Phillips P. Jonathon, 2011, HDB FACE RECOGNITION, P551, DOI DOI 10.1007/978-0-85729-932-1_21.; Rifai S., 2011, PROC INT C MACH LEAR; Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B, 2000, ADV NEUR IN, V12, P582; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Xiao H., 2017, ARXIV 170807747; Zhao M., 2009, ADV NEURAL INFORM PR, P2250	30	7	7	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					998	1004		10.1109/TPAMI.2019.2909876	http://dx.doi.org/10.1109/TPAMI.2019.2909876			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30969917	Green Submitted			2022-12-18	WOS:000526541100014
J	Magerand, L; Del Bue, A				Magerand, Ludovic; Del Bue, Alessio			Revisiting Projective Structure from Motion: A Robust and Efficient Incremental Solution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Three-dimensional displays; Estimation; Robustness; Image reconstruction; Structure from motion; Optimization; Structure-from-motion; perspective cameras; projective reconstruction	MATRIX FACTORIZATION; MISSING DATA; RECONSTRUCTION; ALGORITHMS; SHAPE	This paper presents a solution to the Projective Structure from Motion (PSfM) problem able to deal efficiently with missing data, outliers and, for the first time, large scale 3D reconstruction scenarios. By embedding the projective depths into the projective parameters of the points and views, we decrease the number of unknowns to estimate and improve computational speed by optimizing standard linear Least Squares systems instead of homogeneous ones. In order to do so, we show that an extension of the linear constraints from the Generalized Projective Reconstruction Theorem can be transferred to the projective parameters, ensuring also a valid projective reconstruction in the process. We use an incremental approach that, starting from a solvable sub-problem, incrementally adds views and points until completion with a robust, outliers free, procedure. To prevent error accumulation, a refinement based on alternation between new estimations of views and points is used. This can also be done with constrained non-linear optimization. Experiments with simulated data shows that our approach is performing well, both in term of the quality of the reconstruction and the capacity to handle missing data and outliers with a reduced computational time. Finally, results on real datasets shows the ability of the method to be used in medium and large scale 3D reconstruction scenarios with high ratios of missing data (up to 98 percent).	[Magerand, Ludovic; Del Bue, Alessio] Lab Ist Italiano Tecnol IIT, VGM, Via Morego 30, I-16163 Genoa, GE, Italy; [Magerand, Ludovic] Czech Tech Univ CTU Prague, CIIRC, Prague 16636 6, Czech Republic	Czech Technical University Prague	Magerand, L (corresponding author), Lab Ist Italiano Tecnol IIT, VGM, Via Morego 30, I-16163 Genoa, GE, Italy.	ludovic@magerand.fr; alessio.delbue@iit.it		Del Bue, Alessio/0000-0002-2262-4872; Magerand, Ludovic/0000-0002-1334-4369	European Regional Development Fund under the project IMPACT [CZ.02.1.01/0.0/0.0/15_003/0000468]	European Regional Development Fund under the project IMPACT	This work was partially supported by the European Regional Development Fund under the project IMPACT (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000468).	Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9_3; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; Buchanan AM, 2005, PROC CVPR IEEE, P316; Christy S, 1996, IEEE T PATTERN ANAL, V18, P1098, DOI 10.1109/34.544079; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Dai YC, 2013, IEEE T PATTERN ANAL, V35, P2238, DOI 10.1109/TPAMI.2013.20; Dai YC, 2010, LECT NOTES COMPUT SC, V6314, P396; Eriksson A, 2010, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2010.5540139; Gillis N, 2011, SIAM J MATRIX ANAL A, V32, P1149, DOI 10.1137/110820361; Guan NY, 2012, IEEE T NEUR NET LEAR, V23, P1087, DOI 10.1109/TNNLS.2012.2197827; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hartley R, 2007, INT J COMPUT VISION, V71, P5, DOI 10.1007/s11263-005-4796-1; Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5; Hong JH, 2016, LECT NOTES COMPUT SC, V9905, P477, DOI 10.1007/978-3-319-46448-0_29; Jacobs DW, 2001, COMPUT VIS IMAGE UND, V82, P57, DOI 10.1006/cviu.2001.0906; Jia HJ, 2009, IEEE T PATTERN ANAL, V31, P841, DOI 10.1109/TPAMI.2008.122; Jiang FY, 2015, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2015.7298870; Julia C, 2006, LECT NOTES COMPUT SC, V4141, P804; Ke QF, 2005, PROC CVPR IEEE, P739; Kennedy R, 2016, COMPUT VIS IMAGE UND, V150, P139, DOI 10.1016/j.cviu.2016.04.011; Larsson V, 2014, LECT NOTES COMPUT SC, V8691, P250, DOI 10.1007/978-3-319-10578-9_17; Lin CJ, 2007, NEURAL COMPUT, V19, P2756, DOI 10.1162/neco.2007.19.10.2756; Mackey LW, 2011, ADV NEURAL INFORM PR, P1134, DOI DOI 10.5555/2986459.2986586; Mairal J, 2010, J MACH LEARN RES, V11, P19; Martinec D, 2005, PROC CVPR IEEE, P198; Nasihatkon B, 2015, INT J COMPUT VISION, V115, P87, DOI 10.1007/s11263-015-0803-3; Nister D., 2007, INT C COMP VIS, P1, DOI DOI 10.1109/ICCV.2007.4409095; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Okatani T, 2007, INT J COMPUT VISION, V72, P329, DOI 10.1007/s11263-006-9785-5; Oliensis J, 2007, IEEE T PATTERN ANAL, V29, P2217, DOI 10.1109/TPAMI.2007.1132; Olsson C, 2011, LECT NOTES COMPUT SC, V6688, P524, DOI 10.1007/978-3-642-21227-7_49; Oskarsson M, 2016, PROC CVPR IEEE, P5820, DOI 10.1109/CVPR.2016.627; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; Toldo R, 2015, COMPUT VIS IMAGE UND, V140, P127, DOI 10.1016/j.cviu.2015.05.011; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Triggs B, 1996, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.1996.517170; Ueshiba T., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P296, DOI 10.1007/BFb0055674; Wiberg T, 1976, P 2 S COMP STAT, P229; Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211	47	7	7	4	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					430	443		10.1109/TPAMI.2018.2849973	http://dx.doi.org/10.1109/TPAMI.2018.2849973			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	29994468				2022-12-18	WOS:000508386100014
J	Mequanint, EZ; Alemu, LT; Pelillo, M				Mequanint, Eyasu Zemene; Alemu, Leulseged Tesfaye; Pelillo, Marcello			Dominant Sets for "Constrained" Image Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Interactive segmentation; co-segmentation; dominant sets; quadratic optimization; game dynamics	INTERACTIVE IMAGE; THEORETIC APPROACH; EXTRACTION; DYNAMICS	Image segmentation has come a long way since the early days of computer vision, and still remains a challenging task. Modern variations of the classical (purely bottom-up) approach, involve, e.g., some form of user assistance (interactive segmentation) or ask for the simultaneous segmentation of two or more images (co-segmentation). At an abstract level, all these variants can be thought of as "constrained" versions of the original formulation, whereby the segmentation process is guided by some external source of information. In this paper, we propose a new approach to tackle this kind of problems in a unified way. Our work is based on some properties of a family of quadratic optimization problems related to dominant sets, a graph-theoretic notion of a cluster which generalizes the concept of a maximal clique to edge-weighted graphs. In particular, we show that by properly controlling a regularization parameter which determines the structure and the scale of the underlying problem, we are in a position to extract groups of dominant set clusters that are constrained to contain predefined elements. In particular, we shall focus on interactive segmentation and co-segmentation (in both the unsupervised and the interactive versions). The proposed algorithm can deal naturally with several types of constraints and input modalities, including scribbles, sloppy contours and bounding boxes, and is able to robustly handle noisy annotations on the part of the user. Experiments on standard benchmark datasets show the effectiveness of our approach as compared to state-of-the-art algorithms on a variety of natural images under several input conditions and constraints.	[Mequanint, Eyasu Zemene; Alemu, Leulseged Tesfaye; Pelillo, Marcello] Univ Ca Foscari Venezia, Dipartimento Sci Ambientali Informat & Stat, Via Torino 155, I-30172 Venice, Italy	Universita Ca Foscari Venezia	Mequanint, EZ (corresponding author), Univ Ca Foscari Venezia, Dipartimento Sci Ambientali Informat & Stat, Via Torino 155, I-30172 Venice, Italy.	eyasu.zemene@unive.it; leuelseged.alemu@unive.it; pelillo@unive.it		Pelillo, Marcello/0000-0001-8992-9243	Samsung Global Research Outreach Program	Samsung Global Research Outreach Program(Samsung)	We thank the anonymous reviewers for their constructive comments. This work has been partly supported by the Samsung Global Research Outreach Program. E. Zemene and L. Tesfaye Alemu are equal contributors.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Albarelli A, 2009, IEEE I CONF COMP VIS, P1319, DOI 10.1109/ICCV.2009.5459312; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bai JJ, 2014, PROC CVPR IEEE, P392, DOI 10.1109/CVPR.2014.57; Bai X, 2009, INT J COMPUT VISION, V82, P113, DOI 10.1007/s11263-008-0191-z; Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Bulo SR, 2017, EUR J OPER RES, V262, P1, DOI 10.1016/j.ejor.2017.03.056; Bulo SR, 2013, IEEE T PATTERN ANAL, V35, P1312, DOI 10.1109/TPAMI.2012.226; Bulo SR, 2011, COMPUT VIS IMAGE UND, V115, P984, DOI 10.1016/j.cviu.2010.12.004; Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399; Catanzaro B, 2009, IEEE I CONF COMP VIS, P2381, DOI 10.1109/ICCV.2009.5459410; Chehreghani MH, 2016, MACH LEARN, V104, P271, DOI 10.1007/s10994-016-5573-9; Chew SE, 2015, IEEE I CONF COMP VIS, P1716, DOI 10.1109/ICCV.2015.200; Dong XP, 2015, IEEE T IMAGE PROCESS, V24, P3966, DOI 10.1109/TIP.2015.2456636; Duchenne O., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587419; Eriksson A, 2011, J MATH IMAGING VIS, V39, P45, DOI 10.1007/s10851-010-0223-5; Fanti C, 2004, ADV NEUR IN, V16, P1603; Forsyth D., 2011, COMPUTER VISION MODE; Friedland G, 2005, IEEE INT SYM MULTIM, P253; Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Hati A, 2016, LECT NOTES COMPUT SC, V9910, P736, DOI 10.1007/978-3-319-46466-4_44; Hofbauer J, 2003, B AM MATH SOC, V40, P479, DOI 10.1090/S0273-0979-03-00988-1; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Horn R.A., 2012, MATRIX ANAL, DOI [DOI 10.1017/CBO9780511810817, 10.1017/CBO9780511810817]; Jain SD, 2013, IEEE I CONF COMP VIS, P1313, DOI 10.1109/ICCV.2013.166; JOULIN A, 2010, PROC CVPR IEEE, P1943, DOI DOI 10.1109/CVPR.2010.5539868; Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719; Kamvar S. D., 2003, P 18 INT JOINT C ART, P561; Kulis B, 2009, MACH LEARN, V74, P1, DOI 10.1007/s10994-008-5084-4; Lee C, 2015, PROC CVPR IEEE, P3837, DOI 10.1109/CVPR.2015.7299008; Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li HL, 2013, IEEE T MULTIMEDIA, V15, P1896, DOI 10.1109/TMM.2013.2271476; Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803; Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719; Liu JY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531375; Luenberger D.G., 2008, LINEAR NONLINEAR PRO; Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2057, DOI 10.1109/CVPR.2011.5995630; McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008; Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480; Pavan M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P362; Pavan M, 2003, PROC CVPR IEEE, P145; Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608; Pelillo M, 2006, NEURAL COMPUT, V18, P1215, DOI 10.1162/neco.2006.18.5.1215; Price BL, 2010, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR.2010.5540079; Protiere A, 2007, IEEE T IMAGE PROCESS, V16, P1046, DOI 10.1109/TIP.2007.891796; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934; Sener O., 2012, P 2 ACM INT WORKSH I, P9; Subr K, 2013, COMPUT GRAPH FORUM, V32, P41, DOI 10.1111/cgf.12024; Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0; Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222; Tang M, 2014, LECT NOTES COMPUT SC, V8693, P691, DOI 10.1007/978-3-319-10602-1_45; Tesfaye Y. T., 2017, MULTITARGET TRACKING; Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530; Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512; Weibull J.W., 1997, EVOLUTIONARY GAME TH; Wu JJ, 2014, PROC CVPR IEEE, P256, DOI 10.1109/CVPR.2014.40; Xian M., CORR; Xiao JX, 2009, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2009.5459249; Yang WX, 2010, IEEE T IMAGE PROCESS, V19, P2470, DOI 10.1109/TIP.2010.2048611; Yu HK, 2017, IEEE IMAGE PROC, P3335; Yu SX, 2004, IEEE T PATTERN ANAL, V26, P173, DOI 10.1109/TPAMI.2004.1262179; Zemene E, 2019, IEEE T PATTERN ANAL, V41, P148, DOI 10.1109/TPAMI.2017.2787132; Zemene E, 2016, INT C PATT RECOG, P2568, DOI 10.1109/ICPR.2016.7900022; Zemene E, 2016, LECT NOTES COMPUT SC, V9912, P278, DOI 10.1007/978-3-319-46484-8_17; Zemene E, 2015, LECT NOTES COMPUT SC, V9279, P150, DOI 10.1007/978-3-319-23231-7_14; Zhou YJ, 2015, IEEE WINT CONF APPL, P1076, DOI 10.1109/WACV.2015.148; Zhu W, P IEEE C COMP VIS PA, P2814	74	7	7	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2438	2451		10.1109/TPAMI.2018.2858243	http://dx.doi.org/10.1109/TPAMI.2018.2858243			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30040623	Green Submitted			2022-12-18	WOS:000489763000012
J	Liu, J; Psarakis, EZ; Feng, Y; Stamos, I				Liu, Juan; Psarakis, Emmanouil Z.; Feng, Yang; Stamos, Ioannis			A Kronecker Product Model for Repeated Pattern Detection on 2D Urban Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Repeated pattern detection; low-rank; Kronecker product model; urban facade	FACADE	Repeated patterns (such as windows, balconies, and doors) are prominent and significant features in urban scenes. Therefore, detection of these repeated patterns becomes very important for city scene analysis. This paper attacks the problem of repeated pattern detection in a precise, efficient and automatic way, by combining traditional feature extraction with a Kronecker product based low-rank model. We introduced novel algorithms that extract repeated patterns from rectified images with solid theoretical support. Our method is tailored for 2D images of building facades and tested on a large set of facade images.	[Liu, Juan] Google Inc, New York, NY 10011 USA; [Psarakis, Emmanouil Z.] Univ Patras, Comp Engn & Informat, Patras 26504, Greece; [Feng, Yang] Columbia Univ, Stat, New York, NY 10027 USA; [Stamos, Ioannis] CUNY Hunter Coll, Comp Sci, New York, NY 10021 USA	Google Incorporated; University of Patras; Columbia University; City University of New York (CUNY) System; Hunter College (CUNY)	Feng, Y (corresponding author), Columbia Univ, Stat, New York, NY 10027 USA.	juanliu.ustc@gmail.com; psarakis@ceid.upatras.gr; yang.feng@columbia.edu; istamos@hunter.cuny.edu	Feng, Yang/Y-7374-2019	Feng, Yang/0000-0001-7746-7598	NSF [IIS-0915971]; CUNY bridge funding; NSF CAREER Grant [DMS-1554804]; Division Of Computer and Network Systems [1625843] Funding Source: National Science Foundation	NSF(National Science Foundation (NSF)); CUNY bridge funding; NSF CAREER Grant(National Science Foundation (NSF)NSF - Office of the Director (OD)); Division Of Computer and Network Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	We thank the editor, the AE and two anonymous referees for the insightful comments which has greatly improved the paper. Feng was partially supported by NSF CAREER Grant DMS-1554804. Stamos was partially supported by NSF Grant IIS-0915971 and CUNY bridge funding.	Barinova O, 2010, LECT NOTES COMPUT SC, V6312, P57, DOI 10.1007/978-3-642-15552-9_5; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Cohen A, 2017, INT CONF 3D VISION, P393, DOI 10.1109/3DV.2017.00052; Cohen A, 2014, PROC CVPR IEEE, P3206, DOI 10.1109/CVPR.2014.410; Efron B, 2004, J AM STAT ASSOC, V99, P619, DOI 10.1198/016214504000000692; Friedman S, 2013, INT J COMPUT VISION, V102, P112, DOI 10.1007/s11263-012-0575-y; Gadde R, 2016, INT J COMPUT VISION, V117, P290, DOI 10.1007/s11263-016-0887-4; Gandy S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/2/025010; Kozinski M, 2015, PROC CVPR IEEE, P2820, DOI 10.1109/CVPR.2015.7298899; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Liu J, 2013, IEEE I CONF COMP VIS, P401, DOI 10.1109/ICCV.2013.57; Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332; Muller P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276484, 10.1145/1239451.1239536]; Schindler G, 2008, PROC CVPR IEEE, P77; Shen CH, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024218; STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632; Teboul O., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2273, DOI 10.1109/CVPR.2011.5995319; Van Loan CF, 2000, J COMPUT APPL MATH, V123, P85, DOI 10.1016/S0377-0427(00)00393-9; Wu CC, 2010, LECT NOTES COMPUT SC, V6312, P142; Yang C, 2012, PROC CVPR IEEE, P1720, DOI 10.1109/CVPR.2012.6247867; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609; Yuan M, 2016, SCI CHINA MATH, V59, P2485, DOI 10.1007/s11425-016-0426-8; Zhang Zhengdong, 2010, P AS C COMP VIS; Zhao P, 2010, PROC CVPR IEEE, P342, DOI 10.1109/CVPR.2010.5540192	24	7	7	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2266	2272		10.1109/TPAMI.2018.2858795	http://dx.doi.org/10.1109/TPAMI.2018.2858795			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	30040628	hybrid			2022-12-18	WOS:000480343900016
J	Ardeshir, S; Borji, A				Ardeshir, Shervin; Borji, Ali			Egocentric Meets Top-View	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Egocentric vision; first person vision; surveillance; graph matching; wearable devices; person re-identification	GAZE	Thanks to the availability and increasing popularity of wearable devices such as GoPro cameras, smart phones, and glasses, we have access to a plethora of videos captured from first person perspective. Surveillance cameras and Unmanned Aerial Vehicles (UAVs) also offer tremendous amounts of video data recorded from top and oblique view points. Egocentric and surveillance vision have been studied extensively but separately in the computer vision community. The relationship between these two domains, however, remains unexplored. In this study, we make the first attempt in this direction by addressing two basic yet challenging questions. First, having a set of egocentric videos and a top-view surveillance video, does the top-view video contain all or some of the egocentric viewers? In other words, have these videos been shot in the same environment at the same time? Second, if so, can we identify the egocentric viewers in the top-view video? These problems can become extremely challenging when videos are not temporally aligned. Each view, egocentric or top, is modeled by a graph and the assignment and time-delays are computed iteratively using the spectral graph matching framework. We evaluate our method in terms of ranking and assigning egocentric viewers to identities present in the top-view video over a dataset of 50 top-view and 188 egocentric videos captured under different conditions. We also evaluate the capability of our proposed approaches in terms of temporal alignment. The experiments and results demonstrate the capability of the proposed approaches in terms of jointly addressing the temporal alignment and assignment tasks.	[Ardeshir, Shervin; Borji, Ali] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Ardeshir, S (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.	shervin.ardeshir@gmail.com; aliborji@gmail.com	Ardeshir, Shervin/B-9659-2018	Ardeshir, Shervin/0000-0001-5760-1665; Borji, Ali/0000-0001-8198-0335				Alahi A, 2008, IEEE IMAGE PROC, P1713; ARDESHIR S, 2016, P EUR C COMPUT VIS, V9909, P253, DOI DOI 10.1007/978-3-319-46454-1_16; Bak S., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P179, DOI 10.1109/AVSS.2011.6027316; Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008; Betancourt A, 2015, IEEE T CIRC SYST VID, V25, P744, DOI 10.1109/TCSVT.2015.2409731; Bettadapura V, 2015, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2015.89; Bierlaire M., 2008, P WORKSH MULT MULT S; Borji A, 2014, IEEE T SYST MAN CY-S, V44, P523, DOI 10.1109/TSMC.2013.2279715; Chakrabarti A, 2016, COMPARATIVE PHILOSOPHY WITHOUT BORDERS, P1; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Damen D., 2014, BMVC; Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286; Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51; Fathi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3281, DOI 10.1109/CVPR.2011.5995444; Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23; Fathi A, 2012, PROC CVPR IEEE, P1226, DOI 10.1109/CVPR.2012.6247805; Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Ferland F., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P37; Girshick RB, 2012, DISCRIMINATIVELY TRA; Hoshen Y, 2014, IEEE COMPUT SOC CONF, P587, DOI 10.1109/CVPRW.2014.90; Howard A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3946, DOI 10.1109/IROS.2008.4651147; Kanade T, 2012, P IEEE, V100, P2442, DOI 10.1109/JPROC.2012.2200554; Kiefer P, 2014, T GIS, V18, P660, DOI 10.1111/tgis.12067; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Li Y, 2013, IEEE I CONF COMP VIS, P3216, DOI 10.1109/ICCV.2013.399; Lin YW, 2015, IEEE I CONF COMP VIS, P4426, DOI 10.1109/ICCV.2015.503; Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350; Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103; Park HS, 2013, IEEE I CONF COMP VIS, P3503, DOI 10.1109/ICCV.2013.435; Polatsek P, 2016, IEEE SIGNAL PROC LET, V23, P394, DOI 10.1109/LSP.2016.2523339; Poleg Yair, 2014, P AS C COMP VIS, P315; Regmi K., 2018, P IEEE INT C COMP VI, P5445; Sharghi A, 2016, LECT NOTES COMPUT SC, V9912, P3, DOI 10.1007/978-3-319-46484-8_1; Sigurdsson G. A., 2018, ARXIV180409627; Soran B, 2015, LECT NOTES COMPUT SC, V9007, P178, DOI 10.1007/978-3-319-16814-2_12; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Xu M., 2018, ARXIV180311217; Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540; Yonetani R, 2015, PROC CVPR IEEE, P5445, DOI 10.1109/CVPR.2015.7299183; Zheng K, 2016, IEEE COMPUT SOC CONF, P810, DOI 10.1109/CVPRW.2016.106	42	7	8	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1353	1366		10.1109/TPAMI.2018.2832121	http://dx.doi.org/10.1109/TPAMI.2018.2832121			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29994045	Green Submitted			2022-12-18	WOS:000467037000006
J	Campbell, T; Kulis, B; How, J				Campbell, Trevor; Kulis, Brian; How, Jonathan			Dynamic Clustering Algorithms via Small-Variance Analysis of Markov Chain Mixture Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian nonparametrics; small-variance asymptotics; clustering; dynamic; batch-sequential; hard; spectral	DIRICHLET PROCESS	Bayesian nonparametrics are a class of probabilistic models in which the model size is inferred from data. A recently developed methodology in this field is small variance asymptotic analysis, a mathematical technique for deriving learning algorithms that capture much of the flexibility of Bayesian nonparametric inference algorithms, but are simpler to implement and less computationally expensive. Past work on small-variance analysis of Bayesian nonparametric inference algorithms has exclusively considered batch models trained on a single, static dataset, which are incapable of capturing time evolution in the latent structure of the data. This work presents a small-variance analysis of the maximum a posteriori filtering problem for a temporally varying mixture model with a Markov dependence structure, which captures temporally evolving clusters within a dataset. Two clustering algorithms result from the analysis: D-Means, an iterative clustering algorithm for linearly separable, spherical clusters; and SD-Means, a spectral clustering algorithm derived from a kernelized, relaxed version of the clustering problem. Empirical results from experiments demonstrate the advantages of using D-Means and SD-Means over contemporary clustering algorithms, in terms of both computational cost and clustering accuracy.	[Campbell, Trevor] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Kulis, Brian] Boston Univ, Dept Elect & Comp Engn, 1 Silber Way, Boston, MA 02215 USA; [Kulis, Brian] Boston Univ, Dept Comp Sci, 1 Silber Way, Boston, MA 02215 USA; [How, Jonathan] MIT, Lab Informat & Decis Syst, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Boston University; Boston University; Massachusetts Institute of Technology (MIT)	Campbell, T (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	tdjc@mit.edu; bkulis@bu.edu; jhow@mit.edu		How, Jonathan/0000-0001-8576-1930	NSF CAREER Award [1559558]; ONR MURI grant [N000141110688]	NSF CAREER Award(National Science Foundation (NSF)NSF - Office of the Director (OD)); ONR MURI grant	We acknowledge NSF CAREER Award 1559558 and ONR MURI grant N000141110688. We would also like to thank Miao Liu for discussions and help with implementations.	AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; [Anonymous], [No title captured]; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; Blei DM, 2011, J MACH LEARN RES, V12, P2461; Broderick Tamara, 2013, P 30 INT C MACH LEAR, P226; Campbell T., 2017, ARXIV170708493; Campbell T., 2013, P ADV NEUR INF PROC, P449; CARON F, 2007, 23 C UNC ART INT UAI, P33; Carvalho CM, 2010, BAYESIAN ANAL, V5, P709, DOI 10.1214/10-BA525; Carvalho CM, 2010, STAT SCI, V25, P88, DOI 10.1214/10-STS325; Chakrabarti D., 2006, P 12 ACM SIGKDD INT, P554, DOI [10.1145/1150402.1150467, DOI 10.1145/1150402.1150467]; Chen C., 2013, INT C MACH LEARN, P969; Chi Y, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P153; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]; Doshi-Velez F., 2009, P 26 ANN INT C MACH, P273; Endres F., 2009, P ROB SCI SYST; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; HJORT NL, 1990, ANN STAT, V18, P1259, DOI 10.1214/aos/1176347749; Hoffman MD, 2013, J MACH LEARN RES, V14, P1303; Hofmann T, 2008, ANN STAT, V36, P1171, DOI 10.1214/009053607000000677; Hue C, 2002, IEEE T AERO ELEC SYS, V38, P791, DOI 10.1109/TAES.2002.1039400; Huggins JH, 2015, PR MACH LEARN RES, V37, P693; Ishioka T., 2000, Intelligent Data Engineering and Automated - IDEAL 2000. Data Mining, Financial Engineering, and Intelligent Agents. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.1983), P17; Jiang K., 2012, P INT C NEUR INF PRO, P3158; Joseph J, 2011, AUTON ROBOT, V31, P383, DOI 10.1007/s10514-011-9248-x; Kalnis P, 2005, LECT NOTES COMPUT SC, V3633, P364; Kulis B., 2012, P 29 INT C MACH LEAR, P1131; Leskovec J., 2005, P 11 ACM SIGKDD INT, P177, DOI DOI 10.1145/1081870.1081893; Lin D., 2010, CHILD ISS LAWS PROGR, P1; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Luber M., 2008, P ROB SCI SYST; MacEachern S. N., 1999, ASA P SECT BAYES STA, P50; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Ning HZ, 2010, PATTERN RECOGN, V43, P113, DOI 10.1016/j.patcog.2009.06.001; Pelleg D., 2000, P 17 INT C MACH LEAR, P727, DOI DOI 10.1007/3-540-44491-2_3; PITMAN J, 1995, PROBAB THEORY REL, V102, P145, DOI 10.1007/BF01213386; Roychowdhury A., 2013, ADV NEURAL INFORM PR, V26, P2103; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Snoek J., 2012, P 25 INT C NEUR INF, V2, P2951, DOI DOI 10.48550/ARXIV.1206.2944; Spiliopoulou M., 2006, P 12 ACM SIGKDD INT, P706, DOI [DOI 10.1145/1150402.1150491, 10.1145/1150402.1150491]; Sun Y., P 8 WORKSH MIN LEARN, DOI [10.1145/1830252.1830270, DOI 10.1145/1830252.1830270]; Tang L, 2012, IEEE T KNOWL DATA EN, V24, P72, DOI 10.1109/TKDE.2011.159; Teh Y. W., 2011, P NEUR INF PROC SYST, P1; Teh Y.W., 2010, ENCY MACHINE LEARNIN; Thibaux Romain, 2007, INT C ART INT STAT, P564; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Valgren C, 2007, IEEE INT CONF ROBOT, P4283, DOI 10.1109/ROBOT.2007.364138; Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110; Wang Z., 2008, ROBOT SCI SYST, V8, P433; Xing E., 2008, P 2008 SIAM INT C DA, DOI DOI 10.1137/1.9781611972788.20; Xu K., 2012, THESIS; Xu KS, 2014, DATA MIN KNOWL DISC, V28, P304, DOI 10.1007/s10618-012-0302-x; Xu TB, 2008, IEEE DATA MINING, P658, DOI 10.1109/ICDM.2008.24; Xu TB, 2008, IEEE DATA MINING, P648, DOI 10.1109/ICDM.2008.23; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361; Zha HY, 2002, ADV NEUR IN, V14, P1057	58	7	7	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1338	1352		10.1109/TPAMI.2018.2833467	http://dx.doi.org/10.1109/TPAMI.2018.2833467			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29993439	hybrid, Green Submitted			2022-12-18	WOS:000467037000005
J	Fang, CW; Liao, ZC; Yu, YZ				Fang, Chaowei; Liao, Zicheng; Yu, Yizhou			Piecewise Flat Embedding for Image Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sparsity models; manifold learning; Bregman iterations; image segmentation	DIMENSIONALITY REDUCTION; BOUNDARIES; CONTOURS; COLOR	We introduce a new multi-dimensional nonlinear embedding-Piecewise Flat Embedding (PFE)-for image segmentation. Based on the theory of sparse signal recovery, piecewise flat embedding with diverse channels attempts to recover a piecewise constant image representation with sparse region boundaries and sparse cluster value scattering. The resultant piecewise flat embedding exhibits interesting properties such as suppressing slowly varying signals, and offers an image representation with higher region identifiability which is desirable for image segmentation or high-level semantic analysis tasks. We formulate our embedding as a variant of the Laplacian Eigenmap embedding with an L-1,L-p(0 < p <= 1) regularization term to promote sparse solutions. First, we devise a two-stage numerical algorithm based on Bregman iterations to compute L-1,L-1-regularized piecewise flat embeddings. We further generalize this algorithm through iterative reweighting to solve the general L-1,(p)-regularized problem. To demonstrate its efficacy, we integrate PFE into two existing image segmentation frameworks, segmentation based on clustering and hierarchical segmentation based on contour detection. Experiments on four major benchmark datasets, BSDS500, MSRC, Stanford Background Dataset, and PASCAL Context, show that segmentation algorithms incorporating our embedding achieve significantly improved results.	[Fang, Chaowei; Yu, Yizhou] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; [Liao, Zicheng] Zhejiang Univ, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China	University of Hong Kong; Zhejiang University	Liao, ZC (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.	chwfang@connect.hku.hk; zliao@zju.edu.cn; yizhouy@acm.org	fang, chaowei/AAA-2840-2020		Hong Kong Research Grants Council under General Research Funds [HKU719313]; NSFC Young Researcher Grant [61602406]; Alibaba-ZJU Joint Institute of Frontier Technologies	Hong Kong Research Grants Council under General Research Funds; NSFC Young Researcher Grant; Alibaba-ZJU Joint Institute of Frontier Technologies	We thank all the reviewers and editor. This work is supported in part by Hong Kong Research Grants Council under General Research Funds (HKU719313). ZL is supported in part by NSFC Young Researcher Grant (No. 61602406) and by Alibaba-ZJU Joint Institute of Frontier Technologies.	Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Arbelaez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belongie S., 1998, FINDING BOUNDARIES N, P751; Bi S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766946; Bregman L. M., 1967, COMP MATH MATH PHYS+, V7, P200, DOI DOI 10.1016/0041-5553(67)90040-7; Buhler T., 2009, P 26 ANN INT C MACH, P81, DOI DOI 10.1145/1553374.1553385; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; CHAN PK, 1994, IEEE T COMPUT AID D, V13, P1088, DOI 10.1109/43.310898; Chang SY, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P119, DOI 10.1145/2783258.2783296; CHEEGER J., 1970, PROBLEMS ANAL PAPERS, P195, DOI [10.1515/9781400869312-013, DOI 10.1515/9781400869312-013]; Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cour T, 2005, PROC CVPR IEEE, P1124; Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303; Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715; DONOHO DL, 1989, SIAM J APPL MATH, V49, P906, DOI 10.1137/0149053; DONOHO DL, 1992, SIAM J APPL MATH, V52, P577, DOI 10.1137/0152031; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Elhamifar Ehsan, 2011, ADV NEURAL INF PROCE, V24, P3; Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532; Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592; Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891; Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115; Hein M, 2010, ADV NEURAL INFORM PR, V1, P847; Hinton GE., 2002, NIPS, V15, P833; Hoiem D, 2011, INT J COMPUT VISION, V91, P328, DOI 10.1007/s11263-010-0400-4; Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122; Kokkinos  I., 2016, INT C LEARN REPR ICL; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Lai RJ, 2014, J SCI COMPUT, V58, P431, DOI 10.1007/s10915-013-9740-x; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Maire M., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587420; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Malisiewicz T., 2007, P BRIT MACH VIS C UK, DOI 10.5244/C.21.55; Marr D, 1982, VISION; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; McLachlan GJ, 2004, FINITE MIXTURE MODEL, DOI [10.1002/0471721182, DOI 10.1002/0471721182]; Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Nguyen HV, 2012, LECT NOTES COMPUT SC, V7577, P414, DOI 10.1007/978-3-642-33783-3_30; Ochs P, 2015, SIAM J IMAGING SCI, V8, P331, DOI 10.1137/140971518; Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320; Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481406; Ren ZL, 2013, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2013.262; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Shaw B, 2009, INT C MACH LEARN, P937, DOI DOI 10.1145/1553374.1553494; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Szlam A., 2010, P 27 INT C MACH LEAR, P1039, DOI DOI 10.0RG/PAPERS/233.PDF; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tian F, 2014, AAAI CONF ARTIF INTE, P1293; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Werlberger M, 2010, PROC CVPR IEEE, P2464, DOI 10.1109/CVPR.2010.5539945; Yen-Chuen Wei, 1989, 1989 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No.89CH2805-0), P298, DOI 10.1109/ICCAD.1989.76957; Yu YZ, 2015, IEEE I CONF COMP VIS, P1368, DOI 10.1109/ICCV.2015.161; Zhao Q., 2015, P BMVC	66	7	7	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1470	1485		10.1109/TPAMI.2018.2839733	http://dx.doi.org/10.1109/TPAMI.2018.2839733			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29994301	Green Submitted			2022-12-18	WOS:000467037000014
J	Wang, JD; Zhang, T				Wang, Jingdong; Zhang, Ting			Composite Quantization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Approximate nearest neighbor search; quantization; composite quantization; near-orthogonality	ITERATIVE QUANTIZATION; PROCRUSTEAN APPROACH; BINARY	This paper studies the compact coding approach to approximate nearest neighbor search. We introduce a composite quantization framework. It uses the composition of several (M) elements, each of which is selected from a different dictionary, to accurately approximate a D-dimensional vector, thus yielding accurate search, and represents the data vector by a short code composed of the indices of the selected elements in the corresponding dictionaries. Our key contribution lies in introducing a near-orthogonality constraint, which makes the search efficiency is guaranteed as the cost of the distance computation is reduced to O(M) from O(D) through a distance table lookup scheme. The resulting approach is called near-orthogonal composite quantization. We theoretically justify the equivalence between near-orthogonal composite quantization and minimizing an upper bound of a function formed by jointly considering the quantization error and the search cost according to a generalized triangle inequality. We empirically show the efficacy of the proposed approach over several benchmark datasets. In addition, we demonstrate the superior performances in other three applications: combination with inverted multi-index, inner-product similarity search, and query compression for mobile search.	[Wang, Jingdong; Zhang, Ting] Microsoft Res, Beijing 100080, Peoples R China	Microsoft	Wang, JD (corresponding author), Microsoft Res, Beijing 100080, Peoples R China.	jingdw@microsoft.com; tinzhan@microsoft.com	Wang, Jingdong/E-9920-2017	Wang, Jingdong/0000-0002-4888-4445				Babenko A., 2014, CORR; Babenko A, 2015, PROC CVPR IEEE, P4240, DOI 10.1109/CVPR.2015.7299052; Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124; Babenko A, 2012, PROC CVPR IEEE, P3069, DOI 10.1109/CVPR.2012.6248038; Du Chao, 2014, CORR; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379; Gong Y., 2012, ADV NEURAL INFORM PR, P1196; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Gordo A, 2014, IEEE T PATTERN ANAL, V36, P33, DOI 10.1109/TPAMI.2013.101; Gordo A, 2011, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2011.5995505; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Heo JP, 2014, PROC CVPR IEEE, P2139, DOI 10.1109/CVPR.2014.274; Jia Y, 2010, PROC CVPR IEEE, P3392, DOI 10.1109/CVPR.2010.5540006; Jiang ZY, 2016, AER ADV ENG RES, V80, P325; Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LeCun Y., 2001, INTELLIGENT SIGNAL P, P306; Li W.-J., 2012, P ADV NEUR INF PROC, P1646; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Martinez J, 2016, LECT NOTES COMPUT SC, V9906, P137, DOI 10.1007/978-3-319-46475-6_9; Matsui Y, 2015, IEEE I CONF COMP VIS, P1940, DOI 10.1109/ICCV.2015.225; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Silpa-Anan C, 2008, PROC CVPR IEEE, P2308; Wang JF, 2015, IEEE T KNOWL DATA EN, V27, P180, DOI 10.1109/TKDE.2014.2324592; Wang Jianfeng, 2013, P 21 ACM INT C MULTI, P133; Wang J, 2017, IEEE INFOCOM SER, DOI 10.1007/s12083-017-0556-6; Wang J, 2013, IEEE I CONF COMP VIS, P2128, DOI 10.1109/ICCV.2013.265; Wang J, 2012, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2012.6247790; Wang JD, 2014, IEEE T PATTERN ANAL, V36, P388, DOI 10.1109/TPAMI.2013.125; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Wang JQ, 2012, PROCEEDINGS OF THE 8TH EURO-ASIA CONFERENCE ON ENVIRONMENT AND CSR: TOURISM, MICE, HOSPITALITY MANAGEMENT AND EDUCATION SESSION, PT III, P179; Wang XJ, 2016, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2016.222; Xu B, 2013, P INT JOINT C ART IN, P1820; Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424; Yu FX, 2014, PR MACH LEARN RES, V32, P946; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhang QF, 2014, INT CONF MACH LEARN, P807, DOI 10.1109/ICMLC.2014.7009713; Zhang T, 2016, PROC CVPR IEEE, P2036, DOI 10.1109/CVPR.2016.224; Zhang T, 2015, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2015.7299085; 2011, P INT C AC SPEECH SI, P861; 2011, IEEE T PATTERN ANAL, V33, P117, DOI DOI 10.1109/TPAMI.2010.57; 2008, INT J COMPUT VISION, V77, P157, DOI DOI 10.1007/S11263-007-0090-8	47	7	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1308	1322		10.1109/TPAMI.2018.2835468	http://dx.doi.org/10.1109/TPAMI.2018.2835468			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU					2022-12-18	WOS:000467037000003
J	Griffin, LD				Griffin, Lewis D.			The Atlas Structure of Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image analysis; image representation; image resolution; Gaussian derivatives; filter steering; keypoints	SCALE-SPACE; GEOMETRY; FIELD; REPRESENTATION; HISTOGRAMS; FEATURES	Many operations of vision require image regions to be isolated and inter-related. This is challenging when they are different in detail and extent. Practical methods of Computer Vision approach this through the tools of downsampling, pyramids, cropping and patches. In this paper we develop an ideal geometric structure for this, compatible with the existing scale space model of image measurement. Its elements are apertures which view the image like fuzzy-edged portholes of frosted glass. We establish containment and cause/effect relations between apertures, and show that these link them into cross-scale atlases. Atlases formed of Gaussian apertures are shown to be a continuous version of the image pyramid used in Computer Vision, and allow various types of image description to naturally be expressed within their framework. We show that views through Gaussian apertures are approximately equivalent to the jets of derivative of Gaussian filter responses that form part of standard Scale Space theory. This supports a view of the simple cells of mammalian V1 as implementing a system of local views of the retinal image of varying extent and resolution. As a worked example we develop a keypoint descriptor scheme that outperforms previous schemes that do not make use of learning.	[Griffin, Lewis D.] UCL, Dept Comp Sci, London WC1E 6BT, England	University of London; University College London	Griffin, LD (corresponding author), UCL, Dept Comp Sci, London WC1E 6BT, England.	l.griffin@cs.ucl.ac.uk		Griffin, Lewis/0000-0001-6286-2018				Ball W. R., 1890, P LOND MATH SOC, V1, P104; Balntas V., 2017, ARXIV170405939; Balntas V., 2016, BMVC, V1, P3; Bursuc A, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P595, DOI 10.1145/2671188.2749379; Chen L, 2016, ISPRS ANN PHOTO REM, V3, P11, DOI 10.5194/isprsannals-III-3-11-2016; Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; DEBNATH L, 1964, MATH VESNIK, V1, P285; Duits R, 2004, J MATH IMAGING VIS, V20, P267, DOI 10.1023/B:JMIV.0000024043.96722.aa; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Florack L, 1996, INT J COMPUT VISION, V18, P61, DOI 10.1007/BF00126140; Florack L., 1997, COMP IMAG VIS, V10; Garding J, 1996, INT J COMPUT VISION, V17, P163, DOI 10.1007/BF00058750; Griffin L, 1997, COMP IMAG VIS, V8, P165; Griffin LD, 2012, COMPUT GEOSCI-UK, V39, P129, DOI 10.1016/j.cageo.2011.07.002; Griffin L. D., 2013, HDB EXPT PHENOMENOLO, P449; Griffin LD, 1997, IMAGE VISION COMPUT, V15, P369, DOI 10.1016/S0262-8856(97)87979-6; Griffin LD, 2007, IEEE T PATTERN ANAL, V29, P1355, DOI 10.1109/TPAMI.2007.1066; Griffin LD, 2010, IEEE T PATTERN ANAL, V32, P1072, DOI 10.1109/TPAMI.2009.91; Griffin LD, 2009, LECT NOTES COMPUT SC, V5567, P343, DOI 10.1007/978-3-642-02256-2_29; Hadamard J, 1902, PRINCETON U B, V13, P28; Horn R. A., 1986, MATRIX ANAL; Jaccard N, 2017, COMP M BIO BIO E-IV, V5, P359, DOI 10.1080/21681163.2015.1016243; Jaccard N., 2015, COMPUT METHOD BIOMEC, P1; Jiang Y G, 2007, P 6 ACM INT C IM VID, P494, DOI DOI 10.1145/1282280.1282352; JONES JP, 1987, J NEUROPHYSIOL, V58, P1187, DOI 10.1152/jn.1987.58.6.1187; Kimia BB, 2003, J PHYSIOL-PARIS, V97, P155, DOI 10.1016/j.jphysparis.2003.09.003; Koenderink J. J., 1997, Algebraic Frames for the Perception-Action Cycle. International Workshop, AFPAC'97. Proceedings, P66, DOI 10.1007/BFb0017861; Koenderink J, 2015, PATTERN RECOGN LETT, V64, P71, DOI 10.1016/j.patrec.2015.02.003; KOENDERINK JJ, 1992, IEEE T PATTERN ANAL, V14, P597, DOI 10.1109/34.141551; Koenderink JJ, 2002, LECT NOTES COMPUT SC, V2350, P158; KOENDERINK JJ, 1990, PSYCHOL RES-PSYCH FO, V52, P122, DOI 10.1007/BF00877519; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P159, DOI 10.1023/A:1008065931878; Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070; Li J, 2008, NEUROCOMPUTING, V71, P1771, DOI 10.1016/j.neucom.2007.11.032; Linde O, 2012, COMPUT VIS IMAGE UND, V116, P538, DOI 10.1016/j.cviu.2011.12.003; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lindeberg T, 1997, COMP IMAG VIS, V8, P75; Lindeberg T., 1993, SCALE SPACE THEORY C; Lindeberg T, 2013, BIOL CYBERN, V107, P589, DOI 10.1007/s00422-013-0569-z; Lindeberg T, 2013, ADV IMAG ELECT PHYS, V178, P1, DOI 10.1016/B978-0-12-407701-0.00001-7; Lindeberg T, 2011, J MATH IMAGING VIS, V40, P36, DOI 10.1007/s10851-010-0242-2; Loog M, 2007, LECT NOTES COMPUT SC, V4485, P25; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Makram-Ebeid S, 2003, LECT NOTES COMPUT SC, V2695, P57; Markus N, 2016, INT C PATT RECOG, P2380, DOI 10.1109/ICPR.2016.7899992; MOSTAFAVI H, 1979, IEEE T ACOUST SPEECH, V27, P163, DOI 10.1109/TASSP.1979.1163208; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Olshausen BA, 2005, NEURAL COMPUT, V17, P1665, DOI 10.1162/0899766054026639; Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895; Pillai SU, 2005, IEEE SIGNAL PROC MAG, V22, P62, DOI 10.1109/MSP.2005.1406483; Roelfsema PR, 2006, ANNU REV NEUROSCI, V29, P203, DOI 10.1146/annurev.neuro.29.051605.112939; Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444; Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649; Tikhonov A.N., 1977, SOLUTION ILL POSED P; van Ginneken B, 2000, J VIS COMMUN IMAGE R, V11, P196, DOI 10.1006/jvci.1999.0445; Weickert J, 1997, COMP IMAG VIS, V8, P45; Weickert J, 1999, J MATH IMAGING VIS, V10, P237, DOI 10.1023/A:1008344623873; Young RA, 2001, SPATIAL VISION, V14, P261, DOI 10.1163/156856801753253582	64	7	7	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					234	245		10.1109/TPAMI.2017.2777856	http://dx.doi.org/10.1109/TPAMI.2017.2777856			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990035				2022-12-18	WOS:000452434800018
J	Vaskevicius, N; Birk, A				Vaskevicius, Narunas; Birk, Andreas			Revisiting Superquadric Fitting: A Numerically Stable Formulation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Superquadric fitting; optimization; numerical stability; object recognition	RANGE IMAGES; MODELS; REPRESENTATION; SEGMENTATION; RECOGNITION	Superquadric surfaces play an important role in many different research fields due to their ability to model a variety of shapes with a small number of parameters. One of their core applications is the estimation of object shape characteristics from a set of discrete samples from the surface of an object. However, the corresponding optimization problem is prone to numerical instabilities in some regions of the parameter space. To mitigate this problem, lower bound constraints to the shape parameters are applied during the optimization thus limiting the range of shapes which can be accurately represented by superquadrics. Therefore, the exact modeling of very common shapes like cuboids and cylinders is error-prone in practice. In this article we investigate this problem and provide a numerically stable formulation for the evaluation of the superquadric surface function and for its gradient. This new formulation enables numerically stable fitting of superquadrics in the previously constrained region, i.e., in its full range including cuboids and cylinders. In addition, the new formulation also leads to faster convergence speed. The theoretical contributions are substantiated by experiments on synthetic as well as real data.	[Vaskevicius, Narunas; Birk, Andreas] Jacobs Univ Bremen, Dept Comp Sci & Elect Engn, D-28759 Bremen, Germany	Jacobs University	Vaskevicius, N (corresponding author), Jacobs Univ Bremen, Dept Comp Sci & Elect Engn, D-28759 Bremen, Germany.	n.vaskevicius@jacobs-university.de; a.birk@jacobs-university.de	Birk, Andreas/W-9259-2019	Birk, Andreas/0000-0003-4577-2525	European Community's Seventh Framework Programme (EU FP7); Horizon 2020 (EU H2020)	European Community's Seventh Framework Programme (EU FP7); Horizon 2020 (EU H2020)	The research leading to the results presented here has received funding from the European Community's Seventh Framework Programme (EU FP7) and Horizon 2020 (EU H2020) within the projects "Cognitive Robot for Automation Logistics Processes (RobLog)" and "Effective Dexterous ROV Operations in Presence of Communications Latencies (DexROV)".	Agarwal S., CERES SOLVER; Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; Barr A. H., 1984, Computers & Graphics, V18, P21; Biegelbauer G, 2010, MACH VISION APPL, V21, P497, DOI 10.1007/s00138-008-0178-3; Boult T. E., 1987, P WORKSH SPAT REAS M, P128; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156; COHENSTEINER D, 2004, P SIGGRAPH; Drews P, 2010, IEEE INT CONF ROBOT, P3635, DOI 10.1109/ROBOT.2010.5509405; Duncan K, 2013, IEEE INT CONF ROBOT, P4238, DOI 10.1109/ICRA.2013.6631176; FERRIE FP, 1993, IEEE T PATTERN ANAL, V15, P771, DOI 10.1109/34.236252; Fletcher R., 2000, PRACTICAL METHODS OP; Goldfeder C, 2007, IEEE INT CONF ROBOT, P4679, DOI 10.1109/ROBOT.2007.364200; Jaklic A, 2000, SEGMENTATION RECOVER; Jaklic A, 2015, J ARCHAEOL SCI, V62, P143, DOI 10.1016/j.jas.2015.08.007; Kasper A, 2012, INT J ROBOT RES, V31, P927, DOI 10.1177/0278364912445831; Katsoulas D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P931; Katsoulas D, 2008, IEEE T PATTERN ANAL, V30, P781, DOI 10.1109/TPAMI.2007.70736; Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437; Kohntopp D, 2015, IEEE INT CONF ROBOT, P3380, DOI 10.1109/ICRA.2015.7139666; Korez R, 2014, COMPUT MED IMAG GRAP, V38, P596, DOI 10.1016/j.compmedimag.2014.04.008; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; More J., 1980, ANL8074; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; Pilu Maurizio, 1995, EQUAL DISTANCE SAMPL; Schultz T, 2010, IEEE T VIS COMPUT GR, V16, P1595, DOI 10.1109/TVCG.2010.199; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; Stoyanov T, 2016, IEEE ROBOT AUTOM MAG, V23, P94, DOI 10.1109/MRA.2016.2535098; Tay PC, 2009, J SIGNAL PROCESS SYS, V55, P139, DOI 10.1007/s11265-008-0219-1; Thamer H, 2013, LECT NOTES COMPUT SC, V7950, P215, DOI 10.1007/978-3-642-39094-4_25; Tyrrell JA, 2005, MICROVASC RES, V70, P165, DOI 10.1016/j.mvr.2005.08.005; Vaskevicius N, 2017, J INTELL ROBOT SYST, V88, P57, DOI 10.1007/s10846-017-0540-7; Zhang L, 2016, IEEE T COMPUT IMAG, V2, P86, DOI 10.1109/TCI.2016.2542002; Zhang Y, 2003, PATTERN RECOGN LETT, V24, P2185, DOI 10.1016/s0167-8655(02)00400-2	36	7	7	3	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					220	233		10.1109/TPAMI.2017.2779493	http://dx.doi.org/10.1109/TPAMI.2017.2779493			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990010				2022-12-18	WOS:000452434800017
J	Jiang, SH; Shao, M; Jia, CC; Fu, Y				Jiang, Shuhui; Shao, Ming; Jia, Chengcheng; Fu, Yun			Learning Consensus Representation for Weak Style Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Style classification; deep learning; auto-encoder		Style classification (e.g., Baroque and Gothic architecture style) is grabbing increasing attention in many fields such as fashion, architecture, and manga. Most existing methods focus on extracting discriminative features from local patches or patterns. However, the spread out phenomenon in style classification has not been recognized yet. It means that visually less representative images in a style class are usually very diverse and easily getting misclassified. We name them weak style images. Another issue when employing multiple visual features towards effective weak style classification is lack of consensus among different features. That is, weights for different visual features in the local patch should have been allocated similar values. To address these issues, we propose a Consensus Style Centralizing Auto-Encoder (CSCAE) for learning robust style features representation, especially for weak style classification. First, we propose a Style Centralizing Auto-Encoder (SCAE) which centralizes weak style features in a progressive way. Then, based on SCAE, we propose both the non-linear and linear version CSCAE which adaptively allocate weights for different features during the progressive centralization process. Consensus constraints are added based on the assumption that the weights of different features of the same patch should be similar. Specifically, the proposed linear counterpart of CSCAE motivated by the "shared weights" idea as well as group sparsity improves both efficacy and efficiency. For evaluations, we experiment extensively on fashion, manga and architecture style classification problems. In addition, we collect a new dataset-Online Shopping, for fashion style classification, which will be publicly available for vision based fashion style research. Experiments demonstrate the effectiveness of the SCAE and CSCAE on both public and newly collected datasets when compared with the most recent state-of-the-art works.	[Jiang, Shuhui; Jia, Chengcheng] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Shao, Ming] Univ Massachusetts Dartmouth, Dept Comp Informat Sci, Dartmouth, MA 02747 USA; [Fu, Yun] Northeastern Univ, Coll Engn, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Fu, Yun] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA	Northeastern University; University of Massachusetts System; University Massachusetts Dartmouth; Northeastern University; Northeastern University	Jiang, SH (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.	shjiang@ece.neu.edu; mshao@umassd.edu; jiachengcheng128@gmail.com; yunfu@ece.neu.edu	Jiang, Shuhui/W-6907-2019		NSF IIS award [1651902]; ONR Young Investigator Award [N00014-14-1-0484]; U.S. Army Research Office Award [W911NF-17-1-0367]	NSF IIS award(National Science Foundation (NSF)); ONR Young Investigator Award; U.S. Army Research Office Award	This research is supported in part by the NSF IIS award 1651902, ONR Young Investigator Award N00014-14-1-0484, and U.S. Army Research Office Award W911NF-17-1-0367.	Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bossard Lukas, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P321, DOI 10.1007/978-3-642-37447-0_25; Bunea F, 2012, ANN STAT, V40, P2359, DOI 10.1214/12-AOS1039; Chang Y.-C., 2003, P 6 AS DES C; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Chen M., 2012, P ICML; Chen M., 2012, P LEARN WORKSH UT UT, V36; Chu WT, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P781, DOI 10.1145/2647868.2654962; Ding ZM, 2016, LECT NOTES COMPUT SC, V9910, P567, DOI 10.1007/978-3-319-46466-4_34; Ding ZM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3453; Goel A., 2012, P 8 IND C COMP VIS G, P1; Herlands W, 2014, AAAI CONF ARTIF INTE, P276; Jiang SH, 2016, AAAI CONF ARTIF INTE, P1223; Jiang SH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3721; Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243; Kiapour MH, 2014, LECT NOTES COMPUT SC, V8689, P472, DOI 10.1007/978-3-319-10590-1_31; Le Q.V., 2011, P ICML JAN, P265; Lee S, 2015, PERSPECT CONTEMP KOR, P1; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422; Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071; NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.1090/S0025-5718-1980-0572855-7; Rumelhart D. E., 1988, NEUROCOMPUTING FDN R, P696; Shalunts G, 2015, LECT NOTES COMPUT SC, V9474, P285, DOI 10.1007/978-3-319-27857-5_26; van Gemert J. C., 2011, P ICMR, P1; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Weiss C, 2015, INT CONF ACOUST SPEE, P688, DOI 10.1109/ICASSP.2015.7178057; Wu MJ, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2801127; Xu C, 2009, 2009 THIRD IEEE INTERNATIONAL CONFERENCE ON SECURE SOFTWARE INTEGRATION AND RELIABILITY IMPROVEMENT, PROCEEDINGS, P35, DOI 10.1109/SSIRI.2009.72; Xu Z, 2014, LECT NOTES COMPUT SC, V8689, P600, DOI 10.1007/978-3-319-10590-1_39; Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437; Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Zhang LM, 2015, IEEE INT CON MULTI, DOI 10.1109/GLOCOM.2015.7417436; Zhao HD, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4077	38	7	9	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2906	2919		10.1109/TPAMI.2017.2771766	http://dx.doi.org/10.1109/TPAMI.2017.2771766			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29990099	hybrid			2022-12-18	WOS:000449355500009
J	Lee, S; Gornitz, N; Xing, EP; Heckerman, D; Lippert, C				Lee, Seunghak; Goernitz, Nico; Xing, Eric P.; Heckerman, David; Lippert, Christoph			Ensembles of Lasso Screening Rules	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Lasso; screening rule; ensemble	GENOME-WIDE ASSOCIATION; SELECTION; TESTS	In order to solve large-scale lasso problems, screening algorithms have been developed that discard features with zero coefficients based on a computationally efficient screening rule. Most existing screening rules were developed from a spherical constraint and half-space constraints on a dual optimal solution. However, existing rules admit at most two half-space constraints due to the computational cost incurred by the half-spaces, even though additional constraints may be useful to discard more features. In this paper, we present AdaScreen, an adaptive lasso screening rule ensemble, which allows to combine any one sphere with multiple half-space constraints on a dual optimal solution. Thanks to geometrical considerations that lead to a simple closed form solution for AdaScreen, we can incorporate multiple half-space constraints at small computational cost. In our experiments, we show that AdaScreen with multiple half-space constraints simultaneously improves screening performance and speeds up lasso solvers.	[Lee, Seunghak; Lippert, Christoph] Human Longev Inc, Mountain View, CA 94041 USA; [Xing, Eric P.] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA; [Goernitz, Nico] Berlin Inst Technol, Dept Software Engn & Theoret Comp Sci, Machine Learning Grp, D-10578 Berlin, Germany; [Heckerman, David] Microsoft Res, Los Angeles, CA 90024 USA	Carnegie Mellon University; Technical University of Berlin; Microsoft	Lee, S (corresponding author), Human Longev Inc, Mountain View, CA 94041 USA.	leeseunghak@gmail.com; nico.goernitz@tu-berlin.de; epxing@cs.cmu.edu; heckerma@microsoft.com; christoph.a.lippert@gmail.com	Lippert, Christoph/M-2992-2016	Lippert, Christoph/0000-0001-6363-2556; Gornitz, Nico/0000-0002-5222-3631	BMBF ALICE II [01IB15001B]; NIH [R01GM114311, P30DA035778]; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES [R01GM114311] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DRUG ABUSE [P30DA035778] Funding Source: NIH RePORTER	BMBF ALICE II(Federal Ministry of Education & Research (BMBF)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); NATIONAL INSTITUTE ON DRUG ABUSE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Drug Abuse (NIDA)European Commission)	Part of the work was done while SL, NG, and CL were with Microsoft Research, Los Angeles. NG was supported by BMBF ALICE II grant 01IB15001B, and EPX was supported by NIH R01GM114311 and NIH P30DA035778. Seunghak Lee, Nico Gornitz, and Christoph Lippert contributed equally to this work.	Bonnefoy A., 2014, P EUR SIGN PROC C, P5121; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Collins FS, 2003, SCIENCE, V300, P286, DOI 10.1126/science.1084564; Cuturi M., 2011, P 28 INT C MACH LEAR, P929; Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137; Dixon AL, 2007, NAT GENET, V39, P1202, DOI 10.1038/ng2109; El Ghaoui L, 2012, PAC J OPTIM, V8, P667; Fan JQ, 2008, J R STAT SOC B, V70, P849, DOI 10.1111/j.1467-9868.2008.00674.x; Fan JQ, 2011, J AM STAT ASSOC, V106, P544, DOI 10.1198/jasa.2011.tm09779; Fan JQ, 2010, ANN STAT, V38, P3567, DOI 10.1214/10-AOS798; Fercoq O, 2015, PR MACH LEARN RES, V37, P333; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Lang Ken, 1995, MACHINE LEARNING P; Lee S, 2016, BIOINFORMATICS, V32, P164, DOI 10.1093/bioinformatics/btw270; Lichman M, 2013, UCI MACHINE LEARNING; Liu J., 2014, P INT C MACH LEARN, P1556; Luenberger D. G., 1969, OPTIMIZATION VECTOR; Mazumder R, 2012, J MACH LEARN RES, V13, P781; Ndiaye E, 2015, ADV NEUR IN, V28; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tibshirani R, 2012, J R STAT SOC B, V74, P245, DOI 10.1111/j.1467-9868.2011.01004.x; Wang J, 2014, ADV NEUR IN, V27; Wang Jie, 2013, ADV NEURAL INFORM PR; Wang Y, 2013, INT CONF ACOUST SPEE, P3342, DOI 10.1109/ICASSP.2013.6638277; Wang Y, 2013, INT CONF ACOUST SPEE, P3297, DOI 10.1109/ICASSP.2013.6638268; Webb S., 2006, P C EM ANT; Xiang Z., 2011, ADV NEURAL INFORM PR, V24, P900; Xiang ZJ, 2017, IEEE T PATTERN ANAL, V39, P1008, DOI 10.1109/TPAMI.2016.2568185; Xiang ZJ, 2012, INT CONF ACOUST SPEE, P2137, DOI 10.1109/ICASSP.2012.6288334; Zhang B, 2013, CELL, V153, P707, DOI 10.1016/j.cell.2013.03.030; Zhao P, 2006, J MACH LEARN RES, V7, P2541	33	7	7	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2841	2852		10.1109/TPAMI.2017.2765321	http://dx.doi.org/10.1109/TPAMI.2017.2765321			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29989981	Green Accepted, Bronze			2022-12-18	WOS:000449355500004
J	Kononenko, D; Ganin, Y; Sungatullina, D; Lempitsky, V				Kononenko, Daniil; Ganin, Yaroslav; Sungatullina, Diana; Lempitsky, Victor			Photorealistic Monocular Gaze Redirection Using Machine Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaze redirection; machine learning; deep learning; random forest; weakly-supervised learning; image resynthesis	EYE CONTACT; FORESTS	We propose a general approach to the gaze redirection problem in images that utilizes machine learning. The idea is to learn to re-synthesize images by training on pairs of images with known disparities between gaze directions. We show that such learning-based re-synthesis can achieve convincing gaze redirection based on monocular input, and that the learned systems generalize well to people and imaging conditions unseen during training. We describe and compare three instantiations of our idea. The first system is based on efficient decision forest predictors and redirects the gaze by a fixed angle in real-time (on a single CPU), being particularly suitable for the videoconferencing gaze correction. The second system is based on a deep architecture and allows gaze redirection by a range of angles. The second system achieves higher photorealism, while being several times slower. The third system is based on real-time decision forests at test time, while using the supervision from a "teacher" deep network during training. The third system approaches the quality of a teacher network in our experiments, and thus provides a highly realistic real-time monocular solution to the gaze correction problem. We present in-depth assessment and comparisons of the proposed systems based on quantitative measurements and a user study.	[Kononenko, Daniil; Sungatullina, Diana; Lempitsky, Victor] Skolkovo Inst Sci & Technol, Moscow 143026, Russia; [Ganin, Yaroslav] Univ Montreal, Montreal, PQ, Canada	Skolkovo Institute of Science & Technology; Universite de Montreal	Kononenko, D (corresponding author), Skolkovo Inst Sci & Technol, Moscow 143026, Russia.	daniil.kononenko@skoltech.ru; yaroslav.ganin@gmail.com; d.sungatullina@skoltech.ru; lempitsky@skoltech.ru		Sungatullina, Diana/0000-0002-2957-5495				Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Baltrusaitis T., 2016, 2016 IEEE WINT C APP, P1, DOI [10.1109/WACV.2016.7477553, DOI 10.1109/WACV.2016.7477553]; Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.3390/risks8030083; Bucilua Cristian, 2006, P 12 ACM SIGKDD INT, P535, DOI [10.1145/1150402.1150464, DOI 10.1145/1150402.1150464]; Criminisi A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P191; Denton E, 2015, DEEP GENERATIVE IMAG, DOI DOI 10.5555/; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0; Fanello SR, 2014, PROC CVPR IEEE, P1709, DOI 10.1109/CVPR.2014.221; Gall J, 2009, PROC CVPR IEEE, P1022, DOI 10.1109/CVPRW.2009.5206740; Ganin Y, 2016, LECT NOTES COMPUT SC, V9906, P311, DOI 10.1007/978-3-319-46475-6_20; Gatys L. A., 2015, ADV NEURAL INFORM PR, V28, P262, DOI DOI 10.1016/0014-5793(76)80724-7; Ghodrati A., 2015, AUTOMATIC IMAGE EDIT; Giger D., 2014, 2014 IEEE INT C MULT, P1; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton G., 2017, CORR; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jones A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531370; Kavukcuoglu K, 2015, ADV NEURAL INF PROCE, P2017; Kingma D.P, P 3 INT C LEARNING R; KLEINKE CL, 1986, PSYCHOL BULL, V100, P78, DOI 10.1037/0033-2909.100.1.78; Kononenko D., 2014, GAZE CORRECTION VIDE; Kononenko D, 2015, PROC CVPR IEEE, P4667, DOI 10.1109/CVPR.2015.7299098; Kulkarni TD, 2015, ADV NEUR IN, V28; Kuster C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366193; Lepetit V, 2005, PROC CVPR IEEE, P775; Liu Z., 2017, CORR; Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155; Okada K., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P385, DOI 10.1145/192844.193054; Oquab M., 2015, TORCH7 MODULES SPATI; Park E., 2017, CORR; Reed S, 2015, ADV NEURAL INFORM PR, P1252; Romero Adriana, 2014, CORR; SHOTTON J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI DOI 10.1109/TPAMI.2012.241; Shu ZX, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2926713; Tat-Jen Cham, 2002, 2002 7th International Conference on Control, Automation, Robotics and Vision (IEEE Cat. No.02EX649), P1415; Wallis LJ, 2015, ANIM BEHAV, V106, P27, DOI 10.1016/j.anbehav.2015.04.020; Wolf L, 2010, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2010.5540133; Xue Tianfan, 2016, ADV NEURAL INFORM PR, P2; Yang RG, 2002, LECT NOTES COMPUT SC, V2351, P479; Yeh R., 2016, CORR; Yin P., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383008; Yip B., 2003, P 7 IASTED INT C INT, P245; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18; Zhu JJ, 2011, 3D RES, V2, DOI 10.1007/3DRes.03(2011)5	50	7	7	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2696	2710		10.1109/TPAMI.2017.2737423	http://dx.doi.org/10.1109/TPAMI.2017.2737423			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	28809672				2022-12-18	WOS:000446683700013
J	Li, YQ; Chen, C; Yang, F; Huang, JZ				Li, Yeqing; Chen, Chen; Yang, Fei; Huang, Junzhou			Hierarchical Sparse Representation for Robust Image Registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image registration; hierarchical sparse representation; sparse learning	LIKELIHOOD MOTION ESTIMATION; NONRIGID REGISTRATION; STRONG UNIQUENESS; DYNAMIC MRI; ALIGNMENT; ALGORITHM; DECOMPOSITION; CONVERGENCE; SCALE	Similarity measure is an essential component in image registration. In this article, we propose a novel similarity measure for registration of two or more images. The proposed method is motivated by the fact that optimally registered images can be sparsified hierarchically in the gradient domain and frequency domain with the separation of sparse errors. One of the key advantages of the proposed similarity measure is its robustness in dealing with severe intensity distortions, which widely exist on medical images, remotely sensed images and natural photos due to differences of acquisition modalities or illumination conditions. Two efficient algorithms are proposed to solve the batch image registration and pair registration problems in a unified framework. We have validated our method on extensive and challenging data sets. The experimental results demonstrate the robustness, accuracy and efficiency of our method over nine traditional and state-of-the-art algorithms on synthetic images and a wide range of real-world applications.	[Li, Yeqing; Chen, Chen; Huang, Junzhou] Univ Texas Arlington, Arlington, TX 76019 USA; [Li, Yeqing; Chen, Chen; Huang, Junzhou] Tencent AI Lab, Arlington, TX 76019 USA; [Yang, Fei] Facebook Inc, Menlo Pk, CA 94025 USA	University of Texas System; University of Texas Arlington; Facebook Inc	Huang, JZ (corresponding author), Univ Texas Arlington, Arlington, TX 76019 USA.; Huang, JZ (corresponding author), Tencent AI Lab, Arlington, TX 76019 USA.	yeqing.li@mavs.uta.edu; chenchen.cn87@gmail.com; feiyang@cs.rutgers.edu; jzhuang@uta.edu	li, ye/GWN-2672-2022; Chen, Chen/AAJ-6895-2020	Chen, Chen/0000-0002-9212-9308	US National Science Foundation [IIS-1423056, CMMI-1434401, CNS-1405985, IIS-1718853]; NSF CAREER grant [IIS-1553687]	US National Science Foundation(National Science Foundation (NSF)); NSF CAREER grant(National Science Foundation (NSF)NSF - Office of the Director (OD))	This work was partially supported by US National Science Foundation IIS-1423056, CMMI-1434401, CNS-1405985, IIS-1718853 and the NSF CAREER grant IIS-1553687	[Anonymous], 1998, P 2 INT C FUS EARTH; Bayram I, 2012, IEEE SIGNAL PROC LET, V19, P781, DOI 10.1109/LSP.2012.2220349; Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250; BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Chan RH, 2015, INVERSE PROBL IMAG, V9, P55, DOI 10.3934/ipi.2015.9.55; Chen C, 2014, PROC CVPR IEEE, P2760, DOI 10.1109/CVPR.2014.347; Cocosco C.A., 1997, NEUROIMAGE, V5, P425, DOI DOI 10.1016/S1053-8119(97)80018-3; Cohen B, 2002, PATTERN RECOGN, V35, P455, DOI 10.1016/S0031-3203(01)00053-X; Condat L, 2013, J OPTIMIZ THEORY APP, V158, P460, DOI 10.1007/s10957-012-0245-9; CROMME L, 1978, NUMER MATH, V29, P179, DOI 10.1007/BF01390337; Goshtasby A. A., 2012, IMAGE REGISTRATION, P401; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hamy V, 2014, MED IMAGE ANAL, V18, P301, DOI 10.1016/j.media.2013.10.016; He J, 2014, IMAGE VISION COMPUT, V32, P800, DOI 10.1016/j.imavis.2014.02.015; Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201; Huang G., 2012, ADV NEURAL INFORM PR, P764; Huang GB, 2007, 07 UMASS TR; Huang J., 2008, P IEEE C COMP VIS PA, P1; Huang JZ, 2011, COMPUT VIS IMAGE UND, V115, P1610, DOI 10.1016/j.cviu.2011.06.011; Huang JZ, 2011, MED IMAGE ANAL, V15, P670, DOI 10.1016/j.media.2011.06.001; JITTORNTRUM K, 1980, NUMER MATH, V34, P439, DOI 10.1007/BF01403680; Kim J, 2004, IEEE T MED IMAGING, V23, P1430, DOI 10.1109/TMI.2004.835313; Lee S, 1997, IEEE T VIS COMPUT GR, V3, P228, DOI 10.1109/2945.620490; Lewis AS, 2016, MATH PROGRAM, V158, P501, DOI 10.1007/s10107-015-0943-9; Li YQ, 2015, I S BIOMED IMAGING, P605, DOI 10.1109/ISBI.2015.7163946; LI YQ, 2015, PROC CVPR IEEE, P4894; Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434; Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Myronenko A, 2010, IEEE T MED IMAGING, V29, P1882, DOI 10.1109/TMI.2010.2053043; Myronenko A, 2009, LECT NOTES COMPUT SC, V5528, P427, DOI 10.1007/978-3-642-01932-6_46; Nguyen Hieu V., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P709, DOI 10.1007/978-3-642-19309-5_55; Otazo R, 2015, MAGN RESON MED, V73, P1125, DOI 10.1002/mrm.25240; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603; Studholme C, 2006, IEEE T MED IMAGING, V25, P626, DOI 10.1109/TMI.2006.872745; Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009; Thomas C, 2008, IEEE T GEOSCI REMOTE, V46, P1301, DOI 10.1109/TGRS.2007.912448; Toma A, 2014, I S BIOMED IMAGING, P1152, DOI 10.1109/ISBI.2014.6868079; Tzimiropoulos G, 2010, IEEE T PATTERN ANAL, V32, P1899, DOI 10.1109/TPAMI.2010.107; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wai-tian Tan, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3225, DOI 10.1109/ICIP.2011.6116356; Wu KK, 2011, INT CONF ACOUST SPEE, P1397; Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878; Zana F, 1999, IEEE T MED IMAGING, V18, P419, DOI 10.1109/42.774169; Zheng YJ, 2014, MED IMAGE ANAL, V18, P903, DOI 10.1016/j.media.2013.09.009; Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	56	7	7	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2151	2164		10.1109/TPAMI.2017.2748125	http://dx.doi.org/10.1109/TPAMI.2017.2748125			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28880157	hybrid			2022-12-18	WOS:000440868400009
J	Zheng, EL; Ji, DH; Dunn, E; Frahm, JM				Zheng, Enliang; Ji, Dinghuang; Dunn, Enrique; Frahm, Jan-Michael			Self-Expressive Dictionary Learning for Dynamic 3D Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dictionary learning; self-expression; unsynchronized videos; dynamic 3D reconstruction	STRUCTURE-FROM-MOTION; NONRIGID SHAPE; SPARSE	We target the problem of sparse 3D reconstruction of dynamic objects observed by multiple unsynchronized video cameras with unknown temporal overlap. To this end, we develop a framework to recover the unknown structure without sequencing information across video sequences. Our proposed compressed sensing framework poses the estimation of 3D structure as the problem of dictionary learning, where the dictionary is defined as an aggregation of the temporally varying 3D structures. Given the smooth motion of dynamic objects, we observe any element in the dictionary can be well approximated by a sparse linear combination of other elements in the same dictionary (i.e., self-expression). Our formulation optimizes a biconvex cost function that leverages a compressed sensing formulation and enforces both structural dependency coherence across video streams, as well as motion smoothness across estimates from common video sources. We further analyze the reconstructability of our approach under different capture scenarios, and its comparison and relation to existing methods. Experimental results on large amounts of synthetic data as well as real imagery demonstrate the effectiveness of our approach.	[Zheng, Enliang; Ji, Dinghuang; Frahm, Jan-Michael] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27515 USA; [Dunn, Enrique] Stevens Inst Technol, Dept Comp Sci, Hoboken, NJ 07030 USA	University of North Carolina; University of North Carolina Chapel Hill; Stevens Institute of Technology	Zheng, EL (corresponding author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27515 USA.	ezheng@cs.unc.edu; jdh@cs.unc.edu; edunn@stevens.edu; jmf@cs.unc.edu		Zheng, Enliang/0000-0002-7832-6743				Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Akhter Ijaz, 2008, ADV NEURAL INFORM PR, P41; Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377; Ballan L, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778824; Basha T, 2012, LECT NOTES COMPUT SC, V7577, P654, DOI 10.1007/978-3-642-33783-3_47; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Chen YS, 2014, PROC CVPR IEEE, P1478, DOI 10.1109/CVPR.2014.192; Dai YC, 2014, INT J COMPUT VISION, V107, P101, DOI 10.1007/s11263-013-0684-2; Dekel T, 2013, IEEE I CONF COMP VIS, P977, DOI 10.1109/ICCV.2013.125; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547; Elhayek A, 2015, PROC CVPR IEEE, P3810, DOI 10.1109/CVPR.2015.7299005; Hartley R, 2008, LECT NOTES COMPUT SC, V5302, P276, DOI 10.1007/978-3-540-88682-2_22; Hastie T., 2009, ELEMENTS STAT LEARNI, DOI [10.1007/978-0-387-84858-7, DOI 10.1007/978-0-387-84858-7]; Kong C, 2016, PROC CVPR IEEE, P4123, DOI 10.1109/CVPR.2016.447; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B. D., 1981, INT JOINT C ART INT, P674, DOI DOI 10.5555/1623264.1623280; Muller M., 2007, TECHNICAL REPORT; Paladini Marco, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2898, DOI 10.1109/CVPRW.2009.5206602; Park HS, 2015, INT J COMPUT VISION, V115, P115, DOI 10.1007/s11263-015-0804-2; Park HS, 2010, LECT NOTES COMPUT SC, V6313, P158; Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41; Rao C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P939; Shrestha P, 2010, IEEE T MULTIMEDIA, V12, P79, DOI 10.1109/TMM.2009.2036285; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tompson J.J., 2014, ADV NEURAL INF PROCE, P1799, DOI DOI 10.5555/2968826.2969027; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tuytelaars T, 2004, PROC CVPR IEEE, P762; Valmadre J, 2012, PROC CVPR IEEE, P1394, DOI 10.1109/CVPR.2012.6247826; Vidal R, 2006, LECT NOTES COMPUT SC, V3952, P205; Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25; Xiao J, 2004, LECT NOTES COMPUT SC, V2034, P573; Zheng EL, 2015, IEEE I CONF COMP VIS, P4435, DOI 10.1109/ICCV.2015.504; Zheng EL, 2014, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2014.196; Zheng EL, 2014, LECT NOTES COMPUT SC, V8695, P599, DOI 10.1007/978-3-319-10584-0_39; Zhu YG, 2011, PROCEEDINGS OF THE ASME INTERNATIONAL MANUFACTURING SCIENCE AND ENGINEERING CONFERENCE 2010, VOL 2, P1, DOI 10.1109/CVPR.2011.5995650; Zhu YY, 2014, PROC CVPR IEEE, P1542, DOI 10.1109/CVPR.2014.200	39	7	7	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2223	2237		10.1109/TPAMI.2017.2742950	http://dx.doi.org/10.1109/TPAMI.2017.2742950			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28841551	Green Submitted			2022-12-18	WOS:000440868400014
J	Jiao, YL; Vert, JP				Jiao, Yunlong; Vert, Jean-Philippe			The Kendall and Mallows Kernels for Permutations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel methods; permutation; Kendall tau correlation; Mallows model; cluster analysis of rank data; supervised classification of biomedical data	MARKER GENES; RANKING; CANCER; PATTERNS; TUMOR	We show that the widely used Kendall tau correlation coefficient, and the related Mallows kernel, are positive definite kernels for permutations. They offer computationally attractive alternatives to more complex kernels on the symmetric group to learn from rankings, or learn to rank. We show how to extend these kernels to partial rankings, multivariate rankings and uncertain rankings. Examples are presented on how to formulate typical problems of learning from rankings such that they can be solved with state-of-the-art kernel algorithms. We demonstrate promising results on clustering heterogeneous rank data and high-dimensional classification problems in biomedical applications.	[Jiao, Yunlong; Vert, Jean-Philippe] PSL Res Univ, CBIO Ctr Computat Biol, MINES ParisTech, F-77300 Fontainebleau, France; [Jiao, Yunlong; Vert, Jean-Philippe] Inst Curie, F-75248 Paris, France; [Jiao, Yunlong; Vert, Jean-Philippe] INSERM, U900, F-75248 Paris, France; [Vert, Jean-Philippe] Ecole Normale Super, Dept Math & Their Applicat, F-75005 Paris, France	UDICE-French Research Universities; PSL Research University Paris; MINES ParisTech; UDICE-French Research Universities; PSL Research University Paris; UNICANCER; Institut Curie; UDICE-French Research Universities; PSL Research University Paris; UNICANCER; Institut Curie; Institut National de la Sante et de la Recherche Medicale (Inserm); UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS)	Vert, JP (corresponding author), PSL Res Univ, CBIO Ctr Computat Biol, MINES ParisTech, F-77300 Fontainebleau, France.; Vert, JP (corresponding author), Inst Curie, F-75248 Paris, France.; Vert, JP (corresponding author), INSERM, U900, F-75248 Paris, France.	yunlong.jiao@mines-paristech.fr; jean-philippe.vert@mines-paristech.fr		Vert, Jean-Philippe/0000-0001-9510-8441	European Union 7th Framework Program through the Marie Curie ITNMLPM grant [316861]; European Research Council [ERC-SMAC-280032]; Miller Institute for Basic Research in Science; Fulbright Foundation	European Union 7th Framework Program through the Marie Curie ITNMLPM grant; European Research Council(European Research Council (ERC)European Commission); Miller Institute for Basic Research in Science; Fulbright Foundation	This work was supported by the European Union 7th Framework Program through the Marie Curie ITNMLPM grant No 316861, the European Research Council grant ERC-SMAC-280032, the Miller Institute for Basic Research in Science [to JPV]; and the Fulbright Foundation [to JPV]. We thank anonymous reviewers for interesting comments, in particular the possibility to extend the kernels to partial orders.	Ailon N, 2008, J ACM, V55, DOI 10.1145/1411509.1411513; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; [Anonymous], 1781, HIST LACADEMIE ROYAL; [Anonymous], 1985, METRIC METHODS ANAL; Arrow K. J., 2012, SOCIAL CHOICE INDIVI, V3rd; Bach F.R., 2004, P 21 INT C MACH LEAR, P6, DOI DOI 10.1145/1015330.1015424; BakIr G., 2007, PREDICTING STRUCTURE; Balcan MF, 2008, MACH LEARN, V72, P139, DOI 10.1007/s10994-008-5058-6; BARTHOLDI J, 1989, SOC CHOICE WELFARE, V6, P157, DOI 10.1007/BF00303169; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Bousquet O., 2008, ADV NEURAL INFORM PR, P161, DOI DOI 10.7751/mitpress/8996.003.0015; Copeland A. H., 1951, SEM MATH SOC SCI; Cormen T.H., 2009, INTRO ALGORITHMS; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Desmedt C, 2007, CLIN CANCER RES, V13, P3207, DOI 10.1158/1078-0432.CCR-06-2765; Diaconis Persi, 1988, GROUP REPRESENTATION, V11; Dwork C., 2001, P 10 INT C WORLD WID, P613, DOI [10.1145/371920.372165, DOI 10.1145/371920.372165]; Filippone M, 2008, PATTERN RECOGN, V41, P176, DOI 10.1016/j.patcog.2007.05.018; FLIGNER MA, 1986, J R STAT SOC B, V48, P359; Fukumizu K., 2008, ADV NEURAL INFORM PR, V21, P473; Gartner T, 2004, MACH LEARN, V57, P205, DOI 10.1023/B:MACH.0000039777.23772.30; Geman D., 2004, STAT APPL GENET MOL, V3, P1, DOI [10.2202/1544-6115.1071, DOI 10.2202/1544-6115.1071]; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Gordon GJ, 2002, CANCER RES, V62, P4963; Gormley IC, 2006, J R STAT SOC A STAT, V169, P361, DOI 10.1111/j.1467-985X.2006.00412.x; Gormley IC, 2008, J AM STAT ASSOC, V103, P1014, DOI 10.1198/016214507000001049; Haussler D., 1999, CONVOLUTION KERNELS; Helmbold DP, 2009, J MACH LEARN RES, V10, P1705; Huang J, 2009, J MACH LEARN RES, V10, P997; Inokuchi A., 2003, INT C MACHINE LEARNI, P321; Jacques J, 2014, J STAT PLAN INFER, V149, P201, DOI 10.1016/j.jspi.2014.02.011; Kamishima T., 2003, P 9 ACM SIGKDD INT C, P583; Kemeny J. G., 1962, MATH MODELS SOCIAL S, V9; Kendall M. G., 1948, RANK CORRELATION MET; Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226; KNIGHT WR, 1966, J AM STAT ASSOC, V61, P436, DOI 10.2307/2282833; Kondor Imre Risi, 2008, THESIS; Kondor R.I., 2002, P 19 INT C MACHINE L, P315; Kondor Risi Imre, 2010, COLT, V23, P451; Lai P L, 2000, Int J Neural Syst, V10, P365, DOI 10.1016/S0129-0657(00)00034-X; Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294; Lebanon G, 2008, J MACH LEARN RES, V9, P2401; Li J, 2003, P 3 ACM SIGKDD WORKS, P17; Lin X, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-256; MALLOWS CL, 1957, BIOMETRIKA, V44, P114, DOI 10.2307/2333244; Mania H., 2016, ARXIV160308035; MARDEN J. I., 1996, ANAL MODELING RANK D; Meila M., 2007, P 23 C UNC ART INT U, P285; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Muandet K., 2012, PROC 25 INT C NEURAL, P10; Murphy TB, 2003, COMPUT STAT DATA AN, V41, P645, DOI 10.1016/S0167-9473(02)00165-2; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Schoenberg IJ, 1938, T AM MATH SOC, V44, P522, DOI 10.2307/1989894; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Scholkopf B., 2001, LEARNING KERNELS SUP; Schu┬lkopf B., 2004, KERNEL METHODS COMPU; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Shi P, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-375; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Smola A., 2007, HILBERT SPACE EMBEDD, P13; Smola AJ, 1999, ADV NEUR IN, V11, P585; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Steinwart I, 2005, IEEE T INFORM THEORY, V51, P128, DOI 10.1109/TIT.2004.839514; Tan AC, 2005, BIOINFORMATICS, V21, P3896, DOI 10.1093/bioinformatics/bti631; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V.N, 1998, STAT LEARNING THEORY; Vishwanathan S. V. N., 2009, J MACH LEARN RES, V10, P1; Wang JD, 2003, LECT NOTES ARTIF INT, V2842, P159; Wang YH, 2005, BIOINFORMATICS, V21, P1530, DOI 10.1093/bioinformatics/bti192; Xu L, 2005, BIOINFORMATICS, V21, P3905, DOI 10.1093/bioinformatics/bti647; Zhang R, 2002, INT C PATT RECOG, P289, DOI 10.1109/ICPR.2002.1047453	77	7	7	2	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1755	1769		10.1109/TPAMI.2017.2719680	http://dx.doi.org/10.1109/TPAMI.2017.2719680			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28981406	Bronze, Green Submitted			2022-12-18	WOS:000434294800016
J	Koch, LM; Rajchl, M; Bai, WJ; Baumgartner, CF; Tong, T; Passerat-Palmbach, J; Aljabar, P; Rueckert, D				Koch, Lisa Margret; Rajchl, Martin; Bai, Wenjia; Baumgartner, Christian Frederik; Tong, Tong; Passerat-Palmbach, Jonathan; Aljabar, Paul; Rueckert, Daniel			Multi-Atlas Segmentation Using Partially Annotated Data: Methods and Annotation Strategies	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-atlas segmentation; partial annotations; Markov Random Field; unifying framework; continuous max-flow; annotation strategies	BRAIN MRI SEGMENTATION; IMAGE SEGMENTATION; GRAPH CUTS; LABEL FUSION; REGISTRATION; MODEL; HIPPOCAMPUS; ALGORITHM; SELECTION	Multi-atlas segmentation is a widely used tool in medical image analysis, providing robust and accurate results by learning from annotated atlas datasets. However, the availability of fully annotated atlas images for training is limited due to the time required for the labelling task. Segmentation methods requiring only a proportion of each atlas image to be labelled could therefore reduce the workload on expert raters tasked with annotating atlas images. To address this issue, we first re-examine the labelling problem common in many existing approaches and formulate its solution in terms of a Markov Random Field energy minimisation problem on a graph connecting atlases and the target image. This provides a unifying framework for multi-atlas segmentation. We then show how modifications in the graph configuration of the proposed framework enable the use of partially annotated atlas images and investigate different partial annotation strategies. The proposed method was evaluated on two Magnetic Resonance Imaging (MRI) datasets for hippocampal and cardiac segmentation. Experiments were performed aimed at (1) recreating existing segmentation techniques with the proposed framework and (2) demonstrating the potential of employing sparsely annotated atlas data for multi-atlas segmentation.	[Koch, Lisa Margret; Rajchl, Martin; Bai, Wenjia; Baumgartner, Christian Frederik; Tong, Tong; Passerat-Palmbach, Jonathan; Rueckert, Daniel] Imperial Coll London, Biomed Image Anal Grp, London SW7 2AZ, England; [Aljabar, Paul] Kings Coll London, Div Imaging Sci & Biomed Engn, London WC2R 2LS, England	Imperial College London; University of London; King's College London	Koch, LM (corresponding author), Imperial Coll London, Biomed Image Anal Grp, London SW7 2AZ, England.	l.koch@imperial.ac.uk; m.rajchl@imperial.ac.uk; w.bai@imperial.ac.uk; c.baumgartner@imperial.ac.uk; t.tong11@imperial.ac.uk; j.passerat-palmbach@imperial.ac.uk; paul.aljabar@kcl.ac.uk; d.rueckert@imperial.ac.uk	Koch, Lisa M/AAY-3893-2021; Bai, Wenjia/ABH-6023-2020; Baumgartner, Christian F/Z-1239-2018; Baumgartner, Christian Frederik/AAZ-1891-2020; Passerat-Palmbach, Jonathan/AGG-9688-2022	Bai, Wenjia/0000-0003-2943-7698; Baumgartner, Christian F/0000-0002-3629-4384; Baumgartner, Christian Frederik/0000-0002-3629-4384; Passerat-Palmbach, Jonathan/0000-0003-3178-9502; Rueckert, Daniel/0000-0002-5683-5889	European Union Seventh Framework Programme (FP7) [601055]; Engineering and Physical Sciences Research Council [EP/I000445/1] Funding Source: researchfish; EPSRC [EP/I000445/1] Funding Source: UKRI	European Union Seventh Framework Programme (FP7); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors thank Dr. Declan P. O'Regan from MRC Clinical Sciences Centre, Hammersmith Hospital, Imperial College London, for providing the cardiac MR data and the Alzheimer's Disease Neuroimaging Initiative for providing the brain MR data used in this manuscript. The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007 2013) under grant agreement no. 601055, VPH-DARE@IT.	Aljabar P, 2009, NEUROIMAGE, V46, P726, DOI 10.1016/j.neuroimage.2009.02.018; Artaechevarria X, 2009, IEEE T MED IMAGING, V28, P1266, DOI 10.1109/TMI.2009.2014372; Bai WJ, 2013, IEEE T MED IMAGING, V32, P1302, DOI 10.1109/TMI.2013.2256922; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2000, LECT NOTES COMPUT SC, V1935, P276; Cardoso MJ, 2015, IEEE T MED IMAGING, V34, P1976, DOI 10.1109/TMI.2015.2418298; Chen LC, 2014, PROC CVPR IEEE, P3198, DOI 10.1109/CVPR.2014.409; Coupe P, 2011, NEUROIMAGE, V54, P940, DOI 10.1016/j.neuroimage.2010.09.018; Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012; Iglesias JE, 2015, NEUROIMAGE, V106, P451, DOI 10.1016/j.neuroimage.2014.11.031; Han DF, 2011, LECT NOTES COMPUT SC, V6801, P245, DOI 10.1007/978-3-642-22092-0_21; Heckemann RA, 2006, NEUROIMAGE, V33, P115, DOI 10.1016/j.neuroimage.2006.05.061; Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049; Klein Arno, 2005, BMC Med Imaging, V5, P7, DOI 10.1186/1471-2342-5-7; Koch Lisa M, 2015, Inf Process Med Imaging, V24, P221, DOI 10.1007/978-3-319-19992-4_17; Koch LM, 2014, LECT NOTES COMPUT SC, V8679, P9, DOI 10.1007/978-3-319-10581-9_2; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kuettel D, 2012, LECT NOTES COMPUT SC, V7578, P459, DOI 10.1007/978-3-642-33786-4_34; Landman BA, 2012, IEEE T MED IMAGING, V31, P512, DOI 10.1109/TMI.2011.2172215; Ledig C, 2015, MED IMAGE ANAL, V21, P40, DOI 10.1016/j.media.2014.12.003; Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368; Lotjonen JMP, 2010, NEUROIMAGE, V49, P2352, DOI 10.1016/j.neuroimage.2009.10.026; Makropoulos A, 2014, IEEE T MED IMAGING, V33, P1818, DOI 10.1109/TMI.2014.2322280; Nyul LG, 1999, MAGNET RESON MED, V42, P1072, DOI 10.1002/(SICI)1522-2594(199912)42:6<1072::AID-MRM11>3.0.CO;2-M; Qiu W, 2014, IEEE T MED IMAGING, V33, P947, DOI 10.1109/TMI.2014.2300694; Rajchl M, 2016, MED IMAGE ANAL, V27, P45, DOI 10.1016/j.media.2015.05.005; Rohlfing T, 2004, NEUROIMAGE, V21, P1428, DOI 10.1016/j.neuroimage.2003.11.010; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rousseau F, 2011, IEEE T MED IMAGING, V30, P1852, DOI 10.1109/TMI.2011.2156806; Rubinstein M, 2012, LECT NOTES COMPUT SC, V7574, P85, DOI 10.1007/978-3-642-33712-3_7; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Sabuncu MR, 2010, IEEE T MED IMAGING, V29, P1714, DOI 10.1109/TMI.2010.2050897; van der Lijn F, 2008, NEUROIMAGE, V43, P708, DOI 10.1016/j.neuroimage.2008.07.058; Wang HZ, 2013, IEEE T PATTERN ANAL, V35, P611, DOI 10.1109/TPAMI.2012.143; Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354; Wolz R, 2013, IEEE T MED IMAGING, V32, P1723, DOI 10.1109/TMI.2013.2265805; Wolz R, 2010, NEUROIMAGE, V49, P1316, DOI 10.1016/j.neuroimage.2009.09.069; Xu J, 2015, PROC CVPR IEEE, P3781, DOI 10.1109/CVPR.2015.7299002; Xu J, 2014, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2014.408; Yuan J, 2010, LECT NOTES COMPUT SC, V6316, P379, DOI 10.1007/978-3-642-15567-3_28; Yuan J, 2010, PROC CVPR IEEE, P2217, DOI 10.1109/CVPR.2010.5539903; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015	43	7	8	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1683	1696		10.1109/TPAMI.2017.2711020	http://dx.doi.org/10.1109/TPAMI.2017.2711020			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28841548	hybrid, Green Submitted			2022-12-18	WOS:000434294800011
J	Wang, TC; Chandraker, M; Efros, AA; Ramamoorthi, R				Wang, Ting-Chun; Chandraker, Manmohan; Efros, Alexei A.; Ramamoorthi, Ravi			SVBRDF-Invariant Shape and Reflectance Estimation from a Light-Field Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Light-fields; 3D reconstruction; BRDF	STEREO; STATISTICS	Light-field cameras have recently emerged as a powerful tool for one-shot passive 3D shape capture. However, obtaining the shape of glossy objects like metals or plastics remains challenging, since standard Lambertian cues like photo-consistency cannot be easily applied. In this paper, we derive a spatially-varying (SV)BRDF-invariant theory for recovering 3D shape and reflectance from light-field cameras. Our key theoretical insight is a novel analysis of diffuse plus single-lobe SVBRDFs under a light-field setup. We show that, although direct shape recovery is not possible, an equation relating depths and normals can still be derived. Using this equation, we then propose using a polynomial (quadratic) shape prior to resolve the shape ambiguity. Once shape is estimated, we also recover the reflectance. We present extensive synthetic data on the entire MERL BRDF dataset, as well as a number of real examples to validate the theory, where we simultaneously recover shape and BRDFs from a single image taken with a Lytro Ilium camera.	[Wang, Ting-Chun; Efros, Alexei A.] Univ Calif Berkeley, EECS Dept, Berkeley, CA 94720 USA; [Chandraker, Manmohan; Ramamoorthi, Ravi] Univ Calif San Diego, CSE Dept, La Jolla, CA 92093 USA	University of California System; University of California Berkeley; University of California System; University of California San Diego	Wang, TC (corresponding author), Univ Calif Berkeley, EECS Dept, Berkeley, CA 94720 USA.	tcwang0509@eecs.berkeley.edu; mkchandraker@cs.ucsd.edu; efros@eecs.berkeley.edu; ravir@cs.ucsd.edu	Chandraker, Manmohan/AAU-4762-2021; Wang, Ting-Chun/AAD-4410-2021; Wang, Ting-Chun/AAZ-2408-2020	Wang, Ting-Chun/0000-0002-1522-2381; Efros, Alexei A./0000-0001-5720-8070	Sony; Samsung; Nokia; Draper Lab; Google Research Award; US National Science Foundation [IIS-1617234]; ONR grant [N000141512013]	Sony; Samsung(Samsung); Nokia(Nokia Corporation); Draper Lab; Google Research Award(Google Incorporated); US National Science Foundation(National Science Foundation (NSF)); ONR grant	This work was funded in part by ONR grant N000141512013, US National Science Foundation grant IIS-1617234, a Google Research Award, Draper Lab, and support by Nokia, Samsung and Sony to the UC San Diego Center for Visual Computing.	Alldrin N., 2008, IEEE C COMP VIS PATT, P1; Barron JT, 2012, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2012.6247693; Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5; Bonfort T, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P591; Chandraker M, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481415; Chandraker M, 2014, PROC CVPR IEEE, P2179, DOI 10.1109/CVPR.2014.279; Chandraker M, 2014, LECT NOTES COMPUT SC, V8695, P202, DOI 10.1007/978-3-319-10584-0_14; Chandraker M, 2011, IEEE I CONF COMP VIS, P1076, DOI 10.1109/ICCV.2011.6126354; Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197; Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003; Ecker A, 2010, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2010.5540219; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867; Gallup D, 2010, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2010.5539804; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; Johnson M. K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2553, DOI 10.1109/CVPR.2011.5995510; Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926; Lawrence J, 2006, ACM T GRAPHIC, V25, P735, DOI 10.1145/1141911.1141949; Lucas B.D., 1981, IJCAI 81 P 7 INT JOI, P674, DOI DOI 10.1109/HPDC.2004.1323531; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; NGAN A, 2005, EUR S REND, V16, P117; Nishino K, 2011, J OPT SOC AM A, V28, P8, DOI 10.1364/JOSAA.28.000008; Oxholm G, 2012, LECT NOTES COMPUT SC, V7572, P528, DOI 10.1007/978-3-642-33718-5_38; Perwass C, 2012, PROC SPIE, V8291, DOI 10.1117/12.909882; ROMEIRO F, 2010, P ECCV, V6311, P45; Romeiro F, 2008, LECT NOTES COMPUT SC, V5305, P859, DOI 10.1007/978-3-540-88693-8_63; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; Tao MW, 2016, IEEE T PATTERN ANAL, V38, P1155, DOI 10.1109/TPAMI.2015.2477811; Tao MW, 2015, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2015.7298804; Tao MW, 2015, LECT NOTES COMPUT SC, V8926, P533, DOI 10.1007/978-3-319-16181-5_41; TOMINAGA S, 1991, IEEE T PATTERN ANAL, V13, P658, DOI 10.1109/34.85656; Treuille A, 2004, LECT NOTES COMPUT SC, V3022, P457; Wang TC, 2016, PROC CVPR IEEE, P5451, DOI 10.1109/CVPR.2016.588; Wang TC, 2016, IEEE T PATTERN ANAL, V38, P2170, DOI 10.1109/TPAMI.2016.2515615; Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398; Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu CC, 2012, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2012.6247839; Xiong Y, 2015, IEEE T PATTERN ANAL, V37, P67, DOI 10.1109/TPAMI.2014.2343211; Yang RG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P576, DOI 10.1109/ICCV.2003.1238399; Yu T., 2006, CVPR, P2269; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zickler TE, 2002, INT J COMPUT VISION, V49, P215, DOI 10.1023/A:1020149707513	45	7	7	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					740	754		10.1109/TPAMI.2017.2680442	http://dx.doi.org/10.1109/TPAMI.2017.2680442			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28320650	hybrid			2022-12-18	WOS:000424465900017
J	Hajimirsadeghi, H; Mori, G				Hajimirsadeghi, Hossein; Mori, Greg			Multi-Instance Classification by Max-Margin Training of Cardinality-Based Markov Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiple instance learning; Markov network; conditional random field; cardinality models		We propose a probabilistic graphical framework formulti-instance learning (MIL) based on Markov networks. This framework can deal with different levels of labeling ambiguity (i.e., the portion of positive instances in a bag) in weakly supervised data by parameterizing cardinality potential functions. Consequently, it can be used to encode different cardinality-basedmulti-instance assumptions, ranging from the standard MIL assumption to more general assumptions. In addition, this framework can be efficiently used for both binary and multiclass classification. To this end, an efficient inference algorithm and a discriminative latent max-margin learning algorithm are introduced to train and test the proposed multi-instance Markov network models. We evaluate the performance of the proposed framework on binary and multi-class MIL benchmark datasets as well as two challenging computer vision tasks: cyclist helmet recognition and human group activity recognition. Experimental results verify that encoding the degree of ambiguity in data can improve classification performance.	[Hajimirsadeghi, Hossein; Mori, Greg] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Simon Fraser University	Hajimirsadeghi, H (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	hosseinh@sfu.ca; mori@cs.sfu.ca						Adel T., 2013, P 29 C UNC ART INT, P1; Amer MR, 2012, LECT NOTES COMPUT SC, V7575, P187, DOI 10.1007/978-3-642-33765-9_14; Amores J, 2013, ARTIF INTELL, V201, P81, DOI 10.1016/j.artint.2013.06.003; Andrews S., 2002, NIPS, V2, P561; Bunescu R.C., 2007, P ICML, P105, DOI DOI 10.1145/1273496.1273510; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248; Chen YX, 2004, J MACH LEARN RES, V5, P913; Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16; Choi Wongun, 2009, 2009 IEEE 12 INT C C, P1282; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deselaers T., 2010, P 27 INT C MACH LEAR, P287; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Do T., 2009, P 26 ANN INT C MACH, P265; Dong L., 2006, COMP MULTIINSTANCE L; Duan LX, 2011, IEEE T IMAGE PROCESS, V20, P3280, DOI 10.1109/TIP.2011.2159227; Foulds J, 2010, KNOWL ENG REV, V25, P1, DOI 10.1017/S026988890999035X; Gartner T., 2002, ICML, P179; Gartner T., 2000, THESIS; Gehler P.V., 2007, P 11 INT C ART INT S, P123; Guillaumin M., 2010, ECCV, P634; Gupta R., 2007, P 24 INT C MACH LEAR, P329; Hajimirsadeghi H., 2013, UAI, P262; Hajimirsadeghi H, 2012, INT C PATT RECOG, P2706; Kwok JT, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P901; Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228; Leistner C, 2010, LECT NOTES COMPUT SC, V6316, P29, DOI 10.1007/978-3-642-15567-3_3; Li DX, 2014, J VIS COMMUN IMAGE R, V25, P1112, DOI 10.1016/j.jvcir.2014.03.011; Li F, 2010, P ADV NEUR INF PROC, V10, P1360; Li W, 2011, IEEE I CONF COMP VIS, P2049, DOI 10.1109/ICCV.2011.6126478; Li Y, 2013, PATTERN RECOGN, V46, P865, DOI 10.1016/j.patcog.2012.08.018; Louradour J., 2011, UNCERTAINTY ARTIFICI, P463; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Mangasarian OL, 2008, J OPTIMIZ THEORY APP, V137, P555, DOI 10.1007/s10957-007-9343-5; Maron O, 1998, ADV NEUR IN, V10, P570; Nie F., 2010, ADV NEURAL INFORM PR, V1, P1813, DOI DOI 10.1007/978-3-319-10690-8_12; Quadrianto N, 2009, J MACH LEARN RES, V10, P2349; Ruping S., 2010, P 27 INT C MACH LEAR, P911; Tarlow D., 2012, P 28 C UNC ART INT, P825; Do TMT, 2012, J MACH LEARN RES, V13, P3539; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Wang H., 2011, ARAB J CHEM, P1; Wang H., 2011, P 25 AAAI C ART INT, P507; Wang H, 2012, PROC CVPR IEEE, P2919, DOI 10.1109/CVPR.2012.6248019; Wang Jun, 2000, ICML, P1119; Warrell Jonathan, 2011, Energy Minimization Methods in Computer Vision and Pattern Recognition. Proceedings 8th International Conference, EMMCVPR 2011, P369, DOI 10.1007/978-3-642-23094-3_27; Yu Felix X., 2013, P 30 INT C MACH LEAR, P504; Zhang C, 2006, ADV NEURAL INFORM PR, P1417; Zhang Q, 2002, ADV NEUR IN, V14, P1073; Zhou Z.-H., 2007, P 24 INT C MACHINE L, P1167; Zhou Z.-H., 2009, ANN INT C MACH LEARN, P1249, DOI DOI 10.1145/1553374.1553534	51	7	7	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1839	1852		10.1109/TPAMI.2016.2613865	http://dx.doi.org/10.1109/TPAMI.2016.2613865			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	28114057				2022-12-18	WOS:000406840800011
J	Lin, WY; Zhou, Y; Xu, HT; Yan, JC; Xu, ML; Wu, JX; Liu, ZC				Lin, Weiyao; Zhou, Yang; Xu, Hongteng; Yan, Junchi; Xu, Mingliang; Wu, Jianxin; Liu, Zicheng			A Tube-and-Droplet-Based Approach for Representing and Analyzing Motion Trajectories	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Trajectory representation; trajectory analysis; 3D tube; abnormality detection; 3D action recognition	ACTION RECOGNITION; RETRIEVAL; PATTERNS; POSE	Trajectory analysis is essential in many applications. In this paper, we address the problem of representing motion trajectories in a highly informative way, and consequently utilize it for analyzing trajectories. Our approach first leverages the complete information from given trajectories to construct a thermal transfer field which provides a context-rich way to describe the global motion pattern in a scene. Then, a 3D tube is derived which depicts an input trajectory by integrating its surrounding motion patterns contained in the thermal transfer field. The 3D tube effectively: 1) maintains the movement information of a trajectory, 2) embeds the complete contextual motion pattern around a trajectory, 3) visualizes information about a trajectory in a clear and unified way. We further introduce a droplet-based process. It derives a droplet vector from a 3D tube, so as to characterize the high-dimensional 3D tube information in a simple but effective way. Finally, we apply our tube-and-droplet representation to trajectory analysis applications including trajectory clustering, trajectory classification & abnormality detection, and 3D action recognition. Experimental comparisons with state-of-the-art algorithms demonstrate the effectiveness of our approach.	[Lin, Weiyao; Zhou, Yang] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China; [Xu, Hongteng] Georgia Inst Technol, Dept Elect & Comp Engn, Atlanta, GA 30332 USA; [Yan, Junchi] IBM Res, Shanghai 200240, Peoples R China; [Xu, Mingliang] Zhengzhou Univ, Ctr Interdisciplinary Informat Sci Res, Zhengzhou 100044, Peoples R China; [Wu, Jianxin] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China; [Liu, Zicheng] Microsoft Res, Redmond, WA 98052 USA	Shanghai Jiao Tong University; University System of Georgia; Georgia Institute of Technology; Zhengzhou University; Nanjing University; Microsoft	Lin, WY (corresponding author), Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China.	wylin@sjtu.edu.cn; zhz128ly@sjtu.edu.cn; hxu42@gatech.edu; yanjc@cn.ibm.com; iexumingliang@zzu.edu.cn; wujx2001@nju.edu.cn; zilu@microsoft.com	Xu, Hongteng/AAB-1636-2021	Zhou, Yang/0000-0002-5070-6330; Lin, Weiyao/0000-0001-8307-7107; Yan, Junchi/0000-0001-9639-7679	Natural Science Foundation of China (NSFC) [61471235, 61472370, 61602176, 61672469]	Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This paper is supported in part by the Natural Science Foundation of China (NSFC) under Grant Nos. 61471235, 61472370, 61602176, and 61672469.	Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Berndt DJ, 1994, KDD WORKSH, V10, P359; Browne MW, 2000, J MATH PSYCHOL, V44, P108, DOI 10.1006/jmps.1999.1279; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Evangelidis GD, 2015, LECT NOTES COMPUT SC, V8925, P595, DOI 10.1007/978-3-319-16178-5_42; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760; Goh A, 2007, PROC CVPR IEEE, P2032; Gong D., 2012, P 29 INT C MACH LEAR, P321; Hu WM, 2013, IEEE T PATTERN ANAL, V35, P1051, DOI 10.1109/TPAMI.2012.188; Hu WM, 2004, IEEE T SYST MAN CY B, V34, P1618, DOI 10.1109/TSMCB.2004.826829; Jung YK, 2001, IEEE T INTELL TRANSP, V2, P151, DOI 10.1109/6979.954548; Kim K, 2011, IEEE I CONF COMP VIS, P1164, DOI 10.1109/ICCV.2011.6126365; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Lin WY, 2013, IEEE T CIRC SYST VID, V23, P1980, DOI 10.1109/TCSVT.2013.2269780; Little JJ, 2001, P SOC PHOTO-OPT INS, V4315, P545, DOI 10.1117/12.410966; Lui YM, 2012, IEEE T CIRC SYST VID, V22, P930, DOI 10.1109/TCSVT.2011.2181452; Morris B, 2009, PROC CVPR IEEE, P312, DOI 10.1109/CVPRW.2009.5206559; Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64; Muller M., 2007, INFORM RETRIEVAL MUS, V3, P69, DOI [10.1007/978-3-540- 74048-3_4, DOI 10.1007/978-3-540-74048-3]; Munson B.R., 1990, FUNDAMENTALS FLUID M; Naftel A., 2006, P IEEE INT C COMP VI, P47; Nascimento JC, 2010, IEEE T IMAGE PROCESS, V19, P1338, DOI 10.1109/TIP.2009.2039664; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Palpanas T, 2004, PROC INT CONF DATA, P338; Patankar SV., 1980, NUMERICAL HEAT TRANS; Pletcher R.H., 2012, HEAT TRANSF; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; Reddy J.N., 1993, INTRO FINITE ELEMENT; Sangineto E, 2013, IEEE T PATTERN ANAL, V35, P624, DOI 10.1109/TPAMI.2012.87; Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011; Tao LL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P303, DOI 10.1109/ICCVW.2015.48; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123; Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198; Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9; Wang XG, 2011, INT J COMPUT VISION, V95, P287, DOI 10.1007/s11263-011-0459-6; WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9; Xu HT, 2015, IEEE I CONF COMP VIS, P4328, DOI 10.1109/ICCV.2015.492; Yang X., 2012, COMP VIS PATT REC WO, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]; Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342	43	7	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1489	1503		10.1109/TPAMI.2016.2608884	http://dx.doi.org/10.1109/TPAMI.2016.2608884			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD		Green Submitted			2022-12-18	WOS:000404606300001
J	Yang, B; Pei, HB; Chen, HC; Liu, JM; Xia, S				Yang, Bo; Pei, Hongbin; Chen, Hechang; Liu, Jiming; Xia, Shang			Characterizing and Discovering Spatiotemporal Social Contact Patterns for Healthcare	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Healthcare; epidemic modeling; spatiotemporal social contact; tensor deconvolution; heterogeneous data mining	INFLUENZA; SPREAD; MODELS; METAPOPULATION; INFECTIONS	During an epidemic, the spatial, temporal and demographic patterns of disease transmission are determined by multiple factors. In addition to the physiological properties of the pathogens and hosts, the social contact of the host population, which characterizes the reciprocal exposures of individuals to infection according to their demographic structure and various social activities, are also pivotal to understanding and predicting the prevalence of infectious diseases. How social contact is measured will affect the extent to which we can forecast the dynamics of infections in the real world. Most current work focuses on modeling the spatial patterns of static social contact. In this work, we use a novel perspective to address the problem of how to characterize and measure dynamic social contact during an epidemic. We propose an epidemic-model-based tensor deconvolution framework in which the spatiotemporal patterns of social contact are represented by the factors of the tensors. These factors can be discovered using a tensor deconvolution procedure with the integration of epidemic models based on rich types of data, mainly heterogeneous outbreak surveillance data, socio-demographic census data and physiological data from medical reports. Using reproduction models that include SIR/SIS/SEIR/SEIS models as case studies, the efficacy and applications of the proposed framework are theoretically analyzed, empirically validated and demonstrated through a set of rigorous experiments using both synthetic and real-world data.	[Yang, Bo; Pei, Hongbin; Chen, Hechang] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China; [Yang, Bo; Pei, Hongbin; Chen, Hechang] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engineer, Changchun 130012, Jilin, Peoples R China; [Liu, Jiming] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; [Xia, Shang] Chinese CDC, Natl Inst Parasit Dis, Shanghai 200025, Peoples R China	Jilin University; Jilin University; Hong Kong Baptist University; Chinese Center for Disease Control & Prevention; National Institute of Parasitic Diseases, Chinese Center for Disease Control & Prevention	Yang, B (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Yang, B (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engineer, Changchun 130012, Jilin, Peoples R China.	ybo@jlu.edu.cn; peihb15@mails.jlu.edu.cn; chenhc14@mails.jlu.edu.cn; jiming@comp.hkbu.edu.hk; shangxia@outlook.com	Chen, Hechang/Y-7950-2018	Pei, Hongbin/0000-0002-7157-9959	National Natural Science Foundation of China [61572226, 61133011, 61373053, 61300146, 81273192]; Jilin Province Natural Science Foundation [20150101052JC]; Hong Kong Research Grants Council [RGC/HKBU211212, RGC/HKBU12202415]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Jilin Province Natural Science Foundation; Hong Kong Research Grants Council(Hong Kong Research Grants Council)	Jiming Liu is the corresponding author. The authors would like to thank the handling editor and the anonymous reviewers for their constructive comments. This work was funded by National Natural Science Foundation of China under grants 61572226, 61133011, 61373053, 61300146 and 81273192, Jilin Province Natural Science Foundation under grant 20150101052JC, and Hong Kong Research Grants Council under grant RGC/HKBU211212 and RGC/HKBU12202415. A preliminary version of this work was published in the Proceeding of 14th IEEE International Conference on Data Mining [1].	[Anonymous], 2010, SUMMARY REPORT SURVE; Baguelin M, 2010, VACCINE, V28, P2370, DOI 10.1016/j.vaccine.2010.01.002; Caley P, 2008, J R SOC INTERFACE, V5, P631, DOI 10.1098/rsif.2007.1197; Chen F, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0052814; Chowell G, 2008, EPIDEMIOL INFECT, V136, P852, DOI 10.1017/S0950268807009144; Dimitrov N. B., 2010, INFORMS TUTORIALS OP, V7, P1; Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110; Eubank S, 2004, NATURE, V429, P180, DOI 10.1038/nature02541; Eubank S, 2006, DIMACS SER DISCRET M, V70, P181; Fenichel EP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058249; Ferguson N, 2007, NATURE, V446, P733, DOI 10.1038/446733a; Fumanelli L, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002673; GARNETT GP, 1992, EPIDEMIOL INFECT, V108, P495, DOI 10.1017/S0950268800050007; Giraldo JO, 2008, EPIDEMIOL INFECT, V136, P679, DOI 10.1017/S0950268807009260; Hsieh YH, 2010, BMC INFECT DIS, V10, DOI 10.1186/1471-2334-10-106; Hui P, 2008, PHILOS T R SOC A, V366, P2005, DOI 10.1098/rsta.2008.0010; Iozzi F, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1001021; Keeling M., 2008, MODELING INFECT DIS; Kretzschmar M, 2010, STAT BIOL HEALTH, P209, DOI 10.1007/978-0-387-93835-6_12; Lau SKP, 2009, J CLIN MICROBIOL, V47, P2344, DOI 10.1128/JCM.00924-09; Lee S-I., 2006, P 21 NAT C ART INT, V6, P401; Liu JM, 2011, J MED SYST, V35, P1153, DOI 10.1007/s10916-011-9734-x; Melegaro A, 2011, EPIDEMICS-NETH, V3, P143, DOI 10.1016/j.epidem.2011.04.001; Meloni S, 2011, SCI REP-UK, V1, DOI 10.1038/srep00062; Molinari NAM, 2007, VACCINE, V25, P5086, DOI 10.1016/j.vaccine.2007.03.046; Mossong J, 2008, PLOS MED, V5, P381, DOI 10.1371/journal.pmed.0050074; PATTERSON KD, 1991, B HIST MED, V65, P4; Poletti Piero, 2011, PLoS One, V6, pe16460, DOI 10.1371/journal.pone.0016460; Porter AT, 2013, BIOMETRICS, V69, P101, DOI 10.1111/j.1541-0420.2012.01809.x; Potter GE, 2012, ANN APPL STAT, V6, P1, DOI 10.1214/11-AOAS505; Salathe M, 2010, P NATL ACAD SCI USA, V107, P22020, DOI 10.1073/pnas.1009094108; Stehle J, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023176; Wallinga J, 2010, P NATL ACAD SCI USA, V107, P923, DOI 10.1073/pnas.0908491107; Wang B, 2012, SCI REP-UK, V2, DOI 10.1038/srep00887; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Wu JT, 2010, CLIN INFECT DIS, V51, P1184, DOI 10.1086/656740; Wu JT, 2010, EMERG INFECT DIS, V16, P538, DOI 10.3201/eid1603.091216; Xia S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0065271; Yang B, 2014, IEEE DATA MINING, P630, DOI 10.1109/ICDM.2014.11	39	7	7	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1532	1546		10.1109/TPAMI.2016.2605095	http://dx.doi.org/10.1109/TPAMI.2016.2605095			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	27608452				2022-12-18	WOS:000404606300004
J	Iwata, T; Lloyd, JR; Ghahramani, Z				Iwata, Tomoharu; Lloyd, James Robert; Ghahramani, Zoubin			Unsupervised Many-to-Many Object Matching for Relational Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised object matching; Bayesian nonparametrics; relational data; stochastic block model; MCMC		We propose a method for unsupervised many-to-many object matching from multiple networks, which is the task of finding correspondences between groups of nodes in different networks. For example, the proposed method can discover shared word groups from multi-lingual document-word networks without cross-language alignment information. We assume that multiple networks share groups, and each group has its own interaction pattern with other groups. Using infinite relational models with this assumption, objects in different networks are clustered into common groups depending on their interaction patterns, discovering a matching. The effectiveness of the proposed method is experimentally demonstrated by using synthetic and real relational data sets, which include applications to cross-domain recommendation without shared user/item identifiers and multi-lingual word clustering.	[Iwata, Tomoharu] NTT Commun Sci Labs, Kyoto, Japan; [Lloyd, James Robert; Ghahramani, Zoubin] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	Nippon Telegraph & Telephone Corporation; University of Cambridge	Iwata, T (corresponding author), NTT Commun Sci Labs, Kyoto, Japan.; Lloyd, JR; Ghahramani, Z (corresponding author), Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.	tomoharu@lab.ntt.co.jp; jrl44@cam.ac.uk; zoubin@eng.cam.ac.uk			Engineering and Physical Sciences Research Council [1089321] Funding Source: researchfish	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Blundell C., 2010, UAI, P65; Boyd-Graber Jordan L., 2009, P 25 C UNC ART INT, P75; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Djuric N., 2012, AAAI, P893; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Gale W. A., 1991, P 29 ANN M ASS COMP, P177; Haghighi A, 2008, ACL 2008, P771; Hay M, 2008, PROC VLDB ENDOW, V1, P102, DOI 10.14778/1453856.1453873; Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Ishiguro K., 2010, ADV NEURAL INFORM PR, P919; Iwata T, 2013, P 27 AAAI C ART INT, P445; Iwata Tomoharu, 2010, P ACL 2010 C, P184; Kemp Charles, 2006, AAAI, DOI DOI 10.1145/1837026.1837061; Kirk P, 2012, BIOINFORMATICS, V28, P3290, DOI 10.1093/bioinformatics/bts595; Klami A, 2012, P AS C MACH LEARN, P205; Lang K., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P331; Leskovec J., 2010, P 19 INT C WORLD WID, P631; Li B., 2009, P 26 ANN INT C MACH, P617, DOI DOI 10.1145/1553374.1553454; Miller Kurt T., 2009, NONPARAMETRIC LATENT, P1276; Mimno D., 2009, P 2009 C EMP METH NA, V2, P880, DOI DOI 10.3115/1699571.1699627; Nowicki K, 2001, J AM STAT ASSOC, V96, P1077, DOI 10.1198/016214501753208735; Pan WK, 2010, AAAI CONF ARTIF INTE, P230; Quadrianto N, 2010, IEEE T PATTERN ANAL, V32, P1809, DOI 10.1109/TPAMI.2009.184; Rapp R, 1999, P 37 ANN M ASS COMP, P519, DOI DOI 10.3115/1034678.1034756; Rupnik J., 2010, P C DAT MIN DAT WAR; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Shafto P, 2011, COGNITION, V120, P1, DOI 10.1016/j.cognition.2011.02.010; Sheng Gao, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P161, DOI 10.1007/978-3-642-40991-2_11; Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112; Vu Thuy, 2009, P 12 C EUR CHAPT ASS, P843; Wang C, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1273; Yamada M, 2011, P 14 INT C ART INT S, P807; Zhang JW, 2011, NEUROCOMPUTING, V74, P1720, DOI 10.1016/j.neucom.2011.02.004; Zhang Y., 2010, PROC C UNCERTAINTY A, P725	38	7	7	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					607	617		10.1109/TPAMI.2015.2469284	http://dx.doi.org/10.1109/TPAMI.2015.2469284			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046500				2022-12-18	WOS:000370738900014
J	Luo, Y; Jiang, M; Wong, YK; Zhao, Q				Luo, Yan; Jiang, Ming; Wong, Yongkang; Zhao, Qi			Multi-Camera Saliency	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-camera saliency; global saliency; region competition; high-level feature saliency; label consistent K-SVD; multi-camera eye tracking data set	DISCRIMINATIVE DICTIONARY; VISUAL-ATTENTION; SCENE; MODEL; ALLOCATION; SEARCH	A significant body of literature on saliency modeling predicts where humans look in a single image or video. Besides the scientific goal of understanding how information is fused from multiple visual sources to identify regions of interest in a holistic manner, there are tremendous engineering applications of multi-camera saliency due to the widespread of cameras. This paper proposes a principled framework to smoothly integrate visual information from multiple views to a global scene map, and to employ a saliency algorithm incorporating high-level features to identify the most important regions by fusing visual information. The proposed method has the following key distinguishing features compared with its counterparts: (1) the proposed saliency detection is global (salient regions from one local view may not be important in a global context), (2) it does not require special ways for camera deployment or overlapping field of view, and (3) the key saliency algorithm is effective in highlighting interesting object regions though not a single detector is used. Experiments on several data sets confirm the effectiveness of the proposed principled framework.	[Luo, Yan; Jiang, Ming; Zhao, Qi] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore; [Wong, Yongkang] Natl Univ Singapore, Interact & Digital Media Inst, Singapore 119613, Singapore	National University of Singapore; National University of Singapore	Luo, Y (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore.	luoyan@nus.edu.sg; mjiang@nus.edu.sg; yongkang.wong@nus.edu.sg; eleqiz@nus.edu.sg	Luo, Yan/Y-1320-2019; Jiang, Ming/I-1536-2016	Luo, Yan/0000-0001-5135-0316; Jiang, Ming/0000-0001-6439-5476	Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative; Defense Innovative Research Programme [9014100596]	Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative; Defense Innovative Research Programme	The research was supported by the Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the Interactive Digital Media Programme Office, and the Defense Innovative Research Programme (No. 9014100596). Q. Zhao is the corresponding author.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2004, ELECT LETT COMPUT VI, DOI DOI 10.5565/REV/ELCVIA.66; Avraham T, 2010, IEEE T PATTERN ANAL, V32, P693, DOI 10.1109/TPAMI.2009.53; Bialkowski A., 2012, DICTA; Borji A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.85; Borji A, 2011, MACH VISION APPL, V22, P61, DOI 10.1007/s00138-009-0192-0; Bruce N. D. B., 2005, ADV NEURAL INF PROCE, P155; Bruce NDB, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P88, DOI 10.1109/CRV.2005.13; Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5; Butko Nicholas J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2751, DOI 10.1109/CVPRW.2009.5206540; Cerf M, 2009, J VISION, V9, DOI 10.1167/9.12.10; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Einhauser W, 2008, J VISION, V8, DOI 10.1167/8.2.2; Ekmekcioglu E., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P71, DOI 10.1109/PV.2012.6229756; Elazary L, 2010, VISION RES, V50, P1338, DOI 10.1016/j.visres.2010.01.002; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Frintrop S, 2005, COMPUT VIS IMAGE UND, V100, P124, DOI 10.1016/j.cviu.2004.08.005; Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hartley R., 2004, ROBOTICA; Horaud R, 2006, MACH VISION APPL, V16, P331, DOI 10.1007/s00138-005-0182-9; Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267; Hou X., 2008, NIPS, P681; Hou X., 2009, ADV NEURAL INFORM PR, P681; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L., 2004, SPIE, V64, P64; Jeong S, 2008, NEURAL NETWORKS, V21, P1420, DOI 10.1016/j.neunet.2008.10.002; Jeremy MWolfe, 2007, INTEGRATED MODELS CO, P1, DOI [DOI 10.1093/ACPROF:OSO/9780195189193.003.0008, 10.1093/acprof:oso/9780195189193.003.0008]; Jiang F., 2011, IEEE T COMPUT, P1; Jiang M, 2014, LECT NOTES COMPUT SC, V8695, P17, DOI 10.1007/978-3-319-10584-0_2; Jiang M, 2013, IEEE SYS MAN CYBERN, P2126, DOI 10.1109/SMC.2013.364; Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354; Judd T, 2011, J VISION, V11, DOI 10.1167/11.4.14; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Koch C., 1987, MATTERINTELLIGENCE, P115, DOI [10.1007/978-94-009-3833-5, DOI 10.1007/978-94-009-3833-5, DOI 10.1007/978-94-009-3833-5_5]; Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8; Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86; Lee H., 2007, NIPS, V20, P873; Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6; Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Luo Y, 2011, IEEE T CIRC SYST VID, V21, P1822, DOI 10.1109/TCSVT.2011.2147230; Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112; Maki A, 2000, COMPUT VIS IMAGE UND, V78, P351, DOI 10.1006/cviu.2000.0840; Ngau CWH, 2011, INT PROC COMPUT SCI, V5, P93; Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708; Nuthmann A, 2010, J VISION, V10, DOI 10.1167/10.8.20; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pang D, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1073, DOI 10.1109/ICME.2008.4607624; Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4; Peters R.J., 2007, 2007 IEEE C COMP VIS; Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019; Ramenahalli S., 2013, 2013 47 ANN C INF SC, P1; Rashid U., 2012, P INT S PERV DISPL; Renninger LW, 2004, P ADV NEUR INF PROC, P1121; Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758; Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4; Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017; Thirde D, 2006, P 9 IEEE INT WORKSH, P47; Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53; Torralba A, 2003, J OPT SOC AM A, V20, P1407, DOI 10.1364/JOSAA.20.001407; Torralba A., 2001, P ADV NEUR INF PROC, P1303; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Urban F, 2011, COGN COMPUT, V3, P37, DOI 10.1007/s12559-010-9086-8; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411; Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28; Yu SQ, 2006, INT C PATT RECOG, P441; Yuan JS, 2012, IEEE T IMAGE PROCESS, V21, P2207, DOI 10.1109/TIP.2011.2181952; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhang Y, 2010, LECT NOTES COMPUT SC, V5916, P314, DOI 10.1007/978-3-642-11301-7_33; Zhao Q, 2012, J VISION, V12, DOI 10.1167/12.6.22; Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9	75	7	7	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					2057	2070		10.1109/TPAMI.2015.2392783	http://dx.doi.org/10.1109/TPAMI.2015.2392783			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26340257				2022-12-18	WOS:000360813400009
J	Fix, A; Gruber, A; Boros, E; Zabih, R				Fix, Alexander; Gruber, Aritanan; Boros, Endre; Zabih, Ramin			A Hypergraph-Based Reduction for Higher-Order Binary Markov Random Fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph cuts; higher order priors; Markov random fields; computer vision	ENERGY MINIMIZATION; ROOF DUALITY; GRAPH CUTS; INFERENCE	Higher-order Markov Random Fields, which can capture important properties of natural images, have become increasingly important in computer vision. While graph cuts work well for first-order MRF's, until recently they have rarely been effective for higher-order MRF's. Ishikawa's graph cut technique [1], [2] shows great promise for many higher-order MRF's. His method transforms an arbitrary higher-order MRF with binary labels into a first-order one with the same minima. If all the terms are submodular the exact solution can be easily found; otherwise, pseudoboolean optimization techniques can produce an optimal labeling for a subset of the variables. We present a new transformation with better performance than [1], [2], both theoretically and experimentally. While [1], [2] transforms each higher-order term independently, we use the underlying hypergraph structure of the MRF to transform a group of terms at once. For n binary variables, each of which appears in terms with k other variables, at worst we produce n non-submodular terms, while [1], [2] produces O(nk). We identify a local completeness property under which our method perform even better, and show that under certain assumptions several important vision problems (including common variants of fusion moves) have this property. We show experimentally that our method produces smaller weight of non-submodular edges, and that this metric is directly related to the effectiveness of QPBO [3]. Running on the same field of experts dataset used in [1], [2] we optimally label significantly more variables (96 versus 80 percent) and converge more rapidly to a lower energy. Preliminary experiments suggest that some other higher-order MRF's used in stereo [4] and segmentation [5] are also locally complete and would thus benefit from our work.	[Fix, Alexander; Zabih, Ramin] Cornell Univ, Dept Comp Sci, New York, NY 10011 USA; [Gruber, Aritanan; Boros, Endre] Rutgers Ctr Operat Res, Piscataway, NJ 08854 USA	Cornell University; Rutgers State University New Brunswick	Fix, A (corresponding author), Cornell Univ, Dept Comp Sci, New York, NY 10011 USA.	afix@cs.cornell.edu; Aritanan.Gruber@gmail.com; Endre.Boros@rutgers.edu; rdz@cs.cornell.edu	Gruber, Aritanan/AAG-1212-2020; Boros, Endre/I-3066-2013	Gruber, Aritanan/0000-0001-7426-4226; Boros, Endre/0000-0001-8206-3168; Zabih, Ramin/0000-0001-8769-5666	NSF [IIS-0803705, IIS-1161476/1161860]; joint CAPES (Brazil)/Fulbright (USA) fellowship [BEX2387050/15061676]; Direct For Computer & Info Scie & Enginr [1161476] Funding Source: National Science Foundation	NSF(National Science Foundation (NSF)); joint CAPES (Brazil)/Fulbright (USA) fellowship; Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was supported by NSF grants IIS-0803705 and IIS-1161476/1161860, and by a joint CAPES (Brazil)/Fulbright (USA) fellowship to the second author under BEX2387050/15061676. We thank Joyce Chen and Josh Schwartz for helpful comments. A preliminary version of this work appeared in [6].	Andres B, 2010, LECT NOTES COMPUT SC, V6376, P353; [Anonymous], 1968, BOOLEAN METHODS OPER; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Fix A, 2011, IEEE I CONF COMP VIS, P1020, DOI 10.1109/ICCV.2011.6126347; Freedman D, 2005, PROC CVPR IEEE, P939; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; Ishikawa Hiroshi, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2993, DOI 10.1109/CVPRW.2009.5206689; Ishikawa H, 2011, IEEE T PATTERN ANAL, V33, P1234, DOI 10.1109/TPAMI.2010.91; IVANESCU PL, 1965, OPER RES, V13, P388, DOI 10.1287/opre.13.3.388; Kahl F, 2012, DISCRETE APPL MATH, V160, P2419, DOI 10.1016/j.dam.2012.06.009; Kahl F, 2011, IEEE I CONF COMP VIS, P255, DOI 10.1109/ICCV.2011.6126250; Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175; Kohli P, 2009, IEEE T PATTERN ANAL, V31, P1645, DOI 10.1109/TPAMI.2008.217; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Komodakis Nikos, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2985, DOI 10.1109/CVPRW.2009.5206846; Lan XY, 2006, LECT NOTES COMPUT SC, V3952, P269; Lempitsky V, 2010, IEEE T PATTERN ANAL, V32, P1392, DOI 10.1109/TPAMI.2009.143; Rosenberg I. G., 1975, Cahiers du Centre d'Etudes de Recherche Operationelle, V17, P71; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Rother C, 2009, PROC CVPR IEEE, P1382, DOI 10.1109/CVPRW.2009.5206739; Schlesinger D, 2007, LECT NOTES COMPUT SC, V4679, P28; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Wang CH, 2013, COMPUT VIS IMAGE UND, V117, P1610, DOI 10.1016/j.cviu.2013.07.004; Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131; Zivny S, 2009, LECT NOTES COMPUT SC, V5734, P744	27	7	7	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2015	37	7					1387	1395		10.1109/TPAMI.2014.2382109	http://dx.doi.org/10.1109/TPAMI.2014.2382109			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CK0YG	26352447				2022-12-18	WOS:000355931100007
J	Prusa, D; Werner, T				Prusa, Daniel; Werner, Tomas			Universality of the Local Marginal Polytope	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graphical model; Markov random field; discrete energy minimization; valued constraint satisfaction; linear programming relaxation; local marginal polytope		We show that solving the LP relaxation of the min-sum labeling problem (also known as MAP inference problem in graphical models, discrete energy minimization, or valued constraint satisfaction) is not easier than solving any linear program. Precisely, every polytope is linear-time representable by a local marginal polytope and every LP can be reduced in linear time to a linear optimization (allowing infinite costs) over a local marginal polytope. The reduction can be done (though with a higher time complexity) even if the local marginal polytope is restricted to have a planar structure.	[Prusa, Daniel; Werner, Tomas] Czech Tech Univ, Dept Cybernet, Prague 12135, Czech Republic	Czech Technical University Prague	Prusa, D (corresponding author), Czech Tech Univ, Dept Cybernet, Karlovo Namesti 13, Prague 12135, Czech Republic.	prusapa1@cmp.felk.cvut.cz; werner@cmp.felk.cvut.cz	Prusa, Daniel/G-8551-2014		Czech Science Foundation [P202/12/2071]; European Commission [FP7-ICT-270138]	Czech Science Foundation(Grant Agency of the Czech Republic); European Commission(European CommissionEuropean Commission Joint Research Centre)	The authors were supported by the Czech Science Foundation grant P202/12/2071. Besides, Tomas Werner was supported by the European Commission grant FP7-ICT-270138.	BESSIERE C, 2006, HDB CONSTRAINT PROGR, pCH3; Billera LJ, 1996, COMBINATORICA, V16, P175, DOI 10.1007/BF01844844; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Chekuri C, 2001, SIAM PROC S, P109; Cooper MC, 2010, ARTIF INTELL, V174, P449, DOI 10.1016/j.artint.2010.02.001; De Loera JA, 2006, SIAM J OPTIMIZ, V17, P806, DOI 10.1137/040610623; Globerson Amir, 2008, ADV NEURAL INFORM PR, P553; Johnson J., 2007, P ALL C COMM CONTR C; Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175; KARMARKAR N, 1984, COMBINATORICA, V4, P373, DOI 10.1007/BF02579150; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Komodakis N, 2011, IEEE T PATTERN ANAL, V33, P531, DOI 10.1109/TPAMI.2010.108; Koster AMCA, 1998, OPER RES LETT, V23, P89, DOI 10.1016/S0167-6377(98)00043-1; KOVAL VK, 1976, USSR ACAD SCI AUTOMA, V8, P149; Papadimitriou CH., 1993, COMPUT COMPLEX; PARDALOS PM, 1992, MATH PROGRAM, V57, P337, DOI 10.1007/BF01581088; Rother C., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383203; Shlezinger M. I., 1976, Cybernetics, V12, P612, DOI 10.1007/BF01070399; Sontag D, 2012, OPTIMIZATION FOR MACHINE LEARNING, P219; Thapper J, 2012, ANN IEEE SYMP FOUND, P669, DOI 10.1109/FOCS.2012.25; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036; Zivn Stanislav, 2012, COMPLEXITY VALUED CO	23	7	7	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					898	904		10.1109/TPAMI.2014.2353626	http://dx.doi.org/10.1109/TPAMI.2014.2353626			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353302	Green Published			2022-12-18	WOS:000351213400015
J	Palla, K; Knowles, DA; Ghahramani, Z				Palla, Konstantina; Knowles, David A.; Ghahramani, Zoubin			Relational Learning and Network Modelling Using Infinite Latent Attribute Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; unsupervised learning; network models	PROTEIN	Latent variable models for network data extract a summary of the relational structure underlying an observed network. The simplest possible models subdivide nodes of the network into clusters; the probability of a link between any two nodes then depends only on their cluster assignment. Currently available models can be classified by whether clusters are disjoint or are allowed to overlap. These models can explain a "flat" clustering structure. Hierarchical Bayesian models provide a natural approach to capture more complex dependencies. We propose a model in which objects are characterised by a latent feature vector. Each feature is itself partitioned into disjoint groups (subclusters), corresponding to a second layer of hierarchy. In experimental comparisons, the model achieves significantly improved predictive performance on social and biological link prediction tasks. The results indicate that models with a single layer hierarchy over-simplify real networks.	[Palla, Konstantina; Ghahramani, Zoubin] Univ Cambridge, Cambridge, England; [Knowles, David A.] Stanford Univ, Stanford, CA 94305 USA	University of Cambridge; Stanford University	Palla, K (corresponding author), Univ Cambridge, Cambridge, England.	konstantina.palla@gmail.com; knowles84@gmail.com; zoubin@eng.cam.ac.uk		Knowles, David/0000-0002-7408-146X	Engineering and Physical Sciences Research Council (EPSRC) [EP/I036575/1, EP/H019472/1]; Microsoft Research Roger Needham Scholarship of Wolfson College, Cambridge; Engineering and Physical Sciences Research Council [EP/I036575/1, EP/H019472/1] Funding Source: researchfish; EPSRC [EP/H019472/1, EP/I036575/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council (EPSRC)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Microsoft Research Roger Needham Scholarship of Wolfson College, Cambridge; Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors would like to thank Peter Orbanz for helpful discussion and suggestions for improving the manuscript. This work was supported by the Engineering and Physical Sciences Research Council (EPSRC) under Grant Numbers EP/I036575/1 and EP/H019472/1, and the Microsoft Research Roger Needham Scholarship of Wolfson College, Cambridge.	Airoldi E. M., 2009, ADV NEURAL INFORM PR, P33; [Anonymous], 1992, BAYESIAN STAT; Gelman A, 1992, STAT SCI, V7, P136, DOI 10.1214/ss/1177011136; Geweke J, 2004, J AM STAT ASSOC, V99, P799, DOI 10.1198/016214504000001132; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Globerson A, 2007, J MACH LEARN RES, V8, P2265; Griffiths T.L., 2005, ADV NEURAL INFORM PR; Hoff PD, 2002, J AM STAT ASSOC, V97, P1090, DOI 10.1198/016214502388618906; Jonikas MC, 2009, SCIENCE, V323, P1693, DOI 10.1126/science.1167983; Kemp Charles, 2006, AAAI, DOI DOI 10.1145/1837026.1837061; Kim M., 2011, UAI, P400; Meeds E., 2006, P ADV NEUR INF PROC, P475; Miller Kurt T., 2009, NONPARAMETRIC LATENT, P1276; Morup M., 2011, P IEEE INT WORKSH MA, P1; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Neal RM, 2003, ANN STAT, V31, P705, DOI 10.1214/aos/1056562461; Nowicki K, 2001, J AM STAT ASSOC, V96, P1077, DOI 10.1198/016214501753208735; Palla K., 2012, P 29 INT C MACH LEAR, P572; Pitman J., 2002, 621 U CAL BERK; Roy D. M., 2007, P ADV NEUR INF PROC, P1185; RUBEN SM, 1992, GENE DEV, V6, P745, DOI 10.1101/gad.6.5.745; XU Z., 2006, P 22 C ANN C UNC ART, P544	22	7	8	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					462	474		10.1109/TPAMI.2014.2324586	http://dx.doi.org/10.1109/TPAMI.2014.2324586			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353254				2022-12-18	WOS:000349625500019
J	Akbas, E; Ahuja, N				Akbas, Emre; Ahuja, Narendra			Low-Level Hierarchical Multiscale Segmentation Statistics of Natural Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Natural image statistics; low-level hierarchical segmentation; Markov random field	RECOGNITION	This paper is aimed at obtaining the statistics as a probabilistic model pertaining to the geometric, topological and photometric structure of natural images. The image structure is represented by its segmentation graph derived from the low-level hierarchical multiscale image segmentation. We first estimate the statistics of a number of segmentation graph properties from a large number of images. Our estimates confirm some findings reported in the past work, as well as provide some new ones. We then obtain a Markov random field based model of the segmentation graph which subsumes the observed statistics. To demonstrate the value of the model and the statistics, we show how its use as a prior impacts three applications: image classification, semantic image segmentation and object detection.	[Akbas, Emre] Univ Calif Santa Barbara, Dept Psychol & Brain Sci, Santa Barbara, CA 93106 USA; [Ahuja, Narendra] Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA	University of California System; University of California Santa Barbara; University of Illinois System; University of Illinois Urbana-Champaign	Akbas, E (corresponding author), Univ Calif Santa Barbara, Dept Psychol & Brain Sci, Santa Barbara, CA 93106 USA.		Akbas, Emre/B-6857-2008	Akbas, Emre/0000-0002-3760-6722	Office of Naval Research [N00014-12-1-0259]; National Science Foundation [IIS 11-44227]; Motorola Solutions (Motorola Communications Center) [239, 37]	Office of Naval Research(Office of Naval Research); National Science Foundation(National Science Foundation (NSF)); Motorola Solutions (Motorola Communications Center)	The support of the Office of Naval Research (N00014-12-1-0259), National Science Foundation (IIS 11-44227) and Motorola Solutions (Motorola Communications Center grant 239, RPS #37) are gratefully acknowledged.	Ahuja N, 1996, IEEE T PATTERN ANAL, V18, P1211, DOI 10.1109/34.546258; Ahuja N., 2008, P IEEE C COMP VIS PA; Akbas E., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3623, DOI 10.1109/ICPR.2010.884; Akbas Emre, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P123; Alvarez L, 1999, LECT NOTES COMPUT SC, V1682, P247; Appia V. V., 2011, P SPIE, V7871; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cho T.S., 2010, P IEEE C COMP VIS PA; Coppola DM, 1998, P NATL ACAD SCI USA, V95, P4002, DOI 10.1073/pnas.95.7.4002; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Everingham M., 2007, PASCAL VISUAL OBJECT, DOI DOI 10.1007/S11263-014-0733-5; Ghanem B, 2008, IEEE IMAGE PROC, P393, DOI 10.1109/ICIP.2008.4711774; Ghosh S, 2012, PROC CVPR IEEE, P2272, DOI 10.1109/CVPR.2012.6247937; Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257; Hees N., 2009, P BRIT MACH VIS C BM; Huang J., 1999, P IEEE C COMP VIS PA; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P1; Jaakkola T.S., 1999, P NEUR INF PROC SYST; Li S, 2009, MARKOV RANDOM FIELD; Martin D., 2001, P ICCV, P416, DOI DOI 10.1109/ICCV.2001.937655; Moghaddam B, 2007, IEEE I CONF COMP VIS, P2073, DOI 10.1109/cvpr.2007.383092; Munoz D, 2010, LECT NOTES COMPUT SC, V6316, P57, DOI 10.1007/978-3-642-15567-3_5; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Perronnin F, 2007, PROC CVPR IEEE, P2272; Ren XF, 2002, LECT NOTES COMPUT SC, V2350, P312; Roth S, 2005, PROC CVPR IEEE, P860; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; Todorovic S, 2008, IEEE T PATTERN ANAL, V30, P2158, DOI 10.1109/TPAMI.2008.24; Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Tseng PH, 2009, J VISION, V9, DOI 10.1167/9.7.4; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Wang L, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P539; Yang JJ, 2009, IEEE I CONF COMP VIS, P436, DOI 10.1109/ICCV.2009.5459172; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476	43	7	7	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1900	1906		10.1109/TPAMI.2014.2299809	http://dx.doi.org/10.1109/TPAMI.2014.2299809			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352241				2022-12-18	WOS:000340210100016
J	Raviv, D; Kimmel, R; Bruckstein, AM				Raviv, Dan; Kimmel, Ron; Bruckstein, Alfred M.			Graph Isomorphisms and Automorphisms via Spectral Signatures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph isomorphism; graph symmetries; graph automorphisms; graph Laplacian; heat kernel maps; heat kernel signatures	HEAT KERNEL; ALGORITHM; SYMMETRIES; TIME	An isomorphism between two graphs is a connectivity preserving bijective mapping between their sets of vertices. Finding isomorphisms between graphs, or between a graph and itself (automorphisms), is of great importance in applied sciences. The inherent computational complexity of this problem is as yet unknown. Here, we introduce an efficient method to compute such mappings using heat kernels associated with the graph Laplacian. While the problem is combinatorial in nature, in practice we experience polynomial runtime in the number of vertices. As we demonstrate, the proposed method can handle a variety of graphs and is competitive with state-of-the-art packages on various important examples.	[Raviv, Dan; Kimmel, Ron; Bruckstein, Alfred M.] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Raviv, D (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, Taub Bldg, IL-32000 Haifa, Israel.	darav@cs.technion.ac.il; ron@cs.technion.ac.il; freddy@cs.technion.ac.il	Raviv, Dan/AAZ-2851-2020	Bruckstein, Alfred/0000-0001-5669-0037	Israel Science Foundation [1551/09, 1031/12]; Initial Training Network of the European Commission [PITN-GA-2009-238702]	Israel Science Foundation(Israel Science Foundation); Initial Training Network of the European Commission	This research was partially supported by the Israel Science Foundation grant nos. 1551/09 and 1031/12 and by the Initial Training Network of the European Commission PITN-GA-2009-238702.	Babai L., 1982, P 14 ANN ACM S THEOR, P310; Babai L, 2008, ANN IEEE SYMP FOUND, P667, DOI 10.1109/FOCS.2008.80; BERARD P, 1994, GEOM FUNCT ANAL, V4, P373, DOI 10.1007/BF01896401; Chung F.R, 1997, SPECTRAL GRAPH THEOR; Cordella L.P., 1999, P INT C IM AN PROC; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; Darga PT, 2008, DES AUT CON, P149; Gori M, 2005, IEEE T PATTERN ANAL, V27, P1100, DOI 10.1109/TPAMI.2005.138; Hopcroft J.E, 1974, STOC, P172, DOI [10.1145/800119.803896, DOI 10.1145/800119.803896]; Jiang X., 2011, P CAN C COMP GEOM; Junttila T., 2007, P WORKSH ALG ENG WOR; LUEKER GS, 1979, J ACM, V26, P183, DOI 10.1145/322123.322125; Lukas E.M., 1982, J COMPUTER SYSTEM SC, V25, P42; McKay B., 1981, P 10 MAN C NUM MATH, P45; Murrell J., 1988, CHEM BOND; Ovsjanikov M, 2010, COMPUT GRAPH FORUM, V29, P1555, DOI 10.1111/j.1467-8659.2010.01764.x; Raviv D, 2010, INT J COMPUT VISION, V89, P18, DOI 10.1007/s11263-010-0320-3; Rustamov Raif M, 2007, P 5 EUR S GEOM PROC, P225, DOI DOI 10.2312/SGP/SGP07/225-233; Sharma A., 2012, IMAGE PROCESSING ANA, P441; Sun Jian, 2009, P S GEOM PROC; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Xiao B, 2009, PATTERN RECOGN, V42, P2589, DOI 10.1016/j.patcog.2008.12.029; You M., 1984, P ICPR, P316; [No title captured]	25	7	8	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1985	1993		10.1109/TPAMI.2012.260	http://dx.doi.org/10.1109/TPAMI.2012.260			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23787348	Green Submitted			2022-12-18	WOS:000320381400013
J	Ranjbar, M; Lan, T; Wang, Y; Robinovitch, SN; Li, ZN; Mori, G				Ranjbar, Mani; Lan, Tian; Wang, Yang; Robinovitch, Steven N.; Li, Ze-Nian; Mori, Greg			Optimizing Nondecomposable Loss Functions in Structured Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimization; large-margin; structural SVM	ENERGY MINIMIZATION	We develop an algorithm for structured prediction with nondecomposable performance measures. The algorithm learns parameters of Markov Random Fields (MRFs) and can be applied to multivariate performance measures. Examples include performance measures such as F-beta score (natural language processing), intersection over union (object category segmentation), Precision/Recall at k (search engines), and ROC area (binary classifiers). We attack this optimization problem by approximating the loss function with a piecewise linear function. The loss augmented inference forms a Quadratic Program (QP), which we solve using LP relaxation. We apply this approach to two tasks: object class-specific segmentation and human action retrieval from videos. We show significant improvement over baseline approaches that either use simple loss functions or simple scoring functions on the PASCAL VOC and H3D Segmentation datasets, and a nursing home action recognition dataset.	[Ranjbar, Mani; Lan, Tian; Li, Ze-Nian; Mori, Greg] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; [Wang, Yang] Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada; [Robinovitch, Steven N.] Simon Fraser Univ, Sch Engn Sci, Burnaby, BC V5A 1S6, Canada	Simon Fraser University; University of Manitoba; Simon Fraser University	Ranjbar, M (corresponding author), Simon Fraser Univ, Sch Comp Sci, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.	mra33@sfu.ca; tla58@sfu.ca; ywang@cs.umanitoba.ca; stever@sfu.ca; li@cs.sfu.ca; mori@cs.sfu.ca		Robinovitch, Stephen/0000-0003-3881-6227	Natural Sciences and Engineering Research Council of Canada (NSERC); Canadian Institutes of Health Research (CIHR) [AMG-100487, TIR-103945]	Natural Sciences and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC)); Canadian Institutes of Health Research (CIHR)(Canadian Institutes of Health Research (CIHR))	This work was supported by grants from the Natural Sciences and Engineering Research Council of Canada (NSERC) and Canadian Institutes of Health Research (CIHR, grant numbers AMG-100487 and TIR-103945).	Blaschko M., 2008, P 10 EUR C COMP VIS; Bourdev L., 2009, P 12 IEEE INT C COMP; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Chakrabarti S., 2008, P 14 ACM SIGKDD INT; Dalal N., 2005, IEEE C COMP VIS PATT; Demsar J, 2006, J MACH LEARN RES, V7, P1; Desai C., 2009, P 12 IEEE INT C COMP; Do T., 2009, P 26 INT C MACH LEAR; Everingham M, 2009, PASCAL VISUAL OBJECT; Everingham M., 2010, PASCAL VISUAL OBJECT; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Finley T., 2008, P 25 INT C MACH LEAR; Garland Michael, 1997, P ACM SIGGRAPH; Hoiem D., 2008, P IEEE C COMP VIS PA; JOACHIMS T, 2005, P 22 INT C MACH LEAR; Komodakis N, 2011, IEEE T PATTERN ANAL, V33, P531, DOI 10.1109/TPAMI.2010.108; Lan T., 2010, P INT WORKSH SIGN GE; LEIBE B., 2004, P ECCV WORKSH STAT L; Loy C.C., 2009, P 12 IEEE INT C COMP; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; McAllester D., 2010, P NEUR INF PROC SYST; Meshi O., 2010, P INT C MACH LEARN; Ranjbar M., 2010, P 11 EUR C COMP VIS; Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Taskar B., 2005, P NEUR INF PROC SYST; Taskar B., 2003, P NEUR INF PROC SYST; Taskar B., 2005, P 22 INT C MACH LEAR; Teo C.H., 2007, P 13 ACM SIGKDD INT; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Tsochantaridis I., 2004, P 21 INT C MACH LEAR; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036; Yue Y., 2007, P 30 ANN INT ACM SIG; [No title captured]	38	7	7	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					911	924		10.1109/TPAMI.2012.168	http://dx.doi.org/10.1109/TPAMI.2012.168			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22868650	Green Accepted, Green Submitted, Green Published			2022-12-18	WOS:000314931000011
J	Abd El Munim, HE; Farag, AA; Farag, AA				Abd El Munim, Hossam E.; Farag, Amal A.; Farag, Aly A.			Shape Representation and Registration in Vector Implicit Spaces: Adopting a Closed-Form Solution in the Optimization Process	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape representation; shape alignment; distance transform; vector distance function; free form deformations; optimization		In this paper, a,novel method to solve the shape registration problem covering both global and local deformations is proposed. The vector distance function (VDF) is used to represent source and target shapes. The problem is formulated as an energy optimization process by matching the VDFs of the source and target shapes. The minimization process results in estimating the transformation parameters for the global and local deformation cases. Gradient descent optimization handles the computation of scaling, rotation, and translation matrices used to minimize the global differences between source and target shapes. Nonrigid deformations require a large number of parameters which make the use of the gradient descent minimization a Very time-consuming process. We propose to compute the local deformation parameters using a closed-form solution as a linear system of equations derived from approximating an objective function. Extensive experimental validations and comparisons performed on generalized 2D shape data demonstrate the robustness and effectiveness of the method.	[Abd El Munim, Hossam E.; Farag, Amal A.; Farag, Aly A.] Univ Louisville, Dept Elect & Comp Engn, Comp Vis & Image Proc Lab CVIP Lab, Louisville, KY 40292 USA; [Abd El Munim, Hossam E.] Ain Shams Univ, Fac Engn, Comp & Syst Engn Dept, Cairo 11517, Egypt	University of Louisville; Egyptian Knowledge Bank (EKB); Ain Shams University	Abd El Munim, HE (corresponding author), Univ Louisville, Dept Elect & Comp Engn, Comp Vis & Image Proc Lab CVIP Lab, Rm 006,2301 S 3rd St, Louisville, KY 40292 USA.	hossameldin.hassan@eng.asu.edu.eg; amal.aly1@gmail.com; aly.farag@louisville.edu						Abd El Munim H.E., 2007, P IEEE COMP SOC C CO, P1; Abdelmunim H., 2011, 2011 Canadian Conference on Computer and Robot Vision (CRV), P212, DOI 10.1109/CRV.2011.35; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Chefd'Hotel C, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P21, DOI 10.1109/VLSM.2001.938877; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Diciotti S, 2011, IEEE T BIO-MED ENG, V58, P3418, DOI 10.1109/TBME.2011.2167621; El Munim HEA, 2007, IEEE T PATTERN ANAL, V29, P945, DOI 10.1109/TPAMI.2007.1100; Fornefett M., 1999, P IEEE C COMP VIS PA, V1, P1402; Gomes J, 2003, INT J COMPUT VISION, V52, P161, DOI 10.1023/A:1022956108418; Hartley R., 2003, MULTIPLE VIEW GEOMET; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Li HS, 2011, IEEE T PATTERN ANAL, V33, P1116, DOI 10.1109/TPAMI.2010.169; Paragios N., 2002, P EUR C COMP VIS JUN; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Sandhu R, 2010, IEEE T PATTERN ANAL, V32, P1459, DOI 10.1109/TPAMI.2009.142; Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903; Xie ZY, 2004, IEEE T VIS COMPUT GR, V10, P85, DOI 10.1109/TVCG.2004.1260760; Yu L, 2007, IEEE INT C BIOINFORM, P9, DOI 10.1109/BIBM.2007.19; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	21	7	7	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					763	768		10.1109/TPAMI.2012.245	http://dx.doi.org/10.1109/TPAMI.2012.245			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	26353141				2022-12-18	WOS:000314792900019
J	Qiu, PH; Mukherjee, PS				Qiu, Peihua; Mukherjee, Partha Sarathi			Edge Structure Preserving 3D Image Denoising by Local Surface Approximation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Terms-Edge-preserving image restoration; jump regression analysis; nonparametric regression; surface estimation	NOISE; FILTERS; SPACE	In various applications, including magnetic resonance imaging (MRI) and functional MRI (fMRI), 3D images are becoming increasingly popular. To improve the reliability of subsequent image analyses, 3D image denoising is often a necessary preprocessing step, which is the focus of the current paper. In the literature, most existing image denoising procedures are for 2D images. Their direct extensions to 3D cases generally cannot handle 3D images efficiently because the structure of a typical 3D image is substantially more complicated than that of a typical 2D image. For instance, edge locations are surfaces in 3D cases which would be much more challenging to handle compared to edge curves in 2D cases. We propose a novel 3D image denoising procedure in this paper, based on local approximation of the edge surfaces using a set of surface templates. An important property of this method is that it can preserve edges and major edge structures (e.g., intersections of two edge surfaces and pointed corners). Numerical studies show that it works well in various applications.	[Qiu, Peihua; Mukherjee, Partha Sarathi] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Qiu, PH (corresponding author), Univ Minnesota, Sch Stat, 224 Church St SE, Minneapolis, MN 55455 USA.	qiuxx008@umn.edu; mukh0044@umn.edu	Mukherjee, Partha Sarathi/AAM-5466-2020		US National Science Foundation (NSF)	US National Science Foundation (NSF)(National Science Foundation (NSF))	The authors thank the editor, the associate editor, and the referees for many constructive comments and suggestions, which greatly improved the quality of the paper. This research is supported in part by a US National Science Foundation (NSF) grant.	BESAG J, 1986, J R STAT SOC B, V48, P259; Chabat F, 1999, IMAGE VISION COMPUT, V17, P761, DOI 10.1016/S0262-8856(98)00150-4; Chu CK, 1998, J AM STAT ASSOC, V93, P526, DOI 10.2307/2670100; Coupe P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087; Coupe P, 2008, INT J BIOMED IMAGING, V2008, DOI 10.1155/2008/590183; EPANECHN.VA, 1969, THEOR PROBAB APPL+, V14, P153, DOI 10.1137/1114019; Fan J.Q., 1996, LOCAL POLYNOMIAL MOD; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Getreuer P., 2007, TVDENOISE M MATLAB P; Gijbels I, 2006, IEEE T PATTERN ANAL, V28, P1075, DOI 10.1109/TPAMI.2006.140; Godtliebsen F., 1994, J APPL STAT, V21, P459; Hillebrand M, 2007, ANN STAT, V35, P132, DOI 10.1214/009053606000001109; Hostalkova E, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P175, DOI 10.1109/ICDSP.2007.4288547; Keeling SL, 2003, APPL MATH COMPUT, V139, P101, DOI 10.1016/S0096-3003(02)00171-6; Le T, 2007, J MATH IMAGING VIS, V27, P257, DOI 10.1007/s10851-007-0652-y; Lopes DS, 2007, ANISODIFF3D M MATLAB; Lu HB, 2001, PROC SPIE, V4320, P905, DOI 10.1117/12.430936; Macovski A, 1996, MAGNET RESON MED, V36, P494, DOI 10.1002/mrm.1910360327; Martin-Fernandez M, 2009, MED IMAGE ANAL, V13, P19, DOI 10.1016/j.media.2008.05.004; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Qiu P, 2005, WILEY SER PROBAB ST, P1, DOI 10.1002/0471733156; Qiu PH, 2007, J AM STAT ASSOC, V102, P745, DOI 10.1198/016214507000000301; Qiu PH, 2004, TECHNOMETRICS, V46, P87, DOI 10.1198/004017004000000149; Qiu PH, 1998, ANN STAT, V26, P2218; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339; Seber G.A.F, 1977, LINEAR REGRESSION AN; Sonka M., 2008, IMAGE PROCESSING ANA; Sun JG, 2007, J COMPUT GRAPH STAT, V16, P289, DOI 10.1198/106186007x204753; SUN T, 1994, SIGNAL PROCESS, V35, P213, DOI 10.1016/0165-1684(94)90212-7; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Wang Y, 2006, INT J BIOMED IMAGING, V2006, DOI 10.1155/IJBI/2006/89095; Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190; Wiest-Daessle N, 2008, LECT NOTES COMPUT SC, V5242, P171, DOI 10.1007/978-3-540-85990-1_21; Woiselle A., 2008, P ASTRONOMICAL DATA; Yang GZ, 1996, IMAGE VISION COMPUT, V14, P135, DOI 10.1016/0262-8856(95)01047-5	37	7	10	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1457	1468		10.1109/TPAMI.2011.261	http://dx.doi.org/10.1109/TPAMI.2011.261			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22201061				2022-12-18	WOS:000305188500001
J	Harrison, AP; Joseph, D				Harrison, Adam P.; Joseph, Dileepan			Maximum Likelihood Estimation of Depth Maps Using Photometric Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; depth map; maximum likelihood estimation; nonlinear regression; finite difference methods	NOISE-REDUCTION; SHAPE; GRADIENT	Photometric stereo and depth-map estimation provide a way to construct a depth map from images of an object under one viewpoint but with varying illumination directions. While estimating surface normals using the Lambertian model of reflectance is well established, depth-map estimation is an ongoing field of research and dealing with image noise is an active topic. Using the zero-mean Gaussian model of image noise, this paper introduces a method for maximum likelihood depth-map estimation that accounts for the propagation of noise through all steps of the estimation process. Solving for maximum likelihood depth-map estimates involves an independent sequence of nonlinear regression estimates, one for each pixel, followed by a single large and sparse linear regression estimate. The linear system employs anisotropic weights, which arise naturally and differ in value to related work. The new depth-map estimation method remains efficient and fast, making it practical for realistic image sizes. Experiments using synthetic images demonstrate the method's ability to robustly estimate depth maps under the noise model. Practical benefits of the method on challenging imaging scenarios are illustrated by experiments using the Extended Yale Face Database B and an extensive data set of 500 reflected light microscopy image sequences.	[Harrison, Adam P.; Joseph, Dileepan] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada	University of Alberta	Harrison, AP (corresponding author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.	adam.p.harrison@gmail.com; dil.joseph@ualberta.ca		Harrison, Adam/0000-0003-3315-1772	Natural Sciences and Engineering Research Council (NSERC) of Canada; Alberta Innovates-Technology Futures	Natural Sciences and Engineering Research Council (NSERC) of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); Alberta Innovates-Technology Futures	The authors gratefully acknowledge anonymous reviewers for their constructive feedback. As well, the authors thank Agrawal et al. [11] and Kovesi [9] for sharing valuable Matlab implementations of their respective methods on-line. This work was supported by the Natural Sciences and Engineering Research Council (NSERC) of Canada and Alberta Innovates-Technology Futures.	Agrawal A, 2005, IEEE I CONF COMP VIS, P174, DOI 10.1109/ICCV.2005.31; Agrawal A, 2006, LECT NOTES COMPUT SC, V3951, P578; Boncelet C, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P143, DOI 10.1016/B978-0-12-374457-9.00007-X; Cameron T, 2006, COMPUT IMAGING VIS, V32, P95; Davis TA, 2006, FUND ALGORITHMS, V2, P1, DOI 10.1137/1.9780898718881; Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gonzalez R.C., 2008, DIGITAL IMAGE PROCES; Harker M, 2008, 2008 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2008.4587414; Harrison AP, 2011, J MICROSC-OXFORD, V244, P293, DOI 10.1111/j.1365-2818.2011.03536.x; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; Karacali B, 2004, INT J COMPUT VISION, V60, P25, DOI 10.1023/B:VISI.0000027788.50090.b6; KENNETT JP, 1991, NATURE, V353, P225, DOI 10.1038/353225a0; Kovesi P, 2005, IEEE I CONF COMP VIS, P994; Kuparinen T, 2009, IEEE T PATTERN ANAL, V31, P2282, DOI 10.1109/TPAMI.2009.101; Meyer S., 1975, DATA ANAL SCI ENG; Ng HS, 2010, IEEE T PATTERN ANAL, V32, P2085, DOI 10.1109/TPAMI.2009.183; Noakes L, 2003, J MATH IMAGING VIS, V18, P119, DOI 10.1023/A:1022104332058; Noakes L., 2003, P GEOM MORPH COMP IM, P143; PAIGE CC, 1979, MATH COMPUT, V33, P171, DOI 10.1090/S0025-5718-1979-0514817-3; Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204; Ratkowsky D., 1983, NONLINEAR REGRESSION; Seber GAF, 2003, WILEY SERIES PROBABI, V2nd; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; SWABY PA, 1992, IEEE EXPERT, V7, P36, DOI 10.1109/64.129281; Wild C.J., 1989, NONLINEAR REGRESSION; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479	31	7	7	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1368	1380		10.1109/TPAMI.2011.249	http://dx.doi.org/10.1109/TPAMI.2011.249			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22184255				2022-12-18	WOS:000304138300009
J	Kong, AWK				Kong, Adams Wai-Kin			IrisCode Decompression Based on the Dependence between Its Bit Pairs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometrics; iris recognition; compression; Daugman algorithm; template protection	RECOGNITION; COMPRESSION; INFORMATION	IrisCode is an iris recognition algorithm developed in 1993 and continuously improved by Daugman. Understanding IrisCode's properties is extremely important because over 60 million people have been mathematically enrolled by the algorithm. In this paper, IrisCode is proved to be a compression algorithm, which is to say its templates are compressed iris images. In our experiments, the compression ratio of these images is 1:655. An algorithm is designed to perform this decompression by exploiting a graph composed of the bit pairs in IrisCode, prior knowledge from iris image databases, and the theoretical results. To remove artifacts, two postprocessing techniques that carry out optimization in the Fourier domain are developed. Decompressed iris images obtained from two public iris image databases are evaluated by visual comparison, two objective image quality assessment metrics, and eight iris recognition methods. The experimental results show that the decompressed iris images retain iris texture that their quality is roughly equivalent to a JPEG quality factor of 10 and that the iris recognition methods can match the original images with the decompressed images. This paper also discusses the impacts of these theoretical and experimental findings on privacy and security.	Nanyang Technol Univ, Forens & Secur Lab, Sch Comp Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Kong, AWK (corresponding author), Nanyang Technol Univ, Forens & Secur Lab, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.	adamskong@ntu.edu.sg	Kong, Adams Wai Kin/A-3695-2011		King Saud University, Kingdom of Saudi Arabia	King Saud University, Kingdom of Saudi Arabia	The author would like to thank the University of West Virginia and the University of Beira Interior for sharing their databases. He also thanks Dr. Naif Alajlan for his comments. This work is partially supported by a consultant contract provided by the King Saud University, Kingdom of Saudi Arabia.	Bae K, 2003, LECT NOTES COMPUT SC, V2688, P838; BEHAR J, 1992, IEEE T SIGNAL PROCES, V40, P736, DOI 10.1109/78.127948; Braithwaite Michael, 2002, IEEE WORKSHOP AUTOMA, P14; Cheney W., 2009, LINEAR ALGEBRA THEOR; Cui JL, 2004, INT C PATT RECOG, P471, DOI 10.1109/ICPR.2004.1333804; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Daugman J, 2008, IEEE T INF FOREN SEC, V3, P52, DOI 10.1109/TIFS.2007.916009; Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540; Ea T., 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P1207; Hollingsworth KP, 2009, IEEE T PATTERN ANAL, V31, P964, DOI 10.1109/TPAMI.2008.185; Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011; Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014; Kong A, 2006, PATTERN RECOGN, V39, P1359, DOI 10.1016/j.patcog.2005.10.025; Kong AWK, 2010, IEEE T IMAGE PROCESS, V19, P522, DOI 10.1109/TIP.2009.2033427; Kong AWK, 2009, LECT NOTES COMPUT SC, V5627, P64, DOI 10.1007/978-3-642-02611-9_7; Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184; Krichen E., 2004, P INT C PATT REC, V4, P226; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406; Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787; Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5; Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237; Makthal S., 2005, P 13 EUR SIGN PROC C; MASEK L, 2003, THESIS U W AUSTR; Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002; Noh SI, 2003, LECT NOTES COMPUT SC, V2688, P862; Park CH, 2003, LECT NOTES COMPUT SC, V2695, P576; Park HA, 2007, PATTERN RECOGN LETT, V28, P2019, DOI 10.1016/j.patrec.2007.05.017; Proenca H., 2005, P 13 INT C IM AN PRO, V1, P790; Proenca H, 2007, IEEE T PATTERN ANAL, V29, P607, DOI 10.1109/TPAMI.2007.1016; Rakshit S, 2007, IEEE T INF FOREN SEC, V2, P605, DOI 10.1109/TIFS.2007.902401; Ratha NK, 2003, PATTERN RECOGN LETT, V24, P2105, DOI 10.1016/S0167-8655(03)00080-1; Ross A., 2006, BIOMETRIC CONSORTIUM, P1, DOI DOI 10.1109/BCC.2006.4341625; Rydgren E, 2004, IEEE IMAGE PROC, P861; Sanchez-Avila C, 2005, PATTERN RECOGN, V38, P231, DOI 10.1016/j.patcog.2004.07.004; SCHNEIER B, 2010, IEEE SECUR PRIV, V8, P88; Shah S, 2006, IEEE IMAGE PROC, P317, DOI 10.1109/ICIP.2006.313157; Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378; Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389; Sun Z., 2004, P 5 CHIN C BIOM REC, P491; Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240; Sun ZN, 2005, PROC CVPR IEEE, P279; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Woodward JD, 1997, P IEEE, V85, P1480, DOI 10.1109/5.628723; Yao P, 2006, INT C PATT RECOG, P362; Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981; ZHANG PF, 2004, P 3 INT C MACH LEARN, P26; Zuo JY, 2007, IEEE T INF FOREN SEC, V2, P77, DOI 10.1109/TIFS.2006.890305	51	7	8	2	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					506	520		10.1109/TPAMI.2011.159	http://dx.doi.org/10.1109/TPAMI.2011.159			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21808085				2022-12-18	WOS:000299381600007
J	Ramachandran, M; Veeraraghavan, A; Chellappa, R				Ramachandran, Mahesh; Veeraraghavan, Ashok; Chellappa, Rama			A Fast Bilinear Structure from Motion Algorithm Using a Video Sequence and Inertial Sensors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Structure from motion; multiple view geometry; computer vision		In this paper, we study the benefits of the availability of a specific form of additional information-the vertical direction (gravity) and the height of the camera, both of which can be conveniently measured using inertial sensors and a monocular video sequence for 3D urban modeling. We show that in the presence of this information, the SfM equations can be rewritten in a bilinear form. This allows us to derive a fast, robust, and scalable SfM algorithm for large scale applications. The SfM algorithm developed in this paper is experimentally demonstrated to have favorable properties compared to the sparse bundle adjustment algorithm. We provide experimental evidence indicating that the proposed algorithm converges in many cases to solutions with lower error than state-of-art implementations of bundle adjustment. We also demonstrate that for the case of large reconstruction problems, the proposed algorithm takes lesser time to reach its solution compared to bundle adjustment. We also present SfM results using our algorithm on the Google StreetView research data set.	[Ramachandran, Mahesh] Qualcomm Inc, San Diego, CA 92121 USA; [Veeraraghavan, Ashok] MERL, Cambridge, MA 02139 USA; [Chellappa, Rama] Univ Maryland, Ctr Automat Res, Dept Elect & Comp Engn, College Pk, MD 20742 USA	Qualcomm; University System of Maryland; University of Maryland College Park	Ramachandran, M (corresponding author), Qualcomm Inc, 5775 Morehouse Dr, San Diego, CA 92121 USA.	maheshr@umiacs.umd.edu; veerarag@merl.com; rama@cfar.umd.edu	Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012		US Army Research Office MURI [ARMY-W911NF0410176]	US Army Research Office MURI(MURI)	The authors thank Dr. Aswin Sankaranarayanan, Dr. Carlos Morimoto, and Professor Andre Tits for their comments and discussions during the early development of this work. This work was partly supported by US Army Research Office MURI ARMY-W911NF0410176 under the technical monitorship of Dr. Tom Doligalski. Mahesh Ramachandran was with the Center for Automation Research, University of Maryland, College Park, during the time of this work.	Buchanan AM, 2005, PROC CVPR IEEE, P316; BYROD M, 2009, P BRIT MACH VIS SEPT; CARCERONI R, 2006, P IEEE INT C COMP VI, P477; Euston M, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P340, DOI 10.1109/IROS.2008.4650766; Hager WW, 2006, ACM T MATH SOFTWARE, V32, P113, DOI 10.1145/1132973.1132979; Hartley R., 2004, ROBOTICA; Kaucic R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P420, DOI 10.1109/ICCV.2001.937548; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lourakis M.I., 2004, LEVMAR LEVENBERG MAR; Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527; Madsen K., 2004, INFORM MATH MODELLIN; Mahamud S, 2001, PROC CVPR IEEE, P1018; Malis E, 2002, IEEE T PATTERN ANAL, V24, P1268, DOI 10.1109/TPAMI.2002.1033217; Ni K, 2007, IEEE I CONF COMP VIS, P2009; Oliensis J, 2007, IEEE T PATTERN ANAL, V29, P2217, DOI 10.1109/TPAMI.2007.1132; Qian G, 2000, IEEE IMAGE PROC, P204, DOI 10.1109/ICIP.2000.900930; Rother C, 2002, INT J COMPUT VISION, V49, P117, DOI 10.1023/A:1020189404787; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298	19	7	7	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					186	193		10.1109/TPAMI.2010.163	http://dx.doi.org/10.1109/TPAMI.2010.163			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	20733224				2022-12-18	WOS:000284277600014
J	Ben-Yaacov, H; Malah, D; Barzohar, M				Ben-Yaacov, Hilla; Malah, David; Barzohar, Meir			Recognition of 3D Objects Based on Implicit Polynomials	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Implicit polynomials; 3D object recognition; tensor contraction; rotation-invariant; 3D object fitting	ALGEBRAIC-CURVES; COMPLETE-SETS; SURFACES; REPRESENTATION; 2D	Closed-form expressions for a new set of 3D rotation invariants that are linear, quadratic, and angular combinations of implicit polynomial (IP) coefficients are developed. Based on these invariants, we propose a 3D object recognition method that outperforms recognition based on IP fitting after pose estimation, and the MPEG-7 SSD technique.	[Ben-Yaacov, Hilla; Malah, David; Barzohar, Meir] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Ben-Yaacov, H (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	hilla.ben.yaacov@gmail.com; malah@ee.technion.ac.il; meirb@visionsense.com						Arfken G. B., 2005, MATH METHODS PHYS, V6th; BARZOHAR M, 1994, P IAPR INT C PATT RE, V1, P205; BENYAACOV H, 2008, THESIS TECHNION ISRA; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1139, DOI 10.1109/34.625116; Helzer A, 2004, IEEE T PATTERN ANAL, V26, P1283, DOI 10.1109/TPAMI.2004.91; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Keren D, 2004, IEEE T PATTERN ANAL, V26, P118, DOI 10.1109/TPAMI.2004.1261095; Keren D, 1999, IEEE T PATTERN ANAL, V21, P31, DOI 10.1109/34.745731; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P1143, DOI 10.1109/34.334397; LANDA Z, 2010, 755 CCIT EL ENG DEP; Landa Z., 2006, THESIS TECHNION ISRA; MORDOHAI P, 2009, DIMENSIONALITY ESTIM; *MPEG 7 IMPL STUD, 2001, TECHN MULT CONT DE 6; RUSINKIEWICZ S, 2009, SUGGESTIVE CONTOUR G; Sahin T, 2008, J MATH IMAGING VIS, V32, P127, DOI 10.1007/s10851-008-0092-3; Scharstein D, 2003, PROC CVPR IEEE, P195; Subrahmonia J, 1996, IEEE T PATTERN ANAL, V18, P505, DOI 10.1109/34.494640; Tarel J.-P., 1998, P IEEE WORKSH MOD BA, P13; Tarel JP, 2000, IEEE T PATTERN ANAL, V22, P663, DOI 10.1109/34.865183; Tasdizen T, 2000, IEEE T IMAGE PROCESS, V9, P405, DOI 10.1109/83.826778; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Unel M, 2000, ADV APPL MATH, V24, P65, DOI 10.1006/aama.1999.0679; Unel M, 1999, INT J PATTERN RECOGN, V13, P1137, DOI 10.1142/S0218001499000641; Zaharia T, 2001, PROC SPIE, V4304, P133, DOI 10.1117/12.424969; 2009, STUTTGART RANGE IMAG; 2009, DIGITAL MICHELANGELO	29	7	7	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					954	960		10.1109/TPAMI.2009.197	http://dx.doi.org/10.1109/TPAMI.2009.197			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299718				2022-12-18	WOS:000275569300015
J	Nunziati, W; Sclaroff, S; Del Bimbo, A				Nunziati, Walter; Sclaroff, Stan; Del Bimbo, Alberto			Matching Trajectories between Video Sequences by Exploiting a Sparse Projective Invariant Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Registration; invariants; similarity measures; cross ratio	RECOGNITION; RETRIEVAL	Identifying correspondences between trajectory segments observed from nonsynchronized cameras is important for reconstruction of the complete trajectory of moving targets in a large scene. Such a reconstruction can be obtained from motion data by comparing the trajectory segments and estimating both the spatial and temporal alignments. Exhaustive testing of all possible correspondences of trajectories over a temporal window is only viable in the cases with a limited number of moving targets and large view overlaps. Therefore, alternative solutions are required for situations with several trajectories that are only partially visible in each view. In this paper, we propose a new method that is based on view-invariant representation of trajectories, which is used to produce a sparse set of salient points for trajectory segments observed in each view. Only the neighborhoods at these salient points in the view-invariant representation are then used to estimate the spatial and temporal alignment of trajectory pairs in different views. It is demonstrated that, for planar scenes, the method is able to recover with good precision and efficiency both spatial and temporal alignments, even given relatively small overlap between views and arbitrary (unknown) temporal shifts of the cameras. The method also provides the same capabilities in the case of trajectories that are only locally planar, but exhibit some nonplanarity at a global level.	[Nunziati, Walter] Univ Florence, Media Integrat & Commun Ctr, I-50139 Florence, Italy; [Sclaroff, Stan] Boston Univ, Dept Comp Sci, Coll Arts & Sci, Boston, MA 02215 USA; [Del Bimbo, Alberto] Univ Florence, Dipartimento Sistemi & Informat, Fac Ingn, I-50137 Florence, Italy	University of Florence; Boston University; University of Florence	Nunziati, W (corresponding author), Univ Florence, Media Integrat & Commun Ctr, Viale Morgagni 65, I-50139 Florence, Italy.	nunziati@dsi.unifi.it; sclaroff@cs.bu.edu; delbimbo@dsi.unifi.it		DEL BIMBO, ALBERTO/0000-0002-1052-8322	US National Science Foundation [IIS-0308213, CNS-0202067, IIS-0713168]; US Office of Naval Research [N00014-03-1-0108]	US National Science Foundation(National Science Foundation (NSF)); US Office of Naval Research(Office of Naval Research)	This work was supported in part by US National Science Foundation grants IIS-0308213, CNS-0202067, and IIS-0713168, and US Office of Naval Research grant N00014-03-1-0108.	ASTROM K, 1995, 88 RT IMAGLIFIA; BASHIR F, 2004, P ACM SIGMM INT WORK; BUZAN D, 2004, P INT C PATT REC, V2; Carlsson S, 1996, INT J COMPUT VISION, V19, P211, DOI 10.1007/BF00055145; Caspi Y, 2006, INT J COMPUT VISION, V68, P53, DOI 10.1007/s11263-005-4842-z; CHEN L, 2004, P ACM SIGMM INT WORK; Dagtas S, 2000, IEEE T IMAGE PROCESS, V9, P88, DOI 10.1109/83.817601; GROS P, 1994, P APPL INV COMP VIS; Hartley R., 2004, ROBOTICA; Hsieh JW, 2006, IEEE T CIRC SYST VID, V16, P396, DOI 10.1109/TCSVT.2006.869965; Irani M, 1999, ALL DIRECT METHODS; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912; Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678; Meer P, 1998, INT J COMPUT VISION, V26, P137, DOI 10.1023/A:1007944826230; Mundy J., 1992, GEOMETRIC INVARIANCE; NUNZIATI W, 2005, P INT C IM VID RETR; NUNZIATI W, 2005, P IEEE INT C ADV VID; RAO C, 2001, P IEEE INT C COMP VI; ROTHWELL CA, 1995, INT J COMPUT VISION, V16, P57, DOI 10.1007/BF01428193; Semple J. G., 1959, ALGEBRAIC CURVES; Sheikh Y., 2005, P INT C COMP VIS; SHEIKH Y, 2007, P IEEE INT C COMP VI; STAUFFER C, 2003, P IEEE INT C COMP VI; SUK T, 1997, P COMP AN IM PATT; WEISS I, 1992, P INT C IM PROC	26	7	7	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2010	32	3					517	529		10.1109/TPAMI.2009.35	http://dx.doi.org/10.1109/TPAMI.2009.35			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	543WG	20075475				2022-12-18	WOS:000273609600009
J	Di, HJ; Tao, LM; Xu, GY				Di, Huijun; Tao, Linmi; Xu, Guangyou			A Mixture of Transformed Hidden Markov Models for Elastic Motion Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Elastic motion; shape registration; mixture models; generative model	NONRIGID REGISTRATION; ALGORITHM; ATLAS; 2D	Elastic motion is a nonrigid motion constrained only by some degree of smoothness and continuity. Consequently, elastic motion estimation by explicit feature matching actually contains two correlated subproblems: shape registration and motion tracking, which account for spatial smoothness and temporal continuity, respectively. If we ignore their interrelationship, solving each of them alone will be rather challenging, especially when the cluttered features are involved. To integrate them into a probabilistic model, one straightforward approach is to draw the dependence between their hidden states. With regard to their separated states, there are, however, two different explanations of motion which are still made under the individual constraint of smoothness or continuity. Each one can be error-prone, and their coupling causes error propagation. Therefore, it is highly desirable to design a probabilistic model in which a unified state is shared by the two subproblems. This paper is intended to propose such a model, i.e., a Mixture of Transformed Hidden Markov Models (MTHMM), where a unique explanation of motion is made simultaneously under the spatiotemporal constraints. As a result, the MTHMM could find a coherent global interpretation of elastic motion from local cluttered edge features, and experiments show its robustness under ambiguities, data missing, and outliers.	[Di, Huijun; Tao, Linmi; Xu, Guangyou] Tsinghua Univ, Dept Comp Sci & Technol, Minist Educ, Key Lab Pervas Comp, Beijing 100084, Peoples R China	Tsinghua University	Di, HJ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Minist Educ, Key Lab Pervas Comp, Beijing 100084, Peoples R China.	dhj98@mails.tsinghua.edu.cn; linmi@tsinghua.edu.cn; xgy-dcs@tsinghua.edu.cn			National Natural Science Foundation of China [60673189, 60873266, 90820304]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This research was supported in part by the National Natural Science Foundation of China under Grant Nos. 60673189, 60873266, and 90820304. The authors gratefully acknowledge constructive comments from the anonymous reviewers and would like to thank Haili Chui and Anand Rangarajan for sharing their code. Special thanks go to Jan Neumann, Xiang Li, Naveed Rao, and Bernhard Agthe for their valuable suggestions to improve the presentation of this paper. Thanks should also go to the Video and Multimedia Communications Group of the Informations & Communications Division at Corporate Technology, Siemens AG in Munich for their support.	Aggarwal JK, 1998, COMPUT VIS IMAGE UND, V70, P142, DOI 10.1006/cviu.1997.0620; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Chui H, 2004, IEEE T PATTERN ANAL, V26, P160, DOI 10.1109/TPAMI.2004.1262178; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; David S, 2002, J SUSTAIN AGR, V21, P5, DOI 10.1300/J064v21n02_03; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DI H, 2007, P IEEE C COMP VIS PA; Duta N, 2001, IEEE T PATTERN ANAL, V23, P433, DOI 10.1109/34.922703; Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004; Frey BJ, 2005, IEEE T PATTERN ANAL, V27, P1392, DOI 10.1109/TPAMI.2005.169; FREY BJ, 2000, P UNC ART INT; GLAUNES J, 2004, P IEEE C COMP VIS PA; GUO H, 2004, P IEEE INT S BIOM IM; Hill L, 2000, OXFORD LITERARY REV, V22, P3, DOI 10.3366/olr.2000.001; HUANG T, 1990, P INT C PATT REC; Huang X, 2004, P 3 IEEE WORKSH ART; Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171; Jian B, 2005, IEEE I CONF COMP VIS, P1246; JOJIC N, 2000, P IEEE C COMP VIS PA; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; KAMBHAMETTU C, 1994, HDB PRIP COMPUTER VI, V2; KANADE T, 2000, P IEEE INT C AUT FAC; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; LI M, 2004, P AS C COMP VIS; LIM J, 2005, P IEEE C COMP VIS PA; Magnus J. R, 1999, MATRIX DIFFERENTIAL; Manay S, 2006, IEEE T PATTERN ANAL, V28, P1602, DOI 10.1109/TPAMI.2006.208; MUNIM H, 2007, P IEEE C COMP VIS PA; MYRONENKO A, 2006, P ADV NEUR INF PROC; Paragios N, 2003, COMPUT VIS IMAGE UND, V89, P142, DOI 10.1016/S1077-3142(03)00010-9; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RANGARAJAN A, 2003, P IEEE INT C COMP VI; Rusinkiewicz S, 2001, P 3 INT C 3D DIG IM; SHAPIRO LS, 1992, P BRIT MACH VIS C; Tagare HD, 1999, IEEE T MED IMAGING, V18, P570, DOI 10.1109/42.790457; TORRESANI L, 2001, P IEEE C COMP VIS PA; TSIN Y, 2004, P EUR C COMP VIS; Wang F., 2006, P IEEE C COMP VIS PA; Wang F, 2008, IEEE T PATTERN ANAL, V30, P2011, DOI 10.1109/TPAMI.2007.70829; XIANG S, 2006, P AS C COMP VIS; ZHANG Z, 1992, P BRIT MACH VIS C; Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	52	7	9	2	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1817	1830		10.1109/TPAMI.2009.111	http://dx.doi.org/10.1109/TPAMI.2009.111			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696452				2022-12-18	WOS:000268996500008
J	Bhowmick, P; Pradhan, RK; Bhattacharya, BB				Bhowmick, Partha; Pradhan, Ranjan K.; Bhattacharya, Bhargab B.			Approximate Matching of Digital Point Sets Using a Novel Angular Tree	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Approximate matching; circular range query; digital geometry; point set pattern matching; polygonal range query	BINARY SEARCH TREES; DISCRETE CIRCLES; ALGORITHMS; DISPLAY; RINGS	Matching and analysis of patterns or shapes in the digital plane are of utmost importance in various problems of computer vision and pattern recognition. A digital point set is such a pattern that corresponds to an object in the digital plane. Although there exist several data structures that can be employed for Approximate Point Set Pattern Matching (APSPM) in the real domain, they require substantial modification to support algorithms in the digital domain. To bridge this gap, a novel data structure called "angular tree" is proposed, targeting an efficient and error-controllable circular range query in the digital plane. The farthest pair of points may be used as the starting correspondence between the pattern set and the background set. Several classical discrete structures and methodologies of computational geometry, as well as some topological features of circles/discs in digital geometry, have been used in tandem, for successful realization of the proposed APSPM algorithm in the digital plane. The APSPM algorithm based on the angular tree has been implemented and tested on various point sets and the reported results demonstrate the efficiency and versatility of the new data structure for supporting APSPM algorithms.	[Bhowmick, Partha] Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India; [Pradhan, Ranjan K.] Tata Consultancy Serv, Nilkunthya 721627, E Midnapur, India; [Bhattacharya, Bhargab B.] ISI, Adv Comp & Microelect Unit, Kolkata 700108, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Kharagpur; Tata Sons; Tata Consultancy Services Limited (TCS); Indian Statistical Institute; Indian Statistical Institute Kolkata	Bhowmick, P (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.	pb@cse.iitkgp.ernet.in; ranjan.p@tcs.com; bhargab@isical.ac.in	Bhattacharya, Bhargab/AAE-6130-2020					AGARWAL PK, 1998, ADV DISCRETE COMPUTA, P1; ALT H, 1988, DISCRETE COMPUT GEOM, V3, P237, DOI 10.1007/BF02187910; ALT H, 1996, B9611 FREIE U; Andreadis I, 1997, REAL-TIME IMAGING, V3, P1, DOI 10.1006/rtim.1996.0041; ANDRES E, 1994, COMPUT GRAPH, V18, P695, DOI 10.1016/0097-8493(94)90164-3; Arkin E. M., 1992, ORSA Journal on Computing, V4, P375, DOI 10.1287/ijoc.4.4.375; ATKINSON MD, 1987, J ALGORITHM, V8, P159, DOI 10.1016/0196-6774(87)90036-8; BADLER NI, 1977, COMPUT VISION GRAPH, V6, P589, DOI 10.1016/S0146-664X(77)80018-X; BAIRD HS, 1985, MODEL BASED IMAGE MA; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BENTLEY JL, 1979, IEEE T SOFTWARE ENG, V5, P333, DOI 10.1109/TSE.1979.234200; Bhowmick P, 2005, LECT NOTES COMPUT SC, V3686, P257; Bhowmick P, 2004, INT C PATT RECOG, P544, DOI 10.1109/ICPR.2004.1334194; BHOWMICK P, 2005, INT J IMAGE GRAPHICS, V1, P35; BISHNU A, 2003, P 5 IT C ALG COMPL, P36; BLINN JF, 1987, IEEE COMPUT GRAPH, V7, P39, DOI 10.1109/MCG.1987.276918; BRESENHAM J, 1977, COMMUN ACM, V20, P100, DOI 10.1145/359423.359432; Cormen TH, 2000, INTRO ALGORITHMS; de Berg M., 2000, COMPUTATIONAL GEOMET, P307, DOI DOI 10.1007/978-3-662-04245-8; DEREZENDE PJ, 1995, ALGORITHMICA, V13, P387, DOI 10.1007/BF01293487; DOROS M, 1979, COMPUT VISION GRAPH, V10, P366, DOI 10.1016/S0146-664X(79)80044-1; ERAFAT A, 1996, P 12 ANN ACM S COMP, P301; Finn P. W., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P324, DOI 10.1145/262839.262993; FOLEY J, 1993, COMPUTER GRAPHICS PR; GLEICHER M, 1994, P 10 ANN ACM S COMP, P103; Goodrich M. T., 1994, Proceedings of the Tenth Annual Symposium on Computational Geometry, P103, DOI 10.1145/177424.177572; Hagedoorn M, 1999, INT J COMPUT VISION, V31, P203, DOI 10.1023/A:1008022116857; HARALICK RM, 1974, IEEE T SYST MAN CYB, VSMC4, P394, DOI 10.1109/TSMC.1974.5408463; HEFFERNAN PJ, 1994, COMP GEOM-THEOR APPL, V4, P137, DOI 10.1016/0925-7721(94)90004-3; Hoffmann F, 1999, DISCRETE APPL MATH, V93, P75, DOI 10.1016/S0166-218X(99)00007-4; Holm L, 1996, SCIENCE, V273, P595, DOI 10.1126/science.273.5275.595; HOSUR PI, 1999, P IEEE 3 WORKSH MULT, P309; HSU SY, 1993, COMPUT GRAPH FORUM, V2, P105; Huttenlocher D. P., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P705, DOI 10.1109/CVPR.1993.341019; Huttenlocher D. P., 1992, Proceedings of the Eighth Annual Symposium on Computational Geometry, P110, DOI 10.1145/142675.142700; INDYK P, 1999, P 10 ANN SIAM ACM S; Jobbagy A., 1999, Automatika, V40, P25; Klette R., 2004, DIGITAL GEOMETRY GEO; LI B, 2003, P 4 INT C 3 D DIG IM; Likar B, 1999, MED PHYS, V26, P1678, DOI 10.1118/1.598660; MAINTZ J, 1998, IEEE ENG MED BIOL, V2, P1; MCILROY MD, 1983, ACM T GRAPHIC, V2, P237, DOI 10.1145/245.246; Mount D. M., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P155, DOI 10.1145/276884.276902; Panek J, 1999, ELECTROPHORESIS, V20, P3483, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3483::AID-ELPS3483>3.0.CO;2-R; PARUI SK, 1993, PATTERN RECOGN LETT, V14, P89, DOI 10.1016/0167-8655(93)90081-N; PITTEWAY ML, 1967, COMPUT J, V10, P282, DOI 10.1093/comjnl/10.3.282; Prabhakar S., 2003, HDB FINGERPRINT RECO; SOIFMAN B, 2004, REAL TIME COMPUTER V; SZEKELY I, 1997, COMBINATORICS PROBAB, V6, P36; THOMAS SN, 1989, TETRAHEDRON, V45, P3; Tian GY, 2003, PATTERN RECOGN LETT, V24, P1171, DOI 10.1016/S0167-8655(02)00287-8; WORRING M, 1995, IEEE T PATTERN ANAL, V17, P587, DOI 10.1109/34.387505; Yao CF, 1995, IEEE T VIS COMPUT GR, V1, P311, DOI 10.1109/2945.485618; Yuen PC, 1996, PATTERN RECOGN LETT, V17, P929, DOI 10.1016/0167-8655(96)00050-5	54	7	8	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					769	782		10.1109/TPAMI.2007.70812	http://dx.doi.org/10.1109/TPAMI.2007.70812			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19299854				2022-12-18	WOS:000264144500001
J	Zhang, L				Zhang, Li			In situ image segmentation using the convexity of illumination distribution of the light sources	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		image segmentation; B-spline; illumination; convexity; thresholding	THIN-LAYER-CHROMATOGRAPHY; QUANTITATIVE-EVALUATION; DOCUMENT IMAGE; BINARIZATION; SHAPE; ALGORITHM; SELECTION	When separating objects from a background in an image, we often meet difficulties in obtaining the precise output due to the unclear edges of the objects, as well as the poor or nonuniform illumination. In order to solve this problem, this paper presents an in situ segmentation method that takes advantage of the distribution feature of illumination of light sources, rather than analyzing the image pixels themselves. After analyzing the convexity of illumination distribution ( CID) of point and linear light sources, the paper makes use of the CID features to find pixels belonging to the background. Then, some background pixels are selected as control points to reconstruct the image background by means of B-spline; finally, by subtracting the reconstructed background from the original image, global thresholding can be employed to make the final segmentation. Quantitative evaluation experiments are made to test the performance of the method.	Tsinghua Univ, Dept Elect Engn, Inst Image & Comp Graph, Beijing 100084, Peoples R China	Tsinghua University	Zhang, L (corresponding author), Tsinghua Univ, Dept Elect Engn, Inst Image & Comp Graph, Beijing 100084, Peoples R China.	chinazhangli@tsinghua.edu.cn						Blayvas I, 2006, PATTERN RECOGN, V39, P89, DOI 10.1016/j.patcog.2005.08.011; Chan FHY, 1998, IEEE T IMAGE PROCESS, V7, P468, DOI 10.1109/83.661196; Chau FT, 1998, BIOINFORMATICS, V14, P540, DOI 10.1093/bioinformatics/14.6.540; CHOW CK, 1971, P IFIP C, P1530; Dawoud A, 2004, IEEE T IMAGE PROCESS, V13, P1223, DOI 10.1109/TIP.2004.833101; Fernando SMX, 1982, P 6 INT C PATT REC; Freeman M.H., 2005, OPTICS; Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261; Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; Huang QM, 2005, PATTERN RECOGN LETT, V26, P801, DOI 10.1016/j.patrec.2004.09.035; Inoue Y, 2002, OPT REV, V9, P75, DOI 10.1007/s10043-002-0075-3; Kim IK, 2002, PATTERN RECOGN, V35, P265, DOI 10.1016/S0031-3203(01)00027-9; Liu F, 2002, ELECTRON LETT, V38, P1017, DOI 10.1049/el:20020728; NAKAGAWA Y, 1979, PATTERN RECOGN, V11, P191, DOI 10.1016/0031-3203(79)90006-2; Oh HH, 2005, PATTERN RECOGN, V38, P2612, DOI 10.1016/j.patcog.2004.11.025; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PUN T, 1980, SIGNAL PROCESS, V2, P223, DOI 10.1016/0165-1684(80)90020-1; Rudin W., 1976, PRINCIPLES MATH ANAL, V3; Tan CL, 2006, IEEE T PATTERN ANAL, V28, P195, DOI 10.1109/TPAMI.2006.40; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930; Vovk I, 1997, J CHROMATOGR A, V779, P329, DOI 10.1016/S0021-9673(97)00442-1; Wada T, 1997, INT J COMPUT VISION, V24, P125, DOI 10.1023/A:1007906904009; YANOWITZ SD, 1989, COMPUT VISION GRAPH, V46, P82, DOI 10.1016/S0734-189X(89)80017-9; Zhang L, 2006, J CHROMATOGR A, V1109, P273, DOI 10.1016/j.chroma.2006.01.018; Zhang L, 2006, OPT EXPRESS, V14, P10386, DOI 10.1364/OE.14.010386; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284	28	7	8	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1786	1799		10.1109/TPAMI.2007.70830	http://dx.doi.org/10.1109/TPAMI.2007.70830			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703831				2022-12-18	WOS:000258344900009
J	Bart, E; Ullman, S				Bart, Evgeniy; Ullman, Shimon			Class-based feature matching across unrestricted transformations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature matching; invariant recognition; parts	FACE-RECOGNITION	We develop a novel method for class-based feature matching across large changes in viewing conditions. The method (called MBE) is based on the property that, when objects share a similar part, the similarity is preserved across viewing conditions. Given a feature and a training set of object images, we first identify the subset of objects that share this feature. The transformation of the feature's appearance across viewing conditions is determined mainly by the properties of the feature, rather than of the object in which it is embedded. Therefore, the transformed feature will be shared by approximately the same set of objects. Based on this consistency requirement, corresponding features can be reliably identified from a set of candidate matches. Unlike previous approaches, the proposed scheme compares feature appearances only in similar viewing conditions, rather than across different viewing conditions. As a result, the scheme is not restricted to locally planar objects or affine transformations. The approach also does not require examples of correct matches. We show that, by using the proposed method, a dense set of accurate correspondences can be obtained. Experimental comparisons demonstrate that matching accuracy is significantly improved over previous schemes. Finally, we show that the scheme can be successfully used for invariant object recognition.	[Bart, Evgeniy] CALTECH, Pasadena, CA 91125 USA; [Ullman, Shimon] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	California Institute of Technology; Weizmann Institute of Science	Bart, E (corresponding author), CALTECH, 1200 E Calif Blvd,MC 136-93, Pasadena, CA 91125 USA.	eugenenbart@gmail.com; shimon.ullman@weizmann.ac.il						Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229; AGARWAL S, 2002, P ECCV, P113; BART E, 2004, P IEEE WORKSH IM VID; BART E, 2004, P ECCV, P152; Basri R, 1997, INT J COMPUT VISION, V25, P145, DOI 10.1023/A:1007919917506; Black M. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P231, DOI 10.1109/ICCV.1993.378214; BLACK MJ, 1996, P EUR C COMP VIS, P329; CHOWDHURY A, 2003, IEEE T MULT IN PRESS; CHUM O, 2002, P 13 BRIT MACH VIS C; FERRARI V, 2004, P 8 EUR C COMP VIS; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Laferte JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777; Lai SH, 2000, COMPUT VIS IMAGE UND, V78, P84, DOI 10.1006/cviu.1999.0829; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MIKOLAJCZYK K, 2002, P EUR C COMP VIS, P128; PERRETT DI, 1985, PROC R SOC SER B-BIO, V223, P293, DOI 10.1098/rspb.1985.0003; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; SALI E, 1999, P BRIT MACH VIS C, P203; Salkind N., 2007, ENCY MEASUREMENT STA; Sim T, 2001, CMURITR0102; TELL D, 2002, P 7 EUR C COMP VIS C, P68; Tomasi C, 1991, CMUCS91132; Tuytelaars T., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P412; Ullman S, 2004, NEURAL NETWORKS, V17, P833, DOI 10.1016/j.neunet.2004.01.006; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; WALLRAVEN C, 2001, P CVPR 2001 WORKSH M; *WEIZM I, 2008, WEIZM I TOY CAR DAT; [No title captured]	31	7	7	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1618	1631		10.1109/TPAMI.2007.70818	http://dx.doi.org/10.1109/TPAMI.2007.70818			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	324FZ	18617719	Green Accepted			2022-12-18	WOS:000257504400009
J	Liu, SB; Kang, KB; Tarel, JP; Cooper, DB				Liu, Shubao; Kang, Kongbin; Tarel, Jean-Philippe; Cooper, David B.			Free-form object reconstruction from silhouettes, occluding edges, and texture edges: A unified and robust operator based on duality	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction robust to degeneracies and noise; duality in differential form; dual manifold; multiview reconstruction; shape from silhouettes; shape from occlusions and textures; dynamic programming	STEREO; SHAPE; CONTOURS; CAMERA; MOTION	In this paper, the duality in differential form is developed between a 3D primal surface and its dual manifold formed by the surface's tangent planes, that is, each tangent plane of the primal surface is represented as a four-dimensional vector that constitutes a point on the dual manifold. The iterated dual theorem shows that each tangent plane of the dual manifold corresponds to a point on the original 3D surface, that is, the "dual" of the "dual" goes back to the "primal." This theorem can be directly used to reconstruct 3D surface from image edges by estimating the dual manifold from these edges. In this paper, we further develop the work in our original conference papers resulting in the robust differential dual operator. We argue that the operator makes good use of the information available in the image data by using both points of intensity discontinuity and their edge directions; we provide a simple physical interpretation of what the abstract algorithm is actually estimating and why it makes sense in terms of estimation accuracy; our algorithm operates on all edges in the images, including silhouette edges, self occlusion edges, and texture edges, without distinguishing their types (thus, resulting in improved accuracy and handling locally concave surface estimation if texture edges are present); the algorithm automatically handles various degeneracies; and the algorithm incorporates new methodologies for implementing the required operations such as appropriately relating edges in pairs of images, evaluating and using the algorithm's sensitivity to noise to determine the accuracy of an estimated 3D point. Experiments with both synthetic and real images demonstrate that the operator is accurate, robust to degeneracies and noise, and general for reconstructing free-form objects from occluding edges and texture edges detected in calibrated images or video sequences.	Brown Univ, Div Engn, Providence, RI 02912 USA; LCPC, DESE, F-75015 Paris, France	Brown University; Universite Gustave-Eiffel; Laboratoire Central des Ponts et Chaussees (LCPC)	Liu, SB (corresponding author), Brown Univ, Div Engn, 182 Hope St, Providence, RI 02912 USA.	Shubao_Liu@brown.edu; kk@lems.brown.edu; tarel@lcpc.fr; david@lems.brown.edu	Tarel, Jean-Philippe/A-5598-2013; Liu, Shubao/A-1429-2008	Tarel, Jean-Philippe/0000-0002-9241-5347; 				BAKER HH, 1989, INT J COMPUT VISION, V3, P33, DOI 10.1007/BF00054837; Barton H, 1927, AM J MATH, V49, P598, DOI 10.2307/2370842; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boyer E, 1997, INT J COMPUT VISION, V22, P219, DOI 10.1023/A:1007978616082; Brand M, 2004, PROC CVPR IEEE, P30; BROWNE JM, 2001, GRASSMANN ALGEBRA EX; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; Cipolla R., 2000, VISUAL MOTION CURVES; CRISPELL D, 2006, P INT S 3D DAT PROC; Dopico FM, 2000, BIT, V40, P395, DOI 10.1023/A:1022303426500; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; FRANCO J., 2006, P INT S 3D DAT PROC; Franco J.-S., 2003, BRIT MACH VIS C BMVC, V1, P329, DOI [DOI 10.5244/C.17.32, 10.5244/C.17.32]; Giblin P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P136; GIBLIN P, 2004, P 3 EUR C COMP VIS, V1, P14; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GUAN L, 2006, P INT S 3D DAT PROC; Hartley R., 2004, ROBOTICA; KANG K, 2004, THESIS BROWN U; Kang KB, 2003, FIRST IEEE INTERNATIONAL WORKSHOP ON HIGHER-LEVEL KNOWLEDGE IN 3D MODELING AND MOTION ANALYSIS, PROCEEDINGS, P48, DOI 10.1109/HLK.2003.1240858; Kang KB, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P198, DOI 10.1109/ICCV.2001.937518; Kang SB, 2001, PROC CVPR IEEE, P103; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Lazebnik S, 2001, PROC CVPR IEEE, P156; LEYMARIE FF, 2003, THESIS BROWN U; Liang C, 2005, PROC CVPR IEEE, P878; LUONG QT, 2004, GEOMETRY MULTIPLE IM; Nakamura Y, 1996, PROC CVPR IEEE, P371, DOI 10.1109/CVPR.1996.517099; NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Ogale AS, 2005, IEEE T PATTERN ANAL, V27, P988, DOI 10.1109/TPAMI.2005.123; OGALE AS, 2005, INT J COMP VIS, V65; Raskar R, 2004, ACM T GRAPHIC, V23, P679, DOI 10.1145/1015706.1015779; STEWART GW, 1990, CSTR2539; Sullivan S, 1998, IEEE T PATTERN ANAL, V20, P1091, DOI 10.1109/34.722621; Szeliski R, 1998, INT J COMPUT VISION, V28, P27, DOI 10.1023/A:1008050630628; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; Wedin P.-A., 1972, BIT (Nordisk Tidskrift for Informationsbehandling), V12, P99, DOI 10.1007/BF01932678; Wong KYK, 2002, IMAGE VISION COMPUT, V20, P441, DOI 10.1016/S0262-8856(02)00015-X; Zhang Z., 1999, P 7 IEEE INT C COMP, V1, P666, DOI DOI 10.1109/ICCV.1999.791289; Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184	41	7	14	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					131	146		10.1109/TPAMI.2007.1143	http://dx.doi.org/10.1109/TPAMI.2007.1143			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000330	Green Submitted			2022-12-18	WOS:000250843500011
J	Rahimi, A; Recht, B; Darrell, T				Rahimi, Ali; Recht, Benjamin; Darrell, Trevor			Learning to transform time series with a few examples	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						semisupervised learning; example-based tracking; manifold learning; nonlinear system identification	DIMENSIONALITY REDUCTION	We describe a semisupervised regression algorithm that learns to transform one time series into another time series given examples of the transformation. This algorithm is applied to tracking, where a time series of observations from sensors is transformed to a time series describing the pose of a target. Instead of defining and implementing such transformations for each tracking task separately, our algorithm learns a memoryless transformation of time series from a few example input-output mappings. The algorithm searches for a smooth function that fits the training examples and, when applied to the input time series, produces a time series that evolves according to assumed dynamics. The learning procedure is fast and lends itself to a closed-form solution. It is closely related to nonlinear system identification and manifold learning techniques. We demonstrate our algorithm on the tasks of tracking RFID tags from signal strength measurements, recovering the pose of rigid objects, deformable bodies, and articulated bodies from video sequences. For these tasks, this algorithm requires significantly fewer examples compared to fully supervised regression algorithms or semisupervised learning algorithms that do not take the dynamics of the output time series into account.	CALTECH, Ctr Math Informat, Pasadena, CA 91125 USA; MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA	California Institute of Technology; Massachusetts Institute of Technology (MIT)	Rahimi, A (corresponding author), 1100 NE 45th St,6th Floor, Seattle, WA 98105 USA.	ali.rahimi@intel.com; brecht@ist.caltech.edu; trevor@csail.mit.edu						AGARWAL A, 2004, P ACM SIGGRAPH; Agarwal A., 2004, P IEEE C COMP VIS PA; AGARWALA A, 2002, P INT S NONPH AN REN; Balasubramanian M, 2002, SCIENCE, V295; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; BELKIN M, 2004, P 17 ANN C COMP LEAR; Bennett KP, 1999, ADV NEUR IN, V11, P368; Bertsekas D. P., 2001, CONVEX ANAL OPTIMIZA; Bousquet Olivier, 2002, J MACHINE LEARNING R; BRAND M, 2002, P C NEUR INF PROC SY; Bregler C., 1998, P IEEE C COMP VIS PA; DEBIE T, P C NEUR INF PROC SY; Donoho D. L., 2003, TR200308 STANF U DEP; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; EFROS A, 2003, P INT C COMP VIS; Elgammal A, 2005, PROC CVPR IEEE, P724; EVGENIOU MPT, 2000, ADV COMPUTATIONAL MA; Fokkema DR, 1998, SIAM J SCI COMPUT, V20, P94, DOI 10.1137/S1064827596300073; GHAHRAMANI Z, 1998, NEURAL INFORMATION P, P431; Grauman K., 2004, P IEEE C COMP VIS PA, DOI 10.1109/CVPR.2004.1315035; GRAUMAN K, 2005, P INT C COMP VIS; HAM J, 2003, P INT C MACH LEARN; JENKINS OC, 2004, P INT C MACH LEARN; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Juditsky A, 1995, AUTOMATICA, V31, P1725, DOI 10.1016/0005-1098(95)00119-1; Kailath T, 2000, PR H INF SY, pXIX; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; LEE K, 2005, P IEEE C COMP VIS PA; Ljung L., 1987, SYSTEM IDENTIFICATIO; PATTEN J, 2001, P C HUM FACT COMP SY; PATTEN J, 2002, P C NEW INT MUS EXPR; PLESS R, 2002, P C COMP VIS PATT RE; RAHIMI A, 2005, MIT CSAIL; RAHIMI A, 2005, THESIS MASS I TECHN; RAHIMI A, 2006, P ADV NEUR INF PROC; RAHIMI A, 2005, P IEEE C COMP VIS PA; RIFKIN R, 2003, P C ADV LEARN THEOR, V190; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Roy Nicholas, 2001, P 18 INT C MACH LEAR, P441; Schohn G., 2000, P INT C MACH LEARN, P839; SCHOLKOPT B, 2000, P NEURAL NETWORKS CO; SHAKHNAROVICH G, 2003, P INT C COMP VIS; SIDENBLADH MJ, 2000, P UER C COMP VIS, P702; Smola AJ, 2001, J MACH LEARN RES, V1, P179, DOI 10.1162/15324430152748227; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Valpola H, 2002, NEURAL COMPUT, V14, P2647, DOI 10.1162/089976602760408017; Vapnik V.N, 1998, STAT LEARNING THEORY; WAHBA G, 1990, P SIAM, V59; WEINBERGER KQ, 2004, P IEEE C COMP VIS PA; Yan R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P516; Zhu X., 2003, ICML	51	7	9	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1759	1775		10.1109/TPAMI.2007.1001	http://dx.doi.org/10.1109/TPAMI.2007.1001			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699921	Green Accepted, Green Published			2022-12-18	WOS:000248696100006
J	Naik, SK; Murthy, CA				Naik, Sarif Kumar; Murthy, C. A.			Distinct multicolored region descriptors for object recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object representation; object descriptor; object recognition; object matching; image representation		The problem of object recognition has been considered here. Color descriptions from distinct regions covering multiple segments are considered for object representation. Distinct multicolored regions are detected using edge maps and clustering. Performance of the proposed methodologies has been evaluated on three data sets and the results are found to be better than existing methods when a small number of training views is considered.	Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India	Indian Statistical Institute; Indian Statistical Institute Kolkata	Naik, SK (corresponding author), Indian Stat Inst, Machine Intelligence Unit, 203 Barrackpore Trunk Rd, Kolkata 700108, India.	sarifnaik@gmail.com; murthy@isical.ac.in						Ahmadyfard AR, 2002, IMAGE VISION COMPUT, V20, P769, DOI 10.1016/S0262-8856(02)00040-9; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BURIANEK J, 2006, SOIL 47 SURREY OBJEC; Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Kostin A, 2005, PATTERN RECOGN LETT, V26, P381, DOI 10.1016/j.patrec.2004.10.020; KOUBAROULIS D, 2002, P AS C COMP VIS JAN; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maree R, 2005, PROC CVPR IEEE, P34; Maree R., 2004, P 6 ASIAN C COMPUTER, P860; Marr D., 1982, VISION; Matas J, 2002, COMPUT VIS IMAGE UND, V88, P1, DOI 10.1006/cviu.2002.0965; MATAS J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P726; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Naik SK, 2006, IEEE T IMAGE PROCESS, V15, P2588, DOI 10.1109/TIP.2006.877408; Nayar SK, 1996, INT J COMPUT VISION, V17, P219, DOI 10.1007/BF00128232; Nene A. S., 1996, CUCS00696; OBDRZALEK S, 2002, P BRIT MACH VIS C 20; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; RAMANATH R, 2003, THESIS N CAROLINA ST; Roth D, 2002, NEURAL COMPUT, V14, P1071, DOI 10.1162/089976602753633394; Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972; Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119; STRICKER MA, 1992, TR9222 U CHIC DEP CO; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tu P, 1999, LECT NOTES COMPUT SC, V1681, P246; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257	28	7	10	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1291	1296		10.1109/TPAMI.2007.1029	http://dx.doi.org/10.1109/TPAMI.2007.1029			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496387				2022-12-18	WOS:000246395300017
J	Ji, H; Fermuller, C				Ji, H; Fermuller, C			A 3D shape constraint on video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						three-dimensional motion estimation; integration of motion fields; decoupling translation from rotation; shape and rotation	STRUCTURE-FROM-MOTION; ALGORITHM	We propose to combine the information from multiple motion fields by enforcing a constraint on the surface normals ( 3D shape) of the scene in view. The fact that the shape vectors in the different views are related only by rotation can be formulated as a rank = 3 constraint. This constraint is implemented in an algorithm which solves 3D motion and structure estimation as a practical constrained minimization. Experiments demonstrate its usefulness as a tool in structure from motion providing very accurate estimates of 3D motion.	Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Ji, H (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.	jihui@cfar.umd.edu; fer@cfar.umd.edu	JI, Hui/C-5107-2016	JI, Hui/0000-0002-1674-6056				Baillard C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P559, DOI 10.1109/CVPR.1999.784966; Black M. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P296, DOI 10.1109/CVPR.1991.139705; BLACK MJ, 1992, P ECCV 92, P485; Brodsky T, 2000, INT J COMPUT VISION, V37, P231, DOI 10.1023/A:1008132107950; Carlsson S, 1998, INT J COMPUT VISION, V27, P227, DOI 10.1023/A:1007961913417; Cheong L, 1998, COMPUT VIS IMAGE UND, V71, P356, DOI 10.1006/cviu.1997.0649; DANIILIDIS K, 1990, IMAGE VISION COMPUT, V8, P297, DOI 10.1016/0262-8856(90)80006-F; Dick A., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P372; Faugeras O, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P477, DOI 10.1109/ICCV.1998.710761; Fermuller C, 2000, INT J COMPUT VISION, V37, P43, DOI 10.1023/A:1008177429387; Forsyth D. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P660, DOI 10.1109/ICCV.1999.791288; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; MAYBANK SJ, 1986, IMAGE VISION COMPUT, V4, P38, DOI 10.1016/0262-8856(86)90006-5; Oliensis J, 1999, INT J COMPUT VISION, V34, P163, DOI 10.1023/A:1008139920864; POLAK E, 1996, OPTIMIZATION ALGORIT; Qian G, 2004, INT J COMPUT VISION, V59, P5, DOI 10.1023/B:VISI.0000020669.68126.4b; SHASHUA A, 1996, P EUR C COMP VIS, P196; Shashua A., 1995, P INT C COMP VIS; SPETSAKIS M, 1990, P DARPA IM UND WORKS, P271; Triggs B., 2000, VISION ALGORITHMS TH; VIDAL R, 2002, P EUR C COMP VIS, V2, P383; Zelnik-Manor L, 2000, IEEE T PATTERN ANAL, V22, P1105, DOI 10.1109/34.879791; ZELNIKMANOR L, 1999, P INT C COMP VIS	23	7	7	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					1018	1023		10.1109/TPAMI.2006.109	http://dx.doi.org/10.1109/TPAMI.2006.109			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724596				2022-12-18	WOS:000236734400016
J	Li, Y; Wang, ZY; Zeng, HZ				Li, Y; Wang, ZY; Zeng, HZ			Correlation filter: An accurate approach to detect and locate low contrast character strings in complex table environment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document analysis; graphics recognition; pattern analysis; correlation theory	DATA EXTRACTION; RECOGNITION; DOCUMENTS; SYSTEM	Correlation has been used extensively in object detection field. In this paper, two kinds of correlation filters, Minimum Average Correlation Energy ( MACE) and Extended Maximum Average Correlation Height (EMACH), are applied as adaptive shift locators to detect and locate smudgy character strings in complex tabular color flight coupon images. These strings in irregular tabular coupon are computer-printed characters but of low contrast and could be shifted out of the table so that we cannot detect and locate them using traditional algorithms. In our experiment, strings are extracted in the preprocessing phase by removing background and then based on geometric information, two correlation filters are applied to locate expected fields. We compare results from two correlation filters and demonstrate that this algorithm is a high accurate approach.	S China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China	South China University of Technology	Li, Y (corresponding author), S China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.	liyi@umd.edu; wzhyan@ieee.org; hzzeng@szse.cn						CASEY R, 1991, MACH VISION APPL, V5, P143; Cesarini F., 2003, International Journal on Document Analysis and Recognition, V6, P102, DOI 10.1007/s10032-002-0084-6; Chen JL, 2001, PATTERN RECOGN, V34, P1741, DOI 10.1016/S0031-3203(00)00115-1; Fan KC, 1998, PATTERN RECOGN, V31, P1205, DOI 10.1016/S0031-3203(97)00162-3; GONZALEZ RC, 2002, DIGITAL IMAGE PROCES, P703; HAYKIN S, 1998, NEURAL NETWORKS COMP, P392; HESTER CF, 1980, APPL OPTICS, V19, P1758, DOI 10.1364/AO.19.001758; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Li Y, 2003, PROC INT CONF DOC, P289; [李祖 Li Yi], 2004, [计算机工程与应用, Computer Engineering and Application], V40, P209; LI Z, 1998, IEEE T PATTERN ANAL, V20, P431; MAHALANOBIS A, 1987, APPL OPTICS, V26, P3633, DOI 10.1364/AO.26.003633; Mao JC, 1997, PROC INT CONF DOC, P153, DOI 10.1109/ICDAR.1997.619832; Savvides M., 2002, P 3 IEEE AUT ID ADV, P56, DOI DOI 10.1109/ICISIP.2004.1287684; Singh R, 2002, PROC SPIE, V4727, P265, DOI 10.1117/12.478684; SONKA M, 2000, IMAGE PROCESSING ANA, P191; Tang YY, 1997, IEEE T PATTERN ANAL, V19, P921, DOI 10.1109/34.608296; Taylor S. L., 1992, Machine Vision and Applications, V5, P211, DOI 10.1007/BF02626999; Tofani P, 1998, INT C PATT RECOG, P945, DOI 10.1109/ICPR.1998.711391; Tseng LY, 1998, PATTERN RECOGN, V31, P1525, DOI 10.1016/S0031-3203(98)00007-7; WATANABE T, 1995, IEEE T PATTERN ANAL, V17, P432, DOI 10.1109/34.385976; Xi DH, 2003, PROC INT CONF DOC, P1080; Yu B, 1996, IEEE T PATTERN ANAL, V18, P1127, DOI 10.1109/34.544084; ZHANG C, 1999, P 15 INT C PATT REC, P613	24	7	10	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1639	1644		10.1109/TPAMI.2004.117	http://dx.doi.org/10.1109/TPAMI.2004.117			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	861AO	15573824				2022-12-18	WOS:000224388700009
J	Tasdizen, T; Whitaker, R				Tasdizen, T; Whitaker, R			Higher-order nonlinear priors for surface reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						surface reconstruction; robust estimation; anisotropic diffusion; level sets	IMAGE; DIFFUSION; EQUATIONS; EDGE	For surface reconstruction problems with noisy and incomplete range data, a Bayesian estimation approach can improve the overall quality of the surfaces. The Bayesian approach to surface estimation relies on a likelihood term, which ties the surface estimate to the input data, and the prior, which ensures surface smoothness or continuity. This paper introduces a new high-order, nonlinear prior for surface reconstruction. The proposed prior can smooth complex, noisy surfaces, while preserving sharp, geometric features, and it is a natural generalization of edge-preserving methods in image processing, such as anisotropic diffusion. An exact solution would require solving a fourth-order partial differential equation (PDE), which can be difficult with conventional numerical techniques. Our approach is to solve a cascade system of two second-order PDEs, which resembles the original fourth-order system. This strategy is based on the observation that the generalization of image processing to surfaces entails filtering the surface normals. We solve one PDE for processing the normals and one for refitting the surface to the normals. Furthermore, we implement the associated surface deformations using level sets. Hence, the algorithm can accommodate very complex shapes with arbitrary and changing topologies. This paper gives the mathematical formulation and describes the numerical algorithms. We also show results using range and medical data.	Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA	Utah System of Higher Education; University of Utah	Tasdizen, T (corresponding author), Univ Utah, Sch Comp, 50 S Cent Campus Dr, Salt Lake City, UT 84112 USA.	tolga@cs.utah.edu; whitaker@cs.utah.edu		Tasdizen, Tolga/0000-0001-6574-0366				Ambrosio L, 2003, INTERFACE FREE BOUND, V5, P63; Bajcsy R., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P231; Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036; Bertalmio M, 2001, J COMPUT PHYS, V174, P759, DOI 10.1006/jcph.2001.6937; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; BOLLE RM, 1986, IEEE T PATTERN ANAL, V8, P619, DOI 10.1109/TPAMI.1986.4767836; CHEN Y, 1994, P 2 CAD BAS VIS WORK, V13, P266; Chopp D.L., 1999, INTERFACE FREE BOUND, V1, P1; Clarenz U, 2000, IEEE VISUAL, P397, DOI 10.1109/VISUAL.2000.885721; CURLESS B, 1996, P SIGGRAPH COMP GRAP; DECARLO D, 1994, P 5 INT C COMP VIS, P311; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; GEIGER D, 1991, INT J COMPUT VISION, V6, P227, DOI 10.1007/BF00115697; Gregor J, 2001, GRAPH MODELS, V63, P304, DOI 10.1006/gmod.2001.0562; HILTON A, 1996, P EUR C COMP VIS; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; Lefohn AE, 2003, LECT NOTES COMPUT SC, V2878, P564; Lefohn AE, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P75, DOI 10.1109/VISUAL.2003.1250357; LORIGO L, 2000, P COMP VIS PATT REC; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; MUMFORD D., 1985, P IEEE C COMP VIS PA; NORDSTROM KN, 1990, IMAGE VISION COMPUT, V8, P318, DOI 10.1016/0262-8856(90)80008-H; OHTAKE Y, 2000, GEOMETRIC MODELING P; Pentland A. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P612; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; POLDEN A, 1997, COMPACT SURFACES LEA; Rumpf M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1103, DOI 10.1109/ICIP.2001.958320; Sapiro G., 2001, GEOMETRIC PARTIAL DI; Schneider R., 2000, Proceedings Geometric Modeling and Processing 2000. Theory and Applications, P251, DOI 10.1109/GMAP.2000.838257; Shah J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P202, DOI 10.1109/CVPR.1991.139688; SNYDER W, 1995, IEEE T PATTERN ANAL, V17, P620, DOI 10.1109/34.387509; Tang B, 2000, INT J COMPUT VISION, V36, P149, DOI 10.1023/A:1008152115986; Tasdizen T, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P125, DOI 10.1109/VISUAL.2002.1183766; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Taubin G, 1995, P 22 ANN C COMP GRAP, P351, DOI 10.1145/218380.218473; TAUBIN G, 2001, RC22213 IBM RES DIV; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; WHITAKER R, 2002, IEEE T PATTERN ANAL, V24; Whitaker RT, 2002, MED IMAGE ANAL, V6, P235, DOI 10.1016/S1361-8415(02)00082-8; Whitaker RT, 1998, INT J COMPUT VISION, V29, P203, DOI 10.1023/A:1008036829907; WHITAKER RT, 1994, VISUALIZATION BIOMED; Witkin Andrew, 1995, ANN C SERIES, V28, DOI [10.1145/192161.192216, DOI 10.1145/192161.192216]	42	7	8	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					878	891		10.1109/TPAMI.2004.31	http://dx.doi.org/10.1109/TPAMI.2004.31			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579946	Green Submitted			2022-12-18	WOS:000221323900005
J	Wei, J; Li, ZN				Wei, J; Li, ZN			On active camera control and camera motion recovery with foveate wavelet transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active vision; wavelet transform; variable resolution techniques; gaze control; object tracking; motion detection	TRACKING; STEREO	In this paper, a new variable resolution technique-Foveate Wavelet Transform (FWT) is proposed to represent digital images in an effort to efficiently represent visual data. Compared to existing variable resolution techniques, the strength of the proposed scheme encompasses its linearity preservation, orientation selectivity, and flexibility while supporting interesting behaviors resembling the animate vision system. The linearity preservation of the FWT is due to the fact that only low and/or high-pass filterings are carried out in different regions of an image in the transform. The orientation selectivity indicates the fact that details along the horizontal, vertical, and diagonal directions are readily available in the FWT representation. The flexibility of this new representation technique is witnessed by the readiness of its extensions to represent foveae of different number, shape, and locations. To demonstrate the efficacy of the FWT, two applications are presented. First, an FWT-based active camera control scheme is developed, where the computer can move a camera to track the moving object in the scene. Second, an FWT-based method purporting to recover pan/tilt/zoom camera movements from video clips is developed. Experiments of these two applications have shown encouraging performances.	CUNY City Coll, Dept Comp Sci, New York, NY 10031 USA; Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	City University of New York (CUNY) System; City College of New York (CUNY); Simon Fraser University	Wei, J (corresponding author), CUNY City Coll, Dept Comp Sci, Convent Ave & 138th St, New York, NY 10031 USA.	wei@cs.ccny.cuny.edu; li@cs.sfu.ca						BANDERA C, 1989, 1989 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1-3, P596, DOI 10.1109/ICSMC.1989.71367; Carpenter RHS, 1977, MOVEMENTS EYES; CHANG EC, 1997, P 13 ACM S COMP GEOM, P397; CROWLEY JL, 1995, VISION PROCESS; Darrell T, 1998, PROC CVPR IEEE, P601, DOI 10.1109/CVPR.1998.698667; Ferrari F., 1995, SENSOR REV, V15, P17; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Klarquist WN, 1998, IEEE T ROBOTIC AUTOM, V14, P755, DOI 10.1109/70.720351; MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909; Reid ID, 1996, INT J COMPUT VISION, V18, P41, DOI 10.1007/BF00126139; Sandini G, 1996, RO-MAN '96 - 5TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P158, DOI 10.1109/ROMAN.1996.568790; SANDINI G, 1990, P 5 INT S ROB RES TO, P75; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; SMITH SM, 1994, ENG APPL ARTIF INTEL, V7, P191, DOI 10.1016/0952-1976(94)90023-X; SWAIN MJ, 1993, INT J COMPUT VISION, V11, P109, DOI 10.1007/BF01469224; TONG F, 1995, IEEE T PATTERN ANAL, V17, P500, DOI 10.1109/34.391393; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Wei J, 1999, IEEE T CIRC SYST VID, V9, P960, DOI 10.1109/76.785734; Wei J, 1998, INT C PATT RECOG, P1445, DOI 10.1109/ICPR.1998.711976; Wei J, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P866, DOI 10.1109/IROS.1998.727309; WEI J, 1998, THESIS S FRASER U; WEIMAN CFR, 1979, COMPUT VISION GRAPH, V11, P197, DOI 10.1016/0146-664X(79)90089-3; WIEBE K, 1996, THESIS U ALBERTA; Wiebe KJ, 1997, PATTERN RECOGN, V30, P1687, DOI 10.1016/S0031-3203(96)00160-4; ZHANG J, 1995, IEEE T IMAGE PROCESS, V4, P19, DOI 10.1109/83.350816	25	7	7	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					896	903		10.1109/34.946992	http://dx.doi.org/10.1109/34.946992			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH		Green Submitted			2022-12-18	WOS:000170283300009
J	Shen, XQ; Palmer, P				Shen, XQ; Palmer, P			Uncertainty propagation and the matching of junctions as feature groupings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature tracking; junction; uncertainty propagation; junction matching; junction topology; topological matching; epipolar geometry	TRANSFORM ALGORITHM; IMAGE SEQUENCES; STEREO	The interpretation of the 3D world from image sequences requires the identification and correspondences of key features in the scene. In this paper, we describe a robust algorithm for matching groupings of features related to the objects in the scene. We consider the propagation of uncertainty from the feature detection stage through the grouping stage to provide a measure of uncertainty at the matching stage. We focus upon indoor scenes and match junctions, which are groupings of line segments that meet at a single point. A model of the uncertainty in junction detection is described, and the junction uncertainty under the epipolar constraint is determined. Junction correspondence is achieved through matching of each line segment associated with the junction. A match likelihood is then derived based upon the detection uncertainties and then combined with information on junction topology to create a similarity measure. A robust matching algorithm is proposed and used to match junctions between pairs of images. The presented experimental results on real images show that the matching algorithm produces sufficiently reliable results for applications such as structure from motion.	Altera European Technol Ctr, High Wycombe HP12 4XF, Bucks, England; Univ Surrey, Sch Elect Engn Informat Theory & Math, Guildford GU2 7XH, Surrey, England	University of Surrey	Shen, XQ (corresponding author), Altera European Technol Ctr, Holmers Farm Way, High Wycombe HP12 4XF, Bucks, England.							AYACHE N, 1987, INT J COMPUT VISION, V1, P107, DOI 10.1007/BF00123161; Beymer D. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P720, DOI 10.1109/CVPR.1991.139798; BIRNBAUM ZW, 1962, INTRO PROBABILITY MA; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Chang YL, 1997, COMPUT VIS IMAGE UND, V67, P186, DOI 10.1006/cviu.1997.0527; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FORSTNER W, 1994, P COMP VIS ECCV 94, V1, P383; FREEMAN W, 1991, P ASS RES VIS OPTH; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; Harary F., 1994, GRAPH THEORY; Hartley R.I., 1994, P ARPA IM UND WORKSH; HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855; HU XP, 1994, IEEE T PATTERN ANAL, V16, P1041, DOI 10.1109/34.329004; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NOBLE JA, 1988, IMAGE VISION COMPUT, V6, P121, DOI 10.1016/0262-8856(88)90007-8; Palmer PL, 1997, COMPUT VIS IMAGE UND, V67, P1, DOI 10.1006/cviu.1996.0491; PALMER PL, 1993, CVGIP-IMAG UNDERSTAN, V58, P221, DOI 10.1006/ciun.1993.1039; Parida L, 1998, IEEE T PATTERN ANAL, V20, P687, DOI 10.1109/34.689300; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; Pla F, 1997, COMPUT VIS IMAGE UND, V66, P271, DOI 10.1006/cviu.1996.0512; Reid ID, 1996, INT J COMPUT VISION, V18, P41, DOI 10.1007/BF00126139; Schmid C, 1997, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.1997.609397; VENKATESWAR V, 1995, INT J COMPUT VISION, V15, P245, DOI 10.1007/BF01451743; Wei GQ, 1998, IEEE T PATTERN ANAL, V20, P1143, DOI 10.1109/34.730551; Weng J., 1993, MOTION STRUCTURE IMA; ZHANG Z, 1995, P 5 INT C COMP VIS, P257; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	31	7	11	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2000	22	12					1381	1395		10.1109/34.895973	http://dx.doi.org/10.1109/34.895973			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	383UR					2022-12-18	WOS:000165901900003
J	Combettes, PL; Pesquet, JC				Combettes, PL; Pesquet, JC			Convex multiresolution analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiresolution analysis; convex sets; hierarchical signal analysis; nonlinear filter banks; projections	SCALE-SPACE; RECOVERY	A standard wavelet multiresolution analysis can be defined via a sequence of projectors onto a monotone sequence of closed Vector subspaces possessing certain properties. We propose a nonlinear extension of this framework in which the Vector subspaces are replaced by convex subsets. These sets are chosen so as to provide a recursive, monotone approximation scheme that allows for various signal and image features to be investigated. Several classes of convex multiresolution analyses are discussed and numerical applications to signal and image-processing problems are demonstrated.	CUNY, City Coll & Grad Sch, Dept Elect Engn, New York, NY 10031 USA; Univ Paris 11, Signaux & Syst Lab, F-91192 Gif Sur Yvette, France	City University of New York (CUNY) System; UDICE-French Research Universities; Universite Paris Saclay	Combettes, PL (corresponding author), CUNY, City Coll & Grad Sch, Dept Elect Engn, New York, NY 10031 USA.		Combettes, Patrick L/A-2442-2011	Combettes, Patrick L/0000-0001-9730-5932				BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; Bangham JA, 1996, IEEE T PATTERN ANAL, V18, P529, DOI 10.1109/34.494642; Bangham JA, 1996, IEEE T PATTERN ANAL, V18, P520, DOI 10.1109/34.494641; Benedetto JJ, 1998, APPL COMPUT HARMON A, V5, P389, DOI 10.1006/acha.1997.0237; Bourbaki N, 1987, ELEMENTS MATH TOPOLO; Boyle J. P., 1986, ADV ORDER RESTRICTED, P28, DOI DOI 10.1007/978-1-4613-9940-7_3; CETIN AE, 1994, IEEE T SIGNAL PROCES, V42, P194, DOI 10.1109/78.258135; CIARLET PG, 1989, INTRO ANAL NUMERIQUE; COHEN A, 1994, WAVELETS THEORY ALGO, P3; Combettes PL, 1993, IEEE T IMAGE PROCESS, V2, P269, DOI 10.1109/83.217232; Combettes PL, 1997, IEEE T IMAGE PROCESS, V6, P493, DOI 10.1109/83.563316; Combettes PL., 1996, ADV IMAG ELECT PHYS, P155, DOI DOI 10.1016/S1076-5670(08)70157-5; Daubechies I., 1992, 10 LECT WAVELETS, DOI [10.1137/1.9781611970104.ch1, DOI 10.1137/1.9781611970104.CH1]; Ekeland I., 1976, CONVEX ANAL VARIATIO; Hampson FJ, 1998, IEEE T IMAGE PROCESS, V7, P1547, DOI 10.1109/83.725362; MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909; MALLAT S, 1989, IEEE T PATTERN ANAL, V11, P7; MALLAT SG, 1989, T AM MATH SOC, V315, P69, DOI 10.2307/2001373; Meyer Y., 1990, ONDELETTES OPERATEUR; Morel J.-M., 1995, VARIATIONAL METHODS; SIMARD PY, 1988, IEEE T PATTERN ANAL, V10, P248, DOI 10.1109/34.3886; WONG YFI, 1995, IEEE T IMAGE PROCESS, V4, P774, DOI 10.1109/83.388079	23	7	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1998	20	12					1308	1318		10.1109/34.735804	http://dx.doi.org/10.1109/34.735804			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	147QV					2022-12-18	WOS:000077578300003
J	Boyd, JE; Meloche, J				Boyd, JE; Meloche, J			Binary restoration of thin objects in multidimensional imagery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						binary restoration; image restoration; tomography; x-rays; statistical methods	EARLY VISION; RELAXATION	We present a method for restoration of noisy tomographic images for detecting thin objects, such as explosives. Use of a weighted mean-square estimate optimizes the solution to place emphasis on the infrequent, but significant local structure associated with thin objects. Experimental results show successful restoration at very high noise levels.	Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA; Univ British Columbia, Dept Stat, Vancouver, BC V6T 1Z2, Canada	University of California System; University of California San Diego; University of British Columbia	Boyd, JE (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.							BOYD JE, 1998, 175 U BRIT COL DEP S; Brassard G., 1988, ALGORITHMICS THEORY; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Guy G, 1997, IEEE T PATTERN ANAL, V19, P1265, DOI 10.1109/34.632985; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HALL P, 1992, TECHNOMETRICS, V34, P429, DOI 10.2307/1268942; HANCOCK ER, 1990, IEEE T PATTERN ANAL, V12, P165, DOI 10.1109/34.44403; HARRIS JG, 1990, INT J COMPUT VISION, V4, P211, DOI 10.1007/BF00054996; KAK AC, 1988, PRINCILES COMPUTERIZ; KEELER K, 1991, IEEE C COMP VIS PATT, P420; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; MCDONALD JA, 1986, TECHNOMETRICS, V28, P195, DOI 10.2307/1269075; MELOCHE J, 1994, CAN J STAT, V22, P335, DOI 10.2307/3315596; MORGADO RE, 1993, P SOC PHOTO-OPT INS, V2092, P492; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; SEED T, 1993, P SOC PHOTO-OPT INS, V2092, P482, DOI DOI 10.1117/12.171266; SREDNIAWSKI J, 1997, IND PHYSICIST, P24	19	7	7	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1998	20	6					647	651		10.1109/34.683781	http://dx.doi.org/10.1109/34.683781			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZV807					2022-12-18	WOS:000074343300006
J	Kanatani, K				Kanatani, K			Nonparametric segmentation of curves into various representations - Comment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						curve segmentation; line fitting; conic fitting; pattern recognition; geometric AIC		I point out the existence of a theoretical difficulty that underlies the curve segmentation problem studied by Rosin and West and present a possible solution to it.			Kanatani, K (corresponding author), GUNMA UNIV,DEPT COMP SCI,KIRYU,GUMMA 3768515,JAPAN.							AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BOYER KL, 1994, IEEE T PATTERN ANAL, V16, P987, DOI 10.1109/34.329010; KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P320, DOI 10.1109/34.276132; Kanatani K., 1996, STAT OPTIMIZATION GE; KANATANI K, IN PRESS IEEE T PATT; Kanazawa Y, 1996, IEICE T INF SYST, VE79D, P1317; Kanazawa Y, 1996, IEICE T INF SYST, VE79D, P1323; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; TRIONO I, 1996, P IAPR WORKSH MACH V, P393; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508	10	7	9	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1997	19	12					1391	1392		10.1109/34.643901	http://dx.doi.org/10.1109/34.643901			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YK781					2022-12-18	WOS:A1997YK78100010
J	Oflazer, K				Oflazer, K			Error-tolerant retrieval of trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						example-based machine translation; approximate tree comparison; retrieval from lexical databases; tree databases	SPELLING CORRECTION	We present an efficient algorithm for retrieving from a database of trees, all trees that differ from a given query tree by a small number additional or missing leaves, or leaf label changes. It has natural language processing applications in searching for matches in example-based translation systems, and retrieval from lexical databases containing entries of complex feature structures. For large randomly generated synthetic tree databases (some having tens of thousands of trees), and on databases constructed from Wall Street Journal treebank, it can retrieve for trees with a small error, in a matter of tenths of a second to about a second.			Oflazer, K (corresponding author), BILKENT UNIV,DEPT COMP SCI & INFORMAT ENGN,BILKENT,ANKARA,TURKEY.		Oflazer, Kemal/A-5528-2010	Oflazer, Kemal/0000-0002-4977-0079				DU MW, 1992, ACTA INFORM, V29, P281, DOI 10.1007/BF01185682; Maruyama Hiroshi, 1992, P 4 INT C THEOR METH, P173; MYERS EW, 1989, B MATH BIOL, V51, P5, DOI 10.1007/BF02458834; NIRENBURG S, 1994, P INT C NEW METH LAN, P78; Oflazer K, 1996, COMPUT LINGUIST, V22, P73; Sato S., 1990, P 13 INT C COMPUTATI, P247, DOI [10.3115/991146.991190, DOI 10.3115/991146.991190]; SELKOW SM, 1977, INFORM PROCESS LETT, V6, P184, DOI 10.1016/0020-0190(77)90064-3; TAI KC, 1979, J ACM, V26, P422, DOI 10.1145/322139.322143; UTSURO T, 1994, P 15 INT C COMP LING, V2, P1044; WANG JTL, 1994, IEEE T KNOWL DATA EN, V6, P559, DOI 10.1109/69.298173; WU S, 1991, TR9111 U AR DEP COMP	11	7	8	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1997	19	12					1376	1380		10.1109/34.643897	http://dx.doi.org/10.1109/34.643897			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YK781		Green Published			2022-12-18	WOS:A1997YK78100007
J	Cowell, RG				Cowell, RG			On compatible priors for Bayesian networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian networks; Dirichlet priors; Kullback-Leibler distance; local independence; global independence	EXPERT-SYSTEMS; GRAPHICAL STRUCTURES; PROBABILITIES	Given a Bayesian network of discrete random variables with a hyper-Dirichlet prior, a method is proposed for assigning Dirichlet priors to the conditional probabilities of structurally different networks. It defines a distance measure between priors which is to be minimized for the assignment process. intuitively one would expect that if two models' priors are to qualify as being 'close' in some sense, then their posteriors should also be nearby after an observation. However one does not know in advance what will be observed next. Thus we are led to propose an expectation of Kullback-Leibler distances over all possible next observations to define a measure of distance between priors. In conjunction with the additional assumptions of global and local independence of the parameters [15], a number of theorems emerge which are usually taken as reasonable assumptions in the Bayesian network literature. The method is compared to the 'expansion and contraction' algorithm of [14], and is also contrasted with the results obtained in [7] who employ the additional assumption of likelihood equivalence which is not made here. A simple example illustrates the technique.			Cowell, RG (corresponding author), CITY UNIV LONDON,SCH MATH ACTUARIAL SCI & STAT,LONDON,ENGLAND.							Andersson S. A., 1995, 287 U WASH DEP STAT; CHICKERING D, 1995, R231 U CAL COGN SCI; COOPER G, 1992, MACH LEARN, V42, P393; COWELL RG, 1993, IEEE T PATTERN ANAL, V15, P209, DOI 10.1109/34.204903; FRYDENBERG M, 1989, SCANDINAVIAN J STAT, V17, P323; HECKERMAN D, 1994, MSRTR9554 MICR RES; HECKERMAN D, 1995, MSRTR9504 MICR RES; LAURITZEN SL, 1989, SCAND J STAT, V16, P273; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; NILSSON D, 1994, THESIS U COPENHAGEN; Pearl J, 1988, PROBABILISTIC INFERE; Spiegelhalter D. J., 1992, BAYESIAN STAT, V4, P447; SPIEGELHALTER DJ, 1993, STAT SCI, V8, P219, DOI 10.1214/ss/1177010888; VERMA T, 1990, P 6 C UNC ART INT, P220; Whittaker J., 1990, GRAPHICAL MODELS APP	16	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1996	18	9					901	911		10.1109/34.537344	http://dx.doi.org/10.1109/34.537344			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VK799					2022-12-18	WOS:A1996VK79900004
J	Wheeler, MD; Ikeuchi, K				Wheeler, MD; Ikeuchi, K			Iterative smoothed residuals: A low-pass filter for smoothing with controlled shrinkage	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						smoothing; filtering; curve; shrinkage; Gaussian; computer vision		We present a linear smoothing operator which has lowpass characteristics similar to a Butterworth filter and limited spatial extent similar to a Gaussian. The smoothing operator also has closed forms in the spatial and frequency domains which facilitate analysis and implementation. A formula is derived that allows us to explicitly control shrinkage.			Wheeler, MD (corresponding author), CARNEGIE MELLON UNIV, SCH COMP SCI, PITTSBURGH, PA 15213 USA.							BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; Blom J., 1993, Journal of Visual Communication and Image Representation, V4, P1, DOI 10.1006/jvci.1993.1001; CRAVEN P, 1979, NUMER MATH, V31, P377, DOI 10.1007/BF01437407; GUEZIEC A, 1994, INT J COMPUT VISION, V12, P79, DOI 10.1007/BF01420985; Hamming RW., 1983, DIGITAL FILTERS; LOWE DG, 1989, INT J COMPUT VISION, V3, P119, DOI 10.1007/BF00126428; Meyer Y., 1992, WAVELETS OPERATORS; OLIENSIS J, 1993, IEEE T PATTERN ANAL, V15, P307, DOI 10.1109/34.204914; PRESS WH, 1991, NUMERICAL RECIPES C; SAPIRO G, 1995, IEEE T PATTERN ANAL, V17, P67, DOI 10.1109/34.368150; SHAHRARAY B, 1989, IEEE T PATTERN ANAL, V11, P600, DOI 10.1109/34.24794; TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P852, DOI 10.1109/ICCV.1995.466848; Tukey J.W., 1976, EXPLORATORY DATA ANA; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	15	7	7	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					334	337		10.1109/34.485562	http://dx.doi.org/10.1109/34.485562			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500011
J	ZHANG, ZY				ZHANG, ZY			MOTION AND STRUCTURE OF 4 POINTS FROM ONE MOTION OF A STEREO RIG WITH UNKNOWN EXTRINSIC PARAMETERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						MOTION ANALYSIS; UNCALIBRATED STEREO; STRUCTURE FROM MOTION; 4-POINTS ALGORITHM; MINIMIZATION CRITERIA	PROJECTIONS	We describe an analytical method for recovering 3D motion and structure of four or more points from one motion of a stereo rig. The extrinsic parameters are unknown. The motion of the stereo rig is also unknown. Because of the exploitation of information redundancy, the approach gains over the traditional ''motion and structure from motion'' approach in that less features and less motions are required, and thus more robust estimation of motion and structure can be obtained. Since the constraint on the rotation matrix is Rot fully exploited in the analytical method, nonlinear minimization can be used to improve the result. We propose to estimate directly the motion and structure by minimizing the difference between the measured positions and the predicted ones in the image plane. Both computer simulated data and real data are used to validate the proposed algorithm, and very promising results are obtained.			ZHANG, ZY (corresponding author), INRIA SOPHIA ANTIPOLIS,2004 ROUTE LUCIOLES,BP 93,F-06902 SOPHIA ANTIPOLIS,FRANCE.							Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FAUGERAS OD, 1986, JUN P IEEE C COMP VI, P15; FAUGERAS OD, 1987, 1ST P INT C COMP VIS, P25; HORN B, 1987, J OPT SOC AM A, V7, P629; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368; JERIAN CP, 1991, IEEE T SYST MAN CYB, V21, P572, DOI 10.1109/21.97478; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; Longuet-Higgins H. C., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P395; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1988, P ROY SOC LOND A MAT, V418, P1, DOI 10.1098/rspa.1988.0071; LONGUETHIGGINS HC, 1992, IMAGE VISION COMPUT, V10, P266, DOI 10.1016/0262-8856(92)90040-A; LUONG QT, 1992, THESIS U PARIS 11 OR; MAYBANK S, 1993, THEORY RECONSTRUCTIO; Netravali A. N., 1989, International Journal of Imaging Systems and Technology, V1, P78, DOI 10.1002/ima.1850010110; SHARMA R, 1991, CARTR534 U MARYL CTR; SPETSAKIS ME, 1988, DEC P INT C COMP VIS, P449; TSAI RY, 1982, IEEE T ACOUST SPEECH, V30, P525, DOI 10.1109/TASSP.1982.1163931; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; ZHANG Z, 1994, 12TH P INT C PATT RE, V1, P695; ZHANG Z, IN PRESS IEEE T ROBO; ZHANG Z, 1990, THESIS U PARIS 11 OR; ZHANG Z, IN PRESS ARTIFICIAL; ZHANG Z, 1992, 3D DYNAMIC SCENE ANA; ZHANG Z, 1994, INRIA2273 RES REP	27	7	9	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1222	1227		10.1109/34.476516	http://dx.doi.org/10.1109/34.476516			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500011
J	SCHWEITZER, HS				SCHWEITZER, HS			OCCAM ALGORITHMS FOR COMPUTING VISUAL-MOTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE MOTION; OPTIC FLOW; VIDEO COMPRESSION; MACHINE LEARNING; OCCAM ALGORITHMS	MOVING-OBJECTS; OPTICAL-FLOW	The standard approach to computing motion relies on pixel correspondence, Computational schemes impose additional from constraints, such as smoothness and continuity of the motion vector field, even though these are not directly related to pixel correspondence. This paper proposes an alternative to the multiple constraints approach. By drawing analogy with machine learning, motion is computed as a function that accurately predicts frames, The Occam-Razor principle suggests that among all functions that accurately predict the second frame from the first frame, the best predictor is the ''simplest,'' and simplicity can be rigorously defined in terms of encoding length. An implementation of a practical algorithm is described. Experiments with real video sequences verify the algorithm assumptions by showing that motion in typical sequences can be accurately described in terms of a few parameters. Our particular choice of predictors produces results that compare very favorably with other image flow algorithms in terms of accuracy and compactness. It may, however, be too constrained to enable accurate recovery of 3D motion and structure.			SCHWEITZER, HS (corresponding author), UNIV TEXAS, ERIK JONSSON SCH ENGN & COMP SCI, POB 830688, RICHARDSON, TX 75083 USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237; BERGEN JR, 1987, J OPT SOC AM, V4, P48; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Hestenes M.R., 1980, CONJUGATE DIRECTION; HIDAKA T, 1990, SIGNAL PROCESSING IM, V2; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; IRANI M, 1992, LECT NOTES COMPUT SC, V588, P282; Lee C. H., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P398, DOI 10.1109/CVPR.1988.196266; LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090; Nagel HH, 1982, PATTERN RECOGN LETT, V1, P55, DOI 10.1016/0167-8655(82)90052-6; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; Pearl J., 1984, INTELLIGENT SEARCH S; PENTLAND A, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P178; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936; Samet H., 1990, DESIGN ANAL SPATIAL, V85; SRINIVASAN R, 1985, IEEE T COMMUN, V33, P888, DOI 10.1109/TCOM.1985.1096398; STOCKMEYER L, 1983, INFORM CONTROL, V57, P91, DOI 10.1016/S0019-9958(83)80038-2; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P806, DOI 10.1109/34.149592	27	7	7	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1995	17	11					1033	1042		10.1109/34.473229	http://dx.doi.org/10.1109/34.473229			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TD854					2022-12-18	WOS:A1995TD85400002
J	PORTEGYS, TE				PORTEGYS, TE			A SEARCH TECHNIQUE FOR PATTERN-RECOGNITION USING RELATIVE DISTANCES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						PATTERN RECOGNITION; OPTICAL CHARACTER RECOGNITION; NEAREST NEIGHBOR; DISTANCE METRIC; BRANCH AND BOUND; NIST DIGIT SAMPLES		A technique for creating and searching a tree of patterns using relative distances is presented. The search is conducted to find patterns which are nearest neighbors of a given test pattern. The structure of the tree is such that the search time is proportional to the distance between the test pattern and its nearest neighbor, which suggests the anomalous possibility that a larger tree, which can be expected on average to contain closer neighbors, can be searched faster than a smaller tree. The technique has been used to recognize OCR digit samples derived from NIST data at an accuracy rate of 97% using a tree of 7,000 patterns.			PORTEGYS, TE (corresponding author), AT&T BELL LABS, NAPERVILLE, IL 60566 USA.							BARLEV D, 1984, SEMICONDUCTORS ELECT; BEAL DF, 1991, ADV COMPUTER CHESS, V6; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; Denker John S, 1989, ADV NEURAL INFORM PR, P323; FUKUNAGA K, 1990, INTRO STATISTICAL PA; HILL R, 1988, 1ST COURSE CODING TH; Karim M.A., 1992, OPTICAL COMPUTING IN; KEELER J, 1992, ADV NEUR IN, V4, P496; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761, DOI 10.1109/TPAMI.1986.4767859; MARTIN GL, 1990, ADV NEURAL INFORMATI, V2, P405; SACKINGER E, 1992, ADV NEUR IN, V4, P773	11	7	7	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1995	17	9					910	914		10.1109/34.406658	http://dx.doi.org/10.1109/34.406658			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RR989					2022-12-18	WOS:A1995RR98900009
J	CORAZZA, A; DEMORI, R; GRETTER, R; SATTA, G				CORAZZA, A; DEMORI, R; GRETTER, R; SATTA, G			OPTIMAL PROBABILISTIC EVALUATION FUNCTIONS FOR SEARCH CONTROLLED BY STOCHASTIC CONTEXT-FREE GRAMMARS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						STOCHASTIC LANGUAGE MODELS; STOCHASTIC CONTEXT-FREE GRAMMARS; SYNTAX-CONTROLLED SIGNAL INTERPRETATION; STOCHASTIC PARSING; PROBABILISTIC SCORES FOR LINGUISTIC INTERPRETATION; ISLAND DRIVEN STOCHASTIC PARSERS	LANGUAGES	Recently, the possibility of using Stochastic Context-Free Grammars (SCFG's) in Language Modeling (LM) has been considered. When these grammars are used, search can be directed by evaluation functions based on the probabilities that a SCFG generates a sentence, given only some words in it. Expressions for computing the evaluation function have been proposed by Jelinek and Lafferty for the recognition of word sequences in the case in which only the prefix of a sequence is known. Corazza et al. have proposed methods for probability computation in the more general case in which partial word sequences interleaved by gaps are known. This computation is too complex in practice unless the lengths of the gaps are known. This paper proposes a method for computing the probability of the best parse tree that can generate a sentence only part of which (consisting of islands and gaps) is known. This probability is the minimum possible, and thus the most informative, upper-bound that can be used in the evaluation function. The computation of the proposed upper-bound has cubic time complexity even if the lengths of the gaps are unknown. This makes possible the practical use of SCFG for driving interpretations of sentences in natural language processing.	UNIV PENN,INST RES COGNIT SCI,PHILADELPHIA,PA 19104; IST RIC SCI & TECNOL,I-38050 TRENT,ITALY; UNIV VENEZIA,I-30172 MESTRE,ITALY; MCGILL UNIV,SCH COMP SCI,MONTREAL H3A 2A7,QUEBEC,CANADA	University of Pennsylvania; Universita Ca Foscari Venezia; McGill University				CORAZZA, Anna/0000-0002-9156-5079; SATTA, GIORGIO/0000-0001-7742-6438				Aho A.V., 1972, THEORY PARSING TRANS; CORAZZA A, 1991, IEEE T PATTERN ANAL, V13, P936, DOI 10.1109/34.93811; FU KS, 1982, SYNTACTIC PATTERN RE; GONZALES RC, 1978, SYNTACTIC PATTERN RE; GRETTER R, 1993, UPPER BOUNDS THEORIE; Harrison M. A., 1978, INTRO FORMAL LANGUAG; Jelinek F., 1991, Computational Linguistics, V17, P315; JELINEK F, 1992, SPEECH RECOGNITION U; LEE HC, 1972, IEEE T COMPUT, V4, P660; LU SY, 1977, IEEE T COMPUT, V26, P1268, DOI 10.1109/TC.1977.1674788; PERSOON E, 1975, INT J COMPUT INF SCI, V4, P205, DOI 10.1007/BF01007759; SALOMAA A, 1969, INFORM CONTROL, V15, P529, DOI 10.1016/S0019-9958(69)90554-3; TANAKA E, 1978, IEEE T COMPUT, V27, P605, DOI 10.1109/TC.1978.1675160; WETHERELL CS, 1980, COMPUT SURV, V12, P361, DOI 10.1145/356827.356829; WOODS WA, 1982, ARTIF INTELL, V18, P295, DOI 10.1016/0004-3702(82)90025-X; YOUNGER DH, 1967, INFORM CONTROL, V10, P189, DOI 10.1016/S0019-9958(67)80007-X	16	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1994	16	10					1018	1027		10.1109/34.329008	http://dx.doi.org/10.1109/34.329008			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PM827					2022-12-18	WOS:A1994PM82700005
J	FERMULLER, C; KROPATSCH, W				FERMULLER, C; KROPATSCH, W			A SYNTACTIC APPROACH TO SCALE-SPACE-BASED CORNER DESCRIPTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						2-D-SHAPE DESCRIPTION; SCALE-SPACE REDUCTION OF CURVATURE EXTREMA; CORNER DETECTION; MULTIRESOLUTION REPRESENTATION	PLANAR CURVES; EXTREMA; SHAPES	Planar curves are described by information about corners integrated over various levels of resolution. The detection of corners takes place on a digital representation. To compensate for ambiguities arising from sampling problems due to the discreteness, results about the local behavior of curvature extrema in continuous scale-space are employed.	VIENNA TECH UNIV, INST AUTOMAT, DEPT PATTERN RECOGNIT & IMAGE PROC, A-1040 VIENNA, AUSTRIA	Technische Universitat Wien	FERMULLER, C (corresponding author), UNIV MARYLAND, CTR AUTOMAT RES, COMP VIS LAB, COLLEGE PK, MD 20742 USA.							ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; Aviad Z., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P417; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; FERMULLER C, 1989, 42 I IM PROC COMP GR; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; FISCHLER MA, 1993, P IEEE IMAGE UNDERST, P917; Goshtashby A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P351; HARTLEY R, 1983, CSTR1288 U MARYL CTR; KROPATSCH WG, 1985, PATTERN RECOGN LETT, V3, P315, DOI 10.1016/0167-8655(85)90062-5; KROPATSCH WG, 1987, PATTERN RECOGN LETT, V6, P179, DOI 10.1016/0167-8655(87)90005-5; LEYTON M, 1987, COMPUT VISION GRAPH, V38, P327, DOI 10.1016/0734-189X(87)90117-4; LINDENBERG T, 1991, THESIS ROY I TECHNOL; MEER P, 1988, PATTERN RECOGN, V21, P217, DOI 10.1016/0031-3203(88)90056-8; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PAVLIDIS T, 1977, IEEE T COMPUT, V26, P800, DOI 10.1109/TC.1977.1674918; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; RICHARDS W, 1985, COMPUT VISION GRAPH, V31, P265, DOI 10.1016/0734-189X(85)90031-3; RICHARDS W, 1986, J OPT SOC AM A, V3, P1483, DOI 10.1364/JOSAA.3.001483; SAUND E, 1990, IEEE T PATTERN ANAL, V12, P817, DOI 10.1109/34.57672; WITKIN AP, 1983, 7TH P INT JOINT C AR, P1019; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	23	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1994	16	7					748	751		10.1109/34.297957	http://dx.doi.org/10.1109/34.297957			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NY134		Green Submitted			2022-12-18	WOS:A1994NY13400009
J	BOYER, KL; SARKAR, S				BOYER, KL; SARKAR, S			ON THE LOCALIZATION PERFORMANCE-MEASURE AND OPTIMAL EDGE-DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EDGE DETECTION; OPTIMALITY CRITERIA; SCALE SPACE		In a recent paper, Tagare and deFigueiredo present a localization performance measure for edge detectors. They correctly point out a flaw in,Canny's formulation of the localization criterion, which was subsequently adopted by Sarkar and Boyer. They motivate their form of the localization criterion along a different line of reasoning. In this comment, ae show that although Canny's derivation was in error, the final form of his criterion is adequate and can, in fact, be derived from Tagare and deFigueiredo's formulation of the problem. We also point out some problems with Tagare and deFigueiredo's localization criterion.			BOYER, KL (corresponding author), OHIO STATE UNIV,DEPT ELECT ENGN,COLUMBUS,OH 43210, USA.		Sarkar, Sudeep/ABD-7629-2021; Sarkar, Sudeep/A-8213-2009	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207				CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; GRECO V, 1992, P SPIE CURVES SURFAC; SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275; TAGARE HD, 1990, IEEE T PATTERN ANAL, V12, P1186, DOI [10.1109/34.62607, 10.1117/12.19530]	4	7	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1994	16	1					106	110		10.1109/34.273710	http://dx.doi.org/10.1109/34.273710			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MV733					2022-12-18	WOS:A1994MV73300012
J	ARCHER, NP; WANG, SH				ARCHER, NP; WANG, SH			LEARNING BIAS IN NEURAL NETWORKS AND AN APPROACH TO CONTROLLING ITS EFFECTS IN MONOTONIC CLASSIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						BACKPROPAGATION; LEARNING BIAS, MONOTONICALLY SEPARABLE; MONOTONIC BOUNDARY; MONOTONICITY; NEURAL NETWORK		As a learning machine, a neural network using the back-propagation training algorithm is subject to learning bias. This results in unpredictability of boundary generation behavior in pattern recognition applications, especially in the case of small training sample size. This research sugests that in a large class of pattern recognition problems, such as managerial and other problems possessing monotonicity properties, the effect of learning bias can be controlled by using multiarchitecture monotonic function neural networks.	UNIV NEW BRUNSWICK,FAC BUSINESS,ST JOHN E2L 4L5,NB,CANADA	University of New Brunswick	ARCHER, NP (corresponding author), MCMASTER UNIV,SCH BUSINESS,HAMILTON L8S 4M4,ON,CANADA.							ALTMAN EI, 1968, J FINANC, V28, P589; ARCHER NP, 1993, DECISION SCI, V24, P60, DOI 10.1111/j.1540-5915.1993.tb00462.x; BARNARD E, 1989, IEEE T SYST MAN CYB, V19, P1030, DOI 10.1109/21.44018; CASASENT DP, 1990, APPL OPTICS, V29, P2603, DOI 10.1364/AO.29.002603; CHIEN YT, 1982, HDB STATISTICS, V2, P651; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; GREER CC, 1968, J RETAILING, V43, P44; Hand D. J, 1981, WILEY SERIES PROBABI; Kawabata T, 1991, NEURAL COMPUT, V3, P409, DOI 10.1162/neco.1991.3.3.409; Keeney R.L., 1976, DECISIONS MULTIPLE O, P96; KOHONEN T, 1988, P 1988 IEEE INT C NE, pI61; RAMANUJAM V, 1986, ACAD MANAGE J, V29, P347, DOI 10.2307/256192; Rumelhart D. E., 1988, PARALLEL DISTRIBUTED; SOULIE FF, 1987, 1ST P IEEE INT C NEU; Specht D F, 1990, IEEE Trans Neural Netw, V1, P111, DOI 10.1109/72.80210; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Utgoff P.E., 1986, MACHINE LEARNING ART, V2, P107; UTGOFF PE, 1986, MACHINE LEARNING IND; WIELAND A, 1987, 1ST P IEEE INT C NEU; [No title captured]	21	7	8	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					962	966		10.1109/34.232084	http://dx.doi.org/10.1109/34.232084			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600012
J	OOMMEN, BJ; ZGIERSKI, JR				OOMMEN, BJ; ZGIERSKI, JR			BREAKING SUBSTITUTION CYPHERS USING STOCHASTIC AUTOMATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CRYSTOGRAPHY; LEARNING AUTOMATA; RELAXATION METHODS; SUBSTITUTION CYPHERS		Let LAMBDA be a finite plaintext alphabet and V be a cypher alphabet with the same cardinality as LAMBDA. In all one-to-one substitution cyphers, there exists the property that each element in V maps onto exactly one element in LAMBDA and vice versa. This mapping of V onto A is represented by a function T*, which maps any v is-an-element-or V onto some lambda is-an-element-of LAMBDA (i.e., T*(v) = lambda). In this correspondence, we consider the problem of learning the mapping of T* (or its inverse (T*)-1) by processing a sequence of cypher text. The fastest reported method to achieve this is an elegant relaxation scheme due to Peleg et al. [8], [9] that utilizes the statistical information contained in the unigrams and trigrams of the plaintext language. In this correspondence, we present a new learning automaton solution to the problem called the cypher learning automaton (CLA). The proposed scheme is fast, and the advantages of the scheme in terms of time and space requirements over the relaxation method have been listed. The correspondence contains simulation results comparing both cypher-breaking techniques.			OOMMEN, BJ (corresponding author), CARLETON UNIV, SCH COMP SCI, OTTAWA K1S 5B6, ONTARIO, CANADA.		Oommen, B. John/P-6323-2017	Oommen, B. John/0000-0002-5105-1575				DENNING DER, 1983, CRYPTOGRAPHY DATA SE; Dewey G., 1923, RELATIVE FREQUENCY E; HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830; KIRBY RL, 1980, COMPUT VISION GRAPH, V13, P158, DOI 10.1016/S0146-664X(80)80038-4; LAKSHMIVARAHAN S, 1981, LEARNING ALGORITHMS; Narendra K. S., 1989, LEARNING AUTOMATA IN; NARENDRA KS, 1974, IEEE T SYST MAN CYB, VSMC4, P323, DOI 10.1109/TSMC.1974.5408453; OOMMEN BJ, 1988, IEEE T COMPUT, V37, P2, DOI 10.1109/12.75146; OOMMEN BJ, SCSTR182 CARL U SCH; PELEG S, 1979, COMMUN ACM, V22, P598, DOI 10.1145/359168.359174; PELEG S, 1979, AUG P IEEE C PATT RE, P337; Tsetlin M.L, 1973, AUTOMATON THEORY MOD; Yu C. T., 1981, Proceedings of COMPSAC 81. IEEE Computer Society's Fifth International Computer Software & Applications Conference, P81	13	7	7	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					185	192		10.1109/34.192492	http://dx.doi.org/10.1109/34.192492			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KL910					2022-12-18	WOS:A1993KL91000011
J	RANGARAJAN, K; SHAH, M				RANGARAJAN, K; SHAH, M			INTERPRETATION OF MOTION TRAJECTORIES USING FOCUS OF EXPANSION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DYNAMIC SCENE ANALYSIS; FOCUS OF EXPANSION; MOTION; TRAJECTORIES	OPTICAL-FLOW	The focus of expansion (FOE) of a group of motion trajectories is defined to be a point in the image plane at which the trajectories intersect when they are extended. The FOE observed over a time sequence defines the locus of FOE. We present an analytical approach for the study of dynamic events as they project on the image plane by analyzing the locus of FOE. We have found that the locus of FOE can be used to make qualitative assertions regarding the type of motion. An interesting behavior of the locus of FOE for various types of motion is observed. The cases include a single point, a horizontal, a vertical, and a slopped straight line. We can also determine whether the object has approaching and receding motion or when the object changes its direction of motion. This inference may be used in qualitative computer vision.			RANGARAJAN, K (corresponding author), UNIV CENT FLORIDA,DEPT COMP SCI,ORLANDO,FL 32816, USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ANANDAN P, 1987, THESIS U MASS AMHERS; BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; BURGHARD W, 1989, KRIMINALISTIK, P563; DUTTA R, 1988, APR P DARPA IM UND W, P945; JAIN R, 1983, IEEE T PATTERN ANAL, V5, P58, DOI 10.1109/TPAMI.1983.4767345; LAWTON DT, 1983, COMPUT VISION GRAPH, V22, P116, DOI 10.1016/0734-189X(83)90098-1; MAGEE MJ, 1984, COMPUT VISION GRAPH, V26, P256, DOI 10.1016/0734-189X(84)90188-9; NEGAHDARIPOUR S, 1989, COMPUT VISION GRAPH, V46, P303, DOI 10.1016/0734-189X(89)90035-2; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6	10	7	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1992	14	12					1205	1210		10.1109/34.177386	http://dx.doi.org/10.1109/34.177386			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KC573					2022-12-18	WOS:A1992KC57300007
J	WANG, W; IYENGAR, SS				WANG, W; IYENGAR, SS			EFFICIENT DATA-STRUCTURES FOR MODEL-BASED 3-D OBJECT RECOGNITION AND LOCALIZATION FROM RANGE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CAD-BASED VISION; GEOMETRIC MODELING; IMAGE PROCESSING; MODEL-BASED MACHINE VISION; RANGE IMAGE UNDERSTANDING; SURFACE CURVATURE; SURFACE SHAPE; 3-D OBJECT RECOGNITION AND LOCALIZATION		This paper defines and investigates a fundamental problem in computer vision: recognition and localization of multiple free-form 3-D objects in range images. This facility is important in an automated manufacturing environment in the industry. The emphasis throughout this paper will be on the design of efficient data structures and algorithms. The principal results of our work are as follows: Surfaces are characterized by surface curvatures derived from geometric models of objects. Surface shapes and a knowledge representation scheme are uniquely defined and used in the search for corresponding surfaces of an object, based on an ordered feature space. Knowledge about model surface shapes is automatically abstracted from CAD models, and these models are also used directly in the vision process. Our technique will recognize objects by hypothesizing and locating them. Knowledge about object surface shapes is used to infer hypotheses, and CAD models are used to locate objects. One of the most important problems in 3-D machine vision is the recognition of objects from their partial view due to occlusion. Our approach is surface based and is not sensitive to noise or occlusion. A test system called free-form object recognition and localization (FORL) was implemented and tested on synthetic images.	LOUISIANA STATE UNIV,DEPT COMP SCI,BATON ROUGE,LA 70803	Louisiana State University System; Louisiana State University	WANG, W (corresponding author), METAPHOR COMP SYST,MT VIEW,CA, USA.							BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BHANU B, 1989, PATTERN RECOGN, V22, P49, DOI 10.1016/0031-3203(89)90038-1; BOLLES RC, 1987, 3 DIMENSIONAL MACHIN; Brooks R., 1984, MODEL BASED COMPUTER; DEWEY BR, 1988, COMPUTER GRAPHICS EN; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P114, DOI 10.1109/34.67642; Foley J.D., 1984, FUNDAMENTALS INTERAC; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P1201, DOI 10.1109/34.106994; GRIMSON WEL, 1987, 3 DIMENSIONAL MACHIN; GUNNARSSON KT, 1987, COMPUTER, P66; HSIUNG CC, 1981, 1ST COURSE DIFFERENT; Lipschutz M., 1969, DIFFERENTIAL GEOMETR; ROBERTS LG, 1965, OPT ELECTROOPT INFOR; VAISMAN I, 1984, 1ST COURSE DIFFERENT; VEMURI BC, 1988, IEEE C COMPUT VISION, P893; WANG W, 1989, PATTERN RECOGN, V22, P505, DOI 10.1016/0031-3203(89)90020-4; WANG W, 1989, THESIS LOUISIANA STA; WONG AKC, 1989, IEEE T PATTERN ANAL, V11, P643; [No title captured]	19	7	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1992	14	10					1035	1045		10.1109/34.159905	http://dx.doi.org/10.1109/34.159905			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR944					2022-12-18	WOS:A1992JR94400005
J	VENKATESH, SS; PSALTIS, D				VENKATESH, SS; PSALTIS, D			ON RELIABLE COMPUTATION WITH FORMAL NEURONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CAPACITY; COMPUTATION; FAULT-TOLERANCE; FORMAL NEURONS; LARGE DEVIATIONS; RELIABILITY	ASSOCIATIVE MEMORY; CAPACITY; MODEL	We investigate the computing capabilities of formal McCulloch-Pitts neurons when errors are permitted in decisions. Specifically, given a random m-set of points u1, ..., u(m) is-an-element-of R(X), a corresponding m-set of decisions d1, ..., d(m) is-an-element-of { - 1, 1}, and a fractional error-tolerance O less-than-or-equal-to is-an-element-of < 1, we are interested in the following question: How large can we choose m such that a formal neuron can make assignments u-alpha --> d-alpha, with no more than epsilon-m errors? We obtain formal results for two protocols for error-tolerance-a random error protocol and an exhaustive error protocol. In the random error protocol, a random subset of the m points is randomly and independently specified and the associated decisions labeled "don't care." We prove that if m is chosen less than 2n/(1-2-epsilon), then with high probability, there is a choice of weights for which the expected number of decision errors made by the neuron is no more than epsilon-m; if m is chosen larger than 2n/(1 - 2-epsilon), then the probability approaches zero that there is a choice of synaptic weights for which the expected number of decision errors made by the neuron is fewer than epsilon-m. In the exhaustive error protocol, the total number of decision errors has to lie below epsilon-m, but we are allowed to choose the set of decisions that are in error. We show that there is a function 1 less-than-or-equal-to kappa-epsilon < 505 such that if m exceeds 2-kappa-epsilon-n/(1 - 2-epsilon), then there is, with high probability, no choice of synaptic weights for which a neuron makes fewer than epsilon-m decision errors on the m-set of inputs. For small epsilon, the function kappa-epsilon is close to 1 so that, informally, we can specify m-sets as large as 2n/(1 - 2-epsilon) (but not larger) and obtain reliable decisions within the prescribed tolerance for some suitable choice of weights.	CALTECH,DEPT ELECT ENGN,PASADENA,CA 91125	California Institute of Technology	VENKATESH, SS (corresponding author), UNIV PENN,MOORE SCH ELECT ENGN,PHILADELPHIA,PA 19104, USA.							ABUMOSTAFA YS, 1985, IEEE T INFORM THEORY, V31, P461, DOI 10.1109/TIT.1985.1057069; [Anonymous], 1962, MATH SCAND; BALDI P, 1988, NEURAL INFORMATION P; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; Feller W., 1968, INTRO PROBABILITY TH, V1; FUREDI Z, 1986, DISCRETE COMPUT GEOM, V1, P315, DOI 10.1007/BF02187704; KOMLOS J, 1988, NEURAL NETWORKS, V1, P239, DOI 10.1016/0893-6080(88)90029-9; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; MCELIECE RJ, 1987, IEEE T INFORM THEORY, V33, P461, DOI 10.1109/TIT.1987.1057328; NEWMAN CM, 1988, NEURAL NETWORKS, V1, P233; PSALTIS D, 1989, EVOLUTION LEARNING C; SCHLAFLI L, 1950, GESAMMELTE MATH ABHA, V1, P209; VENKATESH S, 1986, THESIS CALTECH; VENKATESH SS, 1989, IEEE T INFORM THEORY, V35, P558, DOI 10.1109/18.30977; VENKATESH SS, 1992, IN PRESS IEEE T KNOW; VENKATESH SS, 1986, NEURALNETWORKS COMPU	17	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1992	14	1					87	91		10.1109/34.107015	http://dx.doi.org/10.1109/34.107015			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GV942					2022-12-18	WOS:A1992GV94200006
J	CARLSON, BA; CLEMENTS, MA				CARLSON, BA; CLEMENTS, MA			A COMPUTATIONALLY COMPACT DIVERGENCE MEASURE FOR SPEECH PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CENTROID COMPUTATION; COMPUTATIONAL EFFICIENCY; DIVERGENCE; ITAKURA-SAITO; SPEECH PROCESSING		The directed divergence, which is a measure based on the discrimination information between two signal classes, is investigated. A simplified expression for computing the directed divergence is derived for comparing two Gaussian autoregressive processes such as those found in speech. This expression alleviates both the computational cost (reduced by two thirds) and the numerical problems encountered in computing the directed divergence. In addition, the simplified expression is compared with the Itakura-Saito distance (which asymptotically approaches the directed divergence). Although the expressions for these two distances closely resemble each other, only moderate correlations between the two were found on a set of actual speech data.			CARLSON, BA (corresponding author), GEORGIA INST TECHNOL,SCH ELECT ENGN,ATLANTA,GA 30332, USA.							GERSCH W, 1979, SCI, V34, P193; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849; GRAY RM, 1980, IEEE T ACOUST SPEECH, V28, P367, DOI 10.1109/TASSP.1980.1163421; GRAY RM, 1981, IEEE T INFORM THEORY, V27, P708, DOI 10.1109/TIT.1981.1056410; ITAKURA F, 1968, 6TH P INT C AC TOK, pC17; JOHNSON RW, 1979, IEEE T INFORM THEORY, V25, P709, DOI 10.1109/TIT.1979.1056113; KULLBACK S, 1968, INFORMATION THEORY S; LEVINSON S, 1980, IEEE T COMMUN, V28, P84; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Marple S.L., 2019, DIGITAL SPECTRAL ANA, VSecond; SHORE JE, 1981, IEEE T ACOUST SPEECH, V29, P230, DOI 10.1109/TASSP.1981.1163539	14	7	7	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1991	13	12					1255	1260		10.1109/34.106999	http://dx.doi.org/10.1109/34.106999			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GT950					2022-12-18	WOS:A1991GT95000007
J	HOCHBERG, J; MNISZEWSKI, SM; CALLEJA, T; PAPCUN, GJ				HOCHBERG, J; MNISZEWSKI, SM; CALLEJA, T; PAPCUN, GJ			A DEFAULT HIERARCHY FOR PRONOUNCING ENGLISH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ARTIFICIAL INTELLIGENCE; DEFAULT HIERARCHIES; DEFAULT REASONING; INDUCTION; KNOWLEDGE REPRESENTATION; LEARNING; SPEECH SYNTHESIS; SPELLING		In this correspondence, we study the principles governing the power and efficiency of the default hierarchy, a system of knowledge acquisition and representation. The default hierarchy consists of clear and accessible rules, like an expert-made system, but trains automatically when exposed to data, like a neural network. The hierarchy has both general (default) and specific rules. In training, specific rules are learned only if they are exceptions to general rules; in using the hierarchy, default rules are used when no relevant specific rules are found. Our application of the default hierarchy to the task of pronouncing written English reveals interesting properties of the default hierarchy architecture. We find that the hierarchy performs best when there is free access to general rules, and that it is less than 1/4 the size of a comparable nonhierarchial rule set while no less accurate in pronunciation. Evaluating the hierarchy as a pronouncer of English, we find that its rules capture several key features of English spelling. Moreover, the default hierarchy pronounces English better than the neural network NETtalk, and almost as well as expert-devised systems (DECtalk and the Naval Research Laboratory's pronunciation system).			HOCHBERG, J (corresponding author), UNIV CALIF LOS ALAMOS SCI LAB,LOS ALAMOS,NM 87545, USA.							AN ZG, 1988, P IEEE INT C NEURAL, V2, P221; Bloomfield Leonard, 1933, LANGUAGE; Brachman R.J., 1979, ASS NETWORKS REPRESE, P3, DOI 10.1016/B978-0-12-256380-5.50007-4; Carroll JohnB., 1967, COMPUTATIONAL ANAL P; DAVIS AR, 1990, LAUR901614 REP; ELOVITZ HS, 1976, IEEE T ACOUST SPEECH, V24, P446, DOI 10.1109/TASSP.1976.1162873; Fahlman SE., 1979, NETL SYSTEM REPRESEN; HOLLAND J, 1975, ADAPTATION NATURAL A; HUNNICUTT S, 1976, AM J COMPUTAT, V57; KLATT DH, 1982, INT C ACOUST SPEECH, P1589; MacWhinney Brian, 1978, MONOGRAPHS SOC RES C, V43; MEDDIS R, 1984, STATISTICS USING RAN; Minsky Marvin, 1981, MIND DESIGN, P95; MNISZEWSKI SM, 1990, LAUR902019 LOS ANG N; Quillian MR, 1968, SEMANTIC INFORMATION, P216; REITER R, 1980, ARTIF INTELL, V13, P81, DOI 10.1016/0004-3702(80)90014-4; SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523; Sejnowski T. J., 1987, Complex Systems, V1, P145; Stanfill C., 1986, Communications of the ACM, V29, P1213, DOI 10.1145/7902.7906; Touretzky, 1984, P AAAI 84 AUSTIN, P322; VENEZKY R, 1970, STRUCTURE ENGLISH OR	21	7	7	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1991	13	9					957	964		10.1109/34.93813	http://dx.doi.org/10.1109/34.93813			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GJ180					2022-12-18	WOS:A1991GJ18000009
J	AISBETT, J				AISBETT, J			AN ITERATED ESTIMATION OF THE MOTION PARAMETERS OF A RIGID BODY FROM NOISY DISPLACEMENT VECTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											AISBETT, J (corresponding author), DEF SCI & TECHNOL ORG,ELECTR RES LAB,POB 1600,SALISBURY,SA 5108,AUSTRALIA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P3841; AISBETT J, 1989, IEEE T PATTERN A MAY; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; FANG JQ, 1984, COMPUT VISION GRAPH, V26, P183, DOI 10.1016/0734-189X(84)90182-8; FAUGERAS OD, 1986, 3RD P INT S ROB RES, P33; FAUGERAS OD, 1987, 1ST P INT C COMP VIS, P25; HOAGUN DC, 1983, UNDERSTANDING ROBUST; JOBSON JD, 1980, J AM STAT ASSOC, V75, P176, DOI 10.2307/2287408; KANATANI K, 1987, COMPUT VISION GRAPH, V38, P122, DOI 10.1016/S0734-189X(87)80133-0; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; MATTHIES L, 1987, IEEE T ROBOTIC AUTOM, V3, P239, DOI 10.1109/JRA.1987.1087097; NEGAHDARIPOUR S, 1987, MIT AI940 MEM; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SUBBARAO M, 1986, COMPUT VISION GRAPH, V36, P208, DOI 10.1016/0734-189X(86)90076-9; TOSCANI G, 1987, MAR P IEEE INT C ROB, P221; TOSCANI G, 1987, 1ST P IASTED INT S S, P623; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; Weng J., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P381, DOI 10.1109/CVPR.1988.196263; WILLIAMS TD, 1980, IEEE T PATTERN ANAL, V2, P511, DOI 10.1109/TPAMI.1980.6447697; YASUMOTO Y, 1986, IEEE T PATTERN ANAL, V8, P464, DOI 10.1109/TPAMI.1986.4767810	22	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1092	1098		10.1109/34.61709	http://dx.doi.org/10.1109/34.61709			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700007
J	MORRIS, RJT; RUBIN, LD; TIRRI, H				MORRIS, RJT; RUBIN, LD; TIRRI, H			NEURAL NETWORK TECHNIQUES FOR OBJECT ORIENTATION DETECTION - SOLUTION BY OPTIMAL FEEDFORWARD NETWORK AND LEARNING VECTOR QUANTIZATION APPROACHES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV HELSINKI,DEPT COMP SCI,SF-00100 HELSINKI 10,FINLAND	University of Helsinki	MORRIS, RJT (corresponding author), AT&T BELL LABS,HOLMDEL,NJ 07733, USA.			MORRIS, ROBERT/0000-0001-8320-2393				CHOU JH, 1985, J MATH ANAL APPL, V105, P383, DOI 10.1016/0022-247X(85)90055-1; CORLEY HW, 1987, J MATH ANAL APPL, V127, P193, DOI 10.1016/0022-247X(87)90151-X; DUDA RO, 1973, PATTERN ANAL SCENE; GASS SI, 1969, LINEAR PROGRAMMING M; HECHTNIELSEN R, 1987, NEURAL COMPUTERS, P445; HELSTROM CW, 1968, STATISTICAL THEORY S; HUANG WY, 1988, 1987 P C NEUR INF PR; KOHONEN T, COMMUNICATION; Kohonen T., 1988, SELF ORG ASS MEMORY; KOHONEN T, 1988, JUL IEEE INT C NEUR; Lippman R. P., 1987, IEEE ASSP MAGAZI APR, P4; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; Minsky M., 1988, PERCEPTRONS; MORRIS RJT, 1979, J MATH ANAL APPL, V70, P546, DOI 10.1016/0022-247X(79)90064-7; REINGOLD EM, 1977, COMBINATORIAL ALGORI; Rosenblatt F., 1961, PRINCIPLES NEURODYNA, DOI 10.21236/AD0256582; Rumelhart D. E., 1988, PARALLEL DISTRIBUTED; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; SPECHT DF, 1988, JUL IEEE INT C NEUR; Wald A., 1947, SEQUENTIAL ANAL	20	7	9	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1107	1115		10.1109/34.61712	http://dx.doi.org/10.1109/34.61712			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700010
J	SILVERMAN, BW; JENNISON, C; STANDER, J; BROWN, TC				SILVERMAN, BW; JENNISON, C; STANDER, J; BROWN, TC			THE SPECIFICATION OF EDGE PENALTIES FOR REGULAR AND IRREGULAR PIXEL IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV WESTERN AUSTRALIA,DEPT MATH,NEDLANDS,WA 6009,AUSTRALIA	University of Western Australia	SILVERMAN, BW (corresponding author), UNIV BATH,SCH MATH SCI,BATH BA2 7AY,AVON,ENGLAND.		Brown, Timothy/ABC-1300-2020; Silverman, Bernard W/K-6417-2012	Brown, Timothy/0000-0001-6997-0599; Silverman, Bernard W/0000-0002-4059-2376; Stander, Julian/0000-0002-1429-9862				BESAG J, 1986, J R STAT SOC B, V48, P259; DORST L, 1986, IEEE T PATTERN ANAL, V8, P276, DOI 10.1109/TPAMI.1986.4767781; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Hocking J.G., 1961, TOPOLOGY; JENNISON C, 1991, IN PRESS ESSAYS STAT; SILVERMAN BW, 1990, J ROY STAT SOC B MET, V52, P271; SILVERMAN BW, 1985, J R STAT SOC B, V47, P1; Silverman BW, 1985, ENCY STAT SCI, V6, P664	8	7	7	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1990	12	10					1017	1024		10.1109/34.58874	http://dx.doi.org/10.1109/34.58874			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EA042					2022-12-18	WOS:A1990EA04200008
J	LEE, SY; AGGARWAL, JK				LEE, SY; AGGARWAL, JK			A SYSTEM-DESIGN SCHEDULING STRATEGY FOR PARALLEL IMAGE-PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV TEXAS,COLL ENGN,COMP & VIS RES CTR,AUSTIN,TX 78712	University of Texas System; University of Texas Austin								AGGARWAL JK, 1981, P IEEE, V69, P562, DOI 10.1109/PROC.1981.12025; ANTONSSON D, 1981, NOV P WORKSH PICT DA, P295; AVIITZHAK B, 1965, MANAGE SCI, V11, P553, DOI 10.1287/mnsc.11.5.553; BATCHER KE, 1980, IEEE T COMPUT, V29, P836, DOI 10.1109/TC.1980.1675684; BRUELL SC, COMPUTATIONAL ALGORI; Duff M.J.B., 1978, P NATIONAL COMPUTER, P1055; FRIEDMAN HD, 1985, OPER RES, P121; Gonzalez R.C., 1977, DIGITAL IMAGE PROCES; HILLER FS, 1966, OPER RES, P287; HUNT GC, 1956, OPER RES, V4, P674, DOI 10.1287/opre.4.6.674; HWANG K, 1983, IEEE COMPUT, V16; JACKSON JR, 1957, OPER RES, V5, P518, DOI 10.1287/opre.5.4.518; JACKSON RRP, 1956, J ROY STAT SOC B MET, P129; Kleinrock L., 1975, QUEUEING SYST; KONHEIM AG, 1976, J ACM, V23, P328, DOI 10.1145/321941.321952; KUNG HT, 1986, DISTRIBUTED COMPUT, P246; LEE SY, 1987, PATTERN RECOGN, V20, P115, DOI 10.1016/0031-3203(87)90022-7; LEE SY, 1987, IEEE T PATTERN ANAL, V9, P590, DOI 10.1109/TPAMI.1987.4767947; LEE SY, 1986, 2ND P C HYP MULT KNO, P426; LEE SY, 1985, NOV P IEEE INT C SYS, P680; LUETJEN K, 1980, 5TH P INT C PATT REC, P326; MAKINO T, 1964, J OPER RES JAPAN, V7, P14; Mead C, 1980, INTRO VLSI SYSTEMS; NARENDRA P, 1981, SPR P COMPCON, P303; Peterson J. L., 1981, HDB PROCEDURES DESIG; REICH E, 1957, ANN MATH STAT, P768; SHOCH JF, 1982, IEEE COMPUT      AUG, P10; STALLINGS W, 1984, LOCAL NETWORKS INTRO; STERNBERG SR, 1981, AUG P PATT REC IM PR, P374; VERGHESE G, 1986, 668 U WISC COMP SCI; YALAMANCHILI S, 1985, PROGR PATTERN RECOGN, V2, P1	31	7	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1990	12	2					194	204		10.1109/34.44405	http://dx.doi.org/10.1109/34.44405			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CL282					2022-12-18	WOS:A1990CL28200007
J	SANZ, JLC; HUANG, TT				SANZ, JLC; HUANG, TT			IMAGE REPRESENTATION BY SIGN INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SANZ, JLC (corresponding author), IBM CORP, ALMADEN RES CTR, DEPT COMP SCI, RES LAB, SAN JOSE, CA 95120 USA.							BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; CAMPBELL FW, 1968, J PHYSIOL-LONDON, V197, P551, DOI 10.1113/jphysiol.1968.sp008574; CURTIS S, 1985, THESIS MIT; CURTIS SR, 1985, IEEE T ACOUST SPEECH, V33, P643, DOI 10.1109/TASSP.1985.1164589; FIENUP JR, J OPT SOC AM, P40; FUKS B, 1963, INTRO THEORY ANAL FU, V8; GERCHBERG RW, 1972, OPTIK, V35, P237; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; Hormander L., 1962, LINEAR PARTIAL DIFFE; HUANG TT, UNPUB IEEE T ASSP; HUANG TT, 1987, APR INT C ASSP DALL; HUMMEL RA, 1986, IEEE P COMPUT VISION, P204; IZRAELEVITZ D, 1986, DIGEST TOPICAL M SIG; LANE R, IN PRESS IEEE T ACOU; LAWTON W, IN PRESS J OPT SOC A; LEVINSON N, 1940, AM MATH SOC C PUBLIC, V26, P25; LOGAN B, 1984, AT&T TECH J, P287; LOGAN BF, 1977, AT&T TECH J, V56, P487, DOI 10.1002/j.1538-7305.1977.tb00522.x; LOGAN BF, 1984, AT&T TECH J, V63, P261, DOI 10.1002/j.1538-7305.1984.tb00094.x; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARR D, 1979, J OPT SOC AM, V69, P914, DOI 10.1364/JOSA.69.000914; Marr D., 1982, VISION; MOSTOWSKI A, 1964, INTRO HIGHER ALGEBRA; NEVATIA R, 1986, COMMUNICATION; OSGOOD WF, 1965, FUNKTIONENTHEORIE, V2; REIMER J, 1987, APR IEEE INT C ASSP; Ronkin L.i., 1974, INTRO THEORY ENTIRE, V44; ROTEM D, 1986, IEEE T ACOUST SPEECH, V34, P1269, DOI 10.1109/TASSP.1986.1164922; SANZ JLC, 1983, J OPT SOC AM, V73, P1442, DOI 10.1364/JOSA.73.001442; SANZ JLC, 1983, J OPT SOC AM, V73, P1446, DOI 10.1364/JOSA.73.001446; SANZ JLC, 1985, IEEE T ACOUST SPEECH, V33, P997, DOI 10.1109/TASSP.1985.1164646; SANZ JLC, IN PRESS SIAM J APPL; SHAH M, 1985, RSDTR785 U MICH CENT; SHITZ S, 1985, IEEE T ACOUST SPEECH, V33, P1486, DOI 10.1109/TASSP.1985.1164733; VOELCKER HB, 1973, IEEE T COMMUN, VCO21, P738, DOI 10.1109/TCOM.1973.1091718; WILSON HR, 1979, VISION RES, V19, P19, DOI 10.1016/0042-6989(79)90117-2; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YOUNG R, 1986, RES PUBL COMP SCI DE; YUILLE AL, 1985, J OPT SOC AM A, V2, P683, DOI 10.1364/JOSAA.2.000683; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]; ZAKHOR A, 1986, P IEEE, V74, P1285, DOI 10.1109/PROC.1986.13622	41	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1989	11	7					729	738		10.1109/34.192467	http://dx.doi.org/10.1109/34.192467			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AB815					2022-12-18	WOS:A1989AB81500006
J	SHAH, YC; CHAPMAN, R; MAHANI, RB				SHAH, YC; CHAPMAN, R; MAHANI, RB			A NEW TECHNIQUE TO EXTRACT RANGE INFORMATION FROM STEREO IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									CITY UNIV LONDON,LONDON EC1V 0HB,ENGLAND	City University London	SHAH, YC (corresponding author), PA TECHNOL,CAMBRIDGE LAB,ROYSTON 5G8 6DP,HERTS,ENGLAND.							ARNOLD RD, 1980, SPIE, V238, P281; BAKER HH, 1981, 7TH P INT JOINT C AR, V2, P631; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BENARD M, 1983, P EURASIP ERLANGEN, P227; BENNETT VP, 1973, 39 P ASP ANN M, P1; BROWN DC, 1972, 12TH P C INT SOC PHO; BROWN DC, 1971, P S CLOSE RANGE PHOT; CHONG AM, 1982, P IRE C MANCHESTER, P95; DOWMAN IJ, 1977, P INT S IMAGE PROCES, P47; HARDY JG, 1973, P TECHNIQUES APPLICA, P95; JULESZ B, 1971, F CYCLOPEAN PERCEPTI; LLOYD SA, 1985, GEC-J RES, V3, P18; MAHEW JEW, 1980, PERCEPTION, V9, P69; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MARR D, 1977, MIT AI451 ART INT LA; Nagata S, 1982, Iyodenshi To Seitai Kogaku, V20, P154; QUAM LH, 1984, P DARPA IMAGE UNDERS, P211; REAL RR, 1987, IEEE T INSTRUM MEAS, V33, P45; SHAH Y, 1985, OPT LASER ENG, V6, P125, DOI 10.1016/0143-8166(85)90021-1; SIDNEY L, 1981, P TECHNIQUES APPLICA, V281, P332; WONG KW, 1968, CIVIL ENG STUDIES PH, V16; Yagi, 1973, COMPUT VISION GRAPH, V2, P131	22	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1989	11	7					768	773		10.1109/34.192472	http://dx.doi.org/10.1109/34.192472			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AB815					2022-12-18	WOS:A1989AB81500011
J	KANATANI, K				KANATANI, K			3D EUCLIDEAN VERSUS 2D NON-EUCLIDEANT - 2 APPROACHES TO 3D RECOVERY FROM IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											KANATANI, K (corresponding author), GUNMA UNIV,DEPT COMP SCI,KIRYU,GUNMA 376,JAPAN.							CHOU TC, 1987, 1ST P INT C COMP VIS, P534; DEMENTHON D, 1987, APR P IEEE INT C ROB, P1444; Gibson J., 1979, ECOLOGICAL APPROACH; KANATANI K, 1987, COMPUT VISION GRAPH, V38, P122, DOI 10.1016/S0734-189X(87)80133-0; KANATANI K, 1986, COMPUT VISION GRAPH, V35, P181, DOI 10.1016/0734-189X(86)90026-5; KANATANI K, 1988, COMPUT VISION GRAPH, V41, P28, DOI 10.1016/0734-189X(88)90115-6; KANATANI K, 1987, 1ST P IEEE INT C COM, P55; KANATANI K, 1989, J INFORM PROCESS, V12; KANATANI KI, 1988, IEEE T PATTERN ANAL, V10, P131, DOI 10.1109/34.3879; KANATANI KI, 1987, COMPUT VISION GRAPH, V39, P328, DOI 10.1016/S0734-189X(87)80185-8; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; Marr D., 1982, VISION COMPUTATIONAL; NAGEL HH, 1981, COMPUTER, V14, P29, DOI 10.1109/C-M.1981.220560; SAKURAI K, 1987, 1ST P IEEE INT C COM, P651; SILBERBERG TM, 1986, COMPUT VISION GRAPH, V35, P47, DOI 10.1016/0734-189X(86)90125-8; SUBBARAO M, 1986, COMPUT VISION GRAPH, V36, P208, DOI 10.1016/0734-189X(86)90076-9; SUGIHARA K, 1984, COMPUT VISION GRAPH, V27, P309, DOI 10.1016/0734-189X(84)90034-3; THORPE C, 1988, IEEE T PATTERN ANAL, V10, P362, DOI 10.1109/34.3900; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; TURK MA, 1988, IEEE T PATTERN ANAL, V10, P342, DOI 10.1109/34.3899; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WAXMAN AM, 1987, IEEE T ROBOTIC AUTOM, V3, P124, DOI 10.1109/JRA.1987.1087089	23	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					329	332		10.1109/34.21802	http://dx.doi.org/10.1109/34.21802			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840					2022-12-18	WOS:A1989T384000013
J	SRIRAMAN, R; KOPLOWITZ, J; MOHAN, S				SRIRAMAN, R; KOPLOWITZ, J; MOHAN, S			TREE SEARCHED CHAIN CODING FOR SUBPIXEL RECONSTRUCTION OF PLANAR CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									CLARKSON UNIV,DEPT ELECT & COMP ENGN,POTSDAM,NY 13676	Clarkson University	SRIRAMAN, R (corresponding author), NW INSTRUMENT SYST INC,BLDG D4,SUITE 200,19545 NW VON NEUMANN DR,BEAVERTON,OR 97006, USA.			Mohan, Seshadri/0000-0002-8757-9988				ANDERSON JB, 1984, IEEE COMMUN, V32; ANDERSON JB, 1975, IEEE T INFORM TH JUL; FREEMAN H, 1974, COMPUT SURVEYS, V6; FREEMAN H, 1969, IEEE T SYST SCI CYBE, V5; GOODMAN DJ, 1969, BELL SYST TECH J, V48; KOPLOWITZ J, 1981, IEEE T PATTERN ANAL, V3; LITTLE WD, 1974, IEEE T COMPUT, V23; MOHAN S, 1986, IEEE T COMMUN, V34, P1218, DOI 10.1109/TCOM.1986.1096478; NEUHOFF DL, 1985, IEEE T INFORM THEORY, V31; SPANG HA, 1962, IRE T COMMUN SYST, V10	10	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1989	11	1					95	104		10.1109/34.23116	http://dx.doi.org/10.1109/34.23116			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R4474					2022-12-18	WOS:A1989R447400008
J	JANSEN, BH; CHENG, WK				JANSEN, BH; CHENG, WK			CLASSIFICATION OF SLEEP PATTERNS BY MEANS OF MARKOV MODELING AND CORRESPONDENCE-ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											JANSEN, BH (corresponding author), UNIV HOUSTON,DEPT ELECT ENGN,UNIV PK,HOUSTON,TX 77004, USA.							BOWE TR, 1979, PSYCHOPHYSIOLOGY, V16, P41, DOI 10.1111/j.1469-8986.1979.tb01436.x; BURTSCHY B, 1977, 4TH P IJC PATT REC K, P276; GELSEMA ES, 1982, 6TH P IJC PATT REC M; GREENACRE MJ, 1984, THEORY APPLICATIONS; [No title captured]	5	7	7	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					707	710		10.1109/TPAMI.1987.4767968	http://dx.doi.org/10.1109/TPAMI.1987.4767968			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869432				2022-12-18	WOS:A1987J739300015
J	DEMORI, R; LAM, L; GILLOUX, M				DEMORI, R; LAM, L; GILLOUX, M			LEARNING AND PLAN REFINEMENT IN A KNOWLEDGE-BASED SYSTEM FOR AUTOMATIC SPEECH RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CONCORDIA UNIV,DEPT COMP SCI,MONTREAL H3G 1M8,QUEBEC,CANADA; CTR NATL ETUD TELECOMMUN,F-22301 LANNION,FRANCE	Concordia University - Canada	DEMORI, R (corresponding author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3A 2K6,QUEBEC,CANADA.							BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P177; Brownston L., 1985, PROGRAMMING EXPERT S; BUSH M, 1985, P IEEE INT C ACOUST, P1197; COLE RA, 1984, PERFORMING FINE PHON; DEMORI R, 1985, IEEE T PATTERN ANAL, V6, P56; DEMORI R, P INT JOINT C ARTIFI, P876; ERMAN LD, 1980, COMPUT SURV, V12, P213, DOI 10.1145/356810.356816; KOPEC GE, 1985, IEEE T ACOUST SPEECH, V33, P850, DOI 10.1109/TASSP.1985.1164652; LAIRD JE, 1984, CMUCS84129 CARN U DE; LEVINSON SE, 1979, IEEE T ACOUST SPEECH, V27, P134, DOI 10.1109/TASSP.1979.1163222; MERLO E, 1986, APR P INT C AC SPEEC, P1597; NOCERINO N, 1985, MAR P IEEE INT C AC, P25; ROSENBERG AE, 1983, IEEE T ACOUST SPEECH, V31, P713, DOI 10.1109/TASSP.1983.1164132; SACERDOTI ED, 1975, SEP P INT JOINT C AR, P115; STEFIK MJ, 1980, STANCS80784 DEP COMP; WHITEHILL SB, 1980, P AAAI 80, P240; WILKINS DE, 1984, ARTIF INTELL, V22, P269, DOI 10.1016/0004-3702(84)90053-5	17	7	8	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					289	305		10.1109/TPAMI.1987.4767902	http://dx.doi.org/10.1109/TPAMI.1987.4767902			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869398				2022-12-18	WOS:A1987G163300009
J	PETKOVIC, D; HINKLE, EB				PETKOVIC, D; HINKLE, EB			A RULE-BASED SYSTEM FOR VERIFYING ENGINEERING SPECIFICATIONS IN INDUSTRIAL VISUAL INSPECTION APPLICATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											PETKOVIC, D (corresponding author), IBM CORP,ALMADEN RES CTR,DEPT COMP SCI,SAN JOSE,CA 95120, USA.							BARR A, 1981, HDB ARTIFICIAL INTEL, V1, P190; CHIN R, 1982, IEEE T PATTERN ANAL, V4; DOUGLASS R, 1985, IEEE SOFTWARE    MAY, P70; KIBLER D, 1985, 9TH P INT JOINT C AR; Knuth D., 1973, ART COMPUTER PROGRAM, V2nd; MCKEOWN DM, 1985, IEEE T PATTERN ANAL, V7, P570, DOI 10.1109/TPAMI.1985.4767704; NIEMANN H, 1985, IEEE T PATTERN ANAL, V7, P246, DOI 10.1109/TPAMI.1985.4767655; PETKOVIC D, 1986, 8TH P INT C PATT REC; TANAKA H, 1986, COMPUTER, V19, P48, DOI 10.1109/MC.1986.1663226; 1983, COMPUTER SPECIAL ISS	10	7	8	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					306	311		10.1109/TPAMI.1987.4767903	http://dx.doi.org/10.1109/TPAMI.1987.4767903			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869399				2022-12-18	WOS:A1987G163300010
J	MUTCH, KM				MUTCH, KM			DETERMINING OBJECT TRANSLATION INFORMATION USING STEREOSCOPIC MOTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MUTCH, KM (corresponding author), ARIZONA STATE UNIV,DEPT COMP SCI,TEMPE,AZ 85287, USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; BEVERLEY KI, 1973, J PHYSIOL-LONDON, V235, P17, DOI 10.1113/jphysiol.1973.sp010376; BRUSS AR, COMPUT VISION GRAPHI, V21, P3; CYNADER M, 1978, J PHYSIOL-LONDON, V274, P549, DOI 10.1113/jphysiol.1978.sp012166; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JENKIN MRM, 1984, RBCVTR843 U TOR DEP; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MADARASZ RL, 1985, TR85013 AR STAT U TE; Mitiche A., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P156; NAGEL HH, 1985, OCT P INT S ROB RES; NEVATIA R, 1976, COMPUT GRAPH IMAGE P, V5, P203; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; REGAN D, 1979, VISION RES, V19, P1331, DOI 10.1016/0042-6989(79)90205-0; RICHARDS W, 1985, J OPT SOC AM A, V2, P343, DOI 10.1364/JOSAA.2.000343; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; Thompson W. B., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P791; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WAXMAN A, 1985, CARTR119 U MAR CTR A; WAXMAN AM, 1984, CARTR74 CSTR1421 U M	22	7	7	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1986	8	6					750	755		10.1109/TPAMI.1986.4767856	http://dx.doi.org/10.1109/TPAMI.1986.4767856			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	E4469	21869370				2022-12-18	WOS:A1986E446900006
J	STRAT, TM; FISCHLER, MA				STRAT, TM; FISCHLER, MA			ONE-EYED STEREO - A GENERAL-APPROACH TO MODELING 3-D SCENE GEOMETRY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											STRAT, TM (corresponding author), SRI INT,CTR ARTIFICIAL INTELLIGENCE,MENLO PK,CA 94025, USA.							BARNARD ST, 1982, COMPUT SURV, V14; BRADY M, 1981, ARTIFICIAL INTELLIGE, V17; CAMERON R, 1976, SAN FRANCISCO; GANAPATHY SK, 1984, MAR P INT C ROB ATL, P130; GENNERY D, 1979, NOV P IM UND WORKSH, P101; HORN BKP, 1975, MIT335 ART INT MEM; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; KENDER JR, 1980, CMUCS81102 CARN MELL; LAWTON DT, 1980, AUG P AAAI 80, P31; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; NAGEL H, 1981, P IEEE; NITZAN D, 1983, SRI12TH REP; PENTLAND A, 1984, AUG P NAT C AI AUST, P269; PRAZDNY K, P IJCAI 79, P702; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SMITH GB, 1984, OCT P DARPA IM UND W, P211; SMITH GB, P IEEE CVPR 83; STEVENS KA, 1981, ARTIF INTELL, V17, P47, DOI 10.1016/0004-3702(81)90020-5; STEVENS KA, 1983, AUG P AAAI 83, P1057; STRAT TM, 1984, OCT P DARPA IM UND W, P264; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WITKIN A, 1985, AUG P IJCAI 85; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	24	7	7	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1986	8	6					730	741		10.1109/TPAMI.1986.4767854	http://dx.doi.org/10.1109/TPAMI.1986.4767854			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	E4469	21869368				2022-12-18	WOS:A1986E446900004
J	FU, KS; BOOTH, TL				FU, KS; BOOTH, TL			GRAMMATICAL INFERENCE - INTRODUCTION AND SURVEY .2.	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CONNECTICUT,DEPT ELECT ENGN & COMP SCI,STORRS,CT 06268; PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	University of Connecticut; Purdue University System; Purdue University; Purdue University West Lafayette Campus								Aho A. V, 1973, THEORY PARSING TRANS, V1; BALTRUSH MA, 1973, CS735 U CONN DEP EL; BASKIN AB, 1974, UIUCDCSR74663 U ILL; BHARGAVA BK, 1974, 1974 P IEEE INT C SY; BHARGAVA BK, 1974, 12TH P ALL C CIRC SY; BHARGAVA BK, 1972, TREE7230 PURD U SCH; Booth T. L., 1970, IEEE Transactions on Computers, VC-19, P1193, DOI 10.1109/T-C.1970.222858; BOOTH TL, 1973, IEEE T COMPUT, VC 22, P442, DOI 10.1109/T-C.1973.223746; BOOTH TL, 1974, AUG P IFIP C 74; BOOTH TL, 1974, COMPUTING FUNDAMENTA; BOOTH TL, 1969, 10TH P IEEE ANN SWIT; BRAINERD WS, 1969, INFORM CONTROL, V14, P217, DOI 10.1016/S0019-9958(69)90065-5; BRAYER JM, 1975, TREE751 PURD U SCH E; BRONS R, 1974, COMPUTER GRAPHICS IM, V3; COOK CM, 1974, SOME EXPT GRAMMATICA; COOK CM, 1974, 287 U MAR COMP SCI T; CRAMER H, 1946, MATH MODELS STATISTI; DIMITROV V, 1ST P INT JOINT C PA; DONER JE, 1970, J COMPUT SYST SCI, V4; ELLIS C, 1969, 355 U ILL DEP COMP S; Fu K. S., 1972, International Journal of Computer & Information Sciences, V1, P135, DOI 10.1007/BF00995736; Fu K.S., 1974, MATH SCI ENG; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95, DOI 10.1109/TSMC.1975.5409159; FU KS, 1973, IEEE T COMPUT, VC 22, P1087, DOI 10.1109/T-C.1973.223654; FU KS, 1972, FRONTIERS PATTERN RE; FU KS, 1973, COMPUTER GRAPHICS IM, V2; FU KS, 1974, LEARNING STOCHASTIC; FUNG LW, UNPUB IEEE T COMPUT; FUNG LW, UNPUB IEEE T INFORM; GOLDSTEIN RB, 1973, COMMUN ACM, V16, P483, DOI 10.1145/355609.362319; GONZALEZ RC, 1974, 1974 P IEEE INT C SY; GRENANDER U, 1967, SYNTAX CONTROLLED PR; Hopcroft J.E., 1969, FORMAL LANGUAGES THE; Horning J. J, 1969, THESIS STANFORD U ST; HORNING JJ, 1971, AUG IFIP C 71 YUG; HUANG T, 1972, COMPUT GRAPHICS IMAG, V1, P257; KURCH W, 1970, INFORM CONTR, V16, P173; LEE HC, 1972, IEEE T COMPUT, VC 21, P660, DOI 10.1109/T-C.1972.223571; LEE HC, 1972, DEC P COINS 72 S; MARYANSKI FJ, 1974, THESIS U CONN STORRS; MARYANSKI FJ, UNPUB INFERENCE FINI; MOAYER B, 1974, TREE7436 PURD U SCH; MOAYER B, UNPUB PATTERN RECOGN; PATEL AR, 1972, THESIS U CONN STORRS; Paz A., 1971, INTRO PROBABILISTIC; SOULE S, 1974, INFORM CONTROL, V25, P57, DOI 10.1016/S0019-9958(74)90799-2; SOULE S, 1973, THESIS U CHICAGO CHI; SWAIN PH, 1972, PATTERN RECOGN, V4, P83, DOI 10.1016/0031-3203(72)90021-0; THOMASON MG, 1974, IEEE T COMPUT, VC 23, P597, DOI 10.1109/T-C.1974.224000; THOMPSON RA, 1974, IEEE T COMPUT, VC 23, P603, DOI 10.1109/T-C.1974.224001; THOMPSON RA, 1971, THEORY MACHINES COMP; VELASCO FRD, 1974, INT J COMPUT INFORM, V3; WHARTON RM, 1974, INFORM CONTROL, V26, P236, DOI 10.1016/S0019-9958(74)91369-2; ZADEH LA, COMMUNICATION	54	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1986	8	3					360	375		10.1109/TPAMI.1986.4767797	http://dx.doi.org/10.1109/TPAMI.1986.4767797			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	C0841	21869353				2022-12-18	WOS:A1986C084100006
J	CHESNEY, RH; DAS, Y; MCFEE, JE; ITO, MR				CHESNEY, RH; DAS, Y; MCFEE, JE; ITO, MR			IDENTIFICATION OF METALLIC SPHEROIDS BY CLASSIFICATION OF THEIR ELECTROMAGNETIC INDUCTION RESPONSES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV BRITISH COLUMBIA,DEPT ELECT ENGN,VANCOUVER V6T 1W5,BC,CANADA	University of British Columbia	CHESNEY, RH (corresponding author), DEF RES ESTAB SUFFIELD,MINES & RANGE CLEARANCE GRP,RALSTON T0J 2N0,ALBERTA,CANADA.							CHEN CH, 1973, STATISTICAL PATTERN; CHESNEY RH, 1982, THESIS U BRIT COLUMB; DAS Y, 1981, 283 DEF RES EST SUFF; Das Y, 1980, CANADIAN J REMOTE SE, V6, P104; DAS Y, UNPUB IEEE T GEOSCI; FU KS, 1982, APPLICATIONS PATTERN, P89; GLICK N, 1978, PATTERN RECOGNITION, V10, P217; HABEN JF, 1972, B U KENTUCKY, V98, P90; IOANNIDIS G, 1977, IEEE T AERO ELEC SYS, V13, P327, DOI 10.1109/TAES.1977.308404; MCFEE JE, UNPUB REV SCI INSTRU; MCFEE JE, 1981, IEEE T ANTENNAS PROP, V29, P292; SEBAK AA, 1983, MAY P IEEE APS C HOU; SHAFAI L, COMMUNICATION; Tou JT, 1974, PATTERN RECOGN; TOUSSAINT GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260	15	7	7	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					809	820		10.1109/TPAMI.1984.4767605	http://dx.doi.org/10.1109/TPAMI.1984.4767605			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499662				2022-12-18	WOS:A1984TX36100015
J	ITO, T; KODAMA, Y; TOYODA, J				ITO, T; KODAMA, Y; TOYODA, J			A SIMILARITY MEASURE BETWEEN PATTERNS WITH NONINDEPENDENT ATTRIBUTES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									NIPPON ELECT CO LTD,ABIKO 27011,JAPAN; OSAKA UNIV,IBARAKI,OSAKA 567,JAPAN	Osaka University	ITO, T (corresponding author), UNIV LIB & INFORMAT SCI,IBARAKI 305,JAPAN.							AUGUSTSO.JG, 1970, J ACM, V17, P571, DOI 10.1145/321607.321608; BONNER RE, 1964, IBM J RES DEV, V8, P22, DOI 10.1147/rd.81.0022; BURKHARD WA, 1973, COMMUN ACM, V16, P230, DOI 10.1145/362003.362025; DUNN JC, 1974, IEEE T SYST MAN CYB, VSMC4, P310, DOI 10.1109/TSMC.1974.5409141; FINDLER NV, 1979, IEEE T PATTERN ANAL, V1, P116, DOI 10.1109/TPAMI.1979.4766885; Ito T., 1977, ACM Transactions on Mathematical Software, V3, P227, DOI 10.1145/355744.355746; LAM K, 1982, ACM T DATABASE SYST, V7, P500, DOI 10.1145/319732.319756; ROGERS DJ, 1960, SCIENCE, V132, P1115, DOI 10.1126/science.132.3434.1115; Salton G., 1978, ACM Transactions on Database Systems, V3, P321, DOI 10.1145/320289.320291; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	11	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	1					111	115		10.1109/TPAMI.1984.4767484	http://dx.doi.org/10.1109/TPAMI.1984.4767484			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SB213	21869174				2022-12-18	WOS:A1984SB21300015
J	PAU, LF				PAU, LF			INTEGRATED TESTING AND ALGORITHMS FOR VISUAL INSPECTION OF INTEGRATED-CIRCUITS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											PAU, LF (corresponding author), BATTELLE MEM INST,CTR RECH GENEVE,CH-1227 CAROUGE,SWITZERLAND.		Pau, L.F./A-1262-2010	Pau, L.F./0000-0003-1503-1486				BUEHLER MG, 1979, SOLID STATE TECH OCT, P89; Carre B., 1979, GRAPHS NETWORKS; CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309; DANGELO H, 1978, APR P IEEE SOUTH ATL, P213; DUBOIS D, 1981, FUZZY SETS SYSTEMS; EDWARDS DG, 1982, IEEE T RELIAB, V31, P9, DOI 10.1109/TR.1982.5221212; FU KS, 1982, IEEE COMPUTER, V15; HEALY JT, 1980, AUTOMATIC TESTING EV; HORN BK, 1975, COMPUT GRAPHICS IMAG, P294; Howes M.J, 1981, RELIABILITY DEGRADAT; JARVIS JF, 1980, IEEE T PATTERN ANAL, V2, P77, DOI 10.1109/TPAMI.1980.4766975; JARVIS JF, 1980, IEEE COMPUTER    MAY, P32; JENSEN F, 1982, BURN IN; KRUGER RP, 1981, P IEEE, V69, P1524, DOI 10.1109/PROC.1981.12199; LANE CH, 1975, NTIS RADCTR75150 REP; LEE ET, 1969, INFORM SCIENCES, V1, P421, DOI 10.1016/0020-0255(69)90025-5; Pau L, 1981, FAILURE DIAGNOSIS PE; PAU LF, 1980, 1980 P IEEE INT C CY; PAU LF, 1980, 5TH P INT C PATT REC, P238; PAU LF, 1983, MAY SWISS PAT PRIOR; PAU LF, 1978, STATISTICAL QUALITY; PAU LF, 1983, INTRO INFRARED IMAGE; RICKERS HC, 1979, RADC TRS1 REL AN CTR; RUSSEL TJ, 1979, NBS40051 SPEC PUB; SELIM JD, 1979, ADA050243; Tarjan R. E., 1974, Information Processing Letters, V2, P160, DOI 10.1016/0020-0190(74)90003-9; VANCLEEMPUT WM, 1976, ADA048050; VANDEWIELE F, 1977, PROCESS DEVICE MODEL	28	7	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					602	608		10.1109/TPAMI.1983.4767449	http://dx.doi.org/10.1109/TPAMI.1983.4767449			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869146				2022-12-18	WOS:A1983RV48800006
J	SNYDER, WE; COWART, A				SNYDER, WE; COWART, A			AN ITERATIVE APPROACH TO REGION GROWING USING ASSOCIATIVE MEMORIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									N CAROLINA STATE UNIV, DEPT ELECT ENGN, RALEIGH, NC 27650 USA	University of North Carolina; North Carolina State University								BATCHER KE, 1974, 1974 FALL JOINT COMP, V43, P405; BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1; Duda R.O., 1973, J ROYAL STAT SOC SER; KRAKAUER L, 1971, COMPUTER ANAL VISUAL; MILGRAM DL, 1978, ALGORITHMS HARDWARE; MORI K, 1978, JUN P AFIPS NAT COMP, V47, P1025; PARHAMI B, 1973, P IEEE, V61, P722, DOI 10.1109/PROC.1973.9152; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; YAKIMOVSKY Y, 1973, 3RD P INT JOINT C AR, P580; YAU SS, 1977, COMPUT SURV, V9, P3, DOI 10.1145/356683.356685; [No title captured]	11	7	8	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	3					349	352		10.1109/TPAMI.1983.4767398	http://dx.doi.org/10.1109/TPAMI.1983.4767398			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QS785	21869119				2022-12-18	WOS:A1983QS78500011
J	AGUI, T; YAMANOUCHI, T; NAKAJIMA, M				AGUI, T; YAMANOUCHI, T; NAKAJIMA, M			AN ALGEBRAIC DESCRIPTION OF PAINTED DIGITAL PICTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											AGUI, T (corresponding author), TOKYO INST TECHNOL,DEPT IMAGING SCI & COMP GRAPH,IMAGING SCI & ENGN LAB,MIDORI KU,YOKOHAMA,KANAGAWA 227,JAPAN.							AE T, 1980, AUG P WORKSH PICT DA, P266; AGUI T, 1982, IEEE T PATTERN ANAL, V4, P635, DOI 10.1109/TPAMI.1982.4767317; AGUI T, 1981, T IECE JAPAN TGPRL, V80, P19; AGUI T, 1980, T IECE JAPAN TGPRL, V802, P9; CHEN Z, 1980, AUG P WORKSH PICT DA, P42; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; Kakikura M., 1979, Bulletin of the Electrotechnical Laboratory, V43, P351; LEVIN JZ, 1980, SIGGRAPH 80 C P WASH, P86; LONGHEAD RM, 1980, AUG P IEEE WORKSH PI, P281; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; SHAPIRO LG, 1980, IEEE T PATTERN ANAL, V2, P111, DOI 10.1109/TPAMI.1980.4766989; SHAW AC, 1970, J ACM, V17, P453, DOI 10.1145/321592.321598; WEILER KJ, 1980, JUL P ACM SIGGRAPH 8, P10; WOODWARK JR, 1980, AUG P COMP GRAPH 80, P335; YOKOI S, 1977, T IECE JAPAN D, V60, P419; YOKOI S, 1978, T IECE D, V61, P613	16	7	7	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					627	634		10.1109/TPAMI.1982.4767316	http://dx.doi.org/10.1109/TPAMI.1982.4767316			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499637				2022-12-18	WOS:A1982PS23700008
J	BOISSONNAT, JD				BOISSONNAT, JD			STABLE MATCHING BETWEEN A HAND STRUCTURE AND AN OBJECT SILHOUETTE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BOISSONNAT, JD (corresponding author), INST NATL INFORMAT & AUTOMAT,F-78153 LE CHESNAY,FRANCE.							AGIN GJ, 1979, 9TH SRI INT REP MACH; BAIRD M, 1977, 5TH INT JOINT C ART, P694; BAJCSY R, 1979, MAY WORKSH REPR 3 DI; BALLARD DM, 1982, UNPUB COMPUTER VISIO; BHANU B, 1981, RECOGNITION OCCLUDED; BIRK JR, 1981, IEEE T SYST MAN CYB, V11; BOISSONNAT JD, 1981, 7TH INT JOINT C ART; BURR DJ, 1977, 5TH P INT JOINT C AR, P583; CHALLINE JF, 1977, RAIRO AUTOMATIQUE, V11; CHEN NY, 1980, IEEE T AUTOMAT CONTR, V25; CROSSLEY FRE, 1977, DESIGN 3 FINGERED HA, V12; ESPIAU B, 1980, IEEE T SYST MAN CYBE, V10; HANAFUSA H, 1977, 7TH S IND ROB TOK; HEGINBOTHAM WB, 1974, 4TH INT S IND ROB, P53; LAUGIER C, 1981, C AFCET RECONNAISSAN; LOZANOPEREZ T, 1976, AITR397 MIT AL LAB R; Pavlidis T., 1977, STRUCTURAL PATTERN R; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; ROSEN C, 1974, 3RD STANF RES I REP; ROVETTA A, 1979, 9TH INT S IND ROB WA; SKINNER F, 1975, 5TH INT S IND ROB CH; WILL PM, 1972, P IEEE, V60; WINGHAM M, 1977, THESIS U EDINBURGH E; WITWICKI AT, 1979, 9TH P S IND ROB WASH, P489	24	7	7	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					603	612		10.1109/TPAMI.1982.4767313	http://dx.doi.org/10.1109/TPAMI.1982.4767313			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499634				2022-12-18	WOS:A1982PS23700005
J	HALL, RW				HALL, RW			EFFICIENT SPIRAL SEARCH IN BOUNDED SPACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											HALL, RW (corresponding author), UNIV PITTSBURGH,DEPT ELECT ENGN,PITTSBURGH,PA 15261, USA.							AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; Aho A.V., 1974, DESIGN ANAL COMPUTER, P33; ARIKI Y, 1978, NOV P INT JOINT C PA, V4, P681; GREANIAS EC, 1963, IBM J RES DEV, V7, P14, DOI 10.1147/rd.71.0014; HALL RW, UNPUB IMAGE PROCESSI; NAGEL RN, 1972, PR INST ELECTR ELECT, V60, P242, DOI 10.1109/PROC.1972.8611; PRINCE MD, 1971, INTERACTIVE GRAPHICS, P52; ROSENFIELD A, 1976, DIGITAL PICTURE PROC, P333; TAKAGI M, 1978, NOV P INT JOINT C PA, V4, P735	9	7	7	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					208	215		10.1109/TPAMI.1982.4767228	http://dx.doi.org/10.1109/TPAMI.1982.4767228			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869027				2022-12-18	WOS:A1982NE95700017
J	NARENDRA, PM				NARENDRA, PM			SCENE-BASED NONUNIFORMITY COMPENSATION FOR IMAGING SENSORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											NARENDRA, PM (corresponding author), HONEYWELL INC,CTR SYST & RES,MINNEAPOLIS,MN 55413, USA.							CARRISON CL, 1979, P SPIE WASHINGTON; CHANG SK, 1978, COMMUN ACM, V21, P835, DOI 10.1145/359619.359625; DALLAS WJ, 1980, APPL OPTICS, V19, P3586, DOI 10.1364/AO.19.003586; Fitch R., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V244, P198; HORN BKP, 1979, COMPUT VISION GRAPH, V10, P69, DOI 10.1016/0146-664X(79)90035-2	5	7	10	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					57	61		10.1109/TPAMI.1982.4767196	http://dx.doi.org/10.1109/TPAMI.1982.4767196			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21869004				2022-12-18	WOS:A1982MY53400010
J	CLARK, DC; GONZALEZ, RC				CLARK, DC; GONZALEZ, RC			OPTIMAL SOLUTION OF LINEAR INEQUALITIES WITH APPLICATIONS TO PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV TENNESSEE, DEPT ELECT ENGN, KNOXVILLE, TN 37916 USA; UNIV TENNESSEE, DEPT COMP SCI, KNOXVILLE, TN 37916 USA	University of Tennessee System; University of Tennessee Knoxville; University of Tennessee System; University of Tennessee Knoxville								BRYAN JK, 1970, GENERATION MULTIVARI; CHENEY E. W, 1982, INTRO APPROXIMATION, V2nd; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; DOTU H, 1978, IEEE T COMPUT, V27, P648, DOI 10.1109/TC.1978.1675165; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; GRINOLD RG, 1969, IEEE T COMPUT, VC 18, P378, DOI 10.1109/T-C.1969.222667; IBARAKI T, 1970, IEEE T SYST SCI CYB, VSSC6, P53, DOI 10.1109/TSSC.1970.300329; KLEE V, 1971, AM MATH MON, V78, P616, DOI 10.2307/2316569; MENGERT PH, 1970, IEEE T COMPUT, VC 19, P124, DOI 10.1109/T-C.1970.222877; MIYAKE A, 1979, NOV P COMP SOFTW APP, P161; MIYAKE A, 1978, P INT C CYBERN SOC, V2, P1447; Rockafellar R. T., 1970, CONVEX ANAL; SHINMURA S, 1979, NOV P COMP SOFTW APP, P167; SMITH FW, 1968, IEEE T COMPUT, VC 17, P367, DOI 10.1109/TC.1968.229395; Tou JT, 1974, PATTERN RECOGN; WARMACK RE, 1973, IEEE T COMPUT, VC 22, P1065, DOI 10.1109/T-C.1973.223652; WASSEL GN, 1972, THESIS U CALIFORNIA	18	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					643	655		10.1109/TPAMI.1981.4767165	http://dx.doi.org/10.1109/TPAMI.1981.4767165			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MR996	21868984				2022-12-18	WOS:A1981MR99600004
J	DUBITZKI, T; WU, AY; ROSENFELD, A				DUBITZKI, T; WU, AY; ROSENFELD, A			PARALLEL REGION PROPERTY COMPUTATION BY ACTIVE QUADTREE NETWORKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									AMERICAN UNIV,DEPT MATH STAT & COMP SCI,WASHINGTON,DC 20016	American University	DUBITZKI, T (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							ALEXANDRIDIS N, 1978, COMPUT VISION GRAPH, V8, P43, DOI 10.1016/S0146-664X(78)80030-6; DYER CR, 1980, COMPUT VISION GRAPH, V13, P270, DOI 10.1016/0146-664X(80)90050-7; DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838; DYER CR, 1978, 710 U MAR COMP SCI C; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; HUNTER GM, 1979, COMPUT VISION GRAPH, V10, P289, DOI 10.1016/0146-664X(79)90008-X; HUNTER GM, 1978, THESIS PRINCETON U P; KLINGER A, 1979, IEEE T PATTERN ANAL, V1, P50, DOI 10.1109/TPAMI.1979.4766875; Klinger A., 1973, 1st International Joint Conference on Pattern Recognition, P497; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; KOSARAJU SR, 1973, IEEE T COMPUT      C, V23, P561; PRESTON K, 1979, P IEEE, V67, P826, DOI 10.1109/PROC.1979.11331; RIEGER C, 1980, AUG P WORKSH PICT DA, P298; ROSENFELD A, 1979, PICTURE LANGUAGES FO, pCH4; Rosenstiehl P, 1972, GRAPH THEORY COMPUTI, P219; SAMET H, 1981, IEEE T PATTERN ANAL, V3, P683, DOI 10.1109/TPAMI.1981.4767171; SAMET H, 1980, COMPUT VISION GRAPH, V13, P88, DOI 10.1016/0146-664X(80)90118-5; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836; SAMET H, 1979, 768 U MAR COMP SCI C; SAMET H, 1979, 780 U MAR COMP SCI C; SAMET H, UNPUBLISHED; SAMET H, 1979, 803 U MAR COMP SCI C; SHNEIER M, 1979, 770 U MAR COMP SCI C; SHNEIER M, 1979, 794 U MAR COMP SCI C; SMITH A, 1970, 11TH P IEEE ANN S SW, P216; WU A, 1979, INFORM CONTROL, V42, P305, DOI 10.1016/S0019-9958(79)90288-2; WU A, 1979, 730 U MAR COMP SCI C; WU A, 1979, INFORM CONTR, V42, P329	30	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					626	633		10.1109/TPAMI.1981.4767163	http://dx.doi.org/10.1109/TPAMI.1981.4767163			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MR996	21868982				2022-12-18	WOS:A1981MR99600002
J	MCCAUGHEY, DG; ANDREWS, HC				MCCAUGHEY, DG; ANDREWS, HC			IMAGE APPROXIMATION BY VARIABLE KNOT BICUBIC SPLINES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV ARIZONA,DEPT SYST ENGN,TUCSON,AZ 85721; UNIV SO CALIF,DEPT ELECT ENGN,INST IMAGE PROC,LOS ANGELES,CA 90007; UNIV SO CALIF,DEPT COMP SCI,LOS ANGELES,CA 90007	University of Arizona; University of Southern California; University of Southern California								Andrews H.C., 1970, COMPUTER TECHNIQUES; Blum EK., 1972, NUMERICAL ANAL COMPU; de Boor C, 1973, SPLINE FUNCTIONS APP, P1973; GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027; HOU HS, 1977, IEEE T COMPUT, V26, P856, DOI 10.1109/TC.1977.1674934; LANDAU HJ, 1962, BELL SYST TECH J, V41, P1295, DOI 10.1002/j.1538-7305.1962.tb03279.x; PEYROVIAN MJ, 1976, USCIPI680 U SO CAL R; Rice J. R., 1969, APPROXIMATION FUNCTI, V2; Schultz M.H., 1973, SPLINE ANAL; SCHULTZ MH, 1964, SIAM J NUMER ANAL, V6, P184; SCHULTZ MH, 1964, SIAM J NUMER ANAL, V6, P161; SLEPIAN D, 1961, BELL SYST TECH J, V40, P43, DOI 10.1002/j.1538-7305.1961.tb03976.x; Stone M.H., 1948, MATH MAG, V21, P167, DOI DOI 10.2307/3029750; Stone MH., 1948, MATH MAG, V21, P148, DOI [DOI 10.2307/3029750, DOI 10.2307/3029337]	15	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	3					299	310		10.1109/TPAMI.1981.4767103	http://dx.doi.org/10.1109/TPAMI.1981.4767103			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN969	21868951				2022-12-18	WOS:A1981MN96900007
J	TROXEL, DE				TROXEL, DE			AN INTERACTIVE IMAGE-PROCESSING SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											TROXEL, DE (corresponding author), MIT,DEPT ELECT ENGN & COMP SCI,CAMBRIDGE,MA 02139, USA.							GOLDWASSER SM, 1976, THESIS MASSACHUSETTS; HASHIZUME B, 1973, THESIS MASSACHUSETTS; MALONE U, 1977, THESIS MASSACHUSETTS; ROBERTS LG, 1962, IRE T INFORM THEOR, V8, P145, DOI 10.1109/TIT.1962.1057702; SCHREIBER WF, 1974, J TECH ASS PULP PAPE, V47, P91; TROXEL DE, 1975, IEEE T SYST MAN CYB, V5, P625; TROXEL DE, 1978, COMPUT VISION GRAPH, V7, P266, DOI 10.1016/0146-664X(78)90117-X; TROXEL DE, 1977, P MIMI, V77, P141; TROXEL DE, 1969, IEEE T COMMUN TECHNO, V17, P554; TROXEL DE, 1977, P MIMI, V77, P142	10	7	7	4	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					95	101		10.1109/TPAMI.1981.4767055	http://dx.doi.org/10.1109/TPAMI.1981.4767055			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LK116	21868923				2022-12-18	WOS:A1981LK11600011
J	LEVINE, MD; YOUSSEF, YM; NOBLE, PB; BOYARSKY, A				LEVINE, MD; YOUSSEF, YM; NOBLE, PB; BOYARSKY, A			THE QUANTIFICATION OF BLOOD-CELL MOTION BY A METHOD OF AUTOMATIC DIGITAL PICTURE-PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MCGILL UNIV,DEPT ELECT ENGN,COMP VIS & GRAPH LAB,MONTREAL H3C 3G1,QUEBEC,CANADA; MCGILL UNIV,FAC DENT,DEPT ORAL BIOL,MONTREAL H3C 3G1,QUEBEC,CANADA; CONCORDIA UNIV,DEPT MATH,MONTREAL H3G 1M8,QUEBEC,CANADA	McGill University; McGill University; Concordia University - Canada								BOYARSKY A, 1975, J MATH BIOL, V2, P69, DOI 10.1007/BF00276017; BOYARSKY A, 1977, CAN J PHYSIOL PHARM, V55, P1, DOI 10.1139/y77-001; Boyum A, 1968, Scand J Clin Lab Invest Suppl, V97, P9; BREIMAN L, 1967, PROBABILITY STOCHAST; GREENE FM, 1977, REV SCI INSTRUM, V48, P602, DOI 10.1063/1.1135116; KNOLL A, 1979, 7912R MCGILL U DEP E; LEVINE MD, 1975, PATTERN RECOGN, V7, P177, DOI 10.1016/0031-3203(75)90003-5; LEVINE MD, 1978, 4TH INT C CYB SYST A; LEVINE MD, 1977, 775 MCGILL U DEP EL; LEVINE MD, 1978, 782R MCGILL U DEP EL; NOBLE PB, 1979, CAN J PHYSL PHARM, V1, P108; NOBLE PB, 10TH P PIGM CELL; RAWLES ME, 1947, PHYSIOL ZOOL, V20, P248, DOI 10.1086/physzool.20.3.30151958; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; WILKINSON PC, 1974, CHEMOTAXIS INFLAMMAT; YOUSSEF YM, 1977, THESIS MCGILL U MONT	16	7	7	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	5					444	450		10.1109/TPAMI.1980.6592365	http://dx.doi.org/10.1109/TPAMI.1980.6592365			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KW185					2022-12-18	WOS:A1980KW18500007
J	YUNCK, TP; TUTEUR, FB				YUNCK, TP; TUTEUR, FB			COMPARISON OF DECISION RULES FOR AUTOMATIC EEG CLASSIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									YALE UNIV,DEPT ENGN & APPL SCI,NEW HAVEN,CT 06520	Yale University	YUNCK, TP (corresponding author), CALTECH,JET PROP LAB,DIV TELECOMMUN,PASADENA,CA 91103, USA.							AFIFI AA, 1979, STATISTICAL ANAL COM; BAILEY NTJ, 1959, STATISTICAL METHODS, P24; BERKHOUT J, 1969, ELECTROEN CLIN NEURO, V27, P457, DOI 10.1016/0013-4694(69)90186-2; BUSK J, 1975, ELECTROEN CLIN NEURO, V38, P415, DOI 10.1016/0013-4694(75)90265-5; BUTLER SR, 1974, ELECTROEN CLIN NEURO, V36, P481, DOI 10.1016/0013-4694(74)90205-3; Creutzfeldt O., 1969, ATTENTION NEUROPHYSI, P148; DIXON WJ, 1975, BMDP BIOMEDICAL COMP, P411; DOLCE G, 1974, ELECTROEN CLIN NEURO, V36, P577, DOI 10.1016/0013-4694(74)90224-7; DUMAS R, 1975, NEUROPSYCHOLOGIA, V13, P219, DOI 10.1016/0028-3932(75)90031-7; DUMMERMUTH G, 1973, AUTOMATION CLIN ELEC, P145; EBE M, 1973, ELECTROEN CLIN NEURO, V34, P706; FIX E, 1951, USAF4 SCH AV MED; FROST JD, 1973, AUTOMATION CLIN ELEC, P31; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GALIN D, 1972, PSYCHOPHYSIOLOGY, V9, P412, DOI 10.1111/j.1469-8986.1972.tb01788.x; GEVINS AS, 1975, P IEEE, V63, P1382, DOI 10.1109/PROC.1975.9966; ISHIHARA T, 1972, ELECTROEN CLIN NEURO, V33, P71, DOI 10.1016/0013-4694(72)90026-0; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; MARTIN WB, 1972, ELECTROEN CLIN NEURO, V32, P417, DOI 10.1016/0013-4694(72)90009-0; MAYNARD DE, 1973, ELECTROEN CLIN NEURO, V34, P108; MCKEE G, 1973, PSYCHOPHYSIOLOGY, V10, P441, DOI 10.1111/j.1469-8986.1973.tb00803.x; MUNDYCASTLE AC, 1957, ELECTROEN CLIN NEURO, V9, P643, DOI 10.1016/0013-4694(57)90085-8; NILSSON NJ, 1965, LEARNING MACHINES, P118; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; PERSSON J, 1974, ELECTROEN CLIN NEURO, V37, P309, DOI 10.1016/0013-4694(74)90037-6; RABINER LR, 1979, IEEE T ACOUSTICS SPE, V27, P339; SEBESTYEN CS, 1962, DECISION MAKING PROC, P17; SKLAR B, 1973, IEEE T BIO-MED ENG, VBM20, P20, DOI 10.1109/TBME.1973.324247; VIGLIONE SS, 1970, ADAPTIVE LEARNING PA, pCH4; WALTER DO, 1967, ELECTROEN CLIN NEURO, V22, P22, DOI 10.1016/0013-4694(67)90005-3; Yunck T. P., 1979, Journal of Cybernetics and Information Science, V2, P3; YUNCK TP, 1977, THESIS YALE U; [No title captured]	33	7	7	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	5					420	428		10.1109/TPAMI.1980.6592363	http://dx.doi.org/10.1109/TPAMI.1980.6592363			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KW185					2022-12-18	WOS:A1980KW18500005
J	PAVLIDIS, T				PAVLIDIS, T			USE OF A SYNTACTIC SHAPE ANALYZER FOR CONTOUR MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											PAVLIDIS, T (corresponding author), PRINCETON UNIV,DEPT ELECT ENGN & COMP SCI,PRINCETON,NJ 08544, USA.							DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; Fu K.S., 1974, MATH SCI ENG; FU KS, 1977, SYNTACTIC PATTERN RE; HARALICK RM, 1977, JUN P IEEE C PATT RE, P112; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P2, DOI 10.1109/TPAMI.1979.4766870; Pavlidis T., 1977, STRUCTURAL PATTERN R; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; RABIN MO, 1974 P IFIPS, P615	8	7	8	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					307	310		10.1109/TPAMI.1979.4766928	http://dx.doi.org/10.1109/TPAMI.1979.4766928			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868862				2022-12-18	WOS:A1979HC30100010
J	PEARL, J				PEARL, J			CAPACITY AND ERROR ESTIMATES FOR BOOLEAN CLASSIFIERS WITH LIMITED COMPLEXITY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											PEARL, J (corresponding author), UNIV CALIF LOS ANGELES, SCH ENGN & APPL SCI, LOS ANGELES, CA 90024 USA.							CHANDRASEKARAN B, 1975, IEEE T SYST MAN CYB, VSMC5, P240, DOI 10.1109/TSMC.1975.5408477; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; DEVROYE LP, 1976, IEEE T INFORM THEORY, V22, P586, DOI 10.1109/TIT.1976.1055604; FELLER W, 1968, INTRO PROBABILITY TH, V1, P175; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; MICHALSKI RS, 1973, 1ST P I J C PATT REC; PIPPENGER N, 1977, MATH SYST THEORY, V10, P129; PIPPENGER N, 1975, 16TH P ANN S F COMP, P113; SHOLOMOV LA, 1970, SYSTEMS THEORY RES, V19, P123; USPENSKY JV, 1937, INTRO MATH PROBABILI, pCH6; VANCAMPENHOUT JM, 1978, IEEE T SYST MAN CYB, V8, P390, DOI 10.1109/TSMC.1978.4309980; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025	13	7	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	4					350	356		10.1109/TPAMI.1979.4766943	http://dx.doi.org/10.1109/TPAMI.1979.4766943			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HV227	21868869				2022-12-18	WOS:A1979HV22700003
J	Dong, JX; Roth, S; Schiele, B				Dong, Jiangxin; Roth, Stefan; Schiele, Bernt			DWDN: Deep Wiener Deconvolution Network for Non-Blind Image Deblurring	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deconvolution; Image restoration; Feature extraction; Kernel; Standards; Neural networks; Transform coding; Image deblurring; wiener deconvolution; feature-based deconvolution; multi-scale cascaded feature refinement; saturation and JPEG artifacts	SHAKEN; FIELDS	We present a simple and effective approach for non-blind image deblurring, combining classical techniques and deep learning. In contrast to existing methods that deblur the image directly in the standard image space, we propose to perform an explicit deconvolution process in a feature space by integrating a classical Wiener deconvolution framework with learned deep features. A multi-scale cascaded feature refinement module then predicts the deblurred image from the deconvolved deep features, progressively recovering detail and small-scale structures. The proposed model is trained in an end-to-end manner and evaluated on scenarios with simulated Gaussian noise, saturated pixels, or JPEG compression artifacts as well as real-world images. Moreover, we present detailed analyses of the benefit of the feature-based Wiener deconvolution and of the multi-scale cascaded feature refinement as well as the robustness of the proposed approach. Our extensive experimental results show that the proposed deep Wiener deconvolution network facilitates deblurred results with visibly fewer artifacts and quantitatively outperforms state-of-the-art non-blind image deblurring methods by a wide margin.	[Dong, Jiangxin] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China; [Dong, Jiangxin; Schiele, Bernt] Max Planck Inst Informat, Dept Comp Vis & Machine Learning, D-66123 Saarbrucken, Germany; [Roth, Stefan] Tech Univ Darmstadt, Dept Comp Sci, D-64289 Darmstadt, Germany	Nanjing University of Science & Technology; Max Planck Society; Technical University of Darmstadt	Dong, JX (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.	dongjxjx@gmail.com; stefan.roth@visinf.tu-darmstadt.de; schiele@mpi-inf.mpg.de			European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme [866008]	European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme(European Research Council (ERC))	This work was supported in part by European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under Grant 866008.	Anger J, 2018, IEEE IMAGE PROC, P978, DOI 10.1109/ICIP.2018.8451115; Bar L, 2006, INT J COMPUT VISION, V70, P279, DOI 10.1007/s11263-006-6468-1; Bertsekas DP, 2011, MATH PROGRAM, V129, P163, DOI 10.1007/s10107-011-0472-0; Bigdeli S. A., 2017, PROC INT C NEURAL IN, V30, P763; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Chen YJ, 2015, PROC CVPR IEEE, P5261, DOI 10.1109/CVPR.2015.7299163; Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954; Dong J., 2020, ADV NEUR IN, V33; Dong JX, 2018, LECT NOTES COMPUT SC, V11215, P777, DOI 10.1007/978-3-030-01252-6_46; Dong JX, 2017, IEEE I CONF COMP VIS, P2497, DOI 10.1109/ICCV.2017.271; Dong WS, 2019, IEEE T PATTERN ANAL, V41, P2305, DOI 10.1109/TPAMI.2018.2873610; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847; Eboli Thomas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P314, DOI 10.1007/978-3-030-58520-4_19; Gao HY, 2019, PROC CVPR IEEE, P3843, DOI 10.1109/CVPR.2019.00397; Gong D, 2020, IEEE T NEUR NET LEAR, V31, P5468, DOI 10.1109/TNNLS.2020.2968289; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jancsary J, 2012, LECT NOTES COMPUT SC, V7578, P112, DOI 10.1007/978-3-642-33786-4_9; Jin MG, 2017, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2017.408; Kelley C., 1995, FRONTIERS APPL MATH, DOI 10.1137/1.9781611970944; Kingma D.P, 2015, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1412.6980; Krishnan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531402; Kruse J, 2017, IEEE I CONF COMP VIS, P4596, DOI 10.1109/ICCV.2017.491; Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854; Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188; Lee G.-H., 2019, PROC INT C LEARN REP; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888; Mao XJ, 2016, ADV NEUR IN, V29; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51; Mildenhall B, 2018, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2018.00265; Montufar G, 2014, ADV NEUR IN, V27; Nan YS, 2020, PROC CVPR IEEE, P3623, DOI 10.1109/CVPR42600.2020.00368; Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244; Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804; Pan JS, 2017, IEEE I CONF COMP VIS, P1077, DOI 10.1109/ICCV.2017.122; Pan JS, 2017, IEEE T PATTERN ANAL, V39, P342, DOI 10.1109/TPAMI.2016.2551244; Pan JS, 2016, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2016.306; Quan YH, 2022, IEEE T NEUR NET LEAR, V33, P5387, DOI 10.1109/TNNLS.2021.3070596; Quan YH, 2015, J SCI COMPUT, V63, P307, DOI 10.1007/s10915-014-9893-2; Ren DW, 2021, IEEE T PATTERN ANAL, V43, P284, DOI 10.1109/TPAMI.2019.2926357; Ren W., 2018, PROC INT C NEURAL IN, P295; Ren WQ, 2021, IEEE T PATTERN ANAL, V44, P3974, DOI 10.1109/TPAMI.2021.3061604; RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; Romano Y, 2017, SIAM J IMAGING SCI, V10, P1804, DOI 10.1137/16M1102884; Roth S, 2005, PROC CVPR IEEE, P860; Ryu EK, 2019, PR MACH LEARN RES, V97; Schmidt U., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2625, DOI 10.1109/CVPR.2011.5995653; Schmidt U, 2016, IEEE T PATTERN ANAL, V38, P677, DOI 10.1109/TPAMI.2015.2441053; Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349; Schuler CJ, 2013, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2013.142; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Son H, 2017, IEEE INT CONF COMPUT, P23; Diamond S, 2017, Arxiv, DOI arXiv:1701.06487; Sun LB, 2013, IEEE INT CONF COMPUT; Sun LB, 2014, LECT NOTES COMPUT SC, V8692, P231; Tai YW, 2013, IEEE T PATTERN ANAL, V35, P2498, DOI 10.1109/TPAMI.2013.40; Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853; Vasu S, 2018, PROC CVPR IEEE, P3272, DOI 10.1109/CVPR.2018.00345; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Whyte O, 2014, INT J COMPUT VISION, V110, P185, DOI 10.1007/s11263-014-0727-3; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Wiener N., 1949, EXTRAPOLATION INTERP, DOI 10.7551/mitpress/2946.00 1.0001; Xu L, 2014, ADV NEUR IN, V27; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673; Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613; Zhang JW, 2017, PROC CVPR IEEE, P6969, DOI 10.1109/CVPR.2017.737; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	77	6	6	3	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					9960	9976		10.1109/TPAMI.2021.3138787	http://dx.doi.org/10.1109/TPAMI.2021.3138787			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34962863				2022-12-18	WOS:000880661400100
J	Du, RY; Xie, JY; Ma, ZY; Chang, DL; Song, YZ; Guo, J				Du, Ruoyi; Xie, Jiyang; Ma, Zhanyu; Chang, Dongliang; Song, Yi-Zhe; Guo, Jun			Progressive Learning of Category-Consistent Multi-Granularity Features for Fine-Grained Visual Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Convolution; Visualization; Birds; Beak; Task analysis; Semantics; Fine-grained visual classification; convolutional neural network; progressive training; consistency constraint		Fine-grained visual classi?cation (FGVC) is much more challenging than traditional classi?cation tasks due to the inherently subtle intra-class object variations. Recent works are mainly part-driven (either explicitly or implicitly), with the assumption that fine-grained information naturally rests within the parts. In this paper, we take a different stance, and show that part operations are not strictly necessary - the key lies with encouraging the network to learn at different granularities and progressively fusing multi-granularity features together. In particular, we propose: (i) a progressive training strategy that effectively fuses features from different granularities, and (ii) a consistent block convolution that encourages the network to learn the category-consistent features at specific granularities. We evaluate on several standard FGVC benchmark datasets, and demonstrate the proposed method consistently outperforms existing alternatives or delivers competitive results. Codes are available at https://github.com/PRIS-CV/PMG-V2.	[Du, Ruoyi; Xie, Jiyang; Ma, Zhanyu; Chang, Dongliang; Guo, Jun] Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Pattern Recognit & Intelligent Syst Lab, Beijing 100876, Peoples R China; [Song, Yi-Zhe] Univ Surrey, SketchX, CVSSP, London GU2 7XH, England	Beijing University of Posts & Telecommunications; University of Surrey	Ma, ZY (corresponding author), Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Pattern Recognit & Intelligent Syst Lab, Beijing 100876, Peoples R China.	beiyoudry@bupt.edu.cn; xiejiyang2013@bupt.edu.cn; mazhanyu@bupt.edu.cn; changdongliang@bupt.edu.cn; y.song@surrey.ac.uk; guojun@bupt.edu.cn		Du, Ruoyi/0000-0001-8372-5637; Chang, Dongliang/0000-0002-4081-3001; Xie, Jiyang/0000-0003-3659-9476	National Key R&D Program of China [2019YFF0303300, 2019YFF0303302]; National Natural Science Foundation of China (NSFC) [61922015, 61773071, U19B2036]; Beijing Natural Science Foundation Project [Z200002]; China Scholarship Council (CSC) [202006470036]; BUPT Excellent PhD Students Foundation [CX2020105]	National Key R&D Program of China; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation Project(Beijing Natural Science Foundation); China Scholarship Council (CSC)(China Scholarship Council); BUPT Excellent PhD Students Foundation	This work was supported in part by the National Key R&D Program of China under Grant 2019YFF0303300 and Subject II under Grant 2019YFF0303302, in part by National Natural Science Foundation of China (NSFC) under Grants 61922015, 61773071, and U19B2036, in part by Beijing Natural Science Foundation Project under Grant Z200002, in part by a scholarship from China Scholarship Council (CSC) under Grant 202006470036, and in part by BUPT Excellent PhD Students Foundation under Grant CX2020105.	Ahn N., 2018, PROC IEEE C COMPUT V, P791; Andrea Vedaldi, 2013, Arxiv, DOI arXiv:1306.5151; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); Chang DL, 2021, PROC CVPR IEEE, P11471, DOI 10.1109/CVPR46437.2021.01131; Chang DL, 2020, IEEE T IMAGE PROCESS, V29, P4683, DOI 10.1109/TIP.2020.2973812; Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530; Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670; Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5; Durugkar I., 2015, SPECTROCHIMICA ACT B, V107, P1; Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476; Ge WF, 2019, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2019.00315; Ghosh A, 2018, PROC CVPR IEEE, P8513, DOI 10.1109/CVPR.2018.00888; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gupta O., 2018, PROC INT C NEURAL IN, P635; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu YT, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3446208; Huang G., 2017, P IEEE C COMPUTER VI, P4700, DOI DOI 10.1109/CVPR.2017.243; Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jianxin Wu, 2019, Arxiv, DOI arXiv:1907.03069; Karras T., 2017, PROGR GROWING GANS I; Khosla Aditya, 2011, P C COMP VIS PATT RE; Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lei JJ, 2018, IEEE T CIRC SYST VID, V28, P706, DOI 10.1109/TCSVT.2016.2617332; Li JJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P663, DOI 10.1145/3240508.3240579; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Luo W, 2019, IEEE I CONF COMP VIS, P8241, DOI 10.1109/ICCV.2019.00833; Ma ZY, 2019, IEEE T VEH TECHNOL, V68, P3224, DOI 10.1109/TVT.2019.2899972; Ruoyi Du, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P153, DOI 10.1007/978-3-030-58565-5_10; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467; Song KT, 2020, IEEE T IMAGE PROCESS, V29, P7006, DOI 10.1109/TIP.2020.2996736; Van Horn G, 2015, PROC CVPR IEEE, P595, DOI 10.1109/CVPR.2015.7298658; Wah C., 2011, TECH REP; Wang SJ, 2021, AAAI CONF ARTIF INTE, V35, P2791; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436; Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131; Wang YF, 2018, IEEE COMPUT SOC CONF, P977, DOI 10.1109/CVPRW.2018.00131; Wang ZH, 2020, AAAI CONF ARTIF INTE, V34, P12289; Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002; Xie LX, 2013, IEEE I CONF COMP VIS, P1641, DOI 10.1109/ICCV.2013.206; Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26; Zhang LB, 2019, IEEE I CONF COMP VIS, P8330, DOI 10.1109/ICCV.2019.00842; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhang YB, 2018, LECT NOTES COMPUT SC, V11212, P241, DOI 10.1007/978-3-030-01237-3_15; Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515; Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557; Zhuang PQ, 2020, AAAI CONF ARTIF INTE, V34, P13130	53	6	6	5	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					9521	9535		10.1109/TPAMI.2021.3126668	http://dx.doi.org/10.1109/TPAMI.2021.3126668			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34752385				2022-12-18	WOS:000880661400068
J	Pan, XG; Zhan, XH; Dai, B; Lin, DH; Loy, CC; Luo, P				Pan, Xingang; Zhan, Xiaohang; Dai, Bo; Lin, Dahua; Loy, Chen Change; Luo, Ping			Exploiting Deep Generative Prior for Versatile Image Restoration and Manipulation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image prior; generative adversarial networks; image processing	ADVERSARIAL NETWORKS; FRAMEWORK	Learning a good image prior is a long-term goal for image restoration and manipulation. While existing methods like deep image prior (DIP) capture low-level image statistics, there are still gaps toward an image prior that captures rich image semantics including color, spatial coherence, textures, and high-level concepts. This work presents an effective way to exploit the image prior captured by a generative adversarial network (GAN) trained on large-scale natural images. As shown in Fig. 1, the deep generative prior (DGP) provides compelling results to restore missing semantics, e.g., color, patch, resolution, of various degraded images. It also enables diverse image manipulation including random jittering, image morphing, and category transfer. Such highly flexible restoration and manipulation are made possible through relaxing the assumption of existing GAN inversion methods, which tend to fix the generator. Notably, we allow the generator to be fine-tuned on-the-fly in a progressive manner regularized by feature distance obtained by the discriminator in GAN. We show that these easy-to-implement and practical changes help preserve the reconstruction to remain in the manifold of nature images, and thus lead to more precise and faithful reconstruction for real images. Code is available at https://github.com/XingangPan/deep-generative-prior.	[Pan, Xingang; Zhan, Xiaohang; Lin, Dahua] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Peoples R China; [Dai, Bo; Loy, Chen Change] Nanyang Technol Univ, S Lab, Singapore 639798, Singapore; [Luo, Ping] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China	Chinese University of Hong Kong; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Hong Kong	Pan, XG (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Peoples R China.; Luo, P (corresponding author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.	px117@ie.cuhk.edu.hk; xiaohangzhan@outlook.com; bo.dai@ntu.edu.sg; dhlin@ie.cuhk.edu.hk; ccloy@ntu.edu.sg; pluo@cs.hku.hk	Pan, Xingang/HGD-9011-2022; Luo, Ping/HGE-7623-2022	Luo, Ping/0000-0002-6685-7950; Loy, Chen Change/0000-0001-5345-1591; Zhan, Xiaohang/0000-0003-2136-7592	A*STAR through the Industry Alignment Fund -Industry Collaboration Projects Grant; HK General Research Fund [27208720]; RIE2020 Industry Alignment Fund Industry Collaboration Projects (IAF-ICP) Funding Initiative	A*STAR through the Industry Alignment Fund -Industry Collaboration Projects Grant; HK General Research Fund; RIE2020 Industry Alignment Fund Industry Collaboration Projects (IAF-ICP) Funding Initiative	This work was supported in part by A*STAR through the Industry Alignment Fund -Industry Collaboration Projects Grant, in part by the HK General Research Fund under Grant 27208720, and in part by the RIE2020 Industry Alignment Fund Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from the industry partner(s). (Corresponding authors: Xingang Pan and Ping Luo.)	Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453; Abdal Rameen, 2020, P IEEE CVF C COMP VI, P8296, DOI 10.1109/CVPR42600.2020.00832; Albright, 2019, 2019 IEEE CVF C COMP, P96; Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640; Athar S., 2018, PROC INT C LEARN REP; Bau D, 2019, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2019.00460; Bau D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323023; Bigdeli S. A., 2017, PROC INT C NEURAL IN, V30, P763; Bolei Zhou, 2020, Arxiv, DOI arXiv:1911.09267; Brock A., 2019, PROC INT C LEARN REP; Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Dai B, 2017, IEEE I CONF COMP VIS, P2989, DOI 10.1109/ICCV.2017.323; Deng J., 2009, P 2009 IEEE C COMP V, P248, DOI DOI 10.1109/CVPR.2009.5206848; Donahue Jeff, 2017, INT C LEARN REPR ICL; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gu JJ, 2020, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR42600.2020.00308; Harkonen E., 2020, P C NEUR INF PROC SY; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Ian Fischer, 2017, Arxiv, DOI arXiv:1703.09387; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jiapeng Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P592, DOI 10.1007/978-3-030-58520-4_35; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Karras Timo Aila Samuli Laine Tero, 2018, PROC INT C LEARN REP, Patent No. [1710.10196, 171010196]; Kingma D.P, P 3 INT C LEARNING R; Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Mao Q, 2019, PROC CVPR IEEE, P1429, DOI 10.1109/CVPR.2019.00152; Menon S, 2020, PROC CVPR IEEE, P2434, DOI 10.1109/CVPR42600.2020.00251; Minyoung Huh, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P17, DOI 10.1007/978-3-030-58536-5_2; Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726; Ning Yu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P377, DOI 10.1007/978-3-030-58542-6_23; Pan X., 2021, PROC INT C LEARN REP; Paszke A., 2017, AUTOMATIC DIFFERENTI; Raja Giryes, 2019, Arxiv, DOI arXiv:1906.05284; Roth S, 2005, PROC CVPR IEEE, P860; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Salimans T, 2016, ADV NEUR IN, V29; Samangouei P., 2018, P INT C LEARN REPR; Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467; Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329; Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wang XT, 2019, PROC CVPR IEEE, P1692, DOI 10.1109/CVPR.2019.00179; Xiangli Y., 2020, P INT C LEARN REPR; Xingang Pan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P262, DOI 10.1007/978-3-030-58536-5_16; Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728; Yujun Shen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9240, DOI 10.1109/CVPR42600.2020.00926; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983	61	6	6	10	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					7474	7489		10.1109/TPAMI.2021.3115428	http://dx.doi.org/10.1109/TPAMI.2021.3115428			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34559638	Green Submitted			2022-12-18	WOS:000864325900018
J	Schnake, T; Eberle, O; Lederer, J; Nakajima, S; Schutt, KT; Muller, KR; Montavon, G				Schnake, Thomas; Eberle, Oliver; Lederer, Jonas; Nakajima, Shinichi; Schuett, Kristof T.; Mueller, Klaus-Robert; Montavon, Gregoire			Higher-Order Explanations of Graph Neural Networks via Relevant Walks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph neural networks; Neural networks; Predictive models; Optimization; Taylor series; Feature extraction; Adaptation models; Graph neural networks; higher-order explanations; layer-wise relevance propagation; explainable machine learning		Graph Neural Networks (GNNs) are a popular approach for predicting graph structured data. As GNNs tightly entangle the input graph into the neural network structure, common explainable AI approaches are not applicable. To a large extent, GNNs have remained black-boxes for the user so far. In this paper, we show that GNNs can in fact be naturally explained using higher-order expansions, i.e., by identifying groups of edges that jointly contribute to the prediction. Practically, we find that such explanations can be extracted using a nested attribution scheme, where existing techniques such as layer-wise relevance propagation (LRP) can be applied at each step. The output is a collection of walks into the input graph that are relevant for the prediction. Our novel explanation method, which we denote by GNN-LRP, is applicable to a broad range of graph neural networks and lets us extract practically relevant insights on sentiment analysis of text data, structure-property relationships in quantum chemistry, and image classification.	[Schnake, Thomas; Eberle, Oliver; Nakajima, Shinichi; Schuett, Kristof T.; Mueller, Klaus-Robert; Montavon, Gregoire] Berlin Inst Technol TU Berlin, BIFOLD Berlin Inst Fdn Learning & Data, D-10587 Berlin, Germany; [Lederer, Jonas] Berlin Inst Technol TU Berlin, D-10587 Berlin, Germany; [Nakajima, Shinichi] RIKEN AIP, Tokyo 1030027, Japan; [Mueller, Klaus-Robert] Google Res, Brain Team, Berlin, Germany; [Mueller, Klaus-Robert] Korea Univ, Dept Artificial Intelligence, Seoul 136713, South Korea; [Mueller, Klaus-Robert] Max Planck Inst Informat, D-66123 Saarbrucken, Germany	Technical University of Berlin; Technical University of Berlin; RIKEN; Google Incorporated; Korea University; Max Planck Society	Muller, KR; Montavon, G (corresponding author), Berlin Inst Technol TU Berlin, BIFOLD Berlin Inst Fdn Learning & Data, D-10587 Berlin, Germany.; Muller, KR (corresponding author), Google Res, Brain Team, Berlin, Germany.; Muller, KR (corresponding author), Korea Univ, Dept Artificial Intelligence, Seoul 136713, South Korea.	t.schnake@tu-berlin.de; oliver.eberle@campus.tu-berlin.de; jonas.lederer@tu-berlin.de; nakajima@tu-berlin.de; kristof.schuett@tu-berlin.de; klaus-robert.mueller@tu-berlin.de; gregoire.montavoni@tu-berlin.de	Mueller, Klaus-Robert/Y-3547-2019; Schutt, Kristof/Q-2604-2017	Mueller, Klaus-Robert/0000-0002-3861-7685; Schutt, Kristof/0000-0001-8342-0964; Eberle, Oliver/0000-0002-6967-9950	German Ministry for Education and Research [01IS18025A, 01IS18037A]; German Research Foundation (DFG) as Math+: Berlin Mathematics Research Center [EXC 2046/1, 390685689]; Institute of Information & Communications Technology Planning & Evaluation (IITP) - Korea Government [2019-0-00079]	German Ministry for Education and Research(Federal Ministry of Education & Research (BMBF)); German Research Foundation (DFG) as Math+: Berlin Mathematics Research Center(German Research Foundation (DFG)); Institute of Information & Communications Technology Planning & Evaluation (IITP) - Korea Government(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of Korea)	This work was funded by the German Ministry for Education and Research as BIFOLD -Berlin Institute for the Foundations of Learning and Data (ref. 01IS18025A and ref. 01IS18037A), and the German Research Foundation (DFG) as Math+: Berlin Mathematics Research Center (EXC 2046/1, projectID: 390685689). This work was partly supported by the Institute of Information & Communications Technology Planning & Evaluation (IITP) grants funded by the Korea Government (No. 2019-0-00079, Artificial Intelligence Graduate School Program, Korea University).	Adebayo J, 2018, ADV NEUR IN, V31; Albert R, 2002, REV MOD PHYS, V74, P47, DOI 10.1103/RevModPhys.74.47; Alvarez-Melis D, 2018, ADV NEUR IN, V31; Arras L., 2019, EXPLAINING INTERPRET, P211, DOI [10.1007/978-3-030-28954-611.https://doi.org/10.1007/978-3-030-28954-611, DOI 10.1007/978-3-030-28954-611.HTTPS://DOI.ORG/10.1007/978-3-030-28954-611, DOI 10.1007/978-3-030-28954-6_11]; Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140; Bansal N, 2020, IEEE COMPUT SOC CONF, P11, DOI 10.1109/CVPRW50498.2020.00009; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Bastings Joost, 2017, P EMNLP, DOI [10.18653/v1/d17-1209, DOI 10.18653/V1/D17-1209]; Beck D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P273; Bolukbasi T, 2016, ADV NEUR IN, V29; Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418; Bruna Joan, 2014, ICLR, DOI DOI 10.1145/3170427.3188467; Caruana R, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1721, DOI 10.1145/2783258.2788613; Chang Y, 2020, GRAPHLIME LOCAL INTE; Cui TY, 2020, FRONT ARTIF INTEL AP, V325, P1087, DOI 10.3233/FAIA200205; Defferrard M, 2016, ADV NEUR IN, V29; Dombrowski AK, 2019, ADV NEUR IN, V32; Doshi-Velez F., 2017, CORR; Duvenaud David K, 2015, P NIPS; Eberle O, 2022, IEEE T PATTERN ANAL, V44, P1149, DOI 10.1109/TPAMI.2020.3020738; Gilmer J, 2017, PR MACH LEARN RES, V70; Gonen Hila, 2019, ARXIV190303862; Hamilton WL, 2017, ADV NEUR IN, V30; Hu W., 2020, ADV NEURAL INFORM PR, V33, P22118; Janizek JD, 2021, J MACH LEARN RES, V22; Ji C., 2020, CORR; Keith JA, 2021, CHEM REV, V121, P9816, DOI 10.1021/acs.chemrev.1c00107; Kipf T. N., 2017, INT C LEARN REPR, DOI [DOI 10.1109/ICDM.2008.17, DOI 10.1109/ICDM.2019.00070]; Lapuschkin S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08987-4; Lin WY, 2021, PR MACH LEARN RES, V139; Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11; Luo D., 2020, NEURIPS, V33, P19620, DOI DOI 10.48550/ARXIV.2011.04573; Marcheggiani D., 2017, P 2017 C EMP METH NA, P1506, DOI [10.18653/v1/D17-1159, DOI 10.18653/V1/D17-1159]; Montavon G., 2019, EXPLAINABLE INTERPRE, P253, DOI [10.1007/978-3-030-28954-6_13, DOI 10.1007/978-3-030-28954-6_13]; Montavon Gr<prime>egoire, 2019, EXPLAINABLE AI INTER, P193, DOI DOI 10.1007/978-3-030-28954-6_10; Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011; Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008; Mordvintsev A, 2015, INCEPTIONISM GOING D; Noe F, 2020, ANNU REV PHYS CHEM, V71, P361, DOI 10.1146/annurev-physchem-042018-052331; Perelygin Socher A, 2013, P 2013 C EMP METH NA, P1631; Pope PE, 2019, PROC CVPR IEEE, P10764, DOI 10.1109/CVPR.2019.01103; Ramakrishnan R, 2014, SCI DATA, V1, DOI 10.1038/sdata.2014.22; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rieck K, 2010, J MACH LEARN RES, V11, P555; Samek W., 2019, EXPLAINABLE AI INTER, V1700; Samek W, 2021, P IEEE, V109, P247, DOI 10.1109/JPROC.2021.3060483; Samek W, 2017, IEEE T NEUR NET LEAR, V28, P2660, DOI 10.1109/TNNLS.2016.2599820; Sanchez-Lengeling B., 2020, PROC 34 INT C NEURAL, V33, P5898; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Sch_utt K. T., 2019, EXPLAINABLE INTERPRE, V11700, P311; Sch_utt K. T., 2020, MACHINE LEARNINGMEET, V968; Schlichtkrull M.S., 2021, PROC INT C LEARN REP; Schutt KT, 2018, J CHEM PHYS, V148, DOI 10.1063/1.5019779; Schutt KT, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms13890; Schutt KT, 2019, J CHEM THEORY COMPUT, V15, P448, DOI 10.1021/acs.jctc.8b00908; Schutt K.T., 2017, ADV NEURAL INF PROCE, V30, P992; Schwarzenberg Robert, 2019, EMNLP IJCNLP 2019 GR, P58, DOI [10.18653/v1/d19-5308, DOI 10.18653/V1/D19-5308, 10.18653/v1/D19-5308]; Shrikumar A, 2017, PR MACH LEARN RES, V70; Simonyan K., 2015, INT C LEARN REPR ICL; Sundararajan M, 2017, PR MACH LEARN RES, V70; Tsang M., 2018, PROC 6 INT C LEARN R; Unke OT, 2021, CHEM REV, V121, P10142, DOI 10.1021/acs.chemrev.0c01111; Vu M., 2020, P 34 INT C NEUR INF, P12225; Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362; Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386; Xu K.-Y, 2019, PROC 7 INT C LEARN R; Ying Rex, 2019, Adv Neural Inf Process Syst, V32, P9240; Ying R, 2018, ADV NEUR IN, V31; Yu B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3634; Yuan H., 2020, ARXIV; Yuan H, 2021, PR MACH LEARN RES, V139; Yuan H, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P430, DOI 10.1145/3394486.3403085; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhou J., 2020, OPEN, V1, DOI [10.1016/j.aiopen.2021.01.001, DOI 10.1016/J.AIOPEN.2021.01.001]; Zitnik M, 2018, BIOINFORMATICS, V34, P457, DOI 10.1093/bioinformatics/bty294	78	6	6	5	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					7581	7596		10.1109/TPAMI.2021.3115452	http://dx.doi.org/10.1109/TPAMI.2021.3115452			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34559639	hybrid, Green Submitted			2022-12-18	WOS:000864325900025
J	Huan, LX; Xue, N; Zheng, XW; He, W; Gong, JY; Xia, GS				Huan, Linxi; Xue, Nan; Zheng, Xianwei; He, Wei; Gong, Jianya; Xia, Gui-Song			Unmixing Convolutional Features for Crisp Edge Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image edge detection; Cats; Location awareness; Detectors; Entropy; Feature extraction; Training; Edge detection; deep learning; convolutional feature unmixing	BOUNDARIES	This article presents a context-aware tracing strategy (CATS) for crisp edge detection with deep edge detectors, based on an observation that the localization ambiguity of deep edge detectors is mainly caused by the mixing phenomenon of convolutional neural networks: Feature mixing in edge classification and side mixing during fusing side predictions. The CATS consists of two modules: A novel tracing loss that performs feature unmixing by tracing boundaries for better side edge learning, and a context-aware fusion block that tackles the side mixing by aggregating the complementary merits of learned side edges. Experiments demonstrate that the proposed CATS can be integrated into modern deep edge detectors to improve localization accuracy. With the vanilla VGG16 backbone, in terms of BSDS500 dataset, our CATS improves the F-measure (ODS) of the RCF and BDCN deep edge detectors by 12 and 6 percent, respectively when evaluating without using the morphological non-maximal suppression scheme for edge detection.	[Huan, Linxi; Zheng, Xianwei; Gong, Jianya] Wuhan Univ, LIESMARS, Wuhan 430079, Peoples R China; [Xue, Nan; Xia, Gui-Song] Wuhan Univ, Sch Comp Sci, Wuhan 430079, Peoples R China; [He, Wei] RIKEN Ctr, Tokyo 1030027, Japan; [Gong, Jianya] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China	Wuhan University; Wuhan University; RIKEN; Wuhan University	Zheng, XW (corresponding author), Wuhan Univ, LIESMARS, Wuhan 430079, Peoples R China.	whu_hlx@whu.edu.cn; xuenan@whu.edu.cn; zhengxw@whu.edu.cn; wei.he@riken.jp; gongjy@whu.edu.cn; guisong.xia@whu.edu.cn	Xue, Nan/HCI-0300-2022	Xia, Gui-Song/0000-0001-7660-6090	National Key Research and Development Program of China [2018YFB0505400]; National Natural Science Foundation of China Project [42071370, 61922065]	National Key Research and Development Program of China; National Natural Science Foundation of China Project(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China under Grant 2018YFB0505400 and in part by the National Natural Science Foundation of China Project under Grants 42071370 and 61922065. Linxi Huan and Nan Xue contributed equally to this work.	Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bertasius G, 2015, IEEE I CONF COMP VIS, P504, DOI 10.1109/ICCV.2015.65; Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; De Brabandere B, 2016, ADV NEUR IN, V29; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng RX, 2018, LECT NOTES COMPUT SC, V11210, P570, DOI 10.1007/978-3-030-01231-1_35; Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36; Hallman S, 2015, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2015.7298782; He JZ, 2019, PROC CVPR IEEE, P3823, DOI 10.1109/CVPR.2019.00395; Hu Y, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P782; Iasonas Kokkinos, 2016, Arxiv, DOI arXiv:1511.07386; Kittler J, 1983, IMAGE VISION COMPUT, V1, P37, DOI DOI 10.1016/0262-8856(83)90006-9; Liao Y, 2017, IEEE INT CON MULTI, P859, DOI 10.1109/ICME.2017.8019358; Liu Y, 2016, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2016.32; Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mely DA, 2016, VISION RES, V120, P93, DOI 10.1016/j.visres.2015.11.007; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; Paszke A, 2019, ADV NEUR IN, V32; Roberts Lawrence G, 1963, THESIS, P2; Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Wang YP, 2019, IEEE T IMAGE PROCESS, V28, P1285, DOI 10.1109/TIP.2018.2874279; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xiaofeng R., 2012, P ADV NEUR INF PROC, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu D, 2017, ADV NEUR IN, V30; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28	34	6	6	13	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6602	6609		10.1109/TPAMI.2021.3084197	http://dx.doi.org/10.1109/TPAMI.2021.3084197			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34043504	Green Submitted			2022-12-18	WOS:000853875300055
J	Liu, YH; Zhang, FD; Chen, CQ; Wang, SW; Wang, YZ; Yu, YZ				Liu, Yuhang; Zhang, Fandong; Chen, Chaoqi; Wang, Siwen; Wang, Yizhou; Yu, Yizhou			Act Like a Radiologist: Towards Reliable Multi-View Correspondence Reasoning for Mammogram Mass Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cognition; Mammography; Visualization; Solid modeling; Bipartite graph; Semantics; Proposals; Detection; graph convolutional network; multi-view reasoning; mammogram	CONVOLUTIONAL NEURAL-NETWORKS; AUTOMATED DETECTION; BREAST MASSES; MODEL; CLASSIFICATION; ALGORITHM; SELECTION	Mammogram mass detection is crucial for diagnosing and preventing the breast cancers in clinical practice. The complementary effect of multi-view mammogram images provides valuable information about the breast anatomical prior structure and is of great significance in digital mammography interpretation. However, unlike radiologists who can utilize the natural reasoning ability to identify masses based on multiple mammographic views, how to endow the existing object detection models with the capability of multi-view reasoning is vital for decision-making in clinical diagnosis but remains the boundary to explore. In this paper, we propose an anatomy-aware graph convolutional network (AGN), which is tailored for mammogram mass detection and endows existing detection methods with multi-view reasoning ability. The proposed AGN consists of three steps. First, we introduce a bipartite graph convolutional network (BGN) to model the intrinsic geometric and semantic relations of ipsilateral views. Second, considering that the visual asymmetry of bilateral views is widely adopted in clinical practice to assist the diagnosis of breast lesions, we propose an inception graph convolutional network (IGN) to model the structural similarities of bilateral views. Finally, based on the constructed graphs, the multi-view information is propagated through nodes methodically, which equips the features learned from the examined view with multi-view reasoning ability. Experiments on two standard benchmarks reveal that AGN significantly exceeds the state-of-the-art performance. Visualization results show that AGN provides interpretable visual cues for clinical diagnosis.	[Liu, Yuhang; Chen, Chaoqi; Wang, Siwen] Deepwise Healthcare, AI Lab, Beijing 100080, Peoples R China; [Zhang, Fandong] Peking Univ, Ctr Data Sci, Beijing 100871, Peoples R China; [Wang, Yizhou] Peking Univ, Ctr Frontiers Comp Studies, Adv Inst Informat Technol, Dept Comp Sci & Technol, Beijing 100871, Peoples R China; [Yu, Yizhou] Univ Hong Kong, Dept Comp Sci, Pokfulam, Hong Kong, Peoples R China	Peking University; Peking University; University of Hong Kong	Yu, YZ (corresponding author), Univ Hong Kong, Dept Comp Sci, Pokfulam, Hong Kong, Peoples R China.	liuyuhang@pku.edu.cn; fd.zhang@pku.edu.cn; cqchen1994@gmail.com; wangsiwen@deepwise.com; Yizhou.Wang@pku.edu.cn; yizhouy@acm.org			Zhejiang Province Key Research & Development Program [2020C03073, MOST-2018AAA0102004]; National Natural Science Foundation of China [61625201, 61527804]; DFG TRR169/NSFC Major International Collaboration Project "Crossmodal Learning"	Zhejiang Province Key Research & Development Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); DFG TRR169/NSFC Major International Collaboration Project "Crossmodal Learning"(Fondazione Telethon)	This work was supported in part by Zhejiang Province Key Research & Development Program (No. 2020C03073), MOST-2018AAA0102004, National Natural Science Foundation of China (No. 61625201, No. 61527804), DFG TRR169/NSFC Major International Collaboration Project "Crossmodal Learning". Yuhang Li and Fandong Zhang contributed equally to thiswork.	Adam P. Harrison, 2020, Arxiv, DOI arXiv:2007.01464; Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Almazan J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814; Aurenhammer F, 2000, HANDBOOK OF COMPUTATIONAL GEOMETRY, P201, DOI 10.1016/B978-044482537-7/50006-1; Diniz JOB, 2018, COMPUT METH PROG BIO, V156, P191, DOI 10.1016/j.cmpb.2018.01.007; Bjoern H Menze, 2019, Arxiv, DOI arXiv:1907.00528; BRZAKOVIC D, 1990, IEEE T MED IMAGING, V9, P233, DOI 10.1109/42.57760; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Campanini R, 2004, PHYS MED BIOL, V49, P961, DOI 10.1088/0031-9155/49/6/007; Cao ZJ, 2019, IEEE INT CONF COMP V, P362, DOI 10.1109/ICCVW.2019.00047; Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567; Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685; Chen XL, 2018, PROC CVPR IEEE, P7239, DOI 10.1109/CVPR.2018.00756; Cheng HD, 2006, PATTERN RECOGN, V39, P646, DOI 10.1016/j.patcog.2005.07.006; Ciompi F, 2015, MED IMAGE ANAL, V26, P195, DOI 10.1016/j.media.2015.08.001; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009; Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160; Dryden I. L., 2016, WILEY SERIES PROBABI, V2nd; Eltonsy NH, 2007, IEEE T MED IMAGING, V26, P880, DOI 10.1109/TMI.2007.895460; Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035; Frome A., 2013, ADV NEURAL INFORM PR, P2121; Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478; Guo ZH, 2018, I S BIOMED IMAGING, P1230; Han Hu, 2019, Arxiv, DOI arXiv:1904.11490; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212; Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378; Jiang CH, 2018, ADV NEUR IN, V31; Johns E, 2016, PROC CVPR IEEE, P3813, DOI 10.1109/CVPR.2016.414; Jung H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203355; Kar A, 2017, ADV NEUR IN, V30; Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Li H, 2001, IEEE T MED IMAGING, V20, P289, DOI 10.1109/42.921478; Li Y, 2018, ADV NEUR IN, V31; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu JY, 2019, IEEE I CONF COMP VIS, P10631, DOI 10.1109/ICCV.2019.01073; Liu YH, 2020, PROC CVPR IEEE, P3811, DOI 10.1109/CVPR42600.2020.00387; Liu YH, 2019, LECT NOTES COMPUT SC, V11769, P477, DOI 10.1007/978-3-030-32226-7_53; Mao JH, 2015, IEEE I CONF COMP VIS, P2533, DOI 10.1109/ICCV.2015.291; Marino K., 2016, ARXIV; Max Welling, 2017, Arxiv, DOI arXiv:1609.02907; Mendez AJ, 1998, MED PHYS, V25, P957, DOI 10.1118/1.598274; Misra I, 2017, PROC CVPR IEEE, P1160, DOI 10.1109/CVPR.2017.129; Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014; Mudigonda NR, 2001, IEEE T MED IMAGING, V20, P1215, DOI 10.1109/42.974917; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609; Rebecq H, 2018, INT J COMPUT VISION, V126, P1394, DOI 10.1007/s11263-017-1050-6; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z; Sampat MP, 2008, MED PHYS, V35, P2110, DOI 10.1118/1.2890080; Sampat MP, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P1195, DOI 10.1016/B978-012119792-6/50130-3; Schops T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272; Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809; Shen W, 2017, PATTERN RECOGN, V61, P663, DOI 10.1016/j.patcog.2016.05.029; Sickles E A, 1997, J Natl Cancer Inst Monogr, P99; Siegel RL, 2015, CA-CANCER J CLIN, V65, P5, DOI 10.3322/caac.21254; Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114; SUCKLING J, 1994, INT CONGR SER, V1069, P375; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tai SC, 2014, IEEE J BIOMED HEALTH, V18, P618, DOI 10.1109/JBHI.2013.2279097; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang S, 2017, MED IMAGE ANAL, V40, P172, DOI 10.1016/j.media.2017.06.014; Wei J, 2005, MED PHYS, V32, P2827, DOI 10.1118/1.1997327; Wu BT, 2019, IEEE I CONF COMP VIS, P10589, DOI 10.1109/ICCV.2019.01069; Wu N, 2020, IEEE T MED IMAGING, V39, P1184, DOI 10.1109/TMI.2019.2945514; Xu H, 2019, PROC CVPR IEEE, P6412, DOI 10.1109/CVPR.2019.00658; Xu ZB, 2018, LECT NOTES COMPUT SC, V11071, P711, DOI 10.1007/978-3-030-00934-2_79; Yang Z, 2019, IEEE I CONF COMP VIS, P7504, DOI 10.1109/ICCV.2019.00760; Yellin F, 2018, PROC CVPR IEEE, P8953, DOI 10.1109/CVPR.2018.00933; Zhang FD, 2019, PROC CVPR IEEE, P12570, DOI 10.1109/CVPR.2019.01286; Zhe L, 2018, PROC CVPR IEEE, P8290, DOI 10.1109/CVPR.2018.00865; Zheng L, 2001, IEEE T MED IMAGING, V20, P559, DOI 10.1109/42.932741; Zhicheng Yang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P200, DOI 10.1007/978-3-030-59725-2_20	81	6	6	9	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					5947	5961		10.1109/TPAMI.2021.3085783	http://dx.doi.org/10.1109/TPAMI.2021.3085783			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34061740	Green Submitted			2022-12-18	WOS:000853875300011
J	Qin, YX; Yu, ZT; Yan, LB; Wang, ZZ; Zhao, CX; Lei, Z				Qin, Yunxiao; Yu, Zitong; Yan, Longbin; Wang, Zezheng; Zhao, Chenxu; Lei, Zhen			Meta-Teacher For Face Anti-Spoofing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Detectors; Face recognition; Training; Faces; Feature extraction; Training data; Optimization; Face anti-spoofing; meta-teacher; pixel-wise supervision; deep-learning		Face anti-spoofing (FAS) secures face recognition from presentation attacks (PAs). Existing FAS methods usually supervise PA detectors with handcrafted binary or pixel-wise labels. However, handcrafted labels may are not the most adequate way to supervise PA detectors learning sufficient and intrinsic spoofing cues. Instead of using the handcrafted labels, we propose a novel Meta-Teacher FAS (MT-FAS) method to train a meta-teacher for supervising PA detectors more effectively. The meta-teacher is trained in a bi-level optimization manner to learn the ability to supervise the PA detectors learning rich spoofing cues. The bi-level optimization contains two key components: 1) a lower-level training in which the meta-teacher supervises the detector's learning process on the training set; and 2) a higher-level training in which the meta-teacher's teaching performance is optimized by minimizing the detector's validation loss. Our meta-teacher differs significantly from existing teacher-student models because the meta-teacher is explicitly trained for better teaching the detector (student), whereas existing teachers are trained for outstanding accuracy neglecting teaching ability. Extensive experiments on five FAS benchmarks show that with the proposed MT-FAS, the trained meta-teacher 1) provides better-suited supervision than both handcrafted labels and existing teacher-student models; and 2) significantly improves the performances of PA detectors.	[Qin, Yunxiao] Commun Univ China, Neurosci & Intelligent Media Inst NIMI, Beijing 100024, Peoples R China; [Qin, Yunxiao; Yan, Longbin] Northwestern Polytech Univ, Xian 710072, Peoples R China; [Yu, Zitong] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu 90014, Finland; [Wang, Zezheng] Beijing Kwai Technol Co Ltd, Beijing 102600, Peoples R China; [Zhao, Chenxu] MiningLamp Technol, Beijing 100000, Peoples R China; [Lei, Zhen] Chinese Acad Sci CASIA, Ctr Biometr & Secur Res CBSR, Inst Automat, Natl Lab Pattern Recognit NLPR, Beijing 100190, Peoples R China; [Lei, Zhen] Univ Chinese Acad Sci UCAS, Sch Artificial Intelligence, Beijing 100049, Peoples R China; [Lei, Zhen] Chinese Acad Sci, Ctr Artificial Intelligence & Robot, Hong Kong Inst Sci & Innovat, Hong Kong, Peoples R China	Communication University of China; Northwestern Polytechnical University; University of Oulu; Chinese Academy of Sciences	Lei, Z (corresponding author), Chinese Acad Sci CASIA, Ctr Biometr & Secur Res CBSR, Inst Automat, Natl Lab Pattern Recognit NLPR, Beijing 100190, Peoples R China.	qyxqyx@mail.nwpu.edu.cn; zitong.yu@oulu.fi; yanlongbin@mail.nwpu.edu.cn; wangzezheng@kuaishou.com; zhaochenxu@mininglamp.com; zlei@nlpr.ia.ac.cn			National Key Research and Development Program of China [2020AAA0140002]; National Natural Science Foundation of China [61876178, 61976229]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China under Grant 2020AAA0140002 and in part by the National Natural Science Foundation of China under Grants 61876178 and 61976229.	[Anonymous], 2016, 3010712016 ISO IEC; Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713; Boulkenafet Z, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P688; Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740; Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286; Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280; Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77; Bucilua Cristian, 2006, P 12 ACM SIGKDD INT, P535, DOI [10.1145/1150402.1150464, DOI 10.1145/1150402.1150464]; Cai RZ, 2021, IEEE T INF FOREN SEC, V16, P937, DOI 10.1109/TIFS.2020.3026553; Chen DF, 2020, AAAI CONF ARTIF INTE, V34, P3430; Chen GB, 2017, ADV NEUR IN, V30; Chingovska Ivana, 2012, P INT C BIOM SPEC IN, P1; Cho JH, 2019, IEEE I CONF COMP VIS, P4793, DOI 10.1109/ICCV.2019.00489; Colson B, 2007, ANN OPER RES, V153, P235, DOI 10.1007/s10479-007-0176-2; de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Dong Yi, 2014, Arxiv, DOI arXiv:1411.7923; Fei Chen, 2017, Arxiv, DOI arXiv:1707.09835; Finn C, 2017, PR MACH LEARN RES, V70; Geoffrey Hinton, 2015, Arxiv, DOI arXiv:1503.02531; Georgescu A.-L., 2019, 2019 INT C BIOM ICB, P1, DOI DOI 10.1109/ICB45273.2019.8987370; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jin X, 2019, IEEE I CONF COMP VIS, P1345, DOI 10.1109/ICCV.2019.00143; Jourabloo A, 2018, LECT NOTES COMPUT SC, V11217, P297, DOI 10.1007/978-3-030-01261-8_18; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; Kim T, 2019, IEEE INT CONF COMP V, P494, DOI 10.1109/ICCVW.2019.00062; Komulainen J., 2013, INT C BIOMETRICS THE, P1; Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566; Li L, 2016, INT CONF IMAG PROC; Li XB, 2016, INT C PATT RECOG, P4244, DOI 10.1109/ICPR.2016.7900300; Lin Bofan, 2019, P 2019 3 INT C BIOM, P61, DOI DOI 10.1145/3345336.3345345; Liu AJ, 2021, IEEE T INF FOREN SEC, V16, P2759, DOI 10.1109/TIFS.2021.3065495; Liu Hanxiao, 2019, INTERNATIONAL CONFER; Liu SQ, 2016, LECT NOTES COMPUT SC, V9911, P85, DOI 10.1007/978-3-319-46478-7_6; Liu Y., 2020, ARXIV PREPRINT ARXIV; Liu YJ, 2019, PROC CVPR IEEE, P4675, DOI 10.1109/CVPR.2019.00481; Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048; Lucena O, 2017, LECT NOTES COMPUT SC, V10317, P27, DOI 10.1007/978-3-319-59876-5_4; Mi i tti J., 2011, P INT JOINT C BIOM I, P1; Mirzadeh SI, 2020, AAAI CONF ARTIF INTE, V34, P5191; Nagpal C, 2019, IEEE IJCNN; Patel K, 2016, LECT NOTES COMPUT SC, V9967, P611, DOI 10.1007/978-3-319-46654-5_67; Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288; Peixoto Bruno, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3557, DOI 10.1109/ICIP.2011.6116484; Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2; Qin YX, 2020, AAAI CONF ARTIF INTE, V34, P11916; Qin YX, 2020, IEEE SIGNAL PROC LET, V27, P2044, DOI 10.1109/LSP.2020.3036348; Qin YX, 2020, NEUROCOMPUTING, V417, P384, DOI 10.1016/j.neucom.2020.08.068; Romero Adriana, 2015, ICLR; Shao R, 2020, AAAI CONF ARTIF INTE, V34, P11974; Shao R, 2019, PROC CVPR IEEE, P10015, DOI 10.1109/CVPR.2019.01026; Shao R, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P748, DOI 10.1109/BTAS.2017.8272765; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; UMPHRESS D, 1985, INT J MAN MACH STUD, V23, P263, DOI 10.1016/S0020-7373(85)80036-5; Wang ZZ, 2020, PROC CVPR IEEE, P5041, DOI 10.1109/CVPR42600.2020.00509; Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395; Wu X., 2020, IEEE T INF FOREN SEC, V16, P1440; Xu ZQ, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P141, DOI 10.1109/ACPR.2015.7486482; Yang Jianwei, 2014, ARXIV14085601; Yang X, 2019, PROC CVPR IEEE, P3502, DOI 10.1109/CVPR.2019.00362; Yu Z, 2020, P IEEE C COMP VIS PA, P650; Yu Z., 2021, IEEE T BIOMETRICS BE, V3, P285, DOI DOI 10.1109/TBIOM.2021.3065526; Yu Z., IEEE T PATTERN ANAL, V16, P2759; Yu ZT, 2020, PROC CVPR IEEE, P5294, DOI 10.1109/CVPR42600.2020.00534; Yu ZT, 2020, INT CONF ACOUST SPEE, P996, DOI 10.1109/ICASSP40776.2020.9053587; Yuanhan Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P70, DOI 10.1007/978-3-030-58610-2_5; Yunpei Jia, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8481, DOI 10.1109/CVPR42600.2020.00851; Zhang K., 2020, P EUR C COMP VIS, P641; Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754; Zitong Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P557, DOI 10.1007/978-3-030-58571-6_33	74	6	6	7	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6311	6326		10.1109/TPAMI.2021.3091167	http://dx.doi.org/10.1109/TPAMI.2021.3091167			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34156938	Green Submitted, Green Accepted			2022-12-18	WOS:000853875300035
J	Wang, YK; Zhang, L; Yao, Y; Fu, YW				Wang, Yikai; Zhang, Li; Yao, Yuan; Fu, Yanwei			How to Trust Unlabeled Data? Instance Credibility Inference for Few-Shot Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Data models; Noise measurement; Task analysis; Feature extraction; Visualization; Standards; Few-shot learning; incidental parameters; regularization path; semi-supervised learning; self-taught learning	NONLINEAR DIMENSIONALITY REDUCTION; CONSISTENCY; SELECTION	Deep learning based models have excelled in many computer vision tasks and appear to surpass humans' performance. However, these models require an avalanche of expensive human labeled training data and many iterations to train their large number of parameters. This severely limits their scalability to the real-world long-tail distributed categories, some of which are with a large number of instances, but with only a few manually annotated. Learning from such extremely limited labeled examples is known as Few-Shot Learning (FSL). Different to prior arts that leverage meta-learning or data augmentation strategies to alleviate this extremely data-scarce problem, this paper presents a statistical approach, dubbed Instance Credibility Inference (ICI) to exploit the support of unlabeled instances for few-shot visual recognition. Typically, we repurpose the self-taught learning paradigm to predict pseudo-labels of unlabeled instances with an initial classifier trained from the few shot and then select the most confident ones to augment the training set to re-train the classifier. This is achieved by constructing a (Generalized) Linear Model (LM/GLM) with incidental parameters to model the mapping from (un-)labeled features to their (pseudo-)labels, in which the sparsity of the incidental parameters indicates the credibility of the corresponding pseudo-labeled instance. We rank the credibility of pseudo-labeled instances along the regularization path of their corresponding incidental parameters, and the most trustworthy pseudo-labeled examples are preserved as the augmented labeled instances. This process is repeated until all the unlabeled samples are included in the expanded training set. Theoretically, under the conditions of restricted eigenvalue, irrepresentability, and large error, our approach is guaranteed to collect all the correctly-predicted pseudo-labeled instances from the noisy pseudo-labeled set. Extensive experiments under two few-shot settings show the effectiveness of our approach on four widely used few-shot visual recognition benchmark datasets including miniImageNet, tieredImageNet, CIFAR-FS, and CUB. Code and models are released at https://github.com/Yikai-Wang/ICI-FSL.	[Wang, Yikai; Zhang, Li; Fu, Yanwei] Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China; [Wang, Yikai; Zhang, Li; Fu, Yanwei] Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200433, Peoples R China; [Yao, Yuan] Hong Kong Univ Sci & Technol, Dept Math, Hong Kong, Peoples R China; [Yao, Yuan] Hong Kong Univ Sci & Technol, Dept Chem & Biol Engn, Hong Kong, Peoples R China; [Fu, Yanwei] Fudan Univ, MOE Frontiers Ctr Brain Sci, Shanghai 200433, Peoples R China	Fudan University; Fudan University; Hong Kong University of Science & Technology; Hong Kong University of Science & Technology; Fudan University	Fu, YW (corresponding author), Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China.; Yao, Y (corresponding author), Hong Kong Univ Sci & Technol, Dept Math, Hong Kong, Peoples R China.; Yao, Y (corresponding author), Hong Kong Univ Sci & Technol, Dept Chem & Biol Engn, Hong Kong, Peoples R China.	yikaiwang19@fudan.edu.cn; lizhangfd@fudan.edu.cn; yuany@ust.hk; yanweifu@fudan.edu.cn			NSFC [U62076067]; Science and Technology Commission of Shanghai Municipality [19511120700, 19ZR1471800]; Hong Kong Research Grant Council [16303817]; ITF [UIM/390]; Tencent AI Lab; Si Family Foundation; Microsoft Research-Asia	NSFC(National Natural Science Foundation of China (NSFC)); Science and Technology Commission of Shanghai Municipality(Science & Technology Commission of Shanghai Municipality (STCSM)); Hong Kong Research Grant Council(Hong Kong Research Grants Council); ITF; Tencent AI Lab; Si Family Foundation; Microsoft Research-Asia(Microsoft)	This work was supported in part by NSFC Projects under Grant U62076067, and in part by the Science and Technology Commission of Shanghai Municipality Projects under Grants 19511120700 and 19ZR1471800. The work of Yuan Yao was supported in part by Hong Kong Research Grant Council under Grant 16303817, in part by ITF UIM/390, and awards from Tencent AI Lab, Si Family Foundation, and Microsoft Research-Asia. Yuan Yao and Yanwei Fu are the co-corresponding authors.	Alex Nichol, 2018, Arxiv, DOI arXiv:1803.02999; Amini MR, 2002, FR ART INT, V77, P390; Andrew McCallum, 2018, Arxiv, DOI arXiv:1704.07433; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Angluin D., 1988, Machine Learning, V2, P343, DOI 10.1007/BF00116829; Arazo E, 2019, PR MACH LEARN RES, V97; Basu D., 2011, P SEL WORKS DEB BAS, P279; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bennett KP, 1999, ADV NEUR IN, V11, P368; Bernt Schiele, 2019, Arxiv, DOI arXiv:1906.00562; Bertinetto Luca, 2018, INT C LEARN REPR; Chen ZT, 2019, PROC CVPR IEEE, P8672, DOI 10.1109/CVPR.2019.00888; Chen ZT, 2019, IEEE T IMAGE PROCESS, V28, P4594, DOI 10.1109/TIP.2019.2910052; Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222; Diego Ortego, 2020, Arxiv, DOI arXiv:1908.02983; Eduard Hovy, 2020, Arxiv, DOI arXiv:1911.04252; Fan JQ, 2018, STAT SINICA, V28, P2633, DOI 10.5705/ss.202017.0027; Fan JQ, 2010, STAT SINICA, V20, P101; Fei Chen, 2017, Arxiv, DOI arXiv:1707.09835; Finn C, 2017, PR MACH LEARN RES, V70; Flood Sung, 2017, Arxiv, DOI arXiv:1706.09529; Fu YW, 2016, IEEE T PATTERN ANAL, V38, P563, DOI 10.1109/TPAMI.2015.2456887; Ghiasi G, 2018, ADV NEUR IN, V31; Ghosh A, 2017, AAAI CONF ARTIF INTE, P1919; Goldberger J, 2016, INT C LEARNING REPRE; Grandvalet Y., 2005, CAP, P529; Groenen P, 2003, MODERN MULTIDIMENSIO; Hae Beom Lee, 2020, Arxiv, DOI arXiv:2002.12017; Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hilliard N, 2018, ARXIV; Hou RB, 2019, ADV NEUR IN, V32; Hu Y., 2020, ARXIV; Hu Y., 2020, ARXIV; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang JC, 2019, IEEE I CONF COMP VIS, P3325, DOI 10.1109/ICCV.2019.00342; Song H, 2020, Arxiv, DOI arXiv:2007.08199; Iscen A, 2019, PROC CVPR IEEE, P5065, DOI 10.1109/CVPR.2019.00521; Jenni S, 2018, LECT NOTES COMPUT SC, V11214, P632, DOI 10.1007/978-3-030-01249-6_38; Jian Sun, 2015, Arxiv, DOI arXiv:1512.03385; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; KIEFER J, 1956, ANN MATH STAT, V27, P887, DOI 10.1214/aoms/1177728066; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Laine Samuli, 2017, PROC INT C LEARN REP; Lee D., 2013, INT C MACH LEARN ICM; Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091; Lemke C, 2015, ARTIF INTELL REV, V44, P117, DOI 10.1007/s10462-013-9406-y; Li HY, 2019, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2019.00009; Lichtenstein Moshe, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P522, DOI 10.1007/978-3-030-58571-6_31; Ling Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13387, DOI 10.1109/CVPR42600.2020.01340; Liu C, 2020, IEEE COMPUT SOC CONF, P4005, DOI 10.1109/CVPRW50498.2020.00469; Liu Y., 2019, PROC INT C LEARN REP; Liu Y. -C., 2019, PROC INT C LEARN REP; Mishra N., 2018, INT C LEARN REPR; Moreira MJ, 2009, ANN STAT, V37, P3660, DOI 10.1214/09-AOS688; Munkhdalai T, 2018, PR MACH LEARN RES, V80; Neyman J, 1948, ECONOMETRICA, V16, P1, DOI 10.2307/1914288; Oreshkin BN, 2018, ADV NEUR IN, V31; Qiao LM, 2019, IEEE I CONF COMP VIS, P3602, DOI 10.1109/ICCV.2019.00370; Raina R, 2007, 24 ANN INT C MACH LE, V227, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]; Ravi Sachin, 2017, INT C LEARN REPR, V2, P5; Ren M., 2018, ICLR; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rusu Andrei A, 2019, ICLR; Shi WW, 2018, LECT NOTES COMPUT SC, V11209, P311, DOI 10.1007/978-3-030-01228-1_19; Simon Noah, 2013, ARXIV; Snell J, 2017, ADV NEUR IN, V30; Song J., 2020, P EUR C COMP VIS, P556; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; Miyato T, 2016, Arxiv, DOI arXiv:1605.07725; Tarvainen A, 2017, ADV NEUR IN, V30; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tikhonov A.N., 1977, SOLUTIONS ILLPOSED P; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Triantafillou E, 2017, ADV NEUR IN, V30; Vapnik V.N, 1998, STAT LEARNING THEORY; Vinyals O., 2016, ADV NEURAL INFORM PR, P3637, DOI [10.48550/arXiv.1606.04080, DOI 10.5555/3157382.3157504]; Wah C., 2011, CALTECHUCSD BIRDS 20; Wainwright MJ, 2009, IEEE T INFORM THEORY, V55, P2183, DOI 10.1109/TIT.2009.2016018; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Yaoyao Liu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P404, DOI 10.1007/978-3-030-58517-4_24; Yikai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12833, DOI 10.1109/CVPR42600.2020.01285; Yoon SW, 2019, PR MACH LEARN RES, V97; Yosinski J, 2014, ADV NEUR IN, V27; Yu HF, 2011, MACH LEARN, V85, P41, DOI 10.1007/s10994-010-5221-8; Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236	93	6	6	10	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6240	6253		10.1109/TPAMI.2021.3086140	http://dx.doi.org/10.1109/TPAMI.2021.3086140			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34081579	Green Submitted			2022-12-18	WOS:000853875300030
J	Kumawat, S; Verma, M; Nakashima, Y; Raman, S				Kumawat, Sudhakar; Verma, Manisha; Nakashima, Yuta; Raman, Shanmuganathan			Depthwise Spatio-Temporal STFT Convolutiona Neural Networks for Human Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Short-term fourier transform; 3D convolutional networks; human action recognition		Conventional 3D convolutional neural networks (CNNs) are computationally expensive, memory intensive, prone to overfitting, and most importantly, there is a need to improve their feature learning capabilities. To address these issues, we propose spatio-temporal short-term Fourier transform (STFT) blocks, a new class of convolutional blocks that can serve as an alternative to the 3D convolutional layer and its variants in 3D CNNs. An STFT block consists of non-trainable convolution layers that capture spatially and/or temporally local Fourier information using an STFT kernel at multiple low frequency points, followed by a set of trainable linear weights for learning channel correlations. The STFT blocks significantly reduce the space-time complexity in 3D CNNs. In general, they use 3.5 to 4.5 times less parameters and 1.5 to 1.8 times less computational costs when compared to the state-of-the-art methods. Furthermore, their feature learning capabilities are significantly better than the conventional 3D convolutional layer and its variants. Our extensive evaluation on seven action recognition datasets, including Something(2) v1 and v2, Jester, Diving-48, Kinetics-400, UCF 101, and HMDB 51, demonstrate that STFT blocks based 3D CNNs achieve on par or even better performance compared to the state-of-the-art methods.	[Kumawat, Sudhakar; Verma, Manisha; Nakashima, Yuta] Osaka Univ, Inst Databil Sci, Intelligence & Sensing Lab, Osaka 5670871, Japan; [Raman, Shanmuganathan] Indian Inst Technol Gandhinagar, Elect Engn & Comp Sci & Engn, Gandhinagar 382355, Gujarat, India	Osaka University; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Gandhinagar	Kumawat, S (corresponding author), Osaka Univ, Inst Databil Sci, Intelligence & Sensing Lab, Osaka 5670871, Japan.	sudhakar@ids.osaka-u.ac.jp; mverma@ids.osaka-u.ac.jp; n-yuta@ids.osaka-u.ac.jp; shanmuga@iitgn.ac.in		Raman, Shanmuganathan/0000-0003-2718-7891	TCS; MHRD; SERB IMPRINT-2 Grant; JSPS KAKENHI [JP18H03264]	TCS; MHRD; SERB IMPRINT-2 Grant; JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	The work of Sudhakar Kumawat was supported by TCS and MHRD Research Fellowships. The work of Shanmuganathan Raman was supported by SERB IMPRINT-2 Grant. This work was supported in part by JSPS KAKENHI No. JP18H03264.	Amir Roshan Zamir, 2012, Arxiv, DOI arXiv:1212.0402; Andrew G. Howard, 2017, Arxiv, DOI arXiv:1704.04861; Andrew Zisserman, 2017, Arxiv, DOI arXiv:1705.06950; [Anonymous], 20BN JESTER DATASET; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen YP, 2018, LECT NOTES COMPUT SC, V11205, P364, DOI 10.1007/978-3-030-01246-5_22; Chen YP, 2019, IEEE I CONF COMP VIS, P3434, DOI 10.1109/ICCV.2019.00353; Chen YP, 2018, ADV NEUR IN, V31; Christoph Feichtenhofer, 2018, Arxiv, DOI arXiv:1812.04172; Cogswell M., 2016, REDUCING OVERFITTING; Du Tran, 2017, Arxiv, DOI arXiv:1708.05038; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Feichtenhofer C, 2016, ADV NEUR IN, V29; Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630; Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Forrest N. Iandola, 2016, Arxiv, DOI arXiv:1602.07360; Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622; Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685; Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Heikkila J, 2009, LNLA: 2009 INTERNATIONAL WORKSHOP ON LOCAL AND NON-LOCAL APPROXIMATION IN IMAGE PROCESSING, P104, DOI 10.1109/LNLA.2009.5278397; Hinman B., 1984, PROC IEEE INT C ACOU, P166; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang L, 2018, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2018.00089; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209; Kanojia G, 2019, IEEE COMPUT SOC CONF, P2467, DOI 10.1109/CVPRW.2019.00302; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kopuklu O, 2019, IEEE INT CONF COMP V, P1910, DOI 10.1109/ICCVW.2019.00240; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Kumawat S, 2020, INT CONF ACOUST SPEE, P3337, DOI 10.1109/ICASSP40776.2020.9053898; Kumawat S, 2019, PROC CVPR IEEE, P4898, DOI 10.1109/CVPR.2019.00504; Kumra S, 2017, IEEE INT C INT ROBOT, P769; Lee MG, 2018, LECT NOTES COMPUT SC, V11214, P392, DOI 10.1007/978-3-030-01249-6_24; Li YW, 2018, LECT NOTES COMPUT SC, V11210, P520, DOI 10.1007/978-3-030-01231-1_32; Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Ma C., 2017, BRIT MACH VIS C; Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067; Paivarinta J, 2011, LECT NOTES COMPUT SC, V6688, P360, DOI 10.1007/978-3-642-21227-7_34; Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rodriguez Pau, 2017, ICLR; Simonyan K, 2014, ADV NEUR IN, V27; Stroud JC, 2020, IEEE WINT CONF APPL, P614; Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226; Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60; Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xiong W, 2016, IEEE DATA MINING, P519, DOI [10.1109/ICDM.2016.0063, 10.1109/ICDM.2016.66]; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49; Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054; Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43	70	6	6	17	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4839	4851		10.1109/TPAMI.2021.3076522	http://dx.doi.org/10.1109/TPAMI.2021.3076522			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33914681	Green Submitted			2022-12-18	WOS:000836666600028
J	Tan, ZT; Chen, DD; Chu, Q; Chai, ML; Liao, J; He, MM; Yuan, L; Hua, G; Yu, NH				Tan, Zhentao; Chen, Dongdong; Chu, Qi; Chai, Menglei; Liao, Jing; He, Mingming; Yuan, Lu; Hua, Gang; Yu, Nenghai			Efficient Semantic Image Synthesis via Class-Adaptive Normalization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Image synthesis; Modulation; Image segmentation; Task analysis; Generators; Visualization; Semantic image synthesis; Class-adaptive normalization; Positional encoding		Spatially-adaptive normalization (SPADE) is remarkably successful recently in conditional semantic image synthesis in T. Park et al. 2019 which modulates the normalized activation with spatially-varying transformations learned from semantic layouts, to prevent the semantic information from being washed away. Despite its impressive performance, a more thorough understanding of the advantages inside the box is still highly demanded to help reduce the significant computation and parameter overhead introduced by this novel structure. In this paper, from a return-on-investment point of view, we conduct an in-depth analysis of the effectiveness of this spatially-adaptive normalization and observe that its modulation parameters benefit more from semantic-awareness rather than spatial-adaptiveness, especially for high-resolution input masks. Inspired by this observation, we propose class-adaptive normalization (CLADE), a lightweight but equally-effective variant that is only adaptive to semantic class. In order to further improve spatial-adaptiveness, we introduce intra-class positional map encoding calculated from semantic layouts to modulate the normalization parameters of CLADE and propose a truly spatially-adaptive variant of CLADE, namely CLADE-ICPE. Through extensive experiments on multiple challenging datasets, we demonstrate that the proposed CLADE can be generalized to different SPADE-based methods while achieving comparable generation quality compared to SPADE, but it is much more efficient with fewer extra parameters and lower computational cost. The code and pretrained models are available at https://github.com/tzt101/CLADE.git.	[Tan, Zhentao; Chu, Qi; Yu, Nenghai] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230052, Peoples R China; [Chen, Dongdong; Yuan, Lu] Microsoft Cloud AI, Redmond, WA 98052 USA; [Chai, Menglei] Snap Inc, Santa Monica, CA 90405 USA; [Liao, Jing] Univ Hong Kong, Hong Kong, Peoples R China; [He, Mingming] USC Inst Creat Technol, Los Angeles, CA 90094 USA; [Hua, Gang] Wormpex AI Res LLC, Redmond, WA 98004 USA	Chinese Academy of Sciences; University of Science & Technology of China, CAS; University of Hong Kong	Chu, Q (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230052, Peoples R China.	tzt@mail.ustc.edu.cn; cddlyf@gmail.com; qchu@ustc.edu.cn; cmlatsim@gmail.com; jingliao@cihfu.edu.hk; hmm.lillian@gmail.com; luyuan@microsoft.com; ganghua@gmail.com; ynh@ustc.edu.cn	He, Mingming/AAY-5609-2021	He, Mingming/0000-0002-9982-7934; LIAO, Jing/0000-0001-7014-5377	National Natural Science Foundation of China [U20B2047, 62002336]; Exploration Fund Project of University of Science and Technology of China [YD3480002001]; Fundamental Research Funds for the Central Universities [WK2100000011]; Research Grants Council of the Hong Kong [CityU 21209119]; APRC grant from CityU, Hong Kong [9610488]; National Key R&D Program of China [2018AAA0101400]; NSFC [61629301]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Exploration Fund Project of University of Science and Technology of China; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Research Grants Council of the Hong Kong(Hong Kong Research Grants Council); APRC grant from CityU, Hong Kong; National Key R&D Program of China; NSFC(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China under Grant U20B2047 and 62002336, Exploration Fund Project of University of Science and Technology of China under Grant YD3480002001 and the Fundamental Research Funds for the Central Universities under Grant WK2100000011. The work of Jing Liao was supported by the ECS grant from the Research Grants Council of the Hong Kong through Project CityU 21209119 and an APRC grant from CityU, Hong Kong, through Project 9610488. The work of Gang Hua was supported in part by the National Key R&D Program of China under Grant 2018AAA0101400 and in part by the NSFC under Grant 61629301. Zhentao Tan and Dongdong Chen are co-first authors.	Alec Radford, 2016, Arxiv, DOI arXiv:1511.06434; Andrea Vedaldi, 2017, Arxiv, DOI arXiv:1607.08022; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Ba J., 2017, P 3 INT C LEARN REPR; Brock A., 2018, PROC INTERNAT C LEAR; Changxu Zhang, 2020, Arxiv, DOI arXiv:2007.12072; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168; Chintala S., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1701.07875; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; CSAILVision, 2019, PYT IMPL SEM SEGM SC; Dundar Aysegul, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8067, DOI 10.1109/CVPR42600.2020.00809; Github, 2019, DILATED RESIDUAL NET; Github, 2020, SWITCHABLENORMS; Github, 2019, KAZUTO1011; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Haitian Zheng, 2019, Arxiv, DOI arXiv:1911.12362; Hensel M, 2017, ADV NEUR IN, V30; Hong S, 2018, PROC CVPR IEEE, P7986, DOI 10.1109/CVPR.2018.00833; Hsin-Ping Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P592, DOI 10.1007/978-3-030-58610-2_35; Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jaakko Lehtinen, 2018, Arxiv, DOI arXiv:1710.10196; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Jonathon Shlens, 2017, Arxiv, DOI arXiv:1610.07629; Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559; Li B., 2019, P ADV NEUR INF PROC, V32, P1622; Liu MY, 2017, ADV NEUR IN, V30; Liu XH, 2019, ADV NEUR IN, V32; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Oza Manan, 2019, 2019 International Conference of Artificial Intelligence and Information Technology (ICAIIT). Proceedings, P16, DOI 10.1109/ICAIIT.2019.8834613; Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244; Reed S, 2016, PR MACH LEARN RES, V48; Ronneberger O., 2015, P INT C MED IM COMP; Salimans T, 2016, ADV NEUR IN, V29; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tan ZT, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392488; Tang H., 2020, ACM INT C MULTIMEDIA; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w; Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26; Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143; Yipeng Qin, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P310, DOI 10.1007/978-3-030-58517-4_19; Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75; Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821; Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629; Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519; Tan ZT, 2021, Arxiv, DOI arXiv:2103.06878; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu PH, 2020, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR42600.2020.00515; Zhu Z, 2020, PROC CVPR IEEE, P5466, DOI 10.1109/CVPR42600.2020.00551	59	6	6	6	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4852	4866		10.1109/TPAMI.2021.3076487	http://dx.doi.org/10.1109/TPAMI.2021.3076487			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33914680	Green Submitted			2022-12-18	WOS:000836666600029
J	Yang, ZX; Wei, YC; Yang, Y				Yang, Zongxin; Wei, Yunchao; Yang, Yi			Collaborative Video Object Segmentation by Multi-Scale Foreground-Background Integration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video object segmentation; convolutional neural networks; metric learning		This paper investigates the principles of embedding learning to tackle the challenging semi-supervised video object segmentation. Unlike previous practices that focus on exploring the embedding learning of foreground object (s), we consider background should be equally treated. Thus, we propose a Collaborative video object segmentation by Foreground-Background Integration (CFBI) approach. CFBI separates the feature embedding into the foreground object region and its corresponding background region, implicitly promoting them to be more contrastive and improving the segmentation results accordingly. Moreover, CFBI performs both pixel-level matching processes and instance-level attention mechanisms between the reference and the predicted sequence, making CFBI robust to various object scales. Based on CFBI, we introduce a multi-scale matching structure and propose an Atrous Matching strategy, resulting in a more robust and efficient framework, CFBI+. We conduct extensive experiments on two popular benchmarks, i.e., DAVIS and YouTube-VOS. Without applying any simulated data for pre-training, our CFBI+ achieves the performance (J&F) of 82.9 and 82.8 percent, outperforming all the other state-of-the-art methods.	[Yang, Zongxin; Yang, Yi] Zhejiang Univ, Coll Comp Sci & Technol, CCAI, Hangzhou 310027, Zhejiang, Peoples R China; [Wei, Yunchao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China	Zhejiang University; Beijing Jiaotong University	Yang, Y (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, CCAI, Hangzhou 310027, Zhejiang, Peoples R China.	zongxinyang1996@gmail.com; wychao1987@gmail.com; yee.i.yang@gmail.com	yang, yang/HGT-7999-2022; Yang, Yi/B-9273-2017	Yang, Yi/0000-0002-0512-880X	National Key Research and Development Program of China [2020AAA0108800]	National Key Research and Development Program of China	This work was supported by the National Key Research and Development Program of China (2020AAA0108800).	Aggarwal A, 2006, LECT NOTES COMPUT SC, V3852, P121; Badrinarayanan V, 2010, PROC CVPR IEEE, P3265, DOI 10.1109/CVPR.2010.5540054; Bastian Leibe, 2019, Arxiv, DOI arXiv:1904.04552; Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P777, DOI 10.1007/978-3-030-58536-5_46; Borji A., 2012, PROC IEEE COMPUT SOC, P23; Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen Liang-Chieh, 2018, P EUROPEAN C COMPUTE, P801; Chen YH, 2018, PROC CVPR IEEE, P1189, DOI 10.1109/CVPR.2018.00130; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Dauphin YN, 2017, PR MACH LEARN RES, V70; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dingcheng Yue, 2018, Arxiv, DOI arXiv:1809.03327; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Feng QY, 2019, IEEE INT CONF COMP V, P717, DOI 10.1109/ICCVW.2019.00090; Fisher Yu, 2016, Arxiv, DOI arXiv:1511.07122; Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI 10.1109/ICCV.2017.129; Gehring J, 2017, PR MACH LEARN RES, V70; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Holschneider M., 1990, WAVELETS, p286?297, DOI DOI 10.1007/978-3-642-75988-8_28; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hu YT, 2018, LECT NOTES COMPUT SC, V11212, P56, DOI 10.1007/978-3-030-01237-3_4; Johnander J, 2019, PROC CVPR IEEE, P8945, DOI 10.1109/CVPR.2019.00916; Kim Z, 2008, PROC CVPR IEEE, P1626; Liang C., 2020, C COMPUT VIS PATTERN; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Lu X., 2020, ECCV; Luiten J, 2019, LECT NOTES COMPUT SC, V11364, P565, DOI 10.1007/978-3-030-20870-7_35; Maggio E, 2009, IEEE T IMAGE PROCESS, V18, P1873, DOI 10.1109/TIP.2009.2019934; Miao Jiaxu, 2020, P IEEE CVF C COMP VI, P10366; Ngan KN, 2011, VIDEO SEGMENTATION AND ITS APPLICATIONS, P1, DOI 10.1007/978-1-4419-9482-0; Oh SW, 2019, IEEE I CONF COMP VIS, P9225, DOI 10.1109/ICCV.2019.00932; Oh SW, 2019, PROC CVPR IEEE, P5242, DOI 10.1109/CVPR.2019.00539; Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770; Paszke A., 2017, PROC NIPS AUTODIFF W; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372; Pont-Tuset J., 2017, ARXIV; Ramakanth SA, 2014, PROC CVPR IEEE, P376, DOI 10.1109/CVPR.2014.55; Seong Hongje, 2020, ECCV, P629, DOI DOI 10.1007/978-3-030-58542-6_38; Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Vijayanarasimhan S, 2012, LECT NOTES COMPUT SC, V7576, P496, DOI 10.1007/978-3-642-33715-4_36; Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971; Voigtlaender Paul, 2017, ARXIV170609364; Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w; Xiao HX, 2018, PROC CVPR IEEE, P1140, DOI 10.1109/CVPR.2018.00125; Yang LJ, 2019, IEEE I CONF COMP VIS, P5187, DOI 10.1109/ICCV.2019.00529; Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680; Zhang ZY, 2016, PROC CVPR IEEE, P669, DOI 10.1109/CVPR.2016.79; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhou Q, 2019, IEEE INT CONF COMP V, P693, DOI 10.1109/ICCVW.2019.00084; Zhou ZS, 2019, IEEE INT CONF COMP V, P689, DOI 10.1109/ICCVW.2019.00083; Zongxin Yang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P332, DOI 10.1007/978-3-030-58558-7_20; Zongxin Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11791, DOI 10.1109/CVPR42600.2020.01181	60	6	6	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4701	4712		10.1109/TPAMI.2021.3081597	http://dx.doi.org/10.1109/TPAMI.2021.3081597			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	34003746	Green Submitted			2022-12-18	WOS:000836666600019
J	Young, SI; Zhe, W; Taubman, D; Girod, B				Young, Sean, I; Zhe, Wang; Taubman, David; Girod, Bernd			Transform Quantization for CNN Compression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Quantization (signal); Transforms; Kernel; Decorrelation; Convolution; Training; Image coding; Convolutional neural networks; transform coding; compression; quantization; learned transforms	NEURAL-NETWORKS	In this paper, we compress convolutional neural network (CNN) weights post-training via transform quantization. Previous CNN quantization techniques tend to ignore the joint statistics of weights and activations, producing sub-optimal CNN performance at a given quantization bit-rate, or consider their joint statistics during training only and do not facilitate efficient compression of already trained CNN models. We optimally transform (decorrelate) and quantize the weights post-training using a rate-distortion framework to improve compression at any given quantization bit-rate. Transform quantization unifies quantization and dimensionality reduction (decorrelation) techniques in a single framework to facilitate low bit-rate compression of CNNs and efficient inference in the transform domain. We first introduce a theory of rate and distortion for CNN quantization and pose optimum quantization as a rate-distortion optimization problem. We then show that this problem can be solved using optimal bit-depth allocation following decorrelation by the optimal End-to-end Learned Transform (ELT) we derive in this paper. Experiments demonstrate that transform quantization advances the state of the art in CNN compression in both retrained and non-retrained quantization scenarios. In particular, we find that transform quantization with retraining is able to compress CNN models such as AlexNet, ResNet and DenseNet to very low bit-rates (1-2 bits).	[Young, Sean, I; Girod, Bernd] Stanford Univ, Dept Elect Engn, Informat Syst Lab ISL, Stanford, CA 94305 USA; [Zhe, Wang] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore; [Taubman, David] Univ New South Wales, Sch Elect Engn & Telecommun, Sydney, NSW 2052, Australia	Stanford University; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); University of New South Wales Sydney	Young, SI (corresponding author), Stanford Univ, Dept Elect Engn, Informat Syst Lab ISL, Stanford, CA 94305 USA.	sean0@stanford.edu; wang_zhe@i2r.a-star.edu.sg; d.taubman@unsw.edu.au; bgirod@stanford.edu						Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Banner R., 2019, PROC 33 C NEURAL INF; Bernacchia A., 2018, ADV NEURAL INFORM PR, P5941; Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135; Chen SY, 2019, AAAI CONF ARTIF INTE, P3329; Chen WL, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1475, DOI 10.1145/2939672.2939839; Chen WL, 2015, PR MACH LEARN RES, V37, P2285; Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357; Cheng Y, 2015, IEEE I CONF COMP VIS, P2857, DOI 10.1109/ICCV.2015.327; Denton E, 2014, ADV NEUR IN, V27; Desjardins G., 2015, ADV NEURAL INFORM PR, P2071; Dong Z, 2019, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2019.00038; Faraone J, 2018, PROC CVPR IEEE, P4300, DOI 10.1109/CVPR.2018.00452; Flierl M., 2011, VIDEO CODING SUPERIM; Forrest N. Iandola, 2016, Arxiv, DOI arXiv:1602.07360; Gao WH, 2019, PR MACH LEARN RES, V97; George T, 2018, ADV NEUR IN, V31; Gersho A., 1992, VECTOR QUANTIZATION; Gong RH, 2019, IEEE I CONF COMP VIS, P4851, DOI 10.1109/ICCV.2019.00495; Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P9, DOI 10.1109/79.952802; Grosse R, 2016, PR MACH LEARN RES, V48; Han S., 2016, PROC INT C LEARN REP; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234; He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447; He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156; Huang L, 2020, PROC CVPR IEEE, P6428, DOI 10.1109/CVPR42600.2020.00646; Huang L, 2018, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2018.00089; Hubara I, 2018, J MACH LEARN RES, V18; Hubara I, 2016, ADV NEUR IN, V29; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246; Zhang K, 2020, Arxiv, DOI arXiv:2008.13751; Kim Y.-D., 2016, PROC INT C LEARN REP; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lebedev V., 2015, 3 INT C LEARNING REP; Li F., 2016, PROC 30 C NEURAL INF; Li H., 2016, ARXIV160808710, Vabs/1608.08710; Li YW, 2019, IEEE I CONF COMP VIS, P5622, DOI 10.1109/ICCV.2019.00572; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Lin SH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2425; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681; Martens J, 2015, PR MACH LEARN RES, V37, P2408; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; MAX J, 1960, IRE T INFORM THEOR, V6, P7, DOI 10.1109/TIT.1960.1057548; Nagel M, 2019, IEEE I CONF COMP VIS, P1325, DOI 10.1109/ICCV.2019.00141; Novikov A., 2015, ADV NEURAL INFORM PR, V28, P442, DOI DOI 10.5555/2969239.2969289; Oktay D., 2020, PROC INT C LEARN REP; Peng B, 2018, LECT NOTES COMPUT SC, V11212, P307, DOI 10.1007/978-3-030-01237-3_19; Peng HY, 2019, PR MACH LEARN RES, V97; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Samajdar A, 2020, INT SYM PERFORM ANAL, P58, DOI 10.1109/ISPASS48437.2020.00016; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Son S, 2018, LECT NOTES COMPUT SC, V11212, P225, DOI 10.1007/978-3-030-01237-3_14; Stock P., 2020, INT C LEARN REPR; Sullivan Gary, 2020, 2020 IEEE International Conference on Visual Communications and Image Processing (VCIP), DOI 10.1109/VCIP49819.2020.9301847; Sullivan GJ, 1996, IEEE T INFORM THEORY, V42, P1365, DOI 10.1109/18.532878; Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740; Taubman David, 2012, JPEG2000 IMAGE COMPR, V642; Tung F, 2018, PROC CVPR IEEE, P7873, DOI 10.1109/CVPR.2018.00821; Wang K, 2019, PROC CVPR IEEE, P8604, DOI 10.1109/CVPR.2019.00881; Wang M, 2017, IEEE INT CONF COMP V, P545, DOI 10.1109/ICCVW.2017.71; Wang TZ, 2020, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR42600.2020.00215; Wang YH, 2016, ADV NEUR IN, V29, P253; Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521; Ye JC, 2018, SIAM J IMAGING SCI, V11, P991, DOI 10.1137/17M1141771; You ZH, 2019, ADV NEUR IN, V32; Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958; Zeyde Roman, 2010, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47; Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23; Zhang TY, 2018, LECT NOTES COMPUT SC, V11212, P191, DOI 10.1007/978-3-030-01237-3_12; Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809; Zhe W, 2019, IEEE IMAGE PROC, P3826, DOI 10.1109/ICIP.2019.8803498; Zhou A, 2017, INCREMENTAL NETWORK; Zhou S., 2016, ARXIV; Zhu Chenzhuo, 2016, ARXIV161201064; Zhuang ZW, 2018, ADV NEUR IN, V31	90	6	6	8	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5700	5714		10.1109/TPAMI.2021.3084839	http://dx.doi.org/10.1109/TPAMI.2021.3084839			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	34048338	Green Submitted			2022-12-18	WOS:000836666600084
J	Yang, Q; Ma, Z; Xu, YL; Li, Z; Sun, J				Yang, Qi; Ma, Zhan; Xu, Yiling; Li, Zhu; Sun, Jun			Inferring Point Cloud Quality via Graph Similarity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Objective quality assessment; human perception; graph signal processing; point cloud	IMAGE; PERCEPTION; TEXTURE; COLOR; ERROR	Objective quality estimation of media content plays a vital role in a wide range of applications. Though numerous metrics exist for 2D images and videos, similar metrics are missing for 3D point clouds with unstructured and non-uniformly distributed points. In this paper, we propose GraphSIM-a metric to accurately and quantitatively predict the human perception of point cloud with superimposed geometry and color impairments. Human vision system is more sensitive to the high spatial-frequency components (e.g., contours and edges), and weighs local structural variations more than individual point intensities. Motivated by this fact, we use graph signal gradient as a quality index to evaluate point cloud distortions. Specifically, we first extract geometric keypoints by resampling the reference point cloud geometry information to form an object skeleton. Then, we construct local graphs centered at these keypoints for both reference and distorted point clouds. Next, we compute three moments of color gradients between centered keypoint and all other points in the same local graph for local significance similarity feature. Finally, we obtain similarity index by pooling the local graph significance across all color channels and averaging across all graphs. We evaluate GraphSIM on two large and independent point cloud assessment datasets that involve a wide range of impairments (e.g., re-sampling, compression, and additive noise). GraphSIM provides state-of-the-art performance for all distortions with noticeable gains in predicting the subjective mean opinion score (MOS) in comparison with point-wise distance-based metrics adopted in standardized reference software. Ablation studies further show that GraphSIM can be generalized to various scenarios with consistent performance by adjusting its key modules and parameters. Models and associated materials will be made available at https://njuvision.github.io/GraphSIM or http://smt.sjtu.edu.cn/papers/GraphSIM	[Yang, Qi; Xu, Yiling; Sun, Jun] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China; [Ma, Zhan] Nanjing Univ, Nanjing 210093, Jiangsu, Peoples R China; [Li, Zhu] Univ Missouri Kansas City, Kansas City, KS 64110 USA	Shanghai Jiao Tong University; Nanjing University; University of Missouri System; University of Missouri Kansas City	Xu, YL (corresponding author), Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China.; Ma, Z (corresponding author), Nanjing Univ, Nanjing 210093, Jiangsu, Peoples R China.	yang_littleqi@sjtu.edu.cn; mazhan@nju.edu.cn; yl.xu@sjtu.edu.cn; Zhu.li@ieee.org; junsun@sjtu.edu.cn			National Key Research and Development Project of China Science and Technology Exchange Center [2018YFE0206700, 2018YFB1802201]; National Natural Science Foundation of China [61971282, 62022038 U20A20185, U20A20184]; Scientific Research Plan of the Science and Technology Commission of ShanghaiMunicipality [18511105402]	National Key Research and Development Project of China Science and Technology Exchange Center; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Scientific Research Plan of the Science and Technology Commission of ShanghaiMunicipality	The authors would like to thank anonymous reviewers for their constructive comments to improve this manuscript. In the meantime, we really appreciate the efforts devoted in [29] for developing the IPRC point cloud assessment database. This work was supported in part by the National Key Research and Development Project of China Science and Technology Exchange Center (2018YFE0206700 and 2018YFB1802201), National Natural Science Foundation of China (61971282, 62022038 U20A20185, and U20A20184), and Scientific Research Plan of the Science and Technology Commission of ShanghaiMunicipality (18511105402).	Achlioptas P, 2018, PR MACH LEARN RES, V80; Alexiou E, 2017, PROC 9 INT C QUAL MU, P13; Alexiou E, 2018, IEEE INT CON MULTI; Alexiou E, 2019, APSIPA TRANS SIGNAL, V8, DOI 10.1017/ATSIP.2019.20; Alexiou E, 2019, IEEE IMAGE PROC, P4325, DOI 10.1109/ICIP.2019.8803479; Alexiou E, 2019, INT WORK QUAL MULTIM; Alexiou E, 2018, INT WORK QUAL MULTIM, P132; Alexiou E, 2018, PROC SPIE, V10752, DOI 10.1117/12.2321518; Alexiou E, 2017, PROC SPIE, V10396, DOI 10.1117/12.2275142; Alexious E., 2018, APPL DIGITAL IMAGE P, V10752; [Anonymous], 2015, FINAL REPORT VIDEO Q; [Anonymous], 2020, POINT CLOUD SUBJECTI; [Anonymous], MPEG REFERENCE SOFTW; Bai YC, 2019, IEEE T IMAGE PROCESS, V28, P1404, DOI 10.1109/TIP.2018.2874290; Brady DJ, 2018, OPTICA, V5, P127, DOI 10.1364/OPTICA.5.000127; Chen SH, 2018, IEEE T SIGNAL PROCES, V66, P666, DOI 10.1109/TSP.2017.2771730; Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236; CURCIO CA, 1990, J COMP NEUROL, V292, P497, DOI 10.1002/cne.902920402; Fu Y, 2018, IEEE T CIRC SYST VID, V28, P2428, DOI 10.1109/TCSVT.2018.2854176; Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559; Geusebroek JM, 2000, LECT NOTES COMPUT SC, V1842, P331; Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030; Gumhold S., 2005, P ACM SIGGRAPH SKETC, P137; Guo PY, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP); Hackel T., 2017, ARXIV 170403847; Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Javaheri A, 2021, IEEE T MULTIMEDIA, V23, P4049, DOI 10.1109/TMM.2020.3037481; Khaled M., 2017, MPEG2018N17248 ISOIE; Li A, 2000, VISION RES, V40, P217, DOI 10.1016/S0042-6989(99)00169-8; Li L, 2021, IEEE T CIRC SYST VID, V31, P326, DOI 10.1109/TCSVT.2020.2966118; Li L, 2020, IEEE T IMAGE PROCESS, V29, P289, DOI 10.1109/TIP.2019.2931621; Meinhardt E, 2009, J MATH IMAGING VIS, V34, P1, DOI 10.1007/s10851-008-0118-x; Mekuria R., 2016, ISOIECJTC1SC29WG11; MPEG-Systems, 2018, JTC1SC29WG11MPEG2018; Ni ZK, 2018, IEEE T IMAGE PROCESS, V27, P4516, DOI 10.1109/TIP.2018.2839890; Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185; Regaya Y, 2019, 2019 5TH IEEE INTERNATIONAL SYMPOSIUM ON SYSTEMS ENGINEERING (IEEE ISSE 2019); Rusu RB, 2010, KUNSTL INTELL, V24, P345, DOI 10.1007/s13218-010-0059-6; Sakiyama A, 2019, IEEE T SIGNAL PROCES, V67, P2679, DOI 10.1109/TSP.2019.2908129; Schnabel R., 2006, PROC EUROGRAPHICS S, P111; Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981; Shao YT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1199, DOI 10.1145/3240508.3240696; Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959; Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; Su HL, 2019, IEEE IMAGE PROC, P3182, DOI 10.1109/ICIP.2019.8803298; Tahir R., 2006, INT ARCH PHOTOGRAMM, V36, P248, DOI DOI 10.1111/1750-3841.12802; Tchapmi LP, 2017, INT CONF 3D VISION, P537, DOI 10.1109/3DV.2017.00067; THIBOS LN, 1989, P SOC PHOTO-OPT INS, V1199, P1148; Tian D, 2017, IEEE IMAGE PROC, P3460; Torlig EM, 2018, PROC SPIE, V10752, DOI 10.1117/12.2322741; Tsutsui KI, 2002, SCIENCE, V298, P409, DOI 10.1126/science.1074128; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423; Yamins DLK, 2016, NAT NEUROSCI, V19, P356, DOI 10.1038/nn.4244; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yang Q, 2021, IEEE T MULTIMEDIA, V23, P3877, DOI 10.1109/TMM.2020.3033117; Yang Q, 2020, IEEE T BROADCAST, V66, P310, DOI 10.1109/TBC.2019.2954063; Yao W, 2010, IEEE T GEOSCI REMOTE, V48, P3571, DOI 10.1109/TGRS.2010.2047109; Zeng J, 2020, IEEE T IMAGE PROCESS, V29, P3474, DOI 10.1109/TIP.2019.2961429; Zerman E., 2019, ELECT IMAGING, DOI DOI 10.2352/ISSN.2470-1173.2019.10.IQSP-323; Zhang J, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P827, DOI 10.1109/ICALIP.2014.7009910; Zhang ZX, 2016, IEEE T GEOSCI REMOTE, V54, P3309, DOI 10.1109/TGRS.2016.2514508; Zheng TH, 2019, IEEE I CONF COMP VIS, P1598, DOI 10.1109/ICCV.2019.00168	66	6	6	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3015	3029		10.1109/TPAMI.2020.3047083	http://dx.doi.org/10.1109/TPAMI.2020.3047083			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD		Green Submitted			2022-12-18	WOS:000803117500018
J	Yang, X; Zhang, HW; Cai, JF				Yang, Xu; Zhang, Hanwang; Cai, Jianfei			Auto-Encoding and Distilling Scene Graphs for Image Captioning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image captioning; scene graph; transfer learning; memory network; knowledge distillation	DYNAMIC MEMORY NETWORKS; LANGUAGE	We propose scene graph auto-encoder (SGAE) that incorporates the language inductive bias into the encoder-decoder image captioning framework for more human-like captions. Intuitively, we humans use the inductive bias to compose collocations and contextual inferences in discourse. For example, when we see the relation "a person on a bike", it is natural to replace "on" with "ride" and infer "a person riding a bike on a road' even when the 'road" is not evident. Therefore, exploiting such bias as a language prior is expected to help the conventional encoder-decoder models reason as we humans and generate more descriptive captions. Specifically, we use the scene graph-a directed graph (G) where an object node is connected by adjective nodes and relationship nodes-to represent the complex structural layout of both image (I) and sentence (S). In the language domain, we use SGAE to learn a dictionary set (D) that helps reconstruct sentences in the S -> G(S) -> D -> S auto-encoding pipeline, where D encodes the desired language prior and the decoder learns to caption from such a prior; in the vision-language domain, we share D in the I -> G(I) -> D -> S pipeline and distill the knowledge of the language decoder of the auto-encoder to that of the encoder-decoder based image captioner to transfer the language inductive bias. In this way, the shared D provides hidden embeddings about descriptive collocations to the encoder-decoder and the distillation strategy teaches the encoder-decoder to transform these embeddings to human-like captions as the auto-encoder. Thanks to the scene graph representation, the shared dictionary set, and the Knowledge Distillation strategy, the inductive bias is transferred across domains in principle. We validate the effectiveness of SGAE on the challenging MS-COCO image captioning benchmark, where our SGAE-based single-model achieves a new state-of-the-art 129.6 CIDEr-D on the Karpathy split, and a competitive 126.6 CIDEr-D (c40) on the official server, which is even comparable to other ensemble models. Furthermore, we validate the transferability of SGAE on two more challenging settings: transferring inductive bias from other language corpora and unpaired image captioning. Once again, the results of both settings confirm the superiority of SGAE. The code is released in https://github.com/yangxuntu/SGAE.	[Yang, Xu] Nanyang Technol Univ, Sch Comp Sci & Engn, Multimedia & Interact Comp Lab, Singapore 639798, Singapore; [Zhang, Hanwang] Nanyang Technol Univ, Singapore 639798, Singapore; [Cai, Jianfei] Monash Univ, Fac IT, Data Sci & AI Dept, Clayton, Vic 3800, Australia	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Monash University	Zhang, HW (corresponding author), Nanyang Technol Univ, Singapore 639798, Singapore.	s170018@e.ntu.edu.sg; hanwangzhang@ntu.edu.sg; Jianfei.Cai@monash.edu			Singapore MOE AcRF Tier 2, NTU Data Science and Artificial Intelligence Research Center (DSAIR); NTU-Alibaba Lab	Singapore MOE AcRF Tier 2, NTU Data Science and Artificial Intelligence Research Center (DSAIR); NTU-Alibaba Lab	This work was partially supported by Singapore MOE AcRF Tier 2, NTU Data Science and Artificial Intelligence Research Center (DSAIR), and NTU-Alibaba Lab.	Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24; Atwood J., 2016, ADV NEURAL INFORM PR, P1993, DOI DOI 10.5555/3157096.3157320; Banerjee Satanjeev, 2005, P ACL WORKSH INTR EX, P65; Battaglia P. W., 2018, ARXIV 180601261; Bengio S, 2015, ADV NEURAL INFORM PR, V1, P1171; Bruna J., 2014, C TRACK P; Chen L, 2019, IEEE I CONF COMP VIS, P4612, DOI 10.1109/ICCV.2019.00471; Devlin J., 2018, P 2019 C N AM CHAPTE, P4171, DOI DOI 10.18653/V1/N19-1423DIEZPF; diaeresis>el Defferrard Micha<spacing, 2016, NEURIPS, DOI DOI 10.5555/3157382.3157527; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Feng Y, 2019, PROC CVPR IEEE, P4120, DOI 10.1109/CVPR.2019.00425; Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127; Gu J., 2017, PROC AAAI C ARTIF IN; Gu JX, 2018, LECT NOTES COMPUT SC, V11205, P519, DOI 10.1007/978-3-030-01246-5_31; Gu JX, 2019, IEEE I CONF COMP VIS, P10322, DOI 10.1109/ICCV.2019.01042; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Henaff M, 2015, ARXIV150605163; Hinton G., 2015, ARXIV150302531; Hu R, 2018, PROC CVPR IEEE, P4233, DOI 10.1109/CVPR.2018.00445; Hudson D. A., 2018, ARXIV 180303067; Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31; Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133; Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215; Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kingma D.P, P 3 INT C LEARNING R; Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656; Klein D, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P423, DOI 10.3115/1075096.1075150; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Kumar A, 2016, PR MACH LEARN RES, V48; Laina I, 2019, IEEE I CONF COMP VIS, P7413, DOI 10.1109/ICCV.2019.00751; Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837; Li S., 2011, P 15 C COMPUTATIONAL, P220; Li Yujia, 2016, P INT C LEARN REPR I, P2; Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081; Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu DQ, 2019, IEEE I CONF COMP VIS, P4672, DOI 10.1109/ICCV.2019.00477; Liu DQ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1416, DOI 10.1145/3240508.3240632; Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754; Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345; Luo RT, 2018, PROC CVPR IEEE, P6964, DOI 10.1109/CVPR.2018.00728; Marcheggiani D., 2017, P 2017 C EMP METH NA, P1506, DOI [10.18653/v1/D17-1159, DOI 10.18653/V1/D17-1159]; Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information; Mathews A, 2016, AAAI CONF ARTIF INTE, P3574; Micheli A, 2009, IEEE T NEURAL NETWOR, V20, P498, DOI 10.1109/TNN.2008.2010350; Miller A., 2016, ARXIV160603126, P1400; Mitchell Margaret, 2012, EACL; Niepert M, 2016, PR MACH LEARN RES, V48; Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Polino A., 2018, P 6 INT C LEARN REPR; Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856; Ranzato M, 2016, ICLR; Rebuffi Sylvestre-Alvise, 2017, PROC CVPR IEEE, P8, DOI DOI 10.1109/CVPR.2017.587; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131; Schuster Sebastian, 2015, P 4 WORKSH VIS LANG, P70, DOI DOI 10.18653/V1/W15-2812; Shi JX, 2019, PROC CVPR IEEE, P8368, DOI 10.1109/CVPR.2019.00857; Sukhbaatar S, 2015, ADV NEUR IN, V28; Sutskever I., 2014, P ADV INT C NEUR INF, P3104; Tang KH, 2019, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2019.00678; Teney D, 2017, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2017.344; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Vinyals Oriol, 2016, ARXIV160604080, P3630; Xiong CM, 2016, PR MACH LEARN RES, V48; Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077; Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330; Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28; Xu K., 2019, ICLR, P1, DOI DOI 10.1109/VTCFALL.2019.8891597; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41; Yang X, 2018, LECT NOTES COMPUT SC, V11216, P38, DOI 10.1007/978-3-030-01258-8_3; Yang X, 2019, IEEE I CONF COMP VIS, P4249, DOI 10.1109/ICCV.2019.00435; Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094; Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42; Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524; YOSINSKI J, 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.1109/IJCNN.2016.7727519; You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503; Zagoruyko S., 2017, P INT C LEARN REPR, DOI DOI 10.1109/CVPR.2019.00271; Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611; Zha ZJ, 2022, IEEE T PATTERN ANAL, V44, P710, DOI 10.1109/TPAMI.2019.2909864; Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331; Zhang Y., 2018, ICLR; Zhao B, 2019, IEEE COMPUT SOC CONF, P398, DOI [10.1109/CVPRW.2019.00053, 10.1109/CVPR.2019.00878]	94	6	6	9	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2313	2327		10.1109/TPAMI.2020.3042192	http://dx.doi.org/10.1109/TPAMI.2020.3042192			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33270557				2022-12-18	WOS:000792921400009
J	Zhang, HW; Cao, J; Lu, G; Ouyang, WL; Sun, ZN				Zhang, Hongwen; Cao, Jie; Lu, Guo; Ouyang, Wanli; Sun, Zhenan			Learning 3D Human Shape and Pose From Dense Body Parts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Shape; Task analysis; Solid modeling; Two dimensional displays; Predictive models; Pose estimation; 3D human shape and pose estimation; decompose-and-aggregate network; position-aided rotation feature refinement; part-based dropout		Reconstructing 3D human shape and pose from monocular images is challenging despite the promising results achieved by the most recent learning-based methods. The commonly occurred misalignment comes from the facts that the mapping from images to the model space is highly non-linear and the rotation-based pose representation of the body model is prone to result in the drift of joint positions. In this work, we investigate learning 3D human shape and pose from dense correspondences of body parts and propose a Decompose-and-aggregate Network (DaNet) to address these issues. DaNet adopts the dense correspondence maps, which densely build a bridge between 2D pixels and 3D vertexes, as intermediate representations to facilitate the learning of 2D-to-3D mapping. The prediction modules of DaNet are decomposed into one global stream and multiple local streams to enable global and fine-grained perceptions for the shape and pose predictions, respectively. Messages from local streams are further aggregated to enhance the robust prediction of the rotation-based poses, where a position-aided rotation feature refinement strategy is proposed to exploit spatial relationships between body joints. Moreover, a Part-based Dropout (PartDrop) strategy is introduced to drop out dense information from intermediate representations during training, encouraging the network to focus on more complementary body parts as well as neighboring position features. The efficacy of the proposed method is validated on both indoor and real-world datasets including Human3.6M, UP3D, COCO, and 3DPW, showing that our method could significantly improve the reconstruction performance in comparison with previous state-of-the-art methods. Our code is publicly available at https://hongwenzhang.github.io/dense2mesh.	[Zhang, Hongwen; Cao, Jie; Sun, Zhenan] Chinese Acad Sci, Inst Automat, NLPR, CRIPAC, Beijing 100190, Peoples R China; [Zhang, Hongwen; Cao, Jie; Sun, Zhenan] Univ Chinese Acad Sci, Beijing 101408, Peoples R China; [Lu, Guo] Beijing Inst Technol, Beijing 100081, Peoples R China; [Ouyang, Wanli] Univ Sydney, Camperdown, NSW 2006, Australia	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Beijing Institute of Technology; University of Sydney	Sun, ZN (corresponding author), Chinese Acad Sci, Inst Automat, NLPR, CRIPAC, Beijing 100190, Peoples R China.; Sun, ZN (corresponding author), Univ Chinese Acad Sci, Beijing 101408, Peoples R China.	hongwen.zhang@cripac.ia.ac.cn; jie.cao@cripac.ia.ac.cn; guo.lu@bit.edu.cn; wanli.ouyang@sydney.edu.au; znsun@nlpr.ia.ac.cn	Zhang, Hongwen/ABI-2791-2020; cao, xiaoxiang/AAR-9291-2021; cai, jie/HHS-0606-2022	Zhang, Hongwen/0000-0001-8633-4551; 	National Natural Science Foundation of China [U1836217, 61806197]; National Key Research and Development Program of China [2017YFC0821602]; University of Chinese Academy of Sciences	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China; University of Chinese Academy of Sciences(Chinese Academy of Sciences)	The authors would like to thank the associate editor and reviewers for their helpful comments to improve this manuscript. This work was supported in part by the National Natural Science Foundation of China (Grant No. U1836217, 61806197) and the National Key Research and Development Program of China (Grant No. 2017YFC0821602). This work was done when H. Zhang visited the University of Sydney with the support of the Joint Ph.D. Training Program of the University of Chinese Academy of Sciences.	Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Arnab A, 2019, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2019.00351; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257; Chen X., 2014, P 27 ANN C NEURAL IN, P1736, DOI DOI 10.1109/CVPR.2018.00742; Chu X, 2016, PROC CVPR IEEE, P4715, DOI 10.1109/CVPR.2016.510; Dantone M, 2014, IEEE T PATTERN ANAL, V36, P2131, DOI 10.1109/TPAMI.2014.2318702; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dibra E, 2016, INT CONF 3D VISION, P108, DOI 10.1109/3DV.2016.19; Doersch Carl, 2019, ADV NEURAL INFORM PR, P2; Fang HS, 2018, AAAI CONF ARTIF INTE, P6821; Gabeur V, 2019, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2019.00232; Ghiasi G., 2018, PROC INT C NEURAL IN, p10 727; Guler RA, 2019, PROC CVPR IEEE, P10876, DOI 10.1109/CVPR.2019.01114; Guler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762; Guler RA, 2017, PROC CVPR IEEE, P2614, DOI 10.1109/CVPR.2017.280; He K., 2016, PROC IEEE C COMPUTER, P770, DOI DOI 10.1109/CVPR.2016.90; Hinton G., J MACH LEARN RES, V15, P1929; IONESCU C, 2014, IEEE T PATTERN ANAL; Jackson AS, 2019, LECT NOTES COMPUT SC, V11132, P64, DOI 10.1007/978-3-030-11018-5_6; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Johnson S., 2010, P BRIT MACH VIS C; Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318; Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868; Kanazawa A, 2019, PROC CVPR IEEE, P5597, DOI 10.1109/CVPR.2019.00576; Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411; Kipf T.N., 2017, 5 INT C LEARN REPRES, P1; Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530; Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234; Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463; Lassner Christoph, 2017, CVPR; Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8; Liang JB, 2019, IEEE I CONF COMP VIS, P4351, DOI 10.1109/ICCV.2019.00445; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Loper M., 2015, ACM T GRAPHIC, V34; Loper M., 2014, ACM T GRAPHIC, V33; Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11; Luo C., 2018, P BRIT MACH VIS C; Martinez Julieta, 2017, ICCV; Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064; Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170; Nie BX, 2017, IEEE I CONF COMP VIS, P3467, DOI 10.1109/ICCV.2017.373; Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062; Paszke A, 2019, ADV NEURAL INF PROCE, DOI DOI 10.48550/ARXIV.1912.01703; Pavlakos G, 2019, IEEE I CONF COMP VIS, P803, DOI 10.1109/ICCV.2019.00089; Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123; Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055; Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138; PENG G, 2009, 2009 IEEE 12 INT C C, P1381; Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82; Rong Y, 2019, IEEE I CONF COMP VIS, P5339, DOI 10.1109/ICCV.2019.00544; Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241; Sigal Leonid, 2008, NEURIPS; Smith BM, 2019, INT CONF 3D VISION, P279, DOI 10.1109/3DV.2019.00039; Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072; Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33; Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284; Sun Y, 2019, IEEE I CONF COMP VIS, P5348, DOI 10.1109/ICCV.2019.00545; Tan Jun Kai Vince, 2017, BRIT MACH VIS C; Tekin B, 2017, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2017.425; Tompson J.J., 2014, ADV NEURAL INFORM PR, V27, P1799; Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664; Tung HYF, 2017, ADV NEUR IN, V30; Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2; von Marcard T, 2018, LECT NOTES COMPUT SC, V11214, P614, DOI 10.1007/978-3-030-01249-6_37; Wang Jingdong, 2020, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2020.2983686, 10.1109/tpami.2020.2983686]; Xiang DL, 2019, PROC CVPR IEEE, P10957, DOI 10.1109/CVPR.2019.01122; Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29; Xu YL, 2019, IEEE I CONF COMP VIS, P7759, DOI 10.1109/ICCV.2019.00785; Yan Sijie, 2018, AAAI; Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yao P., 2019, DENSEBODY DIRECTLY R; Zhang HW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P935, DOI 10.1145/3343031.3351057; Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354; Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783; Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51; Zhou XY, 2016, LECT NOTES COMPUT SC, V9915, P186, DOI 10.1007/978-3-319-49409-8_17; Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589; Zhu H, 2019, PROC CVPR IEEE, P4486, DOI 10.1109/CVPR.2019.00462; Zuffi S, 2015, PROC CVPR IEEE, P3537, DOI 10.1109/CVPR.2015.7298976	85	6	6	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2610	2627		10.1109/TPAMI.2020.3042341	http://dx.doi.org/10.1109/TPAMI.2020.3042341			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33270560	Green Submitted			2022-12-18	WOS:000792921400029
J	Zhang, YB; Deng, B; Tang, H; Zhang, L; Jia, K				Zhang, Yabin; Deng, Bin; Tang, Hui; Zhang, Lei; Jia, Kui			Unsupervised Multi-Class Domain Adaptation: Theory, Algorithms, and Practice	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Training data; Task analysis; Testing; Machine learning; Adaptation models; Standards; Domain adaptation; multi-class classification; adversarial training; partial or open set domain adaptation		In this paper, we study the formalism of unsupervised multi-class domain adaptation (multi-class UDA), which underlies a few recent algorithms whose learning objectives are only motivated empirically. Multi-Class Scoring Disagreement (MCSD) divergence is presented by aggregating the absolute margin violations in multi-class classification, and this proposed MCSD is able to fully characterize the relations between any pair of multi-class scoring hypotheses. By using MCSD as a measure of domain distance, we develop a new domain adaptation bound for multi-class UDA; its data-dependent, probably approximately correct bound is also developed that naturally suggests adversarial learning objectives to align conditional feature distributions across source and target domains. Consequently, an algorithmic framework of Multi-class Domain-adversarial learning Networks (McDalNets) is developed, and its different instantiations via surrogate learning objectives either coincide with or resemble a few recently popular methods, thus (partially) underscoring their practical effectiveness. Based on our identical theory for multi-class UDA, we also introduce a new algorithm of Domain-Symmetric Networks (SymmNets), which is featured by a novel adversarial strategy of domain confusion and discrimination. SymmNets affords simple extensions that work equally well under the problem settings of either closed set, partial, or open set UDA. We conduct careful empirical studies to compare different algorithms of McDalNets and our newly introduced SymmNets. Experiments verify our theoretical analysis and show the efficacy of our proposed SymmNets. In addition, we have made our implementation code publicly available.	[Zhang, Yabin; Deng, Bin; Tang, Hui; Jia, Kui] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510641, Guangdong, Peoples R China; [Zhang, Yabin; Deng, Bin; Tang, Hui; Jia, Kui] Pazhou Lab, Guangzhou 510335, Peoples R China; [Zhang, Yabin; Zhang, Lei] Alibaba Grp, DAMO Acad, Hangzhou 311121, Peoples R China; [Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China	South China University of Technology; Pazhou Lab; Alibaba Group; Hong Kong Polytechnic University	Jia, K (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510641, Guangdong, Peoples R China.	zhang.yabin@mail.scut.edu.cn; bindeng.scut@gmail.com; eehuitang@mail.scut.edu.cn; cslzhang@comp.polyu.edu.hk; kuijia@scut.edu.cn	Zhang, Yabin/AAF-7624-2021	Deng, Bin/0000-0002-0211-5886	National Natural Science Foundation of China [61771201]; Program for Guangdong Introducing Innovative and Enterpreneurial Teams [2017ZT07X183]; Guangdong R&D key project of China [2019B010155001]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Program for Guangdong Introducing Innovative and Enterpreneurial Teams; Guangdong R&D key project of China	This work was supported in part by the National Natural Science Foundation of China (Grant No. 61771201), the Program for Guangdong Introducing Innovative and Enterpreneurial Teams (Grant No. 2017ZT07X183), and the Guangdong R&D key project of China (Grant No. 2019B010155001). Yabin Zhang and Bin Deng contributed equally to this work.	[Anonymous], 2014, IMAGECLEF DA DATASET; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Ben-David Shai, 2007, NEURIPS, P7; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Busto PP, 2020, IEEE T PATTERN ANAL, V42, P413, DOI 10.1109/TPAMI.2018.2880750; Cao ZJ, 2018, LECT NOTES COMPUT SC, V11212, P139, DOI 10.1007/978-3-030-01237-3_9; Cao ZJ, 2019, PROC CVPR IEEE, P2980, DOI 10.1109/CVPR.2019.00310; Cao ZJ, 2018, PROC CVPR IEEE, P2724, DOI 10.1109/CVPR.2018.00288; Cicek S, 2019, IEEE I CONF COMP VIS, P1416, DOI 10.1109/ICCV.2019.00150; Cortes C, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P169, DOI 10.1145/2783258.2783368; Cortes C, 2014, THEOR COMPUT SCI, V519, P103, DOI 10.1016/j.tcs.2013.09.027; Courty N, 2017, ADV NEUR IN, V30; Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921; Dogan U, 2016, J MACH LEARN RES, V17; Ganin Y., 2017, J MACH LEARN RES, V17, P2096; Ganin Yaroslav, 2015, ICML; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Isola P., 2017, IMAGE TO IMAGE TRANS, P1125; Jia K, 2019, IEEE T IMAGE PROCESS, V28, P5121, DOI 10.1109/TIP.2019.2912356; Kang GL, 2018, LECT NOTES COMPUT SC, V11215, P420, DOI 10.1007/978-3-030-01252-6_25; Kang GL, 2019, PROC CVPR IEEE, P4888, DOI 10.1109/CVPR.2019.00503; Koltchinskii V, 2002, ANN STAT, V30, P1; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kurmi VK, 2019, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2019.00058; Kuroki S, 2019, AAAI CONF ARTIF INTE, P4122; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee C.-Y., 2019, PROC IEEE C COMPUT V, p10 285; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; Li S, 2021, IEEE T PATTERN ANAL, V43, P1352, DOI 10.1109/TPAMI.2019.2948352; Liu H, 2019, PROC CVPR IEEE, P2922, DOI 10.1109/CVPR.2019.00304; Liu YF, 2011, J COMPUT GRAPH STAT, V20, P901, DOI 10.1198/jcgs.2010.09206; Long MS, 2018, ADV NEUR IN, V31; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2017, PR MACH LEARN RES, V70; Long MS, 2016, ADV NEUR IN, V29; Mansour Y., 2009, NEURIPS; Mohri Mehryar, 2012, Algorithmic Learning Theory. 23rd International Conference (ALT 2012). Proceedings, P124, DOI 10.1007/978-3-642-34106-9_13; Mohri M., 2018, FDN MACHINE LEARNING; Netzer Y, 2011, NIPS WORKSH DEEP LEA, P2011, DOI DOI 10.2118/18761-MS; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pan YW, 2019, PROC CVPR IEEE, P2234, DOI 10.1109/CVPR.2019.00234; Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934; Peng X., 2017, ARXIV 171006924; Peng X., 2018, SYN2REAL NEW BENCHMA; Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149; Pinheiro PO, 2018, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2018.00835; Roy S, 2019, PROC CVPR IEEE, P9463, DOI 10.1109/CVPR.2019.00970; Rozantsev A, 2019, IEEE T PATTERN ANAL, V41, P801, DOI 10.1109/TPAMI.2018.2814042; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K., 2018, ICLR; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Saito K, 2018, LECT NOTES COMPUT SC, V11209, P156, DOI 10.1007/978-3-030-01228-1_10; Shalev-Shwartz S., 2014, UNDERSTANDING MACHIN, DOI DOI 10.1017/CBO9781107298019; Szedmak S., 2005, P IEEE INT C DAT MIN, P542; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tang H, 2020, AAAI CONF ARTIF INTE, V34, P5940; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vapnik V.N, 1998, STAT LEARNING THEORY; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Villani C, 2009, GRUNDLEHR MATH WISS, V338, P5; Vinyals O., 2016, ADV NEURAL INFORM PR, P3637, DOI [10.48550/arXiv.1606.04080, DOI 10.5555/3157382.3157504]; Wang XM, 2019, AAAI CONF ARTIF INTE, P5345; Zhang Chao, 2012, Adv Neural Inf Process Syst, V4, P3320; Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851; Zhang YB, 2020, IEEE T MULTIMEDIA, V22, P1345, DOI 10.1109/TMM.2019.2939747; Zhang YB, 2019, PROC CVPR IEEE, P5026, DOI 10.1109/CVPR.2019.00517; Zhang YC, 2019, PR MACH LEARN RES, V97; Zhu Jun-Yan, 2017, ICCV	75	6	6	5	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2775	2792		10.1109/TPAMI.2020.3036956	http://dx.doi.org/10.1109/TPAMI.2020.3036956			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33170775	Green Submitted			2022-12-18	WOS:000792921400040
J	Han, Z; Yu, SQ; Lin, SB; Zhou, DX				Han, Zhi; Yu, Siquan; Lin, Shao-Bo; Zhou, Ding-Xuan			Depth Selection for Deep ReLU Nets in Feature Extraction and Generalization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Data mining; Deep learning; Task analysis; Optimization; Machine learning algorithms; Deep nets; feature extractions; generalization; learning theory	NEURAL-NETWORKS; OPTIMAL APPROXIMATION; SHALLOW; BOUNDS; SMOOTH	Deep learning is recognized to be capable of discovering deep features for representation learning and pattern recognition without requiring elegant feature engineering techniques by taking advantages of human ingenuity and prior knowledge. Thus it has triggered enormous research activities in machine learning and pattern recognition. One of the most important challenges of deep learning is to figure out relations between a feature and the depth of deep neural networks (deep nets for short) to reflect the necessity of depth. Our purpose is to quantify this feature-depth correspondence in feature extraction and generalization. We present the adaptivity of features to depths and vice-verse via showing a depth-parameter trade-off in extracting both single feature and composite features. Based on these results, we prove that implementing the classical empirical risk minimization on deep nets can achieve the optimal generalization performance for numerous learning tasks. Our theoretical results are verified by a series of numerical experiments including toy simulations and a real application of earthquake seismic intensity prediction.	[Han, Zhi; Yu, Siquan] Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang 110016, Peoples R China; [Han, Zhi; Yu, Siquan] Chinese Acad Sci, Inst Robot, Shenyang 110016, Peoples R China; [Han, Zhi; Yu, Siquan] Chinese Acad Sci, Inst Intelligent Mfg, Shenyang 110016, Peoples R China; [Yu, Siquan] Northeastern Univ, Sch Informat Sci & Engn, Shenyang 110819, Peoples R China; [Lin, Shao-Bo] Xi An Jiao Tong Univ, Ctr Intelligent Decis Making & Machine Learning, Sch Management, Xian 710049, Peoples R China; [Zhou, Ding-Xuan] City Univ Hong Kong, Liu Bie Ju Ctr Math Sci, Sch Data Sci, Hong Kong, Peoples R China; [Zhou, Ding-Xuan] City Univ Hong Kong, Dept Math, Hong Kong, Peoples R China	Chinese Academy of Sciences; Shenyang Institute of Automation, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences; Northeastern University - China; Xi'an Jiaotong University; City University of Hong Kong; City University of Hong Kong	Lin, SB (corresponding author), Xi An Jiao Tong Univ, Ctr Intelligent Decis Making & Machine Learning, Sch Management, Xian 710049, Peoples R China.	hanzhi@sia.cn; yusiquan@sia.cn; sblin1983@gmail.com; mazhou@cityu.edu.hk	Zhou, Ding-Xuan/B-3160-2013	Zhou, Ding-Xuan/0000-0003-0224-9216; Yu, Siquan/0000-0003-2513-9175; Lin, Shaobo/0000-0001-5122-9153; Han, Zhi/0000-0002-8039-6679	National Natural Science Foundation of China [61876133, 61977038, 61773367, 61821005]; Youth Innovation Promotion Association of the Chinese Academy of Sciences [2016183]; Research Grant Council of Hong Kong [CityU 11306617]; Hong Kong Institute for Data Science	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Youth Innovation Promotion Association of the Chinese Academy of Sciences; Research Grant Council of Hong Kong(Hong Kong Research Grants Council); Hong Kong Institute for Data Science	The work of Z. Han and S. Yu was supported in part by the National Natural Science Foundation of China [Grant Nos. 61773367, 61821005], the Youth Innovation Promotion Association of the Chinese Academy of Sciences [Grant 2016183]. The work of S.B. Lin was supported by the National Natural Science Foundation of China [Grant No. 61876133,61977038], and the work of D.X. Zhou was partially supported by the Research Grant Council of Hong Kong [Project No. CityU 11306617] and Hong Kong Institute for Data Science.	Allen-Zhu Z, 2019, PR MACH LEARN RES, V97; Bengio, 2011, ADV NEURAL INFORM PR, P666, DOI DOI 10.5555/2986459.2986534; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bianchini M, 2014, IEEE T NEUR NET LEAR, V25, P1553, DOI 10.1109/TNNLS.2013.2293637; Bishop C.M, 2006, PATTERN RECOGN; Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230; Chui C.K., 2018, FRONT APPL MATH STAT, V4, DOI 10.3389/fams.2018.00014; Chui CK, 2019, ANAL APPL, V17, P737, DOI 10.1142/S0219530519400074; CHUI CK, 1994, MATH COMPUT, V63, P607, DOI 10.1090/S0025-5718-1994-1240656-2; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274; Donoho D. L., 1993, Applied and Computational Harmonic Analysis, V1, P100, DOI 10.1006/acha.1993.1008; Eldan R., 2016, P 29 C LEARNING THEO, V49, P907; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Guo ZC, 2020, IEEE T NEUR NET LEAR, V31, P4036, DOI 10.1109/TNNLS.2019.2951788; Guo ZC, 2017, ANAL APPL, V15, P433, DOI 10.1142/S0219530517500026; Gyorfy L., 2002, DISTRIBUTION FREE TH; Hagan M, 1996, NEURAL NETWORK DESIG; Harvey N., 2017, C LEARN THEOR; Hastie T, 2009, ELEMENTS STAT LEARNI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Imaizumi M, 2019, PR MACH LEARN RES, V89, P869; Kohler M, 2017, IEEE T INFORM THEORY, V63, P1620, DOI 10.1109/TIT.2016.2634401; LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5; Lin HW, 2017, J STAT PHYS, V168, P1223, DOI 10.1007/s10955-017-1836-5; Lin SB, 2019, IEEE T NEUR NET LEAR, V30, P1392, DOI 10.1109/TNNLS.2018.2868980; Lin SB, 2018, CONSTR APPROX, V47, P249, DOI 10.1007/s00365-017-9379-1; Lin SB, 2017, NEURAL NETWORKS, V94, P96, DOI 10.1016/j.neunet.2017.06.016; Lin SB, 2019, IEEE T CYBERNETICS, V49, P221, DOI 10.1109/TCYB.2017.2771463; Lin SB, 2014, APPL MATH MODEL, V38, P6031, DOI 10.1016/j.apm.2014.05.018; Maiorov V, 1999, NEUROCOMPUTING, V25, P81, DOI 10.1016/S0925-2312(98)00111-8; Mhaskar HN, 1996, NEURAL COMPUT, V8, P164, DOI 10.1162/neco.1996.8.1.164; Montufar G.F., 2014, ADV NEURAL INF PROCE, V27, P2924, DOI DOI 10.5555/2969033.2969153; Petersen P, 2018, NEURAL NETWORKS, V108, P296, DOI 10.1016/j.neunet.2018.08.019; Pinkus A., 1985, N WIDTHS APPROXIMATI; Safran I, 2017, PR MACH LEARN RES, V70; Satriano C, 2011, SOIL DYN EARTHQ ENG, V31, P106, DOI 10.1016/j.soildyn.2010.07.007; Schwab C, 2019, ANAL APPL, V17, P19, DOI 10.1142/S0219530518500203; Shaham U, 2018, APPL COMPUT HARMON A, V44, P537, DOI 10.1016/j.acha.2016.04.003; Sokolov V.Y., 1998, EARTHQ SPECTRA, V14, P679, DOI [10.1193/1.1586022, DOI 10.1193/1.1586022]; Sokolov VY, 2002, EARTHQ SPECTRA, V18, P161, DOI 10.1193/1.1469037; Vikraman K., 2016, ARXIV161108655; Yarotsky D, 2017, NEURAL NETWORKS, V94, P103, DOI 10.1016/j.neunet.2017.07.002; Ying YM, 2017, APPL COMPUT HARMON A, V42, P224, DOI 10.1016/j.acha.2015.08.007; Zhou DX, 2020, NEURAL NETWORKS, V124, P319, DOI 10.1016/j.neunet.2020.01.018; Zhou DX, 2020, APPL COMPUT HARMON A, V48, P787, DOI 10.1016/j.acha.2019.06.004; Zhou DX, 2018, ANAL APPL, V16, P895, DOI 10.1142/S0219530518500124; Zhou DX, 2003, IEEE T INFORM THEORY, V49, P1743, DOI 10.1109/TIT.2003.813564	53	6	6	79	103	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1853	1868		10.1109/TPAMI.2020.3032422	http://dx.doi.org/10.1109/TPAMI.2020.3032422			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33079656	Green Submitted			2022-12-18	WOS:000764815300016
J	Kang, GL; Jiang, L; Wei, YC; Yang, Y; Hauptmann, A				Kang, Guoliang; Jiang, Lu; Wei, Yunchao; Yang, Yi; Hauptmann, Alexander			Contrastive Adaptation Network for Single- and Multi-Source Domain Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Neural networks; Adaptation models; Benchmark testing; Measurement; Manuals; Estimation; Contrastive; domain adaptation; unsupervised; multi-source		Unsupervised domain adaptation (UDA) makes predictions for the target domain data while manual annotations are only available in the source domain. Previous methods minimize the domain discrepancy neglecting the class information, which may lead to misalignment and poor generalization performance. To tackle this issue, this paper proposes contrastive adaptation network (CAN) that optimizes a new metric named Contrastive Domain Discrepancy explicitly modeling the intra-class domain discrepancy and the inter-class domain discrepancy. To optimize CAN, two technical issues need to be addressed: 1) the target labels are not available; and 2) the conventional mini-batch sampling is imbalanced. Thus we design an alternating update strategy to optimize both the target label estimations and the feature representations. Moreover, we develop class-aware sampling to enable more efficient and effective training. Our framework can be generally applied to the single-source and multi-source domain adaptation scenarios. In particular, to deal with multiple source domain data, we propose: 1) multi-source clustering ensemble which exploits the complementary knowledge of distinct source domains to make more accurate and robust target label estimations; and 2) boundary-sensitive alignment to make the decision boundary better fitted to the target. Experiments are conducted on three real-world benchmarks (i.e., Office-31 and VisDA-2017 for the single-source scenario, DomainNet for the multi-source scenario). All the results demonstrate that our CAN performs favorably against the state-of-the-art methods. Ablation studies also verify the effectiveness of each key component of our proposed system.	[Kang, Guoliang; Hauptmann, Alexander] Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA; [Wei, Yunchao; Yang, Yi] Univ Technol Sydney, AAII, Sydney, NSW 2007, Australia; [Jiang, Lu] Google Res, Mountain View, CA 94043 USA	Carnegie Mellon University; University of Technology Sydney; Google Incorporated	Kang, GL (corresponding author), Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.	gkang@andrew.cmu.edu; lujiang@google.com; yunchao.wei@uts.edu.au; yi.yang@uts.edu.au; alex@cs.cmu.edu	Yang, Yi/B-9273-2017; yang, yang/HGT-7999-2022	Yang, Yi/0000-0002-0512-880X; Jiang, Lu/0000-0003-0286-8439	ARC DECRA [DE190101315]; ARC [DP200100938]	ARC DECRA(Australian Research Council); ARC(Australian Research Council)	This work was supported in part by ARC DECRA DE190101315 and ARC DP200100938.	Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Ben-David Shai, 2007, NEURIPS, P7; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Bousmalis Konstantinos, 2016, ADV NEURAL INFORM PR, P343; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819; French Geoffrey, 2018, P INT C LEARN REPR, V6, P6; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Gong Boqing, 2013, P ADV NEUR INF PROC, P1286; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; Haeusser P, 2017, IEEE I CONF COMP VIS, P2784, DOI 10.1109/ICCV.2017.301; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hermans Alexander, 2017, ARXIV170307737; Hoffman J, 2018, PR MACH LEARN RES, V80; Hoffmann Johannes, 2016, 2016 Conference on Precision Electromagnetic Measurements (CPEM), P1, DOI 10.1109/CPEM.2016.7540615; Hu LQ, 2020, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR42600.2020.00410; Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918; Kang GL, 2018, LECT NOTES COMPUT SC, V11215, P420, DOI 10.1007/978-3-030-01252-6_25; Kang GL, 2019, PROC CVPR IEEE, P4888, DOI 10.1109/CVPR.2019.00503; Kang GL, 2018, IEEE T PATTERN ANAL, V40, P1245, DOI 10.1109/TPAMI.2017.2701831; Lee S, 2019, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2019.00018; Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136; Long MS, 2018, ADV NEUR IN, V31; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2017, PR MACH LEARN RES, V70; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Luo YW, 2019, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2019.00261; Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934; Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149; Peng Xingchao, 2017, VISDA VISUAL DOMAIN; Rostamizadeh A., 2009, ADV NEURAL INFORM PR, P1041; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K., 2018, ICLR; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sejdinovic D, 2013, ANN STAT, V41, P2263, DOI 10.1214/13-AOS1140; Sener Ozan, 2016, ADV NEURAL INFORM PR, P2; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; Tzeng E., 2014, ARXIV PREPRINT ARXIV; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang JD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P402, DOI 10.1145/3240508.3240512; Xu RJ, 2018, PROC CVPR IEEE, P3964, DOI 10.1109/CVPR.2018.00417; Zhao H, 2018, ADV NEUR IN, V31	48	6	6	15	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1793	1804		10.1109/TPAMI.2020.3029948	http://dx.doi.org/10.1109/TPAMI.2020.3029948			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33035160	hybrid			2022-12-18	WOS:000764815300012
J	Long, X; de Melo, G; He, DL; Li, F; Chi, ZZ; Wen, SL; Gan, C				Long, Xiang; de Melo, Gerard; He, Dongliang; Li, Fu; Chi, Zhizhen; Wen, Shilei; Gan, Chuang			Purely Attention Based Local Feature Integration for Video Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Convolution; Computational modeling; Plugs; Three-dimensional displays; Task analysis; Two dimensional displays; Video classification; action recognition; attention mechanism; computer vision		Recently, substantial research effort has focused on how to apply CNNs or RNNs to better capture temporal patterns in videos, so as to improve the accuracy of video classification. In this paper, we investigate the potential of a purely attention based local feature integration. Accounting for the characteristics of such features in video classification, we first propose Basic Attention Clusters (BAC), which concatenates the output of multiple attention units applied in parallel, and introduce a shifting operation to capture more diverse signals. Experiments show that BAC can achieve excellent results on multiple datasets. However, BAC treats all feature channels as an indivisible whole, which is suboptimal for achieving a finer-grained local feature integration over the channel dimension. Additionally, it treats the entire local feature sequence as an unordered set, thus ignoring the sequential relationships. To improve over BAC, we further propose the channel pyramid attention schema by splitting features into sub-features at multiple scales for coarse-to-fine sub-feature interaction modeling, and propose the temporal pyramid attention schema by dividing the feature sequences into ordered sub-sequences of multiple lengths to account for the sequential order. Our final model pyramidxpyramid attention clusters (PPAC) combines both channel pyramid attention and temporal pyramid attention to focus on the most important sub-features, while also preserving the temporal information of the video. We demonstrate the effectiveness of PPAC on seven real-world video classification datasets. Our model achieves competitive results across all of these, showing that our proposed framework can consistently outperform the existing local feature integration methods across a range of different scenarios.	[Long, Xiang; He, Dongliang; Li, Fu; Chi, Zhizhen; Wen, Shilei] Baidu VIS, Beijing 100085, Peoples R China; [de Melo, Gerard] Univ Potsdam, HPI, D-14469 Potsdam, Germany; [Gan, Chuang] MIT, IBM Watson AI Lab, Cambridge, MA 02142 USA	University of Potsdam; Massachusetts Institute of Technology (MIT)	Gan, C (corresponding author), MIT, IBM Watson AI Lab, Cambridge, MA 02142 USA.	longxiang@baidu.com; gdm@demelo.org; hedongliang01@baidu.com; lifu@baidu.com; chizhizhen@baidu.com; wenshilei@baidu.com; ganchuang@csail.mit.edu						Abu-El-Haija S, 2016, YOUTUBE 8M LARGE SCA; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Ba J., 2014, ARXIV; Bahdanau Dzmitry, 2015, NEURAL MACHINE TRANS; Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Cheng Jianpeng, 2016, EMPIRICAL METHODS NA; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Du Y, 2018, LECT NOTES COMPUT SC, V11220, P388, DOI 10.1007/978-3-030-01270-0_23; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Feichtenhofer Christoph, 2016, NIPS; Feng WJ, 2017, LECT NOTES COMPUT SC, V10614, P574, DOI 10.1007/978-3-319-68612-7_65; Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337; Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622; Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kay W., 2017, ARXIV PREPRINT ARXIV; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Li Hanchao, 2018, ARXIV180510180; Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718; Lin RC, 2019, LECT NOTES COMPUT SC, V11132, P206, DOI 10.1007/978-3-030-11018-5_19; Lin Z., 2017, ARXIV PREPRINT ARXIV; Long X, 2018, AAAI CONF ARTIF INTE, P7202; Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003; Materzynska J, 2019, IEEE INT CONF COMP V, P2874, DOI 10.1109/ICCVW.2019.00349; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Paulus Romain, 2017, ARXIV170504304; Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013; Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590; Sharma Shikhar, 2015, ARXIV151104119, P1; Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132; Simonyan Karen, 2015, VERY DEEP CONVOLUTIO; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Soomro K., 2012, COMPUT SCI; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tieleman Tijmen, 2012, LECT 65 RMSPROP DIVI, V4; Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675; Vaswani A, 2017, ADV NEUR IN, V30; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155; Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678; Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059; Wang P, 2017, IEEE T CIRC SYST VID, V27, P2613, DOI 10.1109/TCSVT.2016.2576761; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19; Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297; Zhang D., 2018, PROC ASIAN C COMPUT, P712; Zhang JR, 2020, IEEE T IMAGE PROCESS, V29, P5491, DOI 10.1109/TIP.2020.2985219; Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49; Zhu YY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P99, DOI 10.1145/3240508.3240525	64	6	6	2	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2140	2154		10.1109/TPAMI.2020.3029554	http://dx.doi.org/10.1109/TPAMI.2020.3029554			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33026984				2022-12-18	WOS:000764815300035
J	Wang, HJ; Li, GB; Liu, XB; Lin, L				Wang, Hongjun; Li, Guanbin; Liu, Xiaobai; Lin, Liang			A Hamiltonian Monte Carlo Method for Probabilistic Adversarial Attack and Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Monte Carlo methods; Space exploration; Robustness; Markov processes; Cats; Iterative methods; Adversarial example; adversarial training; robustness and safety of machine learning	NO	Although deep convolutional neural networks (CNNs) have demonstrated remarkable performance on multiple computer vision tasks, researches on adversarial learning have shown that deep models are vulnerable to adversarial examples, which are crafted by adding visually imperceptible perturbations to the input images. Most of the existing adversarial attack methods only create a single adversarial example for the input, which just gives a glimpse of the underlying data manifold of adversarial examples. An attractive solution is to explore the solution space of the adversarial examples and generate a diverse bunch of them, which could potentially improve the robustness of real-world systems and help prevent severe security threats and vulnerabilities. In this paper, we present an effective method, called Hamiltonian Monte Carlo with Accumulated Momentum (HMCAM), aiming to generate a sequence of adversarial examples. To improve the efficiency of HMC, we propose a new regime to automatically control the length of trajectories, which allows the algorithm to move with adaptive step sizes along the search direction at different positions. Moreover, we revisit the reason for high computational cost of adversarial training under the view of MCMC and design a new generative method called Contrastive Adversarial Training (CAT), which approaches equilibrium distribution of adversarial examples with only few iterations by building from small modifications of the standard Contrastive Divergence (CD) and achieve a trade-off between efficiency and accuracy. Both quantitative and qualitative analysis on several natural image datasets and practical systems have confirmed the superiority of the proposed algorithm.	[Wang, Hongjun; Li, Guanbin; Lin, Liang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China; [Liu, Xiaobai] San Diego State Univ, Dept Comp Sci, San Diego, CA 92182 USA	Sun Yat Sen University; California State University System; San Diego State University	Li, GB (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.	wanghq8@mail2.sysu.edu.cn; liguanbin@mail.sysu.edu.cn; xiaobai.liu@sdsu.edu; linliang@ieee.org		Liang, Lin/0000-0003-2248-3755; Wang, Hongjun/0000-0001-5269-5471	National Key Research and Development Program of China [2018YFC0830103]; National Natural Science Foundation of China [61976250, 61702565]; Guangdong Basic and Applied Basic Research Foundation [2020B1515020048]; National High Level Talents Special Support Plan (Ten Thousand Talents Program); CCF-Tencent Open Research Fund	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Guangdong Basic and Applied Basic Research Foundation; National High Level Talents Special Support Plan (Ten Thousand Talents Program); CCF-Tencent Open Research Fund	This work was supported in part by the National Key Research and Development Program of China under Grant No.2018YFC0830103, in part by the National Natural Science Foundation of China under Grant No.61976250, No.61702565 and No.U1811463, in part by the Guangdong Basic and Applied Basic Research Foundation under Grant No.2020B1515020048, in part by National High Level Talents Special Support Plan (Ten Thousand Talents Program). This work was also sponsored by CCF-Tencent Open Research Fund.	Akhtar N, 2018, PROC CVPR IEEE, P3389, DOI 10.1109/CVPR.2018.00357; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Athalye A, 2018, PR MACH LEARN RES, V80; Bhagoji A.N., 2018, 2018 52 ANN C INF SC, P1, DOI [10.1109/CISS.2018.8362326, DOI 10.1109/CISS.2018.8362326]; Bhagoji Arjun Nitin, 2017, ARXIV171209491; Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49; Chen TQ, 2014, PR MACH LEARN RES, V32, P1683; Christian Szegedy, 2014, Arxiv, DOI arXiv:1312.6199; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957; DUANE S, 1987, PHYS LETT B, V195, P216, DOI 10.1016/0370-2693(87)91197-X; Farnia F., 2020, ABS200209124 CORR; Gilmer J., 2018, P 6 INT C LEARN REPR; Goodfellow I.J., 2015, STATISTICAL, DOI DOI 10.48550/ARXIV.1412.6572; Gu S., 2015, INT C LEARN REPR ICL, P1; Gulrajani I., 2019, P 7 INT C LEARN REPR; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hensel M, 2017, ADV NEUR IN, V30; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hoffman MD, 2014, J MACH LEARN RES, V15, P1593; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Kannan Harini, 2018, ARXIV180306373; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Kurakin A, 2018, ICLR, P99, DOI DOI 10.1201/9781351251389-8; LeCun Y, 2011, MNIST DATABASE HANDW, DOI DOI 10.1109/MSP.2012.2211477; Lecuyer M, 2019, P IEEE S SECUR PRIV, P656, DOI 10.1109/SP.2019.00044; Li H., 2019, ABS190503434 CORR; Li X, 2017, IEEE I CONF COMP VIS, P5775, DOI 10.1109/ICCV.2017.615; Li YD, 2019, PR MACH LEARN RES, V97; Liao FZ, 2018, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR.2018.00191; Liu X., 2019, P 7 INT C LEARN REPR; Liu XQ, 2018, LECT NOTES COMPUT SC, V11211, P381, DOI 10.1007/978-3-030-01234-2_23; Liu XQ, 2019, PROC CVPR IEEE, P11226, DOI 10.1109/CVPR.2019.01149; Liu Y., 2017, P 5 INT C LEARN REPR; Ma X., 2018, 2018 15 INT S WIRELE, P1; Madry A., 2018, P ICLR VANC BC CAN; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Metzen J. H., 2017, 5 INT C LEARNING REP, DOI DOI 10.1109/ICCV.2017.300; Neal RM, 2011, CH CRC HANDB MOD STA, P113; Neal RM, 1993, CRGTR931 U TOR DEP C; Nicolae M.-I., 2018, 180701069 CORR, V1807; Papernot N., 2017, ABS170505264 CORR, V1705; Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41; Pasarica C, 2010, STAT SINICA, V20, P343; Radford A., 2015, ARXIV PREPR ARXIV151; Reddi Sashank J., 2018, INT C LEARN REPR; Rony J, 2019, PROC CVPR IEEE, P4317, DOI 10.1109/CVPR.2019.00445; Salimans T, 2015, PR MACH LEARN RES, V37, P1218; Shafahi A, 2019, ADV NEUR IN, V32; Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392; Sitawarin C., 2018, ABS180206430 CORR; Song JM, 2017, ADV NEUR IN, V30; Song Y, 2019, P COMBUST INST, V37, P667, DOI 10.1016/j.proci.2018.06.115; Stutz D, 2019, PROC CVPR IEEE, P6969, DOI 10.1109/CVPR.2019.00714; Tanay T., 2016, ARXIV PREPRINT ARXIV; Tao GH, 2018, ADV NEUR IN, V31; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang HJ, 2020, PROC CVPR IEEE, P339, DOI 10.1109/CVPR42600.2020.00042; Wang HJ, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1141, DOI 10.1145/3357384.3357999; Webster R, 2019, PROC CVPR IEEE, P11265, DOI 10.1109/CVPR.2019.01153; Xie C., 2018, P 6 INT C LEARN REPR; Xie CH, 2019, PROC CVPR IEEE, P2725, DOI 10.1109/CVPR.2019.00284; Xie CH, 2019, PROC CVPR IEEE, P501, DOI 10.1109/CVPR.2019.00059; Xie JW, 2018, AAAI CONF ARTIF INTE, P4292; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Zhang CL, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P271, DOI 10.1109/SIPROCESS.2018.8600516; Zhang DH, 2019, ADV NEUR IN, V32; Zhang HY, 2019, PR MACH LEARN RES, V97; Zheng TH, 2019, AAAI CONF ARTIF INTE, P2253	73	6	6	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1725	1737		10.1109/TPAMI.2020.3032061	http://dx.doi.org/10.1109/TPAMI.2020.3032061			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33074803	Green Submitted			2022-12-18	WOS:000764815300008
J	Souibgui, MA; Kessentini, Y				Souibgui, Mohamed Ali; Kessentini, Yousri			DE-GAN: A Conditional Generative Adversarial Network for Document Enhancement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generative adversarial networks; Text analysis; Machine learning; Image restoration; Document analysis; document enhancement; degraded document binarization; watermark removal; deep learning; generative adversarial networks	THRESHOLD SELECTION METHOD; BINARIZATION TECHNIQUE; COMPETITION; IMAGES	Documents often exhibit various forms of degradation, which make it hard to be read and substantially deteriorate the performance of an OCR system. In this paper, we propose an effective end-to-end framework named document enhancement generative adversarial networks (DE-GAN) that uses the conditional GANs (cGANs) to restore severely degraded document images. To the best of our knowledge, this practice has not been studied within the context of generative adversarial deep networks. We demonstrate that, in different tasks (document clean up, binarization, deblurring and watermark removal), DE-GAN can produce an enhanced version of the degraded document with a high quality. In addition, our approach provides consistent improvements compared to state-of-the-art methods over the widely used DIBCO 2013, DIBCO 2017, and H-DIBCO 2018 datasets, proving its ability to restore a degraded document image to its ideal condition. The obtained results on a wide variety of degradation reveal the flexibility of the proposed model to be exploited in other document enhancement problems.	[Souibgui, Mohamed Ali] Univ Autonoma Barcelona, Comp Vis Ctr, Bellaterra 08193, Spain; [Souibgui, Mohamed Ali] Univ Autonoma Barcelona, Comp Sci Dept, Bellaterra 08193, Spain; [Kessentini, Yousri] Digital Res Ctr Sfax, Sfax 3021, Tunisia; [Kessentini, Yousri] Univ Sfax, MIRACL Lab, Sfax 3029, Tunisia	Autonomous University of Barcelona; Centre de Visio per Computador (CVC); Autonomous University of Barcelona; Centre de Recherche en Numerique de Sfax (CRNS); Universite de Sfax; Universite de Sfax	Kessentini, Y (corresponding author), Digital Res Ctr Sfax, Sfax 3021, Tunisia.; Kessentini, Y (corresponding author), Univ Sfax, MIRACL Lab, Sfax 3029, Tunisia.	msouibgui@cvc.uab.es; yousri.kessentini@crns.rnrt.tn	Kessentini, Yousri/H-9371-2019	Kessentini, Yousri/0000-0002-4017-1846; Souibgui, Mohamed Ali/0000-0003-0100-9392	Swedish Research Council [2018-06074]; Spanish Project [RTI2018-095645-B-C21]; CERCA Program/Generalitat de Catalunya	Swedish Research Council(Swedish Research CouncilEuropean Commission); Spanish Project(Spanish Government); CERCA Program/Generalitat de Catalunya	This work was supported in part by the Swedish Research Council (grant 2018-06074, DECRYPT), the Spanish Project RTI2018-095645-B-C21 and the CERCA Program/Generalitat de Catalunya.	Afzal M. Z., 2015, HIP 15, P79; Annabestani M, 2019, IJST-T ELECTR ENG, V43, P219, DOI 10.1007/s40998-018-0160-7; [Anonymous], 2006, P INT WORKSH FRONT H; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Bako S, 2017, LECT NOTES COMPUT SC, V10113, P173, DOI 10.1007/978-3-319-54187-7_12; Bhunia AK, 2018, INT C PATT RECOG, P3645, DOI 10.1109/ICPR.2018.8545184; Calvo-Zaragoza J, 2019, PATTERN RECOGN, V86, P37, DOI 10.1016/j.patcog.2018.08.011; Chen XG, 2011, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2011.5995568; Cheng DN, 2018, LECT NOTES COMPUT SC, V11258, P27, DOI 10.1007/978-3-030-03338-5_3; Cheriet M, 1998, IEEE T IMAGE PROCESS, V7, P918, DOI 10.1109/83.679444; Chou CH, 2010, PATTERN RECOGN, V43, P1518, DOI 10.1016/j.patcog.2009.10.016; Chutani G, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2272, DOI 10.1109/ICACCI.2015.7275956; Dekel T, 2017, PROC CVPR IEEE, P6864, DOI 10.1109/CVPR.2017.726; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Gatos B, 2004, LECT NOTES COMPUT SC, V3163, P102; Gatos Basilis, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1375, DOI 10.1109/ICDAR.2009.246; Ghosh A, 2017, AAAI CONF ARTIF INTE, P4927; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Hedjam R, 2014, INT C PATT RECOG, P3026, DOI 10.1109/ICPR.2014.522; Howe NR, 2013, INT J DOC ANAL RECOG, V16, P247, DOI 10.1007/s10032-012-0192-x; Hradi M., 2015, BRIT MACH VIS C; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Kingma D.P, P 3 INT C LEARNING R; Kligler N, 2018, PROC CVPR IEEE, P2374, DOI 10.1109/CVPR.2018.00252; Konwer A, 2018, INT C PATT RECOG, P1103, DOI 10.1109/ICPR.2018.8546105; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lelore T, 2013, IEEE T PATTERN ANAL, V35, P2039, DOI 10.1109/TPAMI.2013.63; Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008; Luc P., 2016, NIPS WORKSHOP ADVERS; Mao XJ, 2016, ADV NEUR IN, V29; Meng GF, 2017, PROC INT CONF DOC, P727, DOI 10.1109/ICDAR.2017.124; Milyaev S, 2015, INT J DOC ANAL RECOG, V18, P169, DOI 10.1007/s10032-015-0240-4; Moghaddam RF, 2010, IEEE T PATTERN ANAL, V32, P1347, DOI 10.1109/TPAMI.2009.141; Niblack W., 1985, INTRO DIGITAL IMAGE; Ntirogiannis K, 2014, INT CONF FRONT HAND, P809, DOI 10.1109/ICFHR.2014.141; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Pandey R. K., 2017, ABS170108835, V1701; Phansalkar Neerad, 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P218, DOI 10.1109/ICCSP.2011.5739305; Pratikakis I, 2018, INT CONF FRONT HAND, P489, DOI 10.1109/ICFHR-2018.2018.00091; Pratikakis I, 2017, PROC INT CONF DOC, P1395, DOI 10.1109/ICDAR.2017.228; Pratikakis I, 2016, INT CONF FRONT HAND, P619, DOI [10.1109/ICFHR.2016.0118, 10.1109/ICFHR.2016.110]; Pratikakis I, 2013, PROC INT CONF DOC, P1471, DOI 10.1109/ICDAR.2013.219; Pratikakis I, 2012, INT CONF FRONT HAND, P817, DOI 10.1109/ICFHR.2012.216; Pratikakis I, 2011, PROC INT CONF DOC, P1506, DOI 10.1109/ICDAR.2011.299; Ronneberger O., 2015, INT C MED IM COMP CO, P234, DOI [10.1007/978-3-319-24574-4_28, DOI 10.1007/978-3-319-24574-4_28]; Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2; Schreiber S, 2017, PROC INT CONF DOC, P1162, DOI 10.1109/ICDAR.2017.192; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991; Su BL, 2013, IEEE T IMAGE PROCESS, V22, P1408, DOI 10.1109/TIP.2012.2231089; Tan CL, 2006, IEEE T PATTERN ANAL, V28, P195, DOI 10.1109/TPAMI.2006.40; Tensmeyer C, 2017, PROC INT CONF DOC, P99, DOI 10.1109/ICDAR.2017.25; Vo QN, 2018, PATTERN RECOGN, V74, P568, DOI 10.1016/j.patcog.2017.08.025; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Westphal F, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P263, DOI 10.1109/DAS.2018.71; Wu JL, 2018, INT CONF BIOMETR, P69, DOI 10.1109/ICB2018.2018.00021; Xie J., 2012, ADV NEURAL INFORM PR, P341, DOI DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605; Xiong W, 2018, INT C PATT RECOG, P3716, DOI 10.1109/ICPR.2018.8546099; Xiong W, 2018, OPTIK, V164, P218, DOI 10.1016/j.ijleo.2018.02.072; Xu CR, 2017, INT CONF SYST INFORM, P1152; Zamora-Martinez F, 2007, LECT NOTES COMPUT SC, V4507, P144; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	64	6	6	22	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1180	1191		10.1109/TPAMI.2020.3022406	http://dx.doi.org/10.1109/TPAMI.2020.3022406			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32894707	Green Submitted			2022-12-18	WOS:000752018000009
J	Nie, FP; Wu, DY; Wang, R; Li, XL				Nie, Feiping; Wu, Danyang; Wang, Rong; Li, Xuelong			Truncated Robust Principle Component Analysis With A General Optimization Framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robust principle component analysis (RPCA); unsupervised dimensionality reduction; truncated loss; non-convex optimization	TUTORIAL	Recently, several robust principle component analysis (RPCA) models have been proposed to improve the robustness of principle component analysis (PCA). But an important problem that the robustness to outliers affects the discrimination of correct samples has not been solved yet. To solve this problem, we propose a truncated robust principle component analysis (T-RPCA) model which treats correct samples and outliers separately. In fact, the proposed model performs an implicitly truncated weighted learning scheme which is more reasonable for robustness learning respective to previous works. Moreover, we propose a re-weighted (RW) optimization framework to solve a general problem and generalize two sub-frameworks upon it. To be specific, the first sub-framework orients a general truncated loss optimization problem which contains the objective problem of T-RPCA, and the second one focuses on a general singular-value based optimization problem. Besides, we provide rigorously theoretical guarantees for the proposed model, RW framework and sub-frameworks. Empirical studies demonstrate that the proposed T-RPCA model outperforms previous RPCA models on reconstruction and classification tasks.	[Nie, Feiping; Wu, Danyang; Li, Xuelong] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China; [Nie, Feiping; Wu, Danyang; Li, Xuelong] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning, Xian 710072, Shaanxi, Peoples R China; [Wang, Rong] Northwestern Polytech Univ, Sch Cybersecur, Xian 710072, Shaanxi, Peoples R China; [Wang, Rong] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University	Li, XL (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Li, XL (corresponding author), Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning, Xian 710072, Shaanxi, Peoples R China.	feipingnie@gmail.com; danyangwu41x@mail.nwpu.edu.cn; wangrong07@tsinghua.org.cn; xuelong_li@nwpu.edu.cn	Wu, Danyang/GZH-0208-2022	Wang, Rong/0000-0001-9240-6726; Nie, Feiping/0000-0002-0871-6519; Wu, Danyang/0000-0002-0309-1409	National Key Research and Development Program of China [2018AAA0101902]; National Natural Science Foundation of China [61936014, 61772427, 61751202, U1801262, 61871470]; Fundamental Research Funds for the Central Universities [G2019KY0501]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0101902, in part by the National Natural Science Foundation of China under Grant 61936014, Grant 61772427, Grant 61751202, Grant U1801262, Grant 61871470, and in part by the Fundamental Research Funds for the Central Universities under Grant G2019KY0501.	Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Boyd S, 2004, CONVEX OPTIMIZATION; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cai X., 2013, P 23 INT JOINT C ART, P2598, DOI DOI 10.5555/2540128.2540503; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI [10.1145/1961189.1961199, DOI 10.1145/1961189.1961199]; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Ding C., 2006, PROC INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880; Gao QX, 2013, IEEE T IMAGE PROCESS, V22, P3807, DOI 10.1109/TIP.2013.2262286; He R, 2011, IEEE T IMAGE PROCESS, V20, P1485, DOI 10.1109/TIP.2010.2103949; Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Ke QF, 2005, PROC CVPR IEEE, P739; Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114; Lange K, 2016, MM OPTIMIZATION ALGORITHMS, P1, DOI 10.1137/1.9781611974409; Lee JA, 2010, IEEE IJCNN, DOI 10.1109/CEFC.2010.5481004; Li XL, 2019, IEEE T NEUR NET LEAR, V30, P2067, DOI 10.1109/TNNLS.2018.2876327; Lin Z., 2010, ARXIV PREPRINT ARXIV; Liu GX, 2010, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INNOVATION AND MANAGEMENT, VOLS I AND II, P1; Nie F., 2011, PROC INT JOINT C ART, P1433; Nie F., 2010, ADV NEURAL INFORM PR, V1, P1813, DOI DOI 10.1007/978-3-319-10690-8_12; Nie F., 2012, PROC 26 AAAI C ARTIF, P655; Nie FP, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2012, DOI 10.1145/3219819.3219951; Nie FP, 2017, AAAI CONF ARTIF INTE, P2415; Nie FP, 2014, PR MACH LEARN RES, V32, P1062; Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728; Stewart G., 1998, MATRIX ALGORITHMS, V1; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758; Tuzlukov V., 2018, SIGNAL PROCESSING NO, V1st; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; Wang J, 2002, J PROCESS CONTR, V12, P841, DOI 10.1016/S0959-1524(02)00016-1; Wang QQ, 2018, IEEE T IMAGE PROCESS, V27, P1336, DOI 10.1109/TIP.2017.2777184; Wang YM, 2015, IEEE WINT CONF APPL, P542, DOI 10.1109/WACV.2015.78; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Xiao Cai, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P91, DOI 10.1109/ICDM.2011.105; Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023; Zhang YQ, 2014, INFORM SCIENCES, V259, P128, DOI 10.1016/j.ins.2013.08.002; Zhao W, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P336, DOI 10.1109/AFGR.1998.670971; Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865; Zhou GQ, 2017, IEEE T GEOSCI REMOTE, V55, P1074, DOI 10.1109/TGRS.2016.2619184	41	6	6	14	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					1081	1097		10.1109/TPAMI.2020.3027968	http://dx.doi.org/10.1109/TPAMI.2020.3027968			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32997623				2022-12-18	WOS:000740006100038
J	Qi, XJ; Liu, ZZ; Liao, RJ; Torr, PHS; Urtasun, R; Jia, JY				Qi, Xiaojuan; Liu, Zhengzhe; Liao, Renjie; Torr, Philip H. S.; Urtasun, Raquel; Jia, Jiaya			GeoNet plus plus : Iterative Geometric Neural Network with Edge-Aware Refinement for Joint Depth and Surface Normal Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Surface reconstruction; Estimation; Image reconstruction; Computer architecture; Measurement; Neural networks; Depth estimation; surface normal estimation; 3D point cloud; 3D geometric consistency; 3D reconstruction; edge-aware; convolutional neural network (CNN); geometric neural network		In this paper, we propose a geometric neural network with edge-aware refinement (GeoNet++) to jointly predict both depth and surface normal maps from a single image. Building on top of two-stream CNNs, GeoNet++ captures the geometric relationships between depth and surface normals with the proposed depth-to-normal and normal-to-depth modules. In particular, the "depth-to-normal" module exploits the least square solution of estimating surface normals from depth to improve their quality, while the "normal-to-depth" module refines the depth map based on the constraints on surface normals through kernel regression. Boundary information is exploited via an edge-aware refinement module. GeoNet++ effectively predicts depth and surface normals with high 3D consistency and sharp boundaries resulting in better reconstructed 3D scenes. Note that GeoNet++ is generic and can be used in other depth/normal prediction frameworks to improve 3D reconstruction quality and pixel-wise accuracy of depth and surface normals. Furthermore, we propose a new 3D geometric metric (3DGM) for evaluating depth prediction in 3D. In contrast to current metrics that focus on evaluating pixel-wise error/accuracy, 3DGM measures whether the predicted depth can reconstruct high quality 3D surface normals. This is a more natural metric for many 3D application domains. Our experiments on NYUD-V2 [1] and KITTI [2] datasets verify that GeoNet++ produces fine boundary details and the predicted depth can be used to reconstruct high quality 3D surfaces.	[Qi, Xiaojuan] Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong 999077, Peoples R China; [Liu, Zhengzhe] DJI Corp, Shenzhen 518000, Peoples R China; [Liao, Renjie; Urtasun, Raquel] Univ Toronto, Dept Comp Sci, Uber ATG, Toronto, ON M5S, Canada; [Liao, Renjie] Vector Inst, Toronto, ON M5G 1M1, Canada; [Torr, Philip H. S.] Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England; [Jia, Jiaya] Tencent X Lab, Shenzhen, Peoples R China; [Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong 999077, Peoples R China	University of Hong Kong; University of Toronto; University of Oxford; Chinese University of Hong Kong	Qi, XJ (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong 999077, Peoples R China.	qxj0125@gmail.com; liuzhengzhelzz@gmail.com; rjliao@cs.toronto.edu; philip.torr@eng.ox.ac.uk; urtasun@cs.toronto.edu; leojia@cse.cuhk.edu.hk			HKU Start-up Fund; Seed Fund for Basic Research; ERC [ERC-2012-AdG321162-HELIOS]; EPSRC [Seebibyte EP/M013774/1]; EPSRC/MURI [EP/N019474/1]; Connaught International Scholarship; RBC Fellowship	HKU Start-up Fund; Seed Fund for Basic Research; ERC(European Research Council (ERC)European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC/MURI(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Connaught International Scholarship; RBC Fellowship	The work was supported in part by the HKU Start-up Fund, Seed Fund for Basic Research, the ERC grant ERC-2012-AdG321162-HELIOS, EPSRC grant Seebibyte EP/M013774/1, and EPSRC/MURI grant EP/N019474/1. The authors would also like to thank the Royal Academy of Engineering and FiveAI. Thework of Renjie Liaowas supported by Connaught International Scholarship and RBC Fellowship. Xiaojuan Qi and Zhengzhe Liu are co-first authors.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Baig L., 2016, IEEEWINTER C APPL CO, P1; Bansal A, 2016, PROC CVPR IEEE, P5965, DOI 10.1109/CVPR.2016.642; Bansal Aayush, 2017, ARXIV PREPRINT ARXIV; Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; Chakrabarti Ayan, 2016, NIPS; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LC, 2016, PROC CVPR IEEE, P4545, DOI 10.1109/CVPR.2016.492; Eigen D, 2014, ADV NEUR IN, V27; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Favaro P, 2005, IEEE T PATTERN ANAL, V27, P406, DOI 10.1109/TPAMI.2005.43; Fouhey DF, 2013, IEEE I CONF COMP VIS, P3392, DOI 10.1109/ICCV.2013.421; Fouhey DF, 2014, LECT NOTES COMPUT SC, V8694, P687, DOI 10.1007/978-3-319-10599-4_44; Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56; Kingma D.P, P 3 INT C LEARNING R; Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Ladicky L, 2014, LECT NOTES COMPUT SC, V8693, P468, DOI 10.1007/978-3-319-10602-1_31; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780; Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715; Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Liu MM, 2014, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2014.97; Liu W, 2016, INT WORKS EARTH OB; Ma WC, 2018, LECT NOTES COMPUT SC, V11218, P211, DOI 10.1007/978-3-030-01264-9_13; Qi XJ, 2018, PROC CVPR IEEE, P283, DOI 10.1109/CVPR.2018.00037; Roy A, 2016, PROC CVPR IEEE, P5506, DOI 10.1109/CVPR.2016.594; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Saxena Ashutosh, 2006, ADV NEURAL INFORM PR, P1, DOI [DOI 10.1109/TPAMI.2015.2505283A, 10.1109/TPAMI.2015.2505283a]; Schwing AG, 2013, IEEE I CONF COMP VIS, P353, DOI 10.1109/ICCV.2013.51; Shelhamer E, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P235, DOI 10.1109/ICCVW.2015.39; Shi JP, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818136; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214; Uhrig J, 2017, INT CONF 3D VISION, P11, DOI 10.1109/3DV.2017.00012; Wang P, 2016, ADV NEUR IN, V29; Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897; Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652; Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077; Xu D, 2019, IEEE T PATTERN ANAL, V41, P1426, DOI 10.1109/TPAMI.2018.2839602; Xu D, 2017, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2017.25; Yang ZH, 2018, AAAI CONF ARTIF INTE, P7493; Zhang YD, 2018, PROC CVPR IEEE, P175, DOI 10.1109/CVPR.2018.00026; Zhang ZY, 2018, LECT NOTES COMPUT SC, V11214, P238, DOI 10.1007/978-3-030-01249-6_15; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhuo W, 2015, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2015.7298660	54	6	6	2	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					969	984		10.1109/TPAMI.2020.3020800	http://dx.doi.org/10.1109/TPAMI.2020.3020800			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32870785	Green Submitted			2022-12-18	WOS:000740006100031
J	Chen, GY; Han, K; Shi, BX; Matsushita, Y; Wong, KYK				Chen, Guanying; Han, Kai; Shi, Boxin; Matsushita, Yasuyuki; Wong, Kwan-Yee K.			Deep Photometric Stereo for Non-Lambertian Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; non-Lambertian; uncalibrated; convolutional neural network	SHAPE RECONSTRUCTION	This paper addresses the problem of photometric stereo, in both calibrated and uncalibrated scenarios, for non-Lambertian surfaces based on deep learning. We first introduce a fully convolutional deep network for calibrated photometric stereo, which we call PS-FCN. Unlike traditional approaches that adopt simplified reflectance models to make the problem tractable, our method directly learns the mapping from reflectance observations to surface normal, and is able to handle surfaces with general and unknown isotropic reflectance. At test time, PS-FCN takes an arbitrary number of images and their associated light directions as input and predicts a surface normal map of the scene in a fast feed-forward pass. To deal with the uncalibrated scenario where light directions are unknown, we introduce a new convolutional network, named LCNet, to estimate light directions from input images. The estimated light directions and the input images are then fed to PS-FCN to determine the surface normals. Our method does not require a pre-defined set of light directions and can handle multiple images in an order-agnostic manner. Thorough evaluation of our approach on both synthetic and real datasets shows that it outperforms state-of-the-art methods in both calibrated and uncalibrated scenarios.	[Chen, Guanying; Wong, Kwan-Yee K.] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; [Han, Kai] Univ Oxford, Visual Geometry Grp VGG, Oxford OX1 2JD, England; [Shi, Boxin] Peking Univ, Dept Comp Sci & Technol, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China; [Shi, Boxin] Peking Univ, Inst Artificial Intelligence, Beijing 100871, Peoples R China; [Matsushita, Yasuyuki] Osaka Univ, Suita, Osaka 5650871, Japan	University of Hong Kong; University of Oxford; Peking University; Peking University; Osaka University	Wong, KYK (corresponding author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.	gychen@cs.hku.hk; khan@robots.ox.ac.uk; shiboxin@pku.edu.cn; yasumat@ist.osaka-u.ac.jp; kykwong@cs.hku.hk	Han, Kai/AAB-7809-2021	Han, Kai/0000-0002-7995-9999; Matsushita, Yasuyui/0000-0002-1935-4752	EPSRC [Seebibyte EP/M013774/1]; National Natural Science Foundation of China [61872012]; National Key R&D Program of China [2019YFF0302902]; Beijing Academy of Artificial Intelligence(BAAI); JSPS KAKENHI [JP19H01123]; Research Grant Council of the Hong Kong (SAR), China [HKU 17203119]	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key R&D Program of China; Beijing Academy of Artificial Intelligence(BAAI); JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); Research Grant Council of the Hong Kong (SAR), China(Hong Kong Research Grants Council)	The work of Kai Han was supported by EPSRC Programme Grant Seebibyte EP/M013774/1. The work of Boxin Shi was supported by National Natural Science Foundation of China under Grant No. 61872012, National Key R&D Program of China (2019YFF0302902), and Beijing Academy of Artificial Intelligence (BAAI). The work of Yasuyuki Matsushita was supported by JSPS KAKENHI Grant Number JP19H01123. The work of Kwan-Yee K. Wong was supported by a grant from the Research Grant Council of the Hong Kong (SAR), China, under the ProjectHKU 17203119.	Alldrin N, 2008, PROC CVPR IEEE, P2447; Alldrin NG, 2007, PROC CVPR IEEE, P1822; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Chandraker MK, 2005, PROC CVPR IEEE, P788; Chen GY, 2019, PROC CVPR IEEE, P8731, DOI 10.1109/CVPR.2019.00894; Chen GY, 2018, LECT NOTES COMPUT SC, V11213, P3, DOI 10.1007/978-3-030-01240-3_1; Cho D, 2016, LECT NOTES COMPUT SC, V9906, P170, DOI 10.1007/978-3-319-46475-6_11; Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38; Chung HS, 2008, PROC CVPR IEEE, P3337; Drbohlav O, 2005, IEEE I CONF COMP VIS, P1850; Eigen D, 2014, ADV NEUR IN, V27; Einarsson P., 2006, RENDERING TECHNIQUES, P183, DOI [10.2312/EGWR/EGSR06/183-194, DOI 10.2312/EGWR/EGSR06/183-194]; Gardner MA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130891; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P1060, DOI 10.1109/TPAMI.2009.102; Hartmann W, 2017, IEEE I CONF COMP VIS, P1595, DOI 10.1109/ICCV.2017.176; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Herbort S, 2011, 3D RES, V2, DOI 10.1007/3DRes.03(2011)4; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Hold-Geoffroy Y, 2017, PROC CVPR IEEE, P2373, DOI 10.1109/CVPR.2017.255; Holroyd M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409086; Hui Z, 2017, IEEE T PATTERN ANAL, V39, P2060, DOI 10.1109/TPAMI.2016.2623613; Ikehata S, 2018, LECT NOTES COMPUT SC, V11219, P3, DOI 10.1007/978-3-030-01267-0_1; Ikehata S, 2014, PROC CVPR IEEE, P2187, DOI 10.1109/CVPR.2014.280; Ikehata S, 2012, PROC CVPR IEEE, P318, DOI 10.1109/CVPR.2012.6247691; Jakob Wenzel, 2010, MITSUBA RENDERER; Johnson M. K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2553, DOI 10.1109/CVPR.2011.5995510; Kingma D.P, P 3 INT C LEARNING R; Lu F, 2018, IEEE T PATTERN ANAL, V40, P221, DOI 10.1109/TPAMI.2017.2655525; Lu F, 2015, PROC CVPR IEEE, P168, DOI 10.1109/CVPR.2015.7298612; Lu F, 2013, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2013.196; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; Miyazaki D, 2010, INT J COMPUT VISION, V86, P229, DOI 10.1007/s11263-009-0262-9; Mukaigawa Y, 2007, J OPT SOC AM A, V24, P3326, DOI 10.1364/JOSAA.24.003326; Okabe T, 2009, IEEE I CONF COMP VIS, P1693, DOI 10.1109/ICCV.2009.5459381; Papadhimitri T, 2014, INT J COMPUT VISION, V107, P139, DOI 10.1007/s11263-013-0665-5; Paszke Adam, 2017, PYTORCH TENSORS DYNA, P6; Ruiters R, 2009, COMPUT GRAPH FORUM, V28, P513, DOI 10.1111/j.1467-8659.2009.01390.x; Santo H, 2017, IEEE INT CONF COMP V, P501, DOI 10.1109/ICCVW.2017.66; Sato I, 2007, IEEE I CONF COMP VIS, P1493; Shi BX, 2019, IEEE T PATTERN ANAL, V41, P271, DOI 10.1109/TPAMI.2018.2799222; Shi BX, 2014, IEEE T PATTERN ANAL, V36, P1078, DOI 10.1109/TPAMI.2013.196; Shi BX, 2010, PROC CVPR IEEE, P1118, DOI 10.1109/CVPR.2010.5540091; Silver W.M., 1980, THESIS MIT; Tan P, 2007, PROC CVPR IEEE, P1814; Taniai T, 2018, PR MACH LEARN RES, V80; Tozza S, 2016, J MATH IMAGING VIS, V56, P57, DOI 10.1007/s10851-016-0633-0; Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652; Weber H, 2018, INT CONF 3D VISION, P199, DOI 10.1109/3DV.2018.00032; Wiles Olivia, 2017, P BMVC; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Wu TP, 2010, IEEE T PATTERN ANAL, V32, P546, DOI 10.1109/TPAMI.2009.15; Wu Z, 2013, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2013.197; Yuille AL, 1999, INT J COMPUT VISION, V35, P203, DOI 10.1023/A:1008180726317; Zhou H, 2018, PROC CVPR IEEE, P6238, DOI 10.1109/CVPR.2018.00653	58	6	6	4	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					129	142		10.1109/TPAMI.2020.3005397	http://dx.doi.org/10.1109/TPAMI.2020.3005397			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750798	Green Submitted			2022-12-18	WOS:000728561300011
J	Kim, UH; Kim, SH; Kim, JH				Kim, Ue-Hwan; Kim, Se-Ho; Kim, Jong-Hwan			SimVODIS: Simultaneous Visual Odometry, Object Detection, and Instance Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual odometry (VO); data-driven VO; visual SLAM; semantic VO; semantic SLAM; semantic mapping; monocular video; depth map prediction; depth estimation; ego-motion estimation; unsupervised learning; deep convolutional neural network (CNN)		Intelligent agents need to understand the surrounding environment to provide meaningful services to or interact intelligently with humans. The agents should perceive geometric features as well as semantic entities inherent in the environment. Contemporary methods in general provide one type of information regarding the environment at a time, making it difficult to conduct high-level tasks. Moreover, running two types of methods and associating two resultant information requires a lot of computation and complicates the software architecture. To overcome these limitations, we propose a neural architecture that simultaneously performs both geometric and semantic tasks in a single thread: simultaneous visual odometry, object detection, and instance segmentation (SimVODIS). SimVODIS is built on top of Mask-RCNN which is trained in a supervised manner. Training the pose and depth branches of SimVODIS requires unlabeled video sequences and the photometric consistency between input image frames generates self-supervision signals. The performance of SimVODIS outperforms or matches the state-of-the-art performance in pose estimation, depth map prediction, object detection, and instance segmentation tasks while completing all the tasks in a single thread. We expect SimVODIS would enhance the autonomy of intelligent agents and let the agents provide effective services to humans.	[Kim, Ue-Hwan; Kim, Se-Ho; Kim, Jong-Hwan] KAIST Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Kim, JH (corresponding author), KAIST Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.	uhkim@rit.kaist.ac.kr; shkim@rit.kaist.ac.kr; johkim@rit.kaist.ac.kr			Institute for Information & communications Technology Promotion (IITP) - Korea Government (MSIT) [2020-0-00440]	Institute for Information & communications Technology Promotion (IITP) - Korea Government (MSIT)(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea)	This work was supported by the Institute for Information & communications Technology Promotion (IITP) Grant funded by the Korea Government (MSIT) (No.2020-0-00440, Development of Artificial Intelligence Technology that Continuously Improves Itself as the Situation Changes in the RealWorld).	An LF, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417735667; Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039; Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326; Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203; Casser V, 2019, AAAI CONF ARTIF INTE, P8001; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261; Eigen D, 2014, ADV NEUR IN, V27; Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577; Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335; Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214; Galvez-Lopez D, 2016, ROBOT AUTON SYST, V75, P435, DOI 10.1016/j.robot.2015.08.009; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Jaderberg M, 2015, ADV NEUR IN, V28; Jeong S, 2018, IEEE T PATTERN ANAL, V40, P2455, DOI 10.1109/TPAMI.2017.2757928; Kendall A, 2016, IEEE INT CONF ROBOT, P4762, DOI 10.1109/ICRA.2016.7487679; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Kim DH, 2016, IEEE T ROBOT, V32, P1565, DOI 10.1109/TRO.2016.2609395; Kim UH, 2020, IEEE T CYBERNETICS, V50, P4921, DOI 10.1109/TCYB.2019.2931042; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Li C., 2010, ADV NEURAL INFORM PR, V23, P1351; Lianos KN, 2018, LECT NOTES COMPUT SC, V11208, P246, DOI 10.1007/978-3-030-01225-0_15; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Ma LN, 2017, IEEE INT C INT ROBOT, P598; Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594; McCormac John, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4628, DOI 10.1109/ICRA.2017.7989538; Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103; Pillai S, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI; Qu XZ, 2015, IEEE INT VEH SYM, P605, DOI 10.1109/IVS.2015.7225751; Ranjan A, 2019, IEEE I CONF COMP VIS, P2404, DOI 10.1109/ICCV.2019.00249; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Scona R, 2018, IEEE INT CONF ROBOT, P3849; Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Stuckler J, 2015, J REAL-TIME IMAGE PR, V10, P599, DOI 10.1007/s11554-013-0379-5; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Sunderhauf N, 2017, IEEE INT C INT ROBOT, P5079; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596; Wang S, 2018, INT J ROBOT RES, V37, P513, DOI 10.1177/0278364917734298; Xiang Y, 2017, ROBOTICS: SCIENCE AND SYSTEMS XIII; Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691; Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043; Zhang ZQ, 2019, IEEE ASME INT C ADV, P1151, DOI 10.1109/AIM.2019.8868400; Zhong FW, 2018, IEEE WINT CONF APPL, P1001, DOI 10.1109/WACV.2018.00115; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zou DP, 2013, IEEE T PATTERN ANAL, V35, P354, DOI 10.1109/TPAMI.2012.104	52	6	6	24	64	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					428	441		10.1109/TPAMI.2020.3007546	http://dx.doi.org/10.1109/TPAMI.2020.3007546			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750805	Green Submitted			2022-12-18	WOS:000728561300031
J	Lei, YW; Tang, K				Lei, Yunwen; Tang, Ke			Learning Rates for Stochastic Gradient Descent With Nonconvex Objectives	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Complexity theory; Training; Convergence; Statistics; Sociology; Computational modeling; Testing; Stochastic gradient descent; learning rates; nonconvex optimization; early stopping	STABILITY	Stochastic gradient descent (SGD) has become the method of choice for training highly complex and nonconvex models since it can not only recover good solutions to minimize training errors but also generalize well. Computational and statistical properties are separately studied to understand the behavior of SGD in the literature. However, there is a lacking study to jointly consider the computational and statistical properties in a nonconvex learning setting. In this paper, we develop novel learning rates of SGD for nonconvex learning by presenting high-probability bounds for both computational and statistical errors. We show that the complexity of SGD iterates grows in a controllable manner with respect to the iteration number, which sheds insights on how an implicit regularization can be achieved by tuning the number of passes to balance the computational and statistical errors. As a byproduct, we also slightly refine the existing studies on the uniform convergence of gradients by showing its connection to Rademacher chaos complexities.	[Lei, Yunwen] Southern Univ Sci & Technol, Dept Comp Sci & Engn, Shenzhen 518055, Peoples R China; [Lei, Yunwen] Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England; [Tang, Ke] Southern Univ Sci & Technol, Dept Comp Sci & Engn, Guangdong Key Lab Brain Inspired Intelligent Comp, Shenzhen 518055, Peoples R China; [Tang, Ke] Southern Univ Sci & Technol, Res Inst Trustworthy Autonomous Syst, Shenzhen 518055, Peoples R China	Southern University of Science & Technology; University of Birmingham; Southern University of Science & Technology; Southern University of Science & Technology	Tang, K (corresponding author), Southern Univ Sci & Technol, Dept Comp Sci & Engn, Guangdong Key Lab Brain Inspired Intelligent Comp, Shenzhen 518055, Peoples R China.	y.lei@bham.ac.uk; tangk3@sustech.edu.cn	Lei, Yunwen/V-2782-2018	Lei, Yunwen/0000-0002-5383-467X	Guangdong Provincial Key Laboratory [2020B121201001]; Program for Guangdong Introducing Innovative and Entrepreneurial Teams [2017ZT07X386]; National Natural Science Foundation of China [61806091]; Science and Technology Commission of Shanghai Municipality [19511120600]; MOE University Scientific-Technological Innovation Plan Program	Guangdong Provincial Key Laboratory; Program for Guangdong Introducing Innovative and Entrepreneurial Teams; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science and Technology Commission of Shanghai Municipality(Science & Technology Commission of Shanghai Municipality (STCSM)); MOE University Scientific-Technological Innovation Plan Program	The authors are grateful to the editor and referees for the constructive comments, which are very helpful to improve the paper. This work was supported in part by the Guangdong Provincial Key Laboratory under Grant 2020B121201001, the Program for Guangdong Introducing Innovative and Entrepreneurial Teams under Grant 2017ZT07X386, the National Natural Science Foundation of China under Grant 61806091, the Science and Technology Commission of Shanghai Municipality under Grant 19511120600, and the MOE University Scientific-Technological Innovation Plan Program.	Allen-Zhu Z, 2016, PR MACH LEARN RES, V48; Bertsekas DP, 2000, SIAM J OPTIMIZ, V10, P627, DOI 10.1137/S1052623497331063; Bottou L, 2018, SIAM REV, V60, P223, DOI 10.1137/16M1080173; Bottou Leon, 1999, ON LINE LEARNING NEU, P9, DOI DOI 10.1017/CBO9780511569920.003; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Bousquet O., 2020, P MACHINE LEARNING R, P610; Bousquet O., 2008, ADV NEURAL INFORM PR, P161, DOI DOI 10.7751/mitpress/8996.003.0015; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI [10.1145/1961189.1961199, DOI 10.1145/1961189.1961199]; Charles Z, 2018, PR MACH LEARN RES, V80; Davis D, 2018, ARXIV181007590; de la Pena V., 2012, DECOUPLING DEPENDENC; Dieuleveut A, 2016, ANN STAT, V44, P1363, DOI 10.1214/15-AOS1391; Elisseeff A, 2005, J MACH LEARN RES, V6, P55; Fang C., 2018, ADV NEURAL INFORM PR, P689; Feldman V., 2019, C LEARN THEOR, V99, P1270; Foster DJ, 2018, ADV NEUR IN, V31; Ghadimi S, 2016, MATH PROGRAM, V155, P267, DOI 10.1007/s10107-014-0846-1; Ghadimi S, 2013, SIAM J OPTIMIZ, V23, P2341, DOI 10.1137/120880811; Hardt M, 2016, PR MACH LEARN RES, V48; Huang SJ, 2019, IEEE T PATTERN ANAL, V41, P2614, DOI 10.1109/TPAMI.2018.2861732; Johnson R., 2013, ADV NEURAL INF PROCE, V26, P315, DOI DOI 10.5555/2999611.2999647; Kakade Sham M, 2009, ADV NEURAL INFORM PR, P801; Karimi H., 2016, JOINT EUROPEAN C MAC, P795; Kingma D.P, P 3 INT C LEARNING R; Kuzborskij I., 2018, P MACHINE LEARNING R, P2820; Lei YW, 2018, ADV NEUR IN, V31; Lin JH, 2016, PR MACH LEARN RES, V48; Lin JH, 2017, J MACH LEARN RES, V18; Liu TL, 2017, IEEE T PATTERN ANAL, V39, P227, DOI 10.1109/TPAMI.2016.2544314; Mou W., 2018, P MACHINE LEARNING R, P605; Nguyen Lam M., 2019, ARXIV190107648; Reddi SJ, 2016, PR MACH LEARN RES, V48; Rosasco L., 2015, ADV NEURAL INFORM PR, V28, P1630; Schmidt M, 2017, MATH PROGRAM, V162, P83, DOI 10.1007/s10107-016-1030-6; Shalev-Shwartz S, 2010, J MACH LEARN RES, V11, P2635; Wang Zhe, 2019, ADV NEURAL INFORM PR, P2403; Ying YM, 2010, NEURAL COMPUT, V22, P2858, DOI 10.1162/NECO_a_00028; Zhang CX, 2018, PROTEINS, V86, P136, DOI 10.1002/prot.25414; Zhang L, 2019, P 32 C LEARN THEOR, P3160; Zhang L., 2013, ADV NEURAL INFORM PR, P980; Zhang L., 2017, COLT, P1954; Zhang T., 2004, P 21 INT C MACH LEAR, P116, DOI 10.1145/1015330.1015332; Zhang WZ, 2017, IEEE T PATTERN ANAL, V39, P1223, DOI 10.1109/TPAMI.2016.2578323; Zhou Y., 2019, ARXIV180206903; Zinkevich M., 2003, P 20 INT C MACH LEAR, P928, DOI 10.5555/3041838	54	6	6	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4505	4511		10.1109/TPAMI.2021.3068154	http://dx.doi.org/10.1109/TPAMI.2021.3068154			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	33755555	Green Published			2022-12-18	WOS:000714203900026
J	Dong, XY; Yang, Y; Wei, SE; Weng, XS; Sheikh, Y; Yu, SI				Dong, Xuanyi; Yang, Yi; Wei, Shih-En; Weng, Xinshuo; Sheikh, Yaser; Yu, Shoou-, I			Supervision by Registration and Triangulation for Landmark Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Detectors; Annotations; Training; Optical detectors; Three-dimensional displays; Adaptive optics; Optical imaging; Landmark detection; optical flow; triangulation; deep learning	MODEL	We present supervision by registration and triangulation (SRT), an unsupervised approach that utilizes unlabeled multi-view video to improve the accuracy and precision of landmark detectors. Being able to utilize unlabeled data enables our detectors to learn from massive amounts of unlabeled data freely available and not be limited by the quality and quantity of manual human annotations. To utilize unlabeled data, there are two key observations: (I) The detections of the same landmark in adjacent frames should be coherent with registration, i.e., optical flow. (II) The detections of the same landmark in multiple synchronized and geometrically calibrated views should correspond to a single 3D point, i.e., multi-view consistency. Registration and multi-view consistency are sources of supervision that do not require manual labeling, thus it can be leveraged to augment existing training data during detector training. End-to-end training is made possible by differentiable registration and 3D triangulation modules. Experiments with 11 datasets and a newly proposed metric to measure precision demonstrate accuracy and precision improvements in landmark detection on both images and video.	[Dong, Xuanyi; Yang, Yi] Univ Technol Sydney, Ctr Artificial Intelligence, Ultimo, NSW 2007, Australia; [Wei, Shih-En; Sheikh, Yaser; Yu, Shoou-, I] Facebook Real Labs, Pittsburgh, PA 15213 USA; [Weng, Xinshuo] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	University of Technology Sydney; Facebook Inc; Carnegie Mellon University	Yang, Y (corresponding author), Univ Technol Sydney, Ctr Artificial Intelligence, Ultimo, NSW 2007, Australia.	xuanyi.dong@student.uts.edu.au; yi.yang@uts.edu.au; shih-en.wei@fb.com; xinshuow@cs.cmu.edu; yaser.sheikh@fb.com; shoou-i.yu@fb.com	Yang, Yi/B-9273-2017; yang, yang/GWB-9426-2022; yang, yang/HGT-7999-2022; Dong, Xuanyi/Q-5434-2019; yang, yang/GVT-5210-2022	Yang, Yi/0000-0002-0512-880X; Dong, Xuanyi/0000-0001-9272-1590; Weng, Xinshuo/0000-0002-7894-4381				Amberg B, 2007, IEEE I CONF COMP VIS, P1326; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116; Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012; Chang CH, 2017, PROC CVPR IEEE, P3777, DOI 10.1109/CVPR.2017.402; Charles J, 2016, PROC CVPR IEEE, P3063, DOI 10.1109/CVPR.2016.334; Chrysos GG, 2018, INT J COMPUT VISION, V126, P198, DOI 10.1007/s11263-017-0999-5; Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126; Chung JS, 2018, INTERSPEECH, P1086; Deng JK, 2019, IEEE T IMAGE PROCESS, V28, P3636, DOI 10.1109/TIP.2019.2899267; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Dong XY, 2018, PROC CVPR IEEE, P360, DOI 10.1109/CVPR.2018.00045; Dong XY, 2018, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.2018.00047; Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256; Farneback G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50; Feng ZH, 2018, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2018.00238; Girdhar R, 2018, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.2018.00044; Guler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762; Hartley R., 2003, MULTIPLE VIEW GEOMET; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Jaderberg M, 2015, ADV NEUR IN, V28; Jafarian Yasamin, 2018, ARXIV180600104; Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868; Joo H, 2019, IEEE T PATTERN ANAL, V41, P190, DOI 10.1109/TPAMI.2017.2782743; Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381; Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241; Khan MH, 2017, IEEE I CONF COMP VIS, P3811, DOI 10.1109/ICCV.2017.409; Kingma D.P, P 3 INT C LEARNING R; Kostinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Kumar A, 2018, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2018.00052; Li Wenbo, 2019, ARXIV190100148; Li YZ, 2016, LECT NOTES COMPUT SC, V9907, P420, DOI 10.1007/978-3-319-46487-9_26; Liu H, 2018, IEEE T PATTERN ANAL, V40, P2546, DOI 10.1109/TPAMI.2017.2734779; Loshchilov I., 2017, P INT C LEARNING REP; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Nie XC, 2019, IEEE T IMAGE PROCESS, V28, P924, DOI 10.1109/TIP.2018.2872628; Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794; Peng X, 2018, INT J COMPUT VISION, V126, P184, DOI 10.1007/s11263-017-0996-8; Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3; Rhodin H, 2018, PROC CVPR IEEE, P8437, DOI 10.1109/CVPR.2018.00880; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Shen HQ, 2014, LECT NOTES COMPUT SC, V8693, P347, DOI 10.1007/978-3-319-10602-1_23; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494; Suwajanakorn S, 2018, ADV NEUR IN, V31; TANG Z, 2018, BRIT MACH VIS C BMVC; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Wu CL, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275101; Wu WY, 2018, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2018.00227; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yang J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P994, DOI 10.1109/ICCVW.2015.131; Yoon JS, 2019, PROC CVPR IEEE, P4596, DOI 10.1109/CVPR.2019.00473; Yu X, 2016, LECT NOTES COMPUT SC, V9909, P52, DOI 10.1007/978-3-319-46454-1_4; Zhang Y., 2018, ARXIV181111251; Zhu ML, 2019, PROC CVPR IEEE, P3481, DOI 10.1109/CVPR.2019.00360; Zhu SZ, 2016, PROC CVPR IEEE, P3409, DOI 10.1109/CVPR.2016.371; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu X, 2007, P INT C MACH LEARN I, P1	69	6	6	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3681	3694		10.1109/TPAMI.2020.2983935	http://dx.doi.org/10.1109/TPAMI.2020.2983935			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32248096	Green Submitted			2022-12-18	WOS:000692232400030
J	Zhang, XB; Chang, JL; Guo, YW; Meng, GF; Xiang, SM; Lin, ZC; Pan, CH				Zhang, Xinbang; Chang, Jianlong; Guo, Yiwen; Meng, Gaofeng; Xiang, Shiming; Lin, Zhouchen; Pan, Chunhong			DATA: Differentiable ArchiTecture Approximation With Distribution Guided Sampling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer architecture; Search problems; Optimization; Task analysis; Bridges; Binary codes; Estimation; Neural architecture search(NAS); ensemble gumbel-softmax; distribution guided sampling	DEEP; NETWORKS	Neural architecture search (NAS) is inherently subject to the gap of architectures during searching and validating. To bridge this gap effectively, we develop Differentiable ArchiTecture Approximation (DATA) with Ensemble Gumbel-Softmax (EGS) estimator and Architecture Distribution Constraint (ADC) to automatically approximate architectures during searching and validating in a differentiable manner. Technically, the EGS estimator consists of a group of Gumbel-Softmax estimators, which is capable of converting probability vectors to binary codes and passing gradients reversely, reducing the estimation bias in a differentiable way. To narrow the distribution gap between sampled architectures and supernet, further, the ADC is introduced to reduce the variance of sampling during searching. Benefiting from such modeling, architecture probabilities and network weights in the NAS model can be jointly optimized with the standard back-propagation, yielding an end-to-end learning mechanism for searching deep neural architectures in an extended search space. Conclusively, in the validating process, a high-performance architecture that approaches to the learned one during searching is readily built. Extensive experiments on various tasks including image classification, few-shot learning, unsupervised clustering, semantic segmentation and language modeling strongly demonstrate that DATA is capable of discovering high-performance architectures while guaranteeing the required efficiency. Code is available at https://github.com/XinbangZhang/DATA-NAS.	[Zhang, Xinbang; Meng, Gaofeng; Xiang, Shiming; Pan, Chunhong] Chinese Acad Sci, Inst Automat, Dept Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Zhang, Xinbang; Meng, Gaofeng; Xiang, Shiming] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China; [Chang, Jianlong] Huawei Cloud & AI, Beijing 100095, Peoples R China; [Chang, Jianlong] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100095, Peoples R China; [Guo, Yiwen] Bytedance AI Lab, Beijing 100190, Peoples R China; [Lin, Zhouchen] Peking Univ, Sch EECS, Key Lab Machine Percept MoE, Beijing 100871, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Huawei Technologies; Chinese Academy of Sciences; Institute of Automation, CAS; Peking University	Chang, JL (corresponding author), Huawei Cloud & AI, Beijing 100095, Peoples R China.; Chang, JL (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100095, Peoples R China.	xinbang.zhang@nlpr.ia.ac.cn; jianlong.chang@huawei.com; guoyiwen.ai@bytedance.com; gfmeng@nlpr.ia.ac.cn; smxiang@nlpr.ia.ac.cn; zlin@pku.edu.cn; chpan@nlpr.ia.ac.cn			Major Project for New Generation of AI [2018AAA0100400]; National Natural Science Foundation of China [91646207, 61976208]; National Key R&D Program of China [2019AAA0105200]; NSF China [61625301, 61731018]; Major Scientific Research Project of Zhejiang Lab [2019KB0AC01, 2019KB0AB02]; Beijing Academy of Artificial Intelligence; Qualcomm	Major Project for New Generation of AI; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key R&D Program of China; NSF China(National Natural Science Foundation of China (NSFC)); Major Scientific Research Project of Zhejiang Lab; Beijing Academy of Artificial Intelligence; Qualcomm	This work was supported by the Major Project forNew Generation of AI under Grant No. 2018AAA0100400, the National Natural Science Foundation of China under Grants 91646207 and 61976208. The work of Z. Lin was supported by National Key R&D Program of China (2019AAA0105200), NSF China (grant no.s 61625301 and 61731018), Major Scientific Research Project of Zhejiang Lab (grant no.s 2019KB0AC01 and 2019KB0AB02), Beijing Academy of Artificial Intelligence, and Qualcomm. The authors would like to thank Lele Yu, Jie Gu, Cheng Da, Yukang Chen, and Jiemin Fang for their invaluable contributions in shaping the early stage of this work.	Adam, 2017, MOBILENETS EFFICIENT; ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; Baker B., 2018, P INT C LEARN REPR W; Battaglia P.W., 2018, INT C LEARN REPR; Bello I., 2017, P INT C LEARN REPR W; Bello I, 2017, PR MACH LEARN RES, V70; Brock A., 2018, ICLR, P1; Cai Han, 2019, INT C LEARN REPR; Casale Francesco Paolo, 2019, PROBABILISTIC NEURAL; Chang J., 2018, P C NEUR INF PROC SY, P11; Chang JL, 2017, IEEE I CONF COMP VIS, P5880, DOI 10.1109/ICCV.2017.626; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen Liang-Chieh, 2017, 170605587 ARXIV; Chen X, 2019, IEEE I CONF COMP VIS, P1294, DOI 10.1109/ICCV.2019.00138; Chen Y., 2019, DETNAS NEURAL ARCHIT, P6638; Courbariaux M., 2015, ADV NEUR IN, P3123; Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186; Elsken T., 2018, P INT C LEARN REPR W; Elsken T, 2019, J MACH LEARN RES, V20; Elsken Thomas, 2019, INT C LEARN REPR; Finn C, 2017, PR MACH LEARN RES, V70; Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720; Grave Edouard, 2017, P INT C LEARN REPR; Gumbel E.J., 1954, STAT THEORY EXTREME, V33; Guo Zichao, 2019, ARXIV190400420; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hsu Chi-Hung, 2018, ABS180610332 CORR; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Inan H., 2017, P INT C LEARN REPR; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jang E., 2017, ICLR; Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342; Kamath P., 2018, ABS180306744 CORR; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Li Liam, 2019, ABS190207638 CORR; Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2; Liu Hanxiao, 2018, ICLR; Liu Hanxiao, 2019, INTERNATIONAL CONFER; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luo Renqian, 2018, NIPS; Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8; Maddison Chris J, 2017, ICLR; Melis Gabor, 2018, P INT C LEARN REPR; Merity S., 2018, P INT C LEARN REPR; Miikkulainen Risto, 2017, ABS170300548 CORR; Pham H, 2018, PR MACH LEARN RES, V80; Ravi S., 2017, INT C LEARN REPR, P12; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Real E, 2017, PR MACH LEARN RES, V70; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Snell J., 2017, ADV NEURAL INFORM PR, P4077; Stanley KO, 2019, NAT MACH INTELL, V1, P24, DOI 10.1038/s42256-018-0006-z; Suganuma M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5369; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2019.00293; Tran Du, 2017, ABS170805038 CORR; Veit A, 2018, LECT NOTES COMPUT SC, V11205, P3, DOI 10.1007/978-3-030-01246-5_1; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vinyals Oriol, 2016, ARXIV160604080, P3630; Wang Y. F., 2019, P INT C LEARN REPR; Xie JY, 2016, PR MACH LEARN RES, V48; Xie Sirui, 2019, INT C LEARN REPR; Yang Z., 2018, P INT C LEARN REPR; Yi X., 2018, ABS180403700 CORR; Ying C, 2019, PR MACH LEARN RES, V97; Yu K., 2020, ICLR 2020; Zhang X., 2018, ARXIV181101567; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	81	6	6	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					2905	2920		10.1109/TPAMI.2020.3020315	http://dx.doi.org/10.1109/TPAMI.2020.3020315			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	32866094				2022-12-18	WOS:000681124300007
J	Casaca, W; Gois, JP; Batagelo, HC; Taubin, G; Nonato, LG				Casaca, Wallace; Gois, Joao Paulo; Batagelo, Harlen Costa; Taubin, Gabriel; Nonato, Luis Gustavo			Laplacian Coordinates: Theory and Methods for Seeded Image Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; Laplace equations; Minimization; Mathematical model; Tools; Electronic mail; Computational modeling; Seeded image segmentation; graph laplacian; laplacian coordinates; energy minimization models	FAST INTERACTIVE IMAGE; WATERSHED FRAMEWORK; FORESTING TRANSFORM; VIDEO SEGMENTATION; ALGORITHMS; DIFFUSION; GRABCUT; GRAPHS	Seeded segmentation methods have gained a lot of attention due to their good performance in fragmenting complex images, easy usability and synergism with graph-based representations. These methods usually rely on sophisticated computational tools whose performance strongly depends on how good the training data reflect a sought image pattern. Moreover, poor adherence to the image contours, lack of unique solution, and high computational cost are other common issues present in most seeded segmentation methods. In this work we introduce Laplacian Coordinates, a quadratic energy minimization framework that tackles the issues above in an effective and mathematically sound manner. The proposed formulation builds upon graph Laplacian operators, quadratic energy functions, and fast minimization schemes to produce highly accurate segmentations. Moreover, the presented energy functions are not prone to local minima, i.e., the solution is guaranteed to be globally optimal, a trait not present in most image segmentation methods. Another key property is that the minimization procedure leads to a constrained sparse linear system of equations, enabling the segmentation of high-resolution images at interactive rates. The effectiveness of Laplacian Coordinates is attested by a comprehensive set of comparisons involving nine state-of-the-art methods and several benchmarks extensively used in the image segmentation literature.	[Casaca, Wallace] Sao Paulo State Univ UNESP, Dept Energy Engn, BR-01049010 Rosana, Brazil; [Gois, Joao Paulo; Batagelo, Harlen Costa] Fed Univ ABC UFABC, Ctr Math Comp & Cognit, BR-09210580 Santo Andr e, Brazil; [Taubin, Gabriel] Brown Univ, Sch Engn, Providence, RI 02912 USA; [Nonato, Luis Gustavo] Univ Sao Paulo, ICMC, BR-13566590 Sao Carlos, Brazil	Universidade Estadual Paulista; Brown University; Universidade de Sao Paulo	Casaca, W (corresponding author), Sao Paulo State Univ UNESP, Dept Energy Engn, BR-01049010 Rosana, Brazil.	wallace.casaca@unesp.br; joao.gois@ufabc.edu.br; harlen.batagelo@ufabc.edu.br; taubin@brown.edu; gnonato@icmc.usp.br	Casaca, Wallace/D-1823-2013; Batagelo, Harlen/G-1318-2014; Gois, Joao Paulo/D-1182-2010	Casaca, Wallace/0000-0002-1073-9939; Batagelo, Harlen/0000-0002-2325-2070; Gois, Joao Paulo/0000-0002-9437-6943; Taubin, Gabriel/0000-0002-1983-7607	Center for Mathematical Sciences Applied to Industry (CeMEAI-FAPESP) [2013/07375-0]; Sao Paulo Research Foundation (FAPESP) [2014/16857-0]; National Council for Scientific and Technological Development (CNPq) [2016/04391-2]; CAPES-Brasil [001]	Center for Mathematical Sciences Applied to Industry (CeMEAI-FAPESP); Sao Paulo Research Foundation (FAPESP)(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP)); National Council for Scientific and Technological Development (CNPq)(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); CAPES-Brasil(Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES))	The authors acknowledge the Center for Mathematical Sciences Applied to Industry (CeMEAI-FAPESP, grant #2013/07375-0), Sao Paulo Research Foundation (FAPESP, grant #2014/16857-0), National Council for Scientific and Technological Development (CNPq, grant #2016/04391-2), and CAPES-Brasil (Finance Code 001) for providing resources that contributed greatly to this research.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Aksoy Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201275; Aksoy Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3002176; Allene C, 2010, IMAGE VISION COMPUT, V28, P1460, DOI 10.1016/j.imavis.2009.06.017; Andrade F, 2015, P IEEE S COMP INT MU, P1; Andrews S, 2010, LECT NOTES COMPUT SC, V6363, P9; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bai JJ, 2014, PROC CVPR IEEE, P392, DOI 10.1109/CVPR.2014.57; Bai X, 2007, IEEE I CONF COMP VIS, P809; Bai X, 2009, INT J COMPUT VISION, V82, P113, DOI 10.1007/s11263-008-0191-z; Bampis CG, 2017, IEEE T IMAGE PROCESS, V26, P35, DOI 10.1109/TIP.2016.2621663; Bampis CG, 2015, IEEE IMAGE PROC, P2265, DOI 10.1109/ICIP.2015.7351205; Bergo FPG, 2007, J MATH IMAGING VIS, V29, P141, DOI 10.1007/s10851-007-0035-4; Bollobas B., 2002, MODERN GRAPH THEORY; Borges VRP, 2018, IEEE ACM T COMPUT BI, V15, P257, DOI 10.1109/TCBB.2016.2615606; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Cardenes R, 2010, IMAGE VISION COMPUT, V28, P307, DOI 10.1016/j.imavis.2009.05.013; Casaca W, 2015, IEEE IMAGE PROC, P862, DOI 10.1109/ICIP.2015.7350922; Casaca W, 2015, LECT NOTES COMPUT SC, V9257, P675, DOI 10.1007/978-3-319-23117-4_58; Casaca W, 2014, PROC CVPR IEEE, P384, DOI 10.1109/CVPR.2014.56; Casaca W, 2013, J MATH IMAGING VIS, V45, P227, DOI 10.1007/s10851-012-0359-6; Casaca Wallace Correa de Oliveira, 2014, THESIS U SAO PAULO, DOI [10.11606/ T.55.2014.tde-24062015-112215, DOI 10.11606/T.55.2014.TDE-24062015-112215]; Cerrone L, 2019, PROC CVPR IEEE, P12551, DOI 10.1109/CVPR.2019.01284; Chen Daniel, 2008, 2008 Digital Image Computing: Techniques and Applications, P39, DOI 10.1109/DICTA.2008.68; Chen Xinjian, 2018, IEEE Rev Biomed Eng, V11, P112, DOI 10.1109/RBME.2018.2798701; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Couprie C, 2011, IEEE T PATTERN ANAL, V33, P1384, DOI 10.1109/TPAMI.2010.200; Couprie C, 2009, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2009.5459284; Cour T, 2005, PROC CVPR IEEE, P1124; Cousty J., 2007, P INT S MATH MORPH, P301; Cousty J, 2009, IEEE T PATTERN ANAL, V31, P1362, DOI 10.1109/TPAMI.2008.173; Cousty J, 2010, IEEE T PATTERN ANAL, V32, P925, DOI 10.1109/TPAMI.2009.71; Criminisi A, 2008, LECT NOTES COMPUT SC, V5302, P99, DOI 10.1007/978-3-540-88682-2_9; Dai LZ, 2017, PATTERN RECOGN, V64, P202, DOI 10.1016/j.patcog.2016.11.009; Delong A., 2011, THESIS U W ONTARIO; Dong C., 2017, J HEALTHCARE ENG, V2017, P1; Elmahmudi A, 2019, SIGNAL IMAGE VIDEO P, V13, P1639, DOI 10.1007/s11760-019-01514-4; Eschweiler D, 2019, I S BIOMED IMAGING, P223, DOI 10.1109/ISBI.2019.8759242; Estrada FJ, 2009, INT J COMPUT VISION, V85, P167, DOI 10.1007/s11263-009-0251-z; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; Faliu Yi, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P1936, DOI 10.1109/ICSAI.2012.6223428; Garcia-Rodriguez J., 2012, ROBOTIC VISION TECHN; Gaura J, 2016, INT J ARTIF INTELL T, V25, DOI 10.1142/S0218213016400029; Grady L., 2008, 2008 IEEE C COMP VIS, P1; Grady L., 2012, IMAGE PROCESSING ANA; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Holusa M, 2017, PATTERN RECOGN LETT, V98, P103, DOI 10.1016/j.patrec.2017.09.003; Huang R, 2016, I S BIOMED IMAGING, P1334, DOI 10.1109/ISBI.2016.7493513; Jankovic V, 2005, TEACH MATH-SERB, V8, P53; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jordan J, 2012, IEEE IMAGE PROC, P1585, DOI 10.1109/ICIP.2012.6467177; Juan O., 2006, P IEEE COMP SOC C CO, V1, P1023, DOI [DOI 10.1109/CVPR.2006.47, 10.1109/CVPR.2006.47]; Karayev S, 2014, PROC CVPR IEEE, P572, DOI 10.1109/CVPR.2014.80; Khattab D, 2014, AIN SHAMS ENG J, V5, P1083, DOI 10.1016/j.asej.2014.04.012; Kim KI, 2015, IEEE I CONF COMP VIS, P2776, DOI 10.1109/ICCV.2015.318; Kim TH, 2008, LECT NOTES COMPUT SC, V5304, P264; Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237; Kim TH, 2010, PROC CVPR IEEE, P3201, DOI 10.1109/CVPR.2010.5540078; Kohli P, 2010, MINIMIZING DYNAMIC H; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Koutis I, 2009, LECT NOTES COMPUT SC, V5875, P1067, DOI 10.1007/978-3-642-10331-5_99; Kowal M, 2020, J DIGIT IMAGING, V33, P231, DOI 10.1007/s10278-019-00200-8; Kruskal J. B., 1956, P AM MATH SOC, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.2307/2033241]; Lee C, 2015, PROC CVPR IEEE, P3837, DOI 10.1109/CVPR.2015.7299008; Lei T, 2019, IEEE T IMAGE PROCESS, V28, P5510, DOI 10.1109/TIP.2019.2920514; Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262; Lerme N, 2014, PATTERN ANAL APPL, V17, P361, DOI 10.1007/s10044-013-0337-7; Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168; Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719; Liang Y, 2019, COMPUT GRAPH FORUM, V38, P23, DOI 10.1111/cgf.13813; Linares OC, 2019, VISUAL COMPUT, V35, P1461, DOI 10.1007/s00371-018-1511-0; Liu B, 2017, COMMUN INF SYST, V17, P65, DOI 10.4310/CIS.2017.v17.n2.a1; Lu YW, 2017, INT J IMAG SYST TECH, V27, P383, DOI 10.1002/ima.22242; Malmberg F, 2017, DISCRETE APPL MATH, V216, P449, DOI 10.1016/j.dam.2016.01.006; Malmberg F, 2009, LECT NOTES COMPUT SC, V5852, P201, DOI 10.1007/978-3-642-10210-3_16; McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008; Meila M., 2005, PROC INT C MACHINE L, P577, DOI DOI 10.1145/1102351.1102424; MERRIS R, 1994, LINEAR ALGEBRA APPL, V198, P143; Miranda PAV, 2014, IEEE T IMAGE PROCESS, V23, P389, DOI 10.1109/TIP.2013.2288867; Monteiro FC, 2008, INT C PATT RECOG, P1586; Najman L, 2017, SIAM J IMAGING SCI, V10, P2275, DOI 10.1137/17M1118580; Nascimento MCV, 2011, EUR J OPER RES, V211, P221, DOI 10.1016/j.ejor.2010.08.012; Ochotorena CN, 2020, IEEE T IMAGE PROCESS, V29, P1397, DOI 10.1109/TIP.2019.2941326; Pelillo M., 2018, ENERGY MINIMIZATION, V1; Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015; Pizenberg M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1734, DOI 10.1145/3123266.3123409; Price BL, 2010, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR.2010.5540079; PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x; Qi YL, 2018, SENS IMAGING, V19, DOI 10.1007/s11220-018-0193-z; Ramazanali H., 2016, P 2016 8 IEEE LATIN, P1; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Ruziska FM, 2017, PHYSICA A, V467, P21, DOI 10.1016/j.physa.2016.09.010; Saglam A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP), P130, DOI 10.1109/ICFSP.2017.8097156; Shao JD, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12967; Sinop AK, 2007, IEEE I CONF COMP VIS, P1016, DOI 10.1109/iccv.2007.4408927; Stein O, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3186564; Summa B, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.13174; Suresh Kurumalla, 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 105), P233, DOI 10.1007/978-981-13-1927-3_24; Suzuki CTN, 2013, IEEE T BIO-MED ENG, V60, P803, DOI 10.1109/TBME.2012.2187204; Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222; Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566; Tutunov R., 2015, DISTRIBUTED SDDM SOL; Unnikrishnan R., 2005, P IEEE COMP SOC C CO, P34, DOI DOI 10.1109/CVPR.2005.390; Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046; Vernaza P, 2017, PROC CVPR IEEE, P2953, DOI 10.1109/CVPR.2017.315; Vezhnevets V., 2005, P 15 INT C COMP GRAP, P150, DOI DOI 10.1016/J.AJ0D0.2004.07.036; Vicente S., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587440; Wang T., 2018, PROC ACM INTERACT MO, V1, P1; Wang T, 2018, INFORM SCIENCES, V460, P103, DOI 10.1016/j.ins.2018.05.040; Wardetzky M., 2007, P 5 EUR S GEOM PROC, P33, DOI [DOI 10.2312/SGP/SGP07/033-037, 10.2312/SGP/SGP07/033-037]; Wolf S, 2017, IEEE I CONF COMP VIS, P2030, DOI 10.1109/ICCV.2017.222; Xu N, 2016, PROC CVPR IEEE, P373, DOI 10.1109/CVPR.2016.47; Xu Ning, 2017, BMVC; Yang WX, 2010, IEEE T IMAGE PROCESS, V19, P2470, DOI 10.1109/TIP.2010.2048611; Yu WR, 2016, IEEE DATA MINING, P589, DOI [10.1109/ICDM.2016.163, 10.1109/ICDM.2016.0070]; Zhang JY, 2010, PROC CVPR IEEE, P2125, DOI 10.1109/CVPR.2010.5539891	119	6	7	5	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2665	2681		10.1109/TPAMI.2020.2974475	http://dx.doi.org/10.1109/TPAMI.2020.2974475			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32078536				2022-12-18	WOS:000670578800011
J	Chen, JY; Yang, X; Jia, QZ; Liao, CY				Chen, Jingyu; Yang, Xin; Jia, Qizeng; Liao, Chunyuan			DENAO: Monocular Depth Estimation Network With Auxiliary Optical Flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional neural network; depth estimation; optical flow	PREDICTION; VERSATILE; SLAM	Estimating depth from multi-view images captured by a localized monocular camera is an essential task in computer vision and robotics. In this study, we demonstrate that learning a convolutional neural network (CNN) for depth estimation with an auxiliary optical flow network and the epipolar geometry constraint can greatly benefit the depth estimation task and in turn yield large improvements in both accuracy and speed. Our architecture is composed of two tightly-coupled encoder-decoder networks, i.e., an optical flow net and a depth net, the core part being a list of exchange blocks between the two nets and an epipolar feature layer in the optical flow net to improve predictions of both depth and optical flow. Our architecture allows to input arbitrary number of multiview images with a linearly growing time cost for optical flow and depth estimation. Experimental result on five public datasets demonstrates that our method, named DENAO, runs at 38.46fps on a single Nvidia TITAN Xp GPU which is 5.15X similar to 142X faster than the state-of-the-art depth estimation methods Meanwhile, our DENAO can concurrently output predictions of both depth and optical flow, and performs on par with or outperforms the state-of-the-art depth estimation methods and optical flow methods.	[Chen, Jingyu; Yang, Xin; Jia, Qizeng] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China; [Liao, Chunyuan] HiScene Informat Technol Co Ltd, Shanghai 200120, Peoples R China	Huazhong University of Science & Technology	Yang, X (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China.	chenjingyu@hust.edu.cn; xinyang2014@hust.edu.cn; u201513333@hust.edu.cn; liaocy@hiscene.com			National Natural Science Foundation of China [61872417]; Fundamental Research Funds for the Central Universities [2019kfyRCPY118]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported by the grant from the National Natural Science Foundation of China (61872417), and the Fundamental Research Funds for the Central Universities (2019kfyRCPY118). Jingyu Chen and Xin Yang contributed equally to this work.	Chang A. X., 2015, ABS151203012 CORR; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Concha A, 2015, IEEE INT C INT ROBOT, P5686, DOI 10.1109/IROS.2015.7354184; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Eigen D, 2014, ADV NEUR IN, V27; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577; Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54; Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214; Fuhrmann S, 2014, EUROGRAPHICS WORKSHO, DOI 10.1016/j.cag.2015.09.003; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Greene WN, 2016, IEEE INT CONF ROBOT, P833, DOI 10.1109/ICRA.2016.7487213; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hua BS, 2016, INT CONF 3D VISION, P92, DOI 10.1109/3DV.2016.18; Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253; Klein George, 2007, P1; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Luo HC, 2019, IEEE T MULTIMEDIA, V21, P470, DOI 10.1109/TMM.2018.2859034; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513; Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729; Rabinovich A., 2018, P EUR C COMP VIS, P167; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Schops T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695; Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596; Ummenhofer B, 2015, IEEE I CONF COMP VIS, P1341, DOI 10.1109/ICCV.2015.158; Wang KX, 2018, INT CONF 3D VISION, P248, DOI 10.1109/3DV.2018.00037; Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458; Xue TL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P510, DOI 10.1145/3123266.3123348; Yang X, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P896, DOI 10.1145/3240508.3240564; Yang X, 2019, IEEE T MULTIMEDIA, V21, P2701, DOI 10.1109/TMM.2019.2912121; Yao Y., 2018, CORR; Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zou Y., 2018, EUR C COMP VIS, P36	45	6	6	5	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2598	2610		10.1109/TPAMI.2020.2977021	http://dx.doi.org/10.1109/TPAMI.2020.2977021			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32142422				2022-12-18	WOS:000670578800006
J	Dahan, E; Keller, Y				Dahan, Eran; Keller, Yosi			A Unified Approach to Kinship Verification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; Faces; Training; Measurement; Support vector machines; Generative adversarial networks; Gallium nitride; Kinship verification; face recognition; face biometrics; convolutional neural networks; multi-task learning	FACE	In this work, we propose a deep learning-based approach for kin verification using a unified multi-task learning scheme where all kinship classes are jointly learned. This allows us to better utilize small training sets that are typical of kin verification. We introduce a novel approach for fusing the embeddings of kin images, to avoid overfitting, which is a common issue in training such networks. An adaptive sampling scheme is derived for the training set images, to resolve the inherent imbalance in kin verification datasets. A thorough ablation study exemplifies the effectivity of our approach, which is experimentally shown to outperform contemporary state-of-the-art kin verification results when applied to the Families In the Wild, FG2018, and FG2020 datasets.	[Dahan, Eran; Keller, Yosi] Bar Ilan Univ, Fac Engn, IL-5290002 Ramat Gan, Israel	Bar Ilan University	Keller, Y (corresponding author), Bar Ilan Univ, Fac Engn, IL-5290002 Ramat Gan, Israel.	eran.dahan.ee@gmail.com; yosi.keller@gmail.com						Dahan E., 2017, P WORKSHOP RECOGNIZI, P31; Dandekar AR, 2014, 2014 INTERNATIONAL CONFERENCE ON POWER, AUTOMATION AND COMMUNICATION (INPAC), P157, DOI 10.1109/INPAC.2014.6981146; Dawson M, 2019, LECT NOTES COMPUT SC, V11363, P654, DOI 10.1007/978-3-030-20893-6_41; Duan Q., 2017, P 2017 WORKSH REC FA, P21; Duan QY, 2017, IEEE INT CONF COMP V, P1590, DOI 10.1109/ICCVW.2017.187; Fang RG, 2013, IEEE IMAGE PROC, P2983, DOI 10.1109/ICIP.2013.6738614; Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590; Fu Yun, 2016, P 24 ACM INT C MULTI, DOI DOI 10.1145/2964284.2967219; Gao P., ARXIV191107014, V2019; Kohli N, 2019, IEEE T IMAGE PROCESS, V28, P1329, DOI 10.1109/TIP.2018.2840880; Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811; Lei Z., 2014, LEARNING FACE REPRES; Li XS, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P1, DOI 10.1109/ICIICII.2015.88; Li YY, 2017, ADV SOC SCI EDUC HUM, V159, P13; Lilei Zheng, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163085; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713; Lopez MB, 2016, IEEE T PATTERN ANAL, V38, P2342, DOI 10.1109/TPAMI.2016.2522416; Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505; Mahpod S, 2018, COMPUT VIS IMAGE UND, V167, P28, DOI 10.1016/j.cviu.2017.12.003; Mignon A., 2012, P AS C COMP VIS, P14; Ozkan S, 2018, IEEE IMAGE PROC, P2142, DOI 10.1109/ICIP.2018.8451305; Puthenputhussery A, 2016, IEEE IMAGE PROC, P2921, DOI 10.1109/ICIP.2016.7532894; Qin XQ, 2015, IEEE T MULTIMEDIA, V17, P1855, DOI 10.1109/TMM.2015.2461462; Robinson J. P., 2017, 12 IEEE AMFG RFIW WO, P5; Robinson J. P., 2020, IEEE COMPUT SOC, P877, DOI [10.1109/FG47880.2020.00138, DOI 10.1109/FG47880.2020.00138]; Robinson J. P., 2020, ARXIV200714509; Robinson JP, 2018, IEEE T PATTERN ANAL, V40, P2624, DOI 10.1109/TPAMI.2018.2826549; Robinson JP, 2020, ARXIV200616033; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Wang S., 2016, IJCAI, P2125; Wang SY, 2019, IEEE T PATTERN ANAL, V41, P2783, DOI 10.1109/TPAMI.2018.2861871; Wang SY, 2017, IEEE INT CONF AUTOMA, P216, DOI 10.1109/FG.2017.35; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wu Y, 2018, IEEE INT CONF AUTOMA, P143, DOI 10.1109/FG.2018.00030; Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436; Xu M., 2016, IEEE ACCESS, V4, p10 280; Xu M, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/4072323; Yan HB, 2017, IMAGE VISION COMPUT, V60, P91, DOI 10.1016/j.imavis.2016.08.009; Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757; Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342; Zhou XZ, 2016, INFORM FUSION, V32, P40, DOI 10.1016/j.inffus.2015.08.006	42	6	6	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2851	2857		10.1109/TPAMI.2020.3036993	http://dx.doi.org/10.1109/TPAMI.2020.3036993			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	33175677	Green Submitted			2022-12-18	WOS:000670578800024
J	Yang, SB; Li, GB; Yu, YZ				Yang, Sibei; Li, Guanbin; Yu, Yizhou			Relationship-Embedded Representation Learning for Grounding Referring Expressions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	32nd IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 16-20, 2019	Long Beach, CA	IEEE, CVF, IEEE Comp Soc		Visualization; Semantics; Grounding; Proposals; Data mining; Logic gates; Feature extraction; Referring expressions; cross-modal relationship extractor; gated graph convolutional network		Grounding referring expressions in images aims to locate the object instance in an image described by a referring expression. It involves a joint understanding of natural language and image content, and is essential for a range of visual tasks related to human-computer interaction. As a language-to-vision matching task, the core of this problem is to not only extract all the necessary information (i.e., objects and the relationships among them) in both the image and referring expression, but also make full use of context information to align cross-modal semantic concepts in the extracted information. Unfortunately, existing work on grounding referring expressions fails to accurately extract multi-order relationships from the referring expression and associate them with the objects and their related contexts in the image. In this paper, we propose a cross-modal relationship extractor (CMRE) to adaptively highlight objects and relationships (spatial and semantic relations) related to the given expression with a cross-modal attention mechanism, and represent the extracted information as a language-guided visual relation graph. In addition, we propose a Gated Graph Convolutional Network (GGCN) to compute multimodal semantic contexts by fusing information from different modes and propagating multimodal information in the structured relation graph. Experimental results on three common benchmark datasets show that our Cross-Modal Relationship Inference Network, which consists of CMRE and GGCN, significantly surpasses all existing state-of-the-art methods.	[Yang, Sibei; Yu, Yizhou] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; [Li, Guanbin] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China; [Yu, Yizhou] Deepwise AI Lab, Beijing 100085, Peoples R China	University of Hong Kong; Sun Yat Sen University	Yu, YZ (corresponding author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.; Li, GB (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.	sbyang9@hku.hk; liguanbin@mail.sysu.edu.cn; yizhouy@acm.org	/F-3345-2010	/0000-0002-0470-5548; Li, Guanbin/0000-0002-4805-0926	National Key Research and Development Program of China [2019YFC0118100]; National Natural Science Foundation of China [61976250, 61702565]; Science and Technology Program of Guangdong Province [2017B010116001]; Hong Kong PhD Fellowship	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science and Technology Program of Guangdong Province; Hong Kong PhD Fellowship	This work was supported in part by the National Key Research and Development Program of China under Grant No. 2019YFC0118100, the National Natural Science Foundation of China under Grant No. 61976250 and No. 61702565, the Science and Technology Program of Guangdong Province under Grant No. 2017B010116001 and the Hong Kong PhD Fellowship. This paper was presented at the IEEE Conference CVPR, 2019 [1].	Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Battaglia Peter W, 2018, ARXIV 180601261; Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314; Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209; Cao QX, 2018, PROC CVPR IEEE, P7249, DOI 10.1109/CVPR.2018.00757; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chung Junyoung, 2014, ARXIV PREPRINT ARXIV; Dai B., 2018, P 32 INT C NEUR INF, P656; Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352; Deng CR, 2018, PROC CVPR IEEE, P7746, DOI 10.1109/CVPR.2018.00808; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Fidler S., 2017, ADV NEURAL INFORM PR, P5068; Fukui Akira, 2016, ARXIV160601847; Gao H., 2015, ADV NEURAL INFORM PR, V28, P2296, DOI DOI 10.1145/2733373.2807418; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu RH, 2017, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2017.470; Hudson D. A., 2019, ADV NEURAL INFORM PR, P5901; Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573; Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, P787, DOI DOI 10.3115/V1/D14-1086; Kingma D.P, P 3 INT C LEARNING R; Kipf T. N., 2017, 5 INT C LEARN REPR; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162; Li GB, 2019, IEEE T IMAGE PROCESS, V28, P1591, DOI 10.1109/TIP.2018.2878956; Li GB, 2018, IEEE T NEUR NET LEAR, V29, P6038, DOI 10.1109/TNNLS.2018.2817540; Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu JY, 2017, IEEE I CONF COMP VIS, P4866, DOI 10.1109/ICCV.2017.520; Liu Y, 2018, PROC CVPR IEEE, P6985, DOI 10.1109/CVPR.2018.00730; Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51; Lu JS, 2016, ADV NEUR IN, V29; Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345; Luo RT, 2017, PROC CVPR IEEE, P3125, DOI 10.1109/CVPR.2017.333; Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9; Marino K, 2017, PROC CVPR IEEE, P20, DOI 10.1109/CVPR.2017.10; Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48; Norcliffe-Brown W., 2018, ADV NEURAL INFORM PR, P8334; Ren J, 2017, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2017.87; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49; Santoro A., 2017, ADV NEURAL INFORM PR, P4967; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Schwartz I., 2017, ADV NEURAL INF PROCE, P3664; Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499; Teney D, 2017, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2017.344; Velickovic P., 2018, INT C LEARN REPR; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717; Wu C., 2018, ADV NEURAL INFORM PR, P273; Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309; Wu X, 2018, PROC CVPR IEEE, P6829, DOI 10.1109/CVPR.2018.00714; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41; Yang SB, 2019, PROC CVPR IEEE, P4140, DOI 10.1109/CVPR.2019.00427; Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42; Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142; Yu LC, 2017, PROC CVPR IEEE, P3521, DOI 10.1109/CVPR.2017.375; Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5; Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202; Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611; Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747; Zhang HW, 2018, PROC CVPR IEEE, P4158, DOI 10.1109/CVPR.2018.00437; Zhang YD, 2019, IEEE WINT CONF APPL, P349, DOI 10.1109/WACV.2019.00043; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540	73	6	6	5	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2765	2779		10.1109/TPAMI.2020.2973983	http://dx.doi.org/10.1109/TPAMI.2020.2973983			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	TF2YV	32078531	Green Submitted			2022-12-18	WOS:000670578800018
J	Kalayeh, MM; Shah, M				Kalayeh, Mahdi M.; Shah, Mubarak			On Symbiosis of Attribute Prediction and Semantic Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Attribute prediction; semantic segmentation; semantic gating; facial attributes; person attributes	OBJECTS; DETECT	Attributes are semantically meaningful characteristics whose applicability widely crosses category boundaries. They are particularly important in describing and recognizing concepts for which no explicit training example is given, e.g., zero-shot learning. Additionally, since attributes are human describable, they can be used for efficient human-computer interaction. In this article, we propose to employ semantic segmentation to improve person-related attribute prediction. The core idea lies in the fact that many attributes describe local properties. In other words, the probability of an attribute to appear in an image is far from being uniform in the spatial domain. We build our attribute prediction model jointly with a deep semantic segmentation network. This harnesses the localization cues learned by the semantic segmentation to guide the attention of the attribute prediction to the regions where different attributes naturally show up. As a result of this approach, in addition to prediction, we are able to localize the attributes despite merely having access to image-level labels (weak supervision) during training. We first propose semantic segmentation-based pooling and gating, respectively denoted as SSP and SSG. In the former, the estimated segmentation masks are used to pool the final activations of the attribute prediction network, from multiple semantically homogeneous regions. This is in contrast to global average pooling which is agnostic with respect to where in the spatial domain activations occur. In SSG, the same idea is applied to the intermediate layers of the network. Specifically, we create multiple copies of the internal activations. In each copy, only values that fall within a certain semantic region are preserved while outside of that, activations are suppressed. This mechanism allows us to prevent pooling operation from blending activations that are associated with semantically different regions. SSP and SSG, while effective, impose heavy memory utilization since each channel of the activations is pooled/gated with all the semantic segmentation masks. To circumvent this, we propose Symbiotic Augmentation (SA), where we learn only one mask per activation channel. SA allows the model to either pick one, or combine (weighted superposition) multiple semantic maps, in order to generate the proper mask for each channel. SA simultaneously applies the same mechanism to the reverse problem by leveraging output logits of attribute prediction to guide the semantic segmentation task. We evaluate our proposed methods for facial attributes on CelebA and LFWA datasets, while benchmarking WIDER Attribute and Berkeley Attributes of People for whole body attributes. Our proposed methods achieve superior results compared to the previous works. Furthermore, we show that in the reverse problem, semantic face parsing significantly improves when its associated task is jointly learned, through our proposed Symbiotic Augmentation (SA), with facial attribute prediction. We confirm that when few training instances are available, indeed image-level facial attribute labels can serve as an effective source of weak supervision to improve semantic face parsing. That reaffirms the need to jointly model these two interconnected tasks.	[Kalayeh, Mahdi M.; Shah, Mubarak] Univ Cent Florida, Comp Sci, Orlando, FL 32816 USA; [Kalayeh, Mahdi M.; Shah, Mubarak] Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida; State University System of Florida; University of Central Florida		mahdi@eecs.ucf.edu; shah@crcv.ucf.edu		Shah, Mubarak/0000-0001-6172-5572	National Science Foundation [174143]; Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA RD [D17PC00345]	National Science Foundation(National Science Foundation (NSF)); Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA RD	This work was supported by the National Science Foundation under Grant No. 174143 and the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA R&D Contract No. D17PC00345. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of theODNI, IARPA, or theU.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. This work updates and extends our previous work [1].	[Anonymous], 2013, COMPUT SCI; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413; CHEN H, 2012, P 12 EUR C COMP VIS, P609, DOI DOI 10.1007/978-3-642-33712-3-44; Chen L.C., 2015, P INT C LEARN REPR, P357; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Ciresan Dan, 2012, ADV NEURAL INFORM PR, P2843, DOI DOI 10.5555/2999325.2999452; Dong J, 2013, IEEE I CONF COMP VIS, P3408, DOI 10.1109/ICCV.2013.423; Dong Q, 2017, IEEE I CONF COMP VIS, P1869, DOI 10.1109/ICCV.2017.205; Farhadi A, 2010, PROC CVPR IEEE, P2352, DOI 10.1109/CVPR.2010.5539924; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Gan C, 2016, PROC CVPR IEEE, P87, DOI 10.1109/CVPR.2016.17; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gkioxari G, 2015, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2015.284; Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Hwang SJ, 2011, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2011.5995543; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jayaraman D, 2014, PROC CVPR IEEE, P1629, DOI 10.1109/CVPR.2014.211; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Kae A, 2013, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2013.263; Kalayeh MM, 2017, PROC CVPR IEEE, P4227, DOI 10.1109/CVPR.2017.450; Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; LE V, 2012, P EUR C COMP VIS, P679; Li JS, 2018, IEEE T IMAGE PROCESS, V27, P4651, DOI 10.1109/TIP.2018.2839521; Li YN, 2016, LECT NOTES COMPUT SC, V9910, P684, DOI 10.1007/978-3-319-46466-4_41; Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8; Liang XD, 2015, IEEE I CONF COMP VIS, P1386, DOI 10.1109/ICCV.2015.163; Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360; Lin  Guosheng, 2016, ARXIV161106612; Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748; Liu S, 2015, IEEE T MULTIMEDIA, V17, P1347, DOI 10.1109/TMM.2015.2443559; Liu SF, 2015, PROC CVPR IEEE, P3451, DOI 10.1109/CVPR.2015.7298967; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Parikh D, 2011, PROC CVPR IEEE, P1681, DOI 10.1109/CVPR.2011.5995451; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sarafianos N, 2018, LECT NOTES COMPUT SC, V11215, P708, DOI 10.1007/978-3-030-01252-6_42; Sarfraz M., 2017, BMVC; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Singh KK, 2016, LECT NOTES COMPUT SC, V9910, P753, DOI 10.1007/978-3-319-46466-4_45; Smith BM, 2013, PROC CVPR IEEE, P3484, DOI 10.1109/CVPR.2013.447; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Vedaldi A, 2014, PROC CVPR IEEE, P3622, DOI 10.1109/CVPR.2014.463; Voigtlaender P., 2019, PROC CVPR IEEE; Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251; Wang P, 2015, IEEE I CONF COMP VIS, P1573, DOI 10.1109/ICCV.2015.184; Wang YJ, 2010, PRODUCTION GRIDS IN ASIA: APPLICATIONS, DEVELOPMENTS AND GLOBAL TIES, P155, DOI 10.1007/978-1-4419-0046-3_13; Xia F., 2016, ECCV, P648; Xiong YJ, 2015, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2015.7298768; Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437; Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101; Yang W, 2014, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR.2014.407; Yu F., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1006/JMBI.1990.9999; Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212; Zhong Y, 2016, IEEE IMAGE PROC, P3239, DOI 10.1109/ICIP.2016.7532958; Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219	73	6	6	2	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1620	1635		10.1109/TPAMI.2019.2956039	http://dx.doi.org/10.1109/TPAMI.2019.2956039			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31794386	Green Submitted			2022-12-18	WOS:000637533800010
J	Liu, HM; Wang, RP; Shan, SG; Chen, XL				Liu, Haomiao; Wang, Ruiping; Shan, Shiguang; Chen, Xilin			What is a Tabby? Interpretable Model Decisions by Learning Attribute-Based Classification Criteria	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cats; Prototypes; Visualization; Task analysis; Streaming media; Predictive models; Scalability; Interpretable model; visual attributes; convolutional neural network; classification criteria		State-of-the-art classification models are usually considered as black boxes since their decision processes are implicit to humans. On the contrary, human experts classify objects according to a set of explicit hierarchical criteria. For example, "tabby is a domestic cat with stripes, dots, or lines", where tabby is defined by combining its superordinate category (domestic cat) and some certain attributes (e.g., has stripes). Inspired by this mechanism, we propose an interpretable Hierarchical Criteria Network (HCN) by additionally learning such criteria. To achieve this goal, images and semantic entities (e.g., taxonomies and attributes) are embedded into a common space, where each category can be represented by the linear combination of its superordinate category and a set of learned discriminative attributes. Specifically, a two-stream convolutional neural network (CNN) is elaborately devised, which embeds images and taxonomies with the two streams respectively. The model is trained by minimizing the prediction error of hierarchy labels on both streams. Extensive experiments on two widely studied datasets (CIFAR-100 and ILSVRC) demonstrate that HCN can learn meaningful attributes as well as reasonable and interpretable classification criteria. Therefore, the proposed method enables further human feedback for model correction as an additional benefit.	[Liu, Haomiao] Huawei EI Innovat Lab, Beijing 100085, Peoples R China; [Wang, Ruiping; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, CAS, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Computing Technology, CAS	Chen, XL (corresponding author), Chinese Acad Sci, Inst Comp Technol, CAS, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.	haomiaoliu@vipl.ict.ac.cn; wangruiping@ict.ac.cn; sgshan@ict.ac.cn; xlchen@ict.ac.cn	Chen, Xilin/I-4153-2014	Chen, Xilin/0000-0003-3024-4404; Shan, Shiguang/0000-0002-8348-392X	973 Program [2015CB351802]; Natural Science Foundation of China [61390511, 61772500]; Frontier Science Key Research Project CAS [QYZDJ-SSW-JSC009]; Youth Innovation Promotion Association CAS [2015085]	973 Program(National Basic Research Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Frontier Science Key Research Project CAS; Youth Innovation Promotion Association CAS	This work was done at the Institute of Computing Technology, Chinese Academy of Sciences, where Haomiao Liu pursued the PhD degree. This work is partially supported by 973 Program under contract No. 2015CB351802, Natural Science Foundation of China under contractsNos. 61390511, 61772500, Frontier Science Key Research Project CAS No. QYZDJ-SSW-JSC009, and Youth Innovation Promotion Association CAS No. 2015085.	Ahmed K, 2016, LECT NOTES COMPUT SC, V9911, P516, DOI 10.1007/978-3-319-46478-7_32; Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986; Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354; Chang L, 2017, CELL, V169, P1013, DOI 10.1016/j.cell.2017.05.011; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng Jia, 2014, EUR C COMP VIS, P48, DOI DOI 10.1007/978-3-319-10590-1_4; Ding N, 2015, IEEE I CONF COMP VIS, P1161, DOI 10.1109/ICCV.2015.138; Dosovitskiy A, 2016, PROC CVPR IEEE, P4829, DOI 10.1109/CVPR.2016.522; Dosovitskiy Alexey, 2016, NEURIPS; Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089; Escorcia V, 2015, PROC CVPR IEEE, P1256, DOI 10.1109/CVPR.2015.7298730; Farhadi A, 2010, PROC CVPR IEEE, P2352, DOI 10.1109/CVPR.2010.5539924; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Fong R, 2018, PROC CVPR IEEE, P8730, DOI 10.1109/CVPR.2018.00910; Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371; Glorot X., 2010, PROC MACH LEARN RES, P249; Goo W, 2016, LECT NOTES COMPUT SC, V9906, P86, DOI 10.1007/978-3-319-46475-6_6; Griffin G, 2008, PROC CVPR IEEE, P533; Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013; He K., 2016, PROC IEEE C COMPUTER, P770, DOI DOI 10.1109/CVPR.2016.90; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang C, 2016, PROC CVPR IEEE, P5175, DOI 10.1109/CVPR.2016.559; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Hwang SJ, 2014, ADV NEUR IN, V27; Jia D, 2012, PROC CVPR IEEE, P3450, DOI 10.1109/CVPR.2012.6248086; Jia Y., 2014, P 22 ACM INT C MULT, P675; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Krizhevsky Alex., 2009, LEARNING MULTIPLE LA, P6; LAMPERT CH, 2009, CVPR, P951, DOI DOI 10.1109/CVPR.2009.5206594; Lapuschkin S, 2016, PROC CVPR IEEE, P2912, DOI 10.1109/CVPR.2016.318; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Li O, 2018, AAAI CONF ARTIF INTE, P3530; Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8; Liu HM, 2017, PROC CVPR IEEE, P6259, DOI 10.1109/CVPR.2017.663; Liu WY, 2016, PR MACH LEARN RES, V48; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Maas A.L., 2013, P ICML, V30, P3, DOI DOI 10.1016/0010-0277(84)90022-2; Marszalek M, 2008, LECT NOTES COMPUT SC, V5305, P479, DOI 10.1007/978-3-540-88693-8_35; Mascharka D, 2018, PROC CVPR IEEE, P4942, DOI 10.1109/CVPR.2018.00519; Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282; Nair V., 2010, ICML, P807; Ordonez V, 2013, IEEE I CONF COMP VIS, P2768, DOI 10.1109/ICCV.2013.344; Ouyang WL, 2015, IEEE I CONF COMP VIS, P1895, DOI 10.1109/ICCV.2015.220; Patterson G, 2016, LECT NOTES COMPUT SC, V9910, P85, DOI 10.1007/978-3-319-46466-4_6; Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z; Ranjan R., 2017, ARXIV PREPRINT ARXIV; Rastegari M, 2012, LECT NOTES COMPUT SC, V7577, P876, DOI 10.1007/978-3-642-33783-3_63; Rosch E., 1999, CONCEPTS CORE READIN, P189, DOI [DOI 10.1016/B978-1-4832-1446-7.50028-5, 10.1016/b978-l-4832-1446-7.50028-5]; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Selvaraju RR, 2018, LECT NOTES COMPUT SC, V11217, P540, DOI 10.1007/978-3-030-01261-8_32; Simonyan K., 2014, WORKSH INT C LEARN R, P1; Srivastava Nitish, 2013, NIPS; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vittayakorn S, 2016, LECT NOTES COMPUT SC, V9908, P252, DOI 10.1007/978-3-319-46493-0_16; Wah C., 2011, TECH REP; Wei Z., 2016, DEEPLY FUSED NETS; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Yan ZC, 2015, IEEE I CONF COMP VIS, P2740, DOI 10.1109/ICCV.2015.314; Yosinski J., 2015, ICML DEEP LEARN WORK; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang QS, 2018, PROC CVPR IEEE, P8827, DOI 10.1109/CVPR.2018.00920; Zhao B., 2011, P 24 INT C NEUR INF, P1251; Zhou BL, 2018, LECT NOTES COMPUT SC, V11212, P122, DOI 10.1007/978-3-030-01237-3_8; Zintgraf Luisa M., 2017, P ICLR; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	68	6	6	4	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1791	1807		10.1109/TPAMI.2019.2954501	http://dx.doi.org/10.1109/TPAMI.2019.2954501			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31751226				2022-12-18	WOS:000637533800022
J	Pan, JJ; Gillis, N				Pan, Junjun; Gillis, Nicolas			Generalized Separable Nonnegative Matrix Factorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonnegative matrix factorization; separability; algorithms	ALGORITHM; MODEL; IDENTIFIABILITY; CONVERGENCE; FRAMEWORK; SIGNAL	Nonnegative matrix factorization (NMF) is a linear dimensionality technique for nonnegative data with applications such as image analysis, text mining, audio source separation, and hyperspectral unmixing. Given a data matrix M and a factorization rank r, NMF looks for a nonnegative matrix W with r columns and a nonnegative matrix H with r rows such that M approximate to WH. NMF is NP-hard to solve in general. However, it can be computed efficiently under the separability assumption which requires that the basis vectors appear as data points, that is, that there exists an index set K such that W = M(:,K). In this article, we generalize the separability assumption. We only require that for each rank-one factor W(:, k)II(k, :) for k = 1,2,...,r, either W(:, k) = M(:, j) for some j or H(k, :) = M(i, :) for some i. We refer to the corresponding problem as generalized separable NMF (GS-NMF). We discuss some properties of GS-NMF and propose a convex optimization model which we solve using a fast gradient method. We also propose a heuristic algorithm inspired by the successive projection algorithm. To verify the effectiveness of our methods, we compare them with several state-of-the-art separable NMF and standard NMF algorithms on synthetic, document and image data sets.	[Pan, Junjun; Gillis, Nicolas] Univ Mons, Fac Polytech, Dept Math & Operat Res, Rue Houdain 9, B-7000 Mons, Belgium	University of Mons	Gillis, N (corresponding author), Univ Mons, Fac Polytech, Dept Math & Operat Res, Rue Houdain 9, B-7000 Mons, Belgium.	junjun.pan@umons.ac.be; nicolas.gillis@umons.ac.be		Gillis, Nicolas/0000-0001-6423-6897	Fonds de la Recherche Scientifique-FNRS under EOS Project [O005318F-RG47]; Fonds Wetenschappelijk Onderzoek-Vlanderen (FWO) under EOS Project [O005318F-RG47]; European Research Council (ERC) [679515]	Fonds de la Recherche Scientifique-FNRS under EOS Project(Fonds de la Recherche Scientifique - FNRS); Fonds Wetenschappelijk Onderzoek-Vlanderen (FWO) under EOS Project(FWO); European Research Council (ERC)(European Research Council (ERC)European Commission)	The authors would like to thank the anonymous reviewers for their insightful comments which helped us improve the paper significantly. This work was supported by the Fonds de la Recherche Scientifique-FNRS and the Fonds Wetenschappelijk Onderzoek-Vlanderen (FWO) under EOS Project no O005318F-RG47, and by the European Research Council (ERC starting grant no 679515).	Araujo MCU, 2001, CHEMOMETR INTELL LAB, V57, P65, DOI 10.1016/S0169-7439(01)00119-8; Arora S, 2016, SIAM J COMPUT, V45, P1582, DOI 10.1137/130913869; Arora S, 2012, STOC'12: PROCEEDINGS OF THE 2012 ACM SYMPOSIUM ON THEORY OF COMPUTING, P145; Cai D., 2008, P 17 ACM C INF KNOWL, P911; Chan TH, 2008, IEEE T SIGNAL PROCES, V56, P5120, DOI 10.1109/TSP.2008.928937; Chan TH, 2011, IEEE T GEOSCI REMOTE, V49, P4177, DOI 10.1109/TGRS.2011.2141672; Dikmen O, 2015, IEEE T PATTERN ANAL, V37, P1442, DOI 10.1109/TPAMI.2014.2366144; Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852; Esser E, 2012, IEEE T IMAGE PROCESS, V21, P3239, DOI 10.1109/TIP.2012.2190081; Fevotte C, 2009, NEURAL COMPUT, V21, P793, DOI 10.1162/neco.2008.04-08-771; Fu X, 2019, IEEE SIGNAL PROC MAG, V36, P59, DOI 10.1109/MSP.2018.2877582; Fu X, 2018, IEEE SIGNAL PROC LET, V25, P328, DOI 10.1109/LSP.2018.2789405; Fu X, 2016, IEEE T SIGNAL PROCES, V64, P6254, DOI 10.1109/TSP.2016.2602800; Gillis N, 2014, REGULARIZATION OPTIM, V12, P257; Gillis N, 2018, IEEE T IMAGE PROCESS, V27, P24, DOI 10.1109/TIP.2017.2753400; Gillis N, 2015, IEEE T GEOSCI REMOTE, V53, P2066, DOI 10.1109/TGRS.2014.2352857; Gillis N, 2014, SIAM J IMAGING SCI, V7, P1420, DOI 10.1137/130946782; Gillis N, 2014, J MACH LEARN RES, V15, P1249; Gillis N, 2014, IEEE T PATTERN ANAL, V36, P698, DOI 10.1109/TPAMI.2013.226; Gillis N, 2013, SIAM J MATRIX ANAL A, V34, P1189, DOI 10.1137/120900629; Goreinov SA, 1997, MATH NOTES+, V62, P515, DOI 10.1007/BF02358985; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Huang KJ, 2014, IEEE T SIGNAL PROCES, V62, P211, DOI 10.1109/TSP.2013.2285514; Knight PA, 2008, SIAM J MATRIX ANAL A, V30, P261, DOI 10.1137/060659624; Kumar A., 2013, P INT C MACH LEARN, P231; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Leplat V, 2019, INT CONF ACOUST SPEE, P3402, DOI 10.1109/ICASSP.2019.8682280; Lin CH, 2015, IEEE T GEOSCI REMOTE, V53, P5530, DOI 10.1109/TGRS.2015.2424719; Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422; Ma WK, 2014, IEEE SIGNAL PROC MAG, V31, P67, DOI 10.1109/MSP.2013.2279731; Mahoney MW, 2009, P NATL ACAD SCI USA, V106, P697, DOI [10.1073/pnas.0803205105, 10.1073/pnas.0803205106]; Miao LD, 2007, IEEE T GEOSCI REMOTE, V45, P765, DOI 10.1109/TGRS.2006.888466; Mikhalev A, 2018, LINEAR ALGEBRA APPL, V538, P187, DOI 10.1016/j.laa.2017.10.014; Nascimento JMP, 2005, IEEE T GEOSCI REMOTE, V43, P898, DOI 10.1109/TGRS.2005.844293; NESTEROV IE, 1983, DOKL AKAD NAUK SSSR+, V269, P543; Olshen RA, 2010, ANN STAT, V38, P1638, DOI 10.1214/09-AOS743; Recht B., 2012, ADV NEURAL INFORM PR, V25, P1214; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Ren H, 2003, IEEE T AERO ELEC SYS, V39, P1232, DOI 10.1109/TAES.2003.1261124; Tan VYF, 2013, IEEE T PATTERN ANAL, V35, P1592, DOI 10.1109/TPAMI.2012.240; THOMAS LB, 1974, SIAM REV, V16, P393, DOI 10.1137/1016064; Toh KC, 1999, OPTIM METHOD SOFTW, V11-2, P545, DOI 10.1080/10556789908805762; Zhong S, 2005, KNOWL INF SYST, V8, P374, DOI 10.1007/s10115-004-0194-1	48	6	6	5	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1546	1561		10.1109/TPAMI.2019.2956046	http://dx.doi.org/10.1109/TPAMI.2019.2956046			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31794387	Green Submitted			2022-12-18	WOS:000637533800006
J	Zamir, SW; Vazquez-Corral, J; Bertalmio, M				Zamir, Syed Waqas; Vazquez-Corral, Javier; Bertalmio, Marcelo			Vision Models for Wide Color Gamut Imaging in Cinema	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image color analysis; Motion pictures; Computational modeling; Standards; Germanium; Measurement; TV; Gamut mapping algorithms; wide gamut imaging; color reproduction; vision models for color and contrast; gamut mapping for cinema		Gamut mapping is the problem of transforming the colors of image or video content so as to fully exploit the color palette of the display device where the content will be shown, while preserving the artistic intent of the original content's creator. In particular, in the cinema industry, the rapid advancement in display technologies has created a pressing need to develop automatic and fast gamut mapping algorithms. In this article, we propose a novel framework that is based on vision science models, performs both gamut reduction and gamut extension, is of low computational complexity, produces results that are free from artifacts and outperforms state-of-the-art methods according to psychophysical tests. Our experiments also highlight the limitations of existing objective metrics for the gamut mapping problem.	[Zamir, Syed Waqas] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Vazquez-Corral, Javier; Bertalmio, Marcelo] Univ Pompeu Fabra, Barcelona 08002, Spain	Pompeu Fabra University	Vazquez-Corral, J (corresponding author), Univ Pompeu Fabra, Barcelona 08002, Spain.	waqas.zamir@inceptioniai.org; javier.vazquez@upf.edu; marcelo.bertalmio@upf.edu	Vazquez-Corral, Javier/A-5655-2011; Zamir, Syed Waqas/D-6820-2014	Vazquez-Corral, Javier/0000-0003-0414-7096; Zamir, Syed Waqas/0000-0002-7198-0187	European Union's Horizon 2020 research and innovation programme [761544, 780470]; Spanish government [PGC2018-099651-B-I00, IJCI-2014-19516]; FEDER Fund [PGC2018-099651-B-I00]	European Union's Horizon 2020 research and innovation programme; Spanish government(Spanish GovernmentEuropean Commission); FEDER Fund	The authors are grateful to all the participants of the psychophysical experiments. Special thanks to Dirk Maes from Barco N.V. and to Stephane Cattan from Deluxe-Spain for their invaluable help and unwavering support. This work has received funding from the European Union's Horizon 2020 research and innovation programme under Grant agreement number 761544 (project HDR4EU) and under Grant agreement number 780470 (project SAUCE), and by the Spanish government and FEDER Fund, grant ref. PGC2018-099651-B-I00 (MCIU/AEI/FEDER, UE). The work of J. Vazquez-Corral was supported by the Spanish government under Grant IJCI-2014-19516.	Alsam A, 2012, LECT NOTES COMPUT SC, V7431, P556, DOI 10.1007/978-3-642-33179-4_53; Anderson H, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P188, DOI 10.1109/ICIAPW.2007.27; Andriani S, 2013, IEEE IMAGE PROC, P2289, DOI 10.1109/ICIP.2013.6738472; [Anonymous], 2012, BT500 13 ITU R RECOM; Ayama M, 1998, COLOR RES APPL, V23, P274, DOI 10.1002/(SICI)1520-6378(199810)23:5<274::AID-COL4>3.0.CO;2-T; Bala R, 2001, J IMAGING SCI TECHN, V45, P436; Bankston D., 2005, AM CINEMATOGR, P6; Beck B., 2014, LASERS COMING THEATE; Bertalm M, 2014, IMAGE PROCESSING CIN, V4; Bertalmio M., 2016, J VIS, V16, P1151; Bertalmio M, 2007, IEEE T IMAGE PROCESS, V16, P1058, DOI 10.1109/TIP.2007.891777; Billock VA, 2005, J OPT SOC AM A, V22, P2289, DOI 10.1364/JOSAA.22.002289; Bist Cambodge, 2016, P GRAPHICS INTERFACE, P57; Blakeslee B, 2004, VISION RES, V44, P2483, DOI 10.1016/j.visres.2004.05.015; Braun G. J., 1999, THESIS; Carandini M, 2012, NAT REV NEUROSCI, V13, P51, DOI 10.1038/nrn3136; Casella S. E., 2008, P IS T 16 COL IM C, P106; Chen X., 2002, TEHSIS U DERBY; Cyriac P, 2014, SIAM J IMAGING SCI, V7, P2340, DOI 10.1137/140967209; Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498; Farup I, 2007, IEEE T IMAGE PROCESS, V16, P2423, DOI 10.1109/TIP.2007.904946; Ferradans S, 2011, IEEE T PATTERN ANAL, V33, P2002, DOI 10.1109/TPAMI.2011.46; Froehlich J, 2014, PROC SPIE, V9023, DOI 10.1117/12.2040003; Gatta C., 2017, P IS T INT S EL IM, P12; GENTILE RS, 1990, J IMAGING TECHNOL, V16, P176; Gouras P, 2009, WEBVISION ORG RETINA; Grimaldi A, 2019, J VISION, V19, DOI 10.1167/19.2.13; Hanazawa A, 2000, EUR J NEUROSCI, V12, P1753, DOI 10.1046/j.1460-9568.2000.00041.x; Heckaman R. L., 2011, P SID S, P225; Herzog PG, 1997, P SOC PHOTO-OPT INS, V3018, P117, DOI 10.1117/12.271581; Hoshino T, 1994, U.S. Patent, Patent No. [5 317 426, 5317426]; Hoshino T., 1991, P IS T S EL PHOT, P27; Int. Telecomm. Union, 2008, ITU T RECOMMENDATION; ITU-R, 2002, RECOMMENDATION BT709; ITU-R, 2012, RECOMMENDATION BT202; Jian C., 2014, NANOTECHNOL LAW BUS, V11, P4; Johnson A. J, 1979, IARAIGAI S PRINTED P; Kang BH, 2003, ETRI J, V25, P156, DOI 10.4218/etrij.03.0102.3315; Katoh N, 1996, FOURTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P126; Kennel G, 2007, COLOR ANDMASTERING D; Kim MC, 2004, CGIV 2004: SECOND EUROPEAN CONFERENCE ON COLOR IN GRAPHICS, IMAGING, AND VISION - CONFERENCE PROCEEDINGS, P248; Kimmel R, 2005, IEEE T IMAGE PROCESS, V14, P796, DOI 10.1109/TIP.2005.847299; Kusakabe Y., 2013, P ITE ANN C, P1; Laird J, 2009, COLOR RES APPL, V34, P443, DOI 10.1002/col.20537; Lau C, 2011, IEEE I CONF COMP VIS, P1172, DOI 10.1109/ICCV.2011.6126366; Li Y., 2011, P INT C EL INF CONTR, P1035; Ling Y., 2001, THESIS; Lissner I, 2013, IEEE T IMAGE PROCESS, V22, P435, DOI 10.1109/TIP.2012.2216279; Luo MR, 2001, COLOR RES APPL, V26, P340, DOI 10.1002/col.1049; Marcu G, 1996, P SOC PHOTO-OPT INS, V2658, P308, DOI 10.1117/12.236980; Masaoka K, 2016, J DISP TECHNOL, V12, P760, DOI 10.1109/JDT.2016.2527039; McCann J. J., 2002, CATASTROPHE CULTURE, P213; Meng X., 2013, P INT C INF TECHN  S, P705; Meyer J., 1989, 1989 SID International Symposium. Digest of Technical Papers, P86; Montag ED, 1998, SIXTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P57; Morovi J, 2008, COLOR GAMUT MAPPING, V10; Morovi J., 1998, THESIS U DERBY; Murch G. M., 1989, P ADV COMPUT GRAPH, P19; Nakauchi S, 1999, COLOR RES APPL, V24, P280, DOI 10.1002/(SICI)1520-6378(199908)24:4<280::AID-COL8>3.0.CO;2-#; Olshausen B. A., 2013, 20 YEARS COMPUTATION, P243, DOI [10.1007/978-1-4614-1424-7_12, DOI 10.1007/978-1-4614-1424-7_12]; Pan H, 2008, SID INT SYMP DIG TEC, V39, P1363, DOI 10.1889/1.3069398; POINTER MR, 1980, COLOR RES APPL, V5, P145, DOI 10.1002/col.5080050308; Prashnani E, 2018, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2018.00194; Preiss J, 2012, COLOR IMAG CONF, P230; Preiss J, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2302684; Pridmore RW, 2009, COLOR RES APPL, V34, P55, DOI 10.1002/col.20468; Pytlarz J. A., 2016, P IET C P, P1; Reinhard E, 2005, IEEE T VIS COMPUT GR, V11, P13, DOI 10.1109/TVCG.2005.9; SARA JJ, 1984, THESIS MIT; Schweiger F., 2016, P SMPTE ANN TECH C E, P1; Shapley R., 1984, PROG RETIN RES, V3, P263, DOI [DOI 10.1016/0278-4327(84)90011-7, 10.1016/0278-4327(84)90011-7]; Sikudova E, 2016, IEEE COMPUT GRAPH, V36, P78, DOI 10.1109/MCG.2015.116; Silverstein B. D., 2011, P SID S, P326; Smith A. R., 1978, COMPUTER GRAPHICS, P12, DOI [DOI 10.1145/965139.807361, 10.1145/965139.807361]; SMPTE, 2011, REPORT 431 22011; Song G., 2014, J INF COMPUT SCI, V11, P461; Song G., 2014, J INF COMPUT SCI, V11, P1909; Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899; Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288; UGRA, 1995, UGRA GAMCOM VERSION; Zamir SW, 2017, IEEE T IMAGE PROCESS, V26, P1595, DOI 10.1109/TIP.2017.2661404; Watson AB, 1997, J OPT SOC AM A, V14, P2379, DOI 10.1364/JOSAA.14.002379; Withouck M, 2013, J OPT SOC AM A, V30, P1248, DOI 10.1364/JOSAA.30.001248; Xing DJ, 2015, J NEUROSCI, V35, P2226, DOI 10.1523/JNEUROSCI.3740-14.2015; Yeonan-Kim J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168963; Yuan J., 2015, COMPUT APPL MATH, P1; Zamir S. W., 2016, P SMPTE ANN TECH C E, P1; Zamir SW, 2014, IEEE J-STSP, V8, P490, DOI 10.1109/JSTSP.2014.2313182; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhu M., 2016, 2016 IEEE ACM 24 INT, P1, DOI DOI 10.1109/ITEC.2016.7520192	90	6	6	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1777	1790		10.1109/TPAMI.2019.2938499	http://dx.doi.org/10.1109/TPAMI.2019.2938499			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31725369	Green Accepted, Bronze			2022-12-18	WOS:000637533800021
J	Hou, L; Vicente, TFY; Hoai, M; Samaras, D				Hou, Le; Vicente, Tomas F. Yago; Minh Hoai; Samaras, Dimitris			Large Scale Shadow Annotation and Detection Using Lazy Annotation and Stacked CNNs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Image segmentation; Semantics; Noise measurement; Light sources; Lighting; Deep learning; Shadow detection; semantic segmentation; large scale data collection	ILLUMINATION; REMOVAL; NOISE	Recent shadow detection algorithms have shown initial success on small datasets of images from specific domains. However, shadow detection on broader image domains is still challenging due to the lack of annotated training data, caused by the intense manual labor required for annotating shadow data. In this paper we propose "lazy annotation", an efficient annotation method where an annotator only needs to mark the important shadow areas and some non-shadow areas. This yields data with noisy labels that are not yet useful for training a shadow detector. We address the problem of label noise by jointly learning a shadow region classifier and recovering the labels in the training set. We consider the training labels as unknowns and formulate label recovery as the minimization of the sum of squared leave-one-out errors of a Least Squares SVM, which can be efficiently optimized. Experimental results show that a classifier trained with recovered labels achieves comparable performance to a classifier trained on the properly annotated data. These results motivated us to collect a new dataset that is 20 times larger than existing datasets and contains a large variety of scenes and image types. Naturally, such a large dataset is appropriate for training deep learning methods. Thus, we propose a stacked Convolutional Neural Network architecture that efficiently trains on patch level shadow examples while incorporating image level semantic information. This means that the detected shadow patches are refined based on image semantics. Our proposed pipeline, trained on recovered labels, performs at state-of-the art level. Furthermore, the proposed model performs exceptionally well on a cross dataset task, proving the generalization power of the proposed architecture and dataset.	[Hou, Le; Minh Hoai; Samaras, Dimitris] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA; [Vicente, Tomas F. Yago] A9 Com, 130 Lytton Ave, Palo Alto, CA 94301 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Hou, L (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.	lehhou@cs.stonybrook.edu; victomas@a9.com; minhhoai@cs.stonybrook.edu; samaras@cs.sunysb.edu		Samaras, Dimitris/0000-0002-1373-0294	US National Science Foundation [IIS-1161876, CNS-1718014]; FRA [DTFR5315C00011]; Stony Brook Senson CAT; Sub-sample project from DIGITEO Institute, France; Partner University Fund; SUNY2020 Infrastructure Transportation Security Center	US National Science Foundation(National Science Foundation (NSF)); FRA; Stony Brook Senson CAT; Sub-sample project from DIGITEO Institute, France; Partner University Fund; SUNY2020 Infrastructure Transportation Security Center	The authors thank Hieu Le for providing results of the A+D Net [25]. This work is partially supported by US National Science Foundation IIS-1161876 and CNS-1718014, FRA DTFR5315C00011, the Stony Brook Senson CAT, the Sub-sample project from DIGITEO Institute, France, a gift from Adobe, the Partner University Fund, and the SUNY2020 Infrastructure Transportation Security Center. The authors would also like to thank Amazon for providing EC2 credits and NVIDIA for donating GPUs.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Aloimonos Y, 2014, ICCP, P1; [Anonymous], 2014, P BRIT MACH VIS C; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Bastien F., 2012, P DEEP LEARN UNS FEA; Bergstra J., 2010, P PYTH SCI COMP C SC, V4, P1, DOI DOI 10.25080/MAJORA-92BF1922-003; Biggio B., 2011, PROC ACML, P97; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chen L.-C., 2015, COMPUT SCI; Chen LC, 2016, PROC CVPR IEEE, P4545, DOI 10.1109/CVPR.2016.492; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Crammer K., 2010, ADV NEURAL INFORM PR, P451; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18; Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z; Frenay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894; Gong H, 2014, P BRIT MACH VIS C; Gong H, 2016, J OPT SOC AM A, V33, P1798, DOI 10.1364/JOSAA.33.001798; Gulshan V, 2010, PROC CVPR IEEE, P3129, DOI 10.1109/CVPR.2010.5540073; Guo Ruiqi, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P2956, DOI 10.1109/TPAMI.2012.214; Hieu Le, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11206), P680, DOI 10.1007/978-3-030-01216-8_41; Hoai M, 2015, LECT NOTES COMPUT SC, V9007, P3, DOI 10.1007/978-3-319-16814-2_1; Hoiem D, 2011, CVPR 2011, P2033, DOI DOI 10.1109/CVPR.2011.5995725; Hosseinzadeh S, 2018, IEEE INT C INT ROBOT, P3124, DOI 10.1109/IROS.2018.8594050; Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jiang XY, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.87; Junejo IN, 2008, LECT NOTES COMPUT SC, V5302, P318, DOI 10.1007/978-3-540-88682-2_25; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191; Khan SH, 2014, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2014.249; Khardon R, 2007, J MACH LEARN RES, V8, P227; Lalonde JF, 2009, IEEE I CONF COMP VIS, P183, DOI 10.1109/ICCV.2009.5459163; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Mohajerani S, 2019, IEEE T IMAGE PROCESS, V28, P4117, DOI 10.1109/TIP.2019.2904267; Natarajan Nagarajan, 2013, ADV NEURAL INFORM PR; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Okabe T, 2009, IEEE I CONF COMP VIS, P1693, DOI 10.1109/ICCV.2009.5459381; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pan T, 2018, P BRIT MACH VIS C; Panagopoulos A, 2013, IEEE T PATTERN ANAL, V35, P437, DOI 10.1109/TPAMI.2012.110; Panagopoulos A, 2009, PROC CVPR IEEE, P651, DOI 10.1109/CVPRW.2009.5206665; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Park E, 2016, IEEE WINT CONF APPL; Qu LQ, 2017, PROC CVPR IEEE, P2308, DOI 10.1109/CVPR.2017.248; Saunders C., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P515; Sharkey A.J., 2012, COMBINING ARTIFICIAL; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shen L, 2015, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2015.7298818; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Stempfel G, 2007, LECT NOTES ARTIF INT, V4754, P328; Stempfel G, 2009, LECT NOTES COMPUT SC, V5768, P884, DOI 10.1007/978-3-642-04274-4_91; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255; Vicente TFY, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.126; Vicente TFY, 2018, IEEE T PATTERN ANAL, V40, P682, DOI 10.1109/TPAMI.2017.2691703; Vicente TFY, 2016, PROC CVPR IEEE, P3783, DOI 10.1109/CVPR.2016.411; Vicente TFY, 2015, IEEE I CONF COMP VIS, P3388, DOI 10.1109/ICCV.2015.387; Nguyen V, 2017, IEEE I CONF COMP VIS, P4520, DOI 10.1109/ICCV.2017.483; Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192; Wang YP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1007; Wei ZJ, 2016, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2016.326; Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403; Yu CP, 2015, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2015.361; Yu Chen-Ping, 2013, ADV NEURAL INFORM PR, P118; Zhang L, 2015, IEEE T IMAGE PROCESS, V24, P4623, DOI 10.1109/TIP.2015.2465159; Zheng QL, 2019, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2019.00531; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zhu JJ, 2010, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.2010.5540209; Zhu L, 2018, LECT NOTES COMPUT SC, V11210, P122, DOI 10.1007/978-3-030-01231-1_8; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8	75	6	6	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1337	1351		10.1109/TPAMI.2019.2948011	http://dx.doi.org/10.1109/TPAMI.2019.2948011			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31634124				2022-12-18	WOS:000626525300017
J	Ahmed, I; Galoppo, T; Hu, X; Ding, Y				Ahmed, Imtiaz; Galoppo, Travis; Hu, Xia; Ding, Yu			Graph Regularized Autoencoder and its Application in Unsupervised Anomaly Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manifolds; Anomaly detection; Neural networks; Laplace equations; Dimensionality reduction; Decoding; Measurement; Autoencoder; clustering; minimum spanning tree; nonlinear embedding; unsupervised learning	DIMENSIONALITY; NETWORK	Dimensionality reduction is a crucial first step for many unsupervised learning tasks including anomaly detection and clustering. Autoencoder is a popular mechanism to accomplish dimensionality reduction. In order to make dimensionality reduction effective for high-dimensional data embedding nonlinear low-dimensional manifold, it is understood that some sort of geodesic distance metric should be used to discriminate the data samples. Inspired by the success of geodesic distance approximators such as ISOMAP, we propose to use a minimum spanning tree (MST), a graph-based algorithm, to approximate the local neighborhood structure and generate structure-preserving distances among data points. We use this MST-based distance metric to replace the euclidean distance metric in the embedding function of autoencoders and develop a new graph regularized autoencoder, which outperforms a wide range of alternative methods over 20 benchmark anomaly detection datasets. We further incorporate the MST regularizer into two generative adversarial networks and find that using the MST regularizer improves the performance of anomaly detection substantially for both generative adversarial networks. We also test our MST regularized autoencoder on two datasets in a clustering application and witness its superior performance as well.	[Ahmed, Imtiaz; Ding, Yu] Texas A&M Univ, Dept Ind & Syst Engn, College Stn, TX 77843 USA; [Galoppo, Travis] BAE Syst Inc, Charlotte, NC 28277 USA; [Hu, Xia] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA	Texas A&M University System; Texas A&M University College Station; Texas A&M University System; Texas A&M University College Station	Ding, Y (corresponding author), Texas A&M Univ, Dept Ind & Syst Engn, College Stn, TX 77843 USA.	imtiazavi@tamu.edu; travis.galoppo@baesystems.com; hu@cse.tamu.edu; yuding@tamu.edu	hu, xia hong/GQP-8544-2022	Ahmed, Imtiaz/0000-0003-1577-7384	US National Science Foundation [IIS-1849085, IIS-1750074, IIS-1718840]; ABB project [M1801386]	US National Science Foundation(National Science Foundation (NSF)); ABB project	The work of Imtiaz Ahmed and Yu Ding was supported in part by the grants from US National Science Foundation under grant no. IIS-1849085, and ABB project contract no. M1801386. The work of Xia Ben Hu was supported in part by the US National Science Foundation under Grants IIS-1750074 and IIS-1718840.	Ahmed I, 2021, J MACH LEARN RES, V22; Ahmed I, 2019, IEEE T AUTOM SCI ENG, V16, P654, DOI 10.1109/TASE.2018.2848198; Belkin M, 2002, ADV NEUR IN, V14, P585; Bengio Y., 2016, NATURE, V521, P436; BLAND JM, 1995, BRIT MED J, V310, P170, DOI 10.1136/bmj.310.6973.170; Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Campos GO, 2016, DATA MIN KNOWL DISC, V30, P891, DOI 10.1007/s10618-015-0444-8; Chapelle O., 2006, IEEE T NEURAL NETWOR, V20, P542; Conover W. J, 1999, PRACTICAL NONPARAMET, V350; Demsar J, 2006, J MACH LEARN RES, V7, P1; Facco E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11873-y; Fefferman C, 2016, J AM MATH SOC, V29, P983, DOI 10.1090/jams/852; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Harandi M. T., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P433, DOI 10.1109/WACV.2012.6163005; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang PH, 2014, INT C PATT RECOG, P1532, DOI 10.1109/ICPR.2014.272; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jayasumana S, 2013, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2013.17; Ji P., 2017, ADV NEURAL INF PROCE, P24; Jia K, 2015, NEUROCOMPUTING, V160, P250, DOI 10.1016/j.neucom.2015.02.023; Jian Tang, 2002, Advances in Knowledge Discovery and Data Mining. 6th Pacific-Asia Conference, PAKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2336), P535; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Kriegel HP, 2009, LECT NOTES ARTIF INT, V5476, P831, DOI 10.1007/978-3-642-01307-2_86; Kruskal J. B., 1956, P AM MATH SOC, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.2307/2033241]; Kruskal JosephB., 1978, MULTIDIMENSIONAL SCA, DOI [10.4135/9781412985130, DOI 10.4135/9781412985130]; Levina E., 2005, ADV NEURAL INFORM PR, V17, P777, DOI DOI 10.5555/2976040.2976138; Liao YY, 2017, IEEE T IMAGE PROCESS, V26, P2839, DOI 10.1109/TIP.2016.2605010; Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17; Lu SC, 2015, IEEE SYS MAN CYBERN, P2950, DOI 10.1109/SMC.2015.513; Nesetril J, 2001, DISCRETE MATH, V233, P3, DOI 10.1016/S0012-365X(00)00224-7; Papernot N.., 2018, ARXIV 180304765; PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x; Ranzato M., 2007, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/mitpress/7503.003.0147; Rifai S, 2011, LECT NOTES ARTIF INT, V6912, P645, DOI 10.1007/978-3-642-23783-6_41; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Schreyer M.., 2017, ARXIV 170905254; Sitawarin Chawin, 2019, 2019 IEEE Security and Privacy Workshops (SPW). Proceedings, P1, DOI 10.1109/SPW.2019.00014; Song Q., 2018, INT C LEARN REPR; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Thornton C, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P847, DOI 10.1145/2487575.2487629; van Rijsbergen C., 1979, INFORM RETRIEVAL, V2nd; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wei C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146672; Wenchao Yu, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8190, P208, DOI 10.1007/978-3-642-40994-3_14; Zenati H, 2018, IEEE DATA MINING, P727, DOI 10.1109/ICDM.2018.00088; Zhai SF, 2016, PR MACH LEARN RES, V48; Zhou C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P665, DOI 10.1145/3097983.3098052	52	6	6	9	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 17	2021	44	8					4110	4124		10.1109/TPAMI.2021.3066111	http://dx.doi.org/10.1109/TPAMI.2021.3066111			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HP	33729925	Green Submitted, Bronze			2022-12-18	WOS:000820521900001
J	Li, S; Xie, BH; Lin, QX; Liu, CH; Huang, G; Wang, GR				Li, Shuang; Xie, Binhui; Lin, Qiuxia; Liu, Chi Harold; Huang, Gao; Wang, Guoren			Generalized Domain Conditioned Adaptation Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Feature extraction; Adaptation models; Training; Convolutional codes; Painting; Knowledge engineering; Domain adaptation; domain shift; domain-general; specialized feature learning; channel attention		Domain adaptation (DA) attempts to transfer knowledge learned in the labeled source domain to the unlabeled but related target domain without requiring large amounts of target supervision. Recent advances in DA mainly proceed by aligning the source and target distributions. Despite the significant success, the adaptation performance still degrades accordingly when the source and target domains encounter a large distribution discrepancy. We consider this limitation may attribute to the insufficient exploration of domain-specialized features because most studies merely concentrate on domain-general feature learning in task-specific layers and integrate totally-shared convolutional networks (convnets) to generate common features for both domains. In this paper, we relax the completely-shared convnets assumption adopted by previous DA methods and propose Domain Conditioned Adaptation Network (DCAN), which introduces domain conditioned channel attention module with a multi-path structure to separately excite channel activation for each domain. Such a partially-shared convnets module allows domain-specialized features in low-level to be explored appropriately. Further, given the knowledge transferability varying along with convolutional layers, we develop Generalized Domain Conditioned Adaptation Network (GDCAN) to automatically determine whether domain channel activations should be separately modeled in each attention module. Afterward, the critical domain-specialized knowledge could be adaptively extracted according to the domain statistic gaps. As far as we know, this is the first work to explore the domain-wise convolutional channel activations separately for deep DA networks. Additionally, to effectively match high-level feature distributions across domains, we consider deploying feature adaptation blocks after task-specific layers, which can explicitly mitigate the domain discrepancy. Extensive experiments on four cross-domain benchmarks, including DomainNet, Office-Home, Office-31, and ImageCLEF, demonstrate the proposed approaches outperform the existing methods by a large margin, especially on the large-scale challenging dataset. The code and models are available at https://github.com/BIT-DA/GDCAN.	[Li, Shuang; Xie, Binhui; Lin, Qiuxia; Liu, Chi Harold; Wang, Guoren] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100811, Peoples R China; [Huang, Gao] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Beijing Institute of Technology; Tsinghua University	Liu, CH (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100811, Peoples R China.	shuangli@bit.edu.cn; binhuixie@bit.edu.cn; linqiuxia@bit.edu.cn; chiliu@bit.edu.cn; gaohuang@tsinghua.edu.cn; wanggrbit@bit.edu.cn			National Natural Science Foundation of China [61902028]; National Key Research and Development Plan of China [2018YFB1003701, 2018YFB1003700]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Plan of China	This work was supported in part by the National Natural Science Foundation of China under Grant 61902028, and in part by the National Key Research and Development Plan of China under Grant 2018YFB1003701 and 2018YFB1003700.	[Anonymous], 2017, P 2017 ACM MULT C, DOI DOI 10.1145/3123266.3123292; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542; Chang WG, 2019, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2019.00753; Chen XY, 2019, PR MACH LEARN RES, V97; Cui SH, 2020, PROC CVPR IEEE, P3940, DOI 10.1109/CVPR42600.2020.00400; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Donahue J, 2014, PR MACH LEARN RES, V32; French Geoffrey, 2017, ARXIV170605208; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Grandvalet Y., 2005, CAP, P529; Gretton A, 2012, J MACH LEARN RES, V13, P723; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang GL, 2017, IEEE ICC; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Kang GL, 2018, LECT NOTES COMPUT SC, V11215, P420, DOI 10.1007/978-3-030-01252-6_25; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lee H, 2019, IEEE I CONF COMP VIS, P1854, DOI 10.1109/ICCV.2019.00194; Li S, 2020, AAAI CONF ARTIF INTE, V34, P11386; Li S, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P729, DOI 10.1145/3343031.3351070; Li S, 2021, IEEE T PATTERN ANAL, V43, P2329, DOI 10.1109/TPAMI.2020.2964173; Li S, 2020, IEEE T NEUR NET LEAR, V31, P4842, DOI 10.1109/TNNLS.2019.2958152; Li S, 2018, IEEE T IMAGE PROCESS, V27, P4260, DOI 10.1109/TIP.2018.2839528; Li S, 2017, IEEE T NEUR NET LEAR, V28, P1682, DOI 10.1109/TNNLS.2016.2538282; Li YH, 2018, PATTERN RECOGN, V80, P109, DOI 10.1016/j.patcog.2018.03.005; Liang J, 2019, IEEE T PATTERN ANAL, V41, P1027, DOI 10.1109/TPAMI.2018.2832198; Long MS, 2018, ADV NEUR IN, V31; Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2017, PR MACH LEARN RES, V70; Long MS, 2016, ADV NEUR IN, V29; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Nair V., 2010, ICML, P807; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Paszke A, 2019, ADV NEUR IN, V32; Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934; Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149; Roy S, 2019, PROC CVPR IEEE, P9463, DOI 10.1109/CVPR.2019.00970; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Simonyan K, 2014, ADV NEUR IN, V27; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; Tzeng E., 2014, ARXIV PREPRINT ARXIV; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A., 2017, P 31 INT C NEUR INF, P5998, DOI DOI 10.5555/3295222.3295349; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Wang XM, 2019, ADV NEUR IN, V32; Wang XM, 2019, AAAI CONF ARTIF INTE, P5345; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xie SA, 2018, PR MACH LEARN RES, V80; Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151; Yosinski J, 2014, ADV NEUR IN, V27; Zellinger W., 2017, ARXIV 170208811; Zhang WC, 2021, IEEE T PATTERN ANAL, V43, P2047, DOI 10.1109/TPAMI.2019.2962476; Zhang WC, 2018, PROC CVPR IEEE, P3801, DOI 10.1109/CVPR.2018.00400; Zhang YB, 2019, PROC CVPR IEEE, P5026, DOI 10.1109/CVPR.2019.00517; Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223; Zhang YC, 2019, PR MACH LEARN RES, V97; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	70	6	6	5	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	44	8					4093	4109		10.1109/TPAMI.2021.3062644	http://dx.doi.org/10.1109/TPAMI.2021.3062644			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HW	33646945	Green Submitted			2022-12-18	WOS:000820522600001
J	Gould, S; Hartley, R; Campbell, DJ				Gould, Stephen; Hartley, Richard; Campbell, Dylan John			Deep Declarative Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimization; Deep learning; Mathematical model; Computational modeling; Three-dimensional displays; Neural networks; Task analysis; Deep learning; implicit differentiation; declarative networks		We explore a class of end-to-end learnable models wherein data processing nodes (or network layers) are defined in terms of desired behavior rather than an explicit forward function. Specifically, the forward function is implicitly defined as the solution to a mathematical optimization problem. Consistent with nomenclature in the programming languages community, we name these models deep declarative networks. Importantly, it can be shown that the class of deep declarative networks subsumes current deep learning models. Moreover, invoking the implicit function theorem, we show how gradients can be back-propagated through many declaratively defined data processing nodes thereby enabling end-to-end learning. We discuss how these declarative processing nodes can be implemented in the popular PyTorch deep learning software library allowing declarative and imperative nodes to co-exist within the same network. We also provide numerous insights and illustrative examples of declarative nodes and demonstrate their application for image and point cloud classification tasks.	[Gould, Stephen; Campbell, Dylan John] Australian Natl Univ, Res Sch Comp Sci, Australian Ctr Robot Vis, Canberra, ACT 0200, Australia; [Hartley, Richard] Australian Natl Univ, Australian Ctr Robot Vis, Res Sch Engn, Canberra, ACT 0200, Australia	Australian Centre for Robotic Vision; Australian National University; Australian Centre for Robotic Vision; Australian National University	Gould, S (corresponding author), Australian Natl Univ, Res Sch Comp Sci, Australian Ctr Robot Vis, Canberra, ACT 0200, Australia.	stephen.gould@anu.edu.au; richard.hartley@anu.edu.au; dylan.campbell@anu.edu.au			Australian Research Council Centre of Excellence in Computer Vision [CE140100016]	Australian Research Council Centre of Excellence in Computer Vision(Australian Research Council)	The authors would like to thanks to Bob Williamson and John Lloyd for helpful discussions, and anonymous reviewers for insightful suggestions. They also like to thank Itzik Ben-Shabat for recommending experiments on point cloud classification. This work was supported in part by the Australian Research Council Centre of Excellence in Computer Vision (CE140100016).	Agrawal A., 2019, J APPL NUMER OPTIM, V1, P107, DOI [DOI 10.23952/JANO.1.2019.2.02, 10.23952/jano.1.2019.2.02]; Agrawal A., 2019, PROC INT C NEURAL IN; Amos B., 2019, THESIS CARNEGIE MELL; Amos B, 2017, PR MACH LEARN RES, V70; Amos B, 2018, ADV NEUR IN, V31; [Anonymous], 2013, IMPLICIT FUNCTION TH; Bai SJ, 2019, ADV NEUR IN, V32; Bard J. F., 1998, PRACTICAL BILEVEL OP; Belbute-Peres FD, 2018, ADV NEUR IN, V31; Berthet Q., 2020, PROC INT C NEURAL IN, V33, P9508; Bertsekas D.P., 2019, REINFORCEMENT LEARNI; Bertsekas D. P., 2004, NONLINEAR PROGRAMMIN; Bo Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8097, DOI 10.1109/CVPR42600.2020.00812; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); Boyd S, 2004, CONVEX OPTIMIZATION; Campbell Dylan, 2020, EUR C COMP VIS, P244; Chen R. T., 2018, ADV NEURAL INFORM PR, P6571; Cherian A, 2017, PROC CVPR IEEE, P1581, DOI 10.1109/CVPR.2017.172; CLARKE FH, 1975, T AM MATH SOC, V205, P247, DOI 10.1090/s0002-9947-1975-0367131-6; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dempe S, 2016, COMPUT OPTIM APPL, V63, P685, DOI 10.1007/s10589-015-9795-8; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; DENNIS JE, 1978, COMMUN STAT B-SIMUL, V7, P345, DOI 10.1080/03610917808812083; Djolonga J, 2017, ADV NEUR IN, V30; Do C. B., 2007, ADV NEURAL INFORM PR, P377; Domke Justin, 2012, INT C ARTIFICIAL INT; Dontchev A. L., 2014, IMPLICIT FUNCTIONS S, V2nd; Duchi J., 2008, PROC 25 INT C MACH L, P272; Fernando B, 2017, INT J COMPUT VISION, V124, P335, DOI 10.1007/s11263-017-1030-x; Fernando B, 2016, PR MACH LEARN RES, V48; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gould Stephen, 2016, ARXIV160705447; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jiang SA, 2020, INT CONF 3D VISION, P682, DOI 10.1109/3DV50981.2020.00078; Klatzer T., 2015, COMP VIS WINT WORKSH, P39; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091; Marquez-Neila P., 2017, P CVPR WORKSH NEG RE; MEYER CD, 1973, SIAM J APPL MATH, V24, P315; Ochs Peter, 2015, Scale Space and Variational Methods in Computer Vision. 5th International Conference, SSVM 2015. Proceedings: LNCS 9087, P654, DOI 10.1007/978-3-319-18461-6_52; Oymak S, 2018, PROC 35 INT C MACH L, P3963; Paulus Max B., 2020, ABS200608063 ARXIV; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Samuel KGG, 2009, PROC CVPR IEEE, P477, DOI 10.1109/CVPRW.2009.5206774; Santa Cruz R, 2019, IEEE T PATTERN ANAL, V41, P3100, DOI 10.1109/TPAMI.2018.2873701; Scarpello G. M., 2002, DIVULG MAT, V10, P171; Tschiatschek S, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2731; Vlastelica M., 2020, P INT C LEARN REPR; von Stackelberg H., 2011, MARKET STRUCTURE EQU; Wang PW, 2019, PR MACH LEARN RES, V97; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801	55	6	6	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 16	2021	44	8					3988	4004		10.1109/TPAMI.2021.3059462	http://dx.doi.org/10.1109/TPAMI.2021.3059462			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HM	33591908	Green Submitted			2022-12-18	WOS:000820521600001
J	Mancini, M; Porzi, L; Bulo, SR; Caputo, B; Ricci, E				Mancini, Massimiliano; Porzi, Lorenzo; Bulo, Samuel Rota; Caputo, Barbara; Ricci, Elisa			Inferring Latent Domains for Unsupervised Deep Domain Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Adaptation models; Data models; Computer architecture; Neural networks; Training; Visualization; Training data; Unsupervised domain adaptation; batch normalization; domain discovery; object recognition		Unsupervised Domain Adaptation (UDA) refers to the problem of learning a model in a target domain where labeled data are not available by leveraging information from annotated data in a source domain. Most deep UDA approaches operate in a single-source, single-target scenario, i.e., they assume that the source and the target samples arise from a single distribution. However, in practice most datasets can be regarded as mixtures of multiple domains. In these cases, exploiting traditional single-source, single-target methods for learning classification models may lead to poor results. Furthermore, it is often difficult to provide the domain labels for all data points, i.e. latent domains should be automatically discovered. This paper introduces a novel deep architecture which addresses the problem of UDA by automatically discovering latent domains in visual datasets and exploiting this information to learn robust target classifiers. Specifically, our architecture is based on two main components, i.e. a side branch that automatically computes the assignment of each sample to its latent domain and novel layers that exploit domain membership information to appropriately align the distribution of the CNN internal feature representations to a reference distribution. We evaluate our approach on publicly available benchmarks, showing that it outperforms state-of-the-art domain adaptation methods.	[Mancini, Massimiliano] Sapienza Univ Rome, Dept Comp Control & Management Engn, I-00185 Rome, Italy; [Mancini, Massimiliano; Caputo, Barbara] Italian Inst Technol, I-10144 Turin, Italy; [Mancini, Massimiliano; Ricci, Elisa] Fdn Bruno Kessler, Trento, Italy; [Porzi, Lorenzo; Bulo, Samuel Rota] Mapillary Res, Graz, Austria; [Caputo, Barbara] Politecn Torino, DAUIN Dept Control & Comp Engn, I-10129 Turin, Italy; [Ricci, Elisa] Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy	Sapienza University Rome; Istituto Italiano di Tecnologia - IIT; Fondazione Bruno Kessler; Polytechnic University of Turin; University of Trento	Mancini, M (corresponding author), Sapienza Univ Rome, Dept Comp Control & Management Engn, I-00185 Rome, Italy.; Mancini, M (corresponding author), Italian Inst Technol, I-10144 Turin, Italy.	mancini@diag.uniroma1.it; lorenzo@mapillary.com; samuel@mapillary.com; barbara.caputo@polito.it; eliricci@fbk.eu			ERC [637076]; project DIGIMAP - Austrian Research Promotion Agency (FFG) [860375]	ERC(European Research Council (ERC)European Commission); project DIGIMAP - Austrian Research Promotion Agency (FFG)	We acknowledge financial support from ERC grant 637076 - RoboExNovo and project DIGIMAP, grant 860375, funded by the Austrian Research Promotion Agency (FFG). This work was carried out under the "Vision and Learning joint Laboratory" between FBK and UNITN.	Aljundi R, 2016, LECT NOTES COMPUT SC, V9915, P508, DOI 10.1007/978-3-319-49409-8_43; Angeletti G, 2018, IEEE INT CONF ROBOT, P7135; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Bousmalis Konstantinos, 2016, ADV NEURAL INFORM PR, P343; Carlucci FM, 2017, LECT NOTES COMPUT SC, V10484, P357, DOI 10.1007/978-3-319-68560-1_32; Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542; Crammer K, 2008, J MACH LEARN RES, V9, P1757; Donahue J, 2014, PR MACH LEARN RES, V32; Duan L., 2009, P 26 ANN INT C MACH, P289, DOI DOI 10.1145/1553374.1553411; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Friedman J., 2001, ELEMENTS STAT LEARNI, V1; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Yaroslav, 2015, ICML; Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gong Boqing, 2013, P ADV NEUR INF PROC, P1286; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gopalan R, 2014, IEEE T PATTERN ANAL, V36, P2288, DOI 10.1109/TPAMI.2013.249; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Haeusser P, 2017, IEEE I CONF COMP VIS, P2784, DOI 10.1109/ICCV.2017.301; Hoffman J, 2012, LECT NOTES COMPUT SC, V7573, P702, DOI 10.1007/978-3-642-33709-3_50; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li D, 2018, AAAI CONF ARTIF INTE, P3490; Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591; Li W, 2018, IEEE T PATTERN ANAL, V40, P1114, DOI 10.1109/TPAMI.2017.2704624; Li Y., 2017, P INT C LEARN REPR W; Lin YW, 2017, IEEE T CYBERNETICS, V47, P1090, DOI 10.1109/TCYB.2016.2538199; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2017, PR MACH LEARN RES, V70; Long MS, 2016, ADV NEUR IN, V29; Long MS, 2013, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.2013.59; Mancini M., 2018, IEEE ROBOTICS AUTOMA, V3, P2093, DOI DOI 10.1109/LRA.2018.2809700; Mancini M, 2018, PROC CVPR IEEE, P3771, DOI 10.1109/CVPR.2018.00397; Mancini M, 2018, IEEE IMAGE PROC, P1353, DOI 10.1109/ICIP.2018.8451318; Muandet Krikamol, 2013, ICML; Netzer Y, 2011, NIPS WORKSH DEEP LEA, P2011, DOI DOI 10.2118/18761-MS; Nguyen HV, 2015, IEEE T IMAGE PROCESS, V24, P5479, DOI 10.1109/TIP.2015.2479405; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Rostamizadeh A., 2009, ADV NEURAL INFORM PR, P1041; Russo P, 2018, PROC CVPR IEEE, P8099, DOI 10.1109/CVPR.2018.00845; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K, 2017, PR MACH LEARN RES, V70; Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887; Sener Ozan, 2016, ADV NEURAL INFORM PR, P2; Sha, 2013, P INT C MACH LEARN; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Sun Qian, 2011, ADV NEURAL INFORM PR, P505; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; Xie JW, 2015, INT J COMPUT VISION, V114, P91, DOI 10.1007/s11263-014-0757-x; Xiong CM, 2014, AAAI CONF ARTIF INTE, P2860; Xu RJ, 2018, PROC CVPR IEEE, P3964, DOI 10.1109/CVPR.2018.00417; Xu Z, 2014, LECT NOTES COMPUT SC, V8691, P628, DOI 10.1007/978-3-319-10578-9_41; Yamada M, 2012, LECT NOTES COMPUT SC, V7575, P674, DOI 10.1007/978-3-642-33765-9_48; Yang J., 2007, 7 IEEE INT C DATA MI, P69, DOI DOI 10.1109/ICDMW.2007.37; Zeng XY, 2014, LECT NOTES COMPUT SC, V8691, P472, DOI 10.1007/978-3-319-10578-9_31; Zhao H., 2018, P INT C LEARN REPR W	65	6	6	2	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					485	498		10.1109/TPAMI.2019.2933829	http://dx.doi.org/10.1109/TPAMI.2019.2933829			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31398109	Green Submitted			2022-12-18	WOS:000607383300008
J	Zhang, ZY; Cui, Z; Xu, CY; Jie, ZQ; Li, X; Yang, J				Zhang, Zhenyu; Cui, Zhen; Xu, Chunyan; Jie, Zequn; Li, Xiang; Yang, Jian			Joint Task-Recursive Learning for RGB-D Scene Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Estimation; Semantics; Image segmentation; Learning systems; Fuses; Cameras; Depth estimation; surface normal estimation; semantic segmentation; recursive learning; RGB-D scene understanding		RGB-D scene understanding under monocular camera is an emerging and challenging topic with many potential applications. In this paper, we propose a novel Task-Recursive Learning (TRL) framework to jointly and recurrently conduct three representative tasks therein containing depth estimation, surface normal prediction and semantic segmentation. TRL recursively refines the prediction results through a series of task-level interactions, where one-time cross-task interaction is abstracted as one network block of one time stage. In each stage, we serialize multiple tasks into a sequence and then recursively perform their interactions. To adaptively enhance counterpart patterns, we encapsulate interactions into a specific Task-Attentional Module (TAM) to mutually-boost the tasks from each other. Across stages, the historical experiences of previous states of tasks are selectively propagated into the next stages by using Feature-Selection unit (FS-Unit), which takes advantage of complementary information across tasks. The sequence of task-level interactions is also evolved along a coarse-to-fine scale space such that the required details may be refined progressively. Finally the task-abstracted sequence problem of multi-task prediction is framed into a recursive network. Extensive experiments on NYU-Depth v2 and SUN RGB-D datasets demonstrate that our method can recursively refines the results of the triple tasks and achieves state-of-the-art performance.	[Zhang, Zhenyu; Cui, Zhen; Xu, Chunyan; Li, Xiang; Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, PCA Lab,Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Peoples R China; [Zhang, Zhenyu; Cui, Zhen; Xu, Chunyan; Li, Xiang; Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Jiangsu Key Lab Image & Video Understanding Socia, Nanjing 210094, Peoples R China; [Jie, Zequn] Tencent AI Lab, Nanjing 210094, Peoples R China	Nanjing University of Science & Technology; Nanjing University of Science & Technology; Tencent	Cui, Z; Yang, J (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, PCA Lab,Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Peoples R China.; Cui, Z; Yang, J (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Jiangsu Key Lab Image & Video Understanding Socia, Nanjing 210094, Peoples R China.	zhangjesse@njust.edu.cn; zhen.cui@njust.edu.cn; cyx@njust.edu.cn; zequn.nus@gmail.com; xiang.li.implus@njust.edu.cn; csjyang@njust.edu.cn			National Natural Science Fund of China [U1713208, 61772276, 61602244]; Tencent AI Lab Rhino-Bird Focused Research Program [JR201922]; fundamental research funds for the central universities [30918011321]; Guangdong Key Area Research Project [2018B010108003]; Program for Changjiang Scholars	National Natural Science Fund of China(National Natural Science Foundation of China (NSFC)); Tencent AI Lab Rhino-Bird Focused Research Program; fundamental research funds for the central universities(Fundamental Research Funds for the Central Universities); Guangdong Key Area Research Project; Program for Changjiang Scholars(Program for Changjiang Scholars & Innovative Research Team in University (PCSIRT))	This work was supported by the National Natural Science Fund of China under Grant Nos. U1713208, 61772276, 61602244, Tencent AI Lab Rhino-Bird Focused Research Program (No. JR201922), the fundamental research funds for the central universities (No. 30918011321), Guangdong Key Area Research Project 2018B010108003, and Program for Changjiang Scholars.	Amit Y., 2007, ICML 07 P 24 INT C M, P17, DOI DOI 10.1145/1273496.1273499; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bansal A, 2016, PROC CVPR IEEE, P5965, DOI 10.1109/CVPR.2016.642; Borst JP, 2010, J EXP PSYCHOL LEARN, V36, P363, DOI 10.1037/a0018106; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chen L.-C., 2014, ARXIV14127062CSCV, P1; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Cheng YH, 2017, PROC CVPR IEEE, P1475, DOI 10.1109/CVPR.2017.161; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng Z, 2015, IEEE I CONF COMP VIS, P1733, DOI 10.1109/ICCV.2015.202; Eigen D, 2014, ADV NEUR IN, V27; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; Fouhey DF, 2013, IEEE I CONF COMP VIS, P3392, DOI 10.1109/ICCV.2013.421; Fouhey DF, 2014, LECT NOTES COMPUT SC, V8694, P687, DOI 10.1007/978-3-319-10599-4_44; Gebru T, 2017, IEEE I CONF COMP VIS, P1358, DOI 10.1109/ICCV.2017.151; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Hadsell R, 2009, J FIELD ROBOT, V26, P120, DOI 10.1002/rob.20276; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He Y, 2017, PROC CVPR IEEE, P7158, DOI 10.1109/CVPR.2017.757; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Jalali A., 2010, ADV NEURAL INF PROCE, V23, P964; Kendall A, 2015, P BRIT MACH VIS C 20; Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781; Kim S, 2016, LECT NOTES COMPUT SC, V9912, P143, DOI 10.1007/978-3-319-46484-8_9; Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Ladicky L, 2014, LECT NOTES COMPUT SC, V8693, P468, DOI 10.1007/978-3-319-10602-1_31; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715; Li X, 2017, IEEE I CONF COMP VIS, P784, DOI 10.1109/ICCV.2017.91; Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34; Lin D, 2017, IEEE I CONF COMP VIS, P1320, DOI 10.1109/ICCV.2017.147; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348; Liu D, 2018, ADV NEUR IN, V31; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Michels Jeff, 2005, P 22 INT C MACH LEAR, P593, DOI DOI 10.1145/1102351.1102426; Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533; Qi XJ, 2018, PROC CVPR IEEE, P283, DOI 10.1109/CVPR.2018.00037; Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556; Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Roy A, 2016, PROC CVPR IEEE, P5506, DOI 10.1109/CVPR.2016.594; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695; Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683; Wang P, 2016, ADV NEUR IN, V29; Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897; Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652; Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759; Wei YC, 2016, PATTERN RECOGN, V59, P234, DOI 10.1016/j.patcog.2016.01.015; Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077; Xu D, 2017, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2017.25; Yosinski J, 2014, ADV NEUR IN, V27; Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391; Zhang Z., 2019, ARXIV190408462; Zhang ZY, 2019, PROC CVPR IEEE, P4101, DOI 10.1109/CVPR.2019.00423; Zhang ZY, 2018, LECT NOTES COMPUT SC, V11214, P238, DOI 10.1007/978-3-030-01249-6_15; Zhang ZY, 2018, PATTERN RECOGN, V83, P430, DOI 10.1016/j.patcog.2018.05.016; Zhang ZY, 2018, IEEE T IMAGE PROCESS, V27, P3691, DOI 10.1109/TIP.2018.2821979; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660	71	6	6	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2608	2623		10.1109/TPAMI.2019.2926728	http://dx.doi.org/10.1109/TPAMI.2019.2926728			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31295103				2022-12-18	WOS:000567471300021
J	Yamasaki, R; Tanaka, T				Yamasaki, Ryoya; Tanaka, Toshiyuki			Properties of Mean Shift	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel; Probability density function; Convergence; Clustering algorithms; Estimation; Bandwidth; Trajectory; Mode estimation; mode clustering; mean shift algorithm; conditional mean shift algorithm; subspace constrained mean shift algorithm	DENSITY RIDGES; CONVERGENCE; ALGORITHM; MODE	We study properties of the mean shift (MS)-type algorithms for estimating modes of probability density functions (PDFs), via regarding these algorithms as gradient ascent on estimated PDFs with adaptive step sizes. We rigorously prove convergence of mode estimate sequences generated by the MS-type algorithms, under the assumption that an analytic kernel function is used. Moreover, our analysis on the MS function finds several new properties of mode estimate sequences and corresponding density estimate sequences, including the result that in the MS-type algorithm using a Gaussian kernel the density estimate monotonically increases between two consecutive mode estimates. This implies that, in the one-dimensional case, the mode estimate sequence monotonically converges to the stationary point nearest to an initial point without jumping over any stationary point.	[Yamasaki, Ryoya; Tanaka, Toshiyuki] Kyoto Univ, Grad Sch Informat, Dept Syst Sci, Kyoto 6068501, Japan	Kyoto University	Yamasaki, R (corresponding author), Kyoto Univ, Grad Sch Informat, Dept Syst Sci, Kyoto 6068501, Japan.	yamasaki@sys.i.kyoto-u.ac.jp; tt@i.kyoto-u.ac.jp	Tanaka, Toshiyuki/C-2749-2011	Yamasaki, Ryoya/0000-0002-4063-8311	MEXT/JSPS KAKENHI [JP25120008, JP16H02878]	MEXT/JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	This work was supported in part by MEXT/JSPS KAKENHI Grant Numbers JP25120008 and JP16H02878.	Absil PA, 2005, SIAM J OPTIMIZ, V16, P531, DOI 10.1137/040605266; Amendola C., 2017, ARXIV170205066V2MATH; [Anonymous], 2018, INT J LOW EXTR WOUND, DOI DOI 10.1177/1534734617750803; [Anonymous], 2017, PR MACH LEARN RES; [Anonymous], 2013, PATTERN RECOGNIT LET, DOI DOI 10.1016/J.PATREC.2013.05.004; [Anonymous], 2013, PATTERN RECOGN, DOI DOI 10.1016/J.PATCOG.2013.04.014; [Anonymous], 2005, PROC CVPR IEEE; Arias-Castro E, 2016, J MACH LEARN RES, V17; Azizyan M., 2015, ARXIV150500482V1MATH; BOYLES RA, 1983, J ROY STAT SOC B MET, V45, P47; Carreira-Perpinan M. A., 2003, EDIINFRR0159 U ED SC; Carreira-Perpinan MA, 2003, LECT NOTES COMPUT SC, V2695, P625; Carreira-Perpinan MA, 2007, IEEE T PATTERN ANAL, V29, P767, DOI 10.1109/TPAMI.2007.1057; Chacon J. E., 2018, ADV DATA ANAL CLASSI, V12, P1; Chacon JE, 2013, ELECTRON J STAT, V7, P499, DOI 10.1214/13-EJS781; Chen Y., 2014, WATER RESOURCES RES; Chen YC, 2016, ANN STAT, V44, P489, DOI 10.1214/15-AOS1373; Chen YC, 2015, MON NOT R ASTRON SOC, V454, P1140, DOI 10.1093/mnras/stv1996; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Einbeck J, 2006, J R STAT SOC C-APPL, V55, P461, DOI 10.1111/j.1467-9876.2006.00547.x; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Ghassabeh YA, 2015, J MULTIVARIATE ANAL, V135, P1, DOI 10.1016/j.jmva.2014.11.009; Guo H., 2005, P INT C NEUR NETW BR, P1118; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hyndman RJ, 1996, J COMPUT GRAPH STAT, V5, P315; Knopp K., 1956, DOVER BOOKS MATH; Li XG, 2007, PATTERN RECOGN, V40, P1756, DOI 10.1016/j.patcog.2006.10.016; Lichman M, 2013, UCI MACHINE LEARNING; Ozertem U, 2011, J MACH LEARN RES, V12, P1249; Salakhutdinov R., 2003, P INT C MACH LEARN, P664; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Sasaki H, 2016, LECT NOTES COMPUT SC, V9948, P108, DOI 10.1007/978-3-319-46672-9_13; Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249; Wu KL, 2007, PATTERN RECOGN, V40, P3035, DOI 10.1016/j.patcog.2007.02.006; Yang C., 2003, P INT C IM PROC, P447; YOUNG D, 1954, T AM MATH SOC, V76, P92, DOI 10.2307/1990745; Zhu Y., 2009, P INT C COMP SCI ENG, P1034	39	6	7	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2273	2286		10.1109/TPAMI.2019.2913640	http://dx.doi.org/10.1109/TPAMI.2019.2913640			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	31034409	Green Published			2022-12-18	WOS:000557354900014
J	Dong, MZ; Wang, YJ; Yang, XC; Xue, JH				Dong, Mingzhi; Wang, Yujiang; Yang, Xiaochen; Xue, Jing-Hao			Learning Local Metrics and Influential Regions for Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Measurement; Task analysis; Learning systems; Mathematical model; Fasteners; Artificial neural networks; Clustering algorithms; Distance-based classification; distance metric; metric learning; local metric		The performance of distance-based classifiers heavily depends on the underlying distance metric, so it is valuable to learn a suitable metric from the data. To address the problem of multimodality, it is desirable to learn local metrics. In this short paper, we define a new intuitive distance with local metrics and influential regions, and subsequently propose a novel local metric learning algorithm called LMLIR for distance-based classification. Our key intuition is to partition the metric space into influential regions and a background region, and then regulate the effectiveness of each local metric to be within the related influential regions. We learn multiple local metrics and influential regions to reduce the empirical hinge loss, and regularize the parameters on the basis of a resultant learning bound. Encouraging experimental results are obtained from various public and popular data sets.	[Dong, Mingzhi; Yang, Xiaochen; Xue, Jing-Hao] UCL, Dept Stat Sci, London WC1E 6BT, England; [Wang, Yujiang] Imperial Coll London, Dept Comp, London SW7 2AZ, England	University of London; University College London; Imperial College London	Xue, JH (corresponding author), UCL, Dept Stat Sci, London WC1E 6BT, England.	mingzhi.dong.13@ucl.ac.uk; yujiang.wang14@imperial.ac.uk; xiaochen.yang.16@ucl.ac.uk; jinghao.xue@ucl.ac.uk		Wang, Yujiang/0000-0002-6220-029X; Xue, Jing-Hao/0000-0003-1174-610X; Yang, Xiaochen/0000-0002-9299-5951				[Anonymous], 2015, P ICCV WORKSH; Nguyen B, 2017, PATTERN RECOGN, V64, P215, DOI 10.1016/j.patcog.2016.11.010; Bohne J, 2014, LECT NOTES COMPUT SC, V8690, P679, DOI 10.1007/978-3-319-10605-2_44; Cao Q, 2016, MACH LEARN, V102, P115, DOI 10.1007/s10994-015-5499-7; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]; Frome A, 2007, IEEE I CONF COMP VIS, P94; Gottlieb LA, 2014, IEEE T INFORM THEORY, V60, P5750, DOI 10.1109/TIT.2014.2339840; Guo ZC, 2014, NEURAL COMPUT, V26, P497, DOI 10.1162/NECO_a_00556; Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Huang ZW, 2018, IEEE T PATTERN ANAL, V40, P2827, DOI 10.1109/TPAMI.2017.2776154; Jin R., 2009, ADV NEURAL INFORM PR, V22; Kusner MJ, 2014, PR MACH LEARN RES, V32, P622; Lachmann K, 2013, AISTECH, P2249; Liu WW, 2019, IEEE T PATTERN ANAL, V41, P408, DOI 10.1109/TPAMI.2018.2794976; Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717; Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134; Mu Y, 2013, PATTERN RECOGN, V46, P2337, DOI 10.1016/j.patcog.2013.01.010; Noh YK, 2018, IEEE T PATTERN ANAL, V40, P106, DOI 10.1109/TPAMI.2017.2666151; Perrot M., 2015, ADV NEURAL INFORM PR, P1810; Russell S. J, 2002, ADV NEURAL INFORM PR, P12, DOI DOI 10.5555/2968618.2968683; Shi Y, 2014, AAAI CONF ARTIF INTE, P2078; St Amand J, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1097, DOI 10.1145/3097983.3098153; Verma N., 2015, ADV NEURAL INFORM PR, P2584; Wang B, 2017, IEEE T PATTERN ANAL, V39, P589, DOI 10.1109/TPAMI.2016.2551245; Wang Jun, 2012, ADV NEURAL INF PROCE, V25, P1601; Weaver N., 1999, LIPSCHITZ ALGEBRAS; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Yang L, 2010, IEEE T PATTERN ANAL, V32, P30, DOI 10.1109/TPAMI.2008.273; Ying YM, 2012, J MACH LEARN RES, V13, P1; Zadeh PH, 2016, PR MACH LEARN RES, V48	31	6	6	3	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1522	1529		10.1109/TPAMI.2019.2914899	http://dx.doi.org/10.1109/TPAMI.2019.2914899			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	31059429	Green Submitted, Green Accepted			2022-12-18	WOS:000535615700017
J	Zou, DQ; Chen, XW; Cao, GY; Wang, XG				Zou, Dongqing; Chen, Xiaowu; Cao, Guangying; Wang, Xiaogang			Unsupervised Video Matting via Sparse and Low-Rank Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optical imaging; Dictionaries; Image color analysis; Streaming media; Topology; Geometrical optics; Benchmark testing; Video matting; image matting; sparse representation; low-rank; unsupervised; discriminative dictionary	IMAGE SUPERRESOLUTION	A novel method, unsupervised video matting via sparse and low-rank representation, is proposed which can achieve high quality in a variety of challenging examples featuring illumination changes, feature ambiguity, topology changes, transparency variation, dis-occlusion, fast motion and motion blur. Some previous matting methods introduced a nonlocal prior to search samples for estimating the alpha matte, which have achieved impressive results on some data. However, on one hand, searching inadequate or excessive samples may miss good samples or introduce noise; on the other hand, it is difficult to construct consistent nonlocal structures for pixels with similar features, yielding video mattes with spatial and temporal inconsistency. In this paper, we proposed a novel video matting method to achieve spatially and temporally consistent matting result. Toward this end, a sparse and low-rank representation model is introduced to pursue consistent nonlocal structures for pixels with similar features. The sparse representation is used to adaptively select best samples and accurately construct the nonlocal structures for all pixels, while the low-rank representation is used to globally ensure consistent nonlocal structures for pixels with similar features. The two representations are combined to generate spatially and temporally consistent video mattes. We test our method on lots of dataset including the benchmark dataset for image matting and dataset for video matting. Our method has achieved the best performance among all unsupervised matting methods in the public alpha matting evaluation dataset for images.	[Zou, Dongqing; Chen, Xiaowu; Cao, Guangying; Wang, Xiaogang] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Key Lab Visual Comp & Human Machine Intelligence, Sch Comp Sci & Engn,Minist Ind & Informat Technol, Beijing 100191, Peoples R China	Beihang University	Chen, XW (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Key Lab Visual Comp & Human Machine Intelligence, Sch Comp Sci & Engn,Minist Ind & Informat Technol, Beijing 100191, Peoples R China.	dqzou@buaa.edu.cn; chen@buaa.edu.cn; cgy@buaa.edu.cn; wangxiaogang@buaa.edu.cn			NSFC [61532003, 61421003]; Beijing Advanced Innovation Center for Big Data and Brain Computing	NSFC(National Natural Science Foundation of China (NSFC)); Beijing Advanced Innovation Center for Big Data and Brain Computing	We thank the reviewers for their valuable feedback, and thank Yifan Zhao and Jianwei Li for discussion and making supplements. This work is supported in part by grants from NSFC (61532003, 61421003), and Beijing Advanced Innovation Center for Big Data and Brain Computing.	[Anonymous], 2008, 5 EUR C VIS MED PROD; [Anonymous], [No title captured]; Apostoloff N, 2004, PROC CVPR IEEE, P407; Bai X, 2011, LECT NOTES COMPUT SC, V6930, P63; Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376; Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Cevher V, 2008, LECT NOTES COMPUT SC, V5303, P155, DOI 10.1007/978-3-540-88688-4_12; Chai ML, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461990; Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981; Chen QF, 2012, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2012.6247760; Chen XW, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366151; Cheng E, 2014, PROC CVPR IEEE, P3057, DOI 10.1109/CVPR.2014.391; Cho D, 2016, LECT NOTES COMPUT SC, V9906, P626, DOI 10.1007/978-3-319-46475-6_39; Choi I, 2012, LECT NOTES COMPUT SC, V7577, P540, DOI 10.1007/978-3-642-33783-3_39; Chuang YY, 2001, PROC CVPR IEEE, P264; Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572; Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x; Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; Johnson J., 2014, P BRIT MACH VIS C, P245; Johnson J, 2016, IEEE T IMAGE PROCESS, V25, P3032, DOI 10.1109/TIP.2016.2555705; Joshi N, 2006, ACM T GRAPHIC, V25, P779, DOI 10.1145/1141911.1141955; Ju JL, 2013, COMPUT GRAPH FORUM, V32, P245, DOI 10.1111/cgf.12232; Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495; Karacan L, 2015, IEEE I CONF COMP VIS, P424, DOI 10.1109/ICCV.2015.56; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lee SY, 2010, GRAPH MODELS, V72, P25, DOI 10.1016/j.gmod.2010.03.001; Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Li DZY, 2013, IEEE I CONF COMP VIS, P3599, DOI 10.1109/ICCV.2013.447; Li JW, 2015, IEEE I CONF COMP VIS, P235, DOI 10.1109/ICCV.2015.35; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Mairal J, 2008, PROC CVPR IEEE, P2415; Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653; McGuire M, 2005, ACM T GRAPHIC, V24, P567, DOI 10.1145/1073204.1073231; Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964; Ruzon MA, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.855793; Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88; Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758; Shen X, 2016, LECT NOTES COMPUT SC, V9905, P92, DOI 10.1007/978-3-319-46448-0_6; Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721; Sun J, 2006, ACM T GRAPHIC, V25, P772, DOI 10.1145/1141911.1141954; Wang J, 2007, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, P90, DOI 10.1109/ISDA.2007.66; Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019; Wang LB, 2014, COMPUT GRAPH-UK, V38, P131, DOI 10.1016/j.cag.2013.10.014; Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363; Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360; Zhang CJ, 2011, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2011.5995484; Zhang Y, 2008, PROC CVPR IEEE, P125; Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326; Zou DQ, 2015, IEEE I CONF COMP VIS, P1564, DOI 10.1109/ICCV.2015.183	63	6	6	3	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1501	1514		10.1109/TPAMI.2019.2895331	http://dx.doi.org/10.1109/TPAMI.2019.2895331			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30703008				2022-12-18	WOS:000535615700015
J	Cho, D; Matsushita, Y; Tai, YW; Kweon, IS				Cho, Donghyeon; Matsushita, Yasuyuki; Tai, Yu-Wing; Kweon, In So			Semi-Calibrated Photometric Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Light sources; Calibration; Robustness; Cameras; Minimization; Pattern recognition; Machine intelligence; Photometric stereo; light intensity; exposure; surface normal	SHAPE; REFLECTIONS; REGRESSION; GEOMETRY; OBJECTS; CAMERA	While conventional calibrated photometric stereo methods assume that light intensities and sensor exposures are known or unknown but identical across observed images, this assumption easily breaks down in practical settings due to individual light bulbs characteristics and limited control over sensors. This paper studies the effect of unknown and possibly non-uniform light intensities and sensor exposures among observed images on the shape recovery based on photometric stereo. This leads to the development of a "semi-calibrated" photometric stereo method, where the light directions are known but light intensities (and sensor exposures) are unknown. We show that the semi-calibrated photometric stereo becomes a bilinear problem, whose general form is difficult to solve, but in the photometric stereo context, there exists a unique solution for the surface normal and light intensities (or sensor exposures). We further show that there exists a linear solution method for the problem, and develop efficient and stable solution methods. The semi-calibrated photometric stereo is advantageous over conventional calibrated photometric stereo in accurate determination of surface normal, because it relaxes the assumption of known light intensity ratios/sensor exposures. The experimental results show superior accuracy of the semi-calibrated photometric stereo in comparison to conventional methods in practical settings.	[Cho, Donghyeon] CNU, Daejeon, South Korea; [Matsushita, Yasuyuki] Osaka Univ, Suita, Osaka 5650871, Japan; [Tai, Yu-Wing] Tencent Youtu, Hong Kong, Peoples R China; [Kweon, In So] Korea Adv Inst Sci & Technol, EE Dept, Daejeon, South Korea	Osaka University; Korea Advanced Institute of Science & Technology (KAIST)	Kweon, IS (corresponding author), Korea Adv Inst Sci & Technol, EE Dept, Daejeon, South Korea.	cdh12242@cnu.ac.kr; yasumat@ist.osaka-u.ac.jp; yuwing@gmail.com; iskweon@kaist.ac.kr	Cho, DongHyeon/AAL-9874-2020; Tai, Yuwing/C-2047-2011	Tai, Yuwing/0000-0002-3148-0380; Matsushita, Yasuyui/0000-0002-1935-4752	JSPS KAKENHI [JP16H01732]; National Research Foundation of Korea (NRF) - Korea government (MSIP) [2010-0028680]	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); National Research Foundation of Korea (NRF) - Korea government (MSIP)(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea)	This work was supported by JSPS KAKENHI Grant Number JP16H01732 and the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2010-0028680).	Abrams A, 2012, LECT NOTES COMPUT SC, V7573, P357, DOI 10.1007/978-3-642-33709-3_26; Ackermann J, 2012, PROC CVPR IEEE, P262, DOI 10.1109/CVPR.2012.6247684; Alldrin NG, 2007, PROC CVPR IEEE, P1822; [Anonymous], [No title captured]; [Anonymous], 2007, P COMP VIS PATT REC; [Anonymous], [No title captured]; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Bezdek J. C., 2003, Neural, Parallel & Scientific Computations, V11, P351; Chandraker M, 2007, IEEE I CONF COMP VIS, P2236; Chandraker MK, 2005, PROC CVPR IEEE, P788; Chen CC, 2006, INT J DISTANCE EDUC, V4, P72, DOI 10.4018/jdet.2006040106; Cho D, 2016, LECT NOTES COMPUT SC, V9906, P170, DOI 10.1007/978-3-319-46475-6_11; Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819; Drbohlav O, 2005, IEEE I CONF COMP VIS, P1850; Favaro P, 2012, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2012.6247754; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; Higo T, 2009, IEEE I CONF COMP VIS, P1234, DOI 10.1109/ICCV.2009.5459331; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Ikehata S, 2014, PROC CVPR IEEE, P2187, DOI 10.1109/CVPR.2014.280; Ikehata S, 2014, IEEE T PATTERN ANAL, V36, P1816, DOI 10.1109/TPAMI.2014.2299798; Iwahori Y., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P83, DOI 10.1109/ICPR.1990.118069; IWAHORI Y, 1993, IEEE IJCNN, P1181; KAMGARPARSI B, 1989, IEEE T PATTERN ANAL, V11, P929, DOI 10.1109/34.35496; Kriegman DJ, 2001, J OPT SOC AM A, V18, P1804, DOI 10.1364/JOSAA.18.001804; Lee JY, 2013, IEEE T PATTERN ANAL, V35, P144, DOI 10.1109/TPAMI.2012.66; Lin S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P855, DOI 10.1109/ICCV.1999.790311; Logothetis F, 2017, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2017.481; Luenberger D. G., 2015, LINEAR NONLINEAR PRO; Malzbender T, 2006, EUROGRAPHICS S RENDE, P245; Mukaigawa Y, 2007, J OPT SOC AM A, V24, P3326, DOI 10.1364/JOSAA.24.003326; Oh TH, 2013, IEEE I CONF COMP VIS, P145, DOI 10.1109/ICCV.2013.25; ONN R, 1990, INT J COMPUT VISION, V5, P105, DOI 10.1007/BF00056773; Papadhimitri T., 2014, PROC BRIT MACH VIS C, P1; Papadhimitri T, 2013, PROC CVPR IEEE, P1474, DOI 10.1109/CVPR.2013.194; Park J, 2014, PROC CVPR IEEE, P2267, DOI 10.1109/CVPR.2014.290; Powell MW, 2001, IEEE T PATTERN ANAL, V23, P1022, DOI 10.1109/34.955114; Queau Y, 2018, J MATH IMAGING VIS, V60, P313, DOI 10.1007/s10851-017-0761-1; Queau Y, 2017, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.2017.45; Queau Y, 2017, LECT NOTES COMPUT SC, V10302, P656, DOI 10.1007/978-3-319-58771-4_52; Sakaue Fumihiko, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P759, DOI 10.1109/ICCVW.2011.6130329; Schnieders D, 2013, COMPUT VIS IMAGE UND, V117, P1536, DOI 10.1016/j.cviu.2013.06.004; Shen HL, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3533326; Shi BX, 2016, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2016.403; Shi BX, 2014, IEEE T PATTERN ANAL, V36, P1078, DOI 10.1109/TPAMI.2013.196; Shi BX, 2010, PROC CVPR IEEE, P1118, DOI 10.1109/CVPR.2010.5540091; Silver W.M., 1980, THESIS; Simakov D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1202; Solomon F, 1996, IEEE T PATTERN ANAL, V18, P449, DOI 10.1109/34.491627; Sunkavalli K, 2010, LECT NOTES COMPUT SC, V6312, P251, DOI 10.1007/978-3-642-15552-9_19; Sylvester J., 1884, CR HEBD ACAD SCI, V99, P67; Verbiest F., 2008, P IEEE C COMP VIS PA, P1; Wong KYK, 2008, LECT NOTES COMPUT SC, V5302, P631, DOI 10.1007/978-3-540-88682-2_48; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Wu TP, 2006, IEEE T PATTERN ANAL, V28, P1830, DOI 10.1109/TPAMI.2006.224; Wu TP, 2010, IEEE T PATTERN ANAL, V32, P546, DOI 10.1109/TPAMI.2009.15; Wu Z, 2013, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2013.197; Xie WY, 2015, PROC CVPR IEEE, P4585, DOI 10.1109/CVPR.2015.7299089; Xie WY, 2014, PROC CVPR IEEE, P2203, DOI 10.1109/CVPR.2014.282; Yu LF, 2013, IEEE INT CONF COMPUT, DOI 10.1109/ICCPhot.2013.6528306; Yuille AL, 1999, INT J COMPUT VISION, V35, P203, DOI 10.1023/A:1008180726317	62	6	6	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					232	245		10.1109/TPAMI.2018.2873295	http://dx.doi.org/10.1109/TPAMI.2018.2873295			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30281438				2022-12-18	WOS:000502294300018
J	Arn, RT; Narayana, P; Emerson, T; Draper, BA; Kirby, M; Peterson, C				Arn, Robert T.; Narayana, Pradyumna; Emerson, Tegan; Draper, Bruce A.; Kirby, Michael; Peterson, Chris			Motion Segmentation via Generalized Curvatures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion segmentation; Computer vision; Approximation algorithms; Trajectory; Sensors; Noise measurement; Tools; Generalized curvature analysis; local SVD; motion segmentation; video segmentation	FRENET-SERRET; RECOGNITION	New depth sensors, like the Microsoft Kinect, produce streams of human pose data. These discrete pose streams can be viewed as noisy samples of an underlying continuous ideal curve that describes a trajectory through high-dimensional pose space. This paper introduces a technique for generalized curvature analysis (GCA) that determines features along the trajectory which can be used to characterize change and segment motion. Tools are developed for approximating generalized curvatures at mean points along a curve in terms of the singular values of local mean-centered data balls. The features of the GCA algorithm are illustrated on both synthetic and real examples, including data collected from a Kinect II sensor. We also applied GCA to the Carnegie Mellon University Motion Capture (MoCaP) database. Given that GCA scales linearly with the length of the time series we are able to analyze large data sets without down sampling. It is demonstrated that the generalized curvature approximations can be used to segment pose streams into motions and transitions between motions. The GCA algorithm can identify 94.2 percent of the transitions between motions without knowing the set of possible motions in advance, even though the subjects do not stop or pause between motions.	[Arn, Robert T.; Emerson, Tegan; Kirby, Michael; Peterson, Chris] Colorado State Univ, Dept Math, Ft Collins, CO 80523 USA; [Narayana, Pradyumna; Draper, Bruce A.] Colorado State Univ, Dept Comp Sci, Ft Collins, CO 80523 USA	Colorado State University; Colorado State University	Kirby, M (corresponding author), Colorado State Univ, Dept Math, Ft Collins, CO 80523 USA.	astroarn@gmail.com; prady@cs.colostate.edu; teganemerson@gmail.com; draper@cs.colostate.edu; kirby@math.colostate.edu; peterson@math.colostate.edu		Peterson, Chris/0000-0002-3982-6876	US National Science Foundation [DMS-1322508]; Defense Advanced Projects Research Agency (DARPA); U.S. Army Research Laboratory (ARL) [W911NF-15-1-0459]	US National Science Foundation(National Science Foundation (NSF)); Defense Advanced Projects Research Agency (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); U.S. Army Research Laboratory (ARL)(United States Department of DefenseUS Army Research Laboratory (ARL))	This paper is based on research partially supported by the US National Science Foundation under Grant No. DMS-1322508, and the Defense Advanced Projects Research Agency (DARPA) and the U.S. Army Research Laboratory (ARL) under contract W911NF-15-1-0459. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.	Alvarez-Vizoso X., 2017, ARXIV151105008V2; Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020; BRONSVOORT WF, 1985, ACM T GRAPHIC, V4, P291, DOI 10.1145/6116.6118; Chern S.-S, 1985, ASTERIQUE, V1985, P67; Ding WW, 2016, J VIS COMMUN IMAGE R, V35, P103, DOI 10.1016/j.jvcir.2015.12.006; Duric Z, 1998, IMAGE VISION COMPUT, V16, P785, DOI 10.1016/S0262-8856(98)00070-5; DURIC Z, 1995, INT J COMPUT VISION, V15, P105, DOI 10.1007/BF01450851; Duric Z, 2002, PATTERN RECOGN, V35, P1339, DOI 10.1016/S0031-3203(01)00119-4; Faugeras O., 1994, CARTANS MOVING FRAME; Firman M, 2016, IEEE COMPUT SOC CONF, P661, DOI 10.1109/CVPRW.2016.88; Golub G. H., 2012, MATRIX COMPUTATIONS, V3; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Huang SZ, 2013, CHIN CONTR CONF, P5877; Kim KR, 2013, IEEE J-STSP, V7, P646, DOI 10.1109/JSTSP.2012.2232280; Kirby M., 2000, GEOMETRIC DATA ANAL; Koenderink J., 1990, SOLID SHAPE; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Kruger B, 2017, IEEE T MULTIMEDIA, V19, P797, DOI 10.1109/TMM.2016.2635030; Kuhnel W., 2006, DIFFERENTIAL GEOMETR, V16; Lillo I, 2014, PROC CVPR IEEE, P812, DOI 10.1109/CVPR.2014.109; Lin CD, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, VOLS 1 AND 2, P1; Lu Xia, 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233; Miranda L, 2014, PATTERN RECOGN LETT, V39, P65, DOI 10.1016/j.patrec.2013.10.005; Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007; Pegna J, 1987, THESIS STANFORD U US; Qu CZ, 2005, LECT NOTES COMPUT SC, V3519, P139; Raptis M., 2011, P 2011 ACM SIGGRAPH, P147, DOI DOI 10.1145/2019406.2019426; Shan JJ, 2014, 2014 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P69, DOI 10.1109/ARSO.2014.7020983; Simon F., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303; Solis FJ, 2000, APPL MATH OPT, V41, P331, DOI 10.1007/s0024599110160; Spivak M., 1975, DIFFERENTIAL GEOMETR, V1, P2; Tang C., 2015, INFO SCI, V467, P219; Vochten M, 2015, IEEE INT CONF ROBOT, P3010, DOI 10.1109/ICRA.2015.7139612; Vogele A., 2014, P ACM SIGGRAPH EUR S, P167, DOI DOI 10.2312/SCA.20141135; Wagner MG, 1997, COMPUT AIDED GEOM D, V15, P79, DOI 10.1016/S0167-8396(97)81786-4; Wang WC, 2015, IEEE INT SYMP CIRC S, P1198, DOI 10.1109/ISCAS.2015.7168854; Zerroug M., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P96, DOI 10.1109/CVPR.1993.340973; Zhang XF, 2014, INTERNATIONAL CONFERENCE ON MECHANICAL DESIGN, MANUFACTURE AND AUTOMATION ENGINEERING (MDMAE 2014), P56; Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24; Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137; Zhu GM, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020161; Zucker S, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P359	42	6	6	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2919	2932		10.1109/TPAMI.2018.2869741	http://dx.doi.org/10.1109/TPAMI.2018.2869741			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30222550				2022-12-18	WOS:000498677600010
J	Kimia, BB; Li, XY; Guo, YL; Tamrakar, A				Kimia, Benjamin B.; Li, Xiaoyan; Guo, Yuliang; Tamrakar, Amir			Differential Geometry in Edge Detection: Accurate Estimation of Position, Orientation and Curvature	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Edge detection; differential geometry; third-order; localization; orientation; curvature; topology	COLOR	The vast majority of edge detection literature has aimed at improving edge recall and precision, with relatively few addressing the accuracy of edge orientation estimates which are often based on gradient. We show that first-order estimates of orientation can have significant error and this can be remedied by employing Third-Order estimates. This paper aims at estimating differential geometry attributes of an edge, namely, localization, orientation, and curvature, as well as edge topology, and develop robust numerical techniques in gray-scale and color images, applicable to a variety of popular edge detectors, such as gradient-based, gPb and SE. Second, a combinatorial model of edge grouping in a small neighborhood is developed to capture all geometrically consistent grouping called curvets, which establish: (i) edge topology in the form of potential links between an edge and other edges; (ii) an accurate curvature estimate for each possible grouping, whose performance is comparable to methods which use global and multi-scale methods; (iii) a more accurate localization of an edge. These have been evaluated using four distinct methodologies (i) traditional human annotated datasets; (ii) using coherence measure; (iii) stability analysis under visual perturbation, and (iv) utilitarian evaluation, and show meaningful improvements.	[Kimia, Benjamin B.] Brown Univ, Sch Engn, Providence, RI 02912 USA; [Li, Xiaoyan; Guo, Yuliang] Brown Univ, Providence, RI 02912 USA; [Tamrakar, Amir] SRI Int, 333 Ravenswood Ave, Menlo Pk, CA 94025 USA	Brown University; Brown University; SRI International	Guo, YL (corresponding author), Brown Univ, Providence, RI 02912 USA.	benjamin_kimia@brown.edu; xiaoyan_li_1@brown.edu; yuliang_guo@brown.edu; amir.tamrakar@sri.com	Guo, Yuliang/X-5920-2019; Li, Xiaoyan/B-7325-2008	Guo, Yuliang/0000-0002-1934-0027; Li, Xiaoyan/0000-0002-2953-9267	NSF [1319914]	NSF(National Science Foundation (NSF))	The authors gratefully acknowledge the support of NSF award 1319914.	Adhikari VK, 2012, IEEE CONF COMPUT, P7, DOI 10.1109/INFCOMW.2012.6193524; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Baker S., 1999, P IEEE COMP SOC C CO; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DOBBINS A, 1987, NATURE, V329, P438, DOI 10.1038/329438a0; Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb P., 2006, IEEE C COMP VIS PATT, V2006, P185, DOI DOI 10.1109/CVPRW.2006.18; Fisher R. B., 1996, IMAGE TECHNOLOGY, DOI [10.1007/978-3-642-58288-2_15, DOI 10.1007/978-3-642-58288-2_15]; Fleet D., 2014, LECT NOTES COMPUTER, V8695; Guo YL, 2014, LECT NOTES COMPUT SC, V8689, P663, DOI 10.1007/978-3-319-10590-1_43; HARRIS M, 1988, NEW YORK TIMES BK R, P1; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; Kennedy R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2065, DOI 10.1109/CVPR.2011.5995739; Kimia BB, 2003, INT J COMPUT VISION, V54, P157, DOI 10.1023/A:1023713602895; Kokkinos I, 2010, PROC CVPR IEEE, P2520, DOI 10.1109/CVPR.2010.5539956; Mairal J, 2008, LECT NOTES COMPUT SC, V5304, P43, DOI 10.1007/978-3-540-88690-7_4; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mortensen E., 1999, P IEEE COMP SOC C CO; Narayanan M., 2012, P IEEE WORKSH PERC O, P47; Ofir N, 2016, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2016.30; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Roberts L. G., 1963, THESIS NEW YORK; ROTHWELL CA, 1995, INT J COMPUT VISION, V16, P57, DOI 10.1007/BF01428193; Roussillon T, 2011, LECT NOTES COMPUT SC, V6636, P43, DOI 10.1007/978-3-642-21073-0_7; Ruzon MA, 2001, IEEE T PATTERN ANAL, V23, P1281, DOI 10.1109/34.969118; Xiaofeng R., 2012, P ADV NEUR INF PROC, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26; Zucker SW, 1989, NEURAL COMPUT, V1, P68, DOI 10.1162/neco.1989.1.1.68; 1999, CVPR 99 IEEE COMP SO	31	6	6	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1573	1586		10.1109/TPAMI.2018.2846268	http://dx.doi.org/10.1109/TPAMI.2018.2846268			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29994245				2022-12-18	WOS:000470972300004
J	Liang, KM; Chang, H; Ma, BP; Shan, SG; Chen, XL				Liang, Kongming; Chang, Hong; Ma, Bingpeng; Shan, Shiguang; Chen, Xilin			Unifying Visual Attribute Learning with Object Recognition in a Multiplicative Framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Attribute learning; zero-shot learning; image understanding	LATE FUSION; CLASSIFICATION	Attributes are mid-level semantic properties of objects. Recent research has shown that visual attributes can benefit many typical learning problems in computer vision community. However, attribute learning is still a challenging problem as the attributes may not always be predictable directly from input images and the variation of visual attributes is sometimes large across categories. In this paper, we propose a unified multiplicative framework for attribute learning, which tackles the key problems. Specifically, images and category information are jointly projected into a shared feature space, where the latent factors are disentangled and multiplied to fulfil attribute prediction. The resulting attribute classifier is category-specific instead of being shared by all categories. Moreover, our model can leverage auxiliary data to enhance the predictive ability of attribute classifiers, which can reduce the effort of instance-level attribute annotation to some extent. By integrated into an existing deep learning framework, our model can both accurately predict attributes and learn efficient image representations. Experimental results show that our method achieves superior performance on both instance-level and category-level attribute prediction. For zero-shot learning based on visual attributes and human-object interaction recognition, our method can improve the state-of-the-art performance on several widely used datasets.	[Liang, Kongming; Chang, Hong; Ma, Bingpeng; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China; [Liang, Kongming; Chang, Hong; Ma, Bingpeng; Shan, Shiguang; Chen, Xilin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Shan, Shiguang] Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Beijing, Peoples R China	Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences	Chang, H (corresponding author), Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China.; Chang, H (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.	kongming.liang@vipl.ict.ac.cn; changhong@ict.ac.cn; bingpeng.ma@vipl.ict.ac.cn; sgshan@ict.ac.cn; xlchen@ict.ac.cn		Shan, Shiguang/0000-0002-8348-392X	973 Program [2015CB351802]; Natural Science Foundation of China (NSFC) [61390515, 61390511, 61572465, 61650202]	973 Program(National Basic Research Program of China); Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work is partially supported by 973 Program under contract No. 2015CB351802, and Natural Science Foundation of China (NSFC): 61390515, 61390511, 61572465 and 61650202.	Akata Z., 2014, ARXIV14098403; Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2011, TECH REP CNS T 2011; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Ba JL, 2015, IEEE I CONF COMP VIS, P4247, DOI 10.1109/ICCV.2015.483; Bengio S, 2015, ADV NEURAL INFORM PR, V1, P1171; Bi JB, 2008, LECT NOTES ARTIF INT, V5211, P117; Chao YW, 2015, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2015.122; Chen CY, 2014, PROC CVPR IEEE, P200, DOI 10.1109/CVPR.2014.33; Chen L, 2014, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2014.135; Chen X., 2014, P 27 ANN C NEURAL IN, P1736, DOI DOI 10.1109/CVPR.2018.00742; Donahue J, 2014, PR MACH LEARN RES, V32; Dong Y, 2014, PATTERN ANAL APPL, V17, P37, DOI 10.1007/s10044-013-0336-8; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Freeman WT, 1997, PROC CVPR IEEE, P554, DOI 10.1109/CVPR.1997.609380; Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354; Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38; Gan C, 2016, PROC CVPR IEEE, P87, DOI 10.1109/CVPR.2016.17; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang S, 2015, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2015.7298638; Hwang SJ, 2011, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2011.5995543; Hwang Sung Ju, 2014, ADV NEURAL INFORM PR, P271; Jayaraman D, 2014, ADV NEUR IN, V27; Jayaraman D, 2014, PROC CVPR IEEE, P1629, DOI 10.1109/CVPR.2014.211; Kemp C., 2006, P 21 NAT C ART INT; Kiros R., 2014, NIPS 14, P2348; Kiros R, 2014, PR MACH LEARN RES, V32, P595; Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lampert C., 2011, SEMANTIC ATTRIBUTES; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu D, 2013, PROC CVPR IEEE, P803, DOI 10.1109/CVPR.2013.109; Liu JC, 2012, LECT NOTES COMPUT SC, V7576, P397, DOI [10.1007/978-3-642-33715-4_29, 10.1007/978-3-642-33167-1_23]; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Nandakumar K, 2008, IEEE T PATTERN ANAL, V30, P342, DOI 10.1109/TPAMI.2007.70796; OSHERSON DN, 1991, COGNITIVE SCI, V15, P251, DOI 10.1207/s15516709cog1502_3; Ouyang WL, 2015, IEEE I CONF COMP VIS, P1895, DOI 10.1109/ICCV.2015.220; Terrades OR, 2009, IEEE T PATTERN ANAL, V31, P1630, DOI 10.1109/TPAMI.2008.224; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Russakovsky Olga, 2010, TRENDS TOPICS COMPUT, P1, DOI DOI 10.1007/978-3-642-35749-7_1; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Shankar S, 2015, PROC CVPR IEEE, P3403, DOI 10.1109/CVPR.2015.7298962; Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Wang X., 2014, ADV NEURAL INFORM PR, P2411; Wang XY, 2013, IEEE I CONF COMP VIS, P2120, DOI 10.1109/ICCV.2013.264; Wang YJ, 2010, PRODUCTION GRIDS IN ASIA: APPLICATIONS, DEVELOPMENTS AND GLOBAL TIES, P155, DOI 10.1007/978-1-4419-0046-3_13; Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368; Ye GN, 2012, PROC CVPR IEEE, P3021, DOI 10.1109/CVPR.2012.6248032; Zeiler M. D., 2014, P EUR C COMPUT VIS, P740; Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54	57	6	6	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1747	1760		10.1109/TPAMI.2018.2836461	http://dx.doi.org/10.1109/TPAMI.2018.2836461			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29994330				2022-12-18	WOS:000470972300017
J	Li, C; Zhou, K; Wu, HT; Lin, S				Li, Chen; Zhou, Kun; Wu, Hsiang-Tao; Lin, Stephen			Physically-Based Simulation of Cosmetics via Intrinsic Image Decomposition with Facial Priors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Digital cosmetics; intrinsic image decomposition; human face priors	SPECULAR REFLECTION; COLOR; APPEARANCE; SKIN	We present a physically-based approach for simulating makeup in face images. The key idea is to decompose the face image into intrinsic image layers - namely albedo, diffuse shading, and specular highlights - which are each differently affected by cosmetics, and then manipulate each layer according to corresponding models of reflectance. Accurate intrinsic image decompositions for faces are obtained with the help of human face priors, including statistics on skin reflectance and facial geometry. The intrinsic image layers are then transformed in appearance according to measured optical properties of cosmetics and proposed adaptations of physically-based reflectance models. With this approach, realistic results are generated in a manner that preserves the personal appearance features and lighting conditions of the target face while not requiring detailed geometric and reflectance measurements. We demonstrate this technique on various forms of cosmetics including foundation, blush, lipstick, and eye shadow. Results on both images and videos exhibit a close approximation to ground truth and compare favorably to existing techniques.	[Li, Chen; Zhou, Kun] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China; [Wu, Hsiang-Tao; Lin, Stephen] Microsoft Res, Beijing 100080, Peoples R China	Zhejiang University; Microsoft	Li, C (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.	lich0622@gmail.com; kunzhou@acm.org; musclewu@microsoft.com; stevelin@microsoft.com	Zhou, Kun/ABF-4071-2020; Zhou, Kun/AAH-9290-2019	Zhou, Kun/0000-0003-2320-3655; 	National Key Research&Development Program of China [2016YFB1001403]; NSF China [U1609215]	National Key Research&Development Program of China; NSF China(National Natural Science Foundation of China (NSFC))	This work was done while Chen Li was an intern at Microsoft Research, Beijing, PRC. The authors thank makeup artists Yang Li, Shuying Wu, Yan Peng and the models. This work is partially supported by the National Key Research&Development Program of China (2016YFB1001403) and NSF China (U1609215).	Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; Bonneel N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661253; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Davis T. A., 2011, ACM T MATH SOFTWARE, V38, DOI DOI 10.1145/2049662.2049670; Doi M, 2005, LECT NOTES COMPUT SC, V3540, P95; Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885; FUNT BV, 1992, LECT NOTES COMPUT SC, V588, P124; Ghosh A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409092; Goldsmith J., 1921, TABLES REFRACTIVE IN; Guo D, 2009, PROC CVPR IEEE, P73, DOI 10.1109/CVPRW.2009.5206833; Huang C.G., 2013, P ACM SIGGRAPH S INT, P190; Igarashi T, 2007, FOUND TRENDS COMPUT, V3, P1, DOI 10.1561/0600000013; Jianbing Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3481, DOI 10.1109/CVPR.2011.5995507; Jimenez J, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1609967.1609970; Kang B, 2002, J KOREAN PHYS SOC, V41, P865; Kim H, 2013, PROC CVPR IEEE, P1460, DOI 10.1109/CVPR.2013.192; Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998; Klinker G.J., 1990, INT J COMPUT VISION, V2, P7; Kong N, 2014, LECT NOTES COMPUT SC, V8690, P360; Kubelka P., 1931, Z TECH PHYS, V12, P593, DOI DOI 10.4236/MSCE.2014.28004; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Land E., 1971, J OPT SOC AM A, V3, P1684; Lee KJ, 2012, LECT NOTES COMPUT SC, V7577, P327, DOI 10.1007/978-3-642-33783-3_24; Li C, 2015, PROC CVPR IEEE, P4621, DOI 10.1109/CVPR.2015.7299093; Li C, 2014, LECT NOTES COMPUT SC, V8693, P218, DOI 10.1007/978-3-319-10602-1_15; Liu L., 2013, P 21 ACM INT C MULTI, P3, DOI [10.1145/2502081.2502126, DOI 10.1145/2502081.2502126]; Louis C. Saint, 2011, CAREER LADDER LIPSTI; Maxwell B. A., 2008, 2008 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2008.4587491; Meka A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925907; Moriuchi Y, 2009, LECT NOTES COMPUT SC, V5575, P138, DOI 10.1007/978-3-642-02230-2_15; Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317; Rother C., 2011, ADV NEURAL INFORM PR, P765; Scherbaum K, 2011, COMPUT GRAPH FORUM, V30, P485, DOI 10.1111/j.1467-8659.2011.01874.x; SCHLICK C, 1994, COMPUT GRAPH FORUM, V13, pC233, DOI 10.1111/1467-8659.1330233; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Shen L., 2008, P IEEE C COMPUTER VI, P1; Tan RT, 2005, IEEE T PATTERN ANAL, V27, P178, DOI 10.1109/TPAMI.2005.36; Tappen M.F., 2006, 2006 IEEE COMPUTER S, V2, P1992; Tong WS, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P211, DOI 10.1109/PG.2007.31; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; Yang F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964955; Yang QX, 2015, IEEE T PATTERN ANAL, V37, P1304, DOI 10.1109/TPAMI.2014.2360402; Ye G., 2014, ACM T GRAPHIC, V33; Zhao Q, 2012, IEEE T PATTERN ANAL, V34, P1437, DOI 10.1109/TPAMI.2012.77; Ziming Sun J., 2005, INT J COSMETIC SCI, V27, P355; 2006, ACM T GRAPH, V25, P1013	49	6	6	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1455	1469		10.1109/TPAMI.2018.2832059	http://dx.doi.org/10.1109/TPAMI.2018.2832059			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29993567				2022-12-18	WOS:000467037000013
J	Reso, M; Jachalsky, J; Rosenhahn, B; Ostermann, J				Reso, Matthias; Jachalsky, Joern; Rosenhahn, Bodo; Ostermann, Joern			Occlusion-Aware Method for Temporally Consistent Superpixels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video segmentation; oversegmentation; supervoxels; superpixels	GRAPH; SEGMENTATION	A wide variety of computer vision applications rely on superpixel or supervoxel algorithms as a preprocessing step. This underlines the overall importance that these approaches have gained in recent years. However, most methods show a lack of temporal consistency or fail in producing temporally stable superpixels. In this paper, we present an approach to generate temporally consistent superpixels for video content. Our method is formulated as a contour-evolving expectation-maximization framework, which utilizes an efficient label propagation scheme to encourage the preservation of superpixel shapes and their relative positioning over time. By explicitly detecting the occlusion of superpixels and the disocclusion of new image regions, our framework is able to terminate and create superpixels whose corresponding image region becomes hidden or newly appears. Additionally, the occluded parts of superpixels are incorporated in the further optimization. This increases the compliance of the superpixel flow with the optical flow present in the scene. Using established benchmark suites, we show that our approach produces highly competitive results in comparison to state-of-the-art streaming-capable supervoxel and superpixel algorithms for video content. This is further shown by comparing the streaming-capable approaches as basis for the task of interactive video segmentation where the proposed approach provides the lowest overall misclassification rate.	[Reso, Matthias; Rosenhahn, Bodo; Ostermann, Joern] Leibniz Univ Hannover, Inst Informat Verarbeitung, D-30167 Hannover, Germany; [Jachalsky, Joern] Technicolor Res & Innovat, D-30657 Hannover, Germany	Leibniz University Hannover; Technicolor SA	Reso, M (corresponding author), Leibniz Univ Hannover, Inst Informat Verarbeitung, D-30167 Hannover, Germany.	reso@tnt.uni-hannover.de; jachalsky@tnt.uni-hannover.de; rosenhahn@tnt.uni-hannover.de; ostermann@tnt.uni-hannover.de		Ostermann, Jorn/0000-0002-6743-3324				Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Chang J, 2013, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2013.267; Chen A. Y. C., 2010, Proceedings of 2010 Western New York Image Processing Workshop (WNYIPW), P14, DOI 10.1109/WNYIPW.2010.5649773; Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Freifeld O, 2015, IEEE IMAGE PROC, P2184, DOI 10.1109/ICIP.2015.7351188; Galasso F., 2013, P AS C COMP VIS ACCV, P760, DOI 10.1007/978-3-642-37331-2_57; Galasso F, 2014, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2014.14; Galasso F, 2013, IEEE I CONF COMP VIS, P3527, DOI 10.1109/ICCV.2013.438; Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Jain A, 2013, IEEE I CONF COMP VIS, P1865, DOI 10.1109/ICCV.2013.234; Jang W.-D., 2016, STREAMING VIDEO SEGM, P599; Khoreva A, 2015, PROC CVPR IEEE, P951, DOI 10.1109/CVPR.2015.7298697; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Levinshtein A., 2010, P AS C COMP VIS, P369; Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96; Liang YL, 2016, IEEE T CIRC SYST VID, V26, P928, DOI 10.1109/TCSVT.2015.2406232; Liu Ce, 2009, THESIS, P2; Meuel H, 2015, APSIPA TRANS SIGNAL, V4, DOI 10.1017/ATSIP.2015.12; Moore A. P., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587471; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perbet F, 2012, IEICE T INF SYST, VE95D, P1740, DOI 10.1587/transinf.E95.D.1740; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; Reso M., 2014, P AS C COMP VIS, P692; Reso M., 2017, THESIS; Reso M, 2014, LECT NOTES COMPUT SC, V8887, P281, DOI 10.1007/978-3-319-14249-4_27; Reso M, 2013, IEEE I CONF COMP VIS, P385, DOI 10.1109/ICCV.2013.55; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Schick A, 2014, PATTERN RECOGN LETT, V43, P71, DOI 10.1016/j.patrec.2013.09.013; Sundberg P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2233, DOI 10.1109/CVPR.2011.5995364; Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5; Van den Bergh M, 2015, INT J COMPUT VISION, V111, P298, DOI 10.1007/s11263-014-0744-2; Van den Bergh M, 2013, IEEE I CONF COMP VIS, P377, DOI 10.1109/ICCV.2013.54; Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16; Vogel C, 2013, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2013.174; Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233; Wang P, 2013, INT J COMPUT VISION, V103, P1, DOI 10.1007/s11263-012-0588-6; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Xu CL, 2016, INT J COMPUT VISION, V119, P272, DOI 10.1007/s11263-016-0906-5; Xu CL, 2012, LECT NOTES COMPUT SC, V7577, P626, DOI 10.1007/978-3-642-33783-3_45; Xu CL, 2012, PROC CVPR IEEE, P1202, DOI 10.1109/CVPR.2012.6247802; Zhang J, 2013, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2013.161; Zitnick CL, 2005, IEEE I CONF COMP VIS, P1308	48	6	7	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1441	1454		10.1109/TPAMI.2018.2832628	http://dx.doi.org/10.1109/TPAMI.2018.2832628			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29993437				2022-12-18	WOS:000467037000012
J	Fasquel, JB; Delanoue, N				Fasquel, Jean-Baptiste; Delanoue, Nicolas			A Graph Based Image Interpretation Method Using A Priori Qualitative Inclusion and Photometric Relationships	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image interpretation; inexact graph matching; subgraph isomorphism; qualitative knowledge; inclusion relationships; photometric relationships	SEGMENTATION; REGIONS; SHIFT; MODEL	This paper presents a method for recovering and identifying image regions from an initial oversegmentation using qualitative knowledge of its content. Compared to recent works favoring spatial information and quantitative techniques, our approach focuses on simple a priori qualitative inclusion and photometric relationships such as "region A is included in region B", "the intensity of region A is lower than the one of region B" or "regions A and B depict similar intensities" (photometric uncertainty). The proposed method is based on a two steps' inexact graph matching approach. The first step searches for the best subgraph isomorphism candidate between expected regions and a subset of regions resulting from the initial oversegmentation. Then, remaining segmented regions are progressively merged with appropriate already matched regions, while preserving the coherence with a priori declared relationships. Strengths and weaknesses of the method are studied on various images (grayscale and color), with various intial oversegmentation algorithms (k-means, meanshift, quickshift). Results show the potential of the method to recover, in a reasonable runtime, expected regions, a priori described in a qualitative manner. For further evaluation and comparison purposes, a Python opensource package implementing the method is provided, together with the specifically built experimental database.	[Fasquel, Jean-Baptiste; Delanoue, Nicolas] Univ Angers, LARIS Lab, EA4094, 62 Ave Notre Dame Du Lac, F-49000 Angers, France	Universite d'Angers	Fasquel, JB (corresponding author), Univ Angers, LARIS Lab, EA4094, 62 Ave Notre Dame Du Lac, F-49000 Angers, France.	Jean-Baptiste.Fasquel@univ-angers.fr; nicolas.delanoue@univ-angers.fr						Cesar RM, 2005, PATTERN RECOGN, V38, P2099, DOI 10.1016/j.patcog.2005.05.007; Chen YF, 2012, BIOMED SIGNAL PROCES, V7, P591, DOI 10.1016/j.bspc.2012.04.005; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; Deruyver A, 2009, ARTIF INTELL, V173, P1245, DOI 10.1016/j.artint.2009.05.003; Deruyver A, 2009, IMAGE VISION COMPUT, V27, P876, DOI 10.1016/j.imavis.2008.10.002; Fasquel JB, 2006, COMPUT METH PROG BIO, V83, P222, DOI 10.1016/j.cmpb.2006.07.002; Fasquel JB, 2006, COMPUT METH PROG BIO, V82, P216, DOI 10.1016/j.cmpb.2006.04.004; Gao XB, 2010, PATTERN ANAL APPL, V13, P113, DOI 10.1007/s10044-008-0141-y; Hudelot C, 2008, FUZZY SET SYST, V159, P1929, DOI 10.1016/j.fss.2008.02.011; Iodice S, 2015, PATTERN RECOGN, V48, P1074, DOI 10.1016/j.patcog.2014.09.011; IRCAD, 2017, 3D IM REC COMP ALG D; Lezoray O., 2012, IMAGE PROCESSING ANA; Madi K, 2017, PATTERN RECOGN LETT, V87, P186, DOI 10.1016/j.patrec.2016.05.005; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mignotte M, 2008, IEEE T IMAGE PROCESS, V17, P780, DOI 10.1109/TIP.2008.920761; Nempont O, 2013, INFORM SCIENCES, V246, P1, DOI 10.1016/j.ins.2013.05.030; Noma A, 2012, PATTERN RECOGN, V45, P1159, DOI 10.1016/j.patcog.2011.08.017; Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015; Serratosa F, 2015, PATTERN RECOGN LETT, V65, P204, DOI 10.1016/j.patrec.2015.08.003; Tremeau A, 2000, IEEE T IMAGE PROCESS, V9, P735, DOI 10.1109/83.841950; Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52	23	6	6	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1043	1055		10.1109/TPAMI.2018.2827939	http://dx.doi.org/10.1109/TPAMI.2018.2827939			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993626				2022-12-18	WOS:000463607400002
J	Fu, X; Huang, KJ; Sidiropoulos, ND; Shi, QJ; Hong, MY				Fu, Xiao; Huang, Kejun; Sidiropoulos, Nicholas D.; Shi, Qingjiang; Hong, Mingyi			Anchor-Free Correlated Topic Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Topic modeling; identifiability; anchor free; sufficiently scattered; non-convex optimization; non negative matrix factorization	NONNEGATIVE MATRIX FACTORIZATION; UNIQUENESS; ALGORITHM	In topic modeling, identifiability of the topics is an essential issue. Many topic modeling approaches have been developed under the premise that each topic has a characteristic anchor word that only appears in that topic. The anchor-word assumption is fragile in practice, because words and terms have multiple uses; yet it is commonly adopted because it enables identifiability guarantees. Remedies in the literature include using three- or higher-order word co-occurence statistics to come up with tensor factorization models, but such statistics need many more samples to obtain reliable estimates, and identifiability still hinges on additional assumptions, such as consecutive words being persistently drawn from the same topic. In this work, we propose a new topic identification criterion using second order statistics of the words. The criterion is theoretically guaranteed to identify the underlying topics even when the anchor-word assumption is grossly violated. An algorithm based on alternating optimization, and an efficient primal-dual algorithm are proposed to handle the resulting identification problem. The former exhibits high performance and is completely parameter-free; the latter affords up to 200 times speedup relative to the former, but requires step-size tuning and a slight sacrifice in accuracy. A variety of real text copora are employed to showcase the effectiveness of the approach, where the proposed anchor-free method demonstrates substantial improvements compared to a number of anchor-word based approaches under various evaluation metrics.	[Fu, Xiao] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA; [Huang, Kejun; Hong, Mingyi] Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA; [Sidiropoulos, Nicholas D.] Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA 22904 USA; [Shi, Qingjiang] Tongji Univ, Sch Software Engn, Shanghai 201804, Peoples R China	Oregon State University; University of Minnesota System; University of Minnesota Twin Cities; University of Virginia; Tongji University	Huang, KJ (corresponding author), Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA.	xiao.fu@oregonstate.edu; huang663@umn.edu; nikos@virginia.edu; qing.j.shi@gmail.com; mhong@umn.edu	Hong, Mingyi/H-6274-2013	Sidiropoulos, Nicholas/0000-0002-3385-7911	US National Science Foundation (NSF) [ECCS-1608961, IIS-1247632]; NSFC [61671411, U1709219, 61374020]; Fundamental Research Funds for the Central Universities; Zhejiang Provincial NSF of China [LR15F010002]; US National Science Foundation [CCF-1526078, CMMI-1727757]; AFOSR [15RT0767]	US National Science Foundation (NSF)(National Science Foundation (NSF)); NSFC(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Zhejiang Provincial NSF of China(Natural Science Foundation of Zhejiang Province); US National Science Foundation(National Science Foundation (NSF)); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR))	The work of X. Fu, K. Huang, and N. D. Sidiropoulos is supported in part by the US National Science Foundation (NSF) under grants ECCS-1608961 and IIS-1247632. The work of Q. Shi is supported in part by NSFC under Grant 61671411, U1709219, 61374020, by the Fundamental Research Funds for the Central Universities, and by Zhejiang Provincial NSF of China under Grant LR15F010002. The work of M. Hong is supported in part by US National Science Foundation under Grant CCF-1526078, CMMI-1727757, and by AFOSR under Grant 15RT0767. Xiao Fu and Kejun Huang contributed equally.	Anandkumar A., 2013, ADV NEURAL INFORM PR, P1986; Anandkumar A, 2015, ALGORITHMICA, V72, P193, DOI 10.1007/s00453-014-9909-1; Anandkumar Anima, 2012, NIPS; Anandkumar A, 2015, J MACH LEARN RES, V16, P2643; [Anonymous], [No title captured]; Arora S., 2013, P 30 INT C INT C MAC; Arora S, 2012, STOC'12: PROCEEDINGS OF THE 2012 ACM SYMPOSIUM ON THEORY OF COMPUTING, P145; Bioucas-Dias JM, 2009, 2009 FIRST WORKSHOP ON HYPERSPECTRAL IMAGE AND SIGNAL PROCESSING: EVOLUTION IN REMOTE SENSING, P1, DOI 10.1109/WHISPERS.2009.5289072; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Cai D, 2011, IEEE T KNOWL DATA EN, V23, P902, DOI 10.1109/TKDE.2010.165; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212; Cohen AM, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-103; Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852; Esser E, 2012, IEEE T IMAGE PROCESS, V21, P3239, DOI 10.1109/TIP.2012.2190081; Fu X, 2016, IEEE T SIGNAL PROCES, V64, P6254, DOI 10.1109/TSP.2016.2602800; Fu X, 2016, IEEE SIGNAL PROC LET, V23, P60, DOI 10.1109/LSP.2015.2498523; Fu X, 2015, IEEE J-STSP, V9, P1128, DOI 10.1109/JSTSP.2015.2410763; Gillis N, 2014, SIAM J IMAGING SCI, V7, P1420, DOI 10.1137/130946782; Gillis N, 2014, IEEE T PATTERN ANAL, V36, P698, DOI 10.1109/TPAMI.2013.226; Gillis N, 2013, SIAM J MATRIX ANAL A, V34, P1189, DOI 10.1137/120900629; Grant M., 2014, CVX MATLAB SOFTWARE; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Huang K., 2016, ADV NEURAL INFORM PR, P1786; Huang KJ, 2014, IEEE T SIGNAL PROCES, V62, P211, DOI 10.1109/TSP.2013.2285514; Kumar A., 2012, P 30 INT C INT C MAC; Lee M., 2015, ADV NEURAL INFORM PR, P2710; Ma W.-K., 2010, CONVEX OPTIMIZATION, P229; Ozgur A, 2008, INT J MOD PHYS C, V19, P689, DOI 10.1142/S0129183108012431; Razaviyayn M, 2013, SIAM J OPTIMIZ, V23, P1126, DOI 10.1137/120891009; Recht B., 2012, ADV NEURAL INFORM PR, V25, P1214; Ruszczynski A. P., 2006, NONLINEAR OPTIMIZATI; Shahnaz F, 2006, INFORM PROCESS MANAG, V42, P373, DOI 10.1016/j.ipm.2004.11.005; Shi Q., 2017, ARXIV171204767; Steyvers M., 2007, HDB LATENT SEMANTIC, V427, P32; Xu W., 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485; Zhang ZY, 2013, PHYS REV E, V87, DOI 10.1103/PhysRevE.87.062803	39	6	6	4	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1056	1071		10.1109/TPAMI.2018.2827377	http://dx.doi.org/10.1109/TPAMI.2018.2827377			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993625	hybrid			2022-12-18	WOS:000463607400003
J	Xu, QQ; Xiong, JC; Cao, XC; Huang, QM; Yao, Y				Xu, Qianqian; Xiong, Jiechao; Cao, Xiaochun; Huang, Qingming; Yao, Yuan			From Social to Individuals: A Parsimonious Path of Multi-Level Models for Crowdsourced Preference Aggregation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Preference aggregation; HodgeRank; mixed-effects models; linearized bregman iterations; personalized ranking; position bias	HODGERANK; REGULARIZATION	In crowdsourced preference aggregation, it is often assumed that all the annotators are subject to a common preference or social utility function which generates their comparison behaviors in experiments. However, in reality, annotators are subject to variations due to multi-criteria, abnormal, or a mixture of such behaviors. In this paper, we propose a parsimonious mixed-effects model, which takes into account both the fixed effect that the majority of annotators follows a common linear utility model, and the random effect that some annotators might deviate from the common significantly and exhibit strongly personalized preferences. The key algorithm in this paper establishes a dynamic path from the social utility to individual variations, with different levels of sparsity on personalization. The algorithm is based on the Linearized Bregman Iterations, which leads to easy parallel implementations to meet the need of large-scale data analysis. In this unified framework, three kinds of random utility models are presented, including the basic linear model with L-2 loss, Bradley-Terry model, and Thurstone-Mosteller model. The validity of these multi-level models are supported by experiments with both simulated and real-world datasets, which shows that the parsimonious multi-level models exhibit improvements in both interpretability and predictive precision compared with traditional HodgeRank.	[Xu, Qianqian] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Xu, Qianqian; Cao, Xiaochun] Chinese Acad Sci, Inst Informat Engn, SKLOIS, Beijing 100093, Peoples R China; [Xiong, Jiechao] Tencent AI Lab, Shenzhen 518057, Peoples R China; [Xiong, Jiechao] Peking Univ, BICMR LMAM LMEQF LMP, Sch Math Sci, Beijing 100871, Peoples R China; [Huang, Qingming] Univ Chinese Acad Sci, Huairou 101408, Peoples R China; [Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China; [Yao, Yuan] Hong Kong Univ Sci & Technol, Dept Math, Hong Kong, Peoples R China; [Yao, Yuan] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China	Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; Institute of Information Engineering, CAS; Tencent; Peking University; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Hong Kong University of Science & Technology; Hong Kong University of Science & Technology	Cao, XC (corresponding author), Chinese Acad Sci, Inst Informat Engn, SKLOIS, Beijing 100093, Peoples R China.; Huang, QM (corresponding author), Univ Chinese Acad Sci, Huairou 101408, Peoples R China.; Huang, QM (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.; Yao, Y (corresponding author), Hong Kong Univ Sci & Technol, Dept Math, Hong Kong, Peoples R China.; Yao, Y (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.	qianqian.xu@vipl.ict.ac.cn; jcxiong@tencent.com; caoxiaochun@iie.ac.cn; qmhuang@ucas.ac.cn; yuany@ust.hk			National Key Research and Development Plan [2016YFB0800403]; National Natural Science Foundation of China [61672514, 61390514, 61572042, U1636214, 61650202, 61332016, 61620106009, 61370004, 11421110001]; Beijing Natural Science Foundation [4182079, 4172068]; Youth Innovation Promotion Association CAS; CCF-Tencent Open Research Fund; Key Program of the Chinese Academy of Sciences [QYZDB-SSW-JSC003]; National Basic Research Program of China (973 Program) [2015CB351800]; Key Research Program of Frontier Sciences [CAS: QYZDJ-SSW-SYS013]; Hong Kong Research Grant Council (HKRGC) [16303817]; National Basic Research Program of China [2015CB85600, 2012CB825501]; Tencent AI Lab; Si Family Foundation; Baidu Big Data Institute; Microsoft Research-Asia	National Key Research and Development Plan; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation); Youth Innovation Promotion Association CAS; CCF-Tencent Open Research Fund; Key Program of the Chinese Academy of Sciences(Chinese Academy of Sciences); National Basic Research Program of China (973 Program)(National Basic Research Program of China); Key Research Program of Frontier Sciences; Hong Kong Research Grant Council (HKRGC)(Hong Kong Research Grants Council); National Basic Research Program of China(National Basic Research Program of China); Tencent AI Lab; Si Family Foundation; Baidu Big Data Institute; Microsoft Research-Asia	The authors would like to thank Prof. Wotao Yin and Prof. Ming Yan on helpful discussions over parallel implementations of LBI. The research of Qianqian Xu was supported in part by the National Key Research and Development Plan (No. 2016YFB0800403), in part by the National Natural Science Foundation of China (No. 61672514, 61390514, 61572042), the Beijing Natural Science Foundation (4182079), the Youth Innovation Promotion Association CAS, and the CCF-Tencent Open Research Fund. The research of Xiaochun Cao was supported in part by the National Natural Science Foundation of China (No. U1636214, 61650202), the Beijing Natural Science Foundation (No. 4172068), and the Key Program of the Chinese Academy of Sciences (No. QYZDB-SSW-JSC003). The research of Qingming Huang was supported in part by the National Natural Science Foundation of China: 61332016, 61620106009, U1636214, and 61650202, in part by the National Basic Research Program of China (973 Program): 2015CB351800, in part by the Key Research Program of Frontier Sciences, CAS: QYZDJ-SSW-SYS013. The research of Yuan Yao was supported in part by the Hong Kong Research Grant Council (HKRGC) grant 16303817, the National Basic Research Program of China (No. 2015CB85600, 2012CB825501), the National Natural Science Foundation of China (No. 61370004, 11421110001), as well as awards from the Tencent AI Lab, Si Family Foundation, Baidu Big Data Institute, and Microsoft Research-Asia.	[Anonymous], 1781, HIST LACADEMIE ROYAL; [Anonymous], 1993, TEXTS APPL MATH; [Anonymous], 2008, P 25 INT C MACH LEAR; Arrow K. J., 1951, SOCIAL CHOICE INDIVI; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Chris Burges T.S., 2005, P 22 INT MACH LEARN, DOI 10.1145/1102351.1102363; David HA., 1988, METHODS PAIRED COMP; Dawid A.P., 1979, APPL STAT, V28, P20, DOI [10.2307/2346806, DOI 10.2307/2346806]; DAY RL, 1969, J MARKETING RES, V6, P98, DOI 10.2307/3150005; Dwork C., 2001, P 10 INT C WORLD WID, P613, DOI [10.1145/371920.372165, DOI 10.1145/371920.372165]; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Farias V. F., 2009, NIPS; Freund Y., 2003, J MACHINE LEARNING R, V4, P933, DOI DOI 10.1162/JMLR.2003.4.6.933; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Fu YW, 2016, IEEE T PATTERN ANAL, V38, P563, DOI 10.1109/TPAMI.2015.2456887; Guo S., 2012, SIGMOD; Hu HQ, 2016, PROC INT CONF DATA, P61, DOI 10.1109/ICDE.2016.7498229; Jiang XY, 2011, MATH PROGRAM, V127, P203, DOI 10.1007/s10107-010-0419-x; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]; Kamar E., 2015, 3 AAAI C HUM COMP CR; Le Callet P., 2005, SUBJECTIVE QUALITY A; Li GL, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1463, DOI 10.1145/3035918.3064036; Li GL, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1711, DOI 10.1145/3035918.3054776; Li GL, 2016, IEEE T KNOWL DATA EN, V28, P2296, DOI 10.1109/TKDE.2016.2535242; Liu X, 2012, PROC VLDB ENDOW, V5, P1040, DOI 10.14778/2336664.2336676; Lu Y, 2015, ANN ALLERTON CONF, P1473, DOI 10.1109/ALLERTON.2015.7447183; Ma WY, 2011, PROC CVPR IEEE, P153, DOI 10.1109/CVPR.2011.5995422; Negahban Sahand, 2012, NIPS, P2483; Oh S., 2014, ADV NEURAL INFORM PR, P595; Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412; Osher S, 2016, APPL COMPUT HARMON A, V41, P436, DOI 10.1016/j.acha.2016.01.002; Osting B., 2013, INT C MACH LEARN, P489; Osting B, 2016, APPL COMPUT HARMON A, V41, P540, DOI 10.1016/j.acha.2016.03.007; Osting B, 2013, INVERSE PROBL IMAG, V7, P907, DOI 10.3934/ipi.2013.7.907; Rajkumar A, 2014, PR MACH LEARN RES, V32; Rashmi KV, 2015, JMLR WORKSH CONF PRO, V38, P489; Raykar V. C., 2009, P 26 ANN INT C MACH, P889, DOI DOI 10.1145/1553374.1553488; Rennie J. D., 2005, P 22 INT C MACHINE L, P713; Sheshadri Aashish, 2013, P 1 AAAI C HUMAN COM, P156, DOI 10.1.1.644.2813; Suh CH, 2017, IEEE T INFORM THEORY, V63, P2201, DOI 10.1109/TIT.2017.2659660; Tran NM, 2016, MATH OPER RES, V41, P643, DOI 10.1287/moor.2015.0744; Venanzi M, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P155, DOI 10.1145/2566486.2567989; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Whitehill J., 2009, ADV NEURAL INFORM PR, P2035; Xu, 2011, P 19 ACM INT C MULT, P393, DOI DOI 10.1145/2072298.2072350; Xu, 2016, INT C MACH LEARN, P1282; Xu QQ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P841, DOI 10.1145/2964284.2964298; Xu Q, 2012, IEEE T MULTIMEDIA, V14, P844, DOI 10.1109/TMM.2012.2190924; Yi J., 2013, P 1 AAAI C HUM COMP, P207; Yu SX, 2012, IEEE T PATTERN ANAL, V34, P158, DOI 10.1109/TPAMI.2011.107; Yuan J, 2009, J MATH IMAGING VIS, V33, P169, DOI 10.1007/s10851-008-0122-1; Zheng Y., 2015, P 18 INT C EXTENDING, P193; Zheng YD, 2017, PROC VLDB ENDOW, V10, P541, DOI 10.14778/3055540.3055547; Zheng YD, 2016, PROC VLDB ENDOW, V10, P361; Zheng YD, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1031, DOI 10.1145/2723372.2749430	57	6	6	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					844	856		10.1109/TPAMI.2018.2817205	http://dx.doi.org/10.1109/TPAMI.2018.2817205			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29993767	Green Submitted			2022-12-18	WOS:000460583500005
J	Zhang, XW; Shi, XD; Sun, Y; Cheng, L				Zhang, Xiaowei; Shi, Xudong; Sun, Yu; Cheng, Li			Multivariate Regression with Gross Errors on Manifold-Valued Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manifold-valued data; multivariate linear regression; gross error; nonsmooth optimization on manifolds; diffusion tensor imaging	RIEMANNIAN-MANIFOLDS; GEODESIC REGRESSION; PARALLEL TRANSPORT; ALGORITHM; OPTIMIZATION; MINIMIZATION; STATISTICS; NONCONVEX; FRAMEWORK; GEOMETRY	We consider the topic of multivariate regression on manifold-valued output, that is, for a multivariate observation, its output response lies on a manifold. Moreover, we propose a new regression model to deal with the presence of grossly corrupted manifold-valued responses, a bottleneck issue commonly encountered in practical scenarios. Our model first takes a correction step on the grossly corrupted responses via geodesic curves on the manifold, then performs multivariate linear regression on the corrected data. This results in a nonconvex and nonsmooth optimization problemon Riemannian manifolds. To this end, we propose a dedicated approach named PALMR, by utilizing and extending the proximal alternating linearized minimization techniques for optimization problems on euclidean spaces. Theoretically, we investigate its convergence property, where it is shown to converge to a critical point under mild conditions. Empirically, we test our model on both synthetic and real diffusion tensor imaging data, and show that our model outperforms other multivariate regression models when manifold-valued responses contain gross errors, and is effective in identifying gross errors.	[Zhang, Xiaowei; Cheng, Li] ASTAR, Bioinformat Inst, Singapore 138632, Singapore; [Shi, Xudong] Natl Univ Singapore, Sch Comp, Singapore 117456, Singapore; [Sun, Yu] Natl Univ Singapore, Singapore Inst Neurotechnol, Singapore 117456, Singapore	Agency for Science Technology & Research (A*STAR); A*STAR - Bioinformatics Institute (BII); National University of Singapore; National University of Singapore	Zhang, XW (corresponding author), ASTAR, Bioinformat Inst, Singapore 138632, Singapore.	zxwtroy87@gmail.com; shixudongleo@gmail.com; lsisu@nus.edu.sg; chengli@bii.a-star.edu.sg	Cheng, Li/AAU-6734-2020	Cheng, Li/0000-0003-3261-3533; SUN, Yu/0000-0002-6666-8586				Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Attouch H, 2010, MATH OPER RES, V35, P438, DOI 10.1287/moor.1100.0449; Bacak M, 2016, SIAM J SCI COMPUT, V38, pA567, DOI 10.1137/15M101988X; Banerjee M, 2016, PROC CVPR IEEE, P4424, DOI 10.1109/CVPR.2016.479; Basser PJ, 1995, NMR BIOMED, V8, P333, DOI 10.1002/nbm.1940080707; Basser PJ, 2002, NMR BIOMED, V15, P456, DOI 10.1002/nbm.783; Basser PJ, 1996, J MAGN RESON SER B, V111, P209, DOI [10.1006/jmrb.1996.0086, 10.1016/j.jmr.2011.09.022]; Bastin ME, 1998, MAGN RESON IMAGING, V16, P773, DOI 10.1016/S0730-725X(98)00098-8; Basu S, 2006, LECT NOTES COMPUT SC, V4190, P117; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Bhatia K., 2015, ADV NEURAL INF PROCE, P721; Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9; Boumal N, 2014, J MACH LEARN RES, V15, P1455; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Carreira J, 2015, IEEE T PATTERN ANAL, V37, P1177, DOI 10.1109/TPAMI.2014.2361137; Cherian A, 2017, IEEE T NEUR NET LEAR, V28, P2859, DOI 10.1109/TNNLS.2016.2601307; Cornea E, 2017, J R STAT SOC B, V79, P463, DOI 10.1111/rssb.12169; Neto JXC, 2013, J CONVEX ANAL, V20, P395; da Cruz Neto J. X., 1998, BALK J GEOM APPL, V2, P89; Davis BC, 2010, INT J COMPUT VISION, V90, P255, DOI 10.1007/s11263-010-0367-1; do Carmo M. P., 1992, RIEMANNIAN GEOMETRY; Du J, 2014, NEUROIMAGE, V87, P416, DOI 10.1016/j.neuroimage.2013.06.081; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Feragen A, 2015, PROC CVPR IEEE, P3032, DOI 10.1109/CVPR.2015.7298922; Ferreira OP, 1998, J OPTIMIZ THEORY APP, V97, P93, DOI 10.1023/A:1022675100677; Fletcher PT, 2007, SIGNAL PROCESS, V87, P250, DOI 10.1016/j.sigpro.2005.12.018; Fletcher PT, 2013, INT J COMPUT VISION, V105, P171, DOI 10.1007/s11263-012-0591-y; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; Harandi M, 2015, PROC CVPR IEEE, P3926, DOI 10.1109/CVPR.2015.7299018; Harandi M, 2015, INT J COMPUT VISION, V114, P113, DOI 10.1007/s11263-015-0833-x; Harandi MT, 2014, LECT NOTES COMPUT SC, V8695, P408, DOI 10.1007/978-3-319-10584-0_27; Harandi MT, 2012, LECT NOTES COMPUT SC, V7573, P216, DOI 10.1007/978-3-642-33709-3_16; Hein M., 2009, ADV NEURAL INFORM PR, V22; Hinkle J, 2014, J MATH IMAGING VIS, V50, P32, DOI 10.1007/s10851-013-0489-5; Hong Y, 2016, IEEE T PATTERN ANAL, V38, P2284, DOI 10.1109/TPAMI.2016.2516533; Hosseini S, 2017, SIAM J OPTIMIZ, V27, P173, DOI 10.1137/16M1069298; Hsu JL, 2008, NEUROIMAGE, V39, P566, DOI 10.1016/j.neuroimage.2007.09.017; Huang W, 2015, SIAM J OPTIMIZ, V25, P1660, DOI 10.1137/140955483; Jayasumana S, 2015, IEEE T PATTERN ANAL, V37, P2464, DOI 10.1109/TPAMI.2015.2414422; Jayasumana S, 2014, PROC CVPR IEEE, P3802, DOI 10.1109/CVPR.2014.480; Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015; Kheyfets A, 2000, INT J THEOR PHYS, V39, P2891, DOI 10.1023/A:1026473418439; Kim HJ, 2015, PR MACH LEARN RES, V37, P1199; Kim HJ, 2014, PROC CVPR IEEE, P2705, DOI 10.1109/CVPR.2014.352; Kovnatsky A, 2016, LECT NOTES COMPUT SC, V9909, P680, DOI 10.1007/978-3-319-46454-1_41; Lorenzi M, 2014, J MATH IMAGING VIS, V50, P5, DOI 10.1007/s10851-013-0470-3; Muralidharan P, 2012, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2012.6247780; Nguyen NH, 2013, IEEE T INFORM THEORY, V59, P2036, DOI 10.1109/TIT.2012.2232347; Quiroz EAP, 2013, J GLOBAL OPTIM, V56, P43, DOI 10.1007/s10898-012-9996-y; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; Rockafellar RT., 1998, VARIATIONAL ANAL, DOI 10.1007/978-3-642-02431-3; Saxena A, 2009, INT CONF ACOUST SPEE, P713, DOI 10.1109/ICASSP.2009.4959683; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Steinke F., 2009, ADV NEURAL INFORM PR, P1561; Vemulapalli R, 2013, PROC CVPR IEEE, P1782, DOI 10.1109/CVPR.2013.233; Wang RY, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276468, 10.1145/1239451.1239524]; Wright J, 2010, IEEE T INFORM THEORY, V56, P3540, DOI 10.1109/TIT.2010.2048473; Wu M, 2008, LECT NOTES COMPUT SC, V5242, P321, DOI 10.1007/978-3-540-85990-1_39; Xu H., 2012, P 15 INT C ART INT S, P1341; Zalesky A, 2011, MAGN RESON IMAGING, V29, P111, DOI 10.1016/j.mri.2010.06.027	65	6	6	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					444	458		10.1109/TPAMI.2017.2776260	http://dx.doi.org/10.1109/TPAMI.2017.2776260			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29993419	Green Submitted, Bronze			2022-12-18	WOS:000456150600013
J	Cigale, B; Zazula, D				Cigale, Boris; Zazula, Damjan			Directional 3D Wavelet Transform Based on Gaussian Mixtures for the Analysis of 3D Ultrasound Ovarian Volumes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Adaptive ovarian follicle recognition; directional wavelet transform; Gaussian mixture model; recursive region splitting; 3D ultrasonic imaging	SEGMENTATION; LAPLACIAN; IMAGES	The success of in-vitro fertilization can be predicted by a correct quantitative and qualitative assessment of ovarian follicles. Several ovarian follicle detection and recognition algorithms have been published. Their effectiveness is inferior to human follicle annotations due to various kinds of noise, degradations, and artefacts in ultrasonic images. This paper deals with an approach to recognize antral follicles from 2 mm in diameter in 3D ultrasound data. Its detection phase looks for candidate follicular regions, while the recognition phase assesses the likelihood of a region to correspond to a follicle. Three innovative definitions underpin the detection: Laplacian-of-Gaussian-based directional 3D wavelet transform, adaptive multiscale search based on Gaussian mixtures, and recursive convexity-based region splitting. A likelihood index is also introduced to support follicle recognition. The proposed approach was tested on 30 ultrasound ovarian volumes generated by different sonographic machines in stimulated and non-stimulated examination cycles. The obtained follicle recognition rates exceed those of the best 3D approaches known by about 10 percent, while qualitative assessments yield comparable values.	[Cigale, Boris] Logicdata Doo, Ul Knew Koclja 22, Maribor 2000, Slovenia; [Zazula, Damjan] Univ Maribor, Fac Elect Engn & Comp Sci, Smetanozia 17, SLO-2000 Maribor, Slovenia	University of Maribor	Zazula, D (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Smetanozia 17, SLO-2000 Maribor, Slovenia.	boris.cigale@logicdata.net; uelzaz01n@gmail.com		Cigale, Boris/0000-0001-5392-7430	Slovenian Research Agency within the Program Funding Scheme [P2-0041]	Slovenian Research Agency within the Program Funding Scheme(Slovenian Research Agency - Slovenia)	This research was completed in the System Software Laboratory at the Faculty of Electrical Engineering and Computer Science, University of Maribor, and supported by the Slovenian Research Agency within the Program Funding Scheme, Unit No. P2-0041. The authors wish to thank Prof. Dr. Veljko Vlaisavljevic, MD, and Dr. Jure Knez, MD, from the University Medical Center of Maribor for their indispensable help in providing test ultrasound ovarian volumes and conveying all their expert knowledge about the follicle analysis and assessment in clinical practice.	Ata B, 2011, HUM REPROD, V26, P127, DOI 10.1093/humrep/deq320; Chen T, 2009, IEEE I CONF COMP VIS, P795, DOI 10.1109/ICCV.2009.5459243; Cigale B, 2004, INT J PATTERN RECOGN, V18, P563, DOI 10.1142/S0218001404003368; Cigale B, 2007, IFMBE PROC, V16, P1017; Deb S, 2010, ULTRASOUND OBST GYN, V35, P354, DOI 10.1002/uog.7505; Deutch T.D., 2007, SONOGRAPHY BASED AUT; Efford N., 2000, DIGITAL IMAGE PROCES; Eisenberg B., 2008, MATH MAG, V81, P362, DOI DOI 10.2307/27643141; Gooding MJ, 2008, ULTRASOUND MED BIOL, V34, P183, DOI 10.1016/j.ultrasmedbio.2007.07.023; Gunn SR, 1999, PATTERN RECOGN, V32, P1463, DOI 10.1016/S0031-3203(98)00163-0; Guvenir HA, 2015, MED BIOL ENG COMPUT, V53, P911, DOI 10.1007/s11517-015-1299-2; Hiremath PS, 2013, ADV BREAKTHROUGHS UL, DOI [10.5772/56518, DOI 10.5772/56518]; Jayaprakasan K, 2015, ULTRASONOGRAPHY IN GYNECOLOGY, P264; Kong H, 2013, IEEE T CYBERNETICS, V43, P1719, DOI 10.1109/TSMCB.2012.2228639; Lu Q., 2008, THESIS; Mallat S., 1999, WAVELET TOUR SIGNAL, DOI 10.1016/B978-012466606-1/50008-8; McLachlan G, 2005, FINITE MIXTURE MODEL; Montero RS., 2009, INT MATH FORUM, V4, P1305; Potocnik B., 2001, Elektrotehniski Vestnik, V68, P97; Potocnik B, 2012, MED BIOL ENG COMPUT, V50, P1201, DOI 10.1007/s11517-012-0956-y; Romeny BMT, 1999, LECT NOTES COMPUT SC, V1613, P56; Singh N, 2015, INT J GYNECOL OBSTET, V131, P166, DOI 10.1016/j.ijgo.2015.04.045; Vandekerckhove F, 2014, FRONT SURG, V1, DOI 10.3389/fsurg.2014.00018; Vlaisavljevic V., 2007, DONALD SCH J ULTRA O, V2, P50; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zalud I, 2012, DONALD SCH J ULTRASO, V6, P1; Zhu C., 2009, P 4 INT C INT COMP S, P122; Zunic J, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P1180, DOI 10.1109/ICIEV.2012.6317466; [No title captured]	29	6	6	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					64	77		10.1109/TPAMI.2017.2780248	http://dx.doi.org/10.1109/TPAMI.2017.2780248			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990234				2022-12-18	WOS:000452434800006
J	Jeong, S; Lee, J; Kim, B; Kim, Y; Noh, J				Jeong, Seunghwa; Lee, Jungjin; Kim, Bumki; Kim, Younghui; Noh, Junyong			Object Segmentation Ensuring Consistency Across Multi-Viewpoint Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-view segmentation; wide-baseline capture environment; inter-view consistency; depth projection		We present a hybrid approach that segments an object by using both color and depth information obtained from views captured from a low-cost RGBD camera and sparsely-located color cameras. Our system begins with generating dense depth information of each target image by using Structure from Motion and Joint Bilateral Upsampling. We formulate the multi-view object segmentation as the Markov Random Field energy optimization on the graph constructed from the superpixels. To ensure inter-view consistency of the segmentation results between color images that have too few color features, our local mapping method generates dense inter-view geometric correspondences by using the dense depth images. Finally, the pixel-based optimization step refines the boundaries of the results obtained from the superpixel-based binary segmentation. We evaluate the validity of our method under various capture conditions such as numbers of views, rotations, and distances between cameras. We compared our method with the state-of-the-art methods that use the standard multi-view datasets. The comparison verified that the proposed method works very efficiently especially in a sparse wide-baseline capture environment.	[Jeong, Seunghwa; Kim, Bumki; Noh, Junyong] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon 34141, South Korea; [Jeong, Seunghwa; Lee, Jungjin; Kim, Younghui] KAI Inc, Daejeon 34126, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Noh, J (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon 34141, South Korea.	seunghwajeong@kaist.ac.kr; jj.lee@kaistudio.co.kr; bumkikim@kaist.ac.kr; yh.kim@kaistudio.co.kr; junyongnoh@kaist.ac.kr	Noh, Junyong/C-1663-2011	Lee, Jungjin/0000-0003-3471-4848	Institute for Information & communications Technology Promotion (IITP) grant - Korea government (MSIP) [R0116-15-3008]	Institute for Information & communications Technology Promotion (IITP) grant - Korea government (MSIP)	This work was supported by Institute for Information & communications Technology Promotion (IITP) grant funded by the Korea government (MSIP) (No. R0116-15-3008)	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Campbell N. D. F., 2011, 2011 Conference for Visual Media Production, P126, DOI 10.1109/CVMP.2011.21; Crabb Ryan, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563170; Criminisi A., 2006, IEEE C COMP VIS PATT, V1, P53, DOI DOI 10.1109/CVPR.2006.69; Djelouah A, 2015, IEEE T PATTERN ANAL, V37, P1890, DOI 10.1109/TPAMI.2014.2385704; Djelouah A, 2013, IEEE I CONF COMP VIS, P2640, DOI 10.1109/ICCV.2013.328; Galasso F., 2013, LNCS, V7724, P760; Gordon G., 1999, IEEE COMP SOC C COMP, P464, DOI DOI 10.1109/CVPR.1999.784721; Guillemaut JY, 2011, INT J COMPUT VISION, V93, P73, DOI 10.1007/s11263-010-0413-z; Hasler N, 2009, PROC CVPR IEEE, P224, DOI 10.1109/CVPRW.2009.5206859; Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868; Kolmogorov V, 2005, PROC CVPR IEEE, P407; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kompatsiaris I, 1998, IEEE T CIRC SYST VID, V8, P547, DOI 10.1109/76.718502; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Kowdle A, 2012, LECT NOTES COMPUT SC, V7576, P789, DOI 10.1007/978-3-642-33715-4_57; Lee W, 2011, IEEE T PATTERN ANAL, V33, P1429, DOI 10.1109/TPAMI.2010.196; Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44; Reso M, 2013, IEEE I CONF COMP VIS, P385, DOI 10.1109/ICCV.2013.55; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Sarim M, 2010, PROCEEDINGS OF THE 2010 ACM WORKSHOP ON 3D VIDEO PROCESSING (3DVP'10), P13, DOI 10.1145/1877791.1877795; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228; Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530; Wang LT, 2010, POWER-AWARE TESTING AND TEST STRATEGIES FOR LOW POWER DEVICES, P1, DOI 10.1007/978-1-4419-0928-2_1; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25; Zeng G., 2004, P AS C COMP VIS, P628	33	6	6	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2455	2468		10.1109/TPAMI.2017.2757928	http://dx.doi.org/10.1109/TPAMI.2017.2757928			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28976312				2022-12-18	WOS:000443875500013
J	Darkner, S; Pai, A; Liptrot, MG; Sporring, J				Darkner, Sune; Pai, Akshay; Liptrot, Matthew G.; Sporring, Jon			Collocation for Diffeomorphic Deformations in Medical Image Registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Registration; ordinary differential equation; convergence and stability; model validation and analysis; image processing and computer vision	PHASE FLOW METHOD; BRAIN; ALGORITHMS; SCANS; FSL	Diffeomorphic deformation is a popular choice in medical image registration. A fundamental property of diffeomorphisms is invertibility, implying that once the relation between two points A to B is found, then the relation B to A is given per definition. Consistency is a measure of a numerical algorithm's ability to mimic this invertibility, and achieving consistency has proven to be a challenge for many state-of-the-art algorithms. We present CDD (Collocation for Diffeomorphic Deformations), a numerical solution to diffeomorphic image registration, which solves for the Stationary Velocity Field (SVF) using an implicit A-stable collocation method. CDD guarantees the preservation of the diffeomorphic properties at all discrete points and is thereby consistent to machine precision. We compared CDD's collocation method with the following standard methods: Scaling and Squaring, Forward Euler, and Runge-Kutta 4, and found that CDD is up to 9 orders of magnitude more consistent. Finally, we evaluated CDD on a number of standard bench-mark data sets and compared the results with current state-of-the-art methods: SPM-DARTEL, Diffeomorphic Demons and SyN. We found that CDD outperforms state-of-the-art methods in consistency and delivers comparable or superior registration precision.	[Darkner, Sune; Pai, Akshay; Liptrot, Matthew G.; Sporring, Jon] Univ Copenhagen, Dept Comp Sci, DK-1165 Copenhagen, Denmark	University of Copenhagen	Darkner, S (corresponding author), Univ Copenhagen, Dept Comp Sci, DK-1165 Copenhagen, Denmark.	darkner@di.ku.dk; akshay@biomediq.com; matthew.liptrot@di.ku.dk; sporring@diku.dk	Sporring, Jon/L-4499-2016; Darkner, Sune/N-1834-2016	Sporring, Jon/0000-0003-1261-6702; Darkner, Sune/0000-0001-6114-7100	Oticon Foundation; Villum Fonden [00008721] Funding Source: researchfish	Oticon Foundation; Villum Fonden(Villum Fonden)	The authors would like to thank the Oticon Foundation for supporting our research.	[Anonymous], [No title captured]; Ardekani BA, 2009, NEUROIMAGE, V46, P677, DOI 10.1016/j.neuroimage.2009.02.030; Arsigny V, 2006, LECT NOTES COMPUT SC, V4190, P924; Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007; Avants B, 2004, NEUROIMAGE, V23, pS139, DOI 10.1016/j.neuroimage.2004.07.010; Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004; Avants BB, 2006, MED IMAGE ANAL, V10, P397, DOI 10.1016/j.media.2005.03.005; Azencot O, 2014, COMPUT GRAPH FORUM, V33, P237, DOI 10.1111/cgf.12449; Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa; Benhimane S, 2007, INT J ROBOT RES, V26, P661, DOI 10.1177/0278364907080252; Boccardi M, 2015, ALZHEIMERS DEMENT, V11, P175, DOI 10.1016/j.jalz.2014.12.002; Bossa Matias, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563005; Bossa M, 2007, LECT NOTES COMPUT SC, V4791, P667; Cachier P, 2000, LECT NOTES COMPUT SC, V1935, P472; Caviness VS, 1996, J COGNITIVE NEUROSCI, V8, P566, DOI 10.1162/jocn.1996.8.6.566; Chiang MC, 2006, I S BIOMED IMAGING, P193; Christensen GE, 1997, IEEE T MED IMAGING, V16, P864, DOI 10.1109/42.650882; Christensen GE, 2001, IEEE T MED IMAGING, V20, P568, DOI 10.1109/42.932742; Christensen GE, 1999, LECT NOTES COMPUT SC, V1613, P224; Christensen GE, 1996, IEEE T IMAGE PROCESS, V5, P1435, DOI 10.1109/83.536892; COLLINS DL, 1994, J COMPUT ASSIST TOMO, V18, P192, DOI 10.1097/00004728-199403000-00005; Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013; Dahlquist G. G., 1963, BIT, V3, P27, DOI DOI 10.1007/BF01963532; Darkner S, 2013, IEEE T PATTERN ANAL, V35, P1437, DOI 10.1109/TPAMI.2012.238; Darkner S, 2011, LECT NOTES COMPUT SC, V6801, P436, DOI 10.1007/978-3-642-22092-0_36; Durrleman S, 2011, LECT NOTES COMPUT SC, V6801, P123, DOI 10.1007/978-3-642-22092-0_11; Evans A. C., 1992, P 22 S SOC NEUR AN, V179, P408; Hellier P, 2001, IEEE T MED IMAGING, V20, P388, DOI 10.1109/42.925292; Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015; Klein A, 2009, NEUROIMAGE, V46, P786, DOI 10.1016/j.neuroimage.2008.12.037; Kloppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P159, DOI 10.1023/A:1008065931878; Lawson J. D., 1967, SIAM J NUMER ANAL, V4, P372; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Modat M., 2012, 2012 IEEE Workshop on Mathematical Methods in Biomedical Image Analysis (MMBIA), P145, DOI 10.1109/MMBIA.2012.6164745; Ou YM, 2014, IEEE T MED IMAGING, V33, P2039, DOI 10.1109/TMI.2014.2330355; Pai A, 2014, LECT NOTES COMPUT SC, V8545, P223, DOI 10.1007/978-3-319-08554-8_23; Palais R.S., 2009, DIFFERENTIAL EQUATIO, V51; Pennec X, 2005, LECT NOTES COMPUT SC, V3750, P943, DOI 10.1007/11566489_116; Preusser T, 2003, PROC SPIE, V5009, P181, DOI 10.1117/12.474013; Rohlfing T, 2012, IEEE T MED IMAGING, V31, P153, DOI 10.1109/TMI.2011.2163944; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Rueckert D, 2006, LECT NOTES COMPUT SC, V4191, P702; Sabuncu MR, 2009, LECT NOTES COMPUT SC, V5761, P565, DOI 10.1007/978-3-642-04268-3_70; Shattuck DW, 2008, NEUROIMAGE, V39, P1064, DOI 10.1016/j.neuroimage.2007.09.031; Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698; Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051; Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0; Suli E., 2003, INTRO NUMERICAL ANAL; Talairach J., 1988, COPLANAR STEREOTAXIC; Vercauteren T., 2007, LNCS, V10, P319, DOI DOI 10.1016/J.NEUR0IMAGE.2008.10.040; Vercauteren T, 2008, LECT NOTES COMPUT SC, V5241, P754, DOI 10.1007/978-3-540-85988-8_90; Woods RP, 1998, J COMPUT ASSIST TOMO, V22, P153, DOI 10.1097/00004728-199801000-00028; Ying LX, 2006, J COMPUT PHYS, V220, P184, DOI 10.1016/j.jcp.2006.05.008; Ying LX, 2006, J COMPUT PHYS, V220, P6, DOI 10.1016/j.jcp.2006.07.032; Zhang Miaomiao, 2015, Inf Process Med Imaging, V24, P249, DOI 10.1007/978-3-319-19992-4_19	56	6	6	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1570	1583		10.1109/TPAMI.2017.2730205	http://dx.doi.org/10.1109/TPAMI.2017.2730205			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28742029				2022-12-18	WOS:000434294800003
J	Mu, TT; Goulermas, JY; Ananiadou, S				Mu, Tingting; Goulermas, John Yannis; Ananiadou, Sophia			Data Visualization with Structural Control of Global Cohort and Local Data Neighborhoods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cohort visualization; cohort separability; manifold optimization; dimensionality reduction; embedding generation	NONLINEAR DIMENSIONALITY REDUCTION	A typical objective of data visualization is to generate low-dimensional plots that maximally convey the information within the data. The visualization output should help the user not only identify the local neighborhood structure of individual samples, but also obtain a global view of the relative positioning and separation between cohorts. Here, we propose a novel visualization framework designed to satisfy these needs. By incorporating additional cohort positioning and discriminative constraints into local neighbor preservation models through the use of computed cohort prototypes, effective control over the arrangements and proximities of data cohorts can be obtained. We introduce various embedding and projection algorithms based on objective functions addressing the different visualization requirements. Their underlying models are optimized effectively using matrix manifold procedures to incorporate the problem constraints. Additionally, to facilitate large-scale applications, a matrix decomposition based model is also proposed to accelerate the computation. The improved capabilities of the new methods are demonstrated using various state-of-the-art dimensionality reduction algorithms. We present many qualitative and quantitative comparisons, on both synthetic problems and real-world tasks of complex text and image data, that show notable improvements over existing techniques.	[Mu, Tingting; Ananiadou, Sophia] Univ Manchester, Sch Comp Sci, Manchester M1 7DN, Lancs, England; [Goulermas, John Yannis] Univ Liverpool, Dept Comp Sci, Liverpool L69 3BX, Merseyside, England	University of Manchester; University of Liverpool	Goulermas, JY (corresponding author), Univ Liverpool, Dept Comp Sci, Liverpool L69 3BX, Merseyside, England.	tingting.mu@manchester.ac.uk; j.y.goulermas@liverpool.ac.uk; sophia.ananiadou@manchester.ac.uk	Mu, Tingting/AAV-4795-2020	Mu, Tingting/0000-0001-6315-3432; Ananiadou, Sophia/0000-0002-4097-9191	Medical Research Council [MR/L01078X/1] Funding Source: researchfish; MRC [MR/L01078X/1] Funding Source: UKRI	Medical Research Council(UK Research & Innovation (UKRI)Medical Research Council UK (MRC)European Commission); MRC(UK Research & Innovation (UKRI)Medical Research Council UK (MRC))		Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bertini E, 2011, IEEE T VIS COMPUT GR, V17, P2203, DOI 10.1109/TVCG.2011.229; Bordes A., 2013, ADV NEURAL INFORM PR; Bordes A, 2014, MACH LEARN, V94, P233, DOI 10.1007/s10994-013-5363-6; Boumal N, 2014, J MACH LEARN RES, V15, P1455; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Dhillon IS, 2002, COMPUT STAT DATA AN, V41, P59, DOI 10.1016/S0167-9473(02)00144-5; Dhillon PS, 2015, J MACH LEARN RES, V16, P3035; Edelman A., 2008, SIAM J MATRIX ANAL A, V29, P93; Etemadpour R, 2015, IEEE T VIS COMPUT GR, V21, P81, DOI 10.1109/TVCG.2014.2330617; Eynard D, 2015, IEEE T PATTERN ANAL, V37, P2505, DOI 10.1109/TPAMI.2015.2408348; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; Globerson A., 2005, ADV NEURAL INF PROCE, V18, P451, DOI DOI 10.5555/2976248.2976305; Goldberger J, 2004, ADV NEURAL INF PROCE, V17, P513, DOI DOI 10.5555/2976040.2976105; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton Geoffrey, 2002, ADV NEURAL INFORM PR, V15, P833, DOI DOI 10.1109/TSMCB.2011.2106208; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740; Kaski S, 2011, IEEE SIGNAL PROC MAG, V28, P100, DOI 10.1109/MSP.2010.940003; Kim H., 2015, NEUROCOMPUTING, V150, P2399; Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131; Min M.R., 2010, P 27 INT C MACH LEAR, P791; Mu TT, 2012, IEEE T PATTERN ANAL, V34, P2216, DOI 10.1109/TPAMI.2012.20; Ng AY, 2002, ADV NEUR IN, V14, P849; Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592; Quadrianto N., 2011, P 28 INT C MACHINE L; Rodriguez-Martinez E, 2010, IEEE T NEURAL NETWOR, V21, P1281, DOI 10.1109/TNN.2010.2051161; Romero E., 2008, PATTERN RECOGN, V45, P1436; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Song L., 2008, P 20 INT C NEUR INF, P1385; Sugiyama M, 2007, J MACH LEARN RES, V8, P1027; Teh W. Y., 2003, ADV NEURAL INFORMATI, V15, P841; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vandereycken B, 2013, SIAM J OPTIMIZ, V23, P1214, DOI 10.1137/110845768; Venna J, 2010, J MACH LEARN RES, V11, P451; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Weinberger K. Q., 2004, P 21 INT C MACH LEAR, P106, DOI 10.1145/1015330.1015345; Weinberger KQ, 2007, ADV NEURAL INFORM PR, P1489; Weston J., 2008, P 25 INT C MACHINE L, P1168, DOI [DOI 10.1145/1390156.1390303, 10.1145/1390156.1390303]; Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141; Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170; Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235; Zhang ZY, 2012, IEEE T PATTERN ANAL, V34, P253, DOI 10.1109/TPAMI.2011.115	52	6	6	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1323	1337		10.1109/TPAMI.2017.2715806	http://dx.doi.org/10.1109/TPAMI.2017.2715806			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28641245	Green Submitted			2022-12-18	WOS:000431524700004
J	Li, HX; Hua, G				Li, Haoxiang; Hua, Gang			Probabilistic Elastic Part Model: A Pose-Invariant Representation for Real-World Face Verification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian mixture model; probabilistic elastic part model; pose variant face verification; pose-invariant face representation	RECOGNITION	Pose variation remains to be a major challenge for real-world face recognition. We approach this problem through a probabilistic elastic part model. We extract local descriptors (e.g., LBP or SIFT) from densely sampled multi-scale image patches. By augmenting each descriptor with its location, a Gaussian mixture model (GMM) is trained to capture the spatial-appearance distribution of the face parts of all face images in the training corpus, namely the probabilistic elastic part ( PEP) model. Each mixture component of the GMM is confined to be a spherical Gaussian to balance the influence of the appearance and the location terms, which naturally defines a part. Given one or multiple face images of the same subject, the PEP-model builds its PEP representation by sequentially concatenating descriptors identified by each Gaussian component in a maximum likelihood sense. We further propose a joint Bayesian adaptation algorithm to adapt the universally trained GMM to better model the pose variations between the target pair of faces/face tracks, which consistently improves face verification accuracy. Our experiments show that we achieve state-of-the-art face verification accuracy with the proposed representations on the Labeled Face in the Wild (LFW) dataset, the YouTube video face database, and the CMU MultiPIE dataset.	[Li, Haoxiang] Adobe Syst Inc, Adobe Res Dept, San Jose, CA 95110 USA; [Hua, Gang] Microsoft Res, Redmond, WA 98052 USA	Adobe Systems Inc.; Microsoft	Li, HX (corresponding author), Adobe Syst Inc, Adobe Res Dept, San Jose, CA 95110 USA.	haoxli@adobe.com; ganghua@gmail.com	Li, Haoxiang/AAD-1049-2020; Li, Haoxiang/A-1769-2014	Li, Haoxiang/0000-0002-5072-9065; Li, Haoxiang/0000-0002-5072-9065	China National Natural Science Foundation [61629301]; US National Science Foundation [IIS-1350763]; NEC Labs; Adobe Research; Google Research Faculty Award	China National Natural Science Foundation(National Natural Science Foundation of China (NSFC)); US National Science Foundation(National Science Foundation (NSF)); NEC Labs; Adobe Research; Google Research Faculty Award(Google Incorporated)	This work is supported by China National Natural Science Foundation Grant 61629301 and US National Science Foundation Grant IIS-1350763, a Google Research Faculty Award, gift grants from both Adobe Research and NEC Labs.	Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469; Arashloo SR, 2014, IEEE T INF FOREN SEC, V9, P2100, DOI 10.1109/TIFS.2014.2359587; Arashloo SR, 2011, IEEE T PATTERN ANAL, V33, P1274, DOI 10.1109/TPAMI.2010.209; Bauml M, 2013, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2013.462; Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Berg T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.129; Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992; Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195; Chan CH, 2007, LECT NOTES COMPUT SC, V4642, P809; Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Chen HT, 2005, PROC CVPR IEEE, P846; Cox D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P8, DOI 10.1109/FG.2011.5771385; Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456; Dixit M, 2011, PROC CVPR IEEE, P937, DOI 10.1109/CVPR.2011.5995674; El Shafey L, 2013, IEEE T PATTERN ANAL, V35, P1788, DOI 10.1109/TPAMI.2013.38; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Georghiades AS, 1998, PROC CVPR IEEE, P52, DOI 10.1109/CVPR.1998.698587; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gross R, 2000, INT C PATT RECOG, P1088, DOI 10.1109/ICPR.2000.905661; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hasan T, 2011, IEEE T AUDIO SPEECH, V19, P1890, DOI 10.1109/TASL.2010.2102753; Heydari M, 2013, P ICB JUN, P1, DOI [10.1109/IranianCEE.2013.6599563, DOI 10.1109/ICB.2013.6612990]; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Hua G, 2007, IEEE I CONF COMP VIS, P229; Hua G, 2009, IEEE I CONF COMP VIS, P2082, DOI 10.1109/ICCV.2009.5459457; Huang G., 2012, ADV NEURAL INFORM PR, P764; Huang G. B., 2008, P FAC REAL LIF IM WO; Huang G.B., 2008, WORKSHOP FACESREAL L; Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858; Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968; Jain V., 2006, P BRIT MACH VIS C BM, V1, P357; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Kannala J, 2012, INT C PATT RECOG, P1363; Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112; Li HX, 2015, PROC CVPR IEEE, P4055, DOI 10.1109/CVPR.2015.7299032; Li HX, 2013, PROC CVPR IEEE, P3499, DOI 10.1109/CVPR.2013.449; Li SX, 2012, LECT NOTES COMPUT SC, V7572, P102, DOI 10.1007/978-3-642-33718-5_8; Liao SC, 2013, IEEE T PATTERN ANAL, V35, P1193, DOI 10.1109/TPAMI.2012.191; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu C., 2015, CORR; Nowak E, 2007, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2007.382969; Parkhi OM, 2014, PROC CVPR IEEE, P1693, DOI 10.1109/CVPR.2014.219; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266; Pinto Nicolas, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2591, DOI 10.1109/CVPRW.2009.5206605; Prabhu U, 2011, IEEE T PATTERN ANAL, V33, P1952, DOI 10.1109/TPAMI.2011.123; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Tahir MA, 2011, IEEE IMAGE PROC, P765, DOI 10.1109/ICIP.2011.6116667; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Turk M. A., 1991, P IEEE C COMP VIS PA, P302; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang F., 2012, P EUR C COMPUT VIS, P1689; Wang XG, 2004, INT C PATT RECOG, P142, DOI 10.1109/ICPR.2004.1333724; Wolf L, 2013, PROC CVPR IEEE, P3523, DOI 10.1109/CVPR.2013.452; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230; Wright J, 2009, PROC CVPR IEEE, P1502, DOI 10.1109/CVPRW.2009.5206786; Yan S, 2008, PR IEEE COMP DESIGN, P142, DOI 10.1109/ICCD.2008.4751853; Yan SC, 2008, INT CONF ACOUST SPEE, P737; Yi Dong, 2014, CORR; Yin Q, 2011, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2011.5995494; Zhou X, 2009, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2009.5459435	69	6	7	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					918	930		10.1109/TPAMI.2017.2695183	http://dx.doi.org/10.1109/TPAMI.2017.2695183			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28436844	hybrid			2022-12-18	WOS:000426687100011
J	Nguyen-Dinh, LV; Calatroni, A; Troster, G				Long-Van Nguyen-Dinh; Calatroni, Alberto; Troster, Gerhard			Supporting One-Time Point Annotations for Gesture Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						One-time point annotation; boundary correction; weakly supervised learning; gesture spotting; wearable sensors; kinect sensors		This paper investigates a new annotation technique that reduces significantly the amount of time to annotate training data for gesture recognition. Conventionally, the annotations comprise the start and end times, and the corresponding labels of gestures in sensor recordings. In this work, we propose a one-time point annotation in which labelers do not have to select the start and end time carefully, but just mark a one-time point within the time a gesture is happening. The technique gives more freedom and reduces significantly the burden for labelers. To make the one-time point annotations applicable, we propose a novel BoundarySearch algorithm to find automatically the correct temporal boundaries of gestures by discovering data patterns around their given one-time point annotations. The corrected annotations are then used to train gesture models. We evaluate the method on three applications from wearable gesture recognition with various gesture classes (10-17 classes) recorded with different sensor modalities. The results show that training on the corrected annotations can achieve performances close to a fully supervised training on clean annotations (lower by just up to 5 percent F1-score on average). Furthermore, the BoundarySearch algorithm is also evaluated on the ChaLearn 2014 multi-modal gesture recognition challenge recorded with Kinect sensors from computer vision and achieves similar results.	[Long-Van Nguyen-Dinh; Calatroni, Alberto; Troster, Gerhard] Swiss Fed Inst Technol, Wearable Comp Lab, Dept Informat Technol & Elect Engn, CH-8092 Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich	Nguyen-Dinh, LV (corresponding author), Swiss Fed Inst Technol, Wearable Comp Lab, Dept Informat Technol & Elect Engn, CH-8092 Zurich, Switzerland.	longvan@ife.ee.ethz.ch; calatroni@ife.ee.ethz.ch; troester@ife.ee.ethz.ch						Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203; Banos O, 2012, IEEE INT SYM WRBL CO, P92, DOI 10.1109/ISWC.2012.17; Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1; Benbasat A. Y., 2002, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop, GW 2001. Revised Papers (Lecture Notes in Artificial Intelligence Vol.2298), P9; Bojanowski P, 2014, LECT NOTES COMPUT SC, V8693, P628, DOI 10.1007/978-3-319-10602-1_41; Bowden R, 2004, LECT NOTES COMPUT SC, V3021, P390; Brewster S., 2003, P SIGCHI C HUM FACT, P473, DOI DOI 10.1145/642611.642694; Buehler P., 2009, P COMP VIS PATT REC, P2161; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chang JY, 2015, LECT NOTES COMPUT SC, V8925, P503, DOI 10.1007/978-3-319-16178-5_35; Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883; Cooper Helen, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2568, DOI 10.1109/CVPRW.2009.5206647; Cooper H, 2012, J MACH LEARN RES, V13, P2205; Deng JW, 2000, INT C PATT RECOG, P679, DOI 10.1109/ICPR.2000.903636; Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279; Escalera S, 2015, LECT NOTES COMPUT SC, V8925, P459, DOI 10.1007/978-3-319-16178-5_32; Fang GL, 2004, INT C PATT RECOG, P454, DOI 10.1109/ICPR.2004.1333800; Feldman A, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P52, DOI 10.1109/ISWC.2005.44; Froehlich J, 2007, MOBISYS '07: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P57; Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007; Hartmann B, 2010, IEEE INTL CONF CONTR, P1011, DOI 10.1109/CCA.2010.5611298; He ZY, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P217, DOI 10.1109/APCCAS.2008.4745999; Junker H, 2008, PATTERN RECOGN, V41, P2010, DOI 10.1016/j.patcog.2007.11.016; KanisM, INCHI 05 HUM FACT CO, P1521; Keskin Cem, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P72, DOI 10.1007/978-3-642-25446-8_8; Ko MH, 2005, Proceedings of the 2005 Intelligent Sensors, Sensor Networks & Information Processing Conference, P283; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lasecki Walter S., 2013, P 2013 C COMP SUPP C, P1203, DOI DOI 10.1145/2441776.2441912; Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; Nguyen-Dinh LV, 2012, INT CONF INTELL SYST, P831, DOI 10.1109/ISDA.2012.6416645; Monnier C, 2015, LECT NOTES COMPUT SC, V8925, P491, DOI 10.1007/978-3-319-16178-5_34; Neverova N, 2015, LECT NOTES COMPUT SC, V8925, P474, DOI 10.1007/978-3-319-16178-5_33; Nguyen-Dinh L.V., 2013, ICMR, P263, DOI 10.1145/2461466.2461508; Nguyen-Dinh L.-V., 2013, P 1 ACM INT WORKSH P, P35; Nguyen-Dinh L.-V., 2013, P 12 INT C MOB UB MU, P18; Nguyen-Dinh LV, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P807, DOI 10.1145/2638728.2641301; Nguyen-Dinh LV, 2014, J MACH LEARN RES, V15, P3187; Ravi Nishkam, 2005, P 17 C INN APPL ART, V3, P1541, DOI DOI 10.1007/978-3-642-02481-8_120; Roggen D., 2010, 2010 Seventh International Conference on Networked Sensing Systems (INSS 2010), P233, DOI 10.1109/INSS.2010.5573462; Rossi M, 2012, IEEE INT SYM WRBL CO, P25, DOI 10.1109/ISWC.2012.12; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Schlomer T., 2008, P INT C TANGIBLE EMB, P11, DOI DOI 10.1145/1347390.1347395; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; Stiefmeier T, 2008, IEEE PERVAS COMPUT, V7, P42, DOI 10.1109/MPRV.2008.40; Stikic Maja, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P2521, DOI 10.1109/TPAMI.2011.36; Tentori M, 2008, IEEE PERVAS COMPUT, V7, P51, DOI 10.1109/MPRV.2008.24; van Laerhoven K, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P63, DOI 10.1109/ISWC.2008.4911586; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; Wu J, 2009, CHINESE LICENSED PHA, V6, P3, DOI DOI 10.1007/978-3-642-02830-4_; Yuen M.-C., 2011, P IEEE 3 INT C PRIV, P766; Zappi P., 2008, WIREL SENS NETWORKS, P17, DOI [10.1007/978-3-540-77690-1_2, DOI 10.1007/978-3-540-77690-1_2]	53	6	6	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2270	2283		10.1109/TPAMI.2016.2637350	http://dx.doi.org/10.1109/TPAMI.2016.2637350			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	27959802				2022-12-18	WOS:000412028600012
J	Al Ismaeil, K; Aouada, D; Solignac, T; Mirbach, B; Ottersten, B				Al Ismaeil, Kassem; Aouada, Djamila; Solignac, Thomas; Mirbach, Bruno; Ottersten, Bjorn			Real-Time Enhancement of Dynamic Depth Videos with Non-Rigid Deformations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Depth enhancement; super-resolution; non-rigid deformations; registration; Kalman filtering; bilateral total variation	RANGE FLOW; SCENE FLOW; IMAGE; SUPERRESOLUTION; FILTER; SHAPE	We propose a novel approach for enhancing depth videos containing non-rigidly deforming objects. Depth sensors are capable of capturing depth maps in real-time but suffer from high noise levels and low spatial resolutions. While solutions for reconstructing 3D details in static scenes, or scenes with rigid global motions have been recently proposed, handling unconstrained non-rigid deformations in relative complex scenes remains a challenge. Our solution consists in a recursive dynamic multi-frame super-resolution algorithm where the relative local 3D motions between consecutive frames are directly accounted for. We rely on the assumption that these 3D motions can be decoupled into lateral motions and radial displacements. This allows to perform a simple local per-pixel tracking where both depth measurements and deformations are dynamically optimized. The geometric smoothness is subsequently added using a multi-level L-1 minimization with a bilateral total variation regularization. The performance of this method is thoroughly evaluated on both real and synthetic data. As compared to alternative approaches, the results show a clear improvement in reconstruction accuracy and in robustness to noise, to relative large non-rigid deformations, and to topological changes. Moreover, the proposed approach, implemented on a CPU, is shown to be computationally efficient and working in real-time.	[Al Ismaeil, Kassem; Aouada, Djamila; Ottersten, Bjorn] Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil & Trust, L-2721 Eschsur Alzette, Luxembourg; [Solignac, Thomas; Mirbach, Bruno] IEE SA, Adv Engn Dept, L-5326 Contern, Luxembourg	University of Luxembourg	Al Ismaeil, K (corresponding author), Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil & Trust, L-2721 Eschsur Alzette, Luxembourg.	kassem.alismaeil@iee.lu; djamila.aouada@iee.lu; thomas.solignac@iee.lu; bruno.mirbach@iee.lu; bjorn.ottersten@uni.lu	Ottersten, Bjorn/AAF-9147-2019; Ottersten, Bjorn/G-1005-2011	Aouada, Djamila/0000-0002-7576-2064; Ottersten, Bjorn/0000-0003-2298-6774	National Research Fund, Luxembourg [C11/BM/1204105/FAVE/Ottersten]	National Research Fund, Luxembourg(Luxembourg National Research Fund)	This work was supported by the National Research Fund, Luxembourg, under C11/BM/1204105/FAVE/Ottersten. The "Facecap" data were provided courtesy of the research group Graphics, Vision & Video of the Max-Planck-Institute for Informatics. The authors would like to thank David Ferstl et al. for making the codes for [28] and [29] publically available, and Konstantinos Papadopoulos and Michel Antunes for their help with the experiments. They also thank the Associate Editor and the anonymous reviewers for their suggestions and comments.	Afzal H, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON 3D VISION, VOL. 2, P7, DOI 10.1109/3DV.2014.114; Al Ismaeil Kassem, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P8, DOI 10.1109/CVPRW.2015.7301389; Al Ismaeil Kassem, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P100, DOI 10.1007/978-3-642-40246-3_13; Al Ismaeil K, 2016, COMPUT VIS IMAGE UND, V147, P38, DOI 10.1016/j.cviu.2016.04.006; Al Ismaeil K, 2013, IEEE IMAGE PROC, P660, DOI 10.1109/ICIP.2013.6738136; Al-Ismaeil K, 2012, INT C PATT RECOG, P258; Aouada Djamila, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P186; Aouada D, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P107, DOI 10.1109/AVSS.2014.6918652; Berretti S, 2014, IEEE T INF FOREN SEC, V9, P1436, DOI 10.1109/TIFS.2014.2337258; Berretti S, 2012, LECT NOTES COMPUT SC, V7583, P73, DOI 10.1007/978-3-642-33863-2_8; Charest MR, 2006, 2006 40TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-4, P452, DOI 10.1109/CISS.2006.286510; Cui Y, 2013, IEEE T PATTERN ANAL, V35, P1039, DOI 10.1109/TPAMI.2012.190; Diebel James, 2005, NEURAL INF PROCESS S, P291; Dou MS, 2015, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2015.7298647; Elad M, 1999, IEEE T IMAGE PROCESS, V8, P387, DOI 10.1109/83.748893; Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126; Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669; Farsiu S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/61859; Ferstl David, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P285, DOI 10.1109/3DV.2014.19; Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127; Garcia F., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P42, DOI 10.1109/AVSS.2011.6027291; Garcia F, 2015, IMAGE VISION COMPUT, V41, P26, DOI 10.1016/j.imavis.2015.06.008; Garcia F, 2010, IEEE IMAGE PROC, P2805, DOI 10.1109/ICIP.2010.5651112; Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271; Gottfried Jens-Malte, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P758; Hadfield S, 2014, IEEE T PATTERN ANAL, V36, P564, DOI 10.1109/TPAMI.2013.162; Hadfield S, 2011, IEEE I CONF COMP VIS, P2290, DOI 10.1109/ICCV.2011.6126509; Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115; Herbst E, 2013, IEEE INT CONF ROBOT, P2276, DOI 10.1109/ICRA.2013.6630885; Hornacek M, 2013, PROC CVPR IEEE, P1123, DOI 10.1109/CVPR.2013.149; Izadi Shahram, 2011, UIST, DOI [10.1145/2047196.2047270, DOI 10.1145/2047196.2047270]; Kheradmand A, 2014, IEEE T IMAGE PROCESS, V23, P5136, DOI 10.1109/TIP.2014.2362059; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Li H., 2013, ACM T GRAPHIC, V32; Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508407; Li J, 2014, PROC CVPR IEEE, P3374, DOI 10.1109/CVPR.2014.431; Li WS, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-222; Mac Aodha O, 2012, LECT NOTES COMPUT SC, V7574, P71, DOI 10.1007/978-3-642-33712-3_6; Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329; Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631; Newland CB, 2007, IASTED INT CONF SIGN, P58; Or-El R, 2015, PROC CVPR IEEE, P5407, DOI 10.1109/CVPR.2015.7299179; Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412; PMD Technologies, CAMB NAN; Schuon S, 2009, PROC CVPR IEEE, P343, DOI 10.1109/CVPRW.2009.5206804; Spies H, 2002, INT C PATT RECOG, P517, DOI 10.1109/ICPR.2002.1047990; Spies H, 2002, COMPUT VIS IMAGE UND, V85, P209, DOI 10.1006/cviu.2002.0970; Spies H., 2000, P ECCV, V1843, P785; Sturmer Michael, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563166; Tian J., 2005, P IEEE INT C IM PROC, V1, P881; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56; Valgaerts L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366206; Wedel A, 2011, INT J COMPUT VISION, V95, P29, DOI 10.1007/s11263-010-0404-0; Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211; YAMAMOTO M, 1993, IEEE T PATTERN ANAL, V15, P82, DOI 10.1109/34.184776; Yanjie Li, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P152, DOI 10.1109/ICME.2012.30; Zhu JJ, 2011, IEEE T PATTERN ANAL, V33, P1400, DOI 10.1109/TPAMI.2010.172; Zollhofer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601165	60	6	6	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					2045	2059		10.1109/TPAMI.2016.2622698	http://dx.doi.org/10.1109/TPAMI.2016.2622698			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	27810799				2022-12-18	WOS:000408807600011
J	Agarwal, R; Chen, Z; Sarma, SV				Agarwal, Rahul; Chen, Zhe; Sarma, Sridevi V.			A Novel Nonparametric Maximum Likelihood Estimator for Probability Density Functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Maximum likelihood; nonparametric; estimation; density; pdf; tail estimation; neuronal receptive fields	BANDWIDTH SELECTION; DRIVEN; FIELDS	Parametric maximum likelihood (ML) estimators of probability density functions (pdfs) are widely used today because they are efficient to compute and have several nice properties such as consistency, fast convergence rates, and asymptotic normality. However, data is often complex making parametrization of the pdf difficult, and nonparametric estimation is required. Popular nonparametric methods, such as kernel density estimation (KDE), produce consistent estimators but are not ML and have slower convergence rates than parametric ML estimators. Further, these nonparametric methods do not share the other desirable properties of parametric ML estimators. This paper introduces a nonparametric ML estimator that assumes that the square-root of the underlying pdf is band-limited (BL) and hence "smooth". The BLML estimator is computed and shown to be consistent. Although convergence rates are not theoretically derived, the BLML estimator exhibits faster convergence rates than state-of-the-art nonparametric methods in simulations. Further, algorithms to compute the BLML estimator with lesser computational complexity than that of KDE methods are presented. The efficacy of the BLML estimator is shown by applying it to (i) density tail estimation and (ii) density estimation of complex neuronal receptive fields where it outperforms state-of-the-art methods used in neuroscience.	[Agarwal, Rahul; Sarma, Sridevi V.] Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD 21218 USA; [Chen, Zhe] NYU, Sch Med, Dept Psychiat, New York, NY 10016 USA	Johns Hopkins University; New York University	Agarwal, R (corresponding author), Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD 21218 USA.	rahul.jhu@gmail.com; zhe.chen3@nyumc.org; sridevi.sarma@gmail.com		Chen, Zhe (Sage)/0000-0002-6483-6056				Agarwal Rahul, 2016, 2016 Annual Conference on Information Science and Systems (CISS), P562, DOI 10.1109/CISS.2016.7460564; Agarwal R, 2016, NEURAL COMPUT, V28, P1356, DOI 10.1162/NECO_a_00847; Agarwal R, 2015, J NEUROSCI, V35, P9508, DOI 10.1523/JNEUROSCI.2643-14.2015; Agarwal R, 2014, IEEE ENG MED BIO, P6573, DOI 10.1109/EMBC.2014.6945134; Agarwal R, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002626; Agarwal R, 2010, IEEE ENG MED BIO, P1539, DOI 10.1109/IEMBS.2010.5626828; AKAIKE H, 1973, SIAM J APPL MATH, V24, P234, DOI 10.1137/0124024; [Anonymous], 2010, REAL ANAL; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; Boyd S, 2004, CONVEX OPTIMIZATION; Carando D, 2009, J MULTIVARIATE ANAL, V100, P981, DOI 10.1016/j.jmva.2008.10.001; Coleman TP, 2010, NEURAL COMPUT, V22, P2002, DOI 10.1162/NECO_a_00001-Coleman; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Donoho DL, 1996, ANN STAT, V24, P508; Efromovich S, 2010, WIRES COMPUT STAT, V2, P467, DOI 10.1002/wics.97; Gelfand I. M., 2000, CALCULUS VARIATIONS; Gurobi Optimization Inc., 2015, GUR OPT REF MAN; Haan L., 2007, EXTREME VALUE THEORY; HALL P, 1987, ANN STAT, V15, P163, DOI 10.1214/aos/1176350259; HALL P, 1991, BIOMETRIKA, V78, P263; Jones MC, 1996, J AM STAT ASSOC, V91, P401, DOI 10.2307/2291420; KANAZAWA Y, 1993, STAT PROBABIL LETT, V18, P315, DOI 10.1016/0167-7152(93)90022-B; Knuth D. E., 1993, THE SANDWICH THEOREM; Kobayashi H., 2011, PROBABILITY RANDOM P; Kochen S., 1964, ILLINOIS J MATH, V8, P248; Lizorkin P., 2001, HAZEWINKEL MICHIEL E; Marks II RJ, 1991, INTRO SHANNON SAMPLI; Merz P, 2002, J HEURISTICS, V8, P197, DOI 10.1023/A:1017912624016; MONTRICHER GFD, 1975, ANN STAT, V3, P1329; Park B. U., 1992, Computational Statistics, V7, P251; PARK BU, 1990, J AM STAT ASSOC, V85, P66, DOI 10.2307/2289526; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Peristera P., 2008, J POPULATION RES, V22, P185; Peter AM, 2008, IEEE T IMAGE PROCESS, V17, P458, DOI 10.1109/TIP.2008.918038; Pinheiro A, 1997, COMPUT STAT DATA AN, V25, P399, DOI 10.1016/S0167-9473(97)00013-3; Protzmann M., 2001, Journal of Electrical Engineering, V52, P96; Rao C. R., 2008, SCHOLARPEDIA, V3; Raykar VC, 2010, J COMPUT GRAPH STAT, V19, P205, DOI 10.1198/jcgs.2010.09046; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Scaillet O, 2004, J NONPARAMETR STAT, V16, P217, DOI 10.1080/10485250310001624819; SCHMEIDLER D, 1970, P AM MATH SOC, V24, P300, DOI 10.2307/2036351; Silverman B. W., 1986, DENSITY ESTIMATION S, V26; SILVERMAN BW, 1982, APPL STAT-J ROY ST C, V31, P93, DOI 10.2307/2347084; WATSON GS, 1969, ANN MATH STAT, V40, P1496, DOI 10.1214/aoms/1177697523	44	6	6	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1294	1308		10.1109/TPAMI.2016.2598333	http://dx.doi.org/10.1109/TPAMI.2016.2598333			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27514035	hybrid			2022-12-18	WOS:000402744400002
J	Lin, JY; Liu, YB; Suo, JL; Dai, QH				Lin, Jingyu; Liu, Yebin; Suo, Jinli; Dai, Qionghai			Frequency-Domain Transient Imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Frequency domain; multi-frequency; transient imaging; time-of-flight camera; 3D shape	MULTIPATH INTERFERENCE; FLIGHT	A transient image is the optical impulse response of a scene, which also visualizes the propagation of light during an ultra-short time interval. In contrast to the previous transient imaging which samples in the time domain using an ultra-fast imaging system, this paper proposes transient imaging in the frequency domain using a multi-frequency time-of-flight (ToF) camera. Our analysis reveals the Fourier relationship between transient images and the measurements of a multi-frequency ToF camera, and identifies the causes of the systematic error-non-sinusoidal and frequency-varying waveforms and limited frequency range of the modulation signal. Based on the analysis we propose a novel framework of frequency-domain transient imaging. By removing the systematic error and exploiting the harmonic components inside the measurements, we achieves high quality reconstruction results. Moreover, our technique significantly reduces the computational cost of ToF camera based transient image reconstruction, especially reduces the memory usage, such that it is feasible for the reconstruction of transient images at extremely small time steps. The effectiveness of frequency-domain transient imaging is tested on synthetic data, real data from the web, and real data acquired by our prototype camera.	[Lin, Jingyu; Liu, Yebin; Suo, Jinli; Dai, Qionghai] Tsinghua Univ, Dept Automat, Beijing, Peoples R China; [Lin, Jingyu; Liu, Yebin; Suo, Jinli; Dai, Qionghai] Tsinghua Univ, Beijing Key Lab Multidimens & Multiscale Computat, Beijing, Peoples R China; [Lin, Jingyu] Guangxi Univ, Coll Elect Engn, Nanning, Peoples R China; [Liu, Yebin; Suo, Jinli; Dai, Qionghai] Tsinghua Berkeley Shenzhen Inst, Shenzhen, Peoples R China	Tsinghua University; Tsinghua University; Guangxi University	Lin, JY (corresponding author), Tsinghua Univ, Dept Automat, Beijing, Peoples R China.; Lin, JY (corresponding author), Tsinghua Univ, Beijing Key Lab Multidimens & Multiscale Computat, Beijing, Peoples R China.; Lin, JY (corresponding author), Guangxi Univ, Coll Elect Engn, Nanning, Peoples R China.	jylin@gxu.edu.cn; liuyebin@tsinghua.edu.cn; jlsuo@tsinghua.edu.cn; qionghaidai@tsinghua.edu.cn	Liu, Yebin/L-7393-2019; Dai, Qionghai/ABD-5298-2021	Dai, Qionghai/0000-0001-7043-3061; Lin, Jingyu/0000-0002-7194-3300	NSFC [61327902, 61561005, 61522111, 61531014]; National Key Foundation for Exploring Scientific Instrument [2013YQ140517]; NSF of Guangxi Province [2015GXNSFAA139284]	NSFC(National Natural Science Foundation of China (NSFC)); National Key Foundation for Exploring Scientific Instrument; NSF of Guangxi Province(National Natural Science Foundation of Guangxi Province)	This work was supported by the Project of NSFC (Nos. 61327902, 61561005, 61522111, and 61531014), National Key Foundation for Exploring Scientific Instrument (No. 2013YQ140517), and NSF of Guangxi Province (No. 2015GXNSFAA139284).	ABRAMSON N, 1978, OPT LETT, V3, P121, DOI 10.1364/OL.3.000121; Bhandari A, 2014, OPT LETT, V39, P1705, DOI 10.1364/OL.39.001705; Cui Y, 2010, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2010.5540082; Dorrington AA, 2011, PROC SPIE, V7864, DOI 10.1117/12.876586; Droeschel D, 2010, IEEE INT C INT ROBOT, P1463, DOI 10.1109/IROS.2010.5649488; Freedman D, 2014, LECT NOTES COMPUT SC, V8689, P234, DOI 10.1007/978-3-319-10590-1_16; Fuchs Stefan, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P31, DOI 10.1007/978-3-642-39402-7_4; Fuchs Stefan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3583, DOI 10.1109/ICPR.2010.874; Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141; Godbaz JP, 2012, REMOTE SENS-BASEL, V4, P21, DOI 10.3390/rs4010021; Godbaz JP, 2012, PROC SPIE, V8296, DOI 10.1117/12.909778; Heide F, 2014, OPT EXPRESS, V22, P26338, DOI 10.1364/OE.22.026338; Heide F, 2014, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2014.418; Heide F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516974; Jimenez D, 2014, IMAGE VISION COMPUT, V32, P1, DOI 10.1016/j.imavis.2013.10.008; Kadambi A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508428; Kirmani A, 2013, IEEE INT CON MULTI; Kirmani A, 2011, INT J COMPUT VISION, V95, P13, DOI 10.1007/s11263-011-0470-y; Kollorz Eva, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P334, DOI 10.1504/IJISTA.2008.021296; Lin JY, 2014, PROC CVPR IEEE, P3230, DOI 10.1109/CVPR.2014.419; Payne AD, 2008, PROC SPIE, V6805, DOI 10.1117/12.765930; Schneider PC, 1997, REV SCI INSTRUM, V68, P4107, DOI 10.1063/1.1148354; Simpson ML, 2005, APPL OPTICS, V44, P7210, DOI 10.1364/AO.44.007210; Squire A, 2000, J MICROSC-OXFORD, V197, P136, DOI 10.1046/j.1365-2818.2000.00651.x; Velten A, 2013, ACM T GRAPHIC, V32, P1, DOI DOI 10.1145/2461912.2461928; Velten A, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1747; Wu D, 2012, LECT NOTES COMPUT SC, V7572, P542, DOI 10.1007/978-3-642-33718-5_39; Wu D, 2012, PROC CVPR IEEE, P366, DOI 10.1109/CVPR.2012.6247697	28	6	7	0	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					937	950		10.1109/TPAMI.2016.2560814	http://dx.doi.org/10.1109/TPAMI.2016.2560814			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	28113541				2022-12-18	WOS:000399250000008
J	Tanaka, K; Mukaigawa, Y; Kubo, H; Matsushita, Y; Yagi, Y				Tanaka, Kenichiro; Mukaigawa, Yasuhiro; Kubo, Hiroyuki; Matsushita, Yasuyuki; Yagi, Yasushi			Recovering Inner Slices of Layered Translucent Objects by Multi-Frequency Illumination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Descattering; layer separation; image restoration; projector-camera system	LIGHT; MICROSCOPY; IMAGES; MEDIA	This paper describes a method for recovering appearance of inner slices of translucent objects. The appearance of a layered translucent object is the summed appearance of all layers, where each layer is blurred by a depth- dependent point spread function (PSF). By exploiting the difference of low-pass characteristics of depth- dependent PSFs, we develop a multi-frequency illumination method for obtaining the appearance of individual inner slices. Specifically, by observing the target object with varying the spatial frequency of checker-pattern illumination, our method recovers the appearance of inner slices via computation. We study the effect of non-uniform transmission due to inhomogeneity of translucent objects and develop a method for recovering clear inner slices based on the pixel-wise PSF estimates under the assumption of spatial smoothness of inner slice appearances. We quantitatively evaluate the accuracy of the proposed method by simulations and qualitatively show faithful recovery using real-world scenes.	[Tanaka, Kenichiro; Yagi, Yasushi] Osaka Univ, Inst Sci & Ind Res, Osaka 5670047, Japan; [Mukaigawa, Yasuhiro; Kubo, Hiroyuki] Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara 6300192, Japan; [Matsushita, Yasuyuki] Osaka Univ, Grad Sch Informat Sci & Technol, Suita, Osaka 5650871, Japan	Osaka University; Nara Institute of Science & Technology; Osaka University	Tanaka, K (corresponding author), Osaka Univ, Inst Sci & Ind Res, Osaka 5670047, Japan.	tanaka@am.sanken.osaka-u.ac.jp; mukaigawa@is.naist.jp; hkubo@is.naist.jp; yasumat@ist.osaka-u.ac.jp; yagi@am.sanken.osaka-u.ac.jp	Kubo, Hiroyuki/AAS-1487-2021	Kubo, Hiroyuki/0000-0002-7061-7941; Matsushita, Yasuyui/0000-0002-1935-4752	JSPS KAKENHI [JP26-6433]	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	We thank all anonymous reviewers who gave us various insightful and constructive comments. We thank Norihiko Kawai for providing his inpainting implementation. The part of this work is supported by JSPS KAKENHI Grant Number JP26-6433, Grant-in-Aid for JSPS Fellows.	Achar S, 2014, LECT NOTES COMPUT SC, V8689, P205, DOI 10.1007/978-3-319-10590-1_14; Achar S, 2013, IEEE I CONF COMP VIS, P1481, DOI 10.1109/ICCV.2013.187; Adam AJL, 2009, OPT EXPRESS, V17, P3407, DOI 10.1364/OE.17.003407; Chandrasekhar S., 1960, RAD TRANSFER; Corle T.R., 1996, CONFOCAL SCANNING OP; d'Eon E., 2011, P SIGGRAPH; Dik J, 2008, ANAL CHEM, V80, P6436, DOI 10.1021/ac800965g; Donner C, 2005, ACM T GRAPHIC, V24, P1032, DOI 10.1145/1073204.1073308; Fercher A F, 1996, J Biomed Opt, V1, P157, DOI 10.1117/12.231361; Fuchs C, 2008, COMPUT GRAPH FORUM, V27, P1245, DOI 10.1111/j.1467-8659.2008.01263.x; Gavrilov D., 2008, INT C NDT ART MAY, P1; Gu JW, 2013, IEEE T PATTERN ANAL, V35, P555, DOI 10.1109/TPAMI.2012.130; Gupta M, 2012, INT J COMPUT VISION, V98, P146, DOI 10.1007/s11263-011-0500-9; Gustafsson MGL, 2008, BIOPHYS J, V94, P4957, DOI 10.1529/biophysj.107.120345; Hanrahan P., 1993, Computer Graphics Proceedings, P165, DOI 10.1145/166117.166139; Hawkins T, 2005, ACM T GRAPHIC, V24, P812, DOI 10.1145/1073204.1073266; Heide F, 2014, OPT EXPRESS, V22, P26338, DOI 10.1364/OE.22.026338; HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169; Ihrke I, 2006, GRAPH MODELS, V68, P484, DOI 10.1016/j.gmod.2006.08.001; Ishimaru A., 1997, WAVE PROPAGATION SCA; Jakob W, 2014, ACM T GRAPHIC, V33, P1; Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319; Kadambi A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508428; Kawai N, 2012, INT C PATT RECOG, P2744; Kner P, 2009, NAT METHODS, V6, P339, DOI [10.1038/NMETH.1324, 10.1038/nmeth.1324]; Kubelka P., 1931, Z TECH PHYS, V12, P593, DOI DOI 10.4236/MSCE.2014.28004; Lamond B., 2007, P SIGGRAPH SKETCH 20; Levoy M, 2004, ACM T GRAPHIC, V23, P825, DOI 10.1145/1015706.1015806; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Li Y, 2014, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2014.346; Lizorkin P., 2001, HAZEWINKEL MICHIEL E; Morris NJW, 2007, IEEE I CONF COMP VIS, P425; Mukaigawa Yasuhiro, 2011, IPSJ Transactions on Computer Vision and Applications, V3, P122, DOI 10.2197/ipsjtcva.3.122; Mukaigawa Y, 2010, PROC CVPR IEEE, P153, DOI 10.1109/CVPR.2010.5540216; Narasimhan SG, 2005, IEEE I CONF COMP VIS, P420; Narasimhan SG, 2003, PROC CVPR IEEE, P665; Narasimhan SG, 2006, ACM T GRAPHIC, V25, P1003, DOI 10.1145/1141911.1141986; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; O'Toole M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766897; O'Toole M, 2014, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2014.421; O'Toole M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601103; O'Toole M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185535; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; Reddy D, 2012, LECT NOTES COMPUT SC, V7577, P596, DOI 10.1007/978-3-642-33783-3_43; Sarel B, 2004, LECT NOTES COMPUT SC, V2034, P328; Shimizu K, 2005, APPL OPTICS, V44, P2154, DOI 10.1364/AO.44.002154; Szeliski R, 2000, PROC CVPR IEEE, P246, DOI 10.1109/CVPR.2000.855826; Tadano R, 2015, IEEE I CONF COMP VIS, P3595, DOI 10.1109/ICCV.2015.410; Tanaka K., 2013, P 16 INT C ADV ROBOT, P1, DOI [10.1109/ICAR.2013.6766534, DOI 10.1109/ICAR.2013.6766534]; Tanaka K, 2015, PROC CVPR IEEE, P5464, DOI 10.1109/CVPR.2015.7299185; Therrien OD, 2011, BIOMED OPT EXPRESS, V2, P696, DOI 10.1364/BOE.2.000696; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x	53	6	6	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					746	757		10.1109/TPAMI.2016.2631625	http://dx.doi.org/10.1109/TPAMI.2016.2631625			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	27893384				2022-12-18	WOS:000397717600011
J	Zhai, YT; Ong, YS; Tsang, IW				Zhai, Yiteng; Ong, Yew-Soon; Tsang, Ivor W.			Making Trillion Correlations Feasible in Feature Grouping and Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Big dimensionality; feature grouping; sparse correlation; one-class learning; robust feature selection	VARIABLE SELECTION; PSORIASIS	Today, modern databases with "Big Dimensionality" are experiencing a growing trend. Existing approaches that require the calculations of pairwise feature correlations in their algorithmic designs have scored miserably on such databases, since computing the full correlation matrix (i.e., square of dimensionality in size) is computationally very intensive (i.e., million features would translate to trillion correlations). This poses a notable challenge that has received much lesser attention in the field of machine learning and data mining research. Thus, this paper presents a study to fill in this gap. Our findings on several established databases with big dimensionality across a wide spectrum of domains have indicated that an extremely small portion of the feature pairs contributes significantly to the underlying interactions and there exists feature groups that are highly correlated. Inspired by the intriguing observations, we introduce a novel learning approach that exploits the presence of sparse correlations for the efficient identifications of informative and correlated feature groups from big dimensional data that translates to a reduction in complexity from O(m(2)n) to O(m log m + K(a)mn), where K-a << min(m, n) generally holds. In particular, our proposed approach considers an explicit incorporation of linear and nonlinear correlation measures as constraints in the learning model. An efficient embedded feature selection strategy, designed to filter out the large number of non-contributing correlations that could otherwise confuse the classifier while identifying the correlated and informative feature groups, forms one of the highlights of our approach. We also demonstrated the proposed method on one-class learning, where notable speedup can be observed when solving one-class problem on big dimensional data. Further, to identify robust informative features with minimal sampling bias, our feature selection strategy embeds the V-fold cross validation in the learning model, so as to seek for features that exhibit stable or consistent performance accuracy on multiple data folds. Extensive empirical studies on both synthetic and several real-world datasets comprising up to 30 million dimensions are subsequently conducted to assess and showcase the efficacy of the proposed approach.	[Zhai, Yiteng; Ong, Yew-Soon] Nanyang Technol Univ, Rolls Royce NTU Corp Lab, Block N4,2a-32 Nanyang Ave, Singapore 639798, Singapore; [Zhai, Yiteng; Ong, Yew-Soon] Nanyang Technol Univ, Sch Comp Sci & Engn, Block N4,2a-32 Nanyang Ave, Singapore 639798, Singapore; [Tsang, Ivor W.] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Sydney, NSW 2007, Australia	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Technology Sydney	Zhai, YT (corresponding author), Nanyang Technol Univ, Rolls Royce NTU Corp Lab, Block N4,2a-32 Nanyang Ave, Singapore 639798, Singapore.; Zhai, YT (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Block N4,2a-32 Nanyang Ave, Singapore 639798, Singapore.	yzhai1@ntu.edu.sg; asysong@ntu.edu.sg; ivor.tsang@gmail.com	Ong, Yew-Soon/A-3733-2011	Ong, Yew-Soon/0000-0002-4480-169X; Tsang, Ivor/0000-0001-8095-4637	National Research Foundation (NRF) Singapore under the Corp Lab@University Scheme; ARC Future Fellowship [FT130100746]; ARC [LP150100671]	National Research Foundation (NRF) Singapore under the Corp Lab@University Scheme(National Research Foundation, Singapore); ARC Future Fellowship(Australian Research Council); ARC(Australian Research Council)	This work was conducted within the Rolls-Royce@NTU Corporate Lab with support from the National Research Foundation (NRF) Singapore under the Corp Lab@University Scheme. Further, Dr. Ivor W. Tsang is grateful for the support from the ARC Future Fellowship FT130100746 and ARC grant LP150100671.	Achlioptas P., 2011, P 17 ACM SIGKDD INT, P726; [Anonymous], 1999, CORRELATION BASED FE; Bach FR, 2008, J MACH LEARN RES, V9, P1179; Brookes AJ, 1999, GENE, V234, P177, DOI 10.1016/S0378-1119(99)00219-X; Calderhead B, 2011, INTERFACE FOCUS, V1, P821, DOI 10.1098/rsfs.2011.0051; Chen M, 2015, IEEE T KNOWL DATA EN, V27, P1465, DOI 10.1109/TKDE.2014.2382599; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; Fan JQ, 2009, J MACH LEARN RES, V10, P2013; FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022; Feng L, 2015, IEEE T EVOLUT COMPUT, V19, P644, DOI 10.1109/TEVC.2014.2362558; Feng YQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2085, DOI 10.1109/ICMLC.2003.1259848; Gupta A, 2016, IEEE T EVOLUT COMPUT, V20, P343, DOI 10.1109/TEVC.2015.2458037; Guyon I., 2008, PRACTICAL FEATURE SE; Joachims T, 2006, PROC 22 ACM SIGKDD I, P217, DOI DOI 10.1145/1150402.1150429; Kalousis, 2012, P ACM SIGKDD C KNOWL, P913; Kim S, 2009, PLOS GENET, V5, DOI 10.1371/journal.pgen.1000587; Li Y.-F., 2009, P 12 INT C ART INT S, V5, P344; Mutapcic A, 2009, OPTIM METHOD SOFTW, V24, P381, DOI 10.1080/10556780802712889; Nair RP, 2009, NAT GENET, V41, P199, DOI 10.1038/ng.311; Nie FP, 2011, IEEE T NEURAL NETWOR, V22, P1796, DOI 10.1109/TNN.2011.2162000; Omidvar MN, 2014, IEEE T EVOLUT COMPUT, V18, P378, DOI 10.1109/TEVC.2013.2281543; Orru S, 2002, TISSUE ANTIGENS, V60, P292, DOI 10.1034/j.1399-0039.2002.600403.x; PATURI R, 1995, INFORM COMPUT, V117, P187, DOI 10.1006/inco.1995.1038; Pearson Karl, 1914, LIFE LETT LABOURS FR; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Press, 1993, NUMERICAL RECIPES C; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Saeys Y, 2008, LECT NOTES ARTIF INT, V5212, P313, DOI 10.1007/978-3-540-87481-2_21; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Speed T, 2011, SCIENCE, V334, P1502, DOI 10.1126/science.1215894; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Valiant G, 2012, ANN IEEE SYMP FOUND, P11, DOI 10.1109/FOCS.2012.27; Wang H, 2015, P 24 ACM INT C INF K, P1687; Yang Sen, 2012, KDD, P922; Yuan GX, 2011, P 17 ACM SIGKDD INT, P33, DOI DOI 10.1145/2020408.2020421; Zhai Y., 2012, P 29 INT C MACH LEAR, P1455; Zhai YT, 2014, IEEE COMPUT INTELL M, V9, P14, DOI 10.1109/MCI.2014.2326099; Zhao Z., 2011, ADV FEATURE SELECTIO; Zhao Z, 2013, IEEE T KNOWL DATA EN, V25, P619, DOI 10.1109/TKDE.2011.222; Zhong L. W., 2011, INT C MACH LEARN BEL; Zhou LP, 2010, IEEE T NEURAL NETWOR, V21, P853, DOI 10.1109/TNN.2010.2044189; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	46	6	6	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2472	2486		10.1109/TPAMI.2016.2533384	http://dx.doi.org/10.1109/TPAMI.2016.2533384			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	27824584				2022-12-18	WOS:000387984700010
J	Barrett, DP; Barbu, A; Siddharth, N; Siskind, JM				Barrett, Daniel Paul; Barbu, Andrei; Siddharth, N.; Siskind, Jeffrey Mark			Saying What You're Looking For: Linguistics Meets Video Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Retrieval; video; language; tracking; object detection; event recognition; sentential video retrieval	CONVOLUTIONAL-CODES	We present an approach to searching large video corpora for clips which depict a natural-language query in the form of a sentence. Compositional semantics is used to encode subtle meaning differences lost in other approaches, such as the difference between two sentences which have identical words but entirely different meaning: The person rode the horse versus The horse rode the person. Given a sentential query and a natural-language parser, we produce a score indicating how well a video clip depicts that sentence for each clip in a corpus and return a ranked list of clips. Two fundamental problems are addressed simultaneously: detecting and tracking objects, and recognizing whether those tracks depict the query. Because both tracking and object detection are unreliable, our approach uses the sentential query to focus the tracker on the relevant participants and ensures that the resulting tracks are described by the sentential query. While most earlier work was limited to single-word queries which correspond to either verbs or nouns, we search for complex queries which contain multiple phrases, such as prepositional phrases, and modifiers, such as adverbs. We demonstrate this approach by searching for 2,627 naturally elicited sentential queries in 10 Hollywood movies.	[Barrett, Daniel Paul; Barbu, Andrei; Siddharth, N.; Siskind, Jeffrey Mark] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA	Purdue University System; Purdue University; Purdue University West Lafayette Campus	Barrett, DP (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.	dpbarret@purdue.edu; andrei@0xab.com; siddharth@iffsid.com; qobi@purdue.edu		Narayanaswamy, Siddharth/0000-0003-4911-7333	Army Research Laboratory;  [W911NF-10-2-0060]	Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); 	This research was sponsored by the Army Research Laboratory and was accomplished under Cooperative Agreement Number W911NF-10-2-0060. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either express or implied, of the Army Research Laboratory or the US Government. The US Government is authorized to reproduce and distribute reprints for Government purposes, notwithstanding any copyright notation herein.	Anjulan A, 2009, IEEE T CIRC SYST VID, V19, P63, DOI 10.1109/TCSVT.2008.2005801; Aytar Y., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587822; Barbu A., 2014, P CVPR WORKSH VIS ME; Barbu A., 2012, ADV COGNITIVE SYSTEM, V2, P203; Barbu A., 2012, ARXIV12042742, P102; Bellman RE, 1957, DYNAMIC PROGRAMMING; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Byrne D, 2010, MULTIMED TOOLS APPL, V49, P119, DOI 10.1007/s11042-009-0403-8; Chang P, 2002, IEEE IMAGE PROC, P609; Chen CY, 2013, PROC CVPR IEEE, P572, DOI 10.1109/CVPR.2013.80; Christel MG, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1032; Cooper M, 2007, IEEE T MULTIMEDIA, V9, P610, DOI 10.1109/TMM.2006.888015; Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Everts I, 2013, PROC CVPR IEEE, P2850, DOI 10.1109/CVPR.2013.367; Feldman J, 2002, IEEE VTS VEH TECHNOL, P371, DOI 10.1109/VETECF.2002.1040367; Felzenszwalb P.F., 2012, THEORY COMPUT, V8, P415, DOI DOI 10.4086/TOC.2012.V008A019; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906; Forsyth D. A., 2007, P IEEE C COMP VIS PA, P1; Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710; Ikizler N, 2008, INT J COMPUT VISION, V80, P337, DOI 10.1007/s11263-008-0142-8; Karpathy A., 2014, ARXIV14122306; Kiros R, 2014, PR MACH LEARN RES, V32, P595; Kong C, 2014, PROC CVPR IEEE, P3558, DOI 10.1109/CVPR.2014.455; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25; Lin DH, 2014, PROC CVPR IEEE, P2657, DOI 10.1109/CVPR.2014.340; Mitchell Margaret, 2012, EACL; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Sadeghi M. A., 2013, P ADV NEUR INF PROC, P2949; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; Siddharth N, 2014, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2014.99; Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014; Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P280, DOI 10.1109/TMM.2006.886275; Song Y, 2013, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2013.457; Tapaswi Makarand, 2014, P ACM INT C MULT RET, P137; Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341; Vaquero D. A., 2009, PROC WORKSHOP APPL C, P1; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; VITERBI AJ, 1971, IEEE T COMMUN TECHN, VCO19, P751, DOI 10.1109/TCOM.1971.1090700; Worring M, 2007, INT CONF ACOUST SPEE, P1213; Yu H., 2013, 51 ANN M ASS COMP LI, P53; Yu Xinguo, 2003, P 11 ACM INT C MULT, P11	47	6	7	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2016	38	10					2069	2081		10.1109/TPAMI.2015.2505297	http://dx.doi.org/10.1109/TPAMI.2015.2505297			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DX2YV	26660701	Green Submitted			2022-12-18	WOS:000384240600011
J	Jiang, Y; Koppula, HS; Saxena, A				Jiang, Yun; Koppula, Hema S.; Saxena, Ashutosh			Modeling 3D Environments through Hidden Human Context	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D scene understanding; human context; machine learning; robotics perception		The idea of modeling object-object relations has been widely leveraged in many scene understanding applications. However, as the objects are designed by humans and for human usage, when we reason about a human environment, we reason about it through an interplay between the environment, objects and humans. In this paper, we model environments not only through objects, but also through latent human poses and human-object interactions. In order to handle the large number of latent human poses and a large variety of their interactions with objects, we present Infinite Latent Conditional Random Field (ILCRF) that models a scene as a mixture of CRFs generated from Dirichlet processes. In each CRF, we model objects and object-object relations as existing nodes and edges, and hidden human poses and human-object relations as latent nodes and edges. ILCRF generatively models the distribution of different CRF structures over these latent nodes and edges. We apply the model to the challenging applications of 3D scene labeling and robotic scene arrangement. In extensive experiments, we show that our model significantly outperforms the state-of-the-art results in both applications. We further use our algorithm on a robot for arranging objects in a new scene using the two applications aforementioned.	[Jiang, Yun; Koppula, Hema S.; Saxena, Ashutosh] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Cornell University	Jiang, Y (corresponding author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.	yunjiang@cs.cornell.edu; hema@cs.cornell.edu; asaxena@cs.cornell.edu			ARO award [W911NF-12-1-0267]; US National Science Foundation (NSF); Microsoft Faculty Fellowship	ARO award; US National Science Foundation (NSF)(National Science Foundation (NSF)); Microsoft Faculty Fellowship(Microsoft)	The authors thank Marcus Lim for useful discussions and help in the experiments. This work was supported by ARO award W911NF-12-1-0267, the US National Science Foundation (NSF) Career Award, and Microsoft Faculty Fellowship to Saxena. Parts of this work have been published as [1], [2], [3], [4] as conference papers.	Anand A, 2013, INT J ROBOT RES, V32, P19, DOI 10.1177/0278364912461538; Anandkumar Anima, 2012, ADV NEURAL INFORM PR, P1052; Beal M., 2002, P ADV NEUR INF PROC, P1088; Bousmalis K., 2011, P NIPS WORKSH BAYES; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Delaitre V, 2012, LECT NOTES COMPUT SC, V7577, P284, DOI 10.1007/978-3-642-33783-3_21; Edsinger A, 2006, IEEE-RAS INT C HUMAN, P102, DOI 10.1109/ICHR.2006.321370; Fisher M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964929; Gael J.V., 2008, P 22 ANN C NEUR INF, P1697; Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327; Griffiths TL, 2011, J MACH LEARN RES, V12, P1185; Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448; Hedau V, 2010, LECT NOTES COMPUT SC, V6316, P224, DOI 10.1007/978-3-642-15567-3_17; Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4; Ickstadt K., 2010, BAYESIAN STAT, V9, P283; Jain D., 2009, ICRA, P3626; Jancsary J., 2012, P NIPS WORKSH MOD NO; Jiang Y., 2012, P 13 INT S EXP ROB, P921; Jiang Y., 2012, P INT C MACH LEARN, P1543; Jiang Y., 2013, P RSS; Jiang Y, 2013, PROC CVPR IEEE, P2993, DOI 10.1109/CVPR.2013.385; Jiang Y, 2012, INT J ROBOT RES, V31, P1021, DOI 10.1177/0278364912438781; Kjellstrom H, 2011, COMPUT VIS IMAGE UND, V115, P81, DOI 10.1016/j.cviu.2010.08.002; Koppula H., 2011, P ADV NEUR INF PROC, P242; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Kumar S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1150, DOI 10.1109/ICCV.2003.1238478; Lee D., 2010, P ADV NEUR INF PROC, P1288; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Pandey A. K., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P791, DOI 10.1109/ROMAN.2012.6343848; Quattoni A., 2004, PROC ADV NEURAL INF, V17, P1097; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; Rodriguez A, 2011, ELECTRON J STAT, V5, P981, DOI 10.1214/11-EJS634; Saxena A., 2014, ROBOBRAIN LARGE SCAL; Saxena Ashutosh, 2005, ADV NEURAL INFORM PR; Schnitzspan P, 2010, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2010.5540220; Schuster M. J., 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P152, DOI 10.1109/ICHR.2010.5686328; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; SUDDERTH EB, 2006, P IEEE C COMP VIS PA; Sung J., 2012, P IN C ROB AUT; SUTTON C, 2004, P 21 INT C MACH LEAR, P783; Teh Y.W., 2010, ENCY MACHINE LEARNIN; Wang S. B., 2006, PROC IEEE COMPUT SOC, P1521, DOI DOI 10.1109/CVPR.2006.132; Wang Y, 2009, PROC CVPR IEEE, P872, DOI 10.1109/CVPRW.2009.5206709; Xiong X., 2010, P BRIT MACH VIS C; Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235; Yeh YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185552	47	6	6	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2016	38	10					2040	2053		10.1109/TPAMI.2015.2501811	http://dx.doi.org/10.1109/TPAMI.2015.2501811			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DX2YV	26660695	Green Submitted			2022-12-18	WOS:000384240600009
J	Escalera, S; Gonzalez, J; Baro, X; Shotton, J				Escalera, Sergio; Gonzalez, Jordi; Baro, Xavier; Shotton, Jamie			Guest Editors' Introduction to the Special Issue on Multimodal Human Pose Recovery and Behavior Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Escalera, Sergio] Univ Barcelona, Dept Math & Informat, E-08007 Barcelona, Spain; [Escalera, Sergio; Gonzalez, Jordi; Baro, Xavier] Comp Vis Ctr, Catalonia, Spain; [Gonzalez, Jordi] Univ Autonoma Barcelona, E-08193 Barcelona, Spain; [Baro, Xavier] Univ Oberta Catalunya, Barcelona, Spain; [Shotton, Jamie] Microsoft Res, Cambridge, England	University of Barcelona; Centre de Visio per Computador (CVC); Autonomous University of Barcelona; UOC Universitat Oberta de Catalunya; Microsoft	Escalera, S (corresponding author), Univ Barcelona, Dept Math & Informat, E-08007 Barcelona, Spain.; Escalera, S (corresponding author), Comp Vis Ctr, Catalonia, Spain.	sergio@maia.ub.es; jordi.gonzalez@cvc.uab.es; xbaro@uoc.edu; Jamie.Shotton@microsoft.com	Gonzàlez, Jordi/I-1812-2015; Escalera, Sergio/L-2998-2015; Baró, Xavier/A-4064-2011	Gonzàlez, Jordi/0000-0001-8033-0306; Escalera, Sergio/0000-0003-0617-8873; Baró, Xavier/0000-0001-5338-3007					0	6	6	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1489	1491		10.1109/TPAMI.2016.2557878	http://dx.doi.org/10.1109/TPAMI.2016.2557878			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO					2022-12-18	WOS:000379926200001
J	Lin, ZC; Huang, YM				Lin, Zhouchen; Huang, Yameng			Fast Multidimensional Ellipsoid-Specific Fitting by Alternating Direction Method of Multipliers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multidimensional ellipsoid; ellipsoid-specific fitting; alternating direction method of multipliers	CURVES	Many problems in computer vision can be formulated as multidimensional ellipsoid-specific fitting, which is to minimize the residual error such that the underlying quadratic surface is a multidimensional ellipsoid. In this paper, we present a fast and robust algorithm for solving ellipsoid-specific fitting directly. Our method is based on the alternating direction method of multipliers, which does not introduce extra positive semi-definiteness constraints. The computation complexity is thus significantly lower than those of semi-definite programming (SDP) based methods. More specifically, to fit n data points into a p dimensional ellipsoid, our complexity is O(p(6) + np(4)) + O(p(3)), where the former O results from preprocessing data once, while that of the state-of-the-art SDP method is O(p(6) + np(4) + n(3/2)p(2)) for each iteration. The storage complexity of our algorithm is about 1/2np(2), which is at most 1/4 of those of SDP methods. Extensive experiments testify to the great speed and accuracy advantages of our method over the state-of-the-art approaches. The implementation of our method is also much simpler than SDP based methods.	[Lin, Zhouchen; Huang, Yameng] Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept, Minist Educ, Beijing 100871, Peoples R China; Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China	Peking University; Shanghai Jiao Tong University	Lin, ZC; Huang, YM (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept, Minist Educ, Beijing 100871, Peoples R China.	zlin@pku.edu.cn; huangyameng@pku.edu.cn			973 Program of China [2015CB352502]; National Natural Science Foundation of China [61272341, 61231002]; Microsoft	973 Program of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Microsoft(Microsoft)	Zhouchen Lin is supported by 973 Program of China (grant no. 2015CB352502), National Natural Science Foundation of China (grant nos. 61272341 and 61231002), and Microsoft Research Asia Collaborative Research Program.	Ahn SJ, 2002, IEEE T PATTERN ANAL, V24, P620, DOI 10.1109/34.1000237; Ahn SJ, 2001, PATTERN RECOGN, V34, P2283, DOI 10.1016/S0031-3203(00)00152-7; Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Calafiore G, 2002, IEEE T SYST MAN CY A, V32, P269, DOI 10.1109/TSMCA.2002.1021114; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Forbes A B, 1993, ALGORITHMS, V5, P523; GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268; Ge ZY, 2005, MED PHYS, V32, P2443, DOI 10.1118/1.1944667; Grammalidis N, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P221, DOI 10.1109/CGI.2000.852337; Ju MY, 2001, IEEE INT CONF ROBOT, P2897, DOI 10.1109/ROBOT.2001.933061; Kleinsteuber M., 2010, RECENT ADV OPTIMIZAT, P73; Lee KK, 2005, PATTERN RECOGN LETT, V26, P1232, DOI 10.1016/j.patrec.2004.11.004; Li QD, 2004, GEOMETRIC MODELING AND PROCESSING 2004, PROCEEDINGS, P335; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Mahdavi S, 2008, IEEE ENG MED BIO, P2988, DOI 10.1109/IEMBS.2008.4649831; Markovsky I, 2004, NUMER MATH, V98, P177, DOI 10.1007/s00211-004-0526-9; Post FH, 2003, COMPUT GRAPH FORUM, V22, P775, DOI 10.1111/j.1467-8659.2003.00723.x; Rimon E, 1997, J INTELL ROBOT SYST, V18, P105, DOI 10.1023/A:1007960531949; ROSIN PL, 1993, PATTERN RECOGN LETT, V14, P799, DOI 10.1016/0167-8655(93)90062-I; Sivapalan S., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P355, DOI 10.1109/AVSS.2011.6027350; Toh KC, 1999, OPTIM METHOD SOFTW, V11-2, P545, DOI 10.1080/10556789908805762; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; Ying XH, 2012, IEEE T PATTERN ANAL, V34, P1856, DOI 10.1109/TPAMI.2012.109; YU JQ, 2009, 2009 3 IEEE INT, P33; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	26	6	7	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					1021	1026		10.1109/TPAMI.2015.2469283	http://dx.doi.org/10.1109/TPAMI.2015.2469283			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	27046842				2022-12-18	WOS:000374164700015
J	Painsky, A; Rosset, S				Painsky, Amichai; Rosset, Saharon			Isotonic Modeling with Non-Differentiable Loss Functions with Application to Lasso Regularization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Isotonic regression; nonparametric regression; regularization path; GIRP; convex optimization	REGRESSION; FREEDOM	In this paper we present an algorithmic approach for fitting isotonic models under convex, yet non-differentiable, loss functions. It is a generalization of the greedy non-regret approach proposed by Luss and Rosset (2014) for differentiable loss functions, taking into account the sub-gradiental extensions required. We prove that our suggested algorithm solves the isotonic modeling problem while maintaining favorable computational and statistical properties. As our suggested algorithm may be used for any non-differentiable loss function, we focus our interest on isotonic modeling for either regression or two-class classification with appropriate log-likelihood loss and lasso penalty on the fitted values. This combination allows us to maintain the non-parametric nature of isotonic modeling, while controlling model complexity through regularization. We demonstrate the efficiency and usefulness of this approach on both synthetic and real world data. An implementation of our suggested solution is publicly available from the first author's website (https://sites.google.com/site/amichaipainsky/software).	[Painsky, Amichai; Rosset, Saharon] Tel Aviv Univ, Sch Math Sci, IL-6997801 Ramat Aviv, Israel	Tel Aviv University	Painsky, A; Rosset, S (corresponding author), Tel Aviv Univ, Sch Math Sci, IL-6997801 Ramat Aviv, Israel.	amichaip@eng.tau.ac.il; saharon@post.tau.ac.il			Israeli Ministry of Science; Israeli Science Foundation [1487/12]	Israeli Ministry of Science(Ministry of Science, Technology and Space (MOST), Israel); Israeli Science Foundation(Israel Science Foundation)	This research was supported in part by a returning scientists grant to Amichai Painsky from the Israeli Ministry of Science, and by Israeli Science Foundation grant 1487/12.	Ahuja R. K., 1993, NETWORK FLOWS THEORY; [Anonymous], 1997, LINEAR COMPLEMENTARI; BARLOW RE, 1972, J AM STAT ASSOC, V67, P140, DOI 10.2307/2284712; Boyd S, 2003, STANFORD U LECT NOTE; Caruana R, 2001, ADV NEUR IN, V13, P402; Chandrasekaran R, 2005, INFORMS J COMPUT, V17, P462, DOI 10.1287/ijoc.1030.0061; EFRON B, 1986, J AM STAT ASSOC, V81, P461, DOI 10.2307/2289236; GALIL Z, 1980, J COMPUT SYST SCI, V21, P203, DOI 10.1016/0022-0000(80)90035-5; Hochbaum DS, 2003, SIAM J DISCRETE MATH, V16, P192, DOI 10.1137/S0895480100369584; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Lichman M, 2013, UCI MACHINE LEARNING; Luss R, 2014, J COMPUT GRAPH STAT, V23, P192, DOI 10.1080/10618600.2012.741550; Luss R, 2012, ANN APPL STAT, V6, P253, DOI 10.1214/11-AOAS504; MAXWELL WL, 1985, OPER RES, V33, P1316, DOI 10.1287/opre.33.6.1316; Meyer M, 2000, ANN STAT, V28, P1083; Obozinski G, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-s1-s6; Rosset S, 2004, J MACH LEARN RES, V5, P941; Ruppert David., 2010, ELEMENTS STAT LEARNI, V99, P567, DOI 10.1007/978-0-387-84858-7; Schell MJ, 1997, J AM STAT ASSOC, V92, P128, DOI 10.2307/2291456; SLEATOR DD, 1983, J COMPUT SYST SCI, V26, P362, DOI 10.1016/0022-0000(83)90006-5; Spouge J, 2003, J OPTIMIZ THEORY APP, V117, P585, DOI 10.1023/A:1023901806339; STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632; Stout QF, 2015, ALGORITHMICA, V71, P450, DOI 10.1007/s00453-013-9814-z; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Wahba G., 1990, CBMS NSF REGIONAL C; Zheng ZH, 2008, ANN ALLERTON CONF, P1108, DOI 10.1109/ALLERTON.2008.4797684; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	27	6	6	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					308	321		10.1109/TPAMI.2015.2441063	http://dx.doi.org/10.1109/TPAMI.2015.2441063			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761736				2022-12-18	WOS:000369989600009
J	Bratieres, S; Quadrianto, N; Ghahramani, Z				Bratieres, Sebastien; Quadrianto, Novi; Ghahramani, Zoubin			GPstruct: Bayesian Structured Prediction Using Gaussian Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Statistical learning; Markov random fields; Gaussion processes; natural language processing; structured prediction		We introduce a conceptually novel structured prediction model, GPstruct, which is kernelized, non-parametric and Bayesian, by design. We motivate the model with respect to existing approaches, among others, conditional random fields (CRFs), maximum margin Markov networks ((MN)-N-3), and structured support vector machines (SVMstruct), which embody only a subset of its properties. We present an inference procedure based on Markov Chain Monte Carlo. The framework can be instantiated for a wide range of structured objects such as linear chains, trees, grids, and other general graphs. As a proof of concept, the model is benchmarked on several natural language processing tasks and a video gesture segmentation task involving a linear chain structure. We show prediction accuracies for GPstruct which are comparable to or exceeding those of CRFs and SVMstruct.	[Bratieres, Sebastien; Ghahramani, Zoubin] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England; [Quadrianto, Novi] Univ Sussex, Dept Informat, SMiLe CLiN, Brighton BN1 9RH, E Sussex, England	University of Cambridge; University of Sussex	Bratieres, S (corresponding author), Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.	sebastien@cantab.net; n.quadrianto@sussex.ac.uk; zoubin@eng.cam.ac.uk		Bratieres, Sebastien/0000-0002-8117-0153; Quadrianto, Novi/0000-0001-8819-306X	EPSRC [EP/I036575/1]; Engineering and Physical Sciences Research Council [EP/I036575/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors would like to thank Simon Lacoste-Julien, Viktoriia Sharmanska, and Chao Chen for discussions, and the anonymous reviewers for their valuable comments and suggestions. Zoubin Ghahramani acknowledges support from EPSRC grant EP/I036575/1.	Altun Y., 2004, UNCERTAINTY ARTIFICI, P2; Altun Y., 2004, P 21 INT C MACH LEAR, p[4, 2], DOI DOI 10.1145/1015330.1015433; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Botha JA, 2014, PR MACH LEARN RES, V32, P1899; Bratieres S, 2014, PR MACH LEARN RES, V32, P334; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Jancsary J, 2012, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2012.6247950; Lafferty J., 2004, P 21 INT C MACH LEAR, P64; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Minka TP., 2001, THESIS MIT CAMBRIDGE; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; Murray I., 2010, JMLR W CP, V9, P541; Nickisch H, 2008, J MACH LEARN RES, V9, P2035; Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033; Perez-Cruz F., 2007, PREDICTING STRUCTURE, P265; Qi Y., 2005, P 10 INT WORKSH ART, P269; Scholkopf B., 2001, LEARNING KERNELS SUP; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013; Taskar B, 2004, ADV NEUR IN, V16, P25; Taskar Ben, 2004, P C EMP METH NAT LAN, P1; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Weston J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P219; Weston J., 2002, NIPS, P873; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807	27	6	8	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2015	37	7					1514	1520		10.1109/TPAMI.2014.2366151	http://dx.doi.org/10.1109/TPAMI.2014.2366151			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CK0YG	26352456	Green Published, Green Accepted			2022-12-18	WOS:000355931100016
J	Takahashi, T; Kurita, T				Takahashi, Takashi; Kurita, Takio			Mixture of Subspaces Image Representation and Compact Coding for Large-Scale Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image retrieval; image search; likelihood function; principal component analysis	NEAREST-NEIGHBOR	There are two major approaches to content-based image retrieval using local image descriptors. One is descriptor-by-descriptor matching and the other is based on comparison of global image representation that describes the set of local descriptors of each image. In large-scale problems, the latter is preferred due to its smaller memory requirements; however, it tends to be inferior to the former in terms of retrieval accuracy. To achieve both low memory cost and high accuracy, we investigate an asymmetric approach in which the probability distribution of local descriptors is modeled for each individual database image while the local descriptors of a query are used as is. We adopt a mixture model of probabilistic principal component analysis. The model parameters constitute a global image representation to be stored in database. Then the likelihood function is employed to compute a matching score between each database image and a query. We also propose an algorithm to encode our image representation into more compact codes. Experimental results demonstrate that our method can represent each database image in less than several hundred bytes achieving higher retrieval accuracy than the state-of-the-art method using Fisher vectors.	[Takahashi, Takashi] Ryukoku Univ, Dept Appl Math & Informat, Otsu, Shiga 5202194, Japan; [Kurita, Takio] Hiroshima Univ, Dept Informat Engn, Higashihiroshima 7398527, Japan	Ryukoku University; Hiroshima University	Takahashi, T (corresponding author), Ryukoku Univ, Dept Appl Math & Informat, Otsu, Shiga 5202194, Japan.	takataka@math.ryukoku.ac.jp; tkurita@hiroshima-u.ac.jp	Kurita, Takio/D-8674-2012	Kurita, Takio/0000-0003-3982-6750; Takahashi, Takashi/0000-0003-2055-7415				Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494; Bishop CM, 2006, PATTERN RECOGNITION; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Ho J., 2008, P IEEE C COMP VIS PA, P11; Jain M., 2012, P 2 ACM INT C MULT R, DOI 10.1145/2324796.2324820; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Negrel R, 2012, IEEE IMAGE PROC, P2425, DOI 10.1109/ICIP.2012.6467387; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Perronnin F, 2007, PROC CVPR IEEE, P2272; Picard D, 2011, IEEE IMAGE PROC, P669, DOI 10.1109/ICIP.2011.6116641; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Tuytelaars T, 2011, IEEE I CONF COMP VIS, P1824, DOI 10.1109/ICCV.2011.6126449; Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739; Weiss Yair, 2008, ADV NEURAL INFORM PR, P1753	24	6	6	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2015	37	7					1469	1479		10.1109/TPAMI.2014.2382092	http://dx.doi.org/10.1109/TPAMI.2014.2382092			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CK0YG	26352453				2022-12-18	WOS:000355931100013
J	Maggiori, E; Lotito, P; Manterola, HL; del Fresno, M				Maggiori, Emmanuel; Lotito, Pablo; Luis Manterola, Hugo; del Fresno, Mariana			Comments on "A Closed-Form Solution to Tensor Voting: Theory and Applications"	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material						Tensor Voting; perceptual grouping; feature inference		We comment on a paper that describes a closed-form formulation to Tensor Voting, a technique to perceptually group clouds of points, usually applied to infer features in images. The authors proved an analytic solution to the technique, a highly relevant contribution considering that the original formulation required numerical integration, a time-consuming task. Their work constitutes the first closed-form expression for the Tensor Voting framework. In this work we first observe that the proposed formulation leads to unexpected results which do not satisfy the constraints for a Tensor Voting output, hence they cannot be interpreted. Given that the closed-form expression is said to be an analytic equivalent solution, unexpected outputs should not be encountered unless there are flaws in the proof. We analyzed the underlying math to find which were the causes of these unexpected results. In this commentary we show that their proposal does not in fact provide a proper analytic solution to Tensor Voting and we indicate the flaws in the proof.	[Maggiori, Emmanuel] Inria Sophia Antipolis, AYIN, F-06902 Valbonne, France; [Maggiori, Emmanuel] Inria Sophia Antipolis, STARS, F-06902 Valbonne, France; [Maggiori, Emmanuel; Lotito, Pablo; Luis Manterola, Hugo; del Fresno, Mariana] Univ Nacl Ctr Prov Buenos Aires, Pladema, Fac Ciencias Exactas, Tandil, Argentina; [Lotito, Pablo; Luis Manterola, Hugo] Consejo Nacl Invest Cient & Tecn, RA-1033 Buenos Aires, DF, Argentina; [del Fresno, Mariana] CIC PBA, La Plata, Buenos Aires, Argentina	Comision Nacional de Energia Atomica (CNEA); Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET)	Maggiori, E (corresponding author), Inria Sophia Antipolis, AYIN, F-06902 Valbonne, France.	emmanuel.maggiori@inria.fr; plotito@exa.unicen.edu.ar; manterolaluis@gmail.com; mdelfres@gmail.com	Maggiori, Emmanuel/Q-3788-2017	Maggiori, Emmanuel/0000-0002-5765-9629				Franken E, 2006, LECT NOTES COMPUT SC, V3954, P228; Medioni G., 2000, COMPUTATIONAL FRAMEW; Mordohai P, 2010, J MACH LEARN RES, V11, P411; Moreno R, 2011, IEEE T PATTERN ANAL, V33, P2215, DOI 10.1109/TPAMI.2011.23; Wu TP, 2012, IEEE T PATTERN ANAL, V34, P1482, DOI 10.1109/TPAMI.2011.250	5	6	7	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2567	2568		10.1109/TPAMI.2014.2342233	http://dx.doi.org/10.1109/TPAMI.2014.2342233			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353158	Green Published			2022-12-18	WOS:000344988000017
J	Boudaren, ME; Monfrini, E; Pieczynski, W; Aissani, A				Boudaren, Mohamed El Yazid; Monfrini, Emmanuel; Pieczynski, Wojciech; Aissani, Amar			Phasic Triplet Markov Chains	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian restoration; biology and genetics; hidden Markov chains; Markov processes; maximal posterior mode; maximum a posteriori; triplet Markov chains; Viterbi algorithm	UNSUPERVISED SEGMENTATION; MULTICLASS SEGMENTATION; HIDDEN; MODEL; ALGORITHM; SIGNALS; FIELDS; GENES; DNA; EM	Hidden Markov chains have been shown to be inadequate for data modeling under some complex conditions. In this work, we address the problem of statistical modeling of phenomena involving two heterogeneous system states. Such phenomena may arise in biology or communications, among other fields. Namely, we consider that a sequence of meaningful words is to be searched within a whole observation that also contains arbitrary one-by-one symbols. Moreover, a word may be interrupted at some site to be carried on later. Applying plain hidden Markov chains to such data, while ignoring their specificity, yields unsatisfactory results. The Phasic triplet Markov chain, proposed in this paper, overcomes this difficulty by means of an auxiliary underlying process in accordance with the triplet Markov chains theory. Related Bayesian restoration techniques and parameters estimation procedures according to the new model are then described. Finally, to assess the performance of the proposed model against the conventional hidden Markov chain model, experiments are conducted on synthetic and real data.	[Boudaren, Mohamed El Yazid] Ecole Mil Polytech, Algiers 16111, Algeria; [Monfrini, Emmanuel; Pieczynski, Wojciech] Telecom SudParis, Inst Mines Telecom, Dept CITI, F-91011 Evry, France; [Aissani, Amar] USTHB, Algiers 16111, Algeria	Ecole Military Polytechnic; IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; University Science & Technology Houari Boumediene	Boudaren, ME (corresponding author), Ecole Mil Polytech, BP 17, Algiers 16111, Algeria.	boudaren@gmail.com; emmanuel.monfrini@it-sudparis.eu; wojciech.pieczynski@it-sudparis.eu; amraissani@yahoo.fr	Pieczynski, Wojciech/AAW-4428-2020; Boudaren, Mohamed El Yazid/H-5348-2019; Aissani, Amar/AAI-6874-2020	Boudaren, Mohamed El Yazid/0000-0002-6149-6383; Aissani, Amar/0000-0003-0567-6942	Ecole Militaire Polytechnique, Algeria	Ecole Militaire Polytechnique, Algeria	Funding for this research was provided in part by Ecole Militaire Polytechnique, Algeria. Authors would like to thank Marc Uro who helped to use EID database, and Frdric Lehmann for the fructuous discussions about PTMC applicability in communications. Authors would also like to thank reviewers for their constructive comments.	Ait-El-Fquih B, 2006, IEEE T SIGNAL PROCES, V54, P2957, DOI 10.1109/TSP.2006.877651; Bardel N, 2012, METHODOL COMPUT APPL, V14, P125, DOI 10.1007/s11009-010-9189-4; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Benboudjema D, 2007, IEEE T PATTERN ANAL, V29, P1367, DOI 10.1109/TPAMI.2007.1059; Benboudjema D, 2013, INT CONF ACOUST SPEE, P1927, DOI 10.1109/ICASSP.2013.6637989; Blanchet J, 2008, IEEE T PATTERN ANAL, V30, P1055, DOI 10.1109/TPAMI.2008.27; Boudaren ME, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-134; Boudaren ME, 2012, EUR SIGNAL PR CONF, P2243; Boudaren ME, 2012, IEEE SIGNAL PROC LET, V19, P619, DOI 10.1109/LSP.2012.2209639; Bricq S, 2006, I S BIOMED IMAGING, P386; Cappe O., 2005, INFERENCE HIDDEN MAR, V6; Carincotte C, 2006, IEEE T GEOSCI REMOTE, V44, P432, DOI 10.1109/TGRS.2005.861007; Celeux G, 1996, J STAT COMPUT SIM, V55, P287, DOI 10.1080/00949659608811772; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; CHURCHILL GA, 1992, COMPUT CHEM, V16, P107, DOI 10.1016/0097-8485(92)80037-Z; Delmas JP, 1997, IEEE T SIGNAL PROCES, V45, P2613, DOI 10.1109/78.640732; Derrode S, 2004, IEEE T SIGNAL PROCES, V52, P2477, DOI 10.1109/TSP.2004.832015; Derrode S., 2011, ON LINE DEMOS RECENT; Ephraim Y, 2002, IEEE T INFORM THEORY, V48, P1518, DOI 10.1109/TIT.2002.1003838; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Gan L, 2012, IET IMAGE PROCESS, V6, P831, DOI 10.1049/iet-ipr.2011.0198; Hatt M, 2007, PHYS MED BIOL, V52, P3467, DOI 10.1088/0031-9155/52/12/010; Henderson J, 1997, J COMPUT BIOL, V4, P127, DOI 10.1089/cmb.1997.4.127; Jelinek Frederick, 1997, STAT METHODS SPEECH; KALEH GK, 1994, IEEE T COMMUN, V42, P2406, DOI 10.1109/26.297849; Koski T., 2001, COMPU BIOL, V2; KROGH A, 1994, NUCLEIC ACIDS RES, V22, P4768, DOI 10.1093/nar/22.22.4768; Kulp D, 1996, Proc Int Conf Intell Syst Mol Biol, V4, P134; Lanchantin P, 2005, IEEE T SIGNAL PROCES, V53, P3091, DOI 10.1109/TSP.2005.851131; Lanchantin P, 2011, SIGNAL PROCESS, V91, P163, DOI 10.1016/j.sigpro.2010.05.033; Lapuyade-Lahorgue J, 2006, AIP CONF PROC, V872, P347; Liang KC, 2007, IEEE ACM T COMPUT BI, V4, P430, DOI 10.1109/TCBB.2007.1027; McLachlan G., 2007, EM ALGORITHM EXTENSI, V382; Nelson R, 2008, PROCEEDINGS OF THE 40TH SOUTHEASTERN SYMPOSIUM ON SYSTEM THEORY, P215; Pieczynski W, 2003, PROC SPIE, V4885, P58, DOI 10.1117/12.463183; Pieczynski W, 2003, IEEE T PATTERN ANAL, V25, P634, DOI 10.1109/TPAMI.2003.1195998; Pieczynski W, 2007, INT J APPROX REASON, V45, P1, DOI 10.1016/j.ijar.2006.05.001; Pieczynski W, 2011, CR MATH, V349, P587, DOI 10.1016/j.crma.2011.02.007; QIAN W, 1989, J APPL STAT, V16, P267; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAFTERY AE, 1985, J R STAT SOC B, V47, P528, DOI 10.1111/j.2517-6161.1985.tb01383.x; Ramasso E, 2009, IEEE INT WORKS MACH, P97; Raphael C, 1999, IEEE T PATTERN ANAL, V21, P360, DOI 10.1109/34.761266; Sakakibara Y, 2005, IEEE T PATTERN ANAL, V27, P1051, DOI 10.1109/TPAMI.2005.140; Sarawagi Sunita, 2004, ADV NEURAL INF PROCE, P1185; Saxonov S, 2000, NUCLEIC ACIDS RES, V28, P185, DOI 10.1093/nar/28.1.185; Searls DB, 2002, NATURE, V420, P211, DOI 10.1038/nature01255; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; Soubaras H, 2010, STUD FUZZ SOFT COMP, V249, P247; Stormo G D, 1994, Proc Int Conf Intell Syst Mol Biol, V2, P369; Nguyen TM, 2012, IEEE T SYST MAN CY B, V42, P193, DOI 10.1109/TSMCB.2011.2161284; Van Rijsbergen CJ, 1979, INFORM RETRIEVAL; Wang F, 2013, IEEE GEOSCI REMOTE S, V10, P697, DOI 10.1109/LGRS.2012.2219494; Wang S, 2013, IEEE T KNOWL DATA EN, V25, P206, DOI 10.1109/TKDE.2011.207; Zhang P, 2012, IEEE GEOSCI REMOTE S, V9, P1099, DOI 10.1109/LGRS.2012.2189094; Zhang P, 2012, PATTERN RECOGN, V45, P4018, DOI 10.1016/j.patcog.2012.04.019	56	6	6	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2310	2316		10.1109/TPAMI.2014.2327974	http://dx.doi.org/10.1109/TPAMI.2014.2327974			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353069	Green Published			2022-12-18	WOS:000343702400015
J	Shen, CH; Lin, GS; van den Hengel, A				Shen, Chunhua; Lin, Guosheng; van den Hengel, Anton			StructBoost: Boosting Methods for Predicting Structured Output Variables	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Boosting; ensemble learning; AdaBoost; structured learning; conditional random field	TRACKING	Boosting is a method for learning a single accurate predictor by linearly combining a set of less accurate weak learners. Recently, structured learning has found many applications in computer vision. Inspired by structured support vector machines (SSVM), here we propose a new boosting algorithm for structured output prediction, which we refer to as StructBoost. StructBoost supports nonlinear structured learning by combining a set of weak structured learners. As SSVM generalizes SVM, our StructBoost generalizes standard boosting approaches such as AdaBoost, or LPBoost to structured learning. The resulting optimization problem of StructBoost is more challenging than SSVM in the sense that it may involve exponentially many variables and constraints. In contrast, for SSVM one usually has an exponential number of constraints and a cutting-plane method is used. In order to efficiently solve StructBoost, we formulate an equivalent 1-slack formulation and solve it using a combination of cutting planes and column generation. We show the versatility and usefulness of StructBoost on a range of problems such as optimizing the tree loss for hierarchical multi-class classification, optimizing the Pascal overlap criterion for robust visual tracking and learning conditional random field parameters for image segmentation.	[Shen, Chunhua; Lin, Guosheng; van den Hengel, Anton] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	University of Adelaide	Shen, CH (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	chunhua.shen@adelaie.edu.au; guosheng.lin@adelaie.edu.au; Anton.vandenHengel@adelaie.edu.au	Lin, Guosheng/Q-4024-2017; Lin, Guosheng/N-9110-2019	Lin, Guosheng/0000-0002-0329-7458; Lin, Guosheng/0000-0002-0329-7458; van den Hengel, Anton/0000-0003-3027-8364	Australian Research Council [FT120100969]	Australian Research Council(Australian Research Council)	This work was supported in part by Australian Research Council Grant FT120100969.	Adam A., 2006, IEEE C COMP VIS PATT; [Anonymous], [No title captured]; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Bertelli L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2153, DOI 10.1109/CVPR.2011.5995597; Bischof H., 2006, BMVC, P47; Blaschko MB, 2008, LECT NOTES COMPUT SC, V5302, P2, DOI 10.1007/978-3-540-88682-2_2; Cai Lijuan, 2004, P 13 ACM INT C INFOR, P78, DOI DOI 10.1145/1031171.1031186; Chunhua Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2585, DOI 10.1109/CVPR.2011.5995554; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x; Dietterich T.G., 2004, P 21 INT C MACH LEAR, P217; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Franc V., 2008, P 25 INT C MACH LEAR, P320, DOI DOI 10.1145/1390156.1390197; Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916; Fulkerson B., 2009, IEEE I CONF COMP VIS, P670, DOI [10.1109/ICCV.2009.5459175, DOI 10.1109/ICCV.2009.5459175]; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Joachims T, 2006, PROC 22 ACM SIGKDD I, P217, DOI DOI 10.1145/1150402.1150429; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Joachims Thorsten, 2005, ICML, DOI DOI 10.1145/1102351.1102399; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Lafferty J, 2001, P 18 INT C MACH LEAR, P282, DOI DOI 10.1038/NPROT.2006.61; Marszatek M., 2007, P IEEE C COMP VIS PA, P1063; Mason L, 2000, ADV NEUR IN, V12, P512; Munoz D, 2009, PROC CVPR IEEE, P975, DOI 10.1109/CVPRW.2009.5206590; Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033; Nowozin S, 2011, IEEE I CONF COMP VIS, P1668, DOI 10.1109/ICCV.2011.6126429; Nowozin S, 2010, LECT NOTES COMPUT SC, V6316, P98, DOI 10.1007/978-3-642-15567-3_8; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Paisitkriangkrai S, 2014, IEEE T NEUR NET LEAR, V25, P764, DOI 10.1109/TNNLS.2013.2281214; Parker C., 2006, P 21 NAT C ART INT, P452; Parker C., 2007, THESIS OREGON STATE; Plath N., 2009, P 26 ANN INT C MACHI, P817, DOI [10.1145/1553374.1553479, DOI 10.1145/1553374.1553479]; Ratliff N, 2007, P ADV NEUR INF PROC; Ratliff ND, 2009, AUTON ROBOT, V27, P25, DOI 10.1007/s10514-009-9121-3; Shen CH, 2013, NEURAL NETWORKS, V48, P44, DOI 10.1016/j.neunet.2013.07.006; Shen CH, 2010, IEEE T PATTERN ANAL, V32, P2216, DOI 10.1109/TPAMI.2010.47; Steinwart I, 2004, J MACH LEARN RES, V4, P1071, DOI 10.1162/1532443041827925; Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013; Szummer M, 2008, LECT NOTES COMPUT SC, V5303, P582, DOI 10.1007/978-3-540-88688-4_43; Teo CH, 2010, J MACH LEARN RES, V11, P311; Tsochantaridis Ioannis, 2004, P 21 INT C MACH LEAR; Wang QI, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1756; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Weston J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P219; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236	48	6	7	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					2089	2103		10.1109/TPAMI.2014.2315792	http://dx.doi.org/10.1109/TPAMI.2014.2315792			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352637	Green Published, Green Submitted			2022-12-18	WOS:000341981300014
J	Cuzzolin, F; Sapienza, M				Cuzzolin, Fabio; Sapienza, Michael			Learning Pullback HMM Distances	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Distance learning; pullback metrics; hidden Markov models; action recognition	KERNELS; MODELS	Recent work in action recognition has exposed the limitations of methods which directly classify local features extracted from spatio-temporal video volumes. In opposition, encoding the actions' dynamics via generative dynamical models has a number of attractive features: however, using all-purpose distances for their classification does not necessarily deliver good results. We propose a general framework for learning distance functions for generative dynamical models, given a training set of labelled videos. The optimal distance function is selected among a family of pullback ones, induced by a parametrised automorphism of the space of models. We focus here on hidden Markov models and their model space, and design an appropriate automorphism there. Experimental results are presented which show how pullback learning greatly improves action recognition performances with respect to base distances.	[Cuzzolin, Fabio; Sapienza, Michael] Oxford Brookes Univ Wheatly Campus, Dept Comp, Oxford OX33 1HX, England		Cuzzolin, F (corresponding author), Oxford Brookes Univ Wheatly Campus, Dept Comp, Turing Bldg, Oxford OX33 1HX, England.		Sapienza, Michael/R-7304-2019	Sapienza, Michael/0000-0001-8876-8492	Engineering and Physical Sciences Research Council (EPSRC) [EP/I018719/1]; Engineering and Physical Sciences Research Council [EP/I018719/1] Funding Source: researchfish; EPSRC [EP/I018719/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council (EPSRC)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was partially supported by the Engineering and Physical Sciences Research Council (EPSRC) grant EP/I018719/1.	Ali S., 2007, P IEEE 11 INT C COMP; [Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], 2008, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2008.4587733; Benbouzid MEH, 1999, IEEE T ENERGY CONVER, V14, P1065, DOI 10.1109/60.815029; Blank M, 2005, IEEE I CONF COMP VIS, P1395; BURMAN P, 1989, BIOMETRIKA, V76, P503, DOI 10.1093/biomet/76.3.503; Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821; Cuzzolin F, 2011, ADV PATTERN RECOGNIT, P55, DOI 10.1007/978-0-85729-057-1_3; Do MN, 2003, IEEE SIGNAL PROC LET, V10, P115, DOI 10.1109/LSP.2003.809034; Elliot R., 1995, HIDDEN MARKOV MODELS; Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079; Galata A, 2001, COMPUT VIS IMAGE UND, V81, P398, DOI 10.1006/cviu.2000.0894; Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492; Hanzon B., 2002, OPEN PROBLEMS MATH S, P27; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669; Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Lafferty J, 2005, J MACH LEARN RES, V6, P129; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Lebanon G, 2006, IEEE T PATTERN ANAL, V28, P497, DOI 10.1109/TPAMI.2006.77; Lebanon G., 2003, P UNC ART INT C UAI; Li R., 2010, P 11 EUR C COMP VIS; Liu J., 2009, P IEEE C COMP VIS PA; Manios E., 2014, LIFE THREATENING VEN; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Petersen P., 1992, RIEMANNIAN GEOMETRY; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B., 2000, STAT LEARNING KERNEL; Shental N, 2002, LECT NOTES COMPUT SC, V2353, P776; Shi Q., 2008, P IEEE C COMP VIS PA, P1, DOI [DOI 10.1109/CVPR.2008.4587557, DOI 10.1109/SARN0F.2008.4520060]; Sykacek P, 2002, ADV NEUR IN, V14, P937; Wang H, 2011, PROC CVPR IEEE	33	6	6	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2014	36	7					1483	1489		10.1109/TPAMI.2013.181	http://dx.doi.org/10.1109/TPAMI.2013.181			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AK1WS	26353316				2022-12-18	WOS:000338209900014
J	Forsyth, DA				Forsyth, David A.			Editorial: State of the Journal	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material																			0	6	7	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					1	1						1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV		Bronze			2022-12-18	WOS:000327965100001
J	Saund, E				Saund, Eric			A Graph Lattice Approach to Maintaining and Learning Dense Collections of Subgraphs as Image Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph lattice; subgraph matching; document classification; line-art analysis; CMD distance; weighted voting	RECOGNITION; CLASSIFICATION; ALGORITHM	Effective object and scene classification and indexing depend on extraction of informative image features. This paper shows how large families of complex image features in the form of subgraphs can be built out of simpler ones through construction of a graph lattice-a hierarchy of related subgraphs linked in a lattice. Robustness is achieved by matching many overlapping and redundant subgraphs, which allows the use of inexpensive exact graph matching, instead of relying on expensive error-tolerant graph matching to a minimal set of ideal model graphs. Efficiency in exact matching is gained by exploitation of the graph lattice data structure. Additionally, the graph lattice enables methods for adaptively growing a feature space of subgraphs tailored to observed data. We develop the approach in the domain of rectilinear line art, specifically for the practical problem of document forms recognition. We are especially interested in methods that require only one or very few labeled training examples per category. We demonstrate two approaches to using the subgraph features for this purpose. Using a bag-of-words feature vector we achieve essentially single-instance learning on a benchmark forms database, following an unsupervised clustering stage. Further performance gains are achieved on a more difficult dataset using a feature voting method and feature selection procedure.	Xerox Corp, Palo Alto Res Ctr, Intelligent Syst Lab, Palo Alto, CA 94304 USA	Xerox	Saund, E (corresponding author), Xerox Corp, Palo Alto Res Ctr, Intelligent Syst Lab, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.							Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Bagdanov AD, 2001, PROC INT CONF DOC, P79, DOI 10.1109/ICDAR.2001.953759; Brown G., 2009, P 12 INT C ART INT S; Bunke H., 2000, P 13 VISION INTERFAC; Chen N, 2007, INT J DOC ANAL RECOG, V10, P1, DOI 10.1007/s10032-006-0020-2; Conte D, 2007, STUD COMPUT INTELL, V52, P85; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; Dimmick D., 2001, STRUCTURED FORMS DAT; Feng S., P INT C CONT BAS IM, P427; JULESZ B, 1978, BIOL CYBERN, V31, P137, DOI 10.1007/BF00336998; Llados J, 2001, IEEE T PATTERN ANAL, V23, P1137, DOI 10.1109/34.954603; Manber U., 1994, P USENIX WINT 1994 T, P2; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; Messmer BT, 2000, IEEE T KNOWL DATA EN, V12, P307, DOI 10.1109/69.842269; Nakai T, 2006, LECT NOTES COMPUT SC, V3872, P541; Neogi D., 2009, United States Patent Application, Patent No. 20090116757; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; PIZANO A, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P399, DOI 10.1109/ICPR.1992.202008; Reddy KVU, 2008, PROC SPIE, V6815, DOI 10.1117/12.766737; Sarkar P, 2006, INT C PATT RECOG, P472; Saund E., 2012, AMA DENT FORMS LINE; Saund E, 2011, PROC INT CONF DOC, P1069, DOI 10.1109/ICDAR.2011.216; Shervashidze N., 2009, P 12 INT C ART INT S, P488; Shin C., 2001, INT J DOCUMENT ANAL, V3; Sidere Nicolas, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P681, DOI 10.1109/ICDAR.2009.218; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Yang J, 2007, MULTIMEDIA C EXHIBIT, P197, DOI [10.1145/1290082.1290111, DOI 10.1145/1290082.1290111]; Zhu L, 2010, PROC CVPR IEEE, P1919	28	6	6	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2323	2339		10.1109/TPAMI.2012.267	http://dx.doi.org/10.1109/TPAMI.2012.267			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23267200				2022-12-18	WOS:000323175200002
J	Taheri, S; Sankaranarayanan, AC; Chellappa, R				Taheri, Sima; Sankaranarayanan, Aswin C.; Chellappa, Rama			Joint Albedo Estimation and Pose Tracking from Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Albedo; pose tracking; spherical harmonics; sequential algorithm; Kalman filter; Rao-Blackwellized particle filter; intrinsic image statistics	PHOTOMETRIC STEREO; FACE RECOGNITION; SHAPE; ILLUMINATION; REFLECTANCE; SURFACES; MODEL	The albedo of a Lambertian object is a surface property that contributes to an object's appearance under changing illumination. As a signature independent of illumination, the albedo is useful for object recognition. Single image-based albedo estimation algorithms suffer due to shadows and non-Lambertian effects of the image. In this paper, we propose a sequential algorithm to estimate the albedo from a sequence of images of a known 3D object in varying poses and illumination conditions. We first show that by knowing/estimating the pose of the object at each frame of a sequence, the object's albedo can be efficiently estimated using a Kalman filter. We then extend this for the case of unknown pose by simultaneously tracking the pose as well as updating the albedo through a Rao-Blackwellized particle filter (RBPF). More specifically, the albedo is marginalized from the posterior distribution and estimated analytically using the Kalman filter, while the pose parameters are estimated using importance sampling and by minimizing the projection error of the face onto its spherical harmonic subspace, which results in an illumination-insensitive pose tracking algorithm. Illustrations and experiments are provided to validate the effectiveness of the approach using various synthetic and real sequences followed by applications to unconstrained, video-based face recognition.	[Taheri, Sima] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA; [Sankaranarayanan, Aswin C.] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77251 USA; [Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, Ctr Automat Res, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park; Rice University; University System of Maryland; University of Maryland College Park	Taheri, S (corresponding author), Univ Maryland, Dept Elect & Comp Engn, 1103 AV Williams, College Pk, MD 20742 USA.	taheri@cs.umd.edu; saswin@rice.edu; rama@cfar.umd.edu	Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAJ-1504-2020	Sankaranarayanan, Aswin/0000-0003-0906-4046	MURI, US Office of Naval Research [N00014-08-1-0638]	MURI, US Office of Naval Research	This work was partially supported by a MURI from the US Office of Naval Research under the grant N00014-08-1-0638. The authors would like to thank Soma Biswas for valuable and insightful discussions.	Aggarwal G., 2005, P 1 INT C PATT REC M; Altman R. B., 1993, P S COMP APPL MED CA; Altman R. B., 1990, TECHNICAL REPORT; Anderson B. D. O., 1979, OPTIMAL FILTERING; Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321; Ba S., 2007, P CLASS EV ACT REL E; BA SO, 2005, P ACM ICMI WORKSH MU; Barmpoutis A., 2008, P IEEE C COMP VIS PA; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Biswas S, 2010, PROC CVPR IEEE, P2683, DOI 10.1109/CVPR.2010.5539987; Biswas S, 2009, IEEE T PATTERN ANAL, V31, P884, DOI 10.1109/TPAMI.2007.12.0830; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BLANZ V., 1999, P ACM SIGGRAPH; DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852; Dovgard R, 2004, P EUR C COMP VIS; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Hong S, 2006, J VLSI SIG PROC SYST, V44, P47, DOI 10.1007/s11265-006-5919-9; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; Horn B.K.P., 1989, SHAPE SHADING; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; Joshi N., 2007, P IEEE INT C COMP VI; La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375; Lakdawalla A., 2007, P PHOT AN COMP VIS; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; LIM J, 2005, P IEEE INT C COMP VI; Marks TK, 2010, IEEE T PATTERN ANAL, V32, P348, DOI 10.1109/TPAMI.2008.278; Maybeck P. S., 1979, MATH SCI ENG; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Paysan P., 2009, P 6 IEEE INT C ADV V; Ramamoorthi R., 2006, FACE PROCESSING ADV; Sankaranarayanan AC, 2008, IEEE T IMAGE PROCESS, V17, P737, DOI 10.1109/TIP.2008.920760; Shi J, 1994, P IEEE C COMP VIS PA; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Simakov D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1202; Smith WAP, 2006, IEEE T PATTERN ANAL, V28, P1914, DOI 10.1109/TPAMI.2006.251; TANABE Y, 1990, GROUP THEORY ITS APP; TAPPEN MF, 2006, P IEEE C COMP VIS PA; Wang Y., 2007, P IEEE C COMP VIS PA; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1968, DOI 10.1109/TPAMI.2008.244; Wen Z., 2003, P IEEE C COMP VIS PA, V2; Weyrich T, 2006, ACM T GRAPHIC, V25, P1013, DOI 10.1145/1141911.1141987; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Xu Y., 2007, P IEEE C COMP VIS PA; Xu YL, 2007, IEEE T PATTERN ANAL, V29, P793, DOI 10.1109/TPAMI.2007.1047; YU T, 2004, P IEEE C COMP VIS PA; Yue Z., 2008, EURASIP J ADV SIGNAL, V2008; Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53; Zhang L., 2003, P IEEE INT C COMP VI; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhao WY, 2001, INT J COMPUT VISION, V45, P55, DOI 10.1023/A:1012369907247; Zhou SK, 2007, IEEE T PATTERN ANAL, V29, P230, DOI 10.1109/TPAMI.2007.25	51	6	7	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1674	1689		10.1109/TPAMI.2012.249	http://dx.doi.org/10.1109/TPAMI.2012.249			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681995				2022-12-18	WOS:000319060600011
J	Holmes, SA; Murray, DW				Holmes, Steven A.; Murray, David W.			Monocular SLAM with Conditionally Independent Split Mapping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Monocular SLAM; relative bundle adjustment; parallel tracking and mapping; split-mapping; submapping	SIMULTANEOUS LOCALIZATION; REAL-TIME; CONSISTENCY; MONOSLAM	The recovery of structure from motion in real time over extended areas demands methods that mitigate the effects of computational complexity and arithmetical inconsistency. In this paper, we develop SCISM, an algorithm based on relative frame bundle adjustment, which splits the recovered map of 3D landmarks and keyframes poses so that the camera can continue to grow and explore a local map in real time while, at the same time, a bulk map is optimized in the background. By temporarily excluding certain measurements, it ensures that both maps are consistent, and by using the relative frame representation, new results from the bulk process can update the local process without disturbance. The paper first shows how to apply this representation to the parallel tracking and mapping (PTAM) method, a real-time bundle adjuster, and compares results obtained using global and relative frames. It then explains the relative representation's use in SCISM and describes an implementation using PTAM. The paper provides evidence of the algorithm's real-time operation in outdoor scenes, and includes comparison with a more conventional submapping approach.	[Holmes, Steven A.; Murray, David W.] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	University of Oxford	Holmes, SA (corresponding author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.	sah@robots.ox.ac.uk; dwm@robots.ox.ac.uk			UK Engineering and Physical Science Research Council [GR/S97774, EP/D037077]; EPSRC; Engineering and Physical Sciences Research Council [GR/S97774/01] Funding Source: researchfish	UK Engineering and Physical Science Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was partially supported by grants GR/S97774 and EP/D037077 from the UK Engineering and Physical Science Research Council, and through an EPSRC Research Studentship to Steven A. Holmes. The authors are grateful to Dr. Georg Klein and Dr. Gabe Sibley for their contributions to the early stages of this work, and particularly to the latter for more recent discussions.	Bailey T, 2006, IEEE INT CONF ROBOT, P424, DOI 10.1109/ROBOT.2006.1641748; Bailey T, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3562, DOI 10.1109/IROS.2006.281644; Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393; Castellanos JA, 2007, ROBOT AUTON SYST, V55, P21, DOI 10.1016/j.robot.2006.06.005; Castle RO, 2010, IMAGE VISION COMPUT, V28, P1548, DOI 10.1016/j.imavis.2010.03.009; Castle RO, 2011, COMPUT VIS IMAGE UND, V115, P854, DOI 10.1016/j.cviu.2011.02.007; Chekhlov D, 2006, LECT NOTES COMPUT SC, V4292, P276; Clemente L.A., 2007, ROBOTICS SCI SYSTEMS, V2; Davison AJ, 2002, IEEE T PATTERN ANAL, V24, P865, DOI 10.1109/TPAMI.2002.1017615; Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049; Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381; Eade E., 2008, P 18 BRIT MACH VIS C; Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264; Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hartley R., 2004, ROBOTICA; Holmes S., 2009, P IEEE INT C ROB AUT; Holmes S., 2008, P IEEE INT C ROB AUT; Holmes S.A., 2010, THESIS U OXFORD; Jongwoo Lim, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3489, DOI 10.1109/CVPR.2011.5995511; Julier SJ, 2001, IEEE INT CONF ROBOT, P4238, DOI 10.1109/ROBOT.2001.933280; KAESS M, 2007, P IEEE INT C ROB AUT; Klein G., 2008, P 10 EUR C COMP VIS; Klein G., 2007, P IEEE ACM 6 INT S M; LEONARD JJ, 1992, DIRECTED SONAR SENSI; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; McGlone C., 2004, MANUAL PHOTOGRAMMETR; Mei C., 2009, P 19 BRIT MACH VIS C; Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7; Montemerlo M., 2002, P AAAI NAT C ART INT; Murray R. M., 1994, MATH INTRO ROBOTIC M; Newman P.M., 2003, P INT JOINT C ART IN; Ni K, 2007, IEEE I CONF COMP VIS, P2009; Ni K, 2010, IEEE INT C INT ROBOT, P2558, DOI 10.1109/IROS.2010.5650197; Pinies P, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3472; Rosten E., 2006, P 9 EUR C COMP VIS; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Sibley G., 2007, P IEEE INT C ROB AUT; Sibley G., 2009, P ROB SCI SYST C; Sibley G., 2009, 230709 U OXF DEP ENG; Sibley G, 2010, INT J ROBOT RES, V29, P958, DOI 10.1177/0278364910369268; SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404; Strasdat H., 2010, P ROB SCI SYST C; Triggs B., 2000, LECT NOTES COMPUTER, V1883, P298, DOI [DOI 10.1007/3-540-44480-7, DOI 10.1007/3-540-44480-7_21]; Williams B., 2009, THESIS U OXFORD	46	6	6	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1451	1463		10.1109/TPAMI.2012.234	http://dx.doi.org/10.1109/TPAMI.2012.234			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599058				2022-12-18	WOS:000317857900014
J	Netz, A; Osadchy, M				Netz, Aaron; Osadchy, Margarita			Recognition Using Specular Highlights	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; varying illumination; pose estimation; invariants; specularities	OBJECT RECOGNITION; IMAGE SEQUENCES; POSE ESTIMATION; COLOR IMAGES; SHAPE; REFLECTANCE; INFORMATION; INVARIANTS; SURFACE; MODELS	We present a novel approach to pose estimation and model-based recognition of specular objects in difficult viewing conditions, such as low illumination, cluttered background, large highlights, and shadows that appear on the object of interest. in such challenging conditions, conventional features are unreliable. We show that under the assumption of a dominant light source, specular highlights produced by a known object can be used to establish correspondence between its image and the 3D model, and to verify the hypothesized pose and the identity of the object. Previous methods that use highlights for recognition make limiting assumptions such as known pose, scene-dependent calibration, simple shape, etc. The proposed method can efficiently recognize free-form specular objects in arbitrary pose and under unknown lighting direction. It uses only a single image of the object as its input and outputs object identity and the full pose. We have performed extensive experiments for both recognition and pose estimation accuracy on synthetic images and on real indoor and outdoor images.	[Netz, Aaron] Univ Haifa, Dept Comp Sci, IL-40700 Ariel, Israel; [Osadchy, Margarita] Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel	University of Haifa; University of Haifa	Netz, A (corresponding author), Univ Haifa, Dept Comp Sci, Uri Baron 28, IL-40700 Ariel, Israel.	aaronetz@gmail.com; rita@cs.haifa.ac.il						Alter T.D., 1992, TECHNICAL REPORT; B Barrois, 2007, P IEEE C COMP VIS PA, P1; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Beis JS, 1999, IEEE T PATTERN ANAL, V21, P1000, DOI 10.1109/34.799907; BIRK JR, 1981, IEEE T SYST MAN CYB, V11, P151, DOI 10.1109/TSMC.1981.4308640; BLAKE A, 1991, PHILOS T R SOC B, V331, P237, DOI 10.1098/rstb.1991.0012; BLAKE A, 1988, P IEEE INT C COMP VI, P394; Blinn J, 1977, ACM SIGGRAPH COMPUT, V11, P192, DOI [10.1145/965141.563893, DOI 10.1145/965141.563893]; CASS TA, 1992, LECT NOTES COMPUT SC, V588, P834; Chang JY, 2009, PROC CVPR IEEE, P1706, DOI 10.1109/CVPRW.2009.5206820; Collet A, 2011, INT J ROBOT RES, V30, P1284, DOI 10.1177/0278364911401765; David P, 2005, IEEE I CONF COMP VIS, P1581; DelPozo A., 2007, P IEEE C COMP VIS PA, V2, P2007; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; Fukada Y., 1984, Robotica, V2, P147, DOI 10.1017/S0263574700000849; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; Gershon R., 1987, P 10 INT JOINT C ART, V2, P752; GREMBAN KD, 1994, INT J COMPUT VISION, V12, P137, DOI 10.1007/BF01421201; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; Hsiao E, 2010, PROC CVPR IEEE, P2653, DOI 10.1109/CVPR.2010.5539981; Huttenlocher D.P., 1987, P IEEE INT C COMP VI, V87, P102; Jacobs D, 1999, INT J COMPUT VISION, V34, P123, DOI 10.1023/A:1008135819955; KLANK U, 2009, P 9 IEEE RAS INT C H; KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279; Koshikawa K., 1985, Proceedings of '85 International Conference on Advanced Robotics, P185; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Lagger P., 2008, P IEEE C COMP VIS PA; Lamdan Y., 1988, P IEEE INT C COMP VI, P238; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; McHenry K, 2005, PROC CVPR IEEE, P973; Norman JF, 2004, PSYCHOL SCI, V15, P565, DOI 10.1111/j.0956-7976.2004.00720.x; Oren M, 1997, INT J COMPUT VISION, V24, P105, DOI 10.1023/A:1007954719939; Ortiz F, 2006, IEEE T SYST MAN CY C, V36, P681, DOI 10.1109/TSMCC.2005.855424; Osadchy M, 2008, COMPUT VIS IMAGE UND, V111, P275, DOI 10.1016/j.cviu.2007.12.004; Powell M. J. D., 1978, Proceedings of the Biennial Conference on numerical analysis, P144; Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448; ROTH S, 2006, P IEEE C COMP VIS PA, P1869; Rothganger F, 2006, LECT NOTES COMPUT SC, V4170, P105; SATO K, 1991, P IEEE WORKSH DIR AU, P2; Savarese S, 2005, INT J COMPUT VISION, V64, P31, DOI 10.1007/s11263-005-1086-x; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; SCHULTZ H, 1994, IEEE T PATTERN ANAL, V16, P195, DOI 10.1109/34.273732; Shirdhonkar S, 2005, IEEE I CONF COMP VIS, P1323; Sim DG, 1999, IEEE T IMAGE PROCESS, V8, P425, DOI 10.1109/83.748897; Suk T., 2004, P INT C PATT REC, V2; Swaminathan R, 2002, LECT NOTES COMPUT SC, V2350, P508; THORNBER K, 2001, 2001033 NEC; Wang J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1374, DOI 10.1109/ICCV.2003.1238650; Wolff L. B., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P363, DOI 10.1109/CVPR.1989.37873	49	6	7	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					639	652		10.1109/TPAMI.2012.127	http://dx.doi.org/10.1109/TPAMI.2012.127			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22665722				2022-12-18	WOS:000314792900010
J	Schluter, R; Nussbaum-Thom, M; Ney, H				Schlueter, Ralf; Nussbaum-Thom, Markus; Ney, Hermann			Does the Cost Function Matter in Bayes Decision Rule?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Statistical pattern recognition; classifier design and evaluation; Bayes decision rule; cost/loss function	AUTOMATIC SPEECH RECOGNITION; RISK; ASR	In many tasks in pattern recognition, such as automatic speech recognition (ASR), optical character recognition (OCR), part-of-speech (POS) tagging, and other string recognition tasks, we are faced with a well-known inconsistency: The Bayes decision rule is usually used to minimize string (symbol sequence) error, whereas, in practice, we want to minimize symbol (word, character, tag, etc.) error. When comparing different recognition systems, we do indeed use symbol error rate as an evaluation measure. The topic of this work is to analyze the relation between string (i.e., 0-1) and symbol error (i.e., metric, integer valued) cost functions in the Bayes decision rule, for which fundamental analytic results are derived. Simple conditions are derived for which the Bayes decision rule with integer-valued metric cost function and with 0-1 cost gives the same decisions or leads to classes with limited cost. The corresponding conditions can be tested with complexity linear in the number of classes. The results obtained do not make any assumption w.r.t. the structure of the underlying distributions or the classification problem. Nevertheless, the general analytic results are analyzed via simulations of string recognition problems with Levenshtein (edit) distance cost function. The results support earlier findings that considerable improvements are to be expected when initial error rates are high.	[Schlueter, Ralf; Nussbaum-Thom, Markus; Ney, Hermann] Rhein Westfal TH Aachen, Lehrstuhl Informat 6, Dept Comp Sci, D-52074 Aachen, Germany	RWTH Aachen University	Schluter, R (corresponding author), Rhein Westfal TH Aachen, Lehrstuhl Informat 6, Dept Comp Sci, Ahornstr 55, D-52074 Aachen, Germany.	schlueter@cs.rwth-aachen.de; nussbaum@cs.rwth-aachen.de; ney@cs.rwth-aachen.de		Schluter, Ralf/0000-0003-2839-9247				Ehling N., 2007, P 45 ANN M ASS COMP, P101; Goel V, 2003, PATTERN RECOGNITION IN SPEECH AND LANGUAGE PROCESSING, P51; Goel V, 2004, IEEE T SPEECH AUDI P, V12, P234, DOI 10.1109/TSA.2004.825678; Goel V, 2000, COMPUT SPEECH LANG, V14, P115, DOI 10.1006/csla.2000.0138; HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x; Hoffmeister B, 2007, INT CONF ACOUST SPEE, P1145; Jelinek Frederick, 1997, STAT METHODS SPEECH; Loof Jonas, 2007, INTERSPEECH, P2145; MANGU L, 1999, P EUR, P495; Merialdo B., 1994, Computational Linguistics, V20, P155; Ney H., 2004, P C EMP METH NAT LAN, P270; Schluter R, 2011, IEEE T AUDIO SPEECH, V19, P1103, DOI 10.1109/TASL.2010.2091635; SCHLUTER R, 2005, P EUR C SPEECH COMM, P1449; Schluter R., 2010, SIMULATION FIXED LEN; Stolcke Andreas, 1997, 5 EUR C SPEECH COMM; Wessel F, 2001, INT CONF ACOUST SPEE, P33, DOI 10.1109/ICASSP.2001.940760	16	6	6	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					292	301		10.1109/TPAMI.2011.163	http://dx.doi.org/10.1109/TPAMI.2011.163			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21844628				2022-12-18	WOS:000298105500008
J	Yuan, H; Atallah, MJ				Yuan, Hao; Atallah, Mikhail J.			Running Max/Min Filters Using 1+o(1) Comparisons per Sample	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mathematical morphology; erosion; dilation; opening; closing	LOWEST COMMON ANCESTORS; FAST ALGORITHMS; MAX FILTERS; MIN	A running max (or min) filter asks for the maximum or (minimum) elements within a fixed-length sliding window. The previous best deterministic algorithm (developed by Gil and Kimmel, and refined by Coltuc) can compute the 1D max filter using 1.5 + o(1) comparisons per sample in the worst case. The best-known algorithm for independent and identically distributed input uses 1.25 + o(1) expected comparisons per sample (by Gil and Kimmel). In this work, we show that the number of comparisons can be reduced to 1 + o(1) comparisons per sample in the worst case. As a consequence of the new max/min filters, the opening (or closing) filter can also be computed using 1 + o(1) comparisons per sample in the worst case, where the previous best work requires 1.5 + o(1) comparisons per sample (by Gil and Kimmel); and computing the max and min filters simultaneously can be done in 2 + o(1) comparisons per sample in the worst case, where the previous best work (by Lemire) requires three comparisons per sample. Our improvements over the previous work are asymptotic, that is, the number of comparisons is reduced only when the window size is large.	[Yuan, Hao] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; [Atallah, Mikhail J.] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	City University of Hong Kong; Purdue University System; Purdue University; Purdue University West Lafayette Campus	Yuan, H (corresponding author), City Univ Hong Kong, Dept Comp Sci, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.	haoyuan@cityu.edu.hk; mja@cs.purdue.edu			US National Science Foundation (NSF) [CNS-0915436, CNS-0913875]; Science and Technology Center [CCF-0939370]; NPRP grant from the Qatar National Research Fund; US Air Force Office of Scientific Research [FA9550-09-1-0223]; Center for Education and Research in Information Assurance and Security; City University of Hong Kong [7200218]	US National Science Foundation (NSF)(National Science Foundation (NSF)); Science and Technology Center(Science and Technology Development Fund (STDF)); NPRP grant from the Qatar National Research Fund(Qatar National Research Fund (QNRF)); US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); Center for Education and Research in Information Assurance and Security; City University of Hong Kong(City University of Hong Kong)	The authors would like to thank the referees for their helpful comments and suggestions. Portions of this work were supported by US National Science Foundation (NSF) Grants CNS-0915436, CNS-0913875, Science and Technology Center CCF-0939370; by an NPRP grant from the Qatar National Research Fund; by Grant FA9550-09-1-0223 from the US Air Force Office of Scientific Research; by sponsors of the Center for Education and Research in Information Assurance and Security; and by a grant from City University of Hong Kong (Project No. 7200218). The statements made herein are solely the responsibility of the authors.	ALSTRUP S, 2002, P 14 ANN ACM S PAR A, P258, DOI DOI 10.1145/564870.564914; Coltuc D, 2008, IEEE T SIGNAL PROCES, V56, P3191, DOI 10.1109/TSP.2008.920141; GABOW HN, 1984, P 16 ANN ACM S THEOR, P135; Gevorkian DZ, 1997, IEEE T PATTERN ANAL, V19, P526, DOI 10.1109/34.589214; Gil J, 2002, IEEE T PATTERN ANAL, V24, P1606, DOI 10.1109/TPAMI.2002.1114852; GIL J, 1993, IEEE T PATTERN ANAL, V15, P504, DOI 10.1109/34.211471; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; HAREL D, 1984, SIAM J COMPUT, V13, P338, DOI 10.1137/0213024; Lemire D., 2006, Nordic Journal of Computing, V13, P328; PITAS I, 1989, IEEE T CIRCUITS SYST, V36, P795, DOI 10.1109/31.90400; SCHIEBER B, 1988, SIAM J COMPUT, V17, P1253, DOI 10.1137/0217079; Soille P., 2013, MORPHOLOGICAL IMAGE; VANHERK M, 1992, PATTERN RECOGN LETT, V13, P517, DOI 10.1016/0167-8655(92)90069-C; VUILLEMIN J, 1980, COMMUN ACM, V23, P229, DOI 10.1145/358841.358852; Yuan H, 2010, PROC APPL MATH, V135, P150	16	6	6	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2544	2548		10.1109/TPAMI.2011.183	http://dx.doi.org/10.1109/TPAMI.2011.183			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21876226				2022-12-18	WOS:000295980000018
J	Caulier, Y; Bourennane, S				Caulier, Yannick; Bourennane, Salah			Visually Inspecting Specular Surfaces: A Generalized Image Capture and Image Description Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deflectometry; specular surfaces; image capturing; image description; stripe pattern; feature selection	FEATURE-SELECTION; FRINGE PATTERNS; FEATURES	Image capturing and image content description can be regarded as the two major steps of a computer vision process. This paper focuses on both within the field of specular surface inspection, by generalizing a previously defined stripe-based inspection method to free-form surfaces on the basis of a specific stripe illumination technique and by outlining a general feature-based stripe image characterization approach by means of new theoretical concepts. One major purpose of this paper is to propose a general stripe image interpretation approach on the basis of a three-step procedure: 1) comparison of different image content description techniques, 2) fusion of the most appropriate ones, and 3) selection of the optimal features. It is shown that this approach leads to an increase in the classification rates of more than 2 percent between the initial fused set and the selected one. The new contributions encompass 1) the generalization of a cylindrical specular surface enhancement technique to more complex specular geometries, 2) the generalization of the previously defined stripe image description by using the same number of features for the bright and the dark stripes, and 3) the definition of an optimal, in terms of classification rates and computational costs, stripe feature set.	[Caulier, Yannick] Fraunhofer Inst Integrated Circuits, D-90762 Furth, Germany; [Bourennane, Salah] Ecole Cent Marseille, Inst Fresnel, F-13397 Marseille 20, France	Fraunhofer Gesellschaft; UDICE-French Research Universities; Aix-Marseille Universite	Caulier, Y (corresponding author), Fraunhofer Inst Integrated Circuits, IIS Dr Mack Str 81, D-90762 Furth, Germany.	yannick.caulier@iis.fraunhofer.de; salah.bourennane@fresnel.fr			Bavarian Research Foundation (Bayerische Forschungsstiftung-BFS)	Bavarian Research Foundation (Bayerische Forschungsstiftung-BFS)	This work was supported by a grant from the Bavarian Research Foundation (Bayerische Forschungsstiftung-BFS).	Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; CAULIER Y, 2008, THESIS U ERLANGEN NU; CAULIER Y, 2010, PRODUCT INFORM; Caulier Y, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/237459; Caulier Y, 2008, OPT ENG, V47, DOI 10.1117/1.2927463; CHEN YQ, 1995, PATTERN RECOGN, V28, P537, DOI 10.1016/0031-3203(94)00116-4; Delcroix G, 2001, J ELECTRON IMAGING, V10, P196, DOI 10.1117/1.1314333; Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100; Farmer ME, 2005, IEEE T IMAGE PROCESS, V14, P2060, DOI 10.1109/TIP.2005.859374; Gutierrez-Osuna R, 2002, IEEE SENS J, V2, P189, DOI 10.1109/JSEN.2002.800688; Hall MA., 1999, CORRELATION BASED FE; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hausler G., 1999, patent, Patent No. 19944354; JUPTNER W, 1994, PROC SPIE, V2343, P16; Kammel S, 2004, THESIS U KARLSRUHE; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kruger S, 2001, J ELECTRON IMAGING, V10, P228, DOI 10.1117/1.1318908; Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71; Leon FP, 1997, P SOC PHOTO-OPT INS, V3208, P394, DOI 10.1117/12.290311; Li XD, 2000, OPT ENG, V39, P2821, DOI 10.1117/1.1308485; MARINO P, 1999, P 25 ANN C IEEE IND, V3, P1330; Martin B., 1995, THESIS U WAIKATO; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P208, DOI 10.1109/70.54736; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Pernkopf F, 2002, EURASIP J APPL SIG P, V2002, P667, DOI 10.1155/S1110865702203145; Petz M, 2002, OPTICAL 3D MEASUREME; QIAN K, 2005, MEASUREMENT SCI TECH, V15, P1582; Quinlan J. R., 2003, C4 5 PROGRAMS MACHIN; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Reindl I., 2007, P 2007 IEEE INSTR ME, P1, DOI [10.1109/IMTC.2007.379109, DOI 10.1109/IMTC.2007.379109]; SEULIN R, 2001, P 5 INT C QUAL CONTR; TAKEDA M, 1982, J OPT SOC AM, V72, P156, DOI 10.1364/JOSA.72.000156; Tuceryan M, 1998, HDB PATTERN RECOGNIT, P207; WAGNER T, 1996, P C MACH VIS APPL IN, P128; WAGNER T, 1999, THESIS U ERLANGEN NU; WESKA JS, 1978, COMPUT GRAPHICS IMAG, V7, P259; WILLIAMS A, 2008, INSPECT MAGAZINE; WOODHAM R, 1991, TR9118 U BRIT COL; ZHI H, 1992, P 11 INT C PATT REC, V3, P105	41	6	6	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					2100	2105		10.1109/TPAMI.2010.137	http://dx.doi.org/10.1109/TPAMI.2010.137			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20714013				2022-12-18	WOS:000281990900012
J	Schuchert, T; Aach, T; Scharr, H				Schuchert, Tobias; Aach, Til; Scharr, Hanno			Range Flow in Varying Illumination: Algorithms and Comparisons	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Range flow; illumination changes; brightness constancy constraint; prefiltering; homomorphic filter; gradient constancy; structure tensor; 3D motion estimation	OPTICAL-FLOW	We extend estimation of range flow to handle brightness changes in image data caused by inhomogeneous illumination. Standard range flow computes 3D velocity fields using both range and intensity image sequences. Toward this end, range flow estimation combines a depth change model with a brightness constancy model. However, local brightness is generally not preserved when object surfaces rotate relative to the camera or the light sources, or when surfaces move in inhomogeneous illumination. We describe and investigate different approaches to handle such brightness changes. A straightforward approach is to prefilter the intensity data such that brightness changes are suppressed, for instance, by a highpass or a homomorphic filter. Such prefiltering may, though, reduce the signal-to-noise ratio. An alternative novel approach is to replace the brightness constancy model by 1) a gradient constancy model, or 2) by a combination of gradient and brightness constancy constraints used earlier successfully for optical flow, or 3) by a physics-based brightness change model. In performance tests, the standard version and the novel versions of range flow estimation are investigated using prefiltered or nonprefiltered synthetic data with available ground truth. Furthermore, the influences of additive Gaussian noise and simulated shot noise are investigated. Finally, we compare all range flow estimators on real data.	[Schuchert, Tobias] Fraunhofer Inst Optron Syst Technol & Image Explo, Dept Autonomous Syst & Machine Vis ASM, D-76131 Karlsruhe, Germany; [Aach, Til] Rhein Westfal TH Aachen, Inst Imaging & Comp Vis, D-52056 Aachen, Germany; [Scharr, Hanno] Forschungszentrum Julich, Inst Chem & Dynam Geosphere, D-52428 Julich, Germany	Fraunhofer Gesellschaft; RWTH Aachen University; Helmholtz Association; Research Center Julich	Schuchert, T (corresponding author), Fraunhofer Inst Optron Syst Technol & Image Explo, Dept Autonomous Syst & Machine Vis ASM, Fraunhoferstr 1, D-76131 Karlsruhe, Germany.	tobias.schuchert@iosb.fraunhofer.de; Til.Aach@lfb.rwth-aachen.de; h.scharr@fz-juelich.de	Scharr, Hanno/D-9051-2015	Scharr, Hanno/0000-0002-8555-6416				ARSENAULT HH, 1983, CAN J PHYS, V61, P309, DOI 10.1139/p83-042; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43; Bruhn Andres., 2006, THESIS SAARLAND U; DENNEY TS, 1994, IEEE T IMAGE PROCESS, V3, P178, DOI 10.1109/83.277899; Gharavi H, 2007, IEEE T INTELL TRANSP, V8, P133, DOI 10.1109/TITS.2006.883112; Haussecker HW, 2001, IEEE T PATTERN ANAL, V23, P661, DOI 10.1109/34.927465; Huguet F., 2007, P IEEE INT C COMP VI; Jahne B., 1999, HDB COMPUTER VISION; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; LI R, 2005, P IEEE WORKSH COMP V, V2, P147; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; Nestares O., 2000, P IEEE C COMP VIS PA; OPPENHEI.AV, 1968, PR INST ELECTR ELECT, V56, P1264, DOI 10.1109/PROC.1968.6570; Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; Scharr H., 2006, P VIS MOD VIS 06, P81; SCHARR H, 2004, P INT WORKSH COMPL M, P14; SCHARR H, 2005, P INT WORKSH COMPL M; SCHUCHERT T, 2008, P EUR C COMP VIS, P509; Schuchert T, 2007, LECT NOTES COMPUT SC, V4713, P184; Spies H, 2002, COMPUT VIS IMAGE UND, V85, P209, DOI 10.1006/cviu.2002.0970; Spies H., 1999, P DAGM, P309; SPIES H, 2001, SURFACE EXPANSION RA, P163; Toth D., 2000, 4th IEEE Southwest Symposium on Image Analysis and Interpretation, P3, DOI 10.1109/IAI.2000.839561; Vedula S, 2005, IEEE T PATTERN ANAL, V27, P475, DOI 10.1109/TPAMI.2005.63; YANAGISAWA K, 1993, HEAD NECK-J SCI SPEC, V15, P1, DOI 10.1002/hed.2880150102; Zhang Y, 2000, PROC CVPR IEEE, P674, DOI 10.1109/CVPR.2000.854939; [No title captured]	31	6	6	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1646	1658		10.1109/TPAMI.2009.162	http://dx.doi.org/10.1109/TPAMI.2009.162			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	626MB	20634558	Green Submitted			2022-12-18	WOS:000279969000008
J	Argentini, A; Blanzieri, E				Argentini, Andrea; Blanzieri, Enrico			About Neighborhood Counting Measure Metric and Minimum Risk Metric	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern recognition; machine learning; k-Nearest Neighbors; distance measures; MRM; NCM		In a 2006 TPAMI paper, Wang proposed the Neighborhood Counting Measure [2], a similarity measure for the k-NN algorithm. In his paper, Wang mentioned the Minimum Risk Metric (MRM, [1]), an early distance measure based on the minimization of the risk of misclassification. Wang did not compare NCM to MRM because of its allegedly excessive computational load. In this comment paper, we complete the comparison that was missing in Wang's paper and, from our empirical evaluation, we show that MRM outperforms NCM and that its running time is not prohibitive as Wang suggested.	[Argentini, Andrea; Blanzieri, Enrico] Univ Trent, Dipartimento Ingn & Sci Informaz, I-38100 Trento, Italy	University of Trento	Argentini, A (corresponding author), Univ Trent, Dipartimento Ingn & Sci Informaz, I-38100 Trento, Italy.	argentini@disi.unitn.it; blanzieri@dit.unitn.it	Argentini, Andrea/L-1703-2019	Argentini, Andrea/0000-0002-9797-6362; Blanzieri, Enrico/0000-0001-6524-0601				ARGENTINI A, 2008, DISI08057 U TRENT IT; Blanzieri E, 1999, MACHINE LEARNING, PROCEEDINGS, P22; Mahamud S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P242; Wang H, 2006, IEEE T PATTERN ANAL, V28, P942, DOI 10.1109/TPAMI.2006.126; Wang H., 2007, COMMUNICATION; Witten I.H., 2005, P DATA MINING LAS VE, P4	6	6	6	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					763	765		10.1109/TPAMI.2009.69	http://dx.doi.org/10.1109/TPAMI.2009.69			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224130	Green Submitted			2022-12-18	WOS:000274548800016
J	Das, S; Vaswani, N				Das, Samarjit; Vaswani, Namrata			Nonstationary Shape Activities: Dynamic Models for Landmark Shape Change and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Landmark shape sequence analysis; nonstationary shape sequences; Kendall's shape space; tangent space; tracking; particle filtering		Our goal is to develop statistical models for the shape change of a configuration of "landmark" points (key points of interest) over time and to use these models for filtering and tracking to automatically extract landmarks, synthesis, and change detection. The term "shape activity" was introduced in recent work to denote a particular stochastic model for the dynamics of landmark shapes (dynamics after global translation, scale, and rotation effects are normalized for). In that work, only models for stationary shape sequences were proposed. But most "activities" of a set of landmarks, e.g., running, jumping, or crawling, have large shape changes with respect to initial shape and hence are nonstationary. The key contribution of this work is a novel approach to define a generative model for both 2D and 3D nonstationary landmark shape sequences. Greatly improved performance using the proposed models is demonstrated for sequentially filtering noise-corrupted landmark configurations to compute Minimum Mean Procrustes Square Error (MMPSE) estimates of the true shape and for tracking human activity videos, i.e., for using the filtering to predict the locations of the landmarks (body parts) and using this prediction for faster and more accurate landmarks extraction from the current image.	[Das, Samarjit; Vaswani, Namrata] Iowa State Univ, Dept Elect & Comp Engn, Ames, IA 50011 USA	Iowa State University	Das, S (corresponding author), Iowa State Univ, Dept Elect & Comp Engn, Ames, IA 50011 USA.	samarjit@iastate.edu; namrata@iastate.edu			US National Science Foundation (NSF) [ECCS 0725849]	US National Science Foundation (NSF)(National Science Foundation (NSF))	Part of this paper appeared in [1], [2]. This work was partially funded by US National Science Foundation (NSF) grant ECCS 0725849.	Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; *CMU, 2009, CMU MOT CAPT DAT; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; DAS S, 2008, P IEEE INT C IM PROC; DOUCET A, 1998, INFENGTR310 CUEDF DE; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HOU SB, 2007, P IEEE INT C COMP VI; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; JU SX, 1996, P 2 INT C AUT FAC GE; Kendall D.G., 1999, SHAPE SHAPE THEORY; KENT JT, 1994, J ROY STAT SOC B MET, V56, P285; KHAN S, 2008, MATLAB CODE OPTICAL; KUME A, 2002, P STAT LARG DAT; Kume A, 2007, BIOMETRIKA, V94, P513, DOI 10.1093/biomet/asm047; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; Lelieveldt B. P. F., 2001, Information Processing in Medical Imaging. 17th International Conference, IPMI 2001. Proceedings (Lecture Notes in Computer Science Vol.2082), P446; PARAGIOS N, 2005, P 5 INT C SCAL SPAC; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; SONG B, 2007, P IEEE C COMP VIS PA; Srivastava A, 2004, ADV APPL PROBAB, V36, P43, DOI 10.1239/aap/1077134463; Srivastava A, 2009, IEEE T PATTERN ANAL, V31, P1616, DOI 10.1109/TPAMI.2008.223; TAIPENG T, 2005, 2005029 BOST U COMP; TIERNEY L, 1986, J AM STAT ASSOC, V81, P82, DOI 10.2307/2287970; Vaswani N, 2005, IEEE T IMAGE PROCESS, V14, P1603, DOI 10.1109/TIP.2005.852197; VASWANI N, 2005, P IEEE C DEC CONTR D; VASWANI N, 2007, P AS C SIGN SYST COM; Vaswani N, 2008, IEEE T SIGNAL PROCES, V56, P4583, DOI 10.1109/TSP.2008.925969; Vaswani N, 2007, IEEE T SIGNAL PROCES, V55, P859, DOI 10.1109/TSP.2006.887111; Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246	32	6	6	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					579	592		10.1109/TPAMI.2009.94	http://dx.doi.org/10.1109/TPAMI.2009.94			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224116				2022-12-18	WOS:000274548800002
J	Giblin, PJ; Kimia, BB; Pollitt, AJ				Giblin, Peter J.; Kimia, Benjamin B.; Pollitt, Anthony J.			Transitions of the 3D Medial Axis under a One-Parameter Family of Deformations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Medial axis; shape; singularity; skeleton; transition	FORMAL CLASSIFICATION; POINTS	The instabilities of the medial axis of a shape under deformations have long been recognized as a major obstacle to its use in recognition and other applications. These instabilities, or transitions, occur when the structure of the medial axis graph changes abruptly under deformations of shape. The recent classification of these transitions in 2D for the medial axis and for the shock graph was a key factor in the development of an object recognition system where the classified instabilities were utilized to represent deformation paths. The classification of generic transitions of the 3D medial axis could likewise potentially lead to a similar representation in 3D. In this paper, these transitions are classified by examining the order of contact of spheres with the surface, leading to an enumeration of possible transitions which are then examined on a case-by-case basis. Some cases are ruled out as never occurring in any family of deformations, while others are shown to be nongeneric in a one-parameter family of deformations. Finally, the remaining cases are shown to be viable by developing a specific example for each. Our work is inspired by that of Bogaevsky, who obtained the transitions as part of an investigation of viscosity solutions of Hamilton-Jacobi equations. Our contribution is to give a more down-to-earth approach, bringing this work to the attention of the computer vision community, and to provide explicit constructions for the various transitions using simple surfaces. We believe that the classification of these transitions is vital to the successful regularization of the medial axis in its use in real applications.	[Giblin, Peter J.; Pollitt, Anthony J.] Univ Liverpool, Dept Math Sci, Liverpool L69 7ZL, Merseyside, England; [Kimia, Benjamin B.] Brown Univ, Div Engn, Providence, RI 02912 USA	University of Liverpool; Brown University	Giblin, PJ (corresponding author), Univ Liverpool, Dept Math Sci, Peach St, Liverpool L69 7ZL, Merseyside, England.	pjgiblin@liv.ac.uk; kimia@lems.brown.edu; ajpollitt@hotmail.co.uk			US National Science Foundation [NSF BCS-9980091, ECS-0070887]; European Union; EPSRC	US National Science Foundation(National Science Foundation (NSF)); European Union(European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors gratefully acknowledge the support of US National Science Foundation Grants NSF BCS-9980091 and ECS-0070887. Peter J. Giblin also acknowledges the European Union for the grant DSSCV, and Peter J. Giblin and Anthony J. Politt acknowledge a grant from the EPSRC. The simulations were performed by Frederic Leymarie and Ming-Ching Chang [32] using a numerical simulation originally developed in [20] and later extended by Ming-Ching Chang. The authors also appreciate the assistance of Mireille Boutin, Raghavan Dhandapani, and Declan Davis in creating some sample cases and Ming-Ching Chang in the final editing of this paper.	ARNOLD VI, 1993, SINGULARITY THEORY 2, V39; Bogaevsky IA, 2002, PHYSICA D, V173, P1, DOI 10.1016/S0167-2789(02)00652-8; Bruce J.W., 1992, CURVES SINGULARITIES; BRUCE JW, 1986, P ROY SOC EDINB A, V104, P179, DOI 10.1017/S030821050001917X; Bruce JW, 1996, INT J COMPUT VISION, V18, P195, DOI 10.1007/BF00123141; CHANG MC, 2008, P IEEE CS C COMP VIS; CHANG MC, 2008, THESIS BROWN U; Chang NC, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P987; Damon J, 2005, INT J COMPUT VISION, V63, P45, DOI 10.1007/s11263-005-4946-5; Damon J, 2007, INT J COMPUT VISION, V74, P103, DOI 10.1007/s11263-006-0004-1; Giblin P, 2004, IEEE T PATTERN ANAL, V26, P238, DOI 10.1109/TPAMI.2004.1262192; Giblin P, 2000, PROC CVPR IEEE, P566, DOI 10.1109/CVPR.2000.855870; Giblin PJ, 2003, INT J COMPUT VISION, V54, P143, DOI 10.1023/A:1023761518825; GIBLIN PJ, 2008, MED REPRESENTATIONS; GIBLIN PJ, 2002, P 7 EUR C COMP VIS, P718; Hallinan P. W., 1999, 2 3 DIMENSIONAL PATT; JOHANNES M, 2001, POCV, P41; Klein P, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P696; Klein PN, 2001, SIAM PROC S, P781; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; Leymarie FF, 2004, INT C PATT RECOG, P123, DOI 10.1109/ICPR.2004.1334484; LEYMARIE FF, 2003, THESIS BROWN U; Leymarie FF, 2008, COMPUT IMAGING VIS, V37, P327; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; POLLITT AJ, 2004, THESIS U LIVERPOOL; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shaked D, 1998, COMPUT VIS IMAGE UND, V69, P156, DOI 10.1006/cviu.1997.0598; Tamrakar A., 2004, P CVPR WORKSH PERC O, P47; Tari ZSG, 1997, COMPUT VIS IMAGE UND, V66, P133, DOI 10.1006/cviu.1997.0612; Tek H, 2001, J MATH IMAGING VIS, V14, P211, DOI 10.1023/A:1011229911541; TRINH N, 2007, P 11 IEEE INT C COMP; [No title captured]	32	6	6	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					900	918		10.1109/TPAMI.2008.120	http://dx.doi.org/10.1109/TPAMI.2008.120			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19299863				2022-12-18	WOS:000264144500010
J	Dobrisek, S; Zibert, J; Pavesic, N; Mihelic, F				Dobrisek, Simon; Zibert, Janez; Pavesic, Nikola; Mihelic, France			An Edit-Distance Model for the Approximate Matching of Timed Strings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern matching; similarity measures; edit distance; classifier evaluation; speech recognition		An edit-distance model that can be used for the approximate matching of contiguous and noncontiguous timed strings is presented. The model extends the concept of the weighted string-edit distance by introducing timed edit operations and by making the edit costs time dependent. Special attention is paid to the timed null symbols that are associated with the timed insertions and deletions. The usefulness of the presented model is demonstrated on the classification of phone-recognition errors using the TIMIT speech database.	[Dobrisek, Simon; Zibert, Janez; Pavesic, Nikola; Mihelic, France] Univ Ljubljana, Fac Elect Engn, Lab Artificial Percept Syst & Cybernet LUKS, SI-1000 Ljubljana, Slovenia	University of Ljubljana	Dobrisek, S (corresponding author), Univ Ljubljana, Fac Elect Engn, Lab Artificial Percept Syst & Cybernet LUKS, Trzaska 25, SI-1000 Ljubljana, Slovenia.	simon.dobrisek@fe.uni-lj.si; janez.zibert@fe.uni-lj.si; nikola.pavesic@fe.uni-lj.si; france.mihelic@fe.uni-lj.si	Dobrisek, Simon/R-2062-2018	Dobrisek, Simon/0000-0002-9130-0345; Zibert, Janez/0000-0003-2312-5431				Aho A.V., 1990, ALGORITHMS COMPLEXIT, VA, P255, DOI 10.1016/B978-0-444-88071-0.50010-2; ALUR R, 1994, THEORETICAL COMPUTER, V126, P235; BUNKE H, 1995, IEEE T SYST MAN CYB, V25, P202, DOI 10.1109/21.362950; Cutler A, 2004, J ACOUST SOC AM, V116, P3668, DOI 10.1121/1.1810292; Doddington G, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P630, DOI 10.1109/ASRU.2003.1318513; Gibbon D, 1997, HDB STANDARDS RESOUR; HETLAND ML, 2004, DATA MINING TIME SER, P27; Kruskal J, 1999, TIME WARPS STRING ED, P125; Kruskal J. B., 1999, TIME WARPS STRING ED, P256; KRUSKAL JB, 1999, TIME WARPS STRING ED, P11; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; Mannila H, 1997, FOURTH INTERNATIONAL WORKSHOP ON TEMPORAL REPRESENTATION AND REASONING, PROCEEDINGS, P136, DOI 10.1109/TIME.1997.600793; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; MASEK WJ, 1980, J COMPUT SYST SCI, V20, P18, DOI 10.1016/0022-0000(80)90002-1; MONGEAU M, 1990, COMPUT HUMANITIES, V24, P161, DOI 10.1007/BF00117340; MYERS CS, 1981, AT&T TECH J, V60, P1389, DOI 10.1002/j.1538-7305.1981.tb00272.x; *NIST, 2007, NIST SPEECH REC SCOR; *NIST, 1990, DARPA TIMIT AC PHON; OKUDA T, 1976, IEEE T COMPUT, V25, P172, DOI 10.1109/TC.1976.5009232; Rabiner L., 1993, FUNDAMENTALS SPEECH; VERWER SE, 2006, P ANN MACH LEARN C B, P57; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Witt SM, 2000, SPEECH COMMUN, V30, P95, DOI 10.1016/S0167-6393(99)00044-8; Young S.J., 2006, HTK BOOK VERSION 3 4; [No title captured]; [No title captured]	26	6	7	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					736	741		10.1109/TPAMI.2008.197	http://dx.doi.org/10.1109/TPAMI.2008.197			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407WX	19229087				2022-12-18	WOS:000263396100012
J	Cortes, L; Amit, Y				Cortes, Leandro; Amit, Yali			Efficient annotation of vesicle dynamics in video microscopy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tracking; object detection; statistical object modeling; coarse-to-fine computation; multiple object configurations; fluorescence microscopy	TRACKING; DETECT	We describe an algorithm for the efficient annotation of events of interest in video microscopy. The specific application involves the detection and tracking of multiple possibly overlapping vesicles in total internal reflection fluorescent microscopy images. A statistical model for the dynamic image data of vesicle configurations allows us to properly weight various hypotheses online. The goal is to find the most likely trajectories given a sequence of images. The computational challenge is addressed by defining a sequence of coarse-to-fine tests, derived from the statistical model, to quickly eliminate most candidate positions at each time frame. The computational load of the tests is initially very low and gradually increases as the false positives become more difficult to eliminate. Only at the last step are state variables estimated from a complete time-dependent model. Processing time thus mainly depends on the number of vesicles in the image and not on image size.	[Cortes, Leandro] Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA; [Amit, Yali] Univ Chicago, Dept Stat, Chicago, IL 60637 USA	University of Chicago; University of Chicago	Cortes, L (corresponding author), Univ Chicago, Dept Comp Sci, 1100 E 58th St, Chicago, IL 60637 USA.	leandro@cs.uchicago.edu; amit@marx.uchicago.edu			Burroughs Wellcome Fund Interfaces [1001774]; NSF ITR [DMS-0219016]	Burroughs Wellcome Fund Interfaces(Burroughs Wellcome Fund); NSF ITR(National Science Foundation (NSF))	The authors are deeply grateful to Eric Schwartz of the Department of Neurobiology, Pharmacology, and Physiology at the University of Chicago, for introducing the problem, supplying the data, encouraging the project, and providing invaluable scientific input. L. Cortes is supported in part by Burroughs Wellcome Fund Interfaces 1001774 and NSF ITR DMS-0219016. Y. Amit is supported in part by NSF ITR DMS-0219016.	Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111; AMIT Y, 2007, INT J COMP VIS; Amit Y., 2002, 2D OBJECT DETECTION; Arias-Castro E, 2005, IEEE T INFORM THEORY, V51, P2402, DOI 10.1109/TIT.2005.850056; Arias-Castro E, 2006, ANN STAT, V34, P326, DOI 10.1214/009053605000000787; Blackman SS, 2004, IEEE AERO EL SYS MAG, V19, P5, DOI 10.1109/MAES.2004.1263228; Carter BC, 2005, PHYS BIOL, V2, P60, DOI 10.1088/1478-3967/2/1/008; Cheezum MK, 2001, BIOPHYS J, V81, P2378, DOI 10.1016/S0006-3495(01)75884-5; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; Johnston LA, 2002, IEEE T AERO ELEC SYS, V38, P228, DOI 10.1109/7.993242; Li CH, 2004, CELL RES, V14, P480, DOI 10.1038/sj.cr.7290251; Meijering E, 2006, IEEE SIGNAL PROC MAG, V23, P46, DOI 10.1109/MSP.2006.1628877; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; REID DB, 1979, IEEE T AUTOMATIC CON, V24, P6; Rice J, 1994, MATH STAT DATA ANAL; Santos A, 2000, APPL OPTICS, V39, P2948, DOI 10.1364/AO.39.002948; Sbalzarini IF, 2005, J STRUCT BIOL, V151, P182, DOI 10.1016/j.jsb.2005.06.002; Steyer JA, 2001, NAT REV MOL CELL BIO, V2, P268, DOI 10.1038/35067069; Sudhof TC, 2004, ANNU REV NEUROSCI, V27, P509, DOI 10.1146/annurev.neuro.26.041002.131412; Thomann D, 2003, J MICROSC-OXFORD, V211, P230, DOI 10.1046/j.1365-2818.2003.01223.x; THOMANN D, 2003, J MICROSCOPY, V208, P49; Tonissen SM, 1998, IEEE T AERO ELEC SYS, V34, P796, DOI 10.1109/7.705887; Viola P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P747	27	6	6	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					1998	2010		10.1109/TPAMI.2008.84	http://dx.doi.org/10.1109/TPAMI.2008.84			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787247	Green Submitted			2022-12-18	WOS:000259110000012
J	van Lieshout, MNM				van Lieshout, M. N. M.			Depth map calculation for a variable number of moving objects using Markov sequential object processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						depth calculation; Markov chain Monte Carlo; Markov sequential object process; object tracking; regularization; stochastic geometry	POINT; EXTRACTION; TRACKING	We advocate the use of Markov sequential object processes for tracking a variable number of moving objects through video frames with a view towards depth calculation. A regression model based on a sequential object process quantifies goodness of fit; regularization terms are incorporated to control within and between frame object interactions. We construct a Markov chain Monte Carlo method for finding the optimal tracks and associated depths and illustrate the approach on a synthetic data set as well as a sports sequence.	[van Lieshout, M. N. M.] Ctr Wiskunde & Informat, NL-1098 SJ Amsterdam, Netherlands; [van Lieshout, M. N. M.] Eindhoven Univ Technol, NL-1009 AB Amsterdam, Netherlands	Eindhoven University of Technology	van Lieshout, MNM (corresponding author), Ctr Wiskunde & Informat, Kruislaan 413, NL-1098 SJ Amsterdam, Netherlands.	colette@cwi.nl						BADDELEY A, 1992, P 11 INT ASS PATT RE, pB136; Baddeley A.J., 1993, J APPL STAT, V20, P231, DOI [10.1080/02664769300000065, DOI 10.1080/02664769300000065]; GEYER CJ, 1994, SCAND J STAT, V21, P359; GOODMAN IR, 1997, MATH DATA FUSION B, V39; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Hue C, 2002, IEEE T SIGNAL PROCES, V50, P309, DOI 10.1109/78.978386; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Lacoste C, 2005, IEEE T PATTERN ANAL, V27, P1568, DOI 10.1109/TPAMI.2005.206; Lund J., 1999, BAYESIAN ANAL SPATIA, V57; Mardia KV, 1997, IEEE T PATTERN ANAL, V19, P1035, DOI 10.1109/34.615452; Matheron G., 1975, RANDOM SETS INTEGRAL; Molina R., 1989, J APPL STAT, V16, P193, DOI [10.1080/02664768900000017, DOI 10.1080/02664768900000017]; RIPLEY BD, 1977, J LOND MATH SOC, V15, P188, DOI 10.1112/jlms/s2-15.1.188; RIPLEY BD, 1990, PHILOS T ROY SOC A, V332, P477, DOI 10.1098/rsta.1990.0127; Rue H, 1999, BIOMETRIKA, V86, P649, DOI 10.1093/biomet/86.3.649; Stoica R, 2004, INT J COMPUT VISION, V57, P121, DOI 10.1023/B:VISI.0000013086.45688.5d; Stone L., 1999, ARTECH HOUSE RADAR; van Lieshout M, 2006, P PRAG STOCH 2006, P215; VANLIESHOUT MNM, 2006, LECT NOTES MONOGRAPH, V48, P154; VIHOLA M, 2004, THESIS TAMPERE U TEC; [No title captured]; [No title captured]	26	6	7	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1308	1312		10.1109/TPAMI.2008.45	http://dx.doi.org/10.1109/TPAMI.2008.45			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550912				2022-12-18	WOS:000256294100016
J	Cooper, MC				Cooper, Martin C.			A rich discrete labeling scheme for line drawings of curved objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scene analysis; shape; line drawing analysis; line labeling; soft constraints	POLYHEDRAL SCENES; CONSTRAINTS; SHAPE	We present a discrete labeling scheme for line drawings of curved objects which can be seen as an information-rich extension of the classic line-labeling scheme in which lines are classified as convex, concave, occluding, or extremal. New labels are introduced to distinguish between curved and planar surface-patches, to identify orthogonal edges and to indicate gradient directions of planar surface-patches.	Univ Toulouse 3, Dept Comp Sci, IRIT, F-31062 Toulouse, France	Universite de Toulouse; Universite Toulouse III - Paul Sabatier	Cooper, MC (corresponding author), Univ Toulouse 3, Dept Comp Sci, IRIT, 118 Route Narbonne, F-31062 Toulouse, France.	cooper@irit.fr	Cooper, Martin/AAV-1705-2021; Cooper, Martin/AAE-8777-2020	Cooper, Martin/0000-0003-4853-053X; Cooper, Martin/0000-0003-4853-053X				CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; Cooper MC, 2007, INT J COMPUT VISION, V73, P195, DOI 10.1007/s11263-006-9783-7; COOPER MC, 1993, IMAGE VISION COMPUT, V11, P82, DOI 10.1016/0262-8856(93)90074-Q; Cooper MC, 1997, IMAGE VISION COMPUT, V15, P263, DOI 10.1016/S0262-8856(96)01135-3; Cooper MC, 2000, ARTIF INTELL, V119, P235, DOI 10.1016/S0004-3702(00)00008-4; Ding Y, 1998, COMPUT VIS IMAGE UND, V70, P197, DOI 10.1006/cviu.1997.0635; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KANATANI KI, 1986, IEEE T PATTERN ANAL, V8, P456, DOI 10.1109/TPAMI.1986.4767809; KIROUSIS LM, 1988, J COMPUT SYST SCI, V37, P14, DOI 10.1016/0022-0000(88)90043-8; Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X; Liu JZ, 2002, IEEE T PATTERN ANAL, V24, P1579, DOI 10.1109/TPAMI.2002.1114850; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; MARILL T, 1991, INT J COMPUT VISION, V6, P147, DOI 10.1007/BF00128154; Meseguer P, 2006, FOUND ARTIF INTELL, P281; PERKINS DN, 1972, PERCEPT PSYCHOPHYS, V12, P396, DOI 10.3758/BF03205849; Sugihara K., 1986, MACHINE INTERPRETATI; Syeda-Mahmood T, 1999, IEEE T PATTERN ANAL, V21, P737, DOI 10.1109/34.784287; TANG X., 2006, P 14 ANN ACM INT C M, P105; Varley P. A. C., 2001, International Journal of Shape Modeling, V7, P23, DOI 10.1142/S0218654301000035; Varley PAC, 2005, COMPUT AIDED DESIGN, V37, P1285, DOI 10.1016/j.cad.2005.01.002	21	6	8	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					741	745		10.1109/TPAMI.2007.70835	http://dx.doi.org/10.1109/TPAMI.2007.70835			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276978				2022-12-18	WOS:000253135600016
J	Iwata, K; Hayashi, A				Iwata, Kazunori; Hayashi, Akira			A redundancy-based measure of dissimilarity among probability distributions for hierarchical clustering criteria	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; mixture model; dissimilarity measure; information theory; Ward's method	PERFORMANCE; ALGORITHMS	We introduce novel dissimilarity into a probabilistic clustering task to properly measure dissimilarity among multiple clusters when each cluster is characterized by a subpopulation in the mixture model. This measure of dissimilarity is called redundancy-based dissimilarity among probability distributions. From aspects of both source coding and a statistical hypothesis test, we shed light on several of the theoretical reasons for the redundancy-based dissimilarity among probability distributions being a reasonable measure of dissimilarity among clusters. We also elucidate a principle in common for the measures of redundancy-based dissimilarity and Ward's method in terms of hierarchical clustering criteria. Moreover, we show several related theorems that are significant for clustering tasks. In the experiments, properties of the measure of redundancy-based dissimilarity are examined in comparison with several other measures.	Hiroshima City Univ, Fac Informat Sci, Hiroshima 7313194, Japan		Iwata, K (corresponding author), Hiroshima City Univ, Fac Informat Sci, Hiroshima 7313194, Japan.	kiwata@hiroshima-cu.ac.jp; akira@hiroshima-cu.ac.jp		Iwata, Kazunori/0000-0002-2638-7288				Anderberg M. R., 1973, PROBABILITY MATH STA, V19; Billingsley P., 1995, WILEY SERIES PROBABI, V3rd; Bishop, 1995, NEURAL NETWORKS PATT; Blake C., 1998, UCI REPOSITORY MACHI; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Csiszar I., 1997, INFORM THEORY CODING; DEMBO A, 1998, LARGE DEVIATION TECH, V38; DEVROYE L, 1996, PROBABILITY THEORY P, V31; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; ELLIS MM, 1912, MEM CARNEGIE MUS, V5, P1; Endres DM, 2003, IEEE T INFORM THEORY, V49, P1858, DOI 10.1109/TIT.2003.813506; Fraley C, 1998, SIAM J SCI COMPUT, V20, P270, DOI 10.1137/S1064827596311451; Fred ALN, 2003, IEEE T PATTERN ANAL, V25, P944, DOI 10.1109/TPAMI.2003.1217600; Gokcay E, 2002, IEEE T PATTERN ANAL, V24, P158, DOI 10.1109/34.982897; HAN TS, 2002, MATH INFORM CODING, V203; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Huang JZX, 2005, IEEE T PATTERN ANAL, V27, P657, DOI 10.1109/TPAMI.2005.95; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Liao TW, 2005, PATTERN RECOGN, V38, P1857, DOI 10.1016/j.patcog.2005.01.025; Maulik U, 2002, IEEE T PATTERN ANAL, V24, P1650, DOI 10.1109/TPAMI.2002.1114856; Meila M, 2001, MACH LEARN, V42, P9, DOI 10.1023/A:1007648401407; Osterreicher F, 1996, KYBERNETIKA, V32, P389; Prieto MS, 2003, IEEE T PATTERN ANAL, V25, P1265, DOI 10.1109/TPAMI.2003.1233900; Roberts SJ, 2001, IEEE T PATTERN ANAL, V23, P909, DOI 10.1109/34.946994; SANOV I. N., 1957, SELECT TRANSL MATH S, V1, P213; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Tipping ME, 1999, IEE CONF PUBL, P815, DOI 10.1049/cp:19991212; Topsoe F, 2000, IEEE T INFORM THEORY, V46, P1602, DOI 10.1109/18.850703; Veenman CJ, 2002, IEEE T PATTERN ANAL, V24, P1273, DOI 10.1109/TPAMI.2002.1033218; WARD JH, 1963, EDUC PSYCHOL MEAS, V23, P69, DOI 10.1177/001316446302300107; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Webb A.R., 2003, STAT PATTERN RECOGNI; Wei J, 2004, IEEE T PATTERN ANAL, V26, P311, DOI 10.1109/TPAMI.2004.1262315; Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141; Yang MS, 2004, IEEE T PATTERN ANAL, V26, P434, DOI 10.1109/TPAMI.2004.1265860; Yeung DS, 2002, IEEE T PATTERN ANAL, V24, P556, DOI 10.1109/34.993562; [No title captured]	38	6	6	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					76	88		10.1109/TPAMI.2007.1160	http://dx.doi.org/10.1109/TPAMI.2007.1160			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000326				2022-12-18	WOS:000250843500007
J	Han, F; Zhu, SC				Han, Feng; Zhu, Song-Chun			A two-level generative model for cloth representation and shape from shading	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape from shading; generate model; shading primitive; sketch graph		In this paper, we present a two-level generative model for representing the images and surface depth maps of drapery and clothes. The upper level consists of a number of folds which will generate the high contrast ( ridge) areas with a dictionary of shading primitives ( for 2D images) and fold primitives (for 3D depth maps). These primitives are represented in parametric forms and are learned in a supervised learning phase using 3D surfaces of clothes acquired through photometric stereo. The lower level consists of the remaining flat areas which fill between the folds with a smoothness prior ( Markov random field). We show that the classical ill-posed problem - shape from shading (SFS) can be much improved by this two-level model for its reduced dimensionality and incorporation of middle-level visual knowledge, i.e., the dictionary of primitives. Given an input image, we first infer the folds and compute a sketch graph using a sketch pursuit algorithm as in the primal sketch [ 10], [ 11]. The 3D folds are estimated by parameter fitting using the fold dictionary and they form the "skeleton" of the drapery/ cloth surfaces. Then, the lower level is computed by conventional SFS method using the fold areas as boundary conditions. The two levels interact at the final stage by optimizing a joint Bayesian posterior probability on the depth map. We show a number of experiments which demonstrate more robust results in comparison with state-of-the-art work. In a broader scope, our representation can be viewed as a two-level inhomogeneous MRF model which is applicable to general shape-from- X problems. Our study is an attempt to revisit Marr's idea [23] of computing the 2 1/2 D sketch from primal sketch. In a companion paper [ 2], we study shape from stereo based on a similar two-level generative sketch representation.	Univ Calif Los Angeles, Dept Comp Sci & Stat, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles	Han, F (corresponding author), Univ Calif Los Angeles, Dept Comp Sci & Stat, 8130 Math Sci Bldg,Box 951554, Los Angeles, CA 90095 USA.	hanf@cs.ucla.edu; sczhu@stat.ucla.edu						Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321; BARBU AB, 2005, P INT C COMP VIS; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; BHAT KS, 2003, P ACM SIGGRAPH EUR S, P37; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Crouzil A, 2003, IEEE T PATTERN ANAL, V25, P1416, DOI 10.1109/TPAMI.2003.1240116; Elder JH, 1999, INT J COMPUT VISION, V34, P97, DOI 10.1023/A:1008183703117; Guo CE, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1228, DOI 10.1109/ICCV.2003.1238631; GUO CE, 2005, 416 U CAL DEP STAT; Haddon J., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P415, DOI 10.1007/BFb0054756; Haddon J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P236, DOI 10.1109/ICCV.1998.710724; HARALICK RM, 1983, COMPUT VISION GRAPH, V22, P28, DOI 10.1016/0734-189X(83)90094-4; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; House D., 2000, CLOTH MODELING ANIMA; Huggins PS, 2001, PROC CVPR IEEE, P718; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; LEE CH, 1989, SHAPE SHADING, P323; LEE KM, 1993, IEEE T PATTERN ANAL, V15, P815, DOI 10.1109/34.236247; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Marr D., 1982, VISION; Nandy D, 2001, IEEE T IMAGE PROCESS, V10, P206, DOI 10.1109/83.902286; NICOLAIDES K, 1941, NATURAL WAY DRAW, P109; OLIENSIS J, 1991, INT J COMPUT VISION, V6, P75, DOI 10.1007/BF00128151; Shashua A, 1992, THESIS MIT; TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Wei GQ, 1997, IEEE T PATTERN ANAL, V19, P353, DOI 10.1109/34.588016; Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406; Zhang R., 1999, IEEE T PATTERN ANAL, V25, P1416; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983; Zhu SC, 2005, INT J COMPUT VISION, V62, P121, DOI 10.1007/s11263-005-4638-1; ZHU SC, 2000, P COMP VIS PATT REC	36	6	6	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1230	1243		10.1109/TPAMI.2007.1040	http://dx.doi.org/10.1109/TPAMI.2007.1040			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496380	Green Submitted			2022-12-18	WOS:000246395300010
J	Vik, T; Heitz, F; Charbonnier, P				Vik, Torbjorn; Heitz, Fabrice; Charbonnier, Pierre			Robust pose estimation and recognition using non-Gaussian modeling of appearance subspaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical image representation; object recognition; nonparametric statistics; robust regression; visual appearance; probabilistic PCA; mean shift; half-quadratic theory	MEAN SHIFT; OBJECTS	We present an original appearance model that generalizes the usual Gaussian visual subspace model to non-Gaussian and nonparametric distributions. It can be useful for the modeling and recognition of images under difficult conditions such as large occlusions and cluttered backgrounds. Inference under the model is efficiently solved using the mean shift algorithm.	Philips Res Europe, D-22335 Hamburg, Germany; CNRS, LSIIT, UMR 7005, F-67400 Illkirch Graffenstaden, France; Lab Reg Ponts & Chaussees, F-67035 Strasbourg, France	Philips; Philips Research; Centre National de la Recherche Scientifique (CNRS)	Vik, T (corresponding author), Philips Res Europe, Roentgenstr 24-26, D-22335 Hamburg, Germany.	torbjoern.vik@philips.com; heitz@lsiit.u-strasbg.fr; pierre.charbonnier@equipement.gouv.fr	Charbonnier, Pierre/H-4037-2016; HEITZ, Fabrice/R-4100-2017	Charbonnier, Pierre/0000-0002-9374-5647; HEITZ, Fabrice/0000-0002-3004-0957				Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dahyot R, 2004, PATTERN ANAL APPL, V7, P317, DOI 10.1007/s10044-004-0230-5; Dahyot R, 2000, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2000.855886; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; Jagmohan A, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1334461; MACKAY DJC, 1995, NUCL INSTRUM METH A, V354, P73, DOI 10.1016/0168-9002(94)00931-7; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; SINGH M, 2004, P EUR C COMP VIS, P508; SINGH M, 2004, P 2004 C COMP VIS PA, V11, P174; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VIK T, 2004, THESIS U LOU PAST; VIK T, 2003, P 2003 IEEE INT C IM	19	6	6	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					901	U2		10.1109/TPAMI.2007.1028	http://dx.doi.org/10.1109/TPAMI.2007.1028			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356209				2022-12-18	WOS:000244855700013
J	Mitra, S; Savvides, M; Brockwell, A				Mitra, Sinjini; Savvides, Marios; Brockwell, Anthony			Statistical performance evaluation of biometric authentication systems using random effects models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; face; authentication; performance evaluation; random effects model; watch-list	INFERENCE	As biometric authentication systems become more prevalent, it is becoming increasingly important to evaluate their performance. This paper introduces a novel statistical method of performance evaluation for these systems. Given a database of authentication results from an existing system, the method uses a hierarchical random effects model, along with Bayesian inference techniques yielding posterior predictive distributions, to predict performance in terms of error rates using various explanatory variables. By incorporating explanatory variables as well as random effects, the method allows for prediction of error rates when the authentication system is applied to potentially larger and/or different groups of subjects than those originally documented in the database. We also extend the model to allow for prediction of the probability of a false alarm on a "watch-list" as a function of the list size. We consider application of our methodology to three different face authentication systems: a filter-based system, a Gaussian Mixture Model (GMM)based system, and a system based on frequency domain representation of facial asymmetry.	Univ So Calif, Inst Informat Sci, Inst Sci Informat, Marina Del Rey, CA 90292 USA; Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA	University of Southern California; Carnegie Mellon University; Carnegie Mellon University	Mitra, S (corresponding author), Univ So Calif, Inst Informat Sci, Inst Sci Informat, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.	mitra@isi.edu; msavid@cs.cmu.edu; abrock@stat.cmu.edu						Bensmail H, 1997, STAT COMPUT, V7, P1, DOI 10.1023/A:1018510926151; Bolle R. M., 1999, P AUTOID 99, P9; Bolle RM, 2000, INT C PATT RECOG, P831, DOI 10.1109/ICPR.2000.906204; DAUGMAN D, 2000, 482 U CAMBR COMP LAB; Egan J.P., 1975, SIGNAL DETECTION THE; GELFAND AE, 1990, J AM STAT ASSOC, V85, P972, DOI 10.2307/2289594; Gelman A, 2013, BAYESIAN DATA ANAL, P16; Gelman A, 1992, STAT SCI, V7, P136, DOI 10.1214/ss/1177011136; Givens G, 2004, PROC CVPR IEEE, P381; GIVENS GH, 2003, P IEEE C COMP VIS PA; GIVENS GH, 2005, P IEEE C COMP VIS PA, P40; GOO SK, 2004, WASH POST       0820, pA1; Grother P, 2004, PROC CVPR IEEE, P68; HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747; Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611; Mclachlan G., 2000, WILEY SER PROB STAT; MITRA S, 2005, P INT C IM AN REC IC, P1065; MITRA S, 2005, P 4 IEEE WORKSH AUT; *NIST, 2002, FAC REC VEND TEST FR; Oppenheim A.V., 1989, DISCRETE TIME SIGNAL; PRABHAKAR S, 2003, SECURITY PRIVACY MAR, P33; Robert C.P., 1996, MARKOV CHAIN MONTE C, P441; Savvides M, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P45, DOI 10.1109/AVSS.2003.1217900; Savvides M., 2002, P 3 IEEE AUT ID ADV, P56, DOI DOI 10.1109/ICISIP.2004.1287684; Schuckers ME., 2003, INT J IMAGE GR, V3, P523, DOI [10.1142/S0219467803001147, DOI 10.1142/S0219467803001147]; Shen WC, 1997, P IEEE, V85, P1464, DOI 10.1109/5.628719; Sim T., 2002, P 5 INT C AUT FAC GE; Turk M., 1991, P IEEE C COMP VIS PA; WAYMAN J, 1997, CTST97 P, P477; Weisberg S., 1985, APPL LINEAR REGRESSI	30	6	6	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					517	530		10.1109/TPAMI.2007.1000	http://dx.doi.org/10.1109/TPAMI.2007.1000			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299211				2022-12-18	WOS:000244855600002
J	Lin, ZC; Shum, HY				Lin, ZC; Shum, HY			Response to the comments on "Fundamental limits of reconstruction-based superresolution algorithms under local translation"	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material						superresolution; reconstruction-based algorithms; perturbation theory		Wang and Feng [1] pointed out that the deduction in [2] overlooked the validity of the perturbation theorem used in [2]. In this paper, we show that, when the perturbation theorem is invalid, the probability of successful superresolution is very low. Therefore, we only have to derive the limits under the condition that validates the perturbation theorem, as done in [2].	Microsoft Res Asia, Beijing 100080, Peoples R China	Microsoft; Microsoft Research Asia	Lin, ZC (corresponding author), Microsoft Res Asia, 5th Floor,Sigma Bldg,Zhichun Rd 49, Beijing 100080, Peoples R China.	zhoulin@microsoft.com; hshum@microsoft.com						Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081; Wang LW, 2006, IEEE T PATTERN ANAL, V28, P846, DOI 10.1109/TPAMI.2006.91	4	6	7	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					847	847		10.1109/TPAMI.2006.105	http://dx.doi.org/10.1109/TPAMI.2006.105			1	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO					2022-12-18	WOS:000235885700018
J	Ruiz-Correa, S; Shapiro, LG; Meila, M; Berson, G; Cunningham, ML; Sze, RW				Ruiz-Correa, S; Shapiro, LG; Meila, M; Berson, G; Cunningham, ML; Sze, RW			Symbolic signatures for deformable shapes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						three-dimensional object recognition and classification; deformable shapes; range data; numeric and symbolic signatures; Mercer kernel; scene analysis; craniosynostosis; craniofacial malformations	SUPPORT	Recognizing classes of objects from their shape is an unsolved problem in machine vision that entails the ability of a computer system to represent and generalize complex geometrical information on the basis of a finite amount of prior data. A practical approach to this problem is particularly difficult to implement, not only because the shape variability of relevant object classes is generally large, but also because standard sensing devices used to capture the real world only provide a partial view of a scene, so there is partial information pertaining to the objects of interest. In this work, we develop an algorithmic framework for recognizing classes of deformable shapes from range data. The basic idea of our component-based approach is to generalize existing surface representations that have proven effective in recognizing specific 3D objects to the problem of object classes using our newly introduced symbolic-signature representation that is robust to deformations, as opposed to a numeric representation that is often tied to a specific shape. Based on this approach, we present a system that is capable of recognizing and classifying a variety of object shape classes from range data. We demonstrate our system in a series of large-scale experiments that were motivated by specific applications in scene analysis and medical diagnosis.	Univ Washington, Dept Radiol, Seattle, WA 98105 USA; Childrens Hosp & Reg Med Ctr, Seattle, WA 98105 USA; Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98105 USA; Univ Washington, Dept Elect Engn, Seattle, WA 98105 USA; Univ Washington, Dept Stat, Seattle, WA 98105 USA; Univ Washington, Sch Med, Childrens Craniofacial Ctr, Seattle, WA 98195 USA; Univ Washington, Sch Med, Pediat Div Genet & Dev Med, Seattle, WA 98195 USA	University of Washington; University of Washington Seattle; Seattle Children's Hospital; University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle	Ruiz-Correa, S (corresponding author), Univ Washington, Dept Radiol, 4800 Sand Point Way NW R-5438, Seattle, WA 98105 USA.	sruiz@u.washington.edu; shapiro@cs.washington.edu; mmp@stat.washington.edu; gberson@u.washington.edu; mcunning@u.washington.edu; raymond.sze@seattlechildrens.org		Ruiz-Correa, Salvador/0000-0002-2918-6780	NIDCR NIH HHS [R01-DE13813] Funding Source: Medline; NATIONAL INSTITUTE OF DENTAL & CRANIOFACIAL RESEARCH [R01DE013813] Funding Source: NIH RePORTER	NIDCR NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Dental & Craniofacial Research (NIDCR)); NATIONAL INSTITUTE OF DENTAL & CRANIOFACIAL RESEARCH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Dental & Craniofacial Research (NIDCR))		Andresen P, 2000, IEEE T MED IMAGING, V19, P1053, DOI 10.1109/42.896780; [Anonymous], 2002, LEARNING KERNELS; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; BOOKSTEIN FL, 1997, COMPUTER VISION IMAG, V66, P99; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CAPELL S, 2002, P 2002 ACM SIGGRAPH, V2, P42; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Davies RH, 2002, IEEE T MED IMAGING, V21, P525, DOI 10.1109/TMI.2002.1009388; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Efron Bradley, 1982, JACKKNIFE BOOTSTRAP; FROSTERISKENIUS UG, 1989, HDB NORMAL PHYS MEAS; Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279; GOLLAND P, 2001, ADV NEURAL INFORM PR, P745; GOLLAND P, 2001, THESIS MIT; HEBRICH R, 2001, J MACHINE LEARNING R, P245; HEISELE B, 2001, ADV NEURAL INFORM PR, V2, P1239; JAAKKOLA T, 1999, ADV NEURAL INFORM PR, P640; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; JOHNSON AE, 1998, GRAPHICS MODELING CO; JONES KL, 1999, SMITHS RECOGNIZABLE; Kazhdan M, 2004, ALGORITHMICA, V38, P201, DOI 10.1007/s00453-003-1050-5; LALE SR, 2001, INVARIANT APPROACH S; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; Martin J, 1998, IEEE T PATTERN ANAL, V20, P97, DOI 10.1109/34.659928; Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386; Rueckert D, 2003, IEEE T MED IMAGING, V22, P1014, DOI 10.1109/TMI.2003.815865; Ruiz-Correa S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1126; Ruiz-Correa S, 2001, PROC CVPR IEEE, P769; RUIZCORREA S, 2004, ADV NEURAL INFORM PR, V16; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Shelton CR, 2000, INT J COMPUT VISION, V38, P75, DOI 10.1023/A:1008170818506; TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840; Vapnik V.N, 1998, STAT LEARNING THEORY	34	6	6	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2006	28	1					75	90		10.1109/TPAMI.2006.23	http://dx.doi.org/10.1109/TPAMI.2006.23			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	982OR	16402621	Green Submitted			2022-12-18	WOS:000233172000007
J	Basu, M; Bunke, H; Del Bimbo, A				Basu, M; Bunke, H; Del Bimbo, A			Guest editors' introduction to the special section on syntactic and structural pattern recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material							DISTANCE		Natl Sci Fdn, CISE, CCF, Arlington, VA 22230 USA; Univ Bern, Inst Informat & Appl Math, CH-3012 Bern, Switzerland; Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy	National Science Foundation (NSF); NSF - Directorate for Computer & Information Science & Engineering (CISE); University of Bern; University of Florence	Basu, M (corresponding author), Natl Sci Fdn, CISE, CCF, 4201 Wilson Blvd, Arlington, VA 22230 USA.	mbasu@nsf.gov; bunke@iam.unibe.ch; delbimbo@dsi.unifi.it		DEL BIMBO, ALBERTO/0000-0002-1052-8322				Durbin R., 2000, BIOL SEQUENCE ANAL; FU KS, 1982, SYNTACTIC PATTERN RE; LU SY, 1979, IEEE T PATTERN ANAL, V1, P219, DOI 10.1109/TPAMI.1979.6786615; Manning CD, 1999, FDN STAT NATURAL LAN; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811	6	6	6	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1009	1012		10.1109/TPAMI.2005.141	http://dx.doi.org/10.1109/TPAMI.2005.141			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013749				2022-12-18	WOS:000229024300001
J	Wang, BC; Omatu, S; Abe, T				Wang, BC; Omatu, S; Abe, T			Identification of the defective transmission devices using the wavelet transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automatic identification; feature extraction; wavelet transform; LVQ; GA		In this paper, a system is described that uses the wavelet transform to automatically identify the particular failure mode of a known defective transmission device. The problem of identifying a particular failure mode within a costly failed assembly is of benefit in practical applications. In this system, external acoustic sensors, instead of intrusive vibrometers, are used to record the acoustic data of the operating transmission device. A skilled factory worker, who is unfamiliar with statistical classification, helps to determine the feature vector of the particular failure mode in the feature extraction process. In the automatic identification part, an improved learning vector quantization (LVQ) method with normalizing the inputting feature vectors is proposed to compensate for variations in practical data. Some acoustic data, which are collected from the manufacturing site, are utilized to test the effectiveness of the described identification system. The experimental results show that this system can identify the particular failure mode of a defective transmission device and find out the causes of failure successfully.	Osaka Prefecture Univ, Grad Sch Engn, Div Comp & Syst Sci, Osaka 599853, Japan; FdnOsaka Sci & Technol Ctr, Nishi Ku, Osaka 5500004, Japan	Osaka Metropolitan University	Wang, BC (corresponding author), Osaka Prefecture Univ, Grad Sch Engn, Div Comp & Syst Sci, Osaka 599853, Japan.	wangb@sig.cs.osakafu-u.ac.jp; omatu@cs.osakafu-u.ac.jp; abe@rsp.ostec.or.jp						Boggess A., 2002, 1 COURSE WAVELETS FO, V2nd; CHOY FK, 1994, TM106623 NASA; COHEN L, 1989, P IEEE, V77, P941, DOI 10.1109/5.30749; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; FURUI S, 1989, DIGITAL SPEECH PROCE; Gersho A., 1991, VECTOR QUANTIZATION; Jain A., 2000, IEEE T PATTERN ANAL, V22; Kohonen T, 2001, SELF ORG MAPS, Vthird, DOI DOI 10.1007/978-3-642-56927-2; LI W, 2000, P INT C COMP EXP MET; Teranishi M., 1997, Transactions of the Institute of Electrical Engineers of Japan, Part C, V117-C, P1677; WANG B, 2003, J SIGNAL PROCESSING, V7, P61; Wang WJ, 1996, J SOUND VIB, V192, P927, DOI 10.1006/jsvi.1996.0226; YAMAGUCHI M, 1991, B JAPAN SOC IND APPL, V1, P202; ZAKRAJSEK JJ, 1994, TM106746 NASA	14	6	6	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					919	928		10.1109/TPAMI.2005.121	http://dx.doi.org/10.1109/TPAMI.2005.121			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943423				2022-12-18	WOS:000228334700007
J	Sminchisescu, C; Metaxas, D; Dickinson, S				Sminchisescu, C; Metaxas, D; Dickinson, S			Incremental model-based estimation using geometric constraints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape recovery; object tracking; parametric models; geometric constraints; bundle adjustment; optimization	RECOVERY; MOTION; SHAPE	We present a model-based framework for incremental, adaptive object shape estimation and tracking in monocular image sequences. Parametric structure and motion estimation methods usually assume a fixed class of shape representation (splines, deformable superquadrics, etc.) that is initialized prior to tracking. Since the model shape coverage is fixed a priori, the incremental recovery of structure is decoupled from tracking, thereby limiting both processes in their scope and robustness. In this work, we describe a model-based framework that supports the automatic detection and integration of low-level geometric primitives ( lines) incrementally. Such primitives are not explicitly captured in the initial model, but are moving consistently with its image motion. The consistency tests used to identify new structure are based on trinocular constraints between geometric primitives. The method allows not only an increase in the model scope, but also improves tracking accuracy by including the newly recovered features in its state estimation. The formulation is a step toward automatic model building, since it allows both weaker assumptions on the availability of a prior shape representation and on the number of features that would otherwise be necessary for entirely bottom-up reconstruction. We demonstrate the proposed approach on two separate image-based tracking domains, each involving complex 3D object structure and motion.	Univ Toronto, Dept Comp Sci, Artificial Intelligence Lab, Toronto, ON M5S 3G4, Canada; Rutgers State Univ, Div Comp & Informat Sci, Piscataway, NJ 08854 USA	University of Toronto; Rutgers State University New Brunswick	Sminchisescu, C (corresponding author), Univ Toronto, Dept Comp Sci, Artificial Intelligence Lab, 6 Kings Coll Rd,Pratt Bldg,Rm 276, Toronto, ON M5S 3G4, Canada.	crismin@cs.toronto.edu; dnm@cs.rutgers.edu; sven@cs.toronto.edu						ARMSTRONG M, 1995, P AS C COMP VIS; AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; BREGLER C, 2000, P IEEE INT C COMP VI; CHAM T, 1999, IEEE INT C COMP VIS, V2, P239; CHAN M, 1994, INT C PATT RECOG, P326, DOI 10.1109/ICPR.1994.576289; CLARKE J, 1996, P 7 BRIT MACH VIS C; CROWLEY J, 1992, INT J COMPUTER VISIO; DeCarlo D, 1996, IEEE T PATTERN ANAL, V18, P443, DOI 10.1109/34.491626; DECARLO D, 1999, P IEEE INT C COMP VI; Dickinson S., 1994, INT J COMPUTER VISIO; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; Dickinson SJ, 1997, INT J PATTERN RECOGN, V11, P115, DOI 10.1142/S0218001497000068; DRUMMOND T, 2000, P EUR C COMP VIS; DUBE D, 1990, P EUR C COMP VIS, P292; Fletcher R, 1987, PRACTICAL METHODS OP, V1; FUA P, 1996, COMPUTER VISION IMAG; HARTLEY R, 1997, INT J COMPUTER VISIO; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Heap T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P344, DOI 10.1109/ICCV.1998.710741; HORN KB, 1990, INT J COMPUTER VISIO; Huang T. S., 1994, P IEEE; KANANTANI K, 1996, STAT OPTIMIZATION GE; KESELMAN Y, 2001, P IEEE INT C COMP VI; Lowe D., 1987, ARTIFICIAL INTELLIGE, V31; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; McReynolds DP, 1996, IEEE T PATTERN ANAL, V18, P1174, DOI 10.1109/34.546255; MITICHE A, 1986, P IEEE WORKSH MOT; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; SAMARAS D, 1998, P IEEE INT C COMP VI; SEITZ S, 1998, P DARPA IM UND WORKS; SHASHUA A, 1995, IEEE T PATTERN ANAL, V17, P779, DOI 10.1109/34.400567; Sminchisescu C, 2003, INT J ROBOT RES, V22, P371, DOI 10.1177/0278364903022006003; SMINCHISESCU C, 2005, INT J COMPUTER VISIO, V61; SMINCHISESCU C, 2002, THESIS INRIA; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; SPESTAKIS M, 1991, INT J COMPUTER VISIO; SZELISKI R, 1994, RECOVERY 3D SHAPE MO; TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; Terzopoulos D., 1988, ARTIFICIAL INTELLIGE, V36; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Triggs B., 2000, VISION ALGORITHMS TH; ULLMAN S, 1984, PERCEPTION, V13, P255, DOI 10.1068/p130255; VIEVILLE T, 1990, P IEEE INT C COMP VI; YEN B, 1983, ASI NATO SERIES	46	6	6	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					727	738		10.1109/TPAMI.2005.104	http://dx.doi.org/10.1109/TPAMI.2005.104			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875794	Green Submitted			2022-12-18	WOS:000227569300006
J	Park, JM				Park, JM			Convergence and application of online active sampling using orthogonal pillar vectors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active learning; machine learning; pattern classification		The analysis of convergence and its application is shown for the Active Sampling-at-the-Boundary method applied to multidimensional space using orthogonal pillar vectors. Active learning method facilitates identifying an optimal decision boundary for pattern classification in machine learning. The result of this method is compared with the standard active learning method that uses random sampling on the decision boundary hyperplane. The comparison is done through simulation and application to the real-world data from the UCI benchmark data set. The boundary is modeled as a nonseparable linear decision hyperplane in multidimensional space with a stochastic oracle.	San Diego State Univ, Dept Elect & Comp Engn, San Diego, CA 92182 USA	California State University System; San Diego State University	Park, JM (corresponding author), San Diego State Univ, Dept Elect & Comp Engn, 5500 Campanile Dr, San Diego, CA 92182 USA.	jong-min@engineering.sdsu.edu						Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Campbell C., 2000, P 17 IN C MACH LAM S, P111; COHN D, 1990, ADV NEURAL INFORMATI, V2; Cohn D. A., 1995, Advances in Neural Information Processing Systems 7, P705; COHN DA, 1994, ADV NEURAL INFORMATI, V6; Federov V.V., 1972, THEORY OPTIMAL EXPT; Fukumizu K, 1996, ADV NEUR IN, V8, P295; HWANG JN, 1991, IEEE T NEURAL NETWOR, V2, P131, DOI 10.1109/72.80299; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; KABASHIMA Y, 1993, P INT JOINT C NEUR N, V2, P1637; Karlin S., 1975, 1 COURSE STOCHASTIC; KINZEL W, 1990, EUROPHYS LETT, V13, P473, DOI 10.1209/0295-5075/13/5/016; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; Murphy P., 1994, UCI REPOSITORY MACHI; PARK JM, 2002, INT JOINT C NEUR NET; PARK JM, 2002, IEEE INT C FUZZ SYST; PARK JM, 1993, IEEE SIGNAL PROC NOV; PLUTOWSKI M, 1990, CS91180; Schohn G., 2000, P INT C MACH LEARN, P839; Sollich P, 1996, PHYS REV E, V53, pR2060, DOI 10.1103/PhysRevE.53.R2060; Tong S., 2000, P 17 INT C MACH LEAR; Wang H, 1999, IEEE T PATTERN ANAL, V21, P271, DOI 10.1109/34.754624; WARMUTH M, 2002, ADV NEURAL INFORMATI, V14; WATKIN TLH, 1992, J PHYS A-MATH GEN, V25, P113, DOI 10.1088/0305-4470/25/1/016	24	6	6	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1197	1207		10.1109/TPAMI.2004.61	http://dx.doi.org/10.1109/TPAMI.2004.61			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742894				2022-12-18	WOS:000222605100008
J	Paget, R				Paget, R			Strong Markov random field model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov processes; contingency table analysis; nonparametric statistics; texture; model development	GIBBS	The strong Markov random field (strong-MRF) model is a submodel of the more general MRF-Gibbs model. The strong-MRF model defines a system whose field is Markovian with respect to a defined neighborhood, and all subneighborhoods are also Markovian. A checkerboard pattern is a perfect example of a strong Markovian system. Although the strong Markovian system requires a more stringent assumption about the field, it does have some very nice mathematical properties. One mathematical property is the ability to define the strong-MRF model with respect to its marginal distributions over the cliques. Also a direct equivalence to the Analysis-of-Variance (ANOVA) log-linear construction can be proven. From this proof, the general ANOVA log-linear construction formula is acquired.	ETH Zentrum, Comp Vis Grp, CH-8092 Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich	Paget, R (corresponding author), ETH Zentrum, Comp Vis Grp, Gloriastr 35, CH-8092 Zurich, Switzerland.	rpaget@vision.ee.ethz.ch						Ashikhmin M., 2001, P 2001 S INT 3D GRAP, P217, DOI DOI 10.1145/364338.364405; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Bishop YM., 2007, DISCRETE MULTIVARIAT; Duda R.O., 1973, J ROYAL STAT SOC SER; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; FIENBERG SE, 1981, ANAL CROSS CLASSIFIE; GEMAN D, 1990, LECT NOTES MATH, V1427, P113; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gimelfarb GL, 1996, IEEE T PATTERN ANAL, V18, P1110, DOI 10.1109/34.544081; Grimmett G. R, 1973, B LOND MATH SOC, V5, P81, DOI DOI 10.1112/BLMS/5.1.81; HARRISON P, 2001, P 9 INT C CENT EUR C; MOUSSOUR.J, 1974, J STAT PHYS, V10, P11, DOI 10.1007/BF01011714; Paget R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P584, DOI 10.1109/ICIP.2000.899520; Paget R, 1998, IEEE T IMAGE PROCESS, V7, P925, DOI 10.1109/83.679446; PAGET R, 2000, P INT C PATT REC SEP, V3, P939; PAGET R, 2002, TEXT SYNTH AN; PAGET R, 1999, THESIS U QUEENSLAND; Rota G.-C., 1964, Z WAHRSCH VERW GEBIE, V2, P340, DOI DOI 10.1007/BF00531932; SEYMOUR L, 1993, THESIS U N CAROLINA; SPITZER F, 1971, AM MATH MON, V78, P142, DOI 10.2307/2317621; *VIS MOD GROUP, VIST TEXT; Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009; Zhu SC, 1996, PROC CVPR IEEE, P686, DOI 10.1109/CVPR.1996.517147	23	6	6	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					408	413		10.1109/TPAMI.2004.1262338	http://dx.doi.org/10.1109/TPAMI.2004.1262338			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376887				2022-12-18	WOS:000188949400011
J	Keren, D				Keren, D			Topologically faithful fitting of simple closed curves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						implicit fitting; topologically faithful fitting; Jordan-Schoenflies theorem	CONIC SECTIONS; IMPLICIT; OBJECTS; RECOGNITION; POLYNOMIALS; SURFACES	Implicit representations of curves have certain advantages over explicit representation, one of them being the ability to determine with ease whether a point is inside or outside the curve (inside-outside functions). However, save for some special cases, it is not known how to construct implicit representations which are guaranteed to preserve the curve's topology. As a result, points may be erroneously classified with respect to the curve. The paper offers to overcome this problem by using a representation which is guaranteed to yield the correct topology of a simple closed curve by using homeomorphic mappings of the plane to itself. If such a map carries the curve onto the unit circle, then a point is inside the curve it and only if its image is inside the unit circle.	Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel	University of Haifa	Keren, D (corresponding author), Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel.	dkeren@cs.haifa.ac.il						BAJAJ C, 1993, ACM T GRAPHIC, V12, P327, DOI 10.1145/159730.159734; Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; Forsyth D. A., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P476, DOI 10.1109/ICCV.1993.378177; GOTSMAN C, 1998, P INT J SHAP MOD, P111; Keren D, 1999, IEEE T PATTERN ANAL, V21, P31, DOI 10.1109/34.745731; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P1143, DOI 10.1109/34.334397; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; Lei ZB, 1998, IEEE T PATTERN ANAL, V20, P212, DOI 10.1109/34.659942; MURAKI S, 1991, COMP GRAPH, V25, P227, DOI 10.1145/127719.122743; PRATT V, 1987, ACM SIGGRAPH, V21, P145; Press WH., 1980, NUMERICAL RECIPES FO; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; Subrahmonia J, 1996, IEEE T PATTERN ANAL, V18, P505, DOI 10.1109/34.494640; SULLIVAN S, 1994, IEEE T PATTERN ANAL, V16, P1183, DOI 10.1109/34.387489; Tasdizen T, 2000, IEEE T IMAGE PROCESS, V9, P405, DOI 10.1109/83.826778; TAUBIN G, 1994, IEEE T PATTERN ANAL, V16, P287, DOI 10.1109/34.276128; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; THOMASSEN C, 1992, AM MATH MON, V99, P116, DOI 10.2307/2324180; Unel M, 1999, INT J PATTERN RECOGN, V13, P1137, DOI 10.1142/S0218001499000641	22	6	6	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2004	26	1					118	123		10.1109/TPAMI.2004.1261095	http://dx.doi.org/10.1109/TPAMI.2004.1261095			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	752LF	15382691	Green Submitted			2022-12-18	WOS:000187161400010
J	Binford, TO; Levitt, TS				Binford, TO; Levitt, TS			Evidential reasoning for object recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						evidential reasoning; object recognition; Bayesian inference; Bayesian networks; computer vision systems; utility-based control	HOMOGENEOUS GENERALIZED CYLINDERS; INVARIANT PROPERTIES	The authors present a framework to guide development of evidential reasoning in object recognition systems. Principles of evidential reasoning processes for open-world object recognition are proposed and applied to build evidential reasoning capabilities. The principles summarize research and findings by the authors up through the mid-1990s, including seminal results in object-centered computer vision, figure-ground discrimination, and the application of hierarchical Bayesian inference, Bayesian networks, and decision graphs to evidential reasoning for object recognition.	Read Ink Corp, Cupertino, CA 95014 USA; Informat Extract & Transport Inc, Arlington, VA 22209 USA		Binford, TO (corresponding author), Read Ink Corp, 16012 Flintlock Rd, Cupertino, CA 95014 USA.	tob@read-ink.com; tlevitt@iet.com						AGOSTA JM, 1990, P C UNC ART INT, P397; ARNOLD G, 1998, P DARPA IM UND WORKS; ARNOLD RD, 1980, P SPIE, V238; Bernardo J. M., 1994, BAYESIAN THEORY; BINFORD TO, 1971, P IEEE C SYST CONTR; BINFORD TO, 1981, INT J ARTIFICIAL AUG; BINFORD TO, 1987, P UNC ART INT; BINFORD TO, 1994, P DARPA IM UND WORKS; BINFORD TO, 1987, P INT S ROB RES; BINFORD TO, 1993, P DARPA IM UND WORKS; BURNS JB, 1992, ARTIF INT, P120; CANNY JF, 1983, 720 MIT; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; DEAN T, 1989, IEEE T SYST MAN CYB, V19, P574, DOI 10.1109/21.31063; HEALEY G, 1988, P DARPA IM UND WORKS; HEALEY G, 1987, P DARPA IM UND WORKS; Horvitz E., 1991, P 7 C UNC ART INT, P151; Howard R.A., 1984, READINGS PRINCIPLES, V2; JENSEN VF, 2001, BAYESIAN NETWORKS DE; Kanazawa K., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P346; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LEVITT TS, 1995, INT J HUMAN COMPUTER; LEVITT TS, 1990, P 4 UNC ART INT, P407; LEVITT TS, 1990, P 5 UNC ART INT; LI ZY, 1994, INT J APPROX REASON, V11, P55, DOI 10.1016/0888-613X(94)90019-1; MANN WB, 1992, P DARPA IM UND WORKS, P793; MANN WB, 1993, P DARPA IM UND WORKS, P633; Morgenstern O., 1953, THEORY GAMES EC BEHA; MUNDY JL, 1991, GEOMETRIC INVARIANCE; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; PONCE J, 1990, INT J COMPUT VISION, V4, P79, DOI 10.1007/BF00137444; RIMEY RD, 1994, INT J COMPUT VISION, V12, P173, DOI 10.1007/BF01421202; SATO H, 1993, CVGIP-IMAG UNDERSTAN, V57, P346, DOI 10.1006/ciun.1993.1023; SATO H, 1992, P IMAGE UNDERSTANDIN, P379; SATO H, 1992, P DARPA IM UND WORKS, P779; TATMAN JA, 1990, IEEE T SYST MAN CYB, V20, P365, DOI 10.1109/21.52548; Urbach P., 1993, SCI REASONING BAYESI, V2; Viola Paul, 2001, PROC CVPR IEEE; Wang BH, 1996, IMAGE UNDERSTANDING WORKSHOP, 1996 PROCEEDINGS, VOLS I AND II, P913; WANG BH, 1997, P DARPA IM UND WORKS, P513; WANG S, 1993, P ARPA IM UND WORKSH, P1063; WANG SJ, 1994, P DARPA IM UND WORKS, P1443; WANG SJ, 1994, P DARPA IM UND WORKS, P1589; WANG SJ, 1995, P DARPA IM UND WORKS; Xiang YP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P688; Zerroug M, 1996, IEEE T PATTERN ANAL, V18, P237, DOI 10.1109/34.485553; [No title captured]	51	6	8	5	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2003	25	7					837	851		10.1109/TPAMI.2003.1206513	http://dx.doi.org/10.1109/TPAMI.2003.1206513			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	692NN					2022-12-18	WOS:000183667300006
J	Freedman, D				Freedman, D			Effective tracking through tree-search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								A new contour tracking algorithm is presented. Tracking is posed as a matching problem between curves constructed out of edges in the image, and some shape space describing the class of objects of interest. The main contributions of the paper are to present an algorithm which solves this problem accurately and efficiently, in a provable manner. In particular, the algorithm's efficiency derives from a novel tree-search algorithm through the shape space, which allows for much of the shape space to be explored with very little effort. This latter property makes the algorithm effective in highly cluttered scenes, as is demonstrated in an experimental comparison with a condensation tracker.	Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Freedman, D (corresponding author), Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.	freedman@cs.rpi.edu						Akgul Y. S., 1999, P 2 INT C SCAL SPAC, P410; Arsenio A., 1997, Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97 (Cat. No.97CH36108), P1342, DOI 10.1109/IROS.1997.656508; AYACHE N, 1992, ACTIVE VISION, P285; BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1; BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Boothby W., 1986, INTRO DIFFERENTIABLE; BREGLER C, 1994, INT CONF ACOUST SPEE, P669, DOI 10.1109/ICASSP.1994.389567; BROCKETT R, 1994, IEEE DECIS CONTR P, P3247, DOI 10.1109/CDC.1994.411640; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Chan MT, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P65, DOI 10.1109/MMSP.1998.738914; DALTON B, 1995, P NATO ASI C SPEECHR; DONG J, 1999, ELECTRON LETT, V135, P1070; Girin L, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P523, DOI 10.1109/MMSP.1998.739034; GIRIN L, 1997, P 5 EUR C SPEECH COM, P2555; Hill A., 1993, P 4 BRIT MACH VIS C, P339, DOI DOI 10.5244/C.7.34; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; KASS M, 1987, P 1 IEEE INT C COMP; Kaucic R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P370, DOI 10.1109/ICCV.1998.710745; Kaucic R., 1996, P EUR C COMP VIS, P376; Koller D., 1994, Proceedings of the Intelligent Vehicles '94 Symposium (Cat. No.94TH8011), P201, DOI 10.1109/IVS.1994.639503; Lievin M, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P691, DOI 10.1109/MMCS.1999.779283; LIPSON P, 1990, P 1 EUR C COMP VIS; Luettin J, 1996, INT CONF ACOUST SPEE, P817, DOI 10.1109/ICASSP.1996.543246; McKenna S, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P271, DOI 10.1109/AFGR.1996.557276; Mignotte M., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P225, DOI 10.1109/CVPR.1999.786943; Munkres J.R., 1975, TOPOLOGY 1 COURSE; RAO BSY, 1993, INT J ROBOT RES, V12, P20, DOI 10.1177/027836499301200102; Sanchiz JM, 1998, P SOC PHOTO-OPT INS, V3364, P287, DOI 10.1117/12.317482; Schwartz I, 1998, P SOC PHOTO-OPT INS, V3364, P328, DOI 10.1117/12.317489; SULLIVAN GD, 1992, PHILOS T ROY SOC B, V337, P361, DOI 10.1098/rstb.1992.0114; Thomanek F., 1994, Proceedings of the Intelligent Vehicles '94 Symposium (Cat. No.94TH8011), P231, DOI 10.1109/IVS.1994.639510; XU G, 1993, P 4 IEEE INT C COMP; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169	36	6	6	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2003	25	5					604	615		10.1109/TPAMI.2003.1195994	http://dx.doi.org/10.1109/TPAMI.2003.1195994			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	669FY					2022-12-18	WOS:000182342300006
J	Cheng, YC; Liu, YS				Cheng, YC; Liu, YS			Polling an image for circles by random lines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						random sampling strategy; poll size determination; circle detection; RANSAC; Hough transform	HOUGH TRANSFORM; CURVE DETECTION	A new random sampling strategy, designed for retrieving subsets consisting of two edge pixels from an input image, is proposed as the sampling process for RANSAC circle detection using coaxal transform. The proposed strategy is shown to have the following advantages over the conventional random sampling strategy. First, a poll size can be planned in a principled manner. Second, once a poll size is set, the probability that a circle is missed by the sampling process is kept relatively constant regardless of noise. Third, the actual number of subsets taken is automatically adjusted for different image complexities. Experimental results in agreement with the claimed advantages are presented.	Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	National Taipei University of Technology	Cheng, YC (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.	yccheng@ntut.edu.tw; ysliu@ntut.edu.tw						BERGEN JR, 1991, J ALGORITHM, V12, P639, DOI 10.1016/0196-6774(91)90037-Y; CHENG YC, 1995, PATTERN RECOGN, V28, P663, DOI 10.1016/0031-3203(94)00138-C; CHENG YC, 2000, P 4 AS C COMP VIS AC, V1, P336; CHENG YC, 1994, P IEEE INT S SPEECH, P515; DUDA RO, 1972, COMMUN ACM, V15, P1; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Jain R., 1995, MACHINE VISION; KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E; LEAVERS VF, 1992, CVGIP-IMAG UNDERSTAN, V56, P381, DOI 10.1016/1049-9660(92)90049-9; Olson CF, 1999, COMPUT VIS IMAGE UND, V73, P329, DOI 10.1006/cviu.1998.0728; ROTH G, 1993, CVGIP-IMAG UNDERSTAN, V58, P1, DOI 10.1006/ciun.1993.1028; XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z; YLAJAASKI A, 1994, IEEE T PATTERN ANAL, V16, P911, DOI 10.1109/34.310688	13	6	6	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2003	25	1					125	130		10.1109/TPAMI.2003.1159952	http://dx.doi.org/10.1109/TPAMI.2003.1159952			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	628NL					2022-12-18	WOS:000180002300011
J	Yu, WC; Sommer, G; Beauchemin, S; Daniilidis, K				Yu, WC; Sommer, G; Beauchemin, S; Daniilidis, K			Oriented structure of the occlusion distortion: Is it reliable?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical flow; occlusion; motion discontinuities; spectral analysis	DISCONTINUOUS MOTION; IMAGE	In the energy spectrum of an occlusion sequence, the distortion term has the same orientation as the velocity of the occluding signal. Recent works claimed that this oriented structure can be used to distinguish the occluding velocity from the occluded one. Here, we argue that the orientation structure of the distortion cannot always work as a reliable feature due to the rapidly decreasing energy contribution. This already weak orientation structure is further blurred by a superposition of distinct distortion components. We also indicate that the superposition principle of Shizawa and Mase for multiple motion estimation needs to be adjusted.	Yale Univ, Dept Diagnost Radiol, New Haven, CT 06520 USA; Univ Kiel, Inst Comp Sci, D-24105 Kiel, Germany; Univ Western Ontario, Dept Comp Sci, London, ON, Canada; Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA	Yale University; University of Kiel; Western University (University of Western Ontario); University of Pennsylvania	Yu, WC (corresponding author), Yale Univ, Dept Diagnost Radiol, BML 332,POB 208042, New Haven, CT 06520 USA.			Yu, Weichuan/0000-0002-5510-6916; Daniilidis, Kostas/0000-0003-0498-0758				ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Beauchemin SS, 2000, J MATH IMAGING VIS, V13, P155, DOI 10.1023/A:1011220130307; Beauchemin SS, 2000, IEEE T PATTERN ANAL, V22, P200, DOI 10.1109/34.825758; BEAUCHEMIN SS, 1997, ADV COMPUTER VISION, P191; Chen WG, 1996, IEEE T IMAGE PROCESS, V5, P1448, DOI 10.1109/83.536893; Chen WG, 1998, IEEE T IMAGE PROCESS, V7, P1242, DOI 10.1109/83.709656; DAUGMAN JG, 1988, IEEE T ACOUSTICS SPE, V36; FLEET DJ, 1994, VISION RES, V34, P3057, DOI 10.1016/0042-6989(94)90278-X; Fleet DJ, 1992, MEASUREMENT IMAGE VE; HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568; HEITGER F, 1992, VISION RES, V32, P963, DOI 10.1016/0042-6989(92)90039-L; Jahne B., 1993, SPATIOTEMPORAL IMAGE; LANGER MS, 2001, P INT C COMP VIS, V1, P155; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406; SHIZAWA M, 1991, IEEE C COMP VIS PATT, P289; YU W, 1999, IEEE C COMP VIS PATT, V1, P171; ZANKER JM, 1993, VISION RES, V33, P553, DOI 10.1016/0042-6989(93)90258-X	17	6	6	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2002	24	9					1286	1290		10.1109/TPAMI.2002.1033220	http://dx.doi.org/10.1109/TPAMI.2002.1033220			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	587KW		Green Published			2022-12-18	WOS:000177640500012
J	Tambouratzis, G				Tambouratzis, G			Improving the clustering performance of the scanning n-tuple method by using self-supervised algorithms to introduce subclasses	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						n-tuple pattern recognition method; scanning n-tuple; chain-coding; handwritten character recognition	PATTERN-RECOGNITION; ORGANIZATION	In this paper, the scanning n-tuple technique (as introduced by Lucas and Amiri [1]) is studied in pattern recognition tasks, with emphasis placed on methods that improve its recognition performance. We remove potential edge effect problems and optimize the parameters of the scanning n-tuple method with respect to memory requirements, processing speed, and recognition accuracy for a case study task. Next, we report an investigation of self-supervised algorithms designed to improve the performance of the scanning n-tuple method by focusing on the characteristics of the pattern space. The most promising algorithm is studied in detail to determine its performance improvement and the consequential increase in the memory requirements. Experimental results using both small-scale and real-world tasks indicate that this algorithm results in an improvement of the scanning n-tuple classification performance.	Inst Language & Speech Proc, Athens 15125, Greece	Institute for Language & Speech Processing (ILSP)	Tambouratzis, G (corresponding author), Inst Language & Speech Proc, Artemidos & Epidavrou St, Athens 15125, Greece.	giorg_t@ilsp.gr						Aleksander I, 1983, PATTERN RECOGN LETT, V1, P375, DOI 10.1016/0167-8655(83)90075-2; ALEKSANDER I, 1979, COMPUTERS DIGITAL TE, V2, P29, DOI DOI 10.1049/IJ-CDT.1979.0009; AUSTIN J, 1998, RAM BASED NEURAL NET; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; Cheung KW, 1998, IEEE T PATTERN ANAL, V20, P1382, DOI 10.1109/34.735813; Jorgensen TM, 1997, INT J NEURAL SYST, V8, P17, DOI 10.1142/S0129065797000045; Jorgensen TM, 1999, IEEE T PATTERN ANAL, V21, P336, DOI 10.1109/34.761264; Jung DM, 1996, IEEE T PATTERN ANAL, V18, P734, DOI 10.1109/34.506795; Lucas S, 1996, IEE P-VIS IMAGE SIGN, V143, P23, DOI 10.1049/ip-vis:19960253; MORCINIEC M, 1998, RAM BASED NEURAL NET, P53; Morns IP, 1999, IEEE T NEURAL NETWOR, V10, P1465, DOI 10.1109/72.809091; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Rohwer R, 1998, NEURAL NETWORKS, V11, P1, DOI 10.1016/S0893-6080(97)00062-2; TAMBOURATZIS G, 1994, NETWORK-COMP NEURAL, V5, P599, DOI 10.1088/0954-898X/5/4/010; TAMBOURATZIS G, 2000, P 15 INT C PATT REC, V2, P1050	15	6	6	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2002	24	6					722	733		10.1109/TPAMI.2002.1008380	http://dx.doi.org/10.1109/TPAMI.2002.1008380			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	556JU					2022-12-18	WOS:000175846300002
J	Lanterman, AD; Grenander, U; Miller, MI				Lanterman, AD; Grenander, U; Miller, MI			Bayesian segmentation via asymptotic partition functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian Markov random fields; texture segmentation; stochastic difference equations	PARTIAL-DIFFERENTIAL EQUATIONS; RANDOM-FIELDS; SPATIAL-INTERACTION; MODELS; IMAGES; CLASSIFICATION; LIKELIHOOD; LATTICE; SYSTEMS	Asymptotic approximations to the partition function of Gaussian random fields are derived. Textures are characterized via Gaussian random fields induced by stochastic difference equations determined by finitely supported, stationary, linear difference operators, adjusted to be nonstationary at the boundaries. It is shown that as the scale of the underlying shape increases, the log-normalizer converges to the integral of the log-spectrum of the operator inducing the random field. Fitting the covariance of the fields amounts to fitting the parameters of the spectrum of the differential operator-induced random field model. Matrix analysis techniques are proposed for handling textures with variable orientation. Examples of texture parameters estimated from training data via asymptotic maximum-likelihood are shown. Isotropic models involving powers of the Laplacian and directional models involving partial derivative mixtures are explored. Parameters are estimated for mitochondria and actin-myocin complexes in electron micrographs and clutter in forward-looking infrared images. Deformable template models are used to infer the shape of mitochondria in electron micrographs, with the asymptotic approximation allowing easy recomputation of the partition function as inference proceeds.	Univ Illinois, Coordinated Sci Lab, Urbana, IL 61801 USA; Brown Univ, Div Appl Math, Providence, RI 02912 USA; Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA; Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA; Washington Univ, St Louis, MO USA	University of Illinois System; University of Illinois Urbana-Champaign; Brown University; Johns Hopkins University; Johns Hopkins University; Washington University (WUSTL)	Lanterman, AD (corresponding author), Univ Illinois, Coordinated Sci Lab, 1308 W Main, Urbana, IL 61801 USA.	lanterma@ifp.uiuc.edu; ulf@brownvm.brown.edu; mim@cis.jhu.edu	Miller, Michael I./A-3213-2010					BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BROCKETT RW, 1989, LINEAR ALGEBRA APPL, V122, P761, DOI 10.1016/0024-3795(89)90675-7; CANNON M, 1995, P 6 ANN GROUND TARG, P144; CARLBOM I, 1994, IEEE T MED IMAGING, V13, P351, DOI 10.1109/42.293928; CHATTERJEE S, 1993, MARKOV RANDOM FIELDS, P159; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P194, DOI 10.1109/TASSP.1985.1164507; Chellappa R., 1985, PATTERN RECOGNITION, V2, P79; COHEN FS, 1987, IEEE T PATTERN ANAL, V9, P195, DOI 10.1109/TPAMI.1987.4767895; COHEN FS, 1988, IEEE T PATTERN ANAL, V35, P691; COHEN I, 1992, CVGIP-IMAG UNDERSTAN, V56, P242, DOI 10.1016/1049-9660(92)90041-Z; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; FAN Z, 1992, CVGIP-GRAPH MODEL IM, V54, P239; FAN ZG, 1988, IEEE T CIRCUITS SYST, V35, P691, DOI 10.1109/31.1806; GRENANDER U, 1994, J R STAT SOC B, V56, P549; Grenander U, 1993, J COMPUT GRAPH STAT, V2, P131; GRENANDER U, UNPUB PATTERN THEORY; Grenander U., 1958, CALIFORNIA MONOGRAPH; GUYON X, 1982, BIOMETRIKA, V69, P95, DOI 10.2307/2335857; Hardy G.H., 1934, INEQUALITIES; JAIN AK, 1978, IEEE T AUTOMAT CONTR, V23, P817, DOI 10.1109/TAC.1978.1101881; JAIN AK, 1977, J OPTIMIZ THEORY APP, V23, P65, DOI 10.1007/BF00932298; KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KASHYAP RL, 1981, PROGR PATTERN RECOGN, V1, P149; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kent JT, 1996, J STAT PLAN INFER, V50, P379, DOI 10.1016/0378-3758(95)00065-8; LAKSHMANAN S, 1993, MARKOV RANDOM FIELDS, P131; MARDIA KV, 1984, BIOMETRIKA, V71, P135, DOI 10.2307/2336405; NEVATIA R, 1986, IEEE T PATTERN ANAL, V8, P76; POSSOLO A, 1991, SPATIAL STAT IMAGING; Rao A. R., 1990, TAXONOMY TEXTURE DES; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024; SMITH K., 1990, P INT C AC SPEECH SI, V4, P2317; SMITH KR, 1990, ADV NEURAL INFORMATI, V2, P388; STAIB LH, 1996, IEEE T MED IMAGING, V15, P1; Tomita F., 1990, COMPUTER ANAL VISUAL; VONNEUMANN J, 1937, TOMSK U REV, V1, P276; WHITTLE P, 1954, BIOMETRIKA, V41, P434; Yuan J., 1993, MARKOV RANDOM FIELDS, P179; ZHAO PY, 1993, IEEE T SIGNAL PROCES, V41, P849, DOI 10.1109/78.193222; ZHU S, 1996, IEEE T PATT AN MACH, V18; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	43	6	6	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					337	347		10.1109/34.845376	http://dx.doi.org/10.1109/34.845376			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT					2022-12-18	WOS:000087250500003
J	Liou, CY; Yang, HC				Liou, CY; Yang, HC			Selective feature-to-feature adhesion for recognition of cursive handprinted characters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handprinted character recognition; topological order; receptive field; Hopfield network; subgraph matching; signature recognition; cell-cell adhesion; selective attention	OBJECT RECOGNITION; SEGMENTATION; NEURONS	A structural-feature-to-structural-feature configuration is naturally constructed using a set of sampled features from a cursive pattern. These features are sampled by maximally fitting bended ellipses in local strokes. This configuration is transformed into an undirected graph to resolve the asymmetric difficulty. The compatibility associated with the graph is further formulated into a devised Hopfield network, where both interfeature and interlink similarities are incorporated into the compatibility. We operate this network to recognize a radical as a whole in a handprinted pattern to accomplish the selective attention task.	Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan	National Taiwan University	Liou, CY (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan.	cyliou@csie.ntu.edu.tw	Liou, Cheng-Yuan/HDM-0177-2022	Yang, Hsin-Chang/0000-0001-5851-2760; LIOU, CHENG-YUAN/0000-0001-7479-1413				Aiyer S B, 1990, IEEE Trans Neural Netw, V1, P204, DOI 10.1109/72.80232; Basak J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P377, DOI 10.1142/S0218001493000194; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; DOBBINS A, 1987, NATURE, V329, P438, DOI 10.1038/329438a0; FUKUSHIMA K, 1993, NEURAL NETWORKS, V6, P33, DOI 10.1016/S0893-6080(05)80071-1; GAAL G, 1993, NEURAL NETWORKS, V6, P499, DOI 10.1016/S0893-6080(05)80054-1; HINTON GE, 1992, ADV NEUR IN, V4, P512; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; Kohonen T., 1988, SELF ORG ASS MEMORY; Kuner P., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P527, DOI 10.1142/S0218001488000303; LIN WC, 1991, IEEE T NEURAL NETWOR, V2, P84, DOI 10.1109/72.80293; Liou C.-Y., 1995, P INT C NEUR NETW IC, V1, P379; Liou CY, 1996, IEEE T PATTERN ANAL, V18, P941, DOI 10.1109/34.537349; LU SW, 1991, PATTERN RECOGN, V24, P617, DOI 10.1016/0031-3203(91)90029-5; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; MOSCONA A, 1952, J ANAT, V86, P287; NASRABADI NM, 1991, IEEE T SYST MAN CYB, V21, P1523, DOI 10.1109/21.135694; ROCHA J, 1995, IEEE T PATTERN ANAL, V17, P903, DOI 10.1109/34.406657; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; SUGANTHAN PN, 1995, IMAGE VISION COMPUT, V13, P45, DOI 10.1016/0262-8856(95)91467-R; SZU H, 1988, P IEEE INT C NEURAL, V2, P259; TOWNES PL, 1955, J EXP ZOOL, V128, P53, DOI 10.1002/jez.1401280105; YANG HC, 1995, P INT C ART NEUR NET, P245	23	6	6	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1999	21	2					184	191		10.1109/34.748829	http://dx.doi.org/10.1109/34.748829			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	167NL					2022-12-18	WOS:000078639900008
J	Nakatani, Y; Sasaki, D; Iiguni, Y; Maeda, H				Nakatani, Y; Sasaki, D; Iiguni, Y; Maeda, H			Online recognition of handwritten Hiragana characters based upon a complex autoregressive model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						complex autoregressive model; PARCOR coefficient; Hiragana character; online character recognition; cross-validation	PLANAR SHAPES; CLASSIFICATION; STATE; ART	An online recognition method for handwritten Hiragana characters is developed based upon a complex AR model. The time delay of the AR model is enlarged so that global attributes of handwritten characters are well incorporated into the model, and a character-segmentation technique is developed for performance improvement. A good recognition score has been obtained for two different writers.	NEC Corp Ltd, C&C Media Res Lab, Kawasaki, Kanagawa 2168555, Japan; Osaka Univ, Grad Sch Engn, Dept Commun Engn, Suita, Osaka 565, Japan	NEC Corporation; Osaka University	Nakatani, Y (corresponding author), NEC Corp Ltd, C&C Media Res Lab, Kawasaki, Kanagawa 2168555, Japan.							DAS M, 1990, IEEE T PATTERN ANAL, V12, P97, DOI 10.1109/34.41389; DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752; Everitt B., 1981, FINITE MIXTURE DISTR, P143; FRIEDLANDER B, 1982, P IEEE, V70, P829, DOI 10.1109/PROC.1982.12407; Haykin S, 1979, NONLINEAR METHODS SP; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; KURITA T, 1994, PATTERN RECOGN, V27, P903, DOI 10.1016/0031-3203(94)90156-2; MANTAS J, 1987, PATTERN RECOGN, V20, P1, DOI 10.1016/0031-3203(87)90012-4; PLAMONDON R, 1989, IEEE T SYST MAN CYB, V19, P1060, DOI 10.1109/21.44021; SEKITA I, 1992, IEEE T PATTERN ANAL, V14, P489, DOI 10.1109/34.126809; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; WAKAHARA T, 1992, P IEEE, V80, P1181, DOI 10.1109/5.156478	13	6	6	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					73	76		10.1109/34.745737	http://dx.doi.org/10.1109/34.745737			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ					2022-12-18	WOS:000078388900010
J	Younes, L				Younes, L			Synchronous random fields and image restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						random fields; image processing; parallelism; Monte-Carlo sampling	BAYESIAN COMPUTATION; BOLTZMANN MACHINES; DISTRIBUTIONS	We propose a general synchronous model of lattice random fields which could be used similarly to Gibbs distributions in a Bayesian framework for image analysis, leading to algorithms ideally designed for an implementation on massively parallel hardware. After a theoretical description of the model, we give an experimental illustration in the context of image restoration.	Ecole Normale Super, CMLA, F-94235 Cachan, France	UDICE-French Research Universities; Universite Paris Saclay	Younes, L (corresponding author), Ecole Normale Super, CMLA, 61 Ave President Wilson, F-94235 Cachan, France.	Laurent.Younes@smla.ens-cachan.fr	Younes, E. Laurent/A-3349-2010	Younes, Laurent/0000-0003-2017-9565				AZENCOTT R, 1993, NETWORK-COMP NEURAL, V4, P461, DOI 10.1088/0954-898X/4/4/004; AZENCOTT R, 1990, NATO ASI F, V68, P51; AZENCOTT R, 1992, LECT NOTES STAT, V74, P14; AZENCOTT R, 1987, P INT C IND APPL MAT; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1993, J ROY STAT SOC B MET, V55, P25; DAWSON DA, 1975, CAN MATH BULL, V17, P633, DOI 10.4153/CMB-1974-117-4; DOBRUSHIN RL, 1970, THEOR PROBAB APPL+, V15, P458, DOI 10.1137/1115049; FRANCOIS O, 1990, CR ACAD SCI I-MATH, V310, P435; FRIGESSI A, 1990, ANN APPL PROBABILITY; GEMAN D, 1991, LECT NOTES MATH, V1427; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1995, ANN APPL PROB, V5, P577; GEYER CJ, 1992, J R STAT SOC B, V54, P657; GOUTSIAS J, 1991, CVGIP-GRAPH MODEL IM, V53, P240, DOI 10.1016/1049-9652(91)90046-M; KOSLOV O, 1980, MULTICOMPONENT RANDO, P415; KUNSCH H, 1984, STOCH PROC APPL, V17, P159, DOI 10.1016/0304-4149(84)90318-1; LEBOWITZ JL, 1990, J STAT PHYS, V59, P117, DOI 10.1007/BF01015566; LITTLE W A, 1974, Mathematical Biosciences, V19, P101, DOI 10.1016/0025-5564(74)90031-5; MAES C, 1989, COMM STAT PHYS, V135, P233; PERETTO P, 1986, DISORDERED SYSTEMS B, P171; POGGIO T, 1988, SCIENCE, V242, P436, DOI 10.1126/science.3175666; PROPP JG, 1996, EXACT SAMPLING COUPL; SMITH AFM, 1993, J ROY STAT SOC B MET, V55, P3; SOKAL A, 1989, COURS 13 CYCLE PHYSI; SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86; TROUVE A, 1992, LECT NOTES CONTROL I, V177; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; Younes L, 1996, APPL MATH LETT, V9, P109, DOI 10.1016/0893-9659(96)00041-9; YOUNES L, 1992, LECT NOTES STAT, V74, P14; YOUNES L, 1996, MARKOV PROCESSES REL, V2, P285	31	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1998	20	4					380	390		10.1109/34.677263	http://dx.doi.org/10.1109/34.677263			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZP214					2022-12-18	WOS:000073729200003
J	Huang, D; Dunsmuir, WTM				Huang, D; Dunsmuir, WTM			Computing joint distributions of 2D moving median filters with applications to detection of edges	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image analysis; moving medians; joint distributions; edge detection; edge miss probability		This paper derives the joint distribution of medians over moving windows in a two dimensional noisy image. The general formulation presented allows derivation of the probability distribution needed to evaluate the probability of failing to detect an edge when present ("edge miss probability") and the probability of falsely detecting a nonexistent edge.	Queensland Univ Technol, Sch Math, Brisbane, Qld 4001, Australia; Univ New S Wales, Sch Math, Sydney, NSW 2052, Australia	Queensland University of Technology (QUT); University of New South Wales Sydney	Huang, D (corresponding author), Queensland Univ Technol, Sch Math, GPO Box 2434, Brisbane, Qld 4001, Australia.							BOVIK AC, 1987, IEEE T PATTERN ANAL, V9, P181, DOI 10.1109/TPAMI.1987.4767894; David H. A., 1981, ORDER STAT; HUANG D, 1992, P 2 INT C IM PROC, P621	3	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					340	343		10.1109/34.667891	http://dx.doi.org/10.1109/34.667891			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156					2022-12-18	WOS:000073078400011
J	Lei, ZB; Cooper, DB				Lei, ZB; Cooper, DB			Linear programming fitting of implicit polynomials	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						implicit polynomials; shape representations; linear programming; distance approximation; fitting algorithms; user interface	RECOGNITION; SURFACES; OBJECTS; CURVES; 2D	A new implicit polynomial (IF) fitting method is presented. It provides a different way of viewing the IP fitting problem from those of the nonlinear optimization approaches. It requires less computation, and can be done automatically or interactively. Linear Programming (LP) is used to do the fitting. The approach can incorporate a variety of distance measures and global geometric constraints.	Lucent Technol, Murray Hill, NJ 07974 USA; Brown Univ, Div Engn, Providence, RI 02912 USA	Alcatel-Lucent; Lucent Technologies; Brown University	Lei, ZB (corresponding author), Lucent Technol, Room 2D335,700 Mt Ave, Murray Hill, NJ 07974 USA.							Dantzig G. B., 1963, LINEAR PROGRAMMING I; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; LEI Z, 1995, P INT C IM PROC WASH, P635; LEI Z, 1995, 146 LEMS BROWN U; Lei ZB, 1996, PROC CVPR IEEE, P514, DOI 10.1109/CVPR.1996.517120; Mundy J., 1992, GEOMETRIC INVARIANCE; Subrahmonia J, 1996, IEEE T PATTERN ANAL, V18, P505, DOI 10.1109/34.494640; SULLIVAN S, 1994, IEEE T PATTERN ANAL, V16, P1183, DOI 10.1109/34.387489; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; TAUBIN G, 1993, P 4 INT C COMP VIS B, P658; VANDERBEI RJ, 1992, PROGRAM STAT OPERATI	11	6	8	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1998	20	2					212	217		10.1109/34.659942	http://dx.doi.org/10.1109/34.659942			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YZ697					2022-12-18	WOS:000072281800011
J	Legault, R; Suen, CY				Legault, R; Suen, CY			Optimal local weighted averaging methods in contour smoothing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						contour smoothing; optimal local weighted averaging; digitization noise modeling; Gaussian smoothing	SCALE-SPACE; ZERO-CROSSINGS; COMPUTER RECOGNITION; GAUSSIAN KERNEL; CIRCULAR ARCS; CURVES; THEOREMS; REGULARIZATION; DECOMPOSITION; SHRINKAGE	In several applications where binary contours are used to represent and classify patterns, smoothing must be performed to attenuate noise and quantization error. This is often implemented with local weighted averaging of contour point coordinates, because of the simplicity, low-cost and effectiveness of such methods. Invoking the ''optimality'' of the Gaussian filter, many authors will use Gaussian-derived weights. But generally these filters are not optimal, and there has been little theoretical investigation of local weighted averaging methods per se. This paper focuses on the direct derivation of optimal local weighted averaging methods tailored towards specific computational goals such as the accurate estimation of contour point positions, tangent slopes, or deviation angles. A new and simple digitization noise model is proposed to derive the best set of weights for different window sizes, for each computational task. Estimates of the fraction of the noise actually removed by these optimum weights are also obtained. Finally, the applicability of these findings for arbitrary curvature is verified, by numerically investigating equivalent problems for digital circles of various radii.			Legault, R (corresponding author), CONCORDIA UNIV, CTR PATTERN RECOGNIT & MACHINE INTELLIGENCE, MONTREAL, PQ H3G 1M8, CANADA.							Anh V, 1996, IEEE T PATTERN ANAL, V18, P309, DOI 10.1109/34.485558; ANSARI N, 1991, PATTERN RECOGN, V24, P849, DOI 10.1016/0031-3203(91)90004-O; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; Badler N. I., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P286; Bangham JA, 1996, IEEE T PATTERN ANAL, V18, P529, DOI 10.1109/34.494642; Bangham JA, 1996, IEEE T PATTERN ANAL, V18, P520, DOI 10.1109/34.494641; BLESSER B, 1983, Patent No. 4375081; BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464; CHEN MH, 1993, IEEE T PATTERN ANAL, V15, P1208; DESSIMOZ JD, 1979, SIGNAL PROCESS, V1, P205, DOI 10.1016/0165-1684(79)90020-3; DILL AR, 1987, IEEE T PATTERN ANAL, V9, P495, DOI 10.1109/TPAMI.1987.4767937; DOROS M, 1979, COMPUT VISION GRAPH, V10, P366, DOI 10.1016/S0146-664X(79)80044-1; ECCLES MJ, 1977, PATTERN RECOGN, V9, P31, DOI 10.1016/0031-3203(77)90028-0; ELLIS TJ, 1979, COMPUT VISION GRAPH, V10, P333, DOI 10.1016/S0146-664X(79)80042-8; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; FREEMAN H, 1962, P NATL ELECT C, V18, P312; GALLUS G, 1970, PHYS MED BIOL, V15, P435, DOI 10.1088/0031-9155/15/3/004; Horn B. K. P., 1976, COMPUTER GRAPHICS IM, V5, P280; HORN BKP, 1986, IEEE T PATTERN ANAL, V8, P665, DOI 10.1109/TPAMI.1986.4767839; KAMMENOS P, 1978, P 8 INT S IND ROB ST, P143; KASVAND T, 1983, P SPIE C ARCHITECTUR, P44; KULPA Z, 1979, COMPUT VISION GRAPH, V9, P102, DOI 10.1016/0146-664X(79)90087-X; KULPA Z, 1979, COMPUT VISION GRAPH, V10, P348, DOI 10.1016/S0146-664X(79)80043-X; LEE D, 1988, IEEE T PATTERN ANAL, V10, P822, DOI 10.1109/34.9105; LEGAULT R, 1993, P 3 INT WORKSH FRONT, P31; LI XP, 1995, IEEE T PATTERN ANAL, V17, P1015, DOI 10.1109/34.464565; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; LOWE DG, 1989, INT J COMPUT VISION, V3, P119, DOI 10.1007/BF00126428; MACKWORTH A, 1988, P IEEE C COMP VIS PA, P318; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MCKEE JW, 1977, IEEE T COMPUT, V26, P790, DOI 10.1109/TC.1977.1674917; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; OLIENSIS J, 1993, IEEE T PATTERN ANAL, V15, P307, DOI 10.1109/34.204914; PAUWELS EJ, 1995, IEEE T PATTERN ANAL, V17, P691, DOI 10.1109/34.391411; PEI SC, 1995, PATTERN RECOGN, V28, P107, DOI 10.1016/0031-3203(94)00086-2; POGGIO T, 1985, 776 MIT AL LAB; REINSCH CH, 1967, NUMER MATH, V10, P177, DOI 10.1007/BF02162161; SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339; SAKAI T, 1972, COMPUT GRAPHICS IMAG, V1, P81; SCHOENBERG IJ, 1964, P NATL ACAD SCI USA, V52, P947, DOI 10.1073/pnas.52.4.947; SHAHRARAY B, 1989, IEEE T PATTERN ANAL, V11, P600, DOI 10.1109/34.24794; Shahraray B., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P210; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; TAPPERT CC, 1987, RC13228 IBM TJ WATS; Taylor AE., 1983, ADV CALCULUS; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; TSAI DM, 1994, PATTERN RECOGN, V27, P699, DOI 10.1016/0031-3203(94)90048-5; Wheeler MD, 1996, IEEE T PATTERN ANAL, V18, P334, DOI 10.1109/34.485562; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; WORRING M, 1995, IEEE T PATTERN ANAL, V17, P587, DOI 10.1109/34.387505; WUESCHER DM, 1991, IEEE T PATTERN ANAL, V13, P41, DOI 10.1109/34.67629; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	56	6	8	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1997	19	8					801	817		10.1109/34.608276	http://dx.doi.org/10.1109/34.608276			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XT987					2022-12-18	WOS:A1997XT98700001
J	Nielsen, M				Nielsen, M			Graduated nonconvexity by functional focusing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graduated nonconvexity; functional minimization; mean field annealing; Bayesian reconstruction	IMAGES	Reconstruction of noise-corrupted surfaces may be stated as a (in general nonconvex) functional minimization problem. For functionals with quadratic data term, this paper addresses the criteria for such functionals to be convex, and the variational approach for minimization. I present two automatic and general methods of approximation with convex functionals based on Gaussian convolution. They are compared to the Blake-Zisserman graduated nonconvexity (GNC) method and Bilbro et al. and Geiger and Girosi's mean field annealing (MFA) of a weak membrane.			Nielsen, M (corresponding author), SCH DENT, LAB 3D, NORRE ALLE 25, DK-2200 COPENHAGEN N, DENMARK.							BELHUMEUR P, 1993, INT C COMPUTER VISIO; BILBRO GL, 1992, IEEE T NEURAL NETWOR, V3, P131, DOI 10.1109/72.105426; GEIEGER D, 1991, T PATTERN ANAL MACHI, V13; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Li M., 1993, INTRO KOLMOGOROV COM; MARCH R, 1992, IMAGE VISION COMPUT, V10, P30, DOI 10.1016/0262-8856(92)90081-D; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; NIELSEN M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P344, DOI 10.1109/ICCV.1995.466918; NIELSEN M, 1994, 2353 INRIA; NIELSEN M, 1995, THESIS DATALOGISK I; NIELSEN M, 1994, 2351 I NATL RECH INF; NIELSEN M, IN PRESS J MATH IMAG; NIELSEN M, 1995, THEORY APPLICATIONS; NIELSEN M, 1993, P 4 BMVC GUILDF ENGL; RANGARAJAN A, 1990, P 10 ICPR ATL CIT NY; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; Saunders P. T., 1980, INTRO CATASTROPHE TH; Thom R., 2018, STRUCTURAL STABILITY; Tikhonov A.N., 1977, SOLUTION ILL POSED P; UNSER M, 1991, T PATTERN ANAL MACHI, V13	22	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					521	525		10.1109/34.589213	http://dx.doi.org/10.1109/34.589213			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300012
J	Super, BJ; Klarquist, WN				Super, BJ; Klarquist, WN			Patch-based stereo in a general binocular viewing geometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo; shape; depth; correspondence; patch matching; area correlation; sampling; perspective; surfaces; computer vision	TEXTURE; SHAPE	This paper presents a one-stage stereo algorithm that yields 3D planar surface patches directly from matching image patch intensity information. The method allows an arbitrary rotation and translation between the cameras; it is not limited to parallel-axis, narrow-baseline, or vergent geometries. The key to the approach is to match image patches that have positions, shapes, sizes, orientations, and samplings consistent with a hypothesized surface patch and with each other. The match error then reflects only the mismatch of patch contents and not the mismatch of patch geometries or samplings. The algorithm is quantitatively evaluated against ground truth on real images with difficult viewing geometries, and demonstrates an average accuracy of about 1% in estimating surface depths and 10 degrees in estimating surface normals.	UNIV TEXAS, CTR VIS & IMAGE SCI, AUSTIN, TX 78712 USA; UNIV TEXAS, DEPT ELECT & COMP ENGN, AUSTIN, TX 78712 USA	University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin								BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; BERGEN JR, 1992, 2ND P EUR C COMP VIS, P237; DEVERNAY F, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P208, DOI 10.1109/CVPR.1994.323831; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; Garding J, 1996, INT J COMPUT VISION, V17, P163, DOI 10.1007/BF00058750; GARDING J, 1994, P 3 EUR C COMP VIS, P365; JONES DG, 1992, P EUR C COMP VIS, P395; JONES DG, 1992, P 2 EUR C COMP VIS S, P661; KASS M, 1987, INT J COMPUT VISION, V1, P357, DOI 10.1007/BF00133572; KOENDERINK JJ, 1976, BIOL CYBERN, V21, P29, DOI 10.1007/BF00326670; KOENDERINK JJ, 1976, J OPT SOC AM, V66, P717, DOI 10.1364/JOSA.66.000717; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; LANE RA, 1994, IMAGE VISION COMPUT, V12, P203, DOI 10.1016/0262-8856(94)90074-4; Lindeberg T, 1994, P 3 EUR C COMP VIS, P389; MANMATHA R, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P141, DOI 10.1109/CVPR.1994.323821; MAYHEW JEW, 1982, NATURE, V297, P376, DOI 10.1038/297376a0; Schweitzer H., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P742, DOI 10.1109/CVPR.1993.341152; SUPER B, 1994, TR94006 U TEX AUST C; SUPER B, 1995, P INT C DIG SIGN PRO, P500; SUPER BJ, 1991, P SOC PHOTO-OPT INS, V1606, P574, DOI 10.1117/12.50344; SUPER BJ, 1995, PATTERN RECOGN, V28, P729, DOI 10.1016/0031-3203(94)00140-H; SUPER BJ, 1995, IEEE T PATTERN ANAL, V17, P333, DOI 10.1109/34.385983; SUPER BJ, 1992, P SOC PHOTO-OPT INS, V1818, P144, DOI 10.1117/12.131433; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	24	6	11	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					247	253		10.1109/34.584102	http://dx.doi.org/10.1109/34.584102			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR582					2022-12-18	WOS:A1997WR58200006
J	Fukushima, S				Fukushima, S			Division-based analysis of symmetry and its application	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; symmetric axis; symmetric points; computational geometry; Voronoi diagram; Delaunay triangulation; generalized cylinder; shape analysis	STOMACH; SHAPE	A computational method, DAS, is proposed for symmetry analysis oi a planar figure closed by a simply connected curve. DAS determines both the symmetric axis and the symmetric point pairs on the curve, consistently, based on the duality of two geometric plane divisions, the Delaunay triangulation and the Voronoi diagram.			Fukushima, S (corresponding author), KYUSHU INST TECHNOL,FAC COMP SCI & SYST ENGN,DEPT CONTROL ENGN & SCI,680-4 KAWAZU,IIZUKA,FUKUOKA 820,JAPAN.							ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V11, P123, DOI 10.1016/0146-664X(79)90062-5; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; BURAGO YD, 1988, GEOMETRIC INEQUALITI, pCH2; CHUNG JM, 1993, COMPUTER GRAPHICS AP, V1, P383; FAIRFIELD J, 1983, IEEE T PATTERN ANAL, V5, P104, DOI 10.1109/TPAMI.1983.4767353; FAIRFIELD JRC, 1983, IEEE T SYST MAN CYB, V13, P363, DOI 10.1109/TSMC.1983.6313168; FUKUNISHI I, 1993, CHILD PSYCHIAT HUM D, V24, P59, DOI 10.1007/BF02353719; Fukushima S., 1991, Systems and Computers in Japan, V22, P74, DOI 10.1002/scj.4690220308; Fukushima S., 1991, Proceedings IECON '91. 1991 International Conference on Industrial Electrlnics, Control and Instrumentation (Cat. No.91CH2976-9), P1773, DOI 10.1109/IECON.1991.239247; FUKUSHIMA S, 1991, P 7 SCAND C IM AN AA, P878; FUKUSHIMA S, 1994, OBSTET GYNECOLOGICAL, V43, P1821; Hilditch C.J., 1969, MACH INTELL, P403; LEE DT, 1982, IEEE T PATTERN ANAL, V4, P363, DOI 10.1109/TPAMI.1982.4767267; LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785; LEYTON M, 1987, COMPUT VISION GRAPH, V38, P327, DOI 10.1016/0734-189X(87)90117-4; MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486; NAGATA S, 1994, EARLY HUM DEV, V37, P27, DOI 10.1016/0378-3782(94)90144-9; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; NEWMAN WM, 1979, PRINCIPLES INTERACTI, pCH25; OROURKE J, 1979, IEEE T PATTERN ANAL, V1, P295, DOI 10.1109/TPAMI.1979.4766925; ROSENFEL.A, 1966, J ACM, V13, P471; SHANI U, 1984, COMPUT VISION GRAPH, V27, P129, DOI 10.1016/S0734-189X(84)80039-0; SOMA T, 1976, DIGITAL PROCESSING M, P323; YOSHIZATO T, 1995, EARLY HUM DEV, V41, P39, DOI 10.1016/0378-3782(94)01607-Q	26	6	13	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					144	148		10.1109/34.574795	http://dx.doi.org/10.1109/34.574795			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800007
J	Heisterkamp, DR; Bhattacharya, P				Heisterkamp, DR; Bhattacharya, P			Matching of 3D polygonal arcs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						polygonal arcs; matching; distance measure; mismatch measure; quaternions; rotation matrix; eigenvalues	CURVES	We define a distance measure between 3D polygonal arcs of equal length, and show that the minimum value of this distance measure is the smallest eigenvalue of a certain matrix. Using this, we develop a mismatch measure and a matching algorithm for 3D polygonal arcs of unequal lengths.			Heisterkamp, DR (corresponding author), UNIV NEBRASKA, DEPT COMP SCI & ENGN, LINCOLN, NE 68588 USA.							Ayache N, 1991, ARTIFICIAL VISION MO; BASCLE B, 1993, P 4 INT C COMP VIS B, P421; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P60; BHATTACHARYA P, 1994, J VIS COMMUN IMAGE R, V50, P353; EASON RO, 1992, DATA FUSION ROBOTICS; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; GUEZIEC A, 1994, INT J COMPUT VISION, V12, P79, DOI 10.1007/BF01420985; Horn B., 1986, ROBOT VISION, P1; KISHON E, 1991, J ROBOTIC SYST, V8, P723, DOI 10.1002/rob.4620080602; Maillot P-G, 1990, GRAPHICS GEMS, P498; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PAJDLA T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P390, DOI 10.1109/ICCV.1995.466913; PARSI B, 1991, COMPUTER VISION GRAP, V53, P227; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; Shoemake K., 1991, GRAPHICS GEMS, VII, P351	15	6	6	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					68	73		10.1109/34.566813	http://dx.doi.org/10.1109/34.566813			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528					2022-12-18	WOS:A1997WE52800008
J	Malik, R; Whangbo, T				Malik, R; Whangbo, T			Angle densities and recognition of 3D objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; feature variation; computer vision; image understanding; scene analysis; model based recognition; 3D recognition; statistical decisions		Recognition of 3D objects using computer vision is complicated by the fact that geometric features vary with view orientation. An important factor in designing recognition algorithms in such situations is understanding the variation of certain critical features such as angles. In this paper we derive the two dimensional joint density function of two angles in a scene given an isotropic view orientation and an orthographic projection. The analytic expression for the densities are useful in determining statistical decision rules to recognize surfaces and objects. Experiments to evaluate the usefulness of the proposed methods are reported.	SAMSUNG ADV INST TECHNOL,DEPT SUPERCOMP APPL,SUWON 440600,SOUTH KOREA	Samsung	Malik, R (corresponding author), NEW JERSEY INST TECHNOL,DEPT ELECT & COMP ENGN,NEWARK,NJ 07102, USA.							BENARIE J, 1990, IEEE T PATTERN ANAL, V12, P760, DOI 10.1109/34.57667; BINFORD TO, 1989, UNCERTAINTY ARTIFICI, V3; BURNS JB, 1993, IEEE T PATTERN ANAL, V15, P51, DOI 10.1109/34.184774; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; JACKSON JE, 1983, SPHERE SPHEROID PROJ; Malik R., 1994, Proceedings of the IEEE Southwest Symposium on Image Analysis and Interpretation, P142, DOI 10.1109/IAI.1994.336668; MALIK R, 1991, P 1991 IEEE INT C SY, V1, P111; MALIK R, 1994, P 3 GWIC INT SYST JU; MALIK R, 1994, P SPIE INT S INT ROB; WHANGBO T, 1995, THESIS STEVENS I TEC; [No title captured]	11	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					52	57		10.1109/34.566810	http://dx.doi.org/10.1109/34.566810			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528					2022-12-18	WOS:A1997WE52800005
J	Maio, D; Maltoni, D; Rizzi, S				Maio, D; Maltoni, D; Rizzi, S			Dynamic clustering of maps in autonomous agents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						autonomous agents; clustering; environment maps; heuristic algorithms; knowledge representation		The problem of organizing and exploiting spatial knowledge for navigation is an important issue in the field of autonomous mobile systems. In particular, partitioning the environment map into connected clusters allows for significant topological features to be captured and enables decomposition of path-planning tasks through a divide-and-conquer policy. Clustering by discovery Ts a procedure for identifying clusters in a map being learned by exploration as the agent moves within the environment, and yields a valid clustering of the available knowledge at each exploration step. In this work, we define a fitness measure for clustering and propose two incremental heuristic algorithms to maximize it. Both algorithms determine clusters dynamically according to a set of topological and metric criteria. The first one is aimed at locally minimizing a measure of ''scattering'' of the entities belonging to clusters, and partially rearranges the existing clusters at each exploration step. The second estimates the positions and dimensions of clusters according to a global map of density. The two algorithms are compared in terms of optimality, efficiency, robustness, and stability.	UNIV BOLOGNA,CSITE,CNR,I-40136 BOLOGNA,ITALY; UNIV BOLOGNA,DEIS,I-47023 CESENA,ITALY	Consiglio Nazionale delle Ricerche (CNR); University of Bologna; University of Bologna	Maio, D (corresponding author), UNIV BOLOGNA,DEIS,VIALE RISORGIMENTO 2,I-40136 BOLOGNA,ITALY.			Rizzi, Stefano/0000-0002-4617-217X				CAUSSE O, 1994, ROBOTICS AUTONOMOUS, V12, P213; CHAUDHURI BB, 1994, PATTERN RECOGN LETT, V15, P27, DOI 10.1016/0167-8655(94)90097-3; Christensen H. I., 1994, Robotics and Autonomous Systems, V12, P199, DOI 10.1016/0921-8890(94)90026-4; CIACCIA P, 1993, P INT WORKSH MECH CO, P367; DAVIS L, 1987, GENETIC ALGORITHMS S, P1; Duda R.O., 1973, J ROYAL STAT SOC SER; ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720; FAVERJON B, 1987, P INT JOINT C ART IN, V2, P1131; Goldberg DE, 1989, GENETIC ALGORITHMS S; Hartigan J.A., 1975, CLUSTERING ALGORITHM; HOLMES PD, 1992, IEEE T PATTERN ANAL, V14, P549, DOI 10.1109/34.134059; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KUIPERS BJ, 1988, P AAAI88 ST PAUL, V2, P774; MAIO D, 1995, PATTERN RECOGN LETT, V16, P89, DOI 10.1016/0167-8655(94)00069-F; MAIO D, 1993, IEEE T PATTERN ANAL, V15, P1286, DOI 10.1109/34.250846; Maio D., 1994, Proceedings The Second International Conference on Expert Systems for Development (Cat. No.94TH0643-7), P222, DOI 10.1109/ICESD.1994.302277; MAIO D, 1992, PATTERN RECOGN LETT, V13, P89, DOI 10.1016/0167-8655(92)90038-2; MAIO D, 1993, P 8 INT S COMP INF S, P4; PHILLIPS WA, 1988, NATO ASI SERIES F, V41, P159; ROSE K, 1990, PATTERN RECOGN LETT, V11, P589, DOI 10.1016/0167-8655(90)90010-Y; SINGH SP, 1992, MACH LEARN, V8, P323, DOI 10.1007/BF00992700; VERCELLI G, 1991, P C ASS IT INT ART I, P342	23	6	6	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1996	18	11					1080	1091		10.1109/34.544077	http://dx.doi.org/10.1109/34.544077			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VU159					2022-12-18	WOS:A1996VU15900003
J	Ishida, T				Ishida, T			Real-time bidirectional search: Coordinated problem solving in uncertain situations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						search; real-time search; bidirectional search; problem solving; real-time problem solving; organizational problem solving; heuristic depression	HEURISTIC-SEARCH; SYSTEMS	This paper investigates real-time bidirectional search (RTBS) algorithms, where two problem solvers, starting from the initial and goal states, physically move toward each other. To evaluate the RTBS performance, two kinds of algorithms are proposed and are compared to real-time unidirectional search. One is called centralized RTBS where a supervisor always selects the best action from all possible moves of the two problem solvers. The other is called decoupled RTBS where no supervisor exists and the two problem solvers independently select their next moves. Experiments on mazes and n-puzzles show that 1) in clear situations decoupled RTBS performs better, while in uncertain situations, centralized RTBS becomes more efficient, and that 2) RTBS is more efficient than real-time unidirectional search for 15- and 24-puzzles but not for randomly generated mazes. It will be shown that the selection of the problem solving organization is the selection of the problem space, which determines the baseline of the organizational efficiency; once a difficult problem space is selected, the local coordination among problem solvers hardly overcome the deficit.			Ishida, T (corresponding author), KYOTO UNIV,DEPT INFORMAT SCI,KYOTO 60601,JAPAN.		Ishida, Toru/AAI-2102-2020; Ishida, Toru/H-5553-2017	Ishida, Toru/0000-0002-0479-4990; Ishida, Toru/0000-0002-0479-4990				CHIMURA F, 1994, AAAI 94, P1347; DECHAMPEAUX D, 1977, J ACM, V24, P177; DECHAMPEAUX D, 1983, J ACM, V30, P22, DOI 10.1145/322358.322360; DURFEE EH, 1987, IEEE T COMPUT, V36, P1275, DOI 10.1109/TC.1987.5009468; FOX MS, 1981, IEEE T SYST MAN CYB, V11, P70, DOI 10.1109/TSMC.1981.4308580; GEORGEFF MP, 1987, AAAI, P677; ISHIDA T, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P525; ISHIDA T, 1992, IEEE T KNOWL DATA EN, V4, P123, DOI 10.1109/69.134249; ISHIDA T, 1995, IEEE T PATTERN ANAL, V17, P609, DOI 10.1109/34.387507; Ishida T., 1995, ICMAS-95 Proceedings. First International Conference on Multi-Agent Systems, P185; ISHIDA T, 1993, IEEE INT C ROB AUT, P839; ISHIDA T, 1991, IJCAI 91, P204; KORF RE, 1990, ARTIF INTELL, V42, P189, DOI 10.1016/0004-3702(90)90054-4; KORF RE, 1985, ARTIF INTELL, V27, P97, DOI 10.1016/0004-3702(85)90084-0; KWA JBH, 1989, ARTIF INTELL, V38, P95, DOI 10.1016/0004-3702(89)90069-6; Lesser V. R., 1990, Journal of Japanese Society for Artificial Intelligence, V5, P392; Pearl J., 1984, INTELLIGENT SEARCH S; Pohl I., 1971, Machine Intelligence Volume 6, P127; POLITOWSKI G, 1984, AAAI 84, P274; Pollack M. E., 1990, AAAI-90 Proceedings. Eighth National Conference on Artificial Intelligence, P183; Russell Stuart, 1991, DO RIGHT THING; [No title captured]	22	6	7	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					617	628		10.1109/34.506412	http://dx.doi.org/10.1109/34.506412			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UR254					2022-12-18	WOS:A1996UR25400005
J	PAUWELS, EJ; FIDDELAERS, P; VANGOOL, LJ				PAUWELS, EJ; FIDDELAERS, P; VANGOOL, LJ			ENHANCEMENT OF PLANAR SHAPE THROUGH OPTIMIZATION OF FUNCTIONALS FOR CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CURVE-EVOLUTION; NORDSTROM-WEN DIFFUSION; GEOMETRY-DRIVEN DIFFUSION; MUMFORD-SHAH FUNCTIONALS; SHAPE; ELASTICAE		We show how optimization of the Nordstrom and Mumford-Shah functionals can be used to develop a type of curve-evolution that is able to preserve salient features of closed curves while simultaneously suppressing noise and irrelevant details. The idea is to characterize a curve by means of its angle-function and apply the appropriate dynamics to this representation. Upon convergence, the resulting form of the contour is reconstructed from the representation.			PAUWELS, EJ (corresponding author), KATHOLIEKE UNIV LEUVEN,ESAT,M12,K MERCIERLAAN 94,B-3001 LOUVAIN,BELGIUM.							ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127; FAUGERAS O, 1993, CR ACAD SCI I-MATH, V317, P565; GAGE M, 1986, J DIFFER GEOM, V23, P69; GRAYSON M, ANN MATH, V129; KIMIA BB, 1993, LEMS105 TECH REP; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NORDSTROM N, 1990, IMAGE VISION COMPUTI, V8; OLVER PJ, 1994, INVARIANT GEOMETRIC, P2238; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PAUWELS EJ, 1994, KULESATMI29414A TECH; Perona P., 1990, IEEE T PATTERN ANAL, V12; SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591; TROUTMAN JL, 1993, VARIATIONAL CALCULUS; WEN YZ, 1993, DUKE MATH J, V70, P683, DOI 10.1215/S0012-7094-93-07016-0	14	6	6	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1995	17	11					1101	1105		10.1109/34.473238	http://dx.doi.org/10.1109/34.473238			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TD854					2022-12-18	WOS:A1995TD85400010
J	CUBANSKI, D; CYGANSKI, D				CUBANSKI, D; CYGANSKI, D			MULTIVARIATE CLASSIFICATION THROUGH ADAPTIVE DELAUNAY-BASED C-0 SPLINE APPROXIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						PATTERN CLASSIFICATION; APPROXIMATION; NEURAL NETWORKS; NONLINEAR OPTIMIZATION; SPLINES; EGG	NEURAL NETWORKS; ALGORITHM	This paper introduces a new method for adaptively building a multivariate C-0 spline approximation from scattered samples of an unknown function. The central feature of the method is a means for adaptively tesselating an approximation space to form a multidimensional mesh over which the spline fitting then occurs, The mesh used is a Delaunay tesselation of the approximation space whose vertices lie at a subset of the scattered sample locations, The specific subset of sample locations used is adaptively determined by repeated overfitting and simplification of the resulting spline approximation. Overfitting and simplification is an attractive paradigm for high-dimensional approximation problems because it provides a means for forming an approximation that is complex only in regions where the scattered sample data provide sufficient evidence of complexity in the underlying unknown function, Overfitting and simplification is effectively exploited in this new approach as the function representation used is not subject to certain recursive dependencies. The properties of the new technique are demonstrated in the context of an easily visualized bivariate classification problem. The technique is then applied to a 10-dimensional clinical ECG classification problem, and the results are compared to those obtained with a perceptron based neural network.	WORCESTER POLYTECH INST,DEPT ELECT & COMP ENGN,WORCESTER,MA 01609	Worcester Polytechnic Institute	CUBANSKI, D (corresponding author), ACUITY IMAGING INC,NASHUA,NH 03063, USA.							BATHE KJ, 1981, INT J NUMER METH ENG, V17, P1717; BELLMAN RICHARD, 1961, ADAPTIVE CONTROL PRO, V94-95; CUBANSKI D, 1993, THESIS WORCESTER POL; CUBANSKI D, 1993, 42ND AM COLL CARD AN, V21, pA182; Fahlman S., 1990, CMUCS90100 CARN MELL; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Karnin E D, 1990, IEEE Trans Neural Netw, V1, P239, DOI 10.1109/72.80236; Lippman R. P., 1987, IEEE ASSP MAGAZI APR, P4; MURPHY OJ, 1991, IEEE T CIRCUITS SYST, V38, P1542, DOI 10.1109/31.108507; Olshen R., 1984, CLASSIFICATION REGRE; QIAN S, 1990, INT JOINT C NEUR NET, V3, P605; SANKAR A, 1992, NEURAL TREE NETWORKS, P327; SCALERO RS, 1992, IEEE T SIGNAL PROCES, V40, P202, DOI 10.1109/78.157194; SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934; WATSON DF, 1981, COMPUT J, V24, P167, DOI 10.1093/comjnl/24.2.167	15	6	6	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1995	17	4					403	417		10.1109/34.385978	http://dx.doi.org/10.1109/34.385978			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QR628					2022-12-18	WOS:A1995QR62800007
J	SOHN, W; KEHTARNAVAZ, ND				SOHN, W; KEHTARNAVAZ, ND			ANALYSIS OF CAMERA MOVEMENT ERRORS IN VISION-BASED VEHICLE TRACKING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CAMERA MOVEMENT ERROR ANALYSIS; OPTIMUM IMAGING GEOMETRY; VISION-BASED VEHICLE TRACKING	NAVIGATION	When a camera is used to provide the navigational parameters in autonomous vehicle operations, it is subjected to unexpected movements or vibrations of the mounting platform. This paper presents a framework for analyzing the effect of uncontrollable camera movements on the navigational parameters, in particular on the range and heading angle in vision-based vehicle tracking. The noise introduced by the platform movements is modeled in two ways: camera noise approach and image noise approach. The parameter space of the camera is divided into a controllable subspace consisting of its height and depression angle, and an uncontrollable subspace consisting of the tracked object coordinates and rotation angle errors. A consistent detectable region is then obtained such that the tracked object is always seen by the camera. Based on this region, a reliable region consisting of no singularity points is established so that the range error does not become infinity. The optimum parameters of the controllable subspace with respect to the uncontrollable subspace are found by employing two estimation schemes: (a) The mini-max estimator to provide the worst case effect, and (b) the minimum-mean-square estimator to provide the average or overall effect. From the results obtained, it is shown how an optimum imaging geometry of a monocular vision-based tracking system can be designed in order to satisfy prescribed levels of range and heading angle errors.						Sohn, Won/0000-0001-9731-3107				BLOSTEIN SD, 1987, IEEE T PATTERN ANAL, V9, P752, DOI 10.1109/TPAMI.1987.4767982; BOX MJ, 1965, COMPUT J, V8, P42, DOI 10.1093/comjnl/8.1.42; GUIN JA, 1968, COMPUT J, V10, P416, DOI 10.1093/comjnl/10.4.416; KEHTARNAVAZ N, 1991, IEEE T VEH TECHNOL, V40, P654, DOI 10.1109/25.97520; KEHTARNAVAZ N, 1990, APR P SPIE S IM PROC; KUAN D, 1988, IEEE T PATTERN ANAL, V10, P648, DOI 10.1109/34.6773; MCVEY ES, 1982, IEEE T PATTERN ANAL, V4, P646, DOI 10.1109/TPAMI.1982.4767319; PRESS WH, 1988, NUMERICAL RECIPES C, P111; SCHALKOFF RJ, 1989, DIGITAL IMAGE PROCES, P30; SOHN W, 1993, THESIS A M U TEXAS; THORPE C, 1988, IEEE T PATTERN ANAL, V10, P362, DOI 10.1109/34.3900; TURK MA, 1988, IEEE T PATTERN ANAL, V10, P342, DOI 10.1109/34.3899; VEATCH PA, 1990, COMPUT VISION GRAPH, V50, P50, DOI 10.1016/0734-189X(90)90067-6	13	6	6	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1995	17	1					57	61		10.1109/34.368152	http://dx.doi.org/10.1109/34.368152			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QB394					2022-12-18	WOS:A1995QB39400006
J	CAGLIOTI, V				CAGLIOTI, V			UNCERTAINTY MINIMIZATION IN THE LOCALIZATION OF POLYHEDRAL OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter								A straightforward method is presented for the determination of the optimal sensor exploration in the localization of a polyhedral object, whose geometry is known. Optimality is intended in the sense of the a posteriori covariance matrix of the object position and orientation parameters. The method consists in decomposing the problem into simpler subproblems, eachone relative to a single planar face of the object. It requires reasonable processing time, i.e., comparable with the sensor activation time.			CAGLIOTI, V (corresponding author), POLITECN MILAN,DEPT ELECTR & INFORMAT,ARTIFICIAL INTELLIGENCE & ROBOT PROJECT,I-20133 MILAN,ITALY.			Caglioti, Vincenzo/0000-0003-2741-7474				BROOKS RA, 1985, IEEE T SYSTEMS MAN C, V15; CAMERON A, 1990, INT J ROBOTICS RES, V9; DURRANTWHITE H, 1988, IEEE T ROBOTICS AUTO, V4; GIGUS Z, 1990, IEEE T PATTERN ANAL, V12; HUTCHINSON SA, 1989, IEEE T ROBOTICS AUTO, V5; Meier L., 1967, IEEE T AUTOMATIC CON, V12; MULLER PC, 1972, AUTOMATICA, V8; Paul R. P., 1981, ROBOT MANIPULATORS M; Schweppe F.C., 1973, UNCERTAIN DYNAMIC SY; WHAITE P, 1991, IEEE T PATTERN ANAL, V13	10	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					524	530		10.1109/34.291444	http://dx.doi.org/10.1109/34.291444			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141					2022-12-18	WOS:A1994NP14100009
J	JONES, R; SVALBE, I				JONES, R; SVALBE, I			MORPHOLOGICAL FILTERING AS TEMPLATE MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						BINARY MORPHOLOGY; MORPHOLOGICAL BASIS DECOMPOSITION; PARALLEL PROCESSING; TEMPLATE MATCHING	MULTIPLE STRUCTURING ELEMENTS; DESIGN; IMAGE	Binary morphological operations using single and multiple structuring elements are implemented using look-up table (LUT) driven templates. Many complex operations can be implemented in one pipeline processing cycle for 3*3 regions of support and in four or five cycles for 5*5 regions of support. The basis representation of the operations is used to specify the required templates.			JONES, R (corresponding author), MONASH UNIV,DEPT PHYS,CLAYTON,VIC 3168,AUSTRALIA.							CRIMMINS TR, 1985, IEEE T AERO ELEC SYS, V21, P60, DOI 10.1109/TAES.1985.310539; JONES R, 1992, PATTERN RECOGN LETT, V13, P175, DOI 10.1016/0167-8655(92)90057-7; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P586, DOI 10.1109/34.24793; Matheron G., 1975, RANDOM SETS INTEGRAL; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; SONG JS, 1990, COMPUT VISION GRAPH, V50, P308, DOI 10.1016/0734-189X(90)90150-T; SVALBE I, 1992, PATTERN RECOGN LETT, V13, P123, DOI 10.1016/0167-8655(92)90043-Y; SVALBE ID, 1989, IEEE T PATTERN ANAL, V11, P941, DOI 10.1109/34.35497; SVALBE ID, 1991, IEEE T PATTERN ANAL, V13, P1214; [No title captured]; [No title captured]; [No title captured]	13	6	7	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1994	16	4					438	443		10.1109/34.277599	http://dx.doi.org/10.1109/34.277599			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NH607					2022-12-18	WOS:A1994NH60700012
J	MANHAEGHE, C; LEMAHIEU, I; VOGELAERS, D; COLARDYN, F				MANHAEGHE, C; LEMAHIEU, I; VOGELAERS, D; COLARDYN, F			AUTOMATIC INITIAL ESTIMATION OF THE LEFT-VENTRICULAR MYOCARDIAL MIDWALL IN EMISSION TOMOGRAMS USING KOHONEN MAPS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CONTOUR DETECTION; MYOCARDIUM; QUANTIFICATION; NEURAL NETWORKS; KOHONEN MAPS; EMISSION TOMOGRAPHY	IMAGES	A new method to make an automatic initial estimation of the position of the middle of the left ventricular (LV) myocardial wall (LV myocardial midwall) in emission tomograms is presented. This method eliminates the manual interaction still required by other, more accurate LV delineation algorithms, and which consists of indicating the LV long axis and/or the LV extremities. A well-known algorithm from the world of neural networks, Kohonen's self-organizing maps, was adapted to use general shapes and to behave well for data with large background noise.	STATE UNIV GHENT HOSP,DEPT INTENS CARE,B-9000 GHENT,BELGIUM	Ghent University; Ghent University Hospital	MANHAEGHE, C (corresponding author), STATE UNIV GHENT,DEPT ELECTR & INFORMAT SYST,B-9000 GHENT,BELGIUM.		Lemahieu, Ignace/G-8625-2012	Lemahieu, Ignace/0000-0002-0894-9988				[Anonymous], 1989, SPRINGER SERIES INFO; CHNG W, 1989, CARDIAC PHANTOM USER; COHEN I, 1992, CVGIP-IMAG UNDERSTAN, V56, P242, DOI 10.1016/1049-9660(92)90041-Z; FABER TL, 1991, IEEE T MED IMAGING, V10, P321, DOI 10.1109/42.97581; GARCIA EV, 1985, J NUCL MED, V26, P17; HE ZX, 1991, J NUCL MED, V32, P1794; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; MANHAEGHE C, 1992, SIGNAL PROCESS, V6, P1725; NUYTS J, 1991, IEEE T MED IMAGING, V10, P489, DOI 10.1109/42.108582; NUYTS J, 1991, THESIS U LEUVEN BELG, P188; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; REIJS AEM, 1987, COMPUT CARDIOL, P279; THIELEMANS K, 1990, 1990 P N SEA C BIOM; UDUPA JK, 1991, 3D IMAGING MED, P1	16	6	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1994	16	3					259	266		10.1109/34.276125	http://dx.doi.org/10.1109/34.276125			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NF114					2022-12-18	WOS:A1994NF11400006
J	KULKARNI, SR; MITTER, SK; TSITSIKLIS, JN; ZEITOUNI, O				KULKARNI, SR; MITTER, SK; TSITSIKLIS, JN; ZEITOUNI, O			PAC LEARNING WITH GENERALIZED SAMPLES AND AN APPLICATION TO STOCHASTIC GEOMETRY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CURVES; GENERALIZED SAMPLES; LEARNING; PAC MODEL; STOCHASTIC GEOMETRY		In this paper, we introduce an extension of the standard probably approximately correct (PAC) learning model, which allows the use of generalized samples. We view a generalized sample as a pair consisting of a functional on the concept class together with the value obtained by the functional operating on the unknown concept. It appears that this model can be applied to a number of problems in signal processing and geometric reconstruction to provide sample size bounds under a PAC criterion. We consider a specific application of the generalized model to a problem of curve reconstruction and discuss some connections with a result from stochastic geometry.	MIT,INFORMAT & DECIS SYST LAB,CAMBRIDGE,MA 02139; MIT,LINCOLN LAB,LEXINGTON,MA 02173; MIT,DEPT ELECT ENGN & COMP SCI,CAMBRIDGE,MA 02139; TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,HAIFA,ISRAEL	Massachusetts Institute of Technology (MIT); Lincoln Laboratory; Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Technion Israel Institute of Technology			ZEITOUNI, OFER/K-1539-2012; zeitouni, ofer/O-7764-2019; zeitouni, ofer/A-5918-2013	ZEITOUNI, OFER/0000-0002-2520-1525; zeitouni, ofer/0000-0002-2520-1525; zeitouni, ofer/0000-0002-2520-1525				ABE N, 1990, 3RD P WORKSH COMP LE, P52; ALEXANDROV AD, 1989, GENREAL THEORY IRREG, V29; BADDELEY AJ, 1986, CWI MONOGRAPHS; BENEDEK GM, 1988, 1ST P WORKSH COMP LE, P80; BLUMER A, 1986, 18TH P ACM S THEOR C, P273; DUDLEY RM, 1978, ANN PROBAB, V6, P899, DOI 10.1214/aop/1176995384; HAUSSLER D, 1992, INFORM COMPUT, V100, P78, DOI 10.1016/0890-5401(92)90010-D; KARL WC, 1991, THESIS MASS I TECHNO; KULKARNI SR, 1991, THESIS MASS I TECHNO; KULKARNI SR, 1989, CICSP160 MIT CENT IN; LELE AS, 1990, SPIE P LASER RADAR 5, V1222, P58; MORAN PAP, 1966, BIOMETRIKA, V53, P359; Pollard David, 1984, CONVERGENCE STOCHAST; PRINCE JL, 1990, IEEE T PATTERN ANAL, V12, P377, DOI 10.1109/34.50623; RICHARDSON TJ, 1992, IN PRESS; Santalo L. A., 1976, Integral geometry and geometric probability; SHERMAN S, 1942, DUKE MATH J, V9, P1; SKIENA SS, 1988, UIUCDCSR881425 U ILL; STEINHAUS H., 1954, C MATH, VIII, P1, DOI DOI 10.4064/CM-3-1-1-13; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V., 1982, ESTIMATION DEPENDENC; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; WAHBA G, 1990, SERIES APPLIED MATH, V59	23	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					933	942		10.1109/34.232080	http://dx.doi.org/10.1109/34.232080			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600007
J	KESHAVAN, HR; BARNETT, J; GEIGER, D; VERMA, T				KESHAVAN, HR; BARNETT, J; GEIGER, D; VERMA, T			INTRODUCTION TO THE SPECIAL SECTION ON PROBABILISTIC REASONING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,HAIFA,ISRAEL	Technion Israel Institute of Technology	KESHAVAN, HR (corresponding author), NORTHROP CORP,AUTOMAT SCI LAB,HAWTHORNE,CA 90250, USA.							Howard RA, 1984, PRINCIPLES APPL DECI, P720; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Neapolitan R.E., 1990, PROBABILISTIC REASON; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4	4	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					193	195						3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800001
J	SAITTA, L; BERGADANO, F				SAITTA, L; BERGADANO, F			PATTERN-RECOGNITION AND VALIANTS LEARNING FRAMEWORK	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTATIONAL LEARNING THEORY; INDUCTION OF BOOLEAN CLASSIFIERS; INDUCTIVE INFERENCE; PROBABILITY OF ERROR; VAPNIK-CHERVONENKIS INEQUALITY	ERROR	The computational learning approach shows that the concept descriptions acquired from examples are approximately correct with a degree of probability that grows with the size of the training sample. On the other hand, the same problem has been widely investigated in the field of pattern recognition under a variety of problem settings. This paper surveys and compares some of the results obtained in both fields and analyzes the limits of their applicability. Moreover, new and tighter bounds for the growth function of some classes of Boolean formulas are presented.	UNIV CATANIA, DIPARTIMENTO MATEMAT, I-95124 CATANIA, ITALY	University of Catania	SAITTA, L (corresponding author), UNIV TURIN, DIPARTIMENTO INFORMAT, I-10124 TURIN, ITALY.		bergadano, francesco/Q-2879-2019	BERGADANO, Francesco/0000-0003-2567-336X				Angluin D., 1988, Machine Learning, V2, P319, DOI 10.1023/A:1022821128753; [Anonymous], 1974, HDB MATH FUNCTIONS; BERGADANO F, 1988, IEEE T PATTERN ANAL, V10, P555, DOI 10.1109/34.3917; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154, DOI 10.1109/TPAMI.1982.4767222; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P1087, DOI 10.1109/34.42839; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; HAUSSLER D, 1988, MACHINE LEARNING; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; PEARL J, 1978, INT J GEN SYST, V4, P255, DOI 10.1080/03081077808960690; PEARL J, 1979, IEEE T PATTERN ANAL, V1, P350, DOI 10.1109/TPAMI.1979.4766943; PIPPENGER N, 1977, MATH SYST THEORY, V10, P124; Raudys S, 1980, IEEE Trans Pattern Anal Mach Intell, V2, P242, DOI 10.1109/TPAMI.1980.4767011; Sturt E., 1981, Applied Statistics, V30, P213, DOI 10.2307/2346344; TOUSSAINT GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; USPENSKY JV, 1974, INTRO MATH PROBABILI; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V., 1982, ESTIMATION DEPENDENC; VAPNIK VN, 1981, THEOR PROBAB APPL+, V26, P532; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Watanabe S., 1969, KNOWING GUESSING	25	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					145	155		10.1109/34.192486	http://dx.doi.org/10.1109/34.192486			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KL910					2022-12-18	WOS:A1993KL91000005
J	LI, ZC; SUEN, CY; BUI, TD; TANG, YY; GU, QL				LI, ZC; SUEN, CY; BUI, TD; TANG, YY; GU, QL			SPLITTING-INTEGRATING METHOD FOR NORMALIZING IMAGES BY INVERSE TRANSFORMATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CHARACTER RECOGNITION; DISTORTED IMAGE AND PATTERN; INVERSE TRANSFORMATION; NONLINEAR TRANSFORMATION; NORMALIZATION; PATTERN RECOGNITION; SHAPE TRANSFORMATION; SPLITTING-INTEGRATING METHOD; SPLITTING-SHOOTING METHOD	PATTERNS	The splitting-integrating method is a new technique developed for the normalization of images by the inverse transformations. This new method does not require solving nonlinear algebraic equations and is much simpler than any existing algorithms for the inverse nonlinear transformations. Moreover, its solutions have a high order of convergence, and the images obtained through T-1 are free from superfluous holes and blanks, which often occur in transforming digitized images by other approaches. Application of the splitting-integrating method can be extended to supersampling in computer graphics, such as picture transformations by antialiasing, inverse nonlinear mapping, etc.			LI, ZC (corresponding author), CONCORDIA UNIV,CTR PATTERN RECOGNIT & MACHINE INTELLIGENCE,DEPT COMP SCI,MONTREAL H3G 1M8,QUEBEC,CANADA.							Burden RL, 1981, NUMERICAL ANAL; Catmull E., 1980, Computer Graphics, V14, P279, DOI 10.1145/965105.807505; Cialet P. G., 1978, FINITE ELEMENT METHO; CROW FC, 1981, IEEE CG A        JAN, P40; FANT KM, 1986, IEEE COMPUTER GR JAN, P71; Feibush E. A., 1980, Computer Graphics, V14, P294, DOI 10.1145/965105.807507; GONZALER RC, 1987, DIGITAL IMAGE PROCES; Gu Q. L., 1991, Computer Processing of Chinese & Oriental Languages, V5, P347; GU QL, 1991, 1991 P INT C COMP PR, P57; HAGEMAN LA, 1981, APPLIED ITERATIVE ME; Lang S., 1973, CALCULUS SEVERAL VAR; LEE SY, 1987, PATTERN RECOGN, V20, P115, DOI 10.1016/0031-3203(87)90022-7; Li Z. C., 1990, International Journal of Pattern Recognition and Artificial Intelligence, V4, P65, DOI 10.1142/S021800149000006X; LI ZC, 1990, IEEE T PATTERN ANAL, V12, P671, DOI 10.1109/34.56210; LI ZC, 1990, IEEE T SYST MAN CYB, V20, P858, DOI 10.1109/21.105085; LI ZC, 1990, PATTERN RECOGN, V23, P1249, DOI 10.1016/0031-3203(90)90120-A; LI ZC, 1990, 10TH INT C PATT REC, V2, P1; LI ZC, CVGIP GRAPHICAL MODE; MAX NL, 1990, IEEE CG A        JAN, P18; NALAW VS, 1988, INT J COMPUT VISION, V2, P18; Ortega J. M., 1970, ITERATIVE SOLUTION N, V30; Penna M.A., 1986, PROJECTIVE GEOMETRY; Tang YY, 1989, COMPUTER TRANSFORMAT; WOLBERG G, 1989, COMPUT GRAPH, P369	25	6	6	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1992	14	6					678	686		10.1109/34.141558	http://dx.doi.org/10.1109/34.141558			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HX546					2022-12-18	WOS:A1992HX54600009
J	ULLMANN, JR				ULLMANN, JR			ANALYSIS OF 2-D OCCLUSION BY SUBTRACTING OUT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						COMPUTER VISION; IMAGE MATCHING; OBJECT RECOGNITION; OCCLUSION ANALYSIS; SEGMENTATION	TWO-DIMENSIONAL OBJECTS	This correspondence introduces a provably correct polynomial-time algorithm for complete systematic analysis of occlusion in synthetically generated noise-free pictures of 2-D objects. The algorithm first recognizes occluding objects and then ignores the mismatch with pixels in occluding objects while recognizing occluded objects by template matching.			ULLMANN, JR (corresponding author), UNIV LONDON KINGS COLL,DEPT COMP,LONDON WC2R 2LS,ENGLAND.							AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P137, DOI 10.1109/TPAMI.1984.4767499; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; COOPER MC, 1988, PATTERN RECOGN LETT, V7, P259, DOI 10.1016/0167-8655(88)90111-0; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; KOCH MW, 1987, IEEE T PATTERN ANAL, V9, P483, DOI 10.1109/TPAMI.1987.4767936; ULLMANN JR, 1983, COMPUT VISION GRAPH, V22, P194, DOI 10.1016/0734-189X(83)90101-9; ULLMANN JR, 91105 KINGS COLL DEP; ULLMANN JR, 1983, PHYSICAL BIOL PROCES, P15	9	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1992	14	4					485	488		10.1109/34.126808	http://dx.doi.org/10.1109/34.126808			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HL193					2022-12-18	WOS:A1992HL19300006
J	JASINSCHI, RS				JASINSCHI, RS			INTRINSIC CONSTRAINTS IN SPACE-TIME FILTERING - A NEW APPROACH TO REPRESENTING UNCERTAINTY IN LOW-LEVEL VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CRAMER-RAO BOUND; ENERGY FILTERS; ESTIMATION ERROR; LOW-LEVEL VISION; OPTICAL FLOW; PARAMETER ESTIMATION; SAMPLING THEOREM	APPARENT MOTION; VISUAL-CORTEX; TEXTURE; CELLS	This paper describes how, in the process of extracting the optical flow through space-time filtering, we have to take into account constraints associated with the motion uncertainty, as well as the spatial and temporal sampling rates of the sequence of images. The motion uncertainty satisfies the Cramer-Rao (CR) inequality, which is shown to be a function of the filter parameters. On the other hand, the spatial and temporal sampling rates have a lower bound, which depend on the motion uncertainty, the maximum support in the frequency domain, and the optical flow. These lower bounds on the sampling rates and on the motion uncertainty are constraints that constitute an intrinsic part of the computational structure of space-time filtering. We show that if we use these constraints simultaneously, the filter parameters cannot be arbitrarily determined but instead have to satisfy consistency constraints. This represents a novel point of view in low-level vision in which, by making use of explicit representations of uncertainties in the extraction of visual attributes, we are able to constrain the range of values assumed by the filter parameters.			JASINSCHI, RS (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; AHUMADA A, 1985, J OPT SOC AM, V2, P322; AHUMADA AJ, 1983, NASA84352 TECH MEM; Amari S.-i., 1985, DIFFERENTIAL GEOMETR, V28; ANSTIS SM, 1980, PHILOS T ROY SOC B, V290, P153, DOI 10.1098/rstb.1980.0088; ARSENYN AN, 1977, SOLUTION ILL POSED P; Bracewell R, 1986, PENTAGRAM NOTATION C, V2nd, P192; BRADDICK O, 1974, VISION RES, V14, P519, DOI 10.1016/0042-6989(74)90041-8; BRADDICK OJ, 1981, PHIL T R SOC LOND B, P137; CHANG JJ, 1983, VISION RES, V23, P1379, DOI 10.1016/0042-6989(83)90149-9; CRICK FHC, 1980, MIT557 ART INT LAB M; DAUGMAN JG, 1983, IEEE T SYST MAN CYB, V13, P882, DOI 10.1109/TSMC.1983.6313083; DAVIS LS, 1983, COMPUT VISION GRAPH, V23, P313, DOI 10.1016/0734-189X(83)90029-4; DURIC Z, 1991, CARTR560 U MARYL TEC; FAHLE M, 1981, P ROY SOC LOND B BIO, V213, P415; FLEET DJ, 1985, RBCVTR858 U TOR TECH; GRZYWACZ NM, 1990, PROC R SOC SER B-BIO, V239, P129, DOI 10.1098/rspb.1990.0012; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HEEGER DJ, 1987, J OPT SOC AM A, V4, P1455, DOI 10.1364/JOSAA.4.001455; Hildreth E., 1984, MEASUREMENT VISUAL M; HOLUB RA, 1981, J NEUROPHYSIOL, V46, P1244, DOI 10.1152/jn.1981.46.6.1244; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Jasinschi R. S., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P428, DOI 10.1109/CCV.1988.590019; Jasinschi R. S., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P139, DOI 10.1109/WVM.1989.47103; Jasinschi R. S., 1991, Journal of Visual Communication and Image Representation, V2, P222, DOI 10.1016/1047-3203(91)90024-A; JASINSCHI RS, 1991, BIOL CYBERN, V65, P515, DOI 10.1007/BF00204665; JASINSCHI RS, 1988, CMURITR889 CARN U TE; JASINSCHI RS, 1991, UNPUB PERCEPTUAL MOT; JULESZ B, 1981, NATURE, V290, P97; Korte A., 1915, Z PSYCHOL, V72, P193; KULIKOWSKI JJ, 1982, BIOL CYBERN, V43, P187, DOI 10.1007/BF00319978; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; Marr D., 1981, VISION; NAKAYAMA K, 1984, VISION RES, V24, P293, DOI 10.1016/0042-6989(84)90054-3; NAKAYAMA K, 1985, VISION RES, V25, P625, DOI 10.1016/0042-6989(85)90171-3; Neuhaus W, 1930, ARCH GESAMTE PSYCHOL, V75, P315; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POGGIO T, 1989, MIT1140 ART INT LAB; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969; Siebert W., 1986, CIRCUITS SIGNALS SYS; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; Van Trees H., 2013, DETECTION ESTIMATION; VERRI A, 1987, 1ST P INT C COMP VIS, P171; VOORHEES H, 1988, NATURE, V333, P364, DOI 10.1038/333364a0; WAHBA G, 1985, J COMPUT PHYS, V59, P441; YOUNG G, 1991, CARTR558 U MARYL TEC	48	6	6	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1992	14	3					353	366		10.1109/34.120330	http://dx.doi.org/10.1109/34.120330			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HF732					2022-12-18	WOS:A1992HF73200005
J	WEINSHALL, D				WEINSHALL, D			DIRECT COMPUTATION OF QUALITATIVE 3-D SHAPE AND MOTION INVARIANTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						FOCUS OF EXPANSION; GAUSSIAN CURVATURE; MOTION; QUALITATIVE VISION; STRUCTURE FROM MOTION; SURFACE CLASSIFICATION	OBJECTS	Structure from motion often refers to the computation of 3-D structure from a matched sequence of images. However, a depth map of a surface is difficult to compute and may not be a good representation for storage and recognition. Given matched images, this correspondence will show that the sign of the normal curvature in a given direction at a given point in the image can be computed from a simple difference of slopes of line segments in one image. Using this result, local surface patches can be classified as convex, concave, cylindrical, hyperbolic (saddle point) or planar. At the same time, the translational component of the optical flow is obtained, from which the focus of expansion can be computed.			WEINSHALL, D (corresponding author), MIT,CTR BIOL INFORMAT PROC,CAMBRIDGE,MA 02139, USA.							BLAKE A, 1989, SHAPE SHADING, P29; KOENDERINK JJ, 1982, PERCEPTION, V11, P129, DOI 10.1068/p110129; KOENDERINK JJ, 1976, J OPT SOC AM, V66, P717, DOI 10.1364/JOSA.66.000717; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; NELSON RC, 1990, JUL AAAI 90 WORKSH Q, P16; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; ULLMAN S, 1983, HUMAN MACHINE; WEINSHALL D, 1989, AI1131 MIT ART INT L; [No title captured]	10	6	6	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1991	13	12					1236	1240		10.1109/34.106997	http://dx.doi.org/10.1109/34.106997			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GT950					2022-12-18	WOS:A1991GT95000004
J	KUNO, Y; OKAMOTO, Y; OKADA, S				KUNO, Y; OKAMOTO, Y; OKADA, S			ROBOT VISION USING A FEATURE SEARCH STRATEGY GENERATED FROM A 3-D OBJECT MODEL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						AUTOMATIC STRATEGY GENERATION; MODEL-BASED VISION; OBJECT RECOGNITION; ROBOT; 3-D MODEL	RECOGNITION; IMAGES	This paper presents a robot vision system that automatically generates an object recognition strategy from a 3-D model and recognizes the object using this strategy. In this system, the appearance of an object from various viewpoints is described in terms of visible 2-D features such as parallel lines and ellipses. Features are then ranked according to the number of viewpoints from which they are visible. The rank and feature extraction cost of each feature are used to generate a tree-like strategy graph. This graph gives an efficient feature search order when the viewpoint is unknown, starting with commonly occurring features and ending with features specific to a certain viewpoint. The system searches for features in the order indicated by the graph. After detection, the system compares a line representation generated from the 3-D model with the image features to localize the object. Perspective projection is used in the localization process to obtain the precise position and attitude of the object, whereas orthographic projection is used in the strategy generation process to allow symbolic manipulation. Experimental results verify the efficiency and robustness of the system.	TOSHIBA CO LTD,NUCL ENGN LAB,KAWASAKI 210,JAPAN	Toshiba Corporation	KUNO, Y (corresponding author), TOSHIBA CO LTD,CTR RES & DEV,KAWASAKI 210,JAPAN.		Kuno, Yoshinori/B-3014-2012	Kuno, Yoshinori/0000-0001-9719-9367				BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; COWAN CK, 1984, DEC P AI APPL DENV, P176; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; GOAD C, 1983, JUN P IM UND WORKSH, P94; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; Hansen C., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P275, DOI 10.1109/CCV.1988.590000; HONG KS, 1989, 5 INT S ROB RES, P164; HORAUD R, 1987, IEEE T PATTERN ANAL, V9, P401, DOI 10.1109/TPAMI.1987.4767922; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; ISHIKAWA M, 1988, MAR SPRING NAT CONV, P2; Lamdan Y., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P238, DOI 10.1109/CCV.1988.589995; LOWE DG, 1987, INT J COMPUT VISION, V1, P57, DOI 10.1007/BF00128526; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MARR D, 1978, TECHNOL REV, V81, P2; OKAMOTO Y, 1988, OCT P IAPR WORKSH CO, P441; OKAMOTO Y, 1990, 19TH P IECON 90 ANN, P558; PONCE J, 1989, NOV P IEEE WORKSH IN, P61; SHOHAM D, 1988, DEC P ICCV TAMP, P259	21	6	8	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1991	13	10					1085	1097		10.1109/34.99241	http://dx.doi.org/10.1109/34.99241			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GM763					2022-12-18	WOS:A1991GM76300010
J	CHEN, HH; HUANG, TS				CHEN, HH; HUANG, TS			USING MOTION FROM ORTHOGRAPHIC VIEWS TO VERIFY 3-D POINT MATCHES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MOTION CONSTRAINT; POINT MATCHING; ORTHOGRAPHIC VIEWS; RIGIDITY CONSTRAINT	ORIENTATION	Identifying the correspondences between points is an important task. It finds applications in computer vision, photogrammetry, and robotics. An effective approach is to use the rigidity constraint on the distances between points and the angles between lines joining the points. However, the rigidity constraint is unable to disambiguate the true match of a point from the false matches when the underlying isotropic error approximation breaks down. In this paper, we present a new method for solving the problem. The method is based on the technique of motion analysis using orthographic views. It discards the noisy z (depth) coordinate and uses only the x and y coordinates of the points to verify a match. The effect of depth errors on the motion estimate is completely prevented. Results show that this method is substantially more effective than previous methods that use all three coordinates.	UNIV ILLINOIS, COORDINATED SCI LAB, URBANA, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	CHEN, HH (corresponding author), AT&T BELL LABS, INFORMAT SYSYT RES LAB, TECH STAFF, HOLMDEL, NJ 07033 USA.			Chen, Homer/0000-0002-8795-1911				ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; BAIRD H, 1986, MODEL BASED IMAGE MA; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; BURR DJ, 1977, R805 U ILL COORD SCI; Chen H. H., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P290, DOI 10.1109/WVM.1989.47121; CHEN HH, 1988, PATTERN RECOGN, V21, P75, DOI 10.1016/0031-3203(88)90016-7; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FAUGERAS OD, 1987, IEEE T ROBOTIC AUTOM, P1433; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; KIM YC, 1987, IEEE T ROBOTIC AUTOM, V3, P599; MATTHIES L, 1987, IEEE T ROBOTIC AUTOM, V3, P239, DOI 10.1109/JRA.1987.1087097; RANADE S, 1980, PATTERN RECOGN, V12, P269, DOI 10.1016/0031-3203(80)90067-9; Roberts L, 1965, MACHINE PERCEPTION 3; SHUSTER MD, 1978, P AIAA GUID CONTR C, P88; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; Young G.-S., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P710, DOI 10.1109/CVPR.1988.196312; [No title captured]	19	6	7	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1991	13	9					872	878		10.1109/34.93806	http://dx.doi.org/10.1109/34.93806			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GJ180					2022-12-18	WOS:A1991GJ18000002
J	VEIJANEN, A				VEIJANEN, A			A SIMULATION-BASED ESTIMATOR FOR HIDDEN MARKOV RANDOM-FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ESTIMATION; IMAGE ANALYSIS; MARKOV RANDOM FIELD; PSEUDOLIKELIHOOD; SIMULATION	GIBBS RANDOM-FIELDS; STATISTICAL-ANALYSIS; IMAGES; SEGMENTATION	A new estimator is introduced for estimating the parameters of a Markov random field X from inaccurate observations. The marginal distributions of (X(i, j,) X(i+u,j+v))(u, v = -1, 0, 1) are first estimated from an image. Then, random fields X* are simulated with the probability of X(i,j)* = a and X(i+u,j+v)* = b nearly equal to the estimate of P{X(i,j) = a, X(i+u,j+v) = b}. A simulation method similar to the Gibbs sampler is used. The parameters of the Markov random field model are estimated from the X*'s with the pseudolikelihood method.			VEIJANEN, A (corresponding author), UNIV HELSINKI,DEPT STAT,SF-00100 HELSINKI 10,FINLAND.							ALMEIDA MP, 1990, VARIATIONAL METHOD E; ANDERSON LS, 1988, 117 DEP STAT U WASH; BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782; BESAG J, 1986, J R STAT SOC B, V48, P259; CHALMOND B, 1989, PATTERN RECOGN, V22, P747, DOI 10.1016/0031-3203(89)90011-3; COMETS F, 1990, PARAMETER ESTIMATION; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; Ganan Stuart, 1985, P STAT COMP SECT AM, P12; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRENANDER U, 1989, ANN STAT, V17, P1, DOI 10.1214/aos/1176347002; GRENANDER U, 1983, TUTORIAL PATTERN THE; HASLETT J, 1985, PATTERN RECOGN, V18, P287, DOI 10.1016/0031-3203(85)90054-8; HJORT NL, 1985, CONTEXTUAL CLASSIFIC; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; OSSOLO A, 1986, ESTIMATION BINARY MA; PENTTINEN A, 1984, JYVASKYLA STUDIES, V7; PIECZYNSKI W, 1989, APPL STAT, V16, P283; QIAN W, 1989, APPL STAT, V16, P267; Ripley B.D., 1987, STOCHASTIC SIMULATIO; RIPLEY BD, 1986, CAN J STAT, V14, P83, DOI 10.2307/3314656; RIPLEY BD, 1988, STATISTICAL INFERENC; VEIJANEN A, 1989, 9 TIL TUTK FINN STAT; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; [No title captured]	25	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					825	830		10.1109/34.85674	http://dx.doi.org/10.1109/34.85674			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642					2022-12-18	WOS:A1991GC64200009
J	WOHN, KY; WU, J; BROCKETT, RW				WOHN, KY; WU, J; BROCKETT, RW			A CONTOUR-BASED RECOVERY OF IMAGE FLOW - ITERATIVE TRANSFORMATION METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; IMAGE MOTION ESTIMATION; ERROR ANALYSIS; IMAGE FLOWS; STRUCTURE FROM MOTION	OPTICAL-FLOW; MOTION; SEGMENTATION; DEFORMATION	We present an interative algorithm for the recovery of 2-D motion, i.e., an algorithm for the determination of a transformation that maps one image onto another. The local ambiguity in measuring the motion of contour segments (called the "aperture problem") forces us to rely on measurements along the normal direction. Since the measured "normal flow" itself does not agree with the actual normal flow, the "full flow" recovered from this erroneous normal flow also possesses substantial error, and any attempt to recover the 3-D motion from such full flow is doomed to failure. Our method is based on the observation that a polynomial approximation of the image flow provides sufficient information for 3-D motion computation. The use of an explicit flow model enables us to improve normal flow estimates through an iterative process. We discuss the adequacy and the convergence of the proposed algorithm. The algorithm has been tested on some synthetic and some simple natural time-varying images. The image flow recovered from this scheme was sufficiently accurate to be useful in 3-D structure and motion computation.	UNIV PENN,DEPT COMP & INFORMAT SCI,PHILADELPHIA,PA 19104; HARVARD UNIV,DIV APPL SCI,CAMBRIDGE,MA 02138	University of Pennsylvania; Harvard University			Wohn, Kwangyun/C-2013-2011	Wohn, Kwangyun/0000-0003-1373-8816				ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ANANDAN P, 1987, MAY INT C COMP VIS L, P219; BROCKETT R, 1990, J VISUAL COMMUN IMAG, V1, P1; BURT PJ, 1982, JUN P IEEE C COMP VI, P269; CARLSSON S, 1986, THESIS ROYAL I TECHN; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; HEEGER DJ, 1987, 1ST P INT C COMP VIS, P181; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; Limb J. O., 1975, Computer Graphics and Image Processing, V4, P311, DOI 10.1016/0146-664X(75)90001-5; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MARR D, 1981, PROC R SOC SER B-BIO, V211, P151, DOI 10.1098/rspb.1981.0001; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; SCHUNCK BG, 1989, IEEE T PATTERN ANAL, V11, P1010, DOI 10.1109/34.42834; SCHUNCK BG, 1986, COMPUT VISION GRAPH, V35, P20, DOI 10.1016/0734-189X(86)90124-6; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WOHN K, 1990, COMPUT VISION GRAPH, V49, P127, DOI 10.1016/0734-189X(90)90134-H; WOHN K, 1986, AAAI, P670; WOHN K, 1990, SPATIO TEMPORAL MULT; WU J, 1988, MSCIS8891 U PENNS CO	24	6	7	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					746	760		10.1109/34.85666	http://dx.doi.org/10.1109/34.85666			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642					2022-12-18	WOS:A1991GC64200001
J	KANADE, T; IKEUCHI, K				KANADE, T; IKEUCHI, K			INTRODUCTION TO THE SPECIAL ISSUE ON PHYSICAL MODELING IN COMPUTER VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									CARNEGIE MELLON UNIV,ROBOT PHD PROGRAM,PITTSBURGH,PA 15213; CARNEGIE MELLON UNIV,SCH COMP SCI,PITTSBURGH,PA 15213	Carnegie Mellon University; Carnegie Mellon University	KANADE, T (corresponding author), CARNEGIE MELLON UNIV,INST ROBOT,PITTSBURGH,PA 15213, USA.							HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; KANADE T, 1991, CARNEGIEMELLON COMPU, P345; MARR D, 1971, VISION	3	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1991	13	7					609	610						2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GA139					2022-12-18	WOS:A1991GA13900001
J	SNYDER, MA				SNYDER, MA			THE PRECISION OF 3-D PARAMETERS IN CORRESPONDENCE-BASED TECHNIQUES - THE CASE OF UNIFORM TRANSLATIONAL MOTION IN A RIGID ENVIRONMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SNYDER, MA (corresponding author), UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,AMHERST,MA 01003, USA.							ADIV G, 1985, THESIS U MASSACHUSET; BHARWANI S, 1985, DEC DARPA I U WORKSH; BLOSTEIN SD, 1987, 1ST P INT COMP VIS L; DURRANTWHYTE HF, 1986, INTEGRATION COORDINA; FANG JQ, 1984, IEEE T PATTERN ANAL, V6, P545, DOI 10.1109/TPAMI.1984.4767569; FAUGERAS O, 1986, APR P IEEE INT C ROB; GENNERY D, 1980, THESIS STANFORD; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MATTHIES L, 1986, CMUCS86140 TECH REP; Moravec H., 1980, THESIS STANFORD; SNYDER MA, UNPUB COMPUTATION DE; SNYDER MA, 1986, 8628 U MASS DEP COMP; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WAXMAN AM, 1985, CAR139 U MAR TECH RE; WAXMAN AM, 1985, CAR138 U MAR TECH RE	16	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1989	11	5					523	528		10.1109/34.24784	http://dx.doi.org/10.1109/34.24784			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U3604					2022-12-18	WOS:A1989U360400007
J	BESTUL, T; DAVIS, LS				BESTUL, T; DAVIS, LS			ON COMPUTING COMPLETE HISTOGRAMS OF IMAGES IN LOG (N) STEPS USING HYPERCUBES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											BESTUL, T (corresponding author), UNIV MARYLAND,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							HILLIS WD, 1986, COMMUN ACM, V29, P1170, DOI 10.1145/7902.7903; HILLIS WD, CONNECTION MACHINE; TANIMOTO SL, MULTIRESOLUTION IMAG, P136	3	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1989	11	2					212	213		10.1109/34.16717	http://dx.doi.org/10.1109/34.16717			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R9989					2022-12-18	WOS:A1989R998900010
J	FUHRMANN, DR				FUHRMANN, DR			QUADTREE TRAVERSAL ALGORITHMS FOR POINTER-BASED AND DEPTH-1ST REPRESENTATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									WASHINGTON UNIV,INST BIOMED COMP,ST LOUIS,MO 63130	Washington University (WUSTL)	FUHRMANN, DR (corresponding author), WASHINGTON UNIV,DEPT ELECT ENGN,ST LOUIS,MO 63130, USA.							GARGANTINI I, 1982, COMMUN ACM, V25; HUNTER GM, 1978, THESIS PRINCETON U P; KAWAGUCHI E, 1983, IEEE T PATTERN ANAL, V5; OLIVER M, 1983, COMPUT J, V26; Samet H., 1985, IEEE T PATTERN ANAL, V7; SAMET H, 1984, PATTERN RECOGNITION, V17; SAMET H, 1984, ACM COMPUT SURVEYS, V16	7	6	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					955	960		10.1109/34.9118	http://dx.doi.org/10.1109/34.9118			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100018
J	LIU, HH; YOUNG, TY; DAS, A				LIU, HH; YOUNG, TY; DAS, A			A MULTILEVEL PARALLEL PROCESSING APPROACH TO SCENE LABELING PROBLEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MIAMI, DEPT ELECT & COMP ENGN, CORAL GABLES, FL 33124 USA	University of Miami								Ballard D.H., 1982, COMPUTER VISION; HARALICK RM, 1980, IEEE T PATTERN ANAL, V2, P193, DOI 10.1109/TPAMI.1980.4767007; HARALICK RM, 1980, ARTIF INTELL, V14, P263, DOI 10.1016/0004-3702(80)90051-X; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HAYNES LS, 1982, COMPUTER, V15, P9, DOI [10.1109/MC.1982.1653823, 10.1109/MC.1982.1653822]; HWANG K, 1983, COMPUTER, V16, P10; LIU HH, 1985, P IEEE WORKSHOP COMP, P25; MACKWORTH AK, 1985, ARTIF INTELL, V25, P65, DOI 10.1016/0004-3702(85)90041-4; MCCALL JT, 1985, IEEE T COMPUT, V34, P973, DOI 10.1109/TC.1985.1676530; Mead C, 1980, INTRO VLSI SYSTEMS; NUDEL B, 1983, ARTIF INTELL, V21, P135, DOI 10.1016/S0004-3702(83)80008-3; REISIS D, 1985, P IEEE WORKSHOP COMP, P381; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; WAH BW, 1984, IEEE T COMPUT, V33, P377, DOI 10.1109/TC.1984.1676453; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19	15	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1988	10	4					586	590		10.1109/34.3919	http://dx.doi.org/10.1109/34.3919			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	P1493					2022-12-18	WOS:A1988P149300012
J	KALAYEH, HM; LANDGREBE, DA				KALAYEH, HM; LANDGREBE, DA			STOCHASTIC-MODEL UTILIZING SPECTRAL AND SPATIAL CHARACTERISTICS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											KALAYEH, HM (corresponding author), DUPONT CO,WILMINGTON,DE 19898, USA.							AKASHI H, 1979, AUTOMATICA, V15, P217, DOI 10.1016/0005-1098(79)90072-4; CRAIG RG, 1979, 13TH P INT S REM SEN, V3, P1517; CRAIG RG, 1980, 14TH P INT S REM SEN, V2, P1755; Kashyap R.L., 1976, DYNAMIC STOCHASTIC M; KASHYAP RL, 1974, IEEE T AUTOMAT CONTR, V19; LANDGREBE DA, 1978, MAY P IEEE COMP C PA; LANDGREBE DA, 1980, J PATTERN RECOGNITIO, V12, P16; Swain P.H., 1978, REMOTE SENSING QUANT; TUBBS JD, 1978, 12TH P INT S REM SEN, V2, P775; TUBBS JD, 1979, 13TH P INT S REM SEN, V3, P1499	10	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1987	9	3					457	461		10.1109/TPAMI.1987.4767928	http://dx.doi.org/10.1109/TPAMI.1987.4767928			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H0768	22516639				2022-12-18	WOS:A1987H076800011
J	KRISHNASWAMY, R; KIM, CE				KRISHNASWAMY, R; KIM, CE			DIGITAL PARALLELISM, PERPENDICULARITY, AND RECTANGLES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											KRISHNASWAMY, R (corresponding author), WASHINGTON STATE UNIV,DEPT COMP SCI,PULLMAN,WA 99164, USA.							ANDERSON TA, 1985, COMPUT VISION GRAPH, V30, P279, DOI 10.1016/0734-189X(85)90161-6; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P618, DOI 10.1109/TPAMI.1982.4767315; KIM CE, 1984, IEEE T PATTERN ANAL, V6, P372, DOI 10.1109/TPAMI.1984.4767531; KRISHNASWAMY R, 1985, CS84131 WASH STAT U; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845	7	6	6	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					316	321		10.1109/TPAMI.1987.4767905	http://dx.doi.org/10.1109/TPAMI.1987.4767905			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869401				2022-12-18	WOS:A1987G163300012
J	FUKUNAGA, K; FLICK, TE				FUKUNAGA, K; FLICK, TE			A TEST OF THE GAUSSIAN-NESS OF A DATA SET USING CLUSTERING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									USN,RES LAB,WASHINGTON,DC 20375	United States Department of Defense; United States Navy; Naval Research Laboratory	FUKUNAGA, K (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							BICKEL PJ, 1977, MATH STATISTICS BASI, pCH8; COX DR, 1978, BIOMETRIKA, V65, P263, DOI 10.2307/2335204; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P779, DOI 10.1109/TPAMI.1984.4767601; FUKUNAGA K, 1972, TREE7273 PURD U TECH; HAWKINS DM, 1981, TECHNOMETRICS, V23; MACHADO SG, 1983, BIOMETRIKA, V70, P713, DOI 10.2307/2336510; MCGILLEM CD, 1974, CONTINUOUS DISCRETE, P254; PATRICK EA, 1972, FUNDAMENTALS PATTERN, P341; ROYSTON JP, 1983, J R STAT SOC C-APPL, V32, P121; YOUNG IT, 1978, IEEE T INFORM THEORY, V24, P773, DOI 10.1109/TIT.1978.1055953	11	6	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					240	247		10.1109/TPAMI.1986.4767777	http://dx.doi.org/10.1109/TPAMI.1986.4767777			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869342				2022-12-18	WOS:A1986A107300011
J	NAGAHASHI, H; NAKATSUYAMA, M				NAGAHASHI, H; NAKATSUYAMA, M			A PATTERN DESCRIPTION AND GENERATION METHOD OF STRUCTURAL CHARACTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											NAGAHASHI, H (corresponding author), YAMAGATA UNIV,FAC ENGN ELECTR ENGN,JYONAN 4-3-16,YONEZAWA,YAMAGATA 992,JAPAN.							AGUI T, 1979, IEEE T PATTERN ANAL, V1, P333, DOI 10.1109/TPAMI.1979.4766941; AGUI T, 1979, IEEE T PATTERN ANAL, V1, P245, DOI 10.1109/TPAMI.1979.4766920; CHANG SK, 1973, IEEE T SYST MAN CYB, VSMC3, P257, DOI 10.1109/TSMC.1973.4309214; FU KS, 1974, SYNTACTIC METHOD PAT; FU KS, 1977, SYNTACTIC PATTERN RE, P1; FUJIMURA O, 1969, ANN B RES I LOGOPEDI, V3, P131; HUANG EM, 1983, OCT P INT C TEXT PRO, P292; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; nagahashi H., 1982, Transactions of the Institute of Electronics and Communication Engineers of Japan, Section E (English), VE65, P607; NAGAHASHI H, 1983, OCT P INT C TEXT PRO, P281; NISIMAKI M, 1978, J I ELECTRON COMMUN, V61, P111; OGAWA K, 1982, T I ELECTRON COMMU D, V65, P234; RANKIN BK, 1965, THESIS U PENNSYLVANI; RANKIN BK, 1966, NBS296 TECH NOT; STALLINGS W, 1975, COMPUT HUMANITIES, V9, P13, DOI 10.1007/BF02404316; Stallings W. W., 1977, SYNTACTIC PATTERN RE, P95	16	6	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1986	8	1					112	118		10.1109/TPAMI.1986.4767759	http://dx.doi.org/10.1109/TPAMI.1986.4767759			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AWT86	21869330				2022-12-18	WOS:A1986AWT8600014
J	KAHN, P				KAHN, P			LOCAL DETERMINATION OF A MOVING CONTRAST EDGE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									HUGHES AIRCRAFT CO,ELECTROOPT & DATA SYST GRP,EL SEGUNDO,CA 90245	Hughes Aircraft Company	KAHN, P (corresponding author), UNIV CALIF LOS ANGELES,ARTIFICIAL INTELLIGENCE LAB,LOS ANGELES,CA 90024, USA.							Ballard D.H., 1982, COMPUTER VISION; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; Barrow H., 1978, COMPUT VIS SYST, V2, P2; BELL SBM, UNPUB SPATIALLY REFE; CRETTEZ JP, 1982, COMPUT VISION GRAPH, V20, P299, DOI 10.1016/0146-664X(82)90055-7; DUNN RF, 1966, J ULTRA MOL STRUCT R, V16, P651, DOI 10.1016/S0022-5320(66)80012-6; ENGSTROM K, 1963, THESIS U STOCKHOLM S; ENGSTROM KJELL, 1963, ACTA ZOOL, V44, P179; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FRISHMAN L, 1979, THESIS U PITTSBURGH; Gibson J., 1979, ECOLOGICAL APPROACH; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HAYNES SM, 1983, COMPUT VISION GRAPH, V21, P345, DOI 10.1016/S0734-189X(83)80048-6; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6; KRAUSKOPF J, 1963, J OPT SOC AM, V53, P741, DOI 10.1364/JOSA.53.000741; LEE DN, 1980, PHILOS T R SOC B, V290, P169, DOI 10.1098/rstb.1980.0089; LYALL AH, 1957, Q J MICROSC SCI, V98, P189; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NAKAYAMA K, 1974, PERCEPTION, V3, P63, DOI 10.1068/p030063; PRAGER JM, 1983, COMPUT VISION GRAPH, V24, P271, DOI 10.1016/0734-189X(83)90057-9; PRAGER JM, 1979, COINS797 U MASS DEP; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003; PRITCHARD R, 1961, SCI AM, V204, P72, DOI 10.1038/scientificamerican0661-72; REICHARDT W, 1979, BIOL CYBERN, V35, P81, DOI 10.1007/BF00337434; Roberts L, 1965, MACHINE PERCEPTION 3; Suciu R. E., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P97; THOMPSON WB, 1981, COMPUTER, V14, P20, DOI 10.1109/C-M.1981.220559; ULLMAN S, 1981, COMPUTER, V14, P57, DOI 10.1109/C-M.1981.220564; ULLMAN S, 1983, PHYSICAL BIOL PROCES, V2, P155; WYATT HJ, 1975, J NEUROPHYSIOL, V38, P613, DOI 10.1152/jn.1975.38.3.613; YACHIDA M, 1983, COMPUT VISION GRAPH, V21, P262, DOI 10.1016/S0734-189X(83)80040-1	32	6	6	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					402	409		10.1109/TPAMI.1985.4767679	http://dx.doi.org/10.1109/TPAMI.1985.4767679			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69	21869278				2022-12-18	WOS:A1985ALB6900004
J	OH, SY				OH, SY			A WALSH-HADAMARD BASED DISTRIBUTED STORAGE DEVICE FOR THE ASSOCIATIVE SEARCH OF INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											OH, SY (corresponding author), UNIV ILLINOIS, DEPT ELECT ENGN & COMP SCI, CHICAGO, IL 60680 USA.							Ahmed N., 1975, ORTHOGONAL TRANSFORM, P86; ALEXANDRIDIS NA, 1972, IEEE T COMPUT, V2; ALTMAN JL, 1977, THESIS CASE W RESERV; AMARI SI, 1972, IEEE T COMPUT, V2; Beauchamp K. G., 1975, WALSH FUNCTIONS THEI; HARMUTH HF, 1972, SEQUENCY THEORY F AP; HARMUTH HF, 1972, TRANSMISSION INFORMA; KOHONEN T, 1974, IEEE T COMPUT, VC 23, P444, DOI 10.1109/T-C.1974.223960; KOHONEN T, 1972, IEEE T COMPUT, VC 21, P353, DOI 10.1109/TC.1972.5008975; KOHONEN T, 1978, ASS MEMORY; MERAT FL, 1974, THESIS CASE W RESERV; NAKANO K, 1972, IEEE T SYST MAN CYB, VSMC2, P380, DOI 10.1109/TSMC.1972.4309133; OH SY, 1981, THESIS CASE W RESERV; PAO YH, 1975, IEEE T SYST MAN CYB, V5, P620; PAO YH, 1978, NOV P INT C PATT REC; SIMMONS GJ, 1964, SPR P JOINT COMP C; Tou JT, 1974, PATTERN RECOGN; VANDERLUGT AB, 1964, IEEE T INFORM THEORY, V10; Walsh JL, 1923, AM J MATH, V45, P5, DOI 10.2307/2387224; WILLSHAW DJ, 1969, NATURE, V222, P960, DOI 10.1038/222960a0	20	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					617	623		10.1109/TPAMI.1984.4767574	http://dx.doi.org/10.1109/TPAMI.1984.4767574			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813	21869229				2022-12-18	WOS:A1984TM81300006
J	TITTERINGTON, DM				TITTERINGTON, DM			APPLICATION OF THE CONDITIONAL POPULATION-MIXTURE MODEL TO IMAGE SEGMENTATION - COMMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											TITTERINGTON, DM (corresponding author), UNIV GLASGOW,DEPT STAT,GLASGOW G12 8QW,SCOTLAND.							AITKIN M, 1981, J ROY STAT SOC A STA, V144, P419, DOI 10.2307/2981826; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; AKAIKE H, 1981, J ECONOMETRICS, V16, P1; BRYANT P, 1978, BIOMETRIKA, V65, P273, DOI 10.1093/biomet/65.2.273; Everitt B., 1981, FINITE MIXTURE DISTR, P143; LITTLE RJA, 1983, AM STAT, V37, P218, DOI 10.2307/2683374; MAKOV UE, 1977, IEEE T INFORM THEORY, V23, P761, DOI 10.1109/TIT.1977.1055801; MARRIOTT FHC, 1975, BIOMETRICS, V31, P767, DOI 10.2307/2529563; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; SCOTT AJ, 1971, BIOMETRICS, V27, P387, DOI 10.2307/2529003; SYMONS MJ, 1981, BIOMETRICS, V37, P35, DOI 10.2307/2530520; YOUNG TY, 1972, IEEE T INFORM THEORY, V18, P671	12	6	6	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					657	658						2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813					2022-12-18	WOS:A1984TM81300013
J	PALIWAL, KK; RAO, PVS				PALIWAL, KK; RAO, PVS			APPLICATION OF K-NEAREST-NEIGHBOR DECISION RULE IN VOWEL RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											PALIWAL, KK (corresponding author), TATA INST FUNDAMENTAL RES,SPEECH & DIGITAL SYST GRP,BOMBAY 400005,INDIA.		Srinivasa Rao, Prof. P/ABG-1688-2021	Srinivasa Rao, Prof. P/0000-0003-1379-4906				ATAL BS, 1974, J ACOUST SOC AM, V55, P1304, DOI 10.1121/1.1914702; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROCHIERE RE, 1980, IEEE T ACOUST SPEECH, V28, P318, DOI 10.1109/TASSP.1980.1163417; GUPTA VN, 1978, IEEE T ACOUST SPEECH, V26, P27, DOI 10.1109/TASSP.1978.1163054; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; LEVINSON SE, 1981, IEEE T ACOUST SPEECH, V29, P450, DOI 10.1109/TASSP.1981.1163593; MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792; NADAS A, 1981, IEEE T ACOUST SPEECH, V29, P449, DOI 10.1109/TASSP.1981.1163578; RABINER LR, 1979, IEEE T ACOUST SPEECH, V27, P336, DOI 10.1109/TASSP.1979.1163259; RABINER LR, 1979, IEEE T ACOUST SPEECH, V27, P583, DOI 10.1109/TASSP.1979.1163323; RABINER LR, 1980, IEEE T ACOUST SPEECH, V28, P377, DOI 10.1109/TASSP.1980.1163422; WAKITA H, 1976, IEEE T ACOUST SPEECH, V24, P270, DOI 10.1109/TASSP.1976.1162797	12	6	6	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					229	231		10.1109/TPAMI.1983.4767378	http://dx.doi.org/10.1109/TPAMI.1983.4767378			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974	21869107				2022-12-18	WOS:A1983QJ97400015
J	BRAKKE, KA; MANTOCK, JM; FUKUNAGA, K				BRAKKE, KA; MANTOCK, JM; FUKUNAGA, K			SYSTEMATIC FEATURE-EXTRACTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,DEPT ELECT ENGN,W LAFAYETTE,IN 47907; AEROSPACE CORP,EL SEGUNDO,CA 90245	Purdue University System; Purdue University; Purdue University West Lafayette Campus; Aerospace Corporation - USA	BRAKKE, KA (corresponding author), PURDUE UNIV,DEPT MATH,W LAFAYETTE,IN 47907, USA.							DUDA OR, 1973, PATTERN CLASSIFICATI, P114; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; FUKUNAGA K, 1969, IEEE T COMPUT, VC 18, P220, DOI 10.1109/T-C.1969.222635; FUKUNAGA K, 1972, INTRO STATISTICAL PA; JONES LN, COMMUNICATION; TOU JT, 1967, COMPUTER INFORMATION, V2, P57	6	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					291	297		10.1109/TPAMI.1982.4767245	http://dx.doi.org/10.1109/TPAMI.1982.4767245			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869035				2022-12-18	WOS:A1982NN06900006
J	BROWN, CA; PURDOM, PW				BROWN, CA; PURDOM, PW			AN EMPIRICAL-COMPARISON OF BACKTRACKING ALGORITHMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											BROWN, CA (corresponding author), INDIANA UNIV, DEPT COMP SCI, BLOOMINGTON, IN 47405 USA.							BITNER JR, 1975, COMMUN ACM, V18, P651, DOI 10.1145/361219.361224; BROWN CA, 1981, SIAM J COMPUT, V10, P583, DOI 10.1137/0210043; CHANDLER JP, STEPIT; CHANDRA AK, 1981, J ACM, V28, P114, DOI 10.1145/322234.322243; COOK SA, 1971, 3RD P ANN ACM S THEO, P151; DAVIS M, 1960, J ACM, V7, P201, DOI 10.1145/321033.321034; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; Garey M.R., 1979, COMPUTERS INTRACTABI; Gaschnig J. G., 1979, THESIS CARNEGIE MELL; GOLDBERG A, UNPUB INFORM PROCESS; HARALICK RM, 1980, IEEE T PATTERN ANAL, V2, P193, DOI 10.1109/TPAMI.1980.4767007; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HARALICK RM, 1978, INFORM SCIENCES, V14, P199, DOI 10.1016/0020-0255(78)90043-9; HARALICK RM, 1979, INCREASING TREE SEAR; Karp RM., 1972, COMPLEXITY COMPUTER, P85; KNUTH DE, 1975, MATH COMPUT, V29, P121, DOI 10.2307/2005469; PURDOM PW, 1978, SIAM J COMPUT, V7, P481, DOI 10.1137/0207038; PURDOM PW, 1981, ACTA INFORM, V15, P99, DOI 10.1007/BF00288958; PURDOM PW, UNPUB SIAM J COMPUT	19	6	6	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					309	316		10.1109/TPAMI.1982.4767250	http://dx.doi.org/10.1109/TPAMI.1982.4767250			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869039				2022-12-18	WOS:A1982NN06900011
J	GUERRA, C; PIERONI, GG				GUERRA, C; PIERONI, GG			A GRAPH-THEORETIC METHOD FOR DECOMPOSING TWO-DIMENSIONAL POLYGONAL SHAPES INTO MEANINGFUL PARTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV CALABRIA,DIPARTIMENTO MATEMAT,ARCAVACATA,ITALY	University of Calabria								SHAPIRO L, 1979, IEEE T PATTERN ANAL, V1	1	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	4					405	408		10.1109/TPAMI.1982.4767272	http://dx.doi.org/10.1109/TPAMI.1982.4767272			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NT735	21869055				2022-12-18	WOS:A1982NT73500007
J	KUSCHEL, SA; PAGE, CV				KUSCHEL, SA; PAGE, CV			AUGMENTED RELAXATION LABELING AND DYNAMIC RELAXATION LABELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824	Michigan State University	KUSCHEL, SA (corresponding author), ENVIRONM RES INST MICHIGAN,DIV RADAR & OPT,ANN ARBOR,MI 48107, USA.							EKLUNDH JO, 1978, TR701 U MAR COMP SCI; KUSCHEL S, 1979, THESIS MICHIGAN STAT; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; PRAGER JM, 1980, IEEE T PATTERN ANAL, V2, P16, DOI 10.1109/TPAMI.1980.4766966; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; WALTZ DL, 1972, THESIS MASSACHUSETTS; WALTZ DL, 1976, PSYCHOL COMPUTER VIS, P19; ZUCKER S, HIERARCHICAL RELAXAT; ZUCKER S, 1978, P IEEE C PATTERN REC; ZUCKER S, 1978, IEEE C PATTERN RECOG; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41	13	6	6	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					676	682		10.1109/TPAMI.1982.4767325	http://dx.doi.org/10.1109/TPAMI.1982.4767325			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499646				2022-12-18	WOS:A1982PS23700017
J	NEVINS, AJ				NEVINS, AJ			REGION EXTRACTION FROM COMPLEX SHAPES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											NEVINS, AJ (corresponding author), GEORGIA STATE UNIV,DEPT INFORMAT SYST,ATLANTA,GA 30303, USA.							BJORKLUND CM, 1981, IEEE T PATTERN ANAL, V3, P144, DOI 10.1109/TPAMI.1981.4767072; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BLUM H, 1964, S MODELS PERCEPTION; DUDANI SA, 1978, PATTERN RECOGN, V10, P145, DOI 10.1016/0031-3203(78)90023-7; FENG HYF, 1975, IEEE T COMPUT, VC 24, P636, DOI 10.1109/T-C.1975.224276; LANGRIDGE DJ, 1972, FRONTIERS PATTERN RE; NEVINS AJ, 1975, ARTIF INTELL, V6, P1, DOI 10.1016/0004-3702(75)90013-2; OCALLAGHAN JF, 1974, COMPUT GRAPHICS IMAG, V3, P300; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PAVLIDIS T, 1977, SYNTACTIC PATTERN RE; ROSE F, 1974, Lichenologist (London), V6, P1, DOI 10.1017/S002428297400003X; ROSENBERG D, 1972, COMPUT GRAPHICS IMAG, V1, P183; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; YAMAMOTO K, 1980, PATTERN RECOGN, V12, P229, DOI 10.1016/0031-3203(80)90062-X	14	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	5					500	511		10.1109/TPAMI.1982.4767294	http://dx.doi.org/10.1109/TPAMI.1982.4767294			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	PG894	21869069				2022-12-18	WOS:A1982PG89400006
J	SCHER, A; SHNEIER, M; ROSENFELD, A				SCHER, A; SHNEIER, M; ROSENFELD, A			A METHOD FOR FINDING PAIRS OF ANTIPARALLEL STRAIGHT-LINES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SCHER, A (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742, USA.			Scher, Ann/0000-0003-4599-9834				BROOKS RA, 1979, APR P DARPA IM UND W, P72; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; PELEG S, 1978, TR694 U MAR COMP SCI; QUAM L, 1978, MAY P IM UND WORKSH, P51; ROSENFELD A, 1979, NOV P IM UND WORKSH, P112; SCHER A, 1982, UNPUB PATTERN RECOGN, V15; TAVAKOLI M, 1980, APR P IM UND WORKSH, P33; WANG S, 1982, UNPUB IEEE T PATTERN, V4	8	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					316	323		10.1109/TPAMI.1982.4767251	http://dx.doi.org/10.1109/TPAMI.1982.4767251			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869041				2022-12-18	WOS:A1982NN06900012
J	ULICHNEY, RA; TROXEL, DE				ULICHNEY, RA; TROXEL, DE			SCALING BINARY IMAGES WITH THE TELESCOPING TEMPLATE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									MIT,ELECTR RES LAB,CAMBRIDGE,MA 02139; MIT,DEPT ELECT ENGN & COMP SCI,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	ULICHNEY, RA (corresponding author), DIGITAL EQUIPMENT CORP,CORP RES GRP,MAYNARD,MA 01754, USA.							BEIGELEISEN JI, 1976, ART DIRECTORS WORKBO; COUEIGNOUX PJM, 1973, THESIS MASSACHUSETTS; EVANS GW, 1977, Patent No. 4029947; HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508; HUANG TS, 1977, IEEE T COMMUN, V25, P1406, DOI 10.1109/TCOM.1977.1093775; KNUTH DE, 1978, STANCS78648 STANF U; PELL R, 1978, COMMUNICATION; PRATT WK, 1978, DIGITAL IMAGE PROCES, pCH4; ULICHNEY RA, 1979, THESIS MASSACHUSETTS; 1978, SEYBOLD REP, V7; 1980, P IEEE, V68, P923; 1980, P IEEE, V68, P757	12	6	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					331	335		10.1109/TPAMI.1982.4767254	http://dx.doi.org/10.1109/TPAMI.1982.4767254			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869044				2022-12-18	WOS:A1982NN06900015
J	SZE, TW; YANG, YH				SZE, TW; YANG, YH			A SIMPLE CONTOUR MATCHING ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SZE, TW (corresponding author), UNIV PITTSBURGH,DEPT ELECT ENGN,PITTSBURGH,PA 15213, USA.							PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P307, DOI 10.1109/TPAMI.1979.4766928; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P2, DOI 10.1109/TPAMI.1979.4766870; Pavlidis T., 1977, STRUCTURAL PATTERN R	3	6	6	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					676	678		10.1109/TPAMI.1981.4767169	http://dx.doi.org/10.1109/TPAMI.1981.4767169			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MR996	21868988				2022-12-18	WOS:A1981MR99600008
J	WANG, S; WU, AY; ROSENFELD, A				WANG, S; WU, AY; ROSENFELD, A			IMAGE APPROXIMATION FROM GRAY SCALE MEDIAL AXES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											WANG, S (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							AHUJA N, 1978, IEEE T COMPUT, V27, P375, DOI 10.1109/TC.1978.1675110; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; DYER CR, 1979, IEEE T PATTERN ANAL, V1, P88, DOI 10.1109/TPAMI.1979.4766880; LEVI G, 1970, INFORM CONTROL, V17, P62, DOI 10.1016/S0019-9958(70)80006-7; MOTTSMITH JC, 1970, PICTURE PROCESSING P, P267; NAKAGAWA Y, 1978, IEEE T SYST MAN CYB, V8, P632; PELEG S, 1981, IEEE T PATTERN ANAL, V3, P208, DOI 10.1109/TPAMI.1981.4767082; PRATT WK, 1978, DIGITAL IMAGE PROCES, P729; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1976, DIGITAL PICTURE PROC, P310; WANG S, 1979, TR843 U MAR COMP SCI	11	6	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					687	696		10.1109/TPAMI.1981.4767172	http://dx.doi.org/10.1109/TPAMI.1981.4767172			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MR996	21868991				2022-12-18	WOS:A1981MR99600011
J	TANG, GY; HUANG, TS				TANG, GY; HUANG, TS			SYNTACTIC-SEMANTIC APPROACH TO IMAGE UNDERSTANDING AND CREATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,DEPT ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	TANG, GY (corresponding author), SUNY BUFFALO,DEPT ELECT ENGN,AMHERST,NY 14260, USA.							AHO AV, 1972, AUTOMATIC COMPUTATIO, V1; BAIRD ML, 1974, PATTERN RECOGN, V6, P61, DOI 10.1016/0031-3203(74)90008-9; BRONS R, 1974, COMPUT GRAPHICS IMAG, V3, P48; CLOWES MB, 1969, CSIRO CANBERRA; CLOWES MB, 1971, ARTIFICIAL INTELLIGE, V2; COHEN M, 1977, PATTERN RECOGNITION, V9; DUDA RO, 1974, PATTERN CLASSIFICATI, P276; DUDA RO, 1972, COMMUN ASS COMPUT MA, V15; FIRSCHEIN O, 1971, PATTERN RECOGN, V3, P421, DOI 10.1016/0031-3203(71)90031-8; FREEMAN H, 1961, IRE T ELECTRON COMPU, V10; Fu K.S., 1974, MATH SCI ENG; FU KS, 1973, IEEE T COMPUT, VC 22, P1087, DOI 10.1109/T-C.1973.223654; FU KS, 1976, APPLICATIONS SYNTACT; FU KS, 1976, IEEE T COMPUT, V25; FU KS, 1971, SOFTWARE ENGINEERING, V2; GUZMAN A, 1971, MACHINE INTELLIGENCE, V6; HOROWITZ SL, 1975, COMMUN ASS COMPUT MA, V18; Knuth D, 1971, MATH SYST THEORY, V2, P127, DOI DOI 10.1007/BF01692511; KNUTH DE, 1975, ART COMPUTER PROGRAM, V3; LEE HC, 1972, IEEE T COMPUT, VC 21, P660, DOI 10.1109/T-C.1972.223571; Lipkin BS, 1970, PICTURE PROCESSING P, P241; LOZANOPEREZ T, 1977, COMPUT GRAPHICS IMAG, V6, P43; MOAYER B, 1976, IEEE T COMPUT, V25; MORSE SP, 1978 P ASS COMP MACH, P45; OGORMAN F, 1976, IEEE T COMPUT, V25; PAVLIDIS T, 1972, PATTERN RECOGN, V4, P5, DOI 10.1016/0031-3203(72)90016-7; PAVLIDIS T, 1971, SOFTWARE ENGINEERING, V4, P223; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1972, MACHINE INTELLIGENCE, V7; ROSENFELD A, 1977, IEEE T COMPUT, V23; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SHAPIRO SD, 1975, COMPUTER GRAPHICS IM, V4; SHAPIRO SD, 1974, 2ND P INT JOINT C PA; SHAW AC, 1970, J ACM, V17, P453, DOI 10.1145/321592.321598; STOCKMAN G, 1975, TR3PO U MAR DEP COMP; Stockman G. C., 1973, 1st International Joint Conference on Pattern Recognition, P236; SWAIN PH, PATTERN RECOGNITION, V4, P83; TANG GY, 1975 1976 PURD Q REP; TANG GY, 1977, TREE7741 PURD U SCH; TANG GY, 1978, THESIS PURDUE U; TANG GY, 1976 PURD U Q PROGR; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; [No title captured]	43	6	6	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					135	144		10.1109/TPAMI.1979.4766899	http://dx.doi.org/10.1109/TPAMI.1979.4766899			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	HA304	21868842				2022-12-18	WOS:A1979HA30400003
J	Ali, M; Berrendorf, M; Hoyt, CT; Vermue, L; Galkin, M; Sharifzadeh, S; Fischer, A; Tresp, V; Lehmann, J				Ali, Mehdi; Berrendorf, Max; Hoyt, Charles Tapley; Vermue, Laurent; Galkin, Mikhail; Sharifzadeh, Sahand; Fischer, Asja; Tresp, Volker; Lehmann, Jens			Bringing Light Into the Dark: A Large-Scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational modeling; Benchmark testing; Magnetic heads; Training; Predictive models; Task analysis; Reproducibility of results; Knowledge graph embeddings; link prediction; reproducibility; benchmarking		The heterogeneity in recently published knowledge graph embedding models' implementations, training, and evaluation has made fair and thorough comparisons difficult. To assess the reproducibility of previously published results, we re-implemented and evaluated 21 models in the PyKEEN software package. In this paper, we outline which results could be reproduced with their reported hyper-parameters, which could only be reproduced with alternate hyper-parameters, and which could not be reproduced at all, as well as provide insight as to why this might be the case. We then performed a large-scale benchmarking on four datasets with several thousands of experiments and 24,804 GPU hours of computation time. We present insights gained as to best practices, best configurations for each model, and where improvements could be made over previously published best configurations. Our results highlight that the combination of model architecture, training approach, loss function, and the explicit modeling of inverse relations is crucial for a model's performance and is not only determined by its architecture. We provide evidence that several architectures can obtain results competitive to the state of the art when configured carefully. We have made all code, experimental configurations, results, and analyses available at https://github.com/pykeen/pykeen and https://github.com/pykeen/benchmarking.	[Ali, Mehdi; Lehmann, Jens] Univ Bonn, Smart Data Analyt, D-53113 Bonn, Germany; [Ali, Mehdi; Lehmann, Jens] Fraunhofer IAIS, D-53757 St Augustin, Germany; [Berrendorf, Max; Sharifzadeh, Sahand; Tresp, Volker] Ludwig Maximilians Univ Munchen, D-80539 Munich, Germany; [Hoyt, Charles Tapley] Harvard Med Sch, Lab Syst Pharmacol, Boston, MA 02115 USA; [Vermue, Laurent] Tech Univ Denmark, DK-2800 Lyngby, Denmark; [Galkin, Mikhail] Mila, Montreal, PQ H3A 0G4, Canada; [Galkin, Mikhail] McGill Univ, Montreal, PQ H3A 0G4, Canada; [Fischer, Asja] Ruhr Univ Bochum, D-44801 Bochum, Germany; [Tresp, Volker] Siemens AG, D-80333 Munich, Germany	University of Bonn; University of Munich; Harvard University; Harvard Medical School; Technical University of Denmark; McGill University; Ruhr University Bochum; Siemens AG; Siemens Germany	Ali, M (corresponding author), Univ Bonn, Smart Data Analyt, D-53113 Bonn, Germany.	mehdi.ali@cs.uni-bonn.de; berrendorf@dbs.ifi.lmu.de; cthoyt@gmail.com; lauve@dtu.dk; mikhail.galkin@mila.quchec; sharifzadeh@dbs.ifi.lmu.de; asja.fischer@rub.de; volker.tresp@siemens.com; jens.lehmann@cs.uni-bonn.de	; Hoyt, Charles/B-5720-2018	Lehmann, Jens/0000-0001-9108-4278; Berrendorf, Max/0000-0001-9724-4009; Hoyt, Charles/0000-0003-4423-4370; Ali, Mehdi/0000-0003-1653-3920	German Federal Ministry of Education and Research (BMBF) [01IS18036A, 01IS18050D]; Defense Advanced Research Projects Agency (DARPA) Automating Scientific Knowledge Extraction (ASKE) program [HR00111990009]; Innovation Fund Denmark with the Danish Center for Big Data Analytics driven Innovation (DABAI)	German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF)); Defense Advanced Research Projects Agency (DARPA) Automating Scientific Knowledge Extraction (ASKE) program; Innovation Fund Denmark with the Danish Center for Big Data Analytics driven Innovation (DABAI)	This work was supported in part by the German Federal Ministry of Education and Research (BMBF) under Grants 01IS18036A and 01IS18050D under Project MLWin, in part the Innovation Fund Denmark with the Danish Center for Big Data Analytics driven Innovation (DABAI), and in part by the Defense Advanced Research Projects Agency (DARPA) Automating Scientific Knowledge Extraction (ASKE) program under Grant HR00111990009.	Akrami F, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1995, DOI 10.1145/3318464.3380599; Akrami F, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1779, DOI 10.1145/3269206.3269266; Balazevic I, 2019, TUCKER TENSOR FACTOR, P5184; Balazevic I, 2019, ADV NEUR IN, V32; Bhushan Kotnis, 2018, Arxiv, DOI arXiv:1708.06816; Bordes A., 2013, ADV NEURAL INFORM PR; Bordes A, 2014, MACH LEARN, V94, P233, DOI 10.1007/s10994-013-5363-6; Bordes Antoine, 2011, P 25 AAAI C ART INT, P301, DOI DOI 10.1016/J.PROCS.2017.05.045; Denham W. W., 1973, THESIS U WASHINGTON; Dettmers T, 2018, AAAI CONF ARTIF INTE, P1811; Dong XL, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P601, DOI 10.1145/2623330.2623623; Fuhr N., 2018, SIGIR FORUM, V51, P32, DOI DOI 10.1145/3190580.3190586; Galarraga Luis Antonio, 2013, P 22 INT C WORLD WID, P413, DOI DOI 10.1145/2488388.2488425; Hamilton WL, 2017, REPRESENTATION LEARN; He S., 2015, PROC 24 ACM INT C IN, P623, DOI [DOI 10.1145/2806416.2806502, 10.1145/2806416.2806502, 10.1145]; Ji GL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P687; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Kadlec Rudolf, 2017, P 2 WORKSH REPR LEAR, P69, DOI [DOI 10.18653/V1/W17-2609, 10.18653/v1/W17-2609]; Kazemi SM, 2020, J MACH LEARN RES, V21; Kazemi SM, 2018, ADV NEUR IN, V31; Lacroix T, 2018, PR MACH LEARN RES, V80; Lin YK, 2015, AAAI CONF ARTIF INTE, P2181; Mahdisoltani F., 2016, PROC C INNOV DATA SY, P177; Max Berrendorf, 2020, Arxiv, DOI arXiv:1905.00966; Berrendorf M, 2020, Arxiv, DOI arXiv:2002.06914; McCray AT, 2003, COMP FUNCT GENOM, V4, P80, DOI 10.1002/cfg.255; Mohamed S. K., 2019, PROC DL4KG ESWC, P1; Nickel M., 2011, INT C INT C MACH LEA, P809, DOI DOI 10.5555/3104482.3104584; Nickel M, 2016, AAAI CONF ARTIF INTE, P1955; Nickel M, 2016, P IEEE, V104, P11, DOI 10.1109/JPROC.2015.2483592; Rebele T, 2016, LECT NOTES COMPUT SC, V9982, P177, DOI 10.1007/978-3-319-46547-0_19; Rossi A., 2020, ARXIV; Ruffinelli D., 2020, PROC INT C LEARN REP; Rummel R. J., 1976, DIMENSIONALITY NATIO; Shi BX, 2017, AAAI CONF ARTIF INTE, P1236; Socher R., 2013, ADV NEURAL INFORM PR, P926, DOI DOI 10.1109/ICICIP.2013.6568119; STEVENS SS, 1946, SCIENCE, V103, P677, DOI 10.1126/science.103.2684.677; Sun Z., 2019, 7 INT C LEARNING REP; Sun Z., 2020, ANN M ASS COMPUTATIO, P5516, DOI 10.18653/v1/2020.acl-main.489; Toutanova K., 2015, P 3 WORKSH CONT VECT, DOI DOI 10.18653/V1/W15-4007; Trouillon T, 2016, PR MACH LEARN RES, V48; Tucker L. R., 1964, CONTRIBUTIONS MATH P, V46, P47; Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499; Wang R, 2020, IEEE ACCESS, V8, P5212, DOI 10.1109/ACCESS.2019.2963367; Wang Z, 2014, AAAI CONF ARTIF INTE, P1112; Yang B., 2015, P INT C LEARN REPR; Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331; Zhang S, 2019, ADV NEUR IN, V32	49	5	5	3	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					8825	8845		10.1109/TPAMI.2021.3124805	http://dx.doi.org/10.1109/TPAMI.2021.3124805			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34735335	Green Submitted			2022-12-18	WOS:000880661400023
J	Shen, JB; Liu, YP; Dong, XP; Lu, XK; Khan, FS; Hoi, S				Shen, Jianbing; Liu, Yuanpei; Dong, Xingping; Lu, Xiankai; Khan, Fahad Shahbaz; Hoi, Steven			Distilled Siamese Networks for Visual Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Target tracking; Real-time systems; Visualization; Correlation; Knowledge engineering; Feature extraction; Siamese network; teacher-students; knowledge distillation; visual object tracking; siamese trackers		In recent years, Siamese network based trackers have significantly advanced the state-of-the-art in real-time tracking. Despite their success, Siamese trackers tend to suffer from high memory costs, which restrict their applicability to mobile devices with tight memory budgets. To address this issue, we propose a distilled Siamese tracking framework to learn small, fast and accurate trackers (students), which capture critical knowledge from large Siamese trackers (teachers) by a teacher-students knowledge distillation model. This model is intuitively inspired by the one teacher versus multiple students learning method typically employed in schools. In particular, our model contains a single teacher-student distillation module and a student-student knowledge sharing mechanism. The former is designed using a tracking-specific distillation strategy to transfer knowledge from a teacher to students. The latter is utilized for mutual learning between students to enable in-depth knowledge understanding. Extensive empirical evaluations on several popular Siamese trackers demonstrate the generality and effectiveness of our framework. Moreover, the results on five tracking benchmarks show that the proposed distilled trackers achieve compression rates of up to 18x and frame-rates of 265 FPS, while obtaining comparable tracking accuracy compared to base models.	[Shen, Jianbing] Univ Macau, Dept Comp & Informat Sci, State Key Lab Internet Things Smart City, Taipa, Macao, Peoples R China; [Liu, Yuanpei] Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China; [Dong, Xingping; Khan, Fahad Shahbaz] Incept Inst Artificial Intelligence, Abu Dhabi 51133, U Arab Emirates; [Lu, Xiankai] Shandong Univ, Sch Software, Jinan 264209, Shandong, Peoples R China; [Khan, Fahad Shahbaz] Linkoping Univ, Linkoping, Sweden; [Hoi, Steven] Singapore Management Univ, Sch Informat Syst, Singapore 188065, Singapore; [Hoi, Steven] Salesforce Res Asia, Singapore 188065, Singapore	University of Macau; Beijing Institute of Technology; Shandong University; Linkoping University; Singapore Management University; Salesforce	Shen, JB (corresponding author), Univ Macau, Dept Comp & Informat Sci, State Key Lab Internet Things Smart City, Taipa, Macao, Peoples R China.	shenjianbingcg@gmail.com; liuyuanpei@bit.edu.cn; dongxingping@bit.edu.cn; carrierlxk@gmail.com; fahad.khan@liu.se; chhoi@smu.edu.sg			National Natural Science Foundation of China [62106128]; Natural Science Foundation of Shandong Province [ZR202102240155]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Shandong Province(Natural Science Foundation of Shandong Province)	This work was supported in part by the National Natural Science Foundation of China under Grant 62106128, and the Natural Science Foundation of Shandong Province under Grant ZR202102240155.	Abhinav Gupta, 2015, Arxiv, DOI arXiv:1501.04587; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Ashok Anubhav, 2018, INT C LEARN REPR; Ba LJ, 2014, ADV NEUR IN, V27; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Bertinetto Luca, 2016, NIPS; Boddeti VN, 2013, PROC CVPR IEEE, P2291, DOI 10.1109/CVPR.2013.297; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; Bucilu C., 2006, PROC ACMSIGKDD C; Chen GB, 2017, ADV NEUR IN, V30; Choi J, 2019, IEEE I CONF COMP VIS, P911, DOI 10.1109/ICCV.2019.00100; Choi J, 2018, PROC CVPR IEEE, P479, DOI 10.1109/CVPR.2018.00057; Courbariaux M, 2015, ADV NEUR IN, V28; Czarnecki WM, 2017, ADV NEUR IN, V30; Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480; Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733; Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143; Danelljan Martin, 2014, BRIT MACH VIS C NOTT; Daniel Soudry, 2016, Arxiv, DOI arXiv:1602.02830; Dong XP, 2021, IEEE T PATTERN ANAL, V43, P1515, DOI 10.1109/TPAMI.2019.2956703; Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567; Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28; Dong XW, 2018, IEEE CONF COMPUT; Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814; Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552; Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI 10.1109/ICCV.2017.129; Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381; Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478; Gupta S, 2015, PR MACH LEARN RES, V37, P1737; Han W, 2021, P IEEE CVF C COMP VI, P16570; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; Hinton G., 2015, NIPS WORKSH, P1; Huang LH, 2019, IEEE I CONF COMP VIS, P3998, DOI 10.1109/ICCV.2019.00410; Huizi Mao, 2016, Arxiv, DOI arXiv:1510.00149; Kart U, 2019, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2019.00143; Kristan M., 2019, PROC IEEE C INT C CO; Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441; Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935; Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146; Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18; Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271; Lopez-Paz David, 2016, INT C LEARN REPR ICL, DOI DOI 10.1109/PAC.2017.13.ARXIV:1511.0; Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332; Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177; Muller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19; Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465; Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823; Qi YW, 2020, IEEE T SYST MAN CY-S, V50, P1442, DOI 10.1109/TSMC.2018.2801284; Qi YK, 2020, IEEE T IMAGE PROCESS, V29, P9152, DOI 10.1109/TIP.2020.3023621; R.Venkatesh Babu, 2015, Arxiv, DOI arXiv:1507.06149; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Romero Adriana, 2014, ARXIV14126550; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sadowski P., 2015, PROC C NEURAL INF PR; Shen JB, 2020, IEEE T CYBERNETICS, V50, P3068, DOI 10.1109/TCYB.2019.2936503; Sun YX, 2019, PROC CVPR IEEE, P5776, DOI 10.1109/CVPR.2019.00593; Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158; Urban G., 2017, PROC INT C LEARN REP; Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531; Vapnik V.N, 1998, STAT LEARNING THEORY; Wang N, 2013, ADV NEURAL INFORM PR, DOI DOI 10.5555/2999611.2999702; Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355; Wang N, 2020, IEEE T IMAGE PROCESS, V29, P6123, DOI 10.1109/TIP.2020.2989544; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Yang TY, 2020, PROC CVPR IEEE, P6717, DOI 10.1109/CVPR42600.2020.00675; Yang YF, 2020, AAAI CONF ARTIF INTE, V34, P12645; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13; Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454; Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472; Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46; Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7	86	5	5	8	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					8896	8909		10.1109/TPAMI.2021.3127492	http://dx.doi.org/10.1109/TPAMI.2021.3127492			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34762585	Green Submitted			2022-12-18	WOS:000880661400027
J	Ma, C; Rao, YM; Lu, JW; Zhou, J				Ma, Cheng; Rao, Yongming; Lu, Jiwen; Zhou, Jie			Structure-Preserving Image Super-Resolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Image edge detection; Superresolution; Distortion; Task analysis; Generative adversarial networks; Image restoration; Super-resolution; image enhancement; self-supervised learning; generative adversarial network		Structures matter in single image super-resolution (SISR). Benefiting from generative adversarial networks (GANs), recent studies have promoted the development of SISR by recovering photo-realistic images. However, there are still undesired structural distortions in the recovered images. In this paper, we propose a structure-preserving super-resolution (SPSR) method to alleviate the above issue while maintaining the merits of GAN-based methods to generate perceptual-pleasant details. First, we propose SPSR with gradient guidance (SPSR-G) by exploiting gradient maps of images to guide the recovery in two aspects. On the one hand, we restore high-resolution gradient maps by a gradient branch to provide additional structure priors for the SR process. On the other hand, we propose a gradient loss to impose a second-order restriction on the super-resolved images, which helps generative networks concentrate more on geometric structures. Second, since the gradient maps are handcrafted and may only be able to capture limited aspects of structural information, we further extend SPSR-G by introducing a learnable neural structure extractor (NSE) to unearth richer local structures and provide stronger supervision for SR. We propose two self-supervised structure learning methods, contrastive prediction and solving jigsaw puzzles, to train the NSEs. Our methods are model-agnostic, which can be potentially used for off-the-shelf SR networks. Experimental results on five benchmark datasets show that the proposed methods outperform state-of-the-art perceptual-driven SR methods under LPIPS, PSNR, and SSIM metrics. Visual results demonstrate the superiority of our methods in restoring structures while generating natural SR images. Code is available at https://github.com/Maclory/SPSR.	[Ma, Cheng; Rao, Yongming; Lu, Jiwen; Zhou, Jie] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing, Peoples R China; [Ma, Cheng; Rao, Yongming; Lu, Jiwen; Zhou, Jie] Tsinghua Univ, Dept Automat, Beijing, Peoples R China	Tsinghua University; Tsinghua University	Lu, JW; Zhou, J (corresponding author), Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing, Peoples R China.; Lu, JW; Zhou, J (corresponding author), Tsinghua Univ, Dept Automat, Beijing, Peoples R China.	macheng17@mails.tsinghua.edu.cn; raoyongmimg95@gmail.com; lujiwen@tsinghua.edu.cn; jzhou@tsinghua.edu.cn	; Lu, Jiwen/C-5291-2009	Rao, Yongming/0000-0003-3952-8753; Ma, Cheng/0000-0002-0232-5912; Lu, Jiwen/0000-0002-6121-5529	National Natural Science Foundation of China [62125603, U1813218, U1713214]; Beijing Academy of Artificial Intelligence	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Academy of Artificial Intelligence	This work was supported in part by the National Natural Science Foundation of China under Grants 62125603, U1813218, and U1713214, in part by a grant from the Beijing Academy of Artificial Intelligence, and in part by a grant from the Institute for Guo Qiang, Tsinghua University.	Aaron van den Oord, 2016, Arxiv, DOI arXiv:1601.06759; Aaron van den Oord, 2019, Arxiv, DOI arXiv:1807.03748; Agustsson Eirikur, 2017, IEEE C COMP VIS PATT; Alec Radford, 2016, Arxiv, DOI arXiv:1511.06434; Alexia Jolicoeur-Martineau, 2018, Arxiv, DOI arXiv:1807.00734; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Anoosheh A, 2019, IEEE INT CONF ROBOT, P5958, DOI 10.1109/ICRA.2019.8794387; Bae W, 2017, IEEE COMPUT SOC CONF, P1141, DOI 10.1109/CVPRW.2017.152; Bahat Y, 2020, PROC CVPR IEEE, P2713, DOI 10.1109/CVPR42600.2020.00279; Ben Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P191, DOI 10.1007/978-3-030-58610-2_12; Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135; Cheng Ma, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7766, DOI 10.1109/CVPR42600.2020.00779; Chintala S., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1701.07875; Dilip Krishnan, 2020, Arxiv, DOI arXiv:1906.05849; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]; Geoffrey Hinton, 2020, Arxiv, DOI arXiv:2002.05709; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187; Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156; Hyun S., 2020, VARSR VARIATIONAL SU, P431; Gulrajani I, 2017, ADV NEUR IN, V30; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kim D, 2018, IEEE WINT CONF APPL, P793, DOI 10.1109/WACV.2018.00092; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kingma D.P, P 3 INT C LEARNING R; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Larsson G, 2017, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2017.96; Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121; Longlong Jing, 2019, Arxiv, DOI arXiv:1902.06162; Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740; Lugmayr Andreas, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P715, DOI 10.1007/978-3-030-58558-7_42; Maeda S, 2020, PROC CVPR IEEE, P288, DOI 10.1109/CVPR42600.2020.00037; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mei YQ, 2020, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR42600.2020.00573; Nair V., 2010, ICML, P807; Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5; Paszke A, 2019, ADV NEUR IN, V32; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Rasti P, 2016, LECT NOTES COMPUT SC, V9756, P175, DOI 10.1007/978-3-319-41778-3_18; Ruiming Guo, 2019, Arxiv, DOI arXiv:1904.00634; Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481; Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Soh JW, 2019, PROC CVPR IEEE, P8114, DOI 10.1109/CVPR.2019.00831; Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871; Tatem AJ, 2002, REMOTE SENS ENVIRON, V79, P1, DOI 10.1016/S0034-4257(01)00229-2; Thornton MW, 2006, INT J REMOTE SENS, V27, P473, DOI 10.1080/01431160500207088; Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wei Pengxu, 2020, EUR C COMP VIS, P101, DOI DOI 10.1007/978-3-030-58598-3_7; Yan Q, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2414877; Yang WH, 2017, IEEE T IMAGE PROCESS, V26, P5895, DOI 10.1109/TIP.2017.2750403; Zeyde Roman, 2010, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47; Zhang LP, 2010, SIGNAL PROCESS, V90, P848, DOI 10.1016/j.sigpro.2009.09.002; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zhang Yulun, 2018, P EUROPEAN C COMPUTE, P286; Zhu Y, 2015, PROC CVPR IEEE, P5417, DOI 10.1109/CVPR.2015.7299180	68	5	5	8	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					7898	7911		10.1109/TPAMI.2021.3114428	http://dx.doi.org/10.1109/TPAMI.2021.3114428			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34550879	Green Submitted			2022-12-18	WOS:000864325900046
J	Guo, D; Wang, H; Wang, M				Guo, Dan; Wang, Hui; Wang, Meng			Context-Aware Graph Inference With Knowledge Distillation for Visual Dialog	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual dialog; cross-modal interaction; relational reasoning; graph inference; knowledge distillation		Visual dialog is a challenging task that requires the comprehension of the semantic dependencies among implicit visual and textual contexts. This task can refer to the relational inference in a graphical model with sparse contextual subjects (nodes) and unknown graph structure (relation descriptor); how to model the underlying context-aware relational inference is critical. To this end, we propose a novel context-aware graph (CAG) neural network. We focus on the exploitation of fine-grained relational reasoning with object-level dialog-historical co-reference nodes. The graph structure (relation in dialog) is iteratively updated using an adaptive top-K message passing mechanism. To eliminate sparse useless relations, each node has dynamic relations in the graph (different related K neighbor nodes), and only the most relevant nodes are attributive to the context-aware relational graph inference. In addition, to avoid negative performance caused by linguistic bias of history, we propose a pure visual-aware knowledge distillation mechanism named CAG-Distill, in which image-only visual clues are used to regularize the joint dialog-historical contextual awareness at the object-level. Experimental results on VisDial v0.9 and v1.0 datasets show that both CAG and CAG-Distill outperform comparative methods. Visualization results further validate the remarkable interpretability of our graph inference solution.	[Guo, Dan; Wang, Hui; Wang, Meng] Hefei Univ Technol HFUT, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei 230601, Peoples R China; [Guo, Dan; Wang, Hui; Wang, Meng] Hefei Univ Technol HFUT, Intelligent Interconnected Syst Lab Anhui Prov, Hefei 230601, Peoples R China; [Guo, Dan; Wang, Hui; Wang, Meng] Hefei Univ Technol HFUT, Sch Comp Sci & Informat Engn, Hefei 230601, Peoples R China; [Guo, Dan; Wang, Hui; Wang, Meng] Hefei Univ Technol HFUT, Sch Artificial Intelligence, Hefei 230601, Peoples R China	Hefei University of Technology; Hefei University of Technology; Hefei University of Technology; Hefei University of Technology	Wang, M (corresponding author), Hefei Univ Technol HFUT, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei 230601, Peoples R China.	guodan@hfut.edu.cn; wanghui.hfut@gmail.com; eric.mengwang@gmail.com		Guo, Dan/0000-0003-2594-254X; Wang, Hui/0000-0002-8745-4042	National Natural Science Foundation of China (NSFC) [61725203, 62020106007, 61876058]; Fundamental Research Funds for the Central Universities [JZ2020HGTB0020]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported in part by the National Natural Science Foundation of China (NSFC) under Grants 61725203, 62020106007, and 61876058, and in part by the Fundamental Research Funds for the Central Universities under Grant JZ2020HGTB0020. D. Guo and H. Wang contribute equally to this work. Our code is available at: https://github.com/wh0330/VisDial-CAG-Distill	Agarwal S., 2020, P 58 ANN M ASS COMP, P8182; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Boxiao Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10867, DOI 10.1109/CVPR42600.2020.01088; Bucila C, 2006, P 12 ACM SIGKDD INT, P535, DOI DOI 10.1145/1150402.1150464; Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059; Dan Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10052, DOI 10.1109/CVPR42600.2020.01007; Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121; de Vries H, 2017, PROC CVPR IEEE, P4466, DOI 10.1109/CVPR.2017.475; Fan HH, 2020, AAAI CONF ARTIF INTE, V34, P10754; Fan HH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3390891; Gan Z, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6463; Geoffrey Hinton, 2015, Arxiv, DOI arXiv:1503.02531; Gu JX, 2019, PROC CVPR IEEE, P1969, DOI 10.1109/CVPR.2019.00207; Guo DL, 2019, PROC CVPR IEEE, P10426, DOI 10.1109/CVPR.2019.01068; Guo D, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P920; Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4989; Guo D, 2020, IEEE T IMAGE PROCESS, V29, P6655, DOI 10.1109/TIP.2020.2992888; Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309; Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473; Jang Y, 2017, PROC CVPR IEEE, P1359, DOI 10.1109/CVPR.2017.149; Jiang XZ, 2020, AAAI CONF ARTIF INTE, V34, P11125; Junyeong Kim, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10103, DOI 10.1109/CVPR42600.2020.01012; Kang GC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2024; Kingma D. P., 2015, 3 INT C LEARN REPR I, P1; Kottur S, 2018, LECT NOTES COMPUT SC, V11219, P160, DOI 10.1007/978-3-030-01267-0_10; Kottur Satwik, 2019, P 2019 C N AM CHAPT, P582; Lei Jie, 2020, P 58 ANN M ASS COMP, P8211, DOI DOI 10.18653/V1/2020.ACL-MAIN.730; Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371; Liang JW, 2019, IEEE T PATTERN ANAL, V41, P1893, DOI 10.1109/TPAMI.2018.2890628; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Y, 2018, PROC CVPR IEEE, P6985, DOI 10.1109/CVPR.2018.00730; Lopez-Paz D., 2016, P INT C LEARN REPR, P1; Lu JS, 2017, ADV NEUR IN, V30; Niu YL, 2019, PROC CVPR IEEE, P6672, DOI 10.1109/CVPR.2019.00684; Niu YL, 2021, IEEE T PATTERN ANAL, V43, P347, DOI 10.1109/TPAMI.2019.2926266; Norcliffe-Brown W, 2018, ADV NEUR IN, V31; Peng YX, 2020, IEEE T CIRC SYST VID, V30, P4368, DOI 10.1109/TCSVT.2019.2953692; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; Schwartz I, 2019, PROC CVPR IEEE, P2039, DOI 10.1109/CVPR.2019.00214; Seo P. H., 2017, PROC INT C NEURAL IN, P3722; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Teney D, 2017, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2017.344; Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042; Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541; Wang P, 2019, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2019.00206; Wang Y. N., 2013, C LEARN THEOR, P25, DOI DOI 10.3969/J.ISSN.1007-7545.2013.11.09; Wu Q, 2018, PROC CVPR IEEE, P6106, DOI 10.1109/CVPR.2018.00639; Wu Y, 2020, IEEE T IMAGE PROCESS, V29, P3984, DOI 10.1109/TIP.2020.2967584; Yang SB, 2021, IEEE T PATTERN ANAL, V43, P2765, DOI 10.1109/TPAMI.2020.2973983; Yang TH, 2019, IEEE I CONF COMP VIS, P2561, DOI 10.1109/ICCV.2019.00265; Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098; Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202; Zha ZJ, 2022, IEEE T PATTERN ANAL, V44, P710, DOI 10.1109/TPAMI.2019.2909864; Zhang J, 2019, AAAI CONF ARTIF INTE, P9185; Zhang JC, 2019, PROC CVPR IEEE, P8319, DOI 10.1109/CVPR.2019.00852; Zhao F, 2018, PROC CVPR IEEE, P5696, DOI 10.1109/CVPR.2018.00597; Zhenfang Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10083, DOI 10.1109/CVPR42600.2020.01010; Zheng ZL, 2019, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2019.00683; Zhu Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10665, DOI 10.1109/CVPR42600.2020.01068	62	5	5	13	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6056	6073		10.1109/TPAMI.2021.3085755	http://dx.doi.org/10.1109/TPAMI.2021.3085755			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34061738				2022-12-18	WOS:000853875300018
J	Jiang, PT; Han, LH; Hou, QB; Cheng, MM; Wei, YC				Jiang, Peng-Tao; Han, Ling-Hao; Hou, Qibin; Cheng, Ming-Ming; Wei, Yunchao			Online Attention Accumulation for Weakly Supervised Semantic Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Semantics; Cats; Image segmentation; Visualization; Task analysis; Location awareness; Weakly supervised semantic segmentation; attention maps; online attention accumulation; attention drop layer; pixel-level supervision	SALIENT OBJECT DETECTION	Object attention maps generated by image classifiers are usually used as priors for weakly supervised semantic segmentation. However, attention maps usually locate the most discriminative object parts. The lack of integral object localization maps heavily limits the performance of weakly supervised segmentation approaches. This paper attempts to investigate a novel way to identify entire object regions in a weakly supervised manner. We observe that image classifiers' attention maps at different training phases may focus on different parts of the target objects. Based on this observation, we propose an online attention accumulation (OAA) strategy that utilizes the attention maps at different training phases to obtain more integral object regions. Specifically, we maintain a cumulative attention map for each target category in each training image and utilize it to record the discovered object regions at different training phases. Albeit OAA can effectively mine more object regions for most images, for some training images, the range of the attention movement is not large, limiting the generation of integral object attention regions. To overcome this problem, we propose incorporating an attention drop layer into the online attention accumulation process to enlarge the range of attention movement during training explicitly. Our method (OAA) can be plugged into any classification network and progressively accumulate the discriminative regions into cumulative attention maps as the training process goes. Additionally, we also explore utilizing the final cumulative attention maps to serve as the pixel-level supervision, which can further assist the network in discovering more integral object regions. When applying the resulting attention maps to the weakly supervised semantic segmentation task, our approach improves the existing state-of-the-art methods on the PASCAL VOC 2012 segmentation benchmark, achieving a mIoU score of 67.2 percent on the test set.	[Jiang, Peng-Tao; Han, Ling-Hao; Cheng, Ming-Ming] Nankai Univ, Coll Comp Sci, TKLNDST, Tianjin 300350, Peoples R China; [Hou, Qibin] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Wei, Yunchao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 10044, Peoples R China	Nankai University; National University of Singapore; Beijing Jiaotong University	Cheng, MM (corresponding author), Nankai Univ, Coll Comp Sci, TKLNDST, Tianjin 300350, Peoples R China.	pt.jiang@mail.nankai.edu.cn; lhhan@mail.nankai.edu.cn; andrewhoux@gmail.com; cmm@nankai.edu.cn; Yunchao.Wei@uts.edu.au	Jiang, Peng-Tao/HHN-3328-2022		National Key Research and Development Program of China [2018AAA0100400]; NSFC [61922046]; S&T Innovation Project from the Chinese Ministry of Education; Fundamental Research Funds for Central Universities, Nankai University [63213090]	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); S&T Innovation Project from the Chinese Ministry of Education; Fundamental Research Funds for Central Universities, Nankai University	This research was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0100400, in part by the NSFC under Grant 61922046, in part by the S&T Innovation Project from the Chinese Ministry of Education, and in part by the Fundamental Research Funds for Central Universities, Nankai University, under Grant 63213090. A preliminary version of this work appeared at ICCV [1]. Both PyTorch [2] and Jittor [3] versions of the source code are publicly available via our project page: http://mmcheng.net/oaa/.Peng-Tao Jiang and Ling-Hao Han are equal contribution to this work.	Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523; Alan L. Yuille, 2016, Arxiv, DOI arXiv:1412.7062; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arpit D, 2017, PR MACH LEARN RES, V70; Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34; Bin Jin, 2017, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR.2017.185; Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9; Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097; Chaudhry A., 2017, P BRIT MACH VIS C LO, P201; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Cheng MM, 2019, COMPUT VIS MEDIA, V5, P3, DOI 10.1007/s41095-018-0120-1; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Choe J, 2019, PROC CVPR IEEE, P2214, DOI 10.1109/CVPR.2019.00232; Deepak Pathak, 2015, Arxiv, DOI arXiv:1412.7144; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Durand T, 2017, PROC CVPR IEEE, P5957, DOI 10.1109/CVPR.2017.631; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fan RC, 2018, LECT NOTES COMPUT SC, V11213, P371, DOI 10.1007/978-3-030-01240-3_23; Fong R, 2019, IEEE I CONF COMP VIS, P2950, DOI 10.1109/ICCV.2019.00304; Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Guolei Sun, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P347, DOI 10.1007/978-3-030-58536-5_21; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hong S, 2017, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2017.239; Hou Q., 2021, SCI SIN INFORM, V9; Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406; Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688; Hou QB, 2018, ADV NEUR IN, V31; Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4; Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069; Huang ZL, 2018, PROC CVPR IEEE, P7014, DOI 10.1109/CVPR.2018.00733; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang PT, 2019, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2019.00216; Jiaxing Zhao, 2018, Computational Visual Media, V4, P333, DOI 10.1007/s41095-018-0123-y; Jimmy Ba, 2015, Arxiv, DOI arXiv:1412.7755; Kim D, 2017, IEEE I CONF COMP VIS, P3554, DOI 10.1109/ICCV.2017.382; Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Li KP, 2020, IEEE T PATTERN ANAL, V42, P2996, DOI 10.1109/TPAMI.2019.2921543; Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960; Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404; Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849; Long J., 2015, P IEEE C COMPUTER VI, P3431, DOI DOI 10.1109/CVPR.2015.7298965; Massiceti D., 2017, INT WORKSHOP ENERGY, P263; Oh SJ, 2017, PROC CVPR IEEE, P5038, DOI 10.1109/CVPR.2017.535; Papadopoulos DP, 2014, LECT NOTES COMPUT SC, V8693, P361, DOI 10.1007/978-3-319-10602-1_24; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Paszke A, 2019, ADV NEUR IN, V32; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Qi XJ, 2016, LECT NOTES COMPUT SC, V9912, P90, DOI 10.1007/978-3-319-46484-8_6; Rebuffi Sylvestre-Alvise, 2020, CVPR; Roy A, 2017, PROC CVPR IEEE, P7282, DOI 10.1109/CVPR.2017.770; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Shimoda W, 2019, IEEE I CONF COMP VIS, P5207, DOI 10.1109/ICCV.2019.00531; Shimoda W, 2016, LECT NOTES COMPUT SC, V9908, P218, DOI 10.1007/978-3-319-46493-0_14; Wah C., 2011, CALTECHUCSD BIRDS 20; Wang HF, 2020, IEEE COMPUT SOC CONF, P111, DOI 10.1109/CVPRW50498.2020.00020; Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3; Wang X, 2018, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2018.00147; Wang XH, 2020, AAAI CONF ARTIF INTE, V34, P12249; Wang XK, 2021, IEEE T IND INFORM, V17, P2231, DOI [10.1109/TII.2020.2999901, 10.1109/TPAMI.2020.3015894]; Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687; Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Yu-Ting Chang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8988, DOI 10.1109/CVPR42600.2020.00901; Yude Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12272, DOI 10.1109/CVPR42600.2020.01229; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747; Zhang JM, 2016, LECT NOTES COMPUT SC, V9908, P543, DOI 10.1007/978-3-319-46493-0_33; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhang XL, 2018, LECT NOTES COMPUT SC, V11216, P610, DOI 10.1007/978-3-030-01258-8_37; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319	77	5	5	13	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					7062	7077		10.1109/TPAMI.2021.3092573	http://dx.doi.org/10.1109/TPAMI.2021.3092573			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34170821				2022-12-18	WOS:000853875300085
J	Zhang, X; Jiao, L; Granmo, OC; Goodwin, M				Zhang, Xuan; Jiao, Lei; Granmo, Ole-Christoffer; Goodwin, Morten			On the Convergence of Tsetlin Machines for the IDENTITY- and NOT Operators	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convergence; Training; Learning automata; Computer architecture; Training data; Task analysis; Pattern recognition; Tsetlin automata; propositional logic; tsetlin machine; convergence analysis		The Tsetlin Machine (TM) is a recent machine learning algorithm with several distinct properties, such as interpretability, simplicity, and hardware-friendliness. Although numerous empirical evaluations report on its performance, the mathematical analysis of its convergence is still open. In this article, we analyze the convergence of the TM with only one clause involved for classification. More specifically, we examine two basic logical operators, namely, the "IDENTITY"- and "NOT" operators. Our analysis reveals that the TM, with just one clause, can converge correctly to the intended logical operator, learning from training data over an infinite time horizon. Besides, it can capture arbitrarily rare patterns and select the most accurate one when two candidate patterns are incompatible, by configuring a granularity parameter. The analysis of the convergence of the two basic operators lays the foundation for analyzing other logical operators. These analyses altogether, from a mathematical perspective, provide new insights on why TMs have obtained state-of-the-art performance on several pattern recognition problems.	[Zhang, Xuan; Jiao, Lei; Granmo, Ole-Christoffer; Goodwin, Morten] Univ Agder, Ctr Artificial Intelligence Res, N-4879 Grimstad, Norway; [Zhang, Xuan] Norwegian Res Ctr NORCE, N-4879 Grimstad, Norway; [Zhang, Xuan] Confirmit, N-0279 Oslo, Norway; [Jiao, Lei; Granmo, Ole-Christoffer; Goodwin, Morten] Univ Agder, Dept ICT, N-4879 Grimstad, Norway	University of Agder; Norwegian Research Centre (NORCE); University of Agder	Jiao, L (corresponding author), Univ Agder, Ctr Artificial Intelligence Res, N-4879 Grimstad, Norway.	xuan.z.jiao@gmail.com; lei.jiao@uia.no; ole.granmo@uia.no; morten.goodwin@uia.no			project Spacetime Vision: Towards Unsupervised Learning in the 4D World - EEA and Norway Grants 2014-2021 [EEA-RO-NO-2018-04]	project Spacetime Vision: Towards Unsupervised Learning in the 4D World - EEA and Norway Grants 2014-2021	This work was supported by the project Spacetime Vision: Towards Unsupervised Learning in the 4D World financed by the EEA and Norway Grants 2014-2021 under Grant EEA-RO-NO-2018-04.	Abeyrathna Kuruge Darshana, 2020, Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices. 33rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12144), P686, DOI 10.1007/978-3-030-55789-8_59; Abeyrathna KD, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0165; Abeyrathna KD, 2021, PR MACH LEARN RES, V139; Berge G. T., IEEE ACCESS, V7, P134; Bhattarai B, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 2, P410, DOI 10.5220/0010382204100417; Blakely C. D., 2021, PROC 34 INT C IND EN; Christian W. Omlin, 2019, Arxiv, DOI arXiv:1905.09688; Jiao L, 2016, APPL INTELL, V44, P307, DOI 10.1007/s10489-015-0682-x; Lei J, 2021, J LOW POWER ELECT AP, V11, DOI 10.3390/jlpea11020018; Goodwin M, 2021, Arxiv, DOI arXiv:2104.06901; Narendra K. S., 1989, LEARNING AUTOMATA IN; Nicolae D. C., 2021, PROC 1 INT WORKSHOP; Granmo OC, 2021, Arxiv, DOI arXiv:1804.01508; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Saha Rupsa, 2020, Artificial Intelligence XXXVII. 40th SGAI International Conference on Artificial Intelligence, AI 2020. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNCS 12498), P67, DOI 10.1007/978-3-030-63799-6_5; Saha R., 2021, ARXIV; Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006; Shafik R, 2020, IEEE INT ON LINE; Tsetlin M. L, 1961, AUTOMAT REM CONTR+, V22, P1345; Wheeldon A, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0593; Yadav RK, 2021, AAAI CONF ARTIF INTE, V35, P14203; Yadav RK, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 2, P402, DOI 10.5220/0010382104020409; Yang Z, 2020, IEEE T COMMUN, V68, P3667, DOI 10.1109/TCOMM.2020.2982136; Yazidi A, 2020, IEEE T NEUR NET LEAR, V31, P512, DOI 10.1109/TNNLS.2019.2905162; Zhang X, 2020, IEEE T NEUR NET LEAR, V31, P284, DOI 10.1109/TNNLS.2019.2900639	26	5	5	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6345	6359		10.1109/TPAMI.2021.3085591	http://dx.doi.org/10.1109/TPAMI.2021.3085591			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34077353	Green Submitted			2022-12-18	WOS:000853875300037
J	Zhu, XG; Zhou, H; Wang, T; Hong, FZ; Li, W; Ma, YX; Li, HS; Yang, RG; Lin, DH				Zhu, Xinge; Zhou, Hui; Wang, Tai; Hong, Fangzhou; Li, Wei; Ma, Yuexin; Li, Hongsheng; Yang, Ruigang; Lin, Dahua			Cylindrical and Asymmetrical 3D Convolution Networks for LiDAR-Based Perception	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Laser radar; Convolution; Feature extraction; Gold; Task analysis; Solid modeling; Cylindrical partition; asymmetrical convolution; point cloud semantic segmentation; point cloud 3D detection; point cloud panoptic segmentation		State-of-the-art methods for driving-scene LiDAR-based perception (including point cloud semantic segmentation, panoptic segmentation and 3D detection, etc.) often project the point clouds to 2D space and then process them via 2D convolution. Although this cooperation shows the competitiveness in the point cloud, it inevitably alters and abandons the 3D topology and geometric relations. A natural remedy is to utilize the 3D voxelization and 3D convolution network. However, we found that in the outdoor point cloud, the improvement obtained in this way is quite limited. An important reason is the property of the outdoor point cloud, namely sparsity and varying density. Motivated by this investigation, we propose a new framework for the outdoor LiDAR segmentation, where cylindrical partition and asymmetrical 3D convolution networks are designed to explore the 3D geometric pattern while maintaining these inherent properties. The proposed model acts as a backbone and the learned features from this model can be used for downstream tasks such as point cloud semantic and panoptic segmentation or 3D detection. In this paper, we benchmark our model on these three tasks. For semantic segmentation, we evaluate the proposed model on several large-scale datasets, i.e., SemanticKITTI, nuScenes and A2D2. Our method achieves the state-of-the-art on the leaderboard of SemanticKITTI (both single-scan and multi-scan challenge), and significantly outperforms existing methods on nuScenes and A2D2 dataset. Furthermore, the proposed 3D framework also shows strong performance and good generalization on LiDAR panoptic segmentation and LiDAR 3D detection.	[Zhu, Xinge; Wang, Tai; Li, Hongsheng; Lin, Dahua] Chinese Univ Hong Kong, Hong Kong, Peoples R China; [Zhou, Hui] SenseTime Res, Hong Kong, Peoples R China; [Hong, Fangzhou] Nanyang Technol Univ, Singapore 639798, Singapore; [Li, Wei] Peking Univ, Beijing 100871, Peoples R China; [Ma, Yuexin] ShanghaiTech Univ, Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai 201210, Peoples R China; [Yang, Ruigang] Univ Kentucky, Lexington, KY 40506 USA	Chinese University of Hong Kong; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Peking University; ShanghaiTech University; University of Kentucky	Ma, YX (corresponding author), ShanghaiTech Univ, Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai 201210, Peoples R China.	zx018@ie.cuhk.edu.hk; smarthuizhou@gmail.com; wt019@ie.cuhk.edu.hk; fangzhouhong820@gmail.com; liweimcc@gmail.com; mayuexin@shanghaitech.edu.cn; hsli@ee.cuhk.edu.hk; ryang@cs.uky.edu; dhlin@ie.cuhk.edu.hk			Centre for Perceptual and Interactive Intelligence Limited; GRF through the Research Grants Council of Hong Kong [14208417, 14207319, 14203518, ITS/431/18FX]; CUHK Strategic Fund; CUHK [TS1712093]; Shanghai Committee of Science and Technology, China [20DZ1100800]	Centre for Perceptual and Interactive Intelligence Limited; GRF through the Research Grants Council of Hong Kong; CUHK Strategic Fund; CUHK(Chinese University of Hong Kong); Shanghai Committee of Science and Technology, China(Shanghai Science & Technology Committee)	This work was supported in part by the Centre for Perceptual and Interactive Intelligence Limited, in part by the GRF through the Research Grants Council of Hong Kong under Grants 14208417, 14207319, and 14203518 and ITS/431/18FX, in part by CUHK Strategic Fund and CUHK Agreement TS1712093, in part by the Shanghai Committee of Science and Technology, China under Grant 20DZ1100800.	Achituve I, 2021, IEEE WINT CONF APPL, P123, DOI 10.1109/WACV48630.2021.00017; Alonso I, 2020, IEEE ROBOT AUTOM LET, V5, P5432, DOI 10.1109/LRA.2020.3007440; Andres Milioto, 2020, Arxiv, DOI arXiv:2003.02371; Behley J, 2019, IEEE I CONF COMP VIS, P9296, DOI 10.1109/ICCV.2019.00939; Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464; Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen Liang-Chieh, 2018, P EUROPEAN C COMPUTE, P801; Chenfeng Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P1, DOI 10.1007/978-3-030-58604-1_1; Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319; Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49; Cong P., 2021, PROC IEEE INT C MULT, P1; Cortinhal Tiago, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12510), P207, DOI 10.1007/978-3-030-64559-5_16; Dahua Lin, 2020, Arxiv, DOI arXiv:2004.02724; Deyvid Kochanov, 2020, Arxiv, DOI arXiv:2007.12668; Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200; Engelmann F, 2019, LECT NOTES COMPUT SC, V11131, P395, DOI 10.1007/978-3-030-11015-4_29; Engelmann Francis, 2020, P IEEE CVF C COMP VI, P9031, DOI DOI 10.1109/CVPR42600.2020.00905; Feihu Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P644, DOI 10.1007/978-3-030-58586-0_38; Gerdzhev M., 2020, ARXIV; Geyer J., 2020, ARXIV; Gong B., 2021, PROC IEEECVF C COMPU, p15 363; Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961; Han L, 2020, PROC CVPR IEEE, P2937, DOI 10.1109/CVPR42600.2020.00301; Haotian* Tang Zhijian*, 2020, EUR C COMP VIS; Hong FZ, 2021, PROC CVPR IEEE, P13085, DOI 10.1109/CVPR46437.2021.01289; Hu Q, 2020, PROC IEEECVF C COMPU, p11 108; Jiang L, 2020, PROC CVPR IEEE, P4866, DOI 10.1109/CVPR42600.2020.00492; Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963; Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479; Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298; Langer F, 2020, IEEE INT C INT ROBOT, P8263, DOI 10.1109/IROS45743.2020.9341508; Long J., 2015, P IEEE C COMPUTER VI, P3431, DOI DOI 10.1109/CVPR.2015.7298965; Lyu Yecheng, 2020, P IEEE CVF C COMP VI, P12255, DOI DOI 10.1109/CVPR42600.2020.01227; Meng HY, 2019, IEEE I CONF COMP VIS, P8499, DOI 10.1109/ICCV.2019.00859; Milioto A, 2020, IEEE INT C INT ROBOT, P8505, DOI 10.1109/IROS45743.2020.9340837; Milioto A, 2019, IEEE INT C INT ROBOT, P4213, DOI 10.1109/IROS40897.2019.8967762; Petar Velickovic, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1710.10903; Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16; Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556; Pham QH, 2019, PROC CVPR IEEE, P8819, DOI 10.1109/CVPR.2019.00903; Ronneberger O., 2015, P MEDICAL IMAGE COMP, P234; Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054; Shi HY, 2020, PROC CVPR IEEE, P4573, DOI 10.1109/CVPR42600.2020.00463; Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252; Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409; Tchapmi LP, 2017, INT CONF 3D VISION, P537, DOI 10.1109/3DV.2017.00067; Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651; Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054; Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362; Wang Yue, 2020, ECCV; Wanli Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P52, DOI 10.1007/978-3-030-58520-4_4; Wu BC, 2019, IEEE INT CONF ROBOT, P4376, DOI 10.1109/ICRA.2019.8793495; Wu BC, 2018, IEEE INT CONF ROBOT, P1887; Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985; Xinge Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P581, DOI 10.1007/978-3-030-58595-2_35; Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337; Yang Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9598, DOI 10.1109/CVPR42600.2020.00962; Yin TW, 2021, PROC CVPR IEEE, P11779, DOI 10.1109/CVPR46437.2021.01161; Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064; Zhang ZY, 2019, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2019.00169; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhou Yin, 2019, C ROB LEARN, P923; Zhu XG, 2019, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2019.00078; Zhu XG, 2018, LECT NOTES COMPUT SC, V11211, P587, DOI 10.1007/978-3-030-01234-2_35	66	5	5	15	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6807	6822		10.1109/TPAMI.2021.3098789	http://dx.doi.org/10.1109/TPAMI.2021.3098789			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34310286	Green Submitted			2022-12-18	WOS:000853875300070
J	Hou, RB; Ma, BP; Chang, H; Gu, XQ; Shan, SG; Chen, XL				Hou, Ruibing; Ma, Bingpeng; Chang, Hong; Gu, Xinqian; Shan, Shiguang; Chen, Xilin			Feature Completion for Occluded Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Feature extraction; Probes; Convolution; Decoding; Computational modeling; Body regions; Person re-identification; occlusion problem; feature completion	ATTENTION; NETWORK	Person re-identification (reID) plays an important role in computer vision. However, existing methods suffer from performance degradation in occluded scenes. In this work, we propose an occlusion-robust block, Region Feature Completion (RFC), for occluded reID. Different from most previous works that discard the occluded regions, RFC block can recover the semantics of occluded regions in feature space. First, a Spatial RFC (SRFC) module is developed. SRFC exploits the long-range spatial contexts from non-occluded regions to predict the features of occluded regions. The unit-wise prediction task leads to an encoder/decoder architecture, where the region-encoder models the correlation between non-occluded and occluded region, and the region-decoder utilizes the spatial correlation to recover occluded region features. Second, we introduce Temporal RFC (TRFC) module which captures the long-term temporal contexts to refine the prediction of SRFC. RFC block is lightweight, end-to-end trainable and can be easily plugged into existing CNNs to form RFCnet. Extensive experiments are conducted on occluded and commonly holistic reID benchmarks. Our method significantly outperforms existing methods on the occlusion datasets, while remains top even superior performance on holistic datasets. The source code is available at https://github.com/blue-blue272/OccludedReID-RFCnet.	[Hou, Ruibing; Chang, Hong; Gu, Xinqian; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc Chinese Acad Sc, Beijing 100190, Peoples R China; [Hou, Ruibing; Chang, Hong; Gu, Xinqian; Chen, Xilin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Ma, Bingpeng] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 100049, Peoples R China; [Shan, Shiguang] CAS Ctr Excellence Brain Sci & Intelligence Techn, Shanghai 200031, Peoples R China	Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Ma, BP (corresponding author), Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 100049, Peoples R China.	ruibing.hou@uipl.ict.ac.cn; bpma@ucas.ac.cn; changhong@ict.ac.cn; xinqian.gu@uipl.ict.ac.cn; sgshan@ict.ac.cn; xlchen@ict.ac.cn			National Key R&D Program of China [2017YFA0700800]; Natural Science Foundation of China (NSFC) [61876171, 61976203]; Shenzhen Institute of Artificial Intelligence and Robotics for Society [AC01202005015]	National Key R&D Program of China; Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Shenzhen Institute of Artificial Intelligence and Robotics for Society	This work was supported in part by the National Key R&D Program of China (under Grant 2017YFA0700800) and Natural Science Foundation of China (NSFC) under Grants 61876171 and 61976203, and the Open Project Fund from Shenzhen Institute of Artificial Intelligence and Robotics for Society, under Grant AC01202005015.	Ba J, 2015, P 3 INT C LEARN REPR; Bai S, 2017, PROC CVPR IEEE, P3356, DOI 10.1109/CVPR.2017.358; Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128; Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149; Dai ZZ, 2019, IEEE I CONF COMP VIS, P3690, DOI 10.1109/ICCV.2019.00379; Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; Ge YX, 2018, ADV NEUR IN, V31; Gu XQ, 2019, IEEE I CONF COMP VIS, P9646, DOI 10.1109/ICCV.2019.00974; Guo JY, 2019, IEEE I CONF COMP VIS, P3641, DOI 10.1109/ICCV.2019.00374; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854; He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739; Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735; Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954; Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535; Jaderberg M, 2015, ADV NEUR IN, V28; Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406; Li JN, 2019, AAAI CONF ARTIF INTE, P8618; Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058; Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046; Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429; Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063; Liao XY, 2019, LECT NOTES COMPUT SC, V11366, P620, DOI 10.1007/978-3-030-20876-9_39; Lingxiao He, 2018, Arxiv, DOI arXiv:1810.07399; Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434; Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499; Liu ZM, 2017, IEEE I CONF COMP VIS, P2448, DOI 10.1109/ICCV.2017.266; McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148; Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063; Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Shen YT, 2018, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR.2018.00720; Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129; Song GL, 2018, AAAI CONF ARTIF INTE, P7347; Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427; Subramaniam A, 2019, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2019.00065; Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25; Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048; Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tian MQ, 2018, PROC CVPR IEEE, P5794, DOI 10.1109/CVPR.2018.00607; Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418; Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45; Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016; Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543; Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226; Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507; You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150; Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12; Zhang H, 2019, PR MACH LEARN RES, V97; Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076; Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103; Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349; Zhao YR, 2019, PROC CVPR IEEE, P4908, DOI 10.1109/CVPR.2019.00505; Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871; Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414; Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588; Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389; Zhou SP, 2017, PROC CVPR IEEE, P5028, DOI 10.1109/CVPR.2017.534; Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717; Zhu XT, 2018, IEEE T IMAGE PROCESS, V27, P2286, DOI 10.1109/TIP.2017.2740564; Zhuo JX, 2018, IEEE INT CON MULTI	78	5	5	12	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4894	4912		10.1109/TPAMI.2021.3079910	http://dx.doi.org/10.1109/TPAMI.2021.3079910			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33983879	Green Submitted			2022-12-18	WOS:000836666600032
