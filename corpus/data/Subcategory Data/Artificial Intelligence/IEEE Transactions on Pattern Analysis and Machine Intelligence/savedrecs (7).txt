PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Myles, Z; Lobo, ND				Myles, Z; Lobo, ND			Recovering affine motion and defocus blur simultaneously	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						defocus blur; affine motion; optical flow; defocussed motion		Motion in depth and/or zooming cause defocus blur. We show how the defocus blur in an image can be recovered simultaneously with affine motion. We introduce the theory, develop a solution method and demonstrate the validity of the theory and the solution by conducting experiments with real scenery.	Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Myles, Z (corresponding author), Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA.							BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; ENS J, 1991, COMPUTER VISION PATT, P600; Horn B., 1986, ROBOT VISION, P1; IRANI M, 1994, CVPR, P454; LAVEST JM, 1993, IEEE T ROBOTIC AUTOM, V9, P196, DOI 10.1109/70.238283; LIU HC, 1994, INT C PATT RECOG, P361; MA J, 1990, J OPT SOC AM A, V7, P1883, DOI 10.1364/JOSAA.7.001883; MANMATHA R, 1994, COMPUTER VISION PATT, P141; MOBASSERI BG, 1994, IEEE INT C IM PROC, V3, P78; NAYAR S, 1995, ICCV95, P995; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P522; Smith W. J., 1990, MODERN OPTICAL ENG; SUBBARAO M, 1993, 931021 STAT U NEW YO; SURYA G, 1993, CVPR, P61; WERKHOVEN P, 1990, BIOL CYBERN, V63, P185, DOI 10.1007/BF00195857; XIONG Y, 1993, IM UND WORKSH, P967	16	33	33	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1998	20	6					652	658		10.1109/34.683782	http://dx.doi.org/10.1109/34.683782			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZV807					2022-12-18	WOS:000074343300007
J	Stewart, AJ; Langer, MS				Stewart, AJ; Langer, MS			Toward accurate recovery of shape from shading under diffuse lighting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape-from-shading; diffuse lighting; interreflections; shadows; visual events; horizon; skyline	VISIBILITY	A new surface radiance model for diffuse lighting is presented which incorporates shadows, interreflections, and surface orientation. An algorithm is presented that uses this model to compute shape-from-shading under diffuse lighting. The algorithm is tested on both synthetic and real images, and is found to perform more accurately than the only previous algorithm for this problem.	NECI,PRINCETON,NJ 08540		Stewart, AJ (corresponding author), UNIV TORONTO,DEPT COMP SCI,10 KINGS COLL RD,ROOM SF4306,TORONTO,ON M5S 3G4,CANADA.							BERN M, 1994, ALGORITHMICA, V11, P360, DOI 10.1007/BF01187019; Cohen M. F., 1985, Computer Graphics, V19, P31, DOI 10.1145/325165.325171; COLE R, 1989, J SYMB COMPUT, V7, P11, DOI 10.1016/S0747-7171(89)80003-3; GIGUS Z, 1990, IEEE T PATTERN ANAL, V12; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595; LANGER MS, 1994, J OPT SOC AM A, V11, P467, DOI 10.1364/JOSAA.11.000467; LANGER MS, 1993, P 4 INT C COMP VIS B, P138; MOON P, 1981, PHOTIC FIELD; PLANTINGA H, 1990, INT J COMPUT VISION, V5, P137, DOI 10.1007/BF00054919; Siegel R., 1981, THERMAL RAD HEAT TRA; Stewart AJ, 1996, PROC CVPR IEEE, P411, DOI 10.1109/CVPR.1996.517105; Ward G. J., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P459, DOI 10.1145/192161.192286	15	33	34	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					1020	1025		10.1109/34.615450	http://dx.doi.org/10.1109/34.615450			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985					2022-12-18	WOS:A1997XX98500007
J	Aladjem, M				Aladjem, M			Linear discriminant analysis for two classes via removal of classification structure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						exploratory data analysis; dimension reduction; linear discriminant analysis; discriminant plots; structure removal		A new method for two-class linear discriminant analysis, called ''removal of classification structure,'' is proposed. Its novelty lies in the transformation of the data along an identified discriminant direction into data without discriminant information and iteration to obtain the next discriminant direction. It is free to search for discriminant directions oblique to each other and ensures that the informative directions already found will not be chosen again at a later stage. The efficacy of the method is examined for two discriminant criteria. Studies with a wide spectrum of synthetic data sets and a real data set indicate that the discrimination quality of these criteria can be improved by the proposed method.			Aladjem, M (corresponding author), BEN GURION UNIV NEGEV,DEPT ELECT & COMP ENGN,POB 653,IL-84105 BEER SHEVA,ISRAEL.			Aladjem, Mayer/0000-0003-3846-3417				ALADJEM M, 1991, COMPUT BIOL MED, V21, P321, DOI 10.1016/0010-4825(91)90014-Z; ALADJEM ME, 1994, SIGNAL PROCESS, V35, P1, DOI 10.1016/0165-1684(94)90186-4; ALADJEM ME, 1994, P 12 INT C PATT REC, V2, P67; Devijver PA, 1982, PATTERN RECOGNITION; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; FUKUNAGA K, 1985, IEEE T PATTERN ANAL, V7, P107, DOI 10.1109/TPAMI.1985.4767625; FUKUNAGA K, 1990, INTRO STATISTICAL PA; HAMAMOTO Y, 1991, PATTERN RECOGN, V24, P681, DOI 10.1016/0031-3203(91)90035-4; KRZANOWSKI WJ, 1995, J R STAT SOC C-APPL, V44, P101, DOI 10.2307/2986198; MALINA W, 1981, IEEE T PATTERN ANAL, V3, P611, DOI 10.1109/TPAMI.1981.4767154; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; SIEDLECKI W, 1988, PATTERN RECOGN, V21, P411, DOI 10.1016/0031-3203(88)90001-5	13	33	33	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					187	192		10.1109/34.574805	http://dx.doi.org/10.1109/34.574805			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800015
J	AviItzhak, H; Diep, T				AviItzhak, H; Diep, T			Arbitrarily tight upper and lower bounds on the Bayesian probability of error	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian decision; probability of error; statistical pattern recognition		This paper presents new upper and lower bounds on the minimum probability of error of Bayesian decision systems for the two-class problem. These bounds can be made arbitrarily close to the exact minimum probability of error, making them tighter than any previously known bounds.	CANON RES CTR,PALO ALTO,CA 94304	Canon Incorporated	AviItzhak, H (corresponding author), STANFORD UNIV,DEPT ELECT ENGN,INFORMAT SYST LAB,STANFORD,CA 94305, USA.							DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; Duda R.O., 1973, J ROYAL STAT SOC SER; HASHLAMOUN WA, 1994, IEEE T PATTERN ANAL, V16, P220, DOI 10.1109/34.273728; HELLMAN ME, 1970, IEEE T INFORMATION T, V16	5	33	33	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					89	91		10.1109/34.476017	http://dx.doi.org/10.1109/34.476017			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500013
J	DAS, S; AHUJA, N				DAS, S; AHUJA, N			PERFORMANCE ANALYSIS OF STEREO, VERGENCE, AND FOCUS AS DEPTH CUES FOR ACTIVE VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ACTIVE VISION; RANGE FROM STEREO; RANGE FROM VERGENCE; RANGE FROM FOCUS; PERFORMANCE EVALUATION; UNCERTAINTY ANALYSIS	QUANTIZATION-ERROR	This paper compares the performances of the binocular cues of stereo and vergence, and the monocular cue of focus for range estimation using an active vision system. The performance of each cue is characterized in terms of sensitivity to errors in the imaging parameters. The effects of random, quantization errors are expressed in terms of the standard deviation of the resulting depth error. The effect of systematic, calibration errors on estimation using each cue is also studied. Performance characterization of each cue is utilized to evaluate the relative performance of the cues. Also discussed, based on such characterization, are ways to select a cue taking into account the computational and reliability aspects of the corresponding estimation process.	UNIV ILLINOIS,COORDINATED SCI LAB,BECKMAN INST,URBANA,IL 61801; UNIV ILLINOIS,DEPT ELECT & COMP ENGN,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign								AHUJA N, 1993, IEEE T PATTERN ANAL, V15, P1007, DOI 10.1109/34.254059; BLOSTEIN SD, 1987, IEEE T PATTERN ANAL, V9, P752, DOI 10.1109/TPAMI.1987.4767982; DAS S, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P485; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; KAMGARPARSI B, 1989, IEEE T PATTERN ANAL, V11, P929, DOI 10.1109/34.35496; Krotkov EP, 1989, ACTIVE COMPUTER VISI; MATTHIES L, 1987, IEEE T ROBOTIC AUTOM, V3, P239, DOI 10.1109/JRA.1987.1087097; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; RODRIGUEZ JJ, 1990, IEEE T PATTERN ANAL, V12, P467, DOI 10.1109/34.55106; SNYDER MA, 1987, DARPA IMAGE UNDERSTA, P681	10	33	33	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1213	1219		10.1109/34.476513	http://dx.doi.org/10.1109/34.476513			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500008
J	GRIMSON, WEL				GRIMSON, WEL			THE COMBINATORICS OF HEURISTIC-SEARCH TERMINATION FOR OBJECT RECOGNITION IN CLUTTERED ENVIRONMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPLEXITY BOUNDS; CONSTRAINED SEARCH; OBJECT RECOGNITION	CONSTRAINT SATISFACTION PROBLEMS; MODEL-BASED RECOGNITION; LOCALIZATION; CONSISTENCY; ALGORITHMS; NETWORKS; TREE	Many current recognition systems use constrained search to locate objects in cluttered environments. Earlier analysis of one class of methods has shown that the expected amount of search is quadratic in the number of model and data features, if all the data is known to come from a single object, but is exponential when spurious data is included. To overcome this, many methods terminate a search once an interpretation that is "good enough" is found. In this paper, we formally examine the combinatorics of this approach, showing that choosing correct termination procedures can dramatically reduce the search. In particular, we provide conditions on the object model and the scene clutter such that the expected search is at most quartic. The analytic results are shown to be in agreement with empirical data for cluttered object recognition. These results imply that it is critical to use techniques that select subsets of the data likely to have come from a single object before establishing a correspondence between data and model features.			GRIMSON, WEL (corresponding author), MIT, ARTIFICIAL INTELLIGENCE LAB, CAMBRIDGE, MA 02139 USA.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; DRUMHELLER M, 1987, IEEE T PATTERN ANAL, V9, P325, DOI 10.1109/TPAMI.1987.4767907; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FREUDER EC, 1982, J ACM, V29, P24, DOI 10.1145/322290.322292; FREUDER EC, 1978, COMMUN ACM, V21, P958, DOI 10.1145/359642.359654; GASCHNIG J, 1979, THESIS CARNEGIEMELLO; GASTON PC, 1984, IEEE T PATTERN ANAL, V6, P257, DOI 10.1109/TPAMI.1984.4767518; Grimson W. E. L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P700, DOI 10.1109/CCV.1988.590054; GRIMSON WEL, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P644; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GRIMSON WEL, 1990, ARTIF INTELL, V44, P121, DOI 10.1016/0004-3702(90)90100-E; HARALICK RM, 1980, ARTIF INTELL, V14, P263, DOI 10.1016/0004-3702(80)90051-X; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HUTTENLOCHER DP, 1989, MIT TR1045 ART INT L; JACOBS DW, 1988, MIT1023 ART IN LAB; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MACKWORTH AK, 1985, ARTIF INTELL, V25, P65, DOI 10.1016/0004-3702(85)90041-4; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; MURRAY DW, 1987, COMPUT VISION GRAPH, V40, P250, DOI 10.1016/S0734-189X(87)80118-4; MURRAY DW, 1988, INT J COMPUT VISION, V2, P153, DOI 10.1007/BF00133698; MURRAY DW, 1987, IMAGE VISION COMPUT, V5, P85, DOI 10.1016/0262-8856(87)90032-1; NUDEL B, 1983, ARTIF INTELL, V21, P135, DOI 10.1016/S0004-3702(83)80008-3; Sha'ashua A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P321, DOI 10.1109/CCV.1988.590008; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; [No title captured]	30	33	35	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1991	13	9					920	935		10.1109/34.93810	http://dx.doi.org/10.1109/34.93810			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GJ180		Green Submitted			2022-12-18	WOS:A1991GJ18000006
J	BENARIE, J				BENARIE, J			THE PROBABILISTIC PEAKING EFFECT OF VIEWED ANGLES AND DISTANCES WITH APPLICATION TO 3-D OBJECT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BENARIE, J (corresponding author), IIT, DEPT ELECT & COMP ENGN, CHICAGO, IL 60616 USA.							AUGUSTEIJN MF, 1985, JUN P IEEE C COMP VI, P100; BENARIE J, 1987, COMPUT VISION GRAPH, V37, P345, DOI 10.1016/0734-189X(87)90042-9; BENARIE J, 1988, NOV P ICPR C ROM, P309; BENARIE J, 1990, PATTERN RECOGNIT JUN; BENARIE J, 1986, COMPUTER VISION 3D 2; BENARIE J, 1988, VISION SYSTEM 3D OBJ; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HOTTENLOCHER D, 1987, FEB P DARPA IM UND W; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; STEVENS KA, 1979, ARTIFICIAL INTELLIGE, V2; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	14	33	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1990	12	8					760	774		10.1109/34.57667	http://dx.doi.org/10.1109/34.57667			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DQ388					2022-12-18	WOS:A1990DQ38800003
J	CLARK, JJ				CLARK, JJ			SINGULARITY THEORY AND PHANTOM EDGES IN SCALE SPACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											CLARK, JJ (corresponding author), HARVARD UNIV, DIV APPL SCI, CAMBRIDGE, MA 02138 USA.			Clark, James/0000-0002-4512-6171				ARNOLD VI, 1981, SINGULARITY THEORY; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CLARK JJ, 1987, 1ST P INT C COMP VIS, P491; CLARK JJ, 1986, AUTHENTICATING EDGES; CLARK JJ, IN PRESS IEEE T PATT; Gilmore R., 1981, CATASTROPHE THEORY S; Guillemin V., 2010, DIFFERENTIAL TOPOLOG, V370; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HUMMEL RA, 1984, 111 NEW YORK U COMP; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION; Milnor J., 1963, ANN MATH STUD, V51; Poston T., 2014, CATASTROPHE THEORY I; RICHTER J, 1986, BIOL CYBERN, V53, P195, DOI 10.1007/BF00342887; SHAH M, 1986, COMPUT VISION GRAPH, V34, P321, DOI 10.1016/S0734-189X(86)80046-9; STANSFIELD JL, 1980, MIT AI601 LAB MEM; Thom R., 2018, STRUCTURAL STABILITY; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	23	33	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					720	727		10.1109/34.6782	http://dx.doi.org/10.1109/34.6782			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500013
J	YODA, H; OHUCHI, Y; TANIGUCHI, Y; EJIRI, M				YODA, H; OHUCHI, Y; TANIGUCHI, Y; EJIRI, M			AN AUTOMATIC WAFER INSPECTION SYSTEM USING PIPELINED IMAGE-PROCESSING TECHNIQUES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									HITACHI LTD,MUSASHI WORKS,KODAIRA,TOKYO 187,JAPAN	Hitachi Limited	YODA, H (corresponding author), HITACHI LTD,CENT RES LAB,DEPT 6,KOKUBUNJI,TOKYO 185,JAPAN.							AWAMURA D, 1984, SEMICONDUCTOR WO JUN, P112; BRUNING JH, 1975, IEEE T ELECTRON DEV, VED22, P487, DOI 10.1109/T-ED.1975.18167; Ejiri M., 1973, COMPUT VISION GRAPH, V2, P326, DOI 10.1016/0146-664X(73)90011-7; FUSEK RL, 1985, OPT ENG, V24, P731, DOI 10.1117/12.7973567; GOTO N, 1978, 4TH P INT JOINT C PA, P970; HARA Y, 1983, IEEE T PATTERN ANAL, V5, P623, DOI 10.1109/TPAMI.1983.4767453; HARRIS K, 1984, SOLDI STATE TECHNOLG, P159; HARRIS K, 1983, SOLID STATE TECH AUG; HSIEH YY, 1980, COMPUT VISION GRAPH, V14, P293, DOI 10.1016/0146-664X(80)90024-6; JARVIS JF, 1980, IEEE T PATTERN ANAL, V2, P77, DOI 10.1109/TPAMI.1980.4766975; Konishi T., 1982, Journal of the Institute of Television Engineers of Japan, V36, P38, DOI 10.3169/itej1978.36.38; PAU LF, 1983, IEEE T PATTERN ANAL, V5, P602, DOI 10.1109/TPAMI.1983.4767449; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8	13	33	38	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1988	10	1					4	16		10.1109/34.3863	http://dx.doi.org/10.1109/34.3863			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	L4366					2022-12-18	WOS:A1988L436600002
J	BOLLE, RM; COOPER, DB				BOLLE, RM; COOPER, DB			BAYESIAN RECOGNITION OF LOCAL 3-D SHAPE BY APPROXIMATING IMAGE INTENSITY FUNCTIONS WITH QUADRIC POLYNOMIALS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BOLLE, RM (corresponding author), BROWN UNIV,DIV ENGN,ENGN MAN MACHINE SYST LAB,PROVIDENCE,RI 02912, USA.							Apostol T., 1969, CALCULUS, VII; BECK F, 1974, SURFACE COLOR PERCEP; CERNUSCHIFRIAS B, 1984, IEEE T PATTERN ANAL, V6, P430, DOI 10.1109/TPAMI.1984.4767548; CERNUSCHIFRIAS B, 1983, 8TH P INT JOINT C AR, P966; CHEN PC, 1980, COMPUT VISION GRAPH, V12, P153, DOI 10.1016/0146-664X(80)90009-X; COOPER DB, 1974, IEEE T INFORM THEORY, V12, P455; FOLEY FD, 1982, FUNDAMENTALS INTERAC; HAKALA DG, 1981, AUG SIGGRAPH 81 SEM; HARALICK RM, 1979, AUG P IEEE C PATT RE, P489; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1979, APPL OPT, V18, P1170; HORN BKP, 1970, MIT MAC TR79; LINDLEY DV, 1961, 4TH P BERK S MATH ST, V12, P453; MORGENTHALER DG, 1981, IEEE T PATTERN ANAL, V3, P482, DOI 10.1109/TPAMI.1981.4767134; PREWITT FMS, 1970, PICTURE PROCESSING P, P75; SCHUMAKER LL, 1979, APPROXIMATION THEORY, V2; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; Von Mises R., 1964, MATH THEORY PROBABIL	18	33	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					418	429		10.1109/TPAMI.1984.4767547	http://dx.doi.org/10.1109/TPAMI.1984.4767547			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SY289	21869210				2022-12-18	WOS:A1984SY28900003
J	CHIANG, YT; FU, KS				CHIANG, YT; FU, KS			PARALLEL PARSING ALGORITHMS AND VLSI IMPLEMENTATIONS FOR SYNTACTIC PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV, SCH ELECT ENGN, W LAFAYETTE, IN 47907 USA	Purdue University System; Purdue University; Purdue University West Lafayette Campus								Aho A.V., 1972, THEORY PARSING TRANS; Aho Alfred V., 1977, PRINCIPLES COMPILER; Aho AV, 1974, DESIGN ANAL COMPUTER; CHIANG YT, 1981, NOV P IEEE WORKSH CA; CHIANG YT, 1983, TREE834 PURD U SCH E; CHU K, 1982, 9TH P ANN INT S COMP; FOSTER MJ, 1980, IEEE COMPUTER, V13; Fu K.S., 1974, MATH SCI ENG; FU KS, 1973, IEEE T COMPUT, VC 22, P1087, DOI 10.1109/T-C.1973.223654; FU KS, 1976, DATA STRUCTURE COMPU; FU KS, 1982, SYNTACTIC PATTERN RE; GRAHAM SL, 1976, ADV COMPUTERS, V14; GRAHAM SL, 1976, 8TH P ANN ACM S THEO; GUIBAS LJ, 1979, JAN P CALTECH C VLSI; KOSARAJU SR, 1975, SIAM J COMPUT, V4; Kung H., 1980, INTRO VLSI SYSTEMS; KUNG HT, 1979, JAN P CALTECH C VLSI; LYON G, 1974, COMMUN ASS COMPUT MA, V17; PERSOON E, 1975, INT J COMPUT INFORM, V4; QINGYUN S, 1982, INFORM SCIENCES, V26, P159, DOI 10.1016/0020-0255(82)90040-8; ROUNDS WC, 1968, OCT IEEE C REC S SWI; TANAKA E, 1978, IEEE T COMPUT, V27, P605, DOI 10.1109/TC.1978.1675160; VALIANT L, 1975, J COMPUT SYST SCI, V10; WEICKER R, 1976, 182 PENNS STAT U DEP	24	33	34	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					302	314		10.1109/TPAMI.1984.4767522	http://dx.doi.org/10.1109/TPAMI.1984.4767522			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SR542	21869196				2022-12-18	WOS:A1984SR54200005
J	LU, SY				LU, SY			A TREE-MATCHING ALGORITHM BASED ON NODE SPLITTING AND MERGING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											LU, SY (corresponding author), EXXON PROD RES CO,POB 2189,HOUSTON,TX 77025, USA.							Aho AV, 1974, DESIGN ANAL COMPUTER; BAH LR, 1975, IEEE T INFORM THEORY, V21; CHENG JK, 1981, PATTERN RECOGN, V13, P371, DOI 10.1016/0031-3203(81)90093-5; EHRICH RW, 1976, IEEE T COMPUT, V25, P725, DOI 10.1109/TC.1976.1674681; FU KS, 1978, IEEE T SYST MAN CYBE, V8; HOROWITZ SL, 1975, COMMUN ASS COMPUT MA, V18; KNUTH D, 1967, ART COMPUTER PROGRAM, V1; LU SY, 1979, IEEE T PATTERN ANAL, V1; LU SY, 1982, 6TH P INT C PATT REC, P178; SHAPIRO LG, 1980, 5TH P INT C PATT REC; TAI KC, 1979, J ASS COMPUT MACH, V26; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811	12	33	34	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	2					249	256		10.1109/TPAMI.1984.4767511	http://dx.doi.org/10.1109/TPAMI.1984.4767511			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SF591	21869190				2022-12-18	WOS:A1984SF59100014
J	Ben, XY; Ren, Y; Zhang, JP; Wang, SJ; Kpalma, K; Meng, WX; Liu, YJ				Ben, Xianye; Ren, Yi; Zhang, Junping; Wang, Su-Jing; Kpalma, Kidiyo; Meng, Weixiao; Liu, Yong-Jin			Video-Based Facial Micro-Expression Analysis: A Survey of Datasets, Features and Algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Micro-expression analysis; survey; spotting; recognition; facial features; datasets	OPTICAL-FLOW; DETECTING DECEPTION; RECOGNITION; CLASSIFICATION; IDENTIFICATION; EMOTIONS; SYSTEM	Unlike the conventional facial expressions, micro-expressions are involuntary and transient facial expressions capable of revealing the genuine emotions that people attempt to hide. Therefore, they can provide important information in a broad range of applications such as lie detection, criminal detection, etc. Since micro-expressions are transient and of low intensity, however, their detection and recognition is difficult and relies heavily on expert experiences. Due to its intrinsic particularity and complexity, video-based micro-expression analysis is attractive but challenging, and has recently become an active area of research. Although there have been numerous developments in this area, thus far there has been no comprehensive survey that provides researchers with a systematic overview of these developments with a unified evaluation. Accordingly, in this survey paper, we first highlight the key differences between macro- and micro-expressions, then use these differences to guide our research survey of video-based micro-expression analysis in a cascaded structure, encompassing the neuropsychological basis, datasets, features, spotting algorithms, recognition algorithms, applications and evaluation of state-of-the-art approaches. For each aspect, the basic techniques, advanced developments and major challenges are addressed and discussed. Furthermore, after considering the limitations of existing micro-expression datasets, we present and release a new dataset - called micro-and-macro expression warehouse (MMEW) - containing more video samples and more labeled emotion types. We then perform a unified comparison of representative methods on CAS(ME)(2) for spotting, and on MMEW and SAMM for recognition, respectively. Finally, some potential future research directions are explored and outlined.	[Ben, Xianye; Ren, Yi] Shandong Univ, Sch Informat Sci & Engn, Qingdao 266237, Peoples R China; [Zhang, Junping] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200433, Peoples R China; [Wang, Su-Jing] Chinese Acad Sci, Inst Psychol, State Key Lab Brain & Cognit Sci, Beijing 100101, Peoples R China; [Kpalma, Kidiyo] Inst Natl Sci Appl Rennes, IETR CNRS UMR 6164, F-35708 Rennes, France; [Meng, Weixiao] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150080, Peoples R China; [Liu, Yong-Jin] Tsinghua Univ, Dept Comp Sci & Technol, BNRist, MOE Key Lab Pervas Comp, Beijing 100084, Peoples R China	Shandong University; Fudan University; Chinese Academy of Sciences; Institute of Psychology, CAS; Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS); Harbin Institute of Technology; Tsinghua University	Wang, SJ (corresponding author), Chinese Acad Sci, Inst Psychol, State Key Lab Brain & Cognit Sci, Beijing 100101, Peoples R China.; Liu, YJ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, BNRist, MOE Key Lab Pervas Comp, Beijing 100084, Peoples R China.	benxianye@gmail.com; yiren@mail.sdu.edu.cn; jpzhang@fudan.edu.cn; wangsujing@psych.ac.cn; Kidiyo.Kpalma@insa-rennes.fr; wxmeng@hit.edu.cn; liuyongjin@tsinghua.edu.cn	Liu, Yong/GWQ-6163-2022		National Key R&D Program of China [2017YFC0803401]; Natural Science Foundation of China [61725204, 61521002, 61971468, 61571275]; Key Scientific Technological Innovation Research Project by Ministry of Education, Shandong Provincial Key Research and Development Program (Major Scientific and Technological Innovation Project) [2019 JZZY010119]; Shanghai Municipal Science and Technology Major Project [2018SHZDZX01]; ZJLab	National Key R&D Program of China; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Scientific Technological Innovation Research Project by Ministry of Education, Shandong Provincial Key Research and Development Program (Major Scientific and Technological Innovation Project); Shanghai Municipal Science and Technology Major Project; ZJLab	The authors would like to thank the associate editor and three anonymous reviewers for their valuable comments, which greatly improve the quality of this paper. This work was partially supported by the National Key R&D Program of China under Grant 2017YFC0803401, the Natural Science Foundation of China (61725204, 61521002, 61971468, 61571275), Key Scientific Technological Innovation Research Project by Ministry of Education, Shandong Provincial Key Research and Development Program (Major Scientific and Technological Innovation Project) under Grant 2019 JZZY010119, the Shanghai Municipal Science and Technology Major Project (2018SHZDZX01) and ZJLab.	Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606; Ngo ACL, 2016, INT CONF ACOUST SPEE, P1243, DOI 10.1109/ICASSP.2016.7471875; [Anonymous], 2009, TELLING LIES CLUES D; [Anonymous], 2018, IEEE T AFFECT COMPUT, DOI DOI 10.1109/TAFFC.2017.2667642; Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442; Bartlett M., 2010, DYNAMIC FACES INSIGH, P211; Ben XY, 2018, PATTERN RECOGN LETT, V107, P50, DOI 10.1016/j.patrec.2017.07.010; Ben XY, 2016, NEURAL COMPUT APPL, V27, P2629, DOI 10.1007/s00521-015-2031-8; Bhushan B., 2015, UNDERSTANDING FACIAL, P265; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821; Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8; Chen MT, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P427, DOI 10.1109/RCAR.2016.7784067; Chunlong Hu, 2018, 2018 24th International Conference on Pattern Recognition (ICPR), P946, DOI 10.1109/ICPR.2018.8545555; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cristinacce D., 2006, P BRIT MACH VIS C, V3, P929; Darwin Charles, 1872, EXPRESSION EMOTIONS, DOI [10.1037/h0076058, DOI 10.1037/10001-000]; Davison AK, 2018, IEEE T AFFECT COMPUT, V9, P116, DOI 10.1109/TAFFC.2016.2573832; Davison AK, 2015, IEEE SYS MAN CYBERN, P1864, DOI 10.1109/SMC.2015.326; Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Duda O. R., 2000, PATTERN CLASSIFICATI; Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010; EKMAN P, 1974, J PERS SOC PSYCHOL, V29, P288, DOI 10.1037/h0036006; EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575; Ekman P., 2005, WHAT FACE REVEALS BA, V68, P83; Ekman P., 1969, SEMIOTICA, V1, P49, DOI [https://doi.org/10.1515/semi.1969.1.1.49, DOI 10.1515/SEMI.1969.1.1.49]; Ekman P., 2009, PHILOS DECEPT, P118; Ekman P, 2006, BEHAV SCI LAW, V24, P673, DOI 10.1002/bsl.729; Fernandez-Delgado M, 2014, J MACH LEARN RES, V15, P3133; Fleischmann O., 2008, THESIS U KIEL DEP CO; Frank M., 2013, P ANN M INT COMM ASS, P3515; Frank MG, 1997, J PERS SOC PSYCHOL, V72, P1429, DOI 10.1037/0022-3514.72.6.1429; Freitas-Magalh aes A., 2020, PSYCHOL EMOTIONS ALL; Friesen E., 1978, CONSULTING PSYCHOL P, V3, P1; Guo YF, 2021, IEEE MULTIMEDIA, V28, P29, DOI 10.1109/MMUL.2021.3058017; Guo YC, 2015, OPTIK, V126, P4446, DOI 10.1016/j.ijleo.2015.08.167; Han YH, 2018, IEEE IMAGE PROC, P1942, DOI 10.1109/ICIP.2018.8451065; He JC, 2017, PATTERN RECOGN, V66, P44, DOI 10.1016/j.patcog.2016.11.029; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; HESS U, 1990, EUR J SOC PSYCHOL, V20, P369, DOI 10.1002/ejsp.2420200502; Hong XP, 2016, NEUROCOMPUTING, V184, P99, DOI 10.1016/j.neucom.2015.07.134; Huang XH, 2019, IEEE T AFFECT COMPUT, V10, P32, DOI 10.1109/TAFFC.2017.2713359; Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096; Huang XH, 2013, LECT NOTES COMPUT SC, V7944, P1; Huang XH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1, DOI 10.1109/ICCVW.2015.10; Hughes MA, 2003, LIBR J, V128, P140; Hurley CM, 2011, J NONVERBAL BEHAV, V35, P119, DOI 10.1007/s10919-010-0102-1; Husak P., 2017, 22 COMP VIS WINT WOR, P1; Jia XT, 2018, J COMPUT SCI-NETH, V25, P289, DOI 10.1016/j.jocs.2017.03.016; Kamarol SKA, 2016, IET IMAGE PROCESS, V10, P534, DOI 10.1049/iet-ipr.2015.0519; Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105; Kim DH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P382, DOI 10.1145/2964284.2967247; Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446; Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717; Li YT, 2018, IEEE IMAGE PROC, P3094, DOI 10.1109/ICIP.2018.8451376; Liong ST, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P665, DOI 10.1109/ACPR.2015.7486586; Liong ST, 2015, LECT NOTES COMPUT SC, V9009, P644, DOI 10.1007/978-3-319-16631-5_47; Liu YJ, 2021, IEEE T AFFECT COMPUT, V12, P254, DOI 10.1109/TAFFC.2018.2854166; Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205; Lu ZY, 2015, LECT NOTES COMPUT SC, V9009, P698, DOI 10.1007/978-3-319-16631-5_51; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Matsumoto D, 2011, MOTIV EMOTION, V35, P181, DOI 10.1007/s11031-011-9212-2; Milborrow S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P380; Moilanen A, 2014, INT C PATT RECOG, P1722, DOI 10.1109/ICPR.2014.303; Nag S, 2019, INT CONF ACOUST SPEE, P2022, DOI 10.1109/ICASSP.2019.8683737; Niu MY, 2019, INT CONF ACOUST SPEE, P2112, DOI 10.1109/ICASSP.2019.8682295; Oh YH, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01128; Oh YH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1237, DOI 10.1109/ICDSP.2015.7252078; Oh YH, 2016, INT CONF ACOUST SPEE, P1851, DOI 10.1109/ICASSP.2016.7471997; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972; Patel D, 2015, LECT NOTES COMPUT SC, V9386, P369, DOI 10.1007/978-3-319-25903-1_32; Peng M, 2018, IEEE INT CONF AUTOMA, P657, DOI 10.1109/FG.2018.00103; Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745; Perez-Rosas V, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P59, DOI 10.1145/2818346.2820758; Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401; Polikovsky S., 2010, KAMEDAS PUBLICATION, V110, P57; Polikovsky S., 2009, 3 INT C CRIM DET PRE, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]; Polikovsky S, 2013, IEICE T INF SYST, VE96D, P81, DOI 10.1587/transinf.E96.D.81; Porter S, 2008, PSYCHOL SCI, V19, P508, DOI 10.1111/j.1467-9280.2008.02116.x; Qu FB, 2018, IEEE T AFFECT COMPUT, V9, P424, DOI 10.1109/TAFFC.2017.2654440; Ras G., 2018, EXPLAINABLE INTERPRE, P19; RINN WE, 1984, PSYCHOL BULL, V95, P52, DOI 10.1037/0033-2909.95.1.52; Rothwell J, 2006, APPL COGNITIVE PSYCH, V20, P757, DOI 10.1002/acp.1204; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Ruiz-Hernandez JA, 2013, IEEE INT CONF AUTOMA, DOI 10.5402/2013/341974; Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216; Shreve Matthew, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P51, DOI 10.1109/FG.2011.5771451; Shreve M., 2009, PROC WORKSHOP APPL C, P1; Shreve M, 2014, IMAGE VISION COMPUT, V32, P476, DOI 10.1016/j.imavis.2014.04.010; Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x; Takalkar M., 2018, MULTIMEDIA TOOLS APP, V77, p19 301; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Van Quang N, 2019, P IEEE 14 INT C AUT, P1, DOI DOI 10.1109/FG.2019.8756544; Verma M, 2020, IEEE T IMAGE PROCESS, V29, P1618, DOI 10.1109/TIP.2019.2912358; Wang SJ, 2018, NEUROCOMPUTING, V312, P251, DOI 10.1016/j.neucom.2018.05.107; Wang SJ, 2017, NEUROCOMPUTING, V230, P382, DOI 10.1016/j.neucom.2016.12.034; Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314; Wang SJ, 2015, LECT NOTES COMPUT SC, V8925, P325, DOI 10.1007/978-3-319-16178-5_23; Wang SJ, 2014, NEURAL PROCESS LETT, V39, P25, DOI 10.1007/s11063-013-9288-7; Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34; Wang YD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124674; Warren G, 2009, J NONVERBAL BEHAV, V33, P59, DOI 10.1007/s10919-008-0057-7; Wojciechowski J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092570; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; [吴奇 Wu Qi], 2010, [心理科学进展, Advances in Psychological Science], V18, P1359; Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351; Xia ZQ, 2016, COMPUT VIS IMAGE UND, V147, P87, DOI 10.1016/j.cviu.2015.12.006; Xiao-li Hao, 2017, Advanced Multimedia and Ubiquitous Engineering, MUE/FutureTech 2017. LNEE 448, P419, DOI 10.1007/978-981-10-5041-1_68; Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162; Yan WJ, 2013, IEEE INT CONF AUTOMA; Yan WJ, 2015, LECT NOTES COMPUT SC, V8925, P296, DOI 10.1007/978-3-319-16178-5_20; Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041; Yan WJ, 2013, J NONVERBAL BEHAV, V37, P217, DOI 10.1007/s10919-013-0159-8; Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981; Zeng XM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02015; Zhang P, 2016, OPTIK, V127, P1395, DOI 10.1016/j.ijleo.2015.10.217; Zhang SY, 2017, LECT NOTES COMPUT SC, V10132, P638, DOI 10.1007/978-3-319-51811-4_52; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao GY, 2013, LECT NOTES COMPUT SC, V7950, P1, DOI 10.1007/978-3-642-39094-4_1; Zhu XN, 2018, MULTIMED TOOLS APPL, V77, P3105, DOI 10.1007/s11042-017-4943-z; Zong Y, 2020, IEEE T CYBERNETICS, V50, P5047, DOI 10.1109/TCYB.2019.2914512; Zong Y, 2018, IEEE T MULTIMEDIA, V20, P3160, DOI 10.1109/TMM.2018.2820321; Zong Y, 2018, IEEE T IMAGE PROCESS, V27, P2484, DOI 10.1109/TIP.2018.2797479	125	32	33	31	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5826	5846		10.1109/TPAMI.2021.3067464	http://dx.doi.org/10.1109/TPAMI.2021.3067464			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33739920	Green Submitted			2022-12-18	WOS:000836666600092
J	Zhou, KY; Yang, YX; Cavallaro, A; Xiang, T				Zhou, Kaiyang; Yang, Yongxin; Cavallaro, Andrea; Xiang, Tao			Learning Generalisable Omni-Scale Representations for Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Adaptation models; Convolutional codes; Architecture; Cameras; Feature extraction; Data models; Convolution; Person re-identification; omni-scale learning; lightweight network; cross-domain Re-ID; neural architecture search	NEURAL-NETWORK	An effective person re-identification (re-ID) model should learn feature representations that are both discriminative, for distinguishing similar-looking people, and generalisable, for deployment across datasets without any adaptation. In this paper, we develop novel CNN architectures to address both challenges. First, we present a re-ID CNN termed omni-scale network (OSNet) to learn features that not only capture different spatial scales but also encapsulate a synergistic combination of multiple scales, namely omni-scale features. The basic building block consists of multiple convolutional streams, each detecting features at a certain scale. For omni-scale feature learning, a unified aggregation gate is introduced to dynamically fuse multi-scale features with channel-wise weights. OSNet is lightweight as its building blocks comprise factorised convolutions. Second, to improve generalisable feature learning, we introduce instance normalisation (IN) layers into OSNet to cope with cross-dataset discrepancies. Further, to determine the optimal placements of these IN layers in the architecture, we formulate an efficient differentiable architecture search algorithm. Extensive experiments show that, in the conventional same-dataset setting, OSNet achieves state-of-the-art performance, despite being much smaller than existing re-ID models. In the more challenging yet practical cross-dataset setting, OSNet beats most recent unsupervised domain adaptation methods without using any target data. Our code and models are released at https://github.com/KaiyangZhou/deep-person-reid.	[Zhou, Kaiyang] Nanyang Technol Univ, Singapore 639798, Singapore; [Yang, Yongxin; Xiang, Tao] Univ Surrey, Guildford GU27XH, Surrey, England; [Cavallaro, Andrea] Queen Mary Univ, London E1 4NS, England	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Surrey; University of London; Queen Mary University London	Zhou, KY (corresponding author), Nanyang Technol Univ, Singapore 639798, Singapore.	kaiyang.zhou@ntu.edu.sg; t.xiang@surrey.ac.uk; a.cavallaro@qmul.ac.uk; t.xiang@surrey.ac.uk						Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016; Alex Chichung Kot, 2018, Arxiv, DOI arXiv:1807.01440; Andrea Vedaldi, 2017, Arxiv, DOI arXiv:1607.08022; Andrew G. Howard, 2017, Arxiv, DOI arXiv:1704.04861; Balaji Y, 2018, ADV NEUR IN, V31; Bender G, 2018, PR MACH LEARN RES, V80; Cai H., 2019, PROC INT C LEARN REP; Carlucci FM, 2019, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2019.00233; Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225; Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902; Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110; Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186; Dumoulin V., 2017, PROC INT C LEARN REP; Fong R, 2018, PROC CVPR IEEE, P8730, DOI 10.1109/CVPR.2018.00910; Forrest N. Iandola, 2016, Arxiv, DOI arXiv:1602.07360; Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621; Fu Y, 2019, AAAI CONF ARTIF INTE, P8295; Ge YX, 2018, ADV NEUR IN, V31; Geng M., 2016, DEEP TRANSFER LEARNI; Gray D., 2007, P IEEE INT WORKSH PE, V3, P1; Guoliang Kang, 2017, Arxiv, DOI arXiv:1708.04896; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Jang E., 2017, P INT C LEARN REPR I; Kaiyang Zhou, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P561, DOI 10.1007/978-3-030-58517-4_33; Li D, 2019, IEEE I CONF COMP VIS, P1446, DOI 10.1109/ICCV.2019.00153; Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591; Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243; Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Lin M., 2014, PROC INT C LEARN REP; Liu H., 2019, PROC INT C LEARN REP; Liu JW, 2019, PROC CVPR IEEE, P7195, DOI 10.1109/CVPR.2019.00737; Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46; Loshchilov I., 2017, P INT C LEARNING REP; Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827; Maddison Chris J, 2017, ICLR; Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152; Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29; Pham H, 2018, PR MACH LEARN RES, V80; Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40; Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577; Qian Yu, 2018, Arxiv, DOI arXiv:1711.08106; Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Real E, 2017, PR MACH LEARN RES, V70; Reddi Sashank J., 2018, INT C LEARN REPR; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Sergey Z., 2017, P INT C LEARN REPR I; Shen YT, 2018, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2018.00241; Shen YT, 2018, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR.2018.00720; Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30; Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562; Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129; Song JF, 2019, PROC CVPR IEEE, P719, DOI 10.1109/CVPR.2019.00081; Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427; Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25; Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30; Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730; Tian MQ, 2018, PROC CVPR IEEE, P5794, DOI 10.1109/CVPR.2018.00607; Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437; Vinyals O., 2016, ADV NEURAL INFORM PR, P3637, DOI [10.48550/arXiv.1606.04080, DOI 10.5555/3157382.3157504]; Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23; Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552; Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242; Wang Y, 2018, PROC CVPR IEEE, P8042, DOI 10.1109/CVPR.2018.00839; Wang YC, 2018, PROC CVPR IEEE, P1470, DOI 10.1109/CVPR.2018.00159; Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016; Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xie S., 2019, PROC INT C LEARN REP; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226; Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375; Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148; Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225; Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12; Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076; Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103; Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI [10.1109/CVPR.2019.00224, 10.1109/CVPR.2019.01247]; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11; Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389; Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069; Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313; Zhou K., 2021, PROC INT C LEARN REP; Zhou K., 2021, ARXIV210302503; Zhou KY, 2020, AAAI CONF ARTIF INTE, V34, P13025; Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380; Zhou Kaiyang, 2020, ARXIV; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	114	32	33	15	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5056	5069		10.1109/TPAMI.2021.3069237	http://dx.doi.org/10.1109/TPAMI.2021.3069237			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33769931	Green Submitted			2022-12-18	WOS:000836666600043
J	Qi, GJ; Luo, JB				Qi, Guo-Jun; Luo, Jiebo			Small Data Challenges in Big Data Era: A Survey of Recent Progress on Unsupervised and Semi-Supervised Methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Data models; Task analysis; Training; Adaptation models; Gallium nitride; Big Data; Supervised learning; Unsupervised methods; semi-supervised methods; domain adaptation; transformation equivariance and invariance; disentangled representations; generative models; auto-encoders; generative adversarial networks; auto-regressive models; flow-based generative models; transformers; self-supervised methods; teach-student models; instance discrimination and equivariance		Representation learning with small labeled data have emerged in many problems, since the success of deep neural networks often relies on the availability of a huge amount of labeled data that is expensive to collect. To address it, many efforts have been made on training sophisticated models with few labeled data in an unsupervised and semi-supervised fashion. In this paper, we will review the recent progresses on these two major categories of methods. A wide spectrum of models will be categorized in a big picture, where we will show how they interplay with each other to motivate explorations of new ideas. We will review the principles of learning the transformation equivariant, disentangled, self-supervised and semi-supervised representations, all of which underpin the foundation of recent progresses. Many implementations of unsupervised and semi-supervised generative models have been developed on the basis of these criteria, greatly expanding the territory of existing autoencoders, generative adversarial nets (GANs) and other deep networks by exploring the distribution of unlabeled data for more powerful representations. We will discuss emerging topics by revealing the intrinsic connections between unsupervised and semi-supervised learning, and propose in future directions to bridge the algorithmic and theoretical gap between transformation equivariance for unsupervised learning and supervised invariance for supervised learning, and unify unsupervised pretraining and supervised finetuning. We will also provide a broader outlook of future directions to unify transformation and instance equivariances for representation learning, connect unsupervised and semi-supervised augmentations, and explore the role of the self-supervised regularization for many learning problems.	[Qi, Guo-Jun] Futurewei Technol, Bellevue, WA 98004 USA; [Luo, Jiebo] Univ Rochester6927, Dept Comp Sci, Rochester, NY 14627 USA	Huawei Technologies; University of Rochester	Qi, GJ (corresponding author), Futurewei Technol, Bellevue, WA 98004 USA.	guojunq@gmail.com; jluo@cs.rochester.edu		Luo, Jiebo/0000-0002-4516-9729				Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13; Arandjelovic R, 2018, LECT NOTES COMPUT SC, V11205, P451, DOI 10.1007/978-3-030-01246-5_27; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108; Bojanowski P, 2017, PR MACH LEARN RES, V70; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Carlucci FM, 2019, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2019.00233; Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9; Caron Mathilde, 2020, ARXIV200609882; Chen T, 2020, PR MACH LEARN RES, V119; Chen T, 2019, PROC CVPR IEEE, P12146, DOI 10.1109/CVPR.2019.01243; Chen Wei-Yu, 2019, INT C LEARN REPR, P12; Chen X, 2016, ADV NEUR IN, V29; Christian Szegedy, 2014, Arxiv, DOI arXiv:1312.6199; Cohen TS, 2016, PR MACH LEARN RES, V48; Cohen Taco S, 2018, ARXIV180310743; Cohen Taco S, 2016, ARXIV161208498; Cohen Taco S, 2018, ICLR; Denton E. L., 2017, ADV NEURAL INFORM PR, P4414; Devlin J., 2018, P 2019 C N AM CHAPTE, P4171, DOI DOI 10.18653/V1/N19-1423DIEZPF; Dinh L, 2016, ARXIV PREPRINT ARXIV; Dinh Laurent, 2014, ARXIV14108516; Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167; Donahue J., 2016, ARXIV160509782; Dosovitskiy A., 2014, ADV NEURAL INFORM PR, V27, P766, DOI [DOI 10.1109/TPAMI.2015.2496141, 10.48550/arXiv.1406.6909]; Dumoulin Vincent, 2016, ARXIV E PRINTS; Edraki M, 2018, LECT NOTES COMPUT SC, V11209, P90, DOI 10.1007/978-3-030-01228-1_6; Finn C, 2017, PR MACH LEARN RES, V70; Fu Yanwei, 2017, ARXIV171004837; Ganin Y, 2016, J MACH LEARN RES, V17; Gao X., 2020, GRAPHTER UNSUPERVISE; Gidaris Spyros, 2018, ARXIV180307728; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He K., 2019, ARXIV191105722; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Higgins I., 2016, INT C LEARNING REPRE; Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6; Huang HB, 2018, ADV NEUR IN, V31; JAMAL MA, 2018, ARXIV180507722; Jampani V, 2015, COMPUT VIS IMAGE UND, V136, P32, DOI 10.1016/j.cviu.2015.03.002; Jeon I., 2018, P INT C LEARN REPR; Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393; Karaletsos Theofanis, 2015, ARXIV150605011; Kim H, 2018, PR MACH LEARN RES, V80; Kingma D.P., 2013, P 2 INT C LEARN REPR; Kingma DP, 2018, ADV NEUR IN, V31; Kingma DP, 2014, ADV NEUR IN, V27; Korbar B, 2018, ADV NEUR IN, V31; Krahenbuhl P., 2015, ARXIV151106856; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Kulkarni T. D., 2014, ARXIV14071339; Kulkarni TD, 2015, ADV NEUR IN, V28; Kurakin A., 2016, ARXIV PREPRINT ARXIV; Laine Samuli, 2016, ARXIV161002242; Larsen A. B. L., 2015, ARXIV PREPRINT ARXIV; Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35; Lenssen Jan Eric, 2018, ARXIV180605086; Li XZ, 2019, ADV NEUR IN, V32; Liu M. -Y., 2016, ADV NEURAL INFORM PR, P469; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11; Ma TL, 2019, AAAI CONF ARTIF INTE, P1069; Maaloe L, 2016, PR MACH LEARN RES, V48; Makhzani A., 2015, ARXIV151105644; Mansinghka V., 2013, ADV NEURAL INFORM PR; Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32; Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821; Netzer Y., 2011, READING DIGITS NATUR; Noroozi M, 2017, IEEE I CONF COMP VIS, P5899, DOI 10.1109/ICCV.2017.628; Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5; Oliver A, 2018, ADV NEUR IN, V31; Owens A, 2016, LECT NOTES COMPUT SC, V9905, P801, DOI 10.1007/978-3-319-46448-0_48; Oyallon E, 2017, IEEE I CONF COMP VIS, P5619, DOI 10.1109/ICCV.2017.599; Oyallon E, 2015, PROC CVPR IEEE, P2865, DOI 10.1109/CVPR.2015.7298904; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Qi GJ, 2019, IEEE I CONF COMP VIS, P8129, DOI 10.1109/ICCV.2019.00822; Qi GJ, 2018, PROC CVPR IEEE, P1517, DOI 10.1109/CVPR.2018.00164; Qi Guo-Jun, 2017, ARXIV170106264; Radford A., 2015, ARXIV PREPR ARXIV151; Raffel C.A., 2019, ADV NEURAL INFORM PR, P5049; Rasmus A., 2015, ADV NEURAL INFORM PR, P3546, DOI DOI 10.1186/1477-5956-9-S1-S5; Reed R., 1992, IJCNN International Joint Conference on Neural Networks (Cat. No.92CH3114-6), P147, DOI 10.1109/IJCNN.1992.227178; Ren M., 2018, ICLR; Rifai S., 2011, PROC INT C MACH LEAR; Rozantsev A, 2019, IEEE T PATTERN ANAL, V41, P801, DOI 10.1109/TPAMI.2018.2814042; Sabour S., 2017, 31 C NEUR INF PROC S, P3856; Sajjadi Mehdi, 2016, NEURIPS; Salimans T, 2016, ADV NEUR IN, V29; Salimans Tim, 2017, ARXIV170105517; Schull J, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P1, DOI 10.1145/2700648.2809870; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Sohn Kihyuk, 2020, ARXIV200107685; Sonderby CK, 2016, ADV NEUR IN, V29; Song Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P933, DOI 10.1109/ICME.2006.262673; Srivastava Akash, 2017, ADV NEURAL INFORM PR, P3310, DOI DOI 10.5555/3294996.3295090; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sun Y., 2019, UNSUPERVISED DOMAIN, P2; Tang ., 2008, P ACM C MULT, P631; Tang J., 2007, P 15 ACM INT C MULT, P297, DOI 10.1145/1291233.1291296.; Tang Y., 2012, ICML; Tarvainen Antti, 2017, CORR, Vabs/1703; Tieleman T., 2014, OPTIMIZING NEURAL NE; Tzeng E., 2014, ARXIV PREPRINT ARXIV; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; Ulyanov D, 2018, AAAI CONF ARTIF INTE, P1250; van den Oord A, 2016, PR MACH LEARN RES, V48; van den Oord Aaron, 2016, ARXIV160605328; van den Oord Aaron, 2018, ARXIV180703748; Vaswani A, 2017, ADV NEUR IN, V30; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wang JY, 2020, PROC CVPR IEEE, P469, DOI 10.1109/CVPR42600.2020.00055; Wang M, 2009, COMPUT VIS IMAGE UND, V113, P384, DOI 10.1016/j.cviu.2008.08.003; Wang X., 2021, P INT C LEARN REPR; Wang Xiao, 2019, ARXIV191109265; Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320; Wei DL, 2018, PROC CVPR IEEE, P8052, DOI 10.1109/CVPR.2018.00840; Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393; Zhai XH, 2019, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2019.00156; Zhang LH, 2020, PROC CVPR IEEE, P3911, DOI 10.1109/CVPR42600.2020.00397; Zhang LH, 2019, PROC CVPR IEEE, P2542, DOI 10.1109/CVPR.2019.00265; Zhang R, 2017, PROC CVPR IEEE, P645, DOI 10.1109/CVPR.2017.76; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhu X.J, 2005, SEMISUPERVISED LEARN	130	32	32	60	97	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2168	2187		10.1109/TPAMI.2020.3031898	http://dx.doi.org/10.1109/TPAMI.2020.3031898			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33074801	Green Submitted			2022-12-18	WOS:000764815300037
J	Hirose, O				Hirose, Osamu			A Bayesian Formulation of Coherent Point Drift	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape; Three-dimensional displays; Inference algorithms; Bayes methods; Coherence; Matrix converters; Kernel; Non-rigid point set registration; coherent point drift; variational Bayesian inference; motion coherence; fast computation	SET REGISTRATION; OBJECT RECOGNITION; ALGORITHM; MODEL; ICP	Coherent point drift is a well-known algorithm for solving point set registration problems, i.e., finding corresponding points between shapes represented as point sets. Despite its advantages over other state-of-the-art algorithms, theoretical and practical issues remain. Among theoretical issues, (1) it is unknown whether the algorithm always converges, and (2) the meaning of the parameters concerning motion coherence is unclear. Among practical issues, (3) the algorithm is relatively sensitive to target shape rotation, and (4) acceleration of the algorithm is restricted to the use of the Gaussian kernel. To overcome these issues and provide a different and more general perspective to the algorithm, we formulate coherent point drift in a Bayesian setting. The formulation brings the following consequences and advances to the field: convergence of the algorithm is guaranteed by variational Bayesian inference; the definition of motion coherence as a prior distribution provides a basis for interpretation of the parameters; rigid and non-rigid registration can be performed in a single algorithm, enhancing robustness against target rotation. We also propose an acceleration scheme for the algorithm that can be applied to non-Gaussian kernels and that provides greater efficiency than coherent point drift.	[Hirose, Osamu] Kanazawa Univ, Inst Sci & Engn, Kanazawa, Ishikawa 9201192, Japan	Kanazawa University	Hirose, O (corresponding author), Kanazawa Univ, Inst Sci & Engn, Kanazawa, Ishikawa 9201192, Japan.	hirose@se.kanazawa-u.ac.jp	Hirose, Osamu/K-7890-2015	Hirose, Osamu/0000-0002-8077-8589	JSPS KAKENHI [17K12712]	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	The author would like to deeply thank the anonymous referees who provided helpful, constructive, and detailed comments on earlier versions of the manuscript. This work was supported by JSPS KAKENHI Grant Number 17K12712.	Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859; Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Amberg Brian, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bishop C.M, 2006, PATTERN RECOGN; Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Chen J, 2015, SIGNAL PROCESS, V106, P62, DOI 10.1016/j.sigpro.2014.07.004; Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377; Cosker D, 2011, IEEE I CONF COMP VIS, P2296, DOI 10.1109/ICCV.2011.6126510; Dupej J, 2015, PATTERN RECOGN LETT, V52, P53, DOI 10.1016/j.patrec.2014.10.005; Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004; Ge S, 2015, IEEE WINT CONF APPL, P94, DOI 10.1109/WACV.2015.20; Golyanik V, 2016, IEEE IMAGE PROC, P4503, DOI 10.1109/ICIP.2016.7533212; Golyanik Vladislav, 2016, 2016 IEEE WINT C APP, P1, DOI DOI 10.1109/ICCV.2017.322; Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418; GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004; Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828; Hasler N, 2009, COMPUT GRAPH FORUM, V28, P337, DOI 10.1111/j.1467-8659.2009.01373.x; Hirose O., 2017, ARXIV171106588V3, P1; Hirshberg DA, 2012, LECT NOTES COMPUT SC, V7577, P242, DOI 10.1007/978-3-642-33783-3_18; Horaud R, 2011, IEEE T PATTERN ANAL, V33, P587, DOI 10.1109/TPAMI.2010.94; Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Khoo Y, 2016, IEEE T IMAGE PROCESS, V25, P2956, DOI 10.1109/TIP.2016.2540810; Kolesov I, 2016, IEEE T PATTERN ANAL, V38, P238, DOI 10.1109/TPAMI.2015.2448102; [Краевский В.В. Kraevsky V.V.], 2005, [Педагогика, Pedagogika], P13; Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x; Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813; Lu M, 2016, IEEE GEOSCI REMOTE S, V13, P162, DOI 10.1109/LGRS.2015.2504268; Ma JY, 2019, IEEE T NEUR NET LEAR, V30, P3584, DOI 10.1109/TNNLS.2018.2872528; Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217; Maiseli B, 2017, J VIS COMMUN IMAGE R, V46, P95, DOI 10.1016/j.jvcir.2017.03.012; Makadia A., 2006, P IEEE C COMP VIS PA, V1, P1297, DOI DOI 10.1109/CVPR.2006.122; Mateus D., 2008, PROC CVPR IEEE, P1, DOI DOI 10.1109/CVPR.2008.4587538; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Mitra Niloy J, 2004, P 2004 EUR ACM SIGGR, P22, DOI DOI 10.1145/1057432.1057435; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Pomerleau F, 2012, INT J ROBOT RES, V31, P1705, DOI 10.1177/0278364912458814; Rangarajan A, 1997, LECT NOTES COMPUT SC, V1230, P29; Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Schlkopf B., 2006, ADV NEURAL INFORM PR, P1009; Song Ge, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P126, DOI 10.1109/CVPRW.2015.7301306; Stewart CV, 2003, IEEE T MED IMAGING, V22, P1379, DOI 10.1109/TMI.2003.819276; Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558; Vongkulbhisal J, 2018, PROC CVPR IEEE, P2993, DOI 10.1109/CVPR.2018.00316; Vongkulbhisal J, 2017, PROC CVPR IEEE, P3975, DOI 10.1109/CVPR.2017.423; Wahba G., 1990, CBMS NSF REGIONAL C, V59; Williams CKI, 2001, ADV NEUR IN, V13, P682; Yang CJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P464; Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405; Yang Y, 2015, PATTERN RECOGN, V48, P156, DOI 10.1016/j.patcog.2014.06.017; YUILLE AL, 1989, INT J COMPUT VISION, V3, P155, DOI 10.1007/BF00126430; Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47	65	32	32	3	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2269	2286		10.1109/TPAMI.2020.2971687	http://dx.doi.org/10.1109/TPAMI.2020.2971687			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	32031931	hybrid			2022-12-18	WOS:000692540900008
J	Zhang, XJ; Ng, MK				Zhang, Xiongjun; Ng, Michael K.			Low Rank Tensor Completion With Poisson Observations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensors; Videos; Numerical models; Convex functions; Manifolds; Maximum likelihood estimation; Matrix decomposition; Maximum likelihood estimate; transformed tensor nuclear norm; low-rank tensor completion; Poisson observations	IMAGE QUALITY ASSESSMENT; FACTORIZATION; MINIMIZATION	Poisson observations for videos are important models in video processing and computer vision. In this paper, we study the third-order tensor completion problem with Poisson observations. The main aim is to recover a tensor based on a small number of its Poisson observation entries. A existing matrix-based method may be applied to this problem via the matricized version of the tensor. However, this method does not leverage on the global low-rankness of a tensor and may be substantially suboptimal. Our approach is to consider the maximum likelihood estimate of the Poisson distribution, and utilize the Kullback-Leibler divergence for the data-fitting term to measure the observations and the underlying tensor. Moreover, we propose to employ a transformed tensor nuclear norm ball constraint and a bounded constraint of each entry, where the transformed tensor nuclear norm is used to get a lower transformed multi-rank tensor with suitable unitary transformation matrices. We show that the upper bound of the error of the estimator of the proposed model is less than that of the existing matrix-based method. Also an information theoretic lower error bound is established. An alternating direction method of multipliers is developed to solve the resulting convex optimization model. Extensive numerical experiments on synthetic data and real-world datasets are presented to demonstrate the effectiveness of our proposed model compared with existing tensor completion methods.	[Zhang, Xiongjun] Cent China Normal Univ, Sch Math & Stat, Wuhan 430079, Peoples R China; [Zhang, Xiongjun] Cent China Normal Univ, Hubei Key Lab Math Sci, Wuhan 430079, Peoples R China; [Ng, Michael K.] Univ Hong Kong, Dept Math, Pokfulam, Hong Kong, Peoples R China	Central China Normal University; Central China Normal University; University of Hong Kong	Zhang, XJ (corresponding author), Cent China Normal Univ, Sch Math & Stat, Wuhan 430079, Peoples R China.; Zhang, XJ (corresponding author), Cent China Normal Univ, Hubei Key Lab Math Sci, Wuhan 430079, Peoples R China.	xjzhang@mail.ccnu.edu.cn; mng@maths.hku.hk	Zhang, Xiongjun/AAH-1360-2019	Zhang, Xiongjun/0000-0002-5387-4129	National Natural Science Foundation of China [11801206, 11871025]; Hubei Provincial Natural Science Foundation of China [2018CFB105]; Fundamental Research Funds for the Central Universities [CCNU19ZN017]; HKRGC GRF [12306616, 12200317, 12300218, 12300519, 17201020]; HKU [104005583]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Hubei Provincial Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); HKRGC GRF(Hong Kong Research Grants Council); HKU(University of Hong Kong)	The authors would like to thank the associate editor and the anonymous referees for their helpful comments and constructive suggestions that have substantially helped to improve the quality and presentation of this paper. The work of Xiongjun Zhang was supported in part by the National Natural Science Foundation of China under Grants 11801206 and 11871025, Hubei Provincial Natural Science Foundation of China under Grant 2018CFB105, and Fundamental Research Funds for the Central Universities under Grant CCNU19ZN017. The work of Michael K. Ng was supported in part by the HKRGC GRF 12306616, 12200317, 12300218, 12300519, and 17201020, and HKU Grant 104005583.	Ashraphijuo M, 2020, ANN MATH ARTIF INTEL, V88, P859, DOI 10.1007/s10472-020-09691-6; Ashraphijuo M, 2019, IEEE T INFORM THEORY, V65, P5380, DOI 10.1109/TIT.2019.2919568; Ashraphijuo M, 2017, J MACH LEARN RES, V18, P1; Bengua JA, 2017, IEEE T IMAGE PROCESS, V26, P2466, DOI 10.1109/TIP.2017.2672439; Candes EJ, 2013, APPL COMPUT HARMON A, V34, P317, DOI 10.1016/j.acha.2012.08.010; Cao Y, 2016, IEEE T SIGNAL PROCES, V64, P1609, DOI 10.1109/TSP.2015.2500192; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; Davenport MA, 2014, INF INFERENCE, V3, P189, DOI 10.1093/imaiai/iau006; Deger Ferdinand, 2015, Opt Express, V23, P1938, DOI 10.1364/OE.23.001938; Fazel M., 2002, MATRIX RANK MINIMIZA; Fazel M, 2013, SIAM J MATRIX ANAL A, V34, P946, DOI 10.1137/110853996; Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42; Gao QX, 2021, IEEE T PATTERN ANAL, V43, P2133, DOI 10.1109/TPAMI.2020.3017672; Ghadermarzy N, 2019, IEEE T SIGNAL PROCES, V67, P29, DOI 10.1109/TSP.2018.2879031; GLOWINSKI R, 1975, REV FR AUTOMAT INFOR, V9, P41; Goodman J. W, 2000, STAT OPTICS; Harshman R.A., 1970, MULTIMODAL FACTOR AN; Hillar CJ, 2013, J ACM, V60, DOI 10.1145/2512329; Kernfeld E, 2015, LINEAR ALGEBRA APPL, V485, P545, DOI 10.1016/j.laa.2015.07.021; Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711; Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020; Kolda TG, 2008, IEEE DATA MINING, P363, DOI 10.1109/ICDM.2008.89; Kressner D, 2014, BIT, V54, P447, DOI 10.1007/s10543-013-0455-z; Le T, 2007, J MATH IMAGING VIS, V27, P257, DOI 10.1007/s10851-007-0652-y; Li BH, 2019, IEEE T IMAGE PROCESS, V28, P170, DOI 10.1109/TIP.2018.2865837; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760; Martin CD, 2013, SIAM J SCI COMPUT, V35, pA474, DOI 10.1137/110841229; McRae AD, 2021, INF INFERENCE, V10, P697, DOI 10.1093/imaiai/iaaa020; MOLINA R, 1994, IEEE T PATTERN ANAL, V16, P1122, DOI 10.1109/34.334393; MORRIS GM, 1984, APPL OPTICS, V23, P3152, DOI 10.1364/AO.23.003152; MORRIS GM, 1984, J OPT SOC AM A, V1, P482, DOI 10.1364/JOSAA.1.000482; Mu C, 2014, PR MACH LEARN RES, V32, P73; Nascimento SMC, 2002, J OPT SOC AM A, V19, P1484, DOI 10.1364/JOSAA.19.001484; Ng MK, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107181; Ollinger JM, 1997, IEEE SIGNAL PROC MAG, V14, P43, DOI 10.1109/79.560323; Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286; Romera-Paredes B., 2013, ADV NEURAL INFORM PR, V2, P2967; Sambasivan AV, 2018, IEEE T INFORM THEORY, V64, P3274, DOI 10.1109/TIT.2018.2809782; Semerci O, 2014, IEEE T IMAGE PROCESS, V23, P1678, DOI 10.1109/TIP.2014.2305840; Sidiropoulos ND, 2017, IEEE T SIGNAL PROCES, V65, P3551, DOI 10.1109/TSP.2017.2690524; Song GJ, 2020, NUMER LINEAR ALGEBR, V27, DOI 10.1002/nla.2299; Soni A, 2016, IEEE T INFORM THEORY, V62, P3636, DOI 10.1109/TIT.2016.2549040; Steinlechner M, 2016, SIAM J SCI COMPUT, V38, pS461, DOI 10.1137/15M1010506; Tavakoli B, 2008, OPT EXPRESS, V16, P4426, DOI 10.1364/OE.16.004426; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wen YW, 2016, SCI CHINA MATH, V59, P141, DOI 10.1007/s11425-015-5079-0; Wernick M. N., 2004, EMISSION TOMOGRAPHY; Xia D, 2019, FOUND COMPUT MATH, V19, P1265, DOI 10.1007/s10208-018-09408-6; Xie Q, 2018, IEEE T PATTERN ANAL, V40, P1888, DOI 10.1109/TPAMI.2017.2734888; Xu YY, 2015, INVERSE PROBL IMAG, V9, P601, DOI 10.3934/ipi.2015.9.601; Yang JH, 2020, J COMPUT APPL MATH, V363, P124, DOI 10.1016/j.cam.2019.06.004; Yuan M, 2016, FOUND COMPUT MATH, V16, P1031, DOI 10.1007/s10208-015-9269-5; Zhang F, 2021, IEEE T PATTERN ANAL, V43, P3492, DOI 10.1109/TPAMI.2020.2986773; Zhang XJ, 2019, SIAM J IMAGING SCI, V12, P1231, DOI 10.1137/18M1202311; Zhang XJ, 2019, IEEE T NEUR NET LEAR, V30, P1659, DOI 10.1109/TNNLS.2018.2872583; Zhang XJ, 2018, J SCI COMPUT, V75, P1535, DOI 10.1007/s10915-017-0597-2; Zhang ZM, 2017, IEEE T SIGNAL PROCES, V65, P1511, DOI 10.1109/TSP.2016.2639466; Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485; Zhu FY, 2014, IEEE T IMAGE PROCESS, V23, P5412, DOI 10.1109/TIP.2014.2363423; Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820	64	32	32	3	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 15	2021	44	8					4239	4251		10.1109/TPAMI.2021.3059299	http://dx.doi.org/10.1109/TPAMI.2021.3059299			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HR	33587697				2022-12-18	WOS:000820522100003
J	Tran, L; Liu, XM				Tran, Luan; Liu, Xiaoming			On Learning 3D Face Morphable Mode from In-the-Wild Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Morphable model; 3DMM; face; nonlinear; weakly supervised; in-the-wild; face reconstruction; face alignment	ALIGNMENT; RECONSTRUCTION; RECOGNITION	As a classic statistical model of 3D facial shape and albedo, 3D Morphable Model (3DMM) is widely used in facial analysis, e.g., model fitting, image synthesis. Conventional 3DMM is learned from a set of 3D face scans with associated well-controlled 2D face images, and represented by two sets of PCA basis functions. Due to the type and amount of training data, as well as, the linear bases, the representation power of 3DMM can be limited. To address these problems, this paper proposes an innovative framework to learn a nonlinear 3DMM model from a large set of in-the-wild face images, without collecting 3D face scans. Specifically, given a face image as input, a network encoder estimates the projection, lighting, shape and albedo parameters. Two decoders serve as the nonlinear 3DMM to map from the shape and albedo parameters to the 3D shape and albedo, respectively. With the projection parameter, lighting, 3D shape, and albedo, a novel analytically-differentiable rendering layer is designed to reconstruct the original input face. The entire network is end-to-end trainable with only weak supervision. We demonstrate the superior representation power of our nonlinear 3DMM over its linear counterpart, and its contribution to face alignment, 3D reconstruction, and face editing. Source code and additional results can be found at our project page: http://cvlab.cse.msu.edu/project-nonlinear-3dmm.html	[Tran, Luan; Liu, Xiaoming] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Liu, XM (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	tranluan@msu.edu; liuxm@cse.msu.edu		liu, xiaoming/0000-0003-3215-8753				Aldrian O, 2013, IEEE T PATTERN ANAL, V35, P1080, DOI 10.1109/TPAMI.2012.206; Amberg B, 2008, IEEE INT CONF AUTOMA, P667; Tran AT, 2018, PROC CVPR IEEE, P3935, DOI 10.1109/CVPR.2018.00414; Bagdanov Andrew D, 2011, P 2011 JOINT ACM WOR, P79, DOI DOI 10.1145/2072572.2072597; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Bolkart T, 2015, IEEE I CONF COMP VIS, P3604, DOI 10.1109/ICCV.2015.411; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Booth J, 2018, IEEE T PATTERN ANAL, V40, P2638, DOI 10.1109/TPAMI.2018.2832138; Booth J, 2017, PROC CVPR IEEE, P5464, DOI 10.1109/CVPR.2017.580; Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598; Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Duong N, 2015, PROC CVPR IEEE, P4786, DOI 10.1109/CVPR.2015.7299111; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cu L, 2008, LECT NOTES COMPUT SC, V5302, P413, DOI 10.1007/978-3-540-88682-2_32; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164; Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264; Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33; Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493; Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347; Jourabloo A, 2017, INT J COMPUT VISION, V124, P187, DOI 10.1007/s11263-017-1012-z; Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454; Jourabloo A, 2015, IEEE I CONF COMP VIS, P3694, DOI 10.1109/ICCV.2015.421; Koppen P, 2018, PATTERN RECOGN, V74, P617, DOI 10.1016/j.patcog.2017.09.006; Liu F, 2018, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2018.00547; Liu XM, 2010, IMAGE VISION COMPUT, V28, P1162, DOI 10.1016/j.imavis.2009.09.016; Liu XM, 2009, IEEE T PATTERN ANAL, V31, P1941, DOI 10.1109/TPAMI.2008.238; Liu YJ, 2017, IEEE INT CONF COMP V, P1619, DOI 10.1109/ICCVW.2017.190; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767; McDonagh J, 2016, LECT NOTES COMPUT SC, V9914, P569, DOI 10.1007/978-3-319-48881-3_39; Meka A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925907; Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024; Patel A, 2009, PROC CVPR IEEE, P1327, DOI 10.1109/CVPRW.2009.5206522; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839; Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317; Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589; Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56; Roth J., 2015, P IEEE C COMP VIS PA, P3658; Roth J, 2017, IEEE T PATTERN ANAL, V39, P2127, DOI 10.1109/TPAMI.2016.2636829; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175; Shi FH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661290; Shu ZX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3095816; Shu ZX, 2017, PROC CVPR IEEE, P5444, DOI 10.1109/CVPR.2017.578; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Staal FCR, 2015, J CRANIO MAXILL SURG, V43, P528, DOI 10.1016/j.jcms.2015.02.005; Taha ZQ, 2006, IEEE ICC, P1071; Tewari A, 2018, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2018.00270; Tewari A, 2017, IEEE I CONF COMP VIS, P3735, DOI 10.1109/ICCV.2017.401; Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182644; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056; Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163; Tran L, 2019, IEEE T PATTERN ANAL, V41, P3007, DOI 10.1109/TPAMI.2018.2868350; Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141; Tulyakov S, 2015, IEEE I CONF COMP VIS, P3748, DOI 10.1109/ICCV.2015.427; Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1968, DOI 10.1109/TPAMI.2008.244; Wu H, 2008, PROC CVPR IEEE, P3200; Wu Y., 2015, P IEEE INT C COMP VI; Yang SW, 2016, INT SYMP ASYNCHRON C, P3, DOI 10.1109/ASYNC.2016.8; Yin X, 2017, IEEE I CONF COMP VIS, P4010, DOI 10.1109/ICCV.2017.430; Yu R, 2017, IEEE I CONF COMP VIS, P4733, DOI 10.1109/ICCV.2017.506; Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53; Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23; Zollhofer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382	76	32	32	2	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					157	171		10.1109/TPAMI.2019.2927975	http://dx.doi.org/10.1109/TPAMI.2019.2927975			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31329546	Green Submitted			2022-12-18	WOS:000597206900011
J	Boominathan, V; Adams, JK; Robinson, JT; Veeraraghavan, A				Boominathan, Vivek; Adams, Jesse K.; Robinson, Jacob T.; Veeraraghavan, Ashok			PhlatCam: Designed Phase-Mask Based Thin Lensless Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Image reconstruction; Two dimensional displays; Lenses; Three-dimensional displays; lensless imaging; diffractive masks; phase retrieval refocusing; 3D imagin	IMAGE; CELLS	We demonstrate a versatile thin lensless camera with a designed phase-mask placed at sub-2 mm from an imaging CMOS sensor. Using wave optics and phase retrieval methods, we present a general-purpose framework to create phase-masks that achieve desired sharp point-spread-functions (PSFs) for desired camera thicknesses. From a single 2D encoded measurement, we show the reconstruction of high-resolution 2D images, computational refocusing, and 3D imaging. This ability is made possible by our proposed high-performance contour-based PSF. The heuristic contour-based PSF is designed using concepts in signal processing to achieve maximal information transfer to a bit-depth limited sensor. Due to the efficient coding, we can use fast linear methods for high-quality image reconstructions and switch to iterative nonlinear methods for higher fidelity reconstructions and 3D imaging.	[Boominathan, Vivek; Robinson, Jacob T.; Veeraraghavan, Ashok] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA; [Adams, Jesse K.] Rice Univ, Appl Phys Program, Houston, TX 77005 USA	Rice University; Rice University	Boominathan, V; Veeraraghavan, A (corresponding author), Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA.	vivekb@rice.edu; jkadams@alumni.rice.edu; jtrobinson@rice.edu; vashok@rice.edu		Veeraraghavan, Ashok/0000-0001-5043-7460	NSF [CAREER: IIS-1652633]; NIH [R21EY029459]; DARPA [NESD: HR0011-17-C0026]	NSF(National Science Foundation (NSF)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	The authors would like to thank Salman S. Khan, IIT Madras, and Jasper Tan, Rice University, for assisting in FlatCam reconstructions [10], [49]. They would also like to thank Fan Ye, Rice University, for assisting in the initial steps of fabrication. This work was supported in part by NSF CAREER: IIS-1652633, DARPA NESD: HR0011-17-C0026, and NIH Grant: R21EY029459.	Adams JK, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1701548; Alan V. O., 1996, SIGNALS SYSTEMS; Antipa N, 2018, OPTICA, V5, P1, DOI 10.1364/OPTICA.5.000001; Asif MS, 2017, IEEE T COMPUT IMAG, V3, P384, DOI 10.1109/TCI.2016.2593662; Berto P, 2017, OPT LETT, V42, P5117, DOI 10.1364/OL.42.005117; Bertolotti J, 2012, NATURE, V491, P232, DOI 10.1038/nature11578; Boominathan V, 2016, IEEE SIGNAL PROC MAG, V33, P23, DOI 10.1109/MSP.2016.2581921; Born M., 2013, PRINCIPLES OPTICS EL; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y; Chen J., 2017, ELECT IMAGING, V2017, P70; Chi WL, 2011, OPT EXPRESS, V19, P4294, DOI 10.1364/OE.19.004294; Chi WL, 2009, OPT COMMUN, V282, P2110, DOI 10.1016/j.optcom.2009.02.031; Cornacchia M, 2017, IEEE SENS J, V17, P386, DOI 10.1109/JSEN.2016.2628346; DeWeert MJ, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.2.023102; Eliakim R, 2006, ENDOSCOPY, V38, P963, DOI 10.1055/s-2006-944832; FENG SC, 1988, PHYS REV LETT, V61, P834, DOI 10.1103/PhysRevLett.61.834; FIENUP JR, 1982, APPL OPTICS, V21, P2758, DOI 10.1364/AO.21.002758; Fresnel A.J., 1996, SPIE MILESTONE SER, V128, P3; FREUND I, 1988, PHYS REV LETT, V61, P2328, DOI 10.1103/PhysRevLett.61.2328; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; GERCHBERG RW, 1972, OPTIK, V35, P237; GOLOMB SW, 1967, SHIFT REGISTER SEQUE; Goodman J. W., 2017, INTRO FOURIER OPTICS, V4th; Katz O, 2012, NAT PHOTONICS, V6, P549, DOI 10.1038/nphoton.2012.150; Khan S. S., 2019, P IEEE INT C COMP VI, P7860; Khorasaninejad M, 2016, SCIENCE, V352, P1190, DOI 10.1126/science.aaf6644; Kim G, 2017, APPL OPTICS, V56, P6450, DOI 10.1364/AO.56.006450; Liu L, 2016, MICRO NANO LETT, V11, P1, DOI 10.1049/mnl.2015.0108; MACWILLIAMS FJ, 1976, P IEEE, V64, P1715, DOI 10.1109/PROC.1976.10411; Oppenheim A.V., 1999, DISCRETE TIME SIGNAL; Ozcan A, 2008, LAB CHIP, V8, P98, DOI 10.1039/b713695a; Pavani SRP, 2009, P NATL ACAD SCI USA, V106, P2995, DOI 10.1073/pnas.0900245106; Perlin K., 2002, ACM T GRAPHIC, V21, P3; Ren Z, 2011, 2011 IET 4TH INTERNATIONAL CONFERENCE ON WIRELESS, MOBILE & MULTIMEDIA NETWORKS (ICWMMN 2011), P6, DOI 10.1049/cp.2011.0946; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Seo S, 2009, LAB CHIP, V9, P777, DOI 10.1039/b813943a; Shechtman Y, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.133902; Shimano T, 2018, APPL OPTICS, V57, P2841, DOI 10.1364/AO.57.002841; Sitzmann V., 1978, ACM T GRAPHIC, V37, P1; Stork D. G., 2013, LENSLESS ULTRA MINIA, P186; Stork DG., 2014, INT J ADV SYST MEASU, V7, P4; Tajima K, 2017, AIP CONF PROC, V1892, DOI 10.1063/1.5005790; Tan J, 2019, IEEE T COMPUT IMAG, V5, P180, DOI 10.1109/TCI.2018.2889933; Wang WX, 2019, OPT EXPRESS, V27, P3799, DOI 10.1364/OE.27.003799; Wei SE, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323030; Wu Yonghui, 2019, JCO Clin Cancer Inform, V3, P1, DOI 10.1200/CCI.19.00001; Yang X, 2014, OPT EXPRESS, V22, P3405, DOI 10.1364/OE.22.003405	49	32	34	9	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1618	1629		10.1109/TPAMI.2020.2987489	http://dx.doi.org/10.1109/TPAMI.2020.2987489			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	32324539	Green Accepted, hybrid			2022-12-18	WOS:000542967200008
J	Xu, D; Ricci, E; Ouyang, WL; Wang, XG; Sebe, N				Xu, Dan; Ricci, Elise; Ouyang, Wanli; Wang, Xiaogang; Sebe, Nicu			Monocular Depth Estimation Using Multi-Scale Continuous CRFs as Sequential Deep Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Monocular depth estimation; convolutional neural networks (CNN); deep multi-scale fusion; conditional random fields (CRFs)		Depth cues have been proved very useful in various computer vision and robotic tasks. This paper addresses the problem of monocular depth estimation from a single still image. Inspired by the effectiveness of recent works on multi-scale convolutional neural networks (CNN), we propose a deep model which fuses complementary information derived from multiple CNN side outputs. Different from previous methods using concatenation or weighted average schemes, the integration is obtained by means of continuous Conditional Random Fields (CRFs). In particular, we propose two different variations, one based on a cascade of multiple CRFs, the other on a unified graphical model. By designing a novel CNN implementation of mean-field updates for continuous CRFs, we show that both proposed models can be regarded as sequential deep networks and that training can be performed end-to-end. Through an extensive experimental evaluation, we demonstrate the effectiveness of the proposed approach and establish new state of the art results for the monocular depth estimation task on three publicly available datasets, i.e., NYUD-V2, Make3D and KITTI.	[Xu, Dan; Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy; [Ricci, Elise] Univ Trento, I-38122 Trento, Italy; [Ouyang, Wanli] Univ Sydney, Sch Elect & Informat Engn, Camperdown, NSW 2006, Australia; [Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China	University of Trento; University of Trento; University of Sydney; Chinese University of Hong Kong	Xu, D (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy.	dan.xu@unitn.it; eliricci@fbk.eu; wanli.ouyang@sydney.edu.au; xgwang@ee.cuhk.edu.hk; niculae.sebe@unitn.it		Sebe, Niculae/0000-0002-6597-7248				Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], P AS C COMP VIS; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067; Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22; Chen D., 2018, P IEEE C COMP VIS PA; Chen Liang-Chich, 2015, ABS14127062 CORR; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; Delage E., 2006, COMP VIS PATT REC 20, V2, P2418, DOI DOI 10.1109/CVPR.2006.23; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Eigen David, 2014, NEURIPS; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; He K., 2016, PROC IEEE C COMPUTER, P770, DOI DOI 10.1109/CVPR.2016.90; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232; Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835; Knobelreiter P., 2016, CVPR; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715; Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152; Liu MM, 2014, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2014.97; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Papandreou G., 2015, ARXIV150202734; Porzi L, 2017, IEEE ROBOT AUTOM LET, V2, P468, DOI 10.1109/LRA.2016.2637444; Ristovski K., 2013, PROC AAAI C ARTIF IN, V27, P840; Roy A, 2016, PROC CVPR IEEE, P5506, DOI 10.1109/CVPR.2016.594; Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Saxena Ashutosh, 2005, ADV NEURAL INFORM PR; Schwing A. G., 2015, ARXIV PREPRINT ARXIV; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu D, 2017, ADV NEUR IN, V30; Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077; Xu D, 2017, PROC CVPR IEEE, P4236, DOI 10.1109/CVPR.2017.451; Xu D, 2017, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2017.25; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zhuo W, 2015, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2015.7298660	53	32	34	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1426	1440		10.1109/TPAMI.2018.2839602	http://dx.doi.org/10.1109/TPAMI.2018.2839602			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29994300	Green Submitted			2022-12-18	WOS:000467037000011
J	Bai, S; Bai, X; Tian, Q; Latecki, LJ				Bai, Song; Bai, Xiang; Tian, Qi; Latecki, Longin Jan			Regularized Diffusion Process on Bidirectional Context for Object Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image retrieval; 3D shape retrieval; cross-modal retrieval; affinity learning; re-ranking; diffusion process	IMAGE RE-RANKING; SIMILARITY; REPRESENTATION; RECOGNITION; CONSISTENCY; SPACES; MODEL	Diffusion process has advanced object retrieval greatly as it can capture the underlying manifold structure. Recent studies have experimentally demonstrated that tensor product diffusion can better reveal the intrinsic relationship between objects than other variants. However, the principle remains unclear, i.e., what kind of manifold structure is captured. In this paper, we propose a new affinity learning algorithm called Regularized Diffusion Process (RDP). By deeply exploring the properties of RDP our first yet basic contribution is providing a manifold-based explanation for tensor product diffusion. A novel criterion measuring the smoothness of the manifold is defined, which simultaneously regularizes four vertices in the affinity graph. Inspired by this observation, we further contribute two variants towards two specific goals. While ARDP can learn similarities across heterogeneous domains, HRDP performs affinity learning on tensor product hypergraph, considering the relationships between objects are generally more complex than pairwise. Consequently, RDP, ARDP and HRDP constitute a generic tool for object retrieval in most commonly-used settings, no matter the input relationships between objects are derived from the same domain or not, and in pairwise formulation or not. Comprehensive experiments on 10 retrieval benchmarks, especially on large scale data, validate the effectiveness and generalization of our work.	[Bai, Song; Bai, Xiang] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China; [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA; [Latecki, Longin Jan] Temple Univ, Dept Comp & Informat Sci, 1925 N 12th St, Philadelphia, PA 19122 USA	Huazhong University of Science & Technology; University of Texas System; University of Texas at San Antonio (UTSA); Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Bai, X (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China.	songbai@hust.edu.cn; xbai@hust.edu.cn; qitian@cs.utsa.edu; latecki@temple.edu		Latecki, Longin Jan/0000-0002-5102-8244; Bai, Xiang/0000-0002-3449-5940	NSFC [61573160, 61429201]; NSF [IIS-1302164]; National Program for Support of Top-notch Young Professionals and the Program for HUST Academic Frontier Youth Team; ARO [W911NF-15-1-0290]; NEC Laboratories of America and Blippar	NSFC(National Natural Science Foundation of China (NSFC)); NSF(National Science Foundation (NSF)); National Program for Support of Top-notch Young Professionals and the Program for HUST Academic Frontier Youth Team; ARO; NEC Laboratories of America and Blippar	The code of this work is available at: http://songbai.site/rdp/. This work was supported by NSFC 61573160, NSFC 61429201 and NSF IIS-1302164, to Dr. Xiang Bai by the National Program for Support of Top-notch Young Professionals and the Program for HUST Academic Frontier Youth Team, to Dr. Qi Tian by ARO grants W911NF-15-1-0290 and Faculty Research Gift Awards by NEC Laboratories of America and Blippar. The corresponding author of this paper is Xiang Bai.	[Anonymous], 3D OBJECT RETRIEVAL, DOI DOI 10.2312/3DOR/3DOR08/009-016; Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38; BAI S, 2017, IEEE I CONF COMP VIS, P774, DOI DOI 10.1109/ICCV.2017.90; Bai S, 2017, AAAI CONF ARTIF INTE, P3967; Bai S, 2017, IEEE T MULTIMEDIA, V19, P1257, DOI 10.1109/TMM.2017.2652071; Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543; Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498; Bai S, 2015, PATTERN RECOGN LETT, V65, P15, DOI 10.1016/j.patrec.2015.06.022; Bai X, 2012, IEEE T IMAGE PROCESS, V21, P2747, DOI 10.1109/TIP.2011.2170082; Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85; Chatfield K., 2014, BRIT MACH VIS C; Chen YZ, 2014, PATTERN RECOGN, V47, P1349, DOI 10.1016/j.patcog.2013.09.011; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601; Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142; Donoser M, 2013, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2013.174; Douze M., 2017, ARXIV170602332; Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540; Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Furuya T., 2014, P BRIT MACH VIS C; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286; Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8; Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15; Pedronette DCG, 2014, INFORM SCIENCES, V265, P91, DOI 10.1016/j.ins.2013.12.030; Pedronette DCG, 2014, IMAGE VISION COMPUT, V32, P120, DOI 10.1016/j.imavis.2013.12.009; Pedronette DCG, 2013, PATTERN RECOGN, V46, P2350, DOI 10.1016/j.patcog.2013.01.004; Iscen A, 2017, PROC CVPR IEEE, P926, DOI 10.1109/CVPR.2017.105; Iscen Ahmet, 2017, ARXIV170306935; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285; Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499; Kontschieder Peter, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P655; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Li B, 2014, COMPUT VIS IMAGE UND, V119, P57, DOI 10.1016/j.cviu.2013.11.008; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Liu MZ, 2012, IEEE T PATTERN ANAL, V34, P2407, DOI 10.1109/TPAMI.2012.44; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo L, 2013, IEEE T MULTIMEDIA, V15, P1174, DOI 10.1109/TMM.2013.2242450; Makadia A, 2010, INT J COMPUT VISION, V89, P193, DOI 10.1007/s11263-009-0280-7; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374; Page L., 1999, STANFORD INFOLAB; Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6; Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608; Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373; Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031; Shi XC, 2016, PROC CVPR IEEE, P5062, DOI 10.1109/CVPR.2016.547; Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504; Sidorov G, 2014, COMPUT SIST, V18, P491, DOI 10.13053/CyS-18-3-2043; Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114; Tabia H, 2014, PROC CVPR IEEE, P4185, DOI 10.1109/CVPR.2014.533; Tabia H, 2011, IEEE T PATTERN ANAL, V33, P852, DOI 10.1109/TPAMI.2010.202; Wang B, 2012, PROC CVPR IEEE, P2312, DOI 10.1109/CVPR.2012.6247942; Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311; Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261; Wang T, 2016, LECT NOTES COMPUT SC, V9906, P508, DOI 10.1007/978-3-319-46475-6_32; Yang F, 2015, IEEE WINT CONF APPL, P572, DOI 10.1109/WACV.2015.82; Yang XW, 2013, IEEE T PATTERN ANAL, V35, P28, DOI 10.1109/TPAMI.2012.60; Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844; Zemene E, 2019, IEEE T PATTERN ANAL, V41, P148, DOI 10.1109/TPAMI.2017.2787132; Zemene E, 2016, LECT NOTES COMPUT SC, V9912, P278, DOI 10.1007/978-3-319-46484-8_17; Zhai X., 2013, P AAAI C ART INT AAA; Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201; Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47; Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533; Zhang ZH, 2017, PATTERN RECOGN, V63, P291, DOI 10.1016/j.patcog.2016.06.009; Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2; Zhou D., 2006, NIPS, V19, P1633; Zhou DY, 2004, ADV NEUR IN, V16, P169; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhu F, 2016, AAAI CONF ARTIF INTE, P3683	78	32	32	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1213	1226		10.1109/TPAMI.2018.2828815	http://dx.doi.org/10.1109/TPAMI.2018.2828815			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993682	hybrid			2022-12-18	WOS:000463607400014
J	Lee, G; Tai, YW; Kim, J				Lee, Gayoung; Tai, Yu-Wing; Kim, Junmo			ELD-Net: An Efficient Deep Learning Architecture for Accurate Saliency Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Salient region detection; feature extraction; superpixel; deep learning; convolutional neural network (CNN)	OBJECT DETECTION; NETWORKS	Recent advances in saliency detection have utilized deep learning to obtain high-level features to detect salient regions in scenes. These advances have yielded results superior to those reported in past work, which involved the use of hand-crafted low-level features for saliency detection. In this paper, we propose ELD-Net, a unified deep learning framework for accurate and efficient saliency detection. We show that hand-crafted features can provide complementary information to enhance saliency detection that uses only high-level features. Our method uses both low-level and high-level features for saliency detection. High-level features are extracted using GoogLeNet, and low-level features evaluate the relative importance of a local region using its differences from other regions in an image. The two feature maps are independently encoded by the convolutional and the ReLU layers. The encoded low-level and high-level features are then combined by concatenation and convolution. Finally, a linear fully connected layer is used to evaluate the saliency of a queried region. A full resolution saliency map is obtained by querying the saliency of each local region of an image. Since the high-level features are encoded at low resolution, and the encoded high-level features can be reused for every query region, our ELD-Net is very fast. Our experiments show that our method outperforms state-of-the-art deep learning-based saliency detection methods.	[Lee, Gayoung; Kim, Junmo] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 305701, South Korea; [Tai, Yu-Wing] Youtu Lab Tencent SNG, Shenzhen, Peoples R China	Korea Advanced Institute of Science & Technology (KAIST)	Kim, J (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 305701, South Korea.	gylee1103@gmail.com; yuwingtai@tencent.com; junmo.kim@kaist.ac.kr	Tai, Yu Wing/C-2047-2011; Kim, Junmo/C-2050-2011	Tai, Yu Wing/0000-0002-3148-0380; 				Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461; Borji A., 2014, ARXIV14115878; Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30; Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Jia Y., 2014, P 22 ACM INT C MULT, P675; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118; Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399; Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78; Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184; Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306; Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120; Park J, 2012, IEEE IMAGE PROC, P2741, DOI 10.1109/ICIP.2012.6467466; Ren C. Y., 2015, ARXIV150904232; Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Simakov Denis, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587842; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tang YB, 2016, LECT NOTES COMPUT SC, V9912, P809, DOI 10.1007/978-3-319-46484-8_49; Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938; Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yu Y, 2016, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON MECHANICAL ENGINEERING AND CONTROL SYSTEMS (MECS2015), P478; Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360	43	32	32	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1599	1610		10.1109/TPAMI.2017.2737631	http://dx.doi.org/10.1109/TPAMI.2017.2737631			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28796612				2022-12-18	WOS:000434294800005
J	Chien, JT; Lee, CH				Chien, Jen-Tzung; Lee, Chao-Hsi			Deep Unfolding for Topic Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep unfolding; topic model; variational inference; deep neural network; unsupervised/supervised learning		Deep unfolding provides an approach to integrate the probabilistic generative models and the deterministic neural networks. Such an approach is benefited by deep representation, easy interpretation, flexible learning and stochastic modeling. This study develops the unsupervised and supervised learning of deep unfolded topic models for document representation and classification. Conventionally, the unsupervised and supervised topic models are inferred via the variational inference algorithm where the model parameters are estimated by maximizing the lower bound of logarithm of marginal likelihood using input documents without and with class labels, respectively. The representation capability or classification accuracy is constrained by the variational lower bound and the tied model parameters across inference procedure. This paper aims to relax these constraints by directly maximizing the end performance criterion and continuously untying the parameters in learning process via deep unfolding inference (DUI). The inference procedure is treated as the layer-wise learning in a deep neural network. The end performance is iteratively improved by using the estimated topic parameters according to the exponentiated updates. Deep learning of topic models is therefore implemented through a back-propagation procedure. Experimental results show the merits of DUI with increasing number of layers compared with variational inference in unsupervised as well as supervised topic models.	[Chien, Jen-Tzung; Lee, Chao-Hsi] Natl Chiao Tung Univ, Dept Elect & Comp Engn, Hsinchu 300, Taiwan	National Yang Ming Chiao Tung University	Chien, JT (corresponding author), Natl Chiao Tung Univ, Dept Elect & Comp Engn, Hsinchu 300, Taiwan.	jtchien@nctu.edu.tw; chlee@chien.cm.nctu.edu.tw		Chien, Jen-Tzung/0000-0003-3466-8941	Ministry of Science and Technology, Taiwan [MOST 105-2221-E-009-137-MY2]	Ministry of Science and Technology, Taiwan(Ministry of Science and Technology, Taiwan)	This work was supported by the Ministry of Science and Technology, Taiwan, under MOST 105-2221-E-009-137-MY2.	Bengio Y, 2006, P 19 INT C NEUR INF, P153; Bengio Y, 2014, PR MACH LEARN RES, V32, P226; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Blitzer J., P 45 ANN M ASS COMP, P440, DOI DOI 10.1109/IRPS.2011.5784441; Burda Y., 2016, P INT C LEARN REPR M; Chang YL, 2009, INT CONF ACOUST SPEE, P1689, DOI 10.1109/ICASSP.2009.4959927; Chen J., 2015, ADV NEURAL INFORM PR, P1765; Chien JT, 2008, IEEE T AUDIO SPEECH, V16, P198, DOI 10.1109/TASL.2007.909452; Chien JT, 2016, IEEE T NEUR NET LEAR, V27, P565, DOI 10.1109/TNNLS.2015.2414658; Chien JT, 2015, IEEE-ACM T AUDIO SPE, V23, P1259, DOI 10.1109/TASLP.2015.2428632; Chien JT, 2012, IEEE T AUDIO SPEECH, V20, P55, DOI 10.1109/TASL.2011.2143405; Chien JT, 2011, IEEE T AUDIO SPEECH, V19, P482, DOI 10.1109/TASL.2010.2050717; Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPRW.2009.5206800, 10.1109/CVPR.2009.5206800]; Chung J, 2015, ADV NEURAL INFORM PR, P2980; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duvenaud D, 2016, JMLR WORKSH CONF PRO, V51, P1070; Gan Z, 2015, PR MACH LEARN RES, V37, P1823; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Hershey J. R., 2014, ARXIV14092574; Hull D., 1993, SIGIR Forum, P329; Kingma D., 2014, P INT C LEARN REPR A; Kingma DP, 2014, PR MACH LEARN RES, V32, P1782; Kivinen J, 1997, INFORM COMPUT, V132, P1, DOI 10.1006/inco.1996.2612; Lacoste-Julien S, 2009, ADV NEURAL INFORM PR, P897, DOI DOI 10.1007/S10618-010-0175-9; Larochelle H., 2012, ADV NEURAL INFORM PR, P2708; Le Roux J, 2015, INT CONF ACOUST SPEE, P66, DOI 10.1109/ICASSP.2015.7177933; Lee CH, 2016, INT CONF ACOUST SPEE, P2279, DOI 10.1109/ICASSP.2016.7472083; Mandt S, 2016, PR MACH LEARN RES, V48; Mcauliffe Jon D., 2008, P ADV NEURAL INFORM, P121; Mnih A, 2014, PR MACH LEARN RES, V32, P1791; Newman D., 2011, ADV NEURAL INFORM PR, V24, P496, DOI DOI 10.5555/2986459.2986515; Ranganath R, 2015, JMLR WORKSH CONF PRO, V38, P762; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Stoyanov Veselin, 2011, P AISTATS; Tang Yichuan, 2013, ADV NEURAL INFORM PR, P530; Watanabe S., 2015, BAYESIAN SPEECH AND; Wisdom S, 2016, INT CONF ACOUST SPEE, P121, DOI 10.1109/ICASSP.2016.7471649; Zheng Y, 2016, IEEE T PATTERN ANAL, V38, P1056, DOI 10.1109/TPAMI.2015.2476802; Zhu J, 2012, J MACH LEARN RES, V13, P2237	39	32	33	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					318	331		10.1109/TPAMI.2017.2677439	http://dx.doi.org/10.1109/TPAMI.2017.2677439			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28278458				2022-12-18	WOS:000422706000005
J	Wandt, B; Ackermann, H; Rosenhahn, B				Wandt, Bastian; Ackermann, Hanno; Rosenhahn, Bodo			3D Reconstruction of Human Motion from Monocular Image Sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human motion; structure and motion; factorization; 3D reconstruction	STRUCTURE-FROM-MOTION; DESCENT METHOD; SHAPE	This article tackles the problem of estimating non-rigid human 3D shape and motion from image sequences taken by uncalibrated cameras. Similar to other state-of-the-art solutions we factorize 2D observations in camera parameters, base poses and mixing coefficients. Existing methods require sufficient camera motion during the sequence to achieve a correct 3D reconstruction. To obtain convincing 3D reconstructions from arbitrary camera motion, our method is based on a-priorly trained base poses. We show that strong periodic assumptions on the coefficients can be used to define an efficient and accurate algorithm for estimating periodic motion such as walking patterns. For the extension to non-periodic motion we propose a novel regularization term based on temporal bone length constancy. In contrast to other works, the proposed method does not use a predefined skeleton or anthropometric constraints and can handle arbitrary camera motion. We achieve convincing 3D reconstructions, even under the influence of noise and occlusions. Multiple experiments based on a 3D error metric demonstrate the stability of the proposed method. Compared to other state-of-the-art methods our algorithm shows a significant improvement.	[Wandt, Bastian; Ackermann, Hanno; Rosenhahn, Bodo] Leibniz Univ Hannover, Inst Informat Verarbeitung, D-30167 Hannover, Germany	Leibniz University Hannover	Wandt, B (corresponding author), Leibniz Univ Hannover, Inst Informat Verarbeitung, D-30167 Hannover, Germany.	wandt@tnt.uni-hannover.de; ackermann@tnt.uni-hannover.de; rosenhahn@tnt.uni-hannover.de						Akhter I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159523; Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309; Chen YL, 2010, LECT NOTES COMPUT SC, V5994, P71; CMU, 2014, HUM MOT CAPT DAT; Dai YC, 2012, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2012.6247905; Gotardo P. F. U., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3065, DOI 10.1109/CVPR.2011.5995560; Gotardo PFU, 2011, IEEE I CONF COMP VIS, P802, DOI 10.1109/ICCV.2011.6126319; Hamsici O., 2011, P 12 EUR C COMP VIS, P260; Hasler N, 2010, PROC CVPR IEEE, P1823, DOI 10.1109/CVPR.2010.5539853; Hasler N, 2009, PROC CVPR IEEE, P224, DOI 10.1109/CVPRW.2009.5206859; Kazemi V, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.48; Kovar Lucas, 2002, P 2002 ACM SIGGRAPH, P97; Li L., 2010, P 2010 ACM SIGGRAPH, P179; LUO ZQ, 1992, J OPTIMIZ THEORY APP, V72, P7, DOI 10.1007/BF00939948; Park HS, 2010, LECT NOTES COMPUT SC, V6313, P158; Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41; Sigal L, 2010, INT J COMPUT VISION, V87, P1, DOI 10.1007/s11263-009-0293-2; Simo-Serra E, 2012, PROC CVPR IEEE, P2673, DOI 10.1109/CVPR.2012.6247988; Theobalt C, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P185, DOI 10.1109/PCCGA.2003.1238260; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2004, ADV NEUR IN, V16, P1555; Torresani L, 2001, PROC CVPR IEEE, P493; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Troje N. F, 2002, LITTLE DIFFERENCE FO, P115; Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2; Tseng P, 2009, MATH PROGRAM, V117, P387, DOI 10.1007/s10107-007-0170-0; Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303; Xiao J, 2004, LECT NOTES COMPUT SC, V2034, P573; Zhu YG, 2011, PROCEEDINGS OF THE ASME INTERNATIONAL MANUFACTURING SCIENCE AND ENGINEERING CONFERENCE 2010, VOL 2, P1, DOI 10.1109/CVPR.2011.5995650	31	32	32	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1505	1516		10.1109/TPAMI.2016.2553028	http://dx.doi.org/10.1109/TPAMI.2016.2553028			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	27093439				2022-12-18	WOS:000379926200003
J	Seyedhosseini, M; Tasdizen, T				Seyedhosseini, Mojtaba; Tasdizen, Tolga			Semantic Image Segmentation with Contextual Hierarchical Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantic segmentation; image segmentation; edge detection; hierarchical models; membrane detection; connectome	SCENE; FEATURES	Semantic segmentation is the problem of assigning an object label to each pixel. It unifies the image segmentation and object recognition problems. The importance of using contextual information in semantic segmentation frameworks has been widely realized in the field. We propose a contextual framework, called contextual hierarchical model (CHM), which learns contextual information in a hierarchical framework for semantic segmentation. At each level of the hierarchy, a classifier is trained based on downsampled input images and outputs of previous levels. Our model then incorporates the resulting multi-resolution contextual information into a classifier to segment the input image at original resolution. This training strategy allows for optimization of a joint posterior probability at multiple resolutions through the hierarchy. Contextual hierarchical model is purely based on the input image patches and does not make use of any fragments or shape examples. Hence, it is applicable to a variety of problems such as object segmentation and edge detection. We demonstrate that CHM performs at par with state-of-the-art on Stanford background and Weizmann horse datasets. It also outperforms state-of-the-art edge detection methods on NYU depth dataset and achieves state-of-the-art on Berkeley segmentation dataset (BSDS 500).	[Seyedhosseini, Mojtaba; Tasdizen, Tolga] Univ Utah, Dept Elect & Comp Engn, Salt Lake City, UT 84112 USA; Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA	Utah System of Higher Education; University of Utah; Utah System of Higher Education; University of Utah	Seyedhosseini, M; Tasdizen, T (corresponding author), Univ Utah, Dept Elect & Comp Engn, Salt Lake City, UT 84112 USA.	mseyed@sci.utah.edu; tolga@sci.utah.edu		Tasdizen, Tolga/0000-0001-6574-0366	NIH [1R01NS075314-01]; NSF [IIS-1149299]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE [R01NS075314] Funding Source: NIH RePORTER	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NSF(National Science Foundation (NSF)); NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS))	This work was supported by NIH 1R01NS075314-01 (TT, MHE) and NSF IIS-1149299(TT). The authors thank the "National Center for Microscopy Imaging Research" and the "Cardona Lab at HHMI Janelia Farm" for providing the mouse neuropil and Drosophila VNC datasets. They also thank Piotr Dollar for providing edge detection results of SE [11] method for NYU depth dataset.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Anderson JR, 2009, PLOS BIOL, V7, P493, DOI 10.1371/journal.pbio.1000074; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Arbelaez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707; Arganda-Carreras I., 2012, ISBI2012 SEGMENTATIO; Bertelli L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2153, DOI 10.1109/CVPR.2011.5995597; Borenstein E., 2004, P IEEE WORKSH PERC O, P46; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cardona A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038011; Cardona A, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000502; Catanzaro B, 2009, IEEE I CONF COMP VIS, P2381, DOI 10.1109/ICCV.2009.5459410; Chen L.C, 2014, ARXIV14127062; Chklovskii DB, 2010, CURR OPIN NEUROBIOL, V20, P667, DOI 10.1016/j.conb.2010.08.002; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Ciresan Dan, 2012, ADV NEURAL INFORM PR, P2843, DOI DOI 10.5555/2999325.2999452; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Denk W, 2004, PLOS BIOL, V2, P1900, DOI 10.1371/journal.pbio.0020329; Dollar P., 2006, P IEEE COMP SOC C CO, V2, P1964, DOI DOI 10.1109/CVPR.2006.298; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Fink M., 2004, P ADV NEUR INF PROC, P9; Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211; Grangier D., 2009, P INT C MACH LEARN; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Haykin S., 1999, NEURAL NETWORKS COMP; He XM, 2004, PROC CVPR IEEE, P695; Heitz G., 2009, ADV NEURAL INFORM PR, V21, P641; Hinton G.E., 2012, COMPUT SCI, V3, P212, DOI DOI 10.9774/GLEAF.978-1-909493-38-42; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Jurrus E, 2010, MED IMAGE ANAL, V14, P770, DOI 10.1016/j.media.2010.06.002; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Kontschieder P, 2011, IEEE I CONF COMP VIS, P2190, DOI 10.1109/ICCV.2011.6126496; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kuettel D, 2012, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2012.6247721; Kumar MP, 2010, PROC CVPR IEEE, P3217, DOI 10.1109/CVPR.2010.5540072; Kumar R., 2010, 2010 IEEE COMPUTER S, P186, DOI DOI 10.1109/CVPRW.2010.5543594; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Laptev D, 2012, LECT NOTES COMPUT SC, V7510, P323, DOI 10.1007/978-3-642-33415-3_40; Larlus D., 2008, COMP VIS PATT REC 20, P1; LeCun Y., 2001, INTELLIGENT SIGNAL P, P306; Lempitsky V., 2011, NIPS, V24, P1485; Levin A, 2006, LECT NOTES COMPUT SC, V3954, P581; Li CC, 2012, IEEE T PATTERN ANAL, V34, P1394, DOI 10.1109/TPAMI.2011.232; Li S., 1995, MARKOV RANDOM FIELD, P1; Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Liu G., 2007, ICCV, P1, DOI DOI 10.1109/ICCV.2007.4408941; Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI 10.1109/CVPR.2015.7298965; Lucchi A, 2010, LECT NOTES COMPUT SC, V6362, P463; Mairal J, 2008, LECT NOTES COMPUT SC, V5304, P43, DOI 10.1007/978-3-540-88690-7_4; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Munoz D, 2010, LECT NOTES COMPUT SC, V6316, P57, DOI 10.1007/978-3-642-15567-3_5; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Pinheiro PO, 2014, PR MACH LEARN RES, V32; Ren X., 2012, ADV NEURAL INFORM PR, V1, P584, DOI DOI 10.5555/2999134.2999200; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Ren ZL, 2013, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2013.262; Seyedhosseini M, 2013, IEEE I CONF COMP VIS, P2168, DOI 10.1109/ICCV.2013.269; Seyedhosseini M, 2013, IEEE T IMAGE PROCESS, V22, P4486, DOI 10.1109/TIP.2013.2274388; Seyedhosseini M, 2011, LECT NOTES COMPUT SC, V6891, P670, DOI 10.1007/978-3-642-23623-5_84; Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298; Socher R., 2011, P 28 INT C INT C MAC, P129; Sporns O, 2005, PLOS COMPUT BIOL, V1, P245, DOI 10.1371/journal.pcbi.0010042; Szegedy Christian, 2013, ADV NEURAL INFORM PR, P3, DOI DOI 10.5555/2999792.2999897; Tighe J, 2013, PROC CVPR IEEE, P3001, DOI 10.1109/CVPR.2013.386; Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z; Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26; Torralba A., 2004, NEURAL INFORM PROCES; Turaga S., 2009, ADV NEURAL INFORM PR, P1865; Vandewalle P., 2006, REPROD RES; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang S, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON NANOSCALE ARCHITECTURE, P1; Yao J, 2012, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2012.6247739; Zheng S., 2015, ARXIV150203240	80	32	32	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					951	964		10.1109/TPAMI.2015.2473846	http://dx.doi.org/10.1109/TPAMI.2015.2473846			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	26336116	Green Accepted			2022-12-18	WOS:000374164700009
J	Filippone, M; Girolami, M				Filippone, Maurizio; Girolami, Mark			Pseudo-Marginal Bayesian Inference for Gaussian Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hierarchic Bayesian models; Gaussian processes; Markov chain Monte Carlo; pseudo-marginal Monte Carlo; Kernel methods; approximate Bayesian inference	CLASSIFICATION; APPROXIMATIONS; FRAMEWORK; MODELS	The main challenges that arise when adopting Gaussian process priors in probabilistic modeling are how to carry out exact Bayesian inference and how to account for uncertainty on model parameters when making model-based predictions on out-of-sample data. Using probit regression as an illustrative working example, this paper presents a general and effective methodology based on the pseudo-marginal approach to Markov chain Monte Carlo that efficiently addresses both of these issues. The results presented in this paper show improvements over existing sampling methods to simulate from the posterior distribution over the parameters defining the covariance function of the Gaussian Process prior. This is particularly important as it offers a powerful tool to carry out full Bayesian inference of Gaussian Process based hierarchic statistical models in general. The results also demonstrate that Monte Carlo based integration of all model parameters is actually feasible in this class of models providing a superior quantification of uncertainty in predictions. Extensive comparisons with respect to state-of-the-art probabilistic classifiers confirm this assertion.	[Filippone, Maurizio] Univ Glasgow, Sch Comp Sci, Glasgow G12 8QQ, Lanark, Scotland; [Girolami, Mark] Univ Warwick, Dept Stat, Coventry CV4 7AL, W Midlands, England	University of Glasgow; University of Warwick	Filippone, M (corresponding author), Univ Glasgow, Sch Comp Sci, Glasgow G12 8QQ, Lanark, Scotland.	maurizio.filippone@glasgow.ac.uk; m.girolami@warwick.ac.uk		Girolami, Mark/0000-0003-3008-253X; Filippone, Maurizio/0000-0001-7294-472X	EPSRC [EP/J016934/2, ENGAGE EP/K015664/2, EQUIP EP/K034154/1]; Royal Society Wolfson Research Merit Award; EPSRC [EP/K015664/2, EP/K034154/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/J016934/2, EP/K034154/1, EP/K015664/2] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Royal Society Wolfson Research Merit Award(Royal Society of London); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors would like to thank the anonymous reviewers for their critical and constructive comments and suggestions. Mark Girolami is supported by an EPSRC Established Career Research Fellowship EP/J016934/2, a Royal Society Wolfson Research Merit Award, and EPSRC Project Grants ENGAGE EP/K015664/2 and EQUIP EP/K034154/1. This work is dedicated to Stefano Filippone.	Andrieu C, 2009, ANN STAT, V37, P697, DOI 10.1214/07-AOS574; Asuncion A, 2007, UCI MACHINE LEARNING; Beaumont MA, 2003, GENETICS, V164, P1139; Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; Chu W, 2005, J MACH LEARN RES, V6, P1019; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cseke B, 2011, J MACH LEARN RES, V12, P417; DUANE S, 1987, PHYS LETT B, V195, P216, DOI 10.1016/0370-2693(87)91197-X; Ferri C., 2004, P 1 INT WORKSH ROC A, V4, P27; Filippone M, 2013, MACH LEARN, V93, P93, DOI 10.1007/s10994-013-5388-x; Filippone M, 2012, ANN APPL STAT, V6, P1883, DOI 10.1214/12-AOAS562; Filippone M., 2013, ARXIV13117320; Friel N, 2008, J R STAT SOC B, V70, P589, DOI 10.1111/j.1467-9868.2007.00650.x; Gelman A, 1992, STAT SCI, V7, P136, DOI 10.1214/ss/1177011136; Geweke J, 2004, J AM STAT ASSOC, V99, P799, DOI 10.1198/016214504000001132; Gibbs MN, 2000, IEEE T NEURAL NETWOR, V11, P1458, DOI 10.1109/72.883477; Gilks W. R., 1996, MARKOV CHAIN MONTE C; Girolami M, 2011, J R STAT SOC B, V73, P123, DOI 10.1111/j.1467-9868.2010.00765.x; Jaakkola T, 2000, J COMPUT BIOL, V7, P95, DOI 10.1089/10665270050081405; Joachims T., 1998, P EUROPEAN C MACHINE, P137, DOI [10.1007/bfb0026683, 10.1007/BFb0026683]; Knorr-Held L, 2002, SCAND J STAT, V29, P597, DOI 10.1111/1467-9469.00308; Kuss M, 2005, J MACH LEARN RES, V6, P1679; Mackay D. J. C., 1994, MODELS NEURAL NETWOR, P211, DOI DOI 10.1007/978-1-4612-0723-8_6; Minka T.P., 2001, P 17 C UNC ART INT, P362; Moller J, 1998, SCAND J STAT, V25, P451, DOI 10.1111/1467-9469.00115; Murray I., 2010, JMLR W CP, V9, P541; Murray I., 2010, ADV NEURAL INFORM PR, V23, P1732, DOI DOI 10.5555/2997046.2997089; Neal RM, 2003, ANN STAT, V31, P705, DOI 10.1214/aos/1056562461; Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028; Neal RM, 1993, CRGTR931 U TOR DEP C; Nickisch H, 2008, J MACH LEARN RES, V9, P2035; Opper M, 2000, NEURAL COMPUT, V12, P2655, DOI 10.1162/089976600300014881; Rasmussen C. E., 2005, INT C MACH LEARN, P689, DOI DOI 10.1145/1102351.1102438; Ratsch G, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S9; Robert C. P., 2005, SPRINGER TEXTS STAT; Rue H, 2009, J R STAT SOC B, V71, P319, DOI 10.1111/j.1467-9868.2008.00700.x; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Skilling J, 2006, BAYESIAN ANAL, V1, P833, DOI 10.1214/06-BA127; Taylor MB, 2012, ARXIV12021738; TIERNEY L, 1986, J AM STAT ASSOC, V81, P82, DOI 10.2307/2287970; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167; Yu YM, 2011, J COMPUT GRAPH STAT, V20, P531, DOI 10.1198/jcgs.2011.203main	49	32	32	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2214	2226		10.1109/TPAMI.2014.2316530	http://dx.doi.org/10.1109/TPAMI.2014.2316530			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353062	Green Submitted, Green Accepted, hybrid			2022-12-18	WOS:000343702400008
J	Wang, JD; Wang, NY; Jia, Y; Li, J; Zeng, G; Zha, HB; Hua, XS				Wang, Jingdong; Wang, Naiyan; Jia, You; Li, Jian; Zeng, Gang; Zha, Hongbin; Hua, Xian-Sheng			Trinary-Projection Trees for Approximate Nearest Neighbor Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Approximate nearest neighbor search; KD trees; trinary-projection trees	TEXTURE SYNTHESIS; SHAPE; SCENE; GRAPH	We address the problem of approximate nearest neighbor (ANN) search for visual descriptor indexing. Most spatial partition trees, such as KD trees, VP trees, and so on, follow the hierarchical binary space partitioning framework. The key effort is to design different partition functions (hyperplane or hypersphere) to divide the points so that 1) the data points can be well grouped to support effective NN candidate location and 2) the partition functions can be quickly evaluated to support efficient NN candidate location. We design a trinary-projection direction-based partition function. The trinary-projection direction is defined as a combination of a few coordinate axes with the weights being 1 or -1. We pursue the projection direction using the widely adopted maximum variance criterion to guarantee good space partitioning and find fewer coordinate axes to guarantee efficient partition function evaluation. We present a coordinate-wise enumeration algorithm to find the principal trinary-projection direction. In addition, we provide an extension using multiple randomized trees for improved performance. We justify our approach on large-scale local patch indexing and similar image search.	[Wang, Jingdong] Microsoft Res Asia, Media Comp Grp, 13-F,Bldg 2,5 Danling St, Beijing 100080, Peoples R China; [Wang, Naiyan] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China; [Jia, You] Facebook, Menlo Pk, CA 94025 USA; [Li, Jian] Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing 100084, Peoples R China; [Zeng, Gang] Peking Univ, Key Lab Machine Percept, Dept Machine Intelligence, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China; [Zha, Hongbin] Peking Univ, Dept Machine Intelligence, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China; [Hua, Xian-Sheng] Microsoft Corp, Redmond, WA 98052 USA	Microsoft; Microsoft Research Asia; Hong Kong University of Science & Technology; Facebook Inc; Tsinghua University; Peking University; Peking University; Microsoft	Wang, JD (corresponding author), Microsoft Res Asia, Media Comp Grp, 13-F,Bldg 2,5 Danling St, Beijing 100080, Peoples R China.	jingdw@microsoft.com; winsty@gmail.com; jiayou50@gmail.com; lapordge@gmail.com; g.zeng@ieee.org; zha@cis.pku.edu.cn; xshua@microsoft.com	Wang, Jingdong/E-9920-2017	Wang, Jingdong/0000-0002-4888-4445	National Basic Research Program of China [2011CBA00300, 2011CBA00301]; National Natural Science Foundation of China [61202009, 61033001, 61061130540, 61073174]	National Basic Research Program of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Jian Li was supported in part by the National Basic Research Program of China grants 2011CBA00300, 2011CBA00301, the National Natural Science Foundation of China grants 61202009, 61033001, 61061130540, and 61073174.	Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Arya S., 1993, P DCC 93 DAT COMPR C, P381; Bawa Mayank, 2005, P 14 INT C WORLD WID, P651, DOI DOI 10.1145/1060745.1060840; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BESAG J, 1986, J R STAT SOC B, V48, P259; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; Cayton L., 2007, P NEUR INF PROC SYST; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dasgupta S, 2008, ACM S THEORY COMPUT, P537; Faloutsos C., 1995, SIGMOD Record, V24, P163, DOI 10.1145/568271.223812; Fei-Fei L., 2004, P C COMP VIS PATT RE; Finkel R. A., 1974, Acta Informatica, V4, P1, DOI 10.1007/BF00288933; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Frome A, 2007, IEEE I CONF COMP VIS, P94; He J., 2010, P ACM SIGKDD INT C K, P1129; Hua G, 2007, IEEE I CONF COMP VIS, P229; Jain P., 2008, P IEEE C COMP VIS PA; Jia Y, 2010, PROC CVPR IEEE, P3392, DOI 10.1109/CVPR.2010.5540006; Johnson W. B., 1984, CONT MATH, V26, P189, DOI DOI 10.1090/CONM/026/737400; Kulis B., 2009, P NEUR INF PROC SYST, P577; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787; Liu T., 2004, ADV NEURAL INFORM PR, V17; Liu T, 2006, J MACH LEARN RES, V7, P1135; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lv Q, 2007, P 33 INT C VER LARG, P950, DOI DOI 10.1145/1143844.1143857; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Moore A. W., 2000, UAI, P397; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Navarro G, 2002, VLDB J, V11, P28, DOI 10.1007/s007780200060; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Samet H, 2006, MORGAN KAUFMANN SERI; Sebastian TB, 2002, INT C PATT RECOG, P291, DOI 10.1109/ICPR.2002.1047852; Silpa-Anan C, 2008, P IEEE C COMP VIS PA; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; Tu W., 2012, P 20 ACM INT C MULT, P885; Verma N., 2009, P MONTR QUE 25 C UNC, P565; Wang J., 2012, PROC 20 ACM INT C MU, P179; Wang J, 2012, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2012.6247790; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Weiss Y., 2008, NIPS, P1753; Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424; YAMAGUCHI K, 1984, IEEE COMPUT GRAPH, V4, P53, DOI 10.1109/MCG.1984.275901; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]	57	32	33	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					388	403		10.1109/TPAMI.2013.125	http://dx.doi.org/10.1109/TPAMI.2013.125			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356357				2022-12-18	WOS:000328899500014
J	Zhou, ZH; Hong, XP; Zhao, GY; Pietikainen, M				Zhou, Ziheng; Hong, Xiaopeng; Zhao, Guoying; Pietikainen, Matti			A Compact Representation of Visual Speech Data Using Latent Variables	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual speech recognition; compact representation; latent variable	MAXIMUM-LIKELIHOOD; RECOGNITION; MODELS; SCALE	The problem of visual speech recognition involves the decoding of the video dynamics of a talking mouth in a high-dimensional visual space. In this paper, we propose a generative latent variable model to provide a compact representation of visual speech data. The model uses latent variables to separately represent the interspeaker variations of visual appearances and those caused by uttering within images, and incorporates the structural information of the visual data through placing priors of the latent variables along a curve embedded within a path graph.	[Zhou, Ziheng; Hong, Xiaopeng; Zhao, Guoying; Pietikainen, Matti] Univ Oulu, Ctr Machine Vision Res, Dept Comp Sci & Engn, FI-90014 Oulu, Finland	University of Oulu	Zhou, ZH (corresponding author), Univ Oulu, Ctr Machine Vision Res, Dept Comp Sci & Engn, POB 4500, FI-90014 Oulu, Finland.	ziheng.zhou@ee.oulu.fi; xiaopeng.hong@ee.oulu.fi; guoying.zhao@ee.oulu.fi; mkp@ee.oulu.fi	HONG, Xiaopeng/V-6078-2019; Zhao, Guoying/ABE-7716-2020	HONG, Xiaopeng/0000-0002-0611-0636; Zhao, Guoying/0000-0003-3694-206X	Academy of Finland; Infotech Oulu	Academy of Finland(Academy of Finland); Infotech Oulu	This research was supported by the Academy of Finland and Infotech Oulu.	Belkin M, 2002, ADV NEUR IN, V14, P585; BREGLER C, 1994, INT CONF ACOUST SPEE, P669, DOI 10.1109/ICASSP.1994.389567; Chung F. R. K., 1996, CBMS REGIONAL C SERI; Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479; Fergus R, 2003, PROC CVPR IEEE, P264; Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043; Gowdy JN, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P993; Kanaujia A, 2007, IEEE I CONF COMP VIS, P142; Lan Y, 2009, P INT C AUD VIS SPEE, P102; Lan Y., 2010, P INT C AUD VIS SPEE, P142; Li P, 2012, IEEE T PATTERN ANAL, V34, P144, DOI 10.1109/TPAMI.2011.104; Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900; MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0; Nefian AV, 2002, EURASIP J APPL SIG P, V2002, P1274, DOI 10.1155/S1110865702206083; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Potamianos G., 2001, International Journal of Speech Technology, V4, P193, DOI 10.1023/A:1011352422845; Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Saenko K, 2009, IEEE T PATTERN ANAL, V31, P1700, DOI 10.1109/TPAMI.2008.303; Tian Y., 2010, P AS C COMP VIS QUEE, P679; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637; ZHOU ZH, 2011, PROC CVPR IEEE, P137	27	32	36	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					181	187		10.1109/TPAMI.2013.173	http://dx.doi.org/10.1109/TPAMI.2013.173			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231875				2022-12-18	WOS:000327965100015
J	Liu, HR; Latecki, LJ; Yan, SC				Liu, Hairong; Latecki, Longin Jan; Yan, Shuicheng			Fast Detection of Dense Subgraphs with Iterative Shrinking and Expansion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dense subgraph; correspondence; point set matching; maximum common subgraph; cluster analysis	COMMUNITY STRUCTURE; ALGORITHM	In this paper, we propose an efficient algorithm to detect dense subgraphs of a weighted graph. The proposed algorithm, called the shrinking and expansion algorithm (SEA), iterates between two phases, namely, the expansion phase and the shrink phase, until convergence. For a current subgraph, the expansion phase adds the most related vertices based on the average affinity between each vertex and the subgraph. The shrink phase considers all pairwise relations in the current subgraph and filters out vertices whose average affinities to other vertices are smaller than the average affinity of the result subgraph. In both phases, SEA operates on small subgraphs; thus it is very efficient. Significant dense subgraphs are robustly enumerated by running SEA from each vertex of the graph. We evaluate SEA on two different applications: solving correspondence problems and cluster analysis. Both theoretic analysis and experimental results show that SEA is very efficient and robust, especially when there exists a large amount of noise in edge weights.	[Liu, Hairong; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119615, Singapore; [Latecki, Longin Jan] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA	National University of Singapore; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Liu, HR (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119615, Singapore.	lhrbss@gmail.com; latecki@temple.edu; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022	Latecki, Longin Jan/0000-0002-5102-8244				Albarelli A, 2009, IEEE I CONF COMP VIS, P1319, DOI 10.1109/ICCV.2009.5459312; Bomze IM, 2002, J GLOBAL OPTIM, V22, P17, DOI 10.1023/A:1013886408463; Bul`o S. R., 2009, ADV NEURAL INFORM PR, P1571; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; Chen J, 2012, IEEE T KNOWL DATA EN, V24, P1216, DOI 10.1109/TKDE.2010.271; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Conte D, 2003, LECT NOTES COMPUT SC, V2726, P130; Crammer K., 2008, P 25 INT C MACH LEAR, P184; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; Duchenne O, 2009, PROC CVPR IEEE, P1980, DOI 10.1109/CVPRW.2009.5206619; Durand PJ, 1999, INTERNET J CHEM, V2; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Georgescu B, 2004, IEEE T PATTERN ANAL, V26, P674, DOI 10.1109/TPAMI.2004.2; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Hein M, 2010, ADV NEURAL INFORM PR, V1, P847; HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855; Jiang H, 2007, IEEE T PATTERN ANAL, V29, P959, DOI 10.1109/TPAMI.2007.1048; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Kuhn H., 1951, P 2 BERK S MATH STAT, P481, DOI DOI 10.1007/BF01582292; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Lin F., 2010, P 27 INT C MACH LEAR, V10, P655; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Liu H., 2010, ADV NEURAL INFORM PR, P1414; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151; MOTZKIN TS, 1965, CANADIAN J MATH, V17, P533, DOI 10.4153/CJM-1965-053-6; Ng AY, 2002, ADV NEUR IN, V14, P849; Ouyang Q, 1997, SCIENCE, V278, P446, DOI 10.1126/science.278.5337.446; Palla G, 2005, NATURE, V435, P814, DOI 10.1038/nature03607; Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608; Pelillo M, 2002, ADV NEUR IN, V14, P865; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Weibull J W, 1997, EVOLUTIONARY GAME TH; Wu X., 2007, P ACM INT C IM VID R, P169; Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P283; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zass R., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587500; Zhao WL, 2007, IEEE T MULTIMEDIA, V9, P1037, DOI 10.1109/TMM.2007.898928; Zhu  J., 2008, P 16 ACM INT C MULT, P41	42	32	34	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2131	2142		10.1109/TPAMI.2013.16	http://dx.doi.org/10.1109/TPAMI.2013.16			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868775	Green Submitted			2022-12-18	WOS:000322029000007
J	Li, YH; Savvides, M				Li, Yung-Hui; Savvides, Marios			An Automatic Iris Occlusion Estimation Method Based on High-Dimensional Density Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian mixture models; iris mask; iris recognition; iris occlusion estimation; biometrics recognition; simulated annealing	RECOGNITION	Iris masks play an important role in iris recognition. They indicate which part of the iris texture map is useful and which part is occluded or contaminated by noisy image artifacts such as eyelashes, eyelids, eyeglasses frames, and specular reflections. The accuracy of the iris mask is extremely important. The performance of the iris recognition system will decrease dramatically when the iris mask is inaccurate, even when the best recognition algorithm is used. Traditionally, people used the rule-based algorithms to estimate iris masks from iris images. However, the accuracy of the iris masks generated this way is questionable. In this work, we propose to use Figueiredo and Jain's Gaussian Mixture Models (FJ-GMMs) to model the underlying probabilistic distributions of both valid and invalid regions on iris images. We also explored possible features and found that Gabor Filter Bank (GFB) provides the most discriminative information for our goal. Finally, we applied Simulated Annealing (SA) technique to optimize the parameters of GFB in order to achieve the best recognition rate. Experimental results show that the masks generated by the proposed algorithm increase the iris recognition rate on both ICE2 and UBIRIS dataset, verifying the effectiveness and importance of our proposed method for iris occlusion estimation.	[Li, Yung-Hui] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan; [Savvides, Marios] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA	Feng Chia University; Carnegie Mellon University	Li, YH (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhua Rd, Taichung 40724, Taiwan.	yunghui@gmail.com; msavvid@ri.cmu.edu			National Science Council of Taiwan [NSC-101-2221-E-035 -084]	National Science Council of Taiwan(Ministry of Science and Technology, Taiwan)	This work was financially supported by the National Science Council of Taiwan under contract no. NSC-101-2221-E-035 -084.	Afshang M, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON MACHINE VISION, PROCEEDINGS, ( ICMV 2009), P199, DOI 10.1109/ICMV.2009.50; [Anonymous], 2006, IR CHALL EV; CERNY V, 1985, J OPTIMIZ THEORY APP, V45, P41, DOI 10.1007/BF00940812; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; Daugman J, 2002, IEEE IMAGE PROC, P33; Daugman J, 2001, INT J COMPUT VISION, V45, P25, DOI 10.1023/A:1012365806338; Daugman J., 1994, US Patent, Patent No. 291560; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Gelfand S., 1987, THESIS MIT; GRANVILLE V, 1994, IEEE T PATTERN ANAL, V16, P652, DOI 10.1109/34.295910; Ilonen J, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1345, DOI 10.1109/ICDSP.2002.1028343; INGBER L, 1992, MATH COMPUT MODEL, V16, P87, DOI 10.1016/0895-7177(92)90108-W; Juels A., 1994, TECHNICAL REPORT; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kong WK, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P263, DOI 10.1109/ISIMP.2001.925384; Krichen E., 2007, P 1 IEEE INT C BIOM, P1; Lahtinen J., 1996, P 2 NORD WORKSH GEN; Li M., 2006, P 8 INT C SIGN PROC, V2; Lindh T, 2003, IEEE INTERNATIONAL SYMPOSIUM ON DIAGNOSTICS FOR ELECTRIC MACHINES, POWER ELECTRONICS AND DRIVES, PROCEEDINGS, P177; Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145; Ma S. K., 1985, STAT MECH; Park K., 1995, P 10 ACM S APPL COMP, P329; Proenca H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119; Rabiner L., 1993, FUNDAMENTALS SPEECH; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Sun ZH, 2005, IEEE T INTELL TRANSP, V6, P125, DOI 10.1109/TITS.2005.848363; Sun ZH, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P307; Thornton J, 2007, P 1 IEEE INT C BIOM, P1; Thornton J., 2007, THESIS CARNEGIE MELL; Tisse C., 2002, PERSON IDENTIFICATIO; Tsai CC, 2008, IEEE SYS MAN CYBERN, P920; Yang MH, 1998, PROC SPIE, V3656, P458, DOI 10.1117/12.333865; Zhao YN, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2229; Zhou J., P 10 INT C OPTICAL C, P1, DOI DOI 10.1080/01431161.2010.517225; Zuo J., 2006, BIOM CONS C 2006 BIO, P1	38	32	33	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					784	796		10.1109/TPAMI.2012.169	http://dx.doi.org/10.1109/TPAMI.2012.169			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22868651				2022-12-18	WOS:000314931000002
J	Ocegueda, O; Fang, TH; Shah, SK; Kakadiaris, IA				Ocegueda, Omar; Fang, Tianhong; Shah, Shishir K.; Kakadiaris, Ioannis A.			3D Face Discriminant Analysis Using Gauss-Markov Posterior Marginals	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature evaluation and selection; object recognition; Markov random fields; segmentation; image processing and computer vision; pattern recognition; face and gesture recognition	RECOGNITION	We present a Markov Random Field model for the analysis of lattices (e.g., images or 3D meshes) in terms of the discriminative information of their vertices. The proposed method provides a measure field that estimates the probability of each vertex being "discriminative" or "nondiscriminative" for a given classification task. To illustrate the applicability and generality of our framework; we use the estimated probabilities as feature scoring to define compact signatures for three different classification tasks: 1) 3D Face Recognition, 2) 3D Facial Expression Recognition, and 3) Ethnicity-based Subject Retrieval, obtaining very competitive results. The main contribution of this work lies in the development of a novel framework for feature selection in scenaria in which the most discriminative information is smoothly distributed along a lattice.	[Ocegueda, Omar; Fang, Tianhong; Shah, Shishir K.; Kakadiaris, Ioannis A.] Univ Houston, Dept Comp Sci, Computat Biomed Lab CBL, Houston, TX 77204 USA	University of Houston System; University of Houston	Ocegueda, O (corresponding author), Univ Houston, Dept Comp Sci, Computat Biomed Lab CBL, MS CSC 3010,219 Philip Guthrie Hoffman Hall PGH,4, Houston, TX 77204 USA.	jomaroceguedag@gmail.com; airfang613@gmail.com; shah@cs.uh.edu; IKakadia@central.uh.edu		Kakadiaris, Ioannis/0000-0002-0591-1079	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the Army Research Laboratory (ARL); University of Houston (UH) Eckhard Pfeiffer Endowment Fund.	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the Army Research Laboratory (ARL); University of Houston (UH) Eckhard Pfeiffer Endowment Fund.	This research was funded in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), through the Army Research Laboratory (ARL) and by the University of Houston (UH) Eckhard Pfeiffer Endowment Fund. All statements of fact, opinion, or conclusions contained herein are those of the authors and should not be construed as representing the official views or policies of IARPA, the ODNI, the US Government, or UH.	Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0; Alyuz Nese, 2009, 2009 IEEE 17th Signal Processing and Communications Applications Conference (SIU), P544, DOI 10.1109/SIU.2009.5136453; Boehnen C, 2009, LECT NOTES COMPUT SC, V5558, P12, DOI 10.1007/978-3-642-01793-3_2; Cai D., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383054; Daniyal F, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P302, DOI 10.1109/AVSS.2009.71; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287; Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616; Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052; Husken M., 2005, P INT C COMP VIS PAT, P174; John G.H., 1994, MACHINE LEARNING P 1, DOI 10.1016/B978-1-55860-335-6.50023-4; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; Liu H, 2010, JMLR WORKSH CONF PRO, V10, P4; Marroquin JL, 2001, IEEE T PATTERN ANAL, V23, P337, DOI 10.1109/34.917570; Martinez Aleix M, 2011, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2011, P7; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14; Rivera M., 2004, P BRIT MACH VIS C SE; Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6; Savvides M., 2006, PROC IEEE C COMPUT V, P48; Toderici G, 2010, INT J COMPUT VISION, V89, P382, DOI 10.1007/s11263-009-0300-7; Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009; Wolf L, 2005, J MACH LEARN RES, V6, P1855; Wolf L., 2005, P IEEE C COMP VIS PA, P20; Yin L., 2008, AUTOMATIC FACE GESTU, V08, P1, DOI DOI 10.1109/AFGR.2008.4813324; Zhao Z, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1156; Zhu M, 2003, J COMPUT GRAPH STAT, V12, P101, DOI 10.1198/1061860031220	30	32	35	0	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					728	739		10.1109/TPAMI.2012.126	http://dx.doi.org/10.1109/TPAMI.2012.126			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22641704				2022-12-18	WOS:000314792900016
J	Wang, G; Hoiem, D; Forsyth, D				Wang, Gang; Hoiem, Derek; Forsyth, David			Learning Image Similarity from Flickr Groups Using Fast Kernel Machines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image similarity; kernel machines; stochastic gradient descent; online learning; image classification; image organization	OBJECT RECOGNITION; CLASSIFICATION; CATEGORIES; TEXTURE; SCENE; SHAPE; TOOL	Measuring image similarity is a central topic in computer vision. In this paper, we propose to measure image similarity by learning from the online Flickr image groups. We do so by: Choosing 103 Flickr groups, building a one-versus-all multiclass classifier to classify test images into a group, taking the set of responses of the classifiers as features, calculating the distance between feature vectors to measure image similarity. Experimental results on the Corel dataset and the PASCAL VOC 2007 dataset show that our approach performs better on image matching, retrieval, and classification than using conventional visual features. To build our similarity measure, we need one-versus-all classifiers that are accurate and can be trained quickly on very large quantities of data. We adopt an SVM classifier with a histogram intersection kernel. We describe a novel fast training algorithm for this classifier: the Stochastic Intersection Kernel MAchine (SIKMA) training algorithm. This method can produce a kernel classifier that is more accurate than a linear classifier on tens of thousands of examples in minutes.	[Wang, Gang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Wang, Gang] Adv Digital Sci Ctr, Singapore, Singapore; [Hoiem, Derek; Forsyth, David] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Illinois System; University of Illinois Urbana-Champaign	Wang, G (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.	wanggang@ntu.edu.sg	Wang, Gang/B-7027-2013		US National Science Foundation (NSF) [IIS-0803603]; US Office of Naval Research [N00014-01-1-0890]; MURI program	US National Science Foundation (NSF)(National Science Foundation (NSF)); US Office of Naval Research(Office of Naval Research); MURI program(MURI)	This work was supported in part by the US National Science Foundation (NSF) under IIS-0803603 and in part by the US Office of Naval Research under N00014-01-1-0890 as part of the MURI program. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the US National Science Foundation or the US Office of Naval Research.	Barnard K, 2001, PROC CVPR IEEE, P434; Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bottou L, 2004, LECT NOTES ARTIF INT, V3176, P146; Bottou L., 2007, LARGE SCALE KERNEL M; Chang C.C., 2001, LIBSVM LIB SUPPORT V, V80, P604; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Cui JY, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P367; Dalai N., 2005, P IEEE CS C COMP VIS, V1; Datta R., 2006, 06009 CSE PENNS STAT; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Everingham M., 2007, P INT JOINT C NEUR N; Fergus R, 2005, IEEE I CONF COMP VIS, P1816; Grauman K., 2005, P IEEE INT C COMP VI, V1, P3; Jacobs C. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P277, DOI 10.1145/218380.218454; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991; Kumar N., 2009, P IEEE INT C COMP VI; Lazebnik S., 2006, P IEEE C COMP VIS PA; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li L., 2010, NEURIPS; Li LJ, 2010, INT J COMPUT VISION, V88, P147, DOI 10.1007/s11263-009-0265-6; Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045; Loeff N, 2008, LECT NOTES COMPUT SC, V5305, P451, DOI 10.1007/978-3-540-88693-8_33; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S., 2009, P IEEE INT C COMP VI; Maji S., 2008, P IEEE C COMP VIS PA; MAKADIA A., 2008, P EUR C COMP VIS; Makadia V.P.A., 2008, P EUR C COMP VIS; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138; Rubner Y, 1998, P IEEE INT C COMP VI; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Schroff F, 2011, IEEE T PATTERN ANAL, V33, P754, DOI 10.1109/TPAMI.2010.133; SHALEV- SHWARTZ S., 2007, P 24 INT C MACH LEAR, P807, DOI [DOI 10.1145/1273496.1273598, 10.1145/1273496.1273598]; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tian Y, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383282; Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Wang G., 2008, P IEEE C COMP VIS PA, P1; Wang G., 2009, P IEEE INT C COMP VI; WANG G., 2009, P IEEE C COMP VIS PA; Wang G., 2010, P IEEE C COMP VIS PA; Wang G, 2010, LECT NOTES COMPUT SC, V6315, P169, DOI 10.1007/978-3-642-15555-0_13; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang L, 2004, P 12 ANN ACM INT C M, P716, DOI DOI 10.1145/1027527.1027689	52	32	37	1	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2012	34	11					2177	2188		10.1109/TPAMI.2012.29	http://dx.doi.org/10.1109/TPAMI.2012.29			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	005MR	22997127				2022-12-18	WOS:000308755000010
J	Tang, H; Chu, SM; Hasegawa-Johnson, M; Huang, TS				Tang, Hao; Chu, Stephen Mingyu; Hasegawa-Johnson, Mark; Huang, Thomas S.			Partially Supervised Speaker Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Speaker clustering; partial supervision; distance metric learning	DIARIZATION	Content-based multimedia indexing, retrieval, and processing as well as multimedia databases demand the structuring of the media content (image, audio, video, text, etc.), one significant goal being to associate the identity of the content to the individual segments of the signals. In this paper, we specifically address the problem of speaker clustering, the task of assigning every speech utterance in an audio stream to its speaker. We offer a complete treatment to the idea of partially supervised speaker clustering, which refers to the use of our prior knowledge of speakers in general to assist the unsupervised speaker clustering process. By means of an independent training data set, we encode the prior knowledge at the various stages of the speaker clustering pipeline via 1) learning a speaker-discriminative acoustic feature transformation, 2) learning a universal speaker prior model, and 3) learning a discriminative speaker subspace, or equivalently, a speaker-discriminative distance metric. We study the directional scattering property of the Gaussian mixture model (GMM) mean supervector representation of utterances in the high-dimensional space, and advocate exploiting this property by using the cosine distance metric instead of the euclidean distance metric for speaker clustering in the GMM mean supervector space. We propose to perform discriminant analysis based on the cosine distance metric, which leads to a novel distance metric learning algorithm-linear spherical discriminant analysis (LSDA). We show that the proposed LSDA formulation can be systematically solved within the elegant graph embedding general dimensionality reduction framework. Our speaker clustering experiments on the GALE database clearly indicate that 1) our speaker clustering methods based on the GMM mean supervector representation and vector-based distance metrics outperform traditional speaker clustering methods based on the "bag of acoustic features" representation and statistical model-based distance metrics, 2) our advocated use of the cosine distance metric yields consistent increases in the speaker clustering performance as compared to the commonly used euclidean distance metric, 3) our partially supervised speaker clustering concept and strategies significantly improve the speaker clustering performance over the baselines, and 4) our proposed LSDA algorithm further leads to state-of-the-art speaker clustering performance.	[Tang, Hao] HP Labs, Palo Alto, CA 94304 USA; [Chu, Stephen Mingyu] IBM Corp, Thomas J Watson Res Ctr, Human Language Technol Grp, Yorktown Hts, NY 10598 USA; [Hasegawa-Johnson, Mark; Huang, Thomas S.] Univ Illinois, Dept Elect & Comp Engn, Beckman Inst, Urbana, IL 61801 USA	Hewlett-Packard; International Business Machines (IBM); University of Illinois System; University of Illinois Urbana-Champaign	Tang, H (corresponding author), HP Labs, 1501 Page Mill Rd, Palo Alto, CA 94304 USA.	hao.tang@hp.com; schu@us.ibm.com; jhasegaw@uiuc.edu; t-huang1@uiuc.edu	Tang, Hua/K-4948-2016	Tang, Hua/0000-0002-6685-6165	US Defense Advanced Research Projects Agency (DARPA) [HR0011-06-2-0001]; US National Science Foundation (NSF) [08-03219]; IBM T.J. Watson Research Center	US Defense Advanced Research Projects Agency (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); US National Science Foundation (NSF)(National Science Foundation (NSF)); IBM T.J. Watson Research Center	This work was supported in part by the US Defense Advanced Research Projects Agency (DARPA) contract HR0011-06-2-0001 and in part by the US National Science Foundation (NSF) Grant 08-03219. The authors would like to thank Dr. Lidia Mangu and Dr. Michael Picheny at the IBM T.J. Watson Research Center for their continuous encouragement and support.	Barras C, 2006, IEEE T AUDIO SPEECH, V14, P1505, DOI 10.1109/TASL.2006.878261; Ben M., 2004, P INT C SPOK LANG PR; Bishop C.M, 2006, PATTERN RECOGN; Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086; Chen S., 1998, P IEEE INT C AC SPEE; Chu S., 2009, P IEEE INT C AC SPEE; Chu S., 2008, P IEEE INT C AC SPEE; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; Duda R.O., 2000, PATTERN CLASSIFICATI; Faltlhauser R., 2001, P IEEE WORKSH AUT SP; Fant G, 1971, 2 ACOUSTIC THEORY SP; Fu Y, 2008, IEEE T PATTERN ANAL, V30, P2229, DOI 10.1109/TPAMI.2008.154; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Gong Y, 2007, MULTIMED SYST APPL, P1; He X., 2003, P ADV NEUR INF PROC; He X., 2005, P IEEE INT C COMP VI; HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423; Jain A., 2010, TRCSE0911; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jain P., 2001, P IEEE INT C AC SPEE; Jin H., 1997, P US DEF ADV RES PRO; Kenny P, 2005, IEEE T SPEECH AUDI P, V13, P345, DOI 10.1109/TSA.2004.840940; Kenny P., 2008, BAYESIAN ANAL SPEAKE; KUHN R, 1998, P ICSLP, P1771; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; Ma Y., 2007, P 24 INT C MACHINE L, P577, DOI DOI 10.1145/1273496.1273569; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Mahalanobis, 1936, P NATL I SCI INDIA, V2, P49; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Miro X. A., 2006, THESIS U POLITECNICA; Moore J, 1997, P WORKSH INF TECHN S; Reynolds D., 2009, P ANN C INT SPEECH C; Reynolds D. A., 1998, P ICSLP; REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Solomonoff A, 1998, INT CONF ACOUST SPEE, P757, DOI 10.1109/ICASSP.1998.675375; Tranter SE, 2006, IEEE T AUDIO SPEECH, V14, P1557, DOI 10.1109/TASL.2006.878256; Tsai W., 2004, P INT C SPOK LANG PR; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wooters C., 2007, P 2 INT WORKSH CLASS	43	32	35	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					959	971		10.1109/TPAMI.2011.174	http://dx.doi.org/10.1109/TPAMI.2011.174			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	21844626				2022-12-18	WOS:000301747400010
J	Liu, YS; Ramani, K; Liu, M				Liu, Yu-Shen; Ramani, Karthik; Liu, Min			Computing the Inner Distances of Volumetric Models for Articulated Shape Description with a Visibility Graph	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Inner distance; visibility graph; articulated shape descriptor; volumetric models	INVARIANT SIGNATURES; RETRIEVAL; GEOMETRY	A new visibility graph-based algorithm is presented for computing the inner distances of a 3D shape represented by a volumetric model. The inner distance is defined as the length of the shortest path between landmark points within the shape. The inner distance is robust to articulation and can reflect the deformation of a shape structure well without an explicit decomposition. Our method is based on the visibility graph approach. To check the visibility between pairwise points, we propose a novel, fast, and robust visibility checking algorithm based on a clustering technique which operates directly on the volumetric model without any surface reconstruction procedure, where an octree is used for accelerating the computation. The inner distance can be used as a replacement for other distance measures to build a more accurate description for complex shapes, especially for those with articulated parts. The binary executable program for the Windows platform is available from https://engineering.purdue.edu/PRECISE/VMID.	[Liu, Yu-Shen] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China; [Ramani, Karthik] Purdue Univ, Sch Mech Engn, W Lafayette, IN 47907 USA; [Liu, Min] Tsinghua Univ, Inst Mfg Engn, Beijing 100084, Peoples R China	Tsinghua University; Purdue University System; Purdue University; Purdue University West Lafayette Campus; Tsinghua University	Liu, YS (corresponding author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.	liuyushen@tsinghua.edu.cn; ramani@purdue.edu; minliu@tsinghua.edu.cn			National Science Foundation of China [61003095]; ANR-NSFC [60911130368]; Chinese 973 Program [2010CB328001]; US National Institutes of Health [GM-075004]; Div Of Industrial Innovation & Partnersh [0917959] Funding Source: National Science Foundation	National Science Foundation of China(National Natural Science Foundation of China (NSFC)); ANR-NSFC(French National Research Agency (ANR)); Chinese 973 Program(National Basic Research Program of China); US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Div Of Industrial Innovation & Partnersh(National Science Foundation (NSF)NSF - Directorate for Engineering (ENG))	The authors appreciate all of the anonymous reviewers whose comments significantly improved this paper. The research was supported by the National Science Foundation of China (61003095), ANR-NSFC (60911130368), Chinese 973 Program (2010CB328001), and the US National Institutes of Health (GM-075004).	Adams B, 2003, ACM T GRAPHIC, V22, P651, DOI 10.1145/882262.882320; Adamson A, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P272; Ben Hamza A, 2003, LECT NOTES COMPUT SC, V2886, P378; Biasotti S, 2006, COMPUT AIDED DESIGN, V38, P1002, DOI 10.1016/j.cad.2006.07.003; Biswas S., 2007, P IEEE C COMP VIS PA; Bronstein A.M., 2009, INT J COMPUTER VISIO; Bronstein AM, 2008, INT J COMPUT VISION, V78, P67, DOI 10.1007/s11263-007-0078-4; Bronstein AM, 2009, INT J COMPUT VISION, V81, P281, DOI 10.1007/s11263-008-0172-2; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Coeurjolly D, 2004, PATTERN RECOGN LETT, V25, P561, DOI 10.1016/j.patrec.2003.12.002; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Daras P, 2006, IEEE ACM T COMPUT BI, V3, P193, DOI 10.1109/TCBB.2006.43; De Berg M., 2008, COMPUTATIONAL GEOMET, Vthird; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279; Funkhouser T., 2006, P 4 EUR S GEOM PROC; Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002; Jain V, 2007, COMPUT AIDED DESIGN, V39, P398, DOI 10.1016/j.cad.2007.02.009; Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007; Ju T, 2004, ACM T GRAPHIC, V23, P888, DOI 10.1145/1015706.1015815; Ju T, 2007, COMPUT AIDED DESIGN, V39, P352, DOI 10.1016/j.cad.2007.02.006; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; KAUFMAN A, 1993, COMPUTER, V26, P51, DOI 10.1109/MC.1993.274942; Li B, 2008, PROTEINS, V71, P670, DOI 10.1002/prot.21732; Ling H., 2005, P IEEE CS C COMP VIS, P286; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Liu R, 2007, COMPUT GRAPH FORUM, V26, P385, DOI 10.1111/j.1467-8659.2007.01061.x; Liu YS, 2006, COMPUT AIDED DESIGN, V38, P55, DOI 10.1016/j.cad.2005.07.002; Liu YS, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-157; Mahmoudi M, 2009, GRAPH MODELS, V71, P22, DOI 10.1016/j.gmod.2008.10.002; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Ovsjanikov M., 2009, P NORDIA; Raviv D., 2010, P ACM WORKSH 3D OBJ; RUGGERI MR, 2008, P EUR WORKSH 3D OBJ; Rustamov R., 2010, P EUR WORKSH 3D OBJ; Rustamov RM, 2009, COMPUT GRAPH FORUM, V28, P1279, DOI 10.1111/j.1467-8659.2009.01505.x; Rustamov R. M., 2007, P 5 EUR S GEOM PROC; Sael L, 2008, PROTEINS, V72, P1259, DOI 10.1002/prot.22030; Schaufler G, 2000, SPRING COMP SCI, P319; Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8; Soille P., 1999, MORPHOLOGICAL IMAGE, DOI 10.1007/978-3-662-03939-7; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x; Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319	47	32	34	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2538	2544		10.1109/TPAMI.2011.116	http://dx.doi.org/10.1109/TPAMI.2011.116			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21670484	Green Published			2022-12-18	WOS:000295980000017
J	Ramanan, D; Baker, S				Ramanan, Deva; Baker, Simon			Local Distance Functions: A Taxonomy, New Algorithms, and an Evaluation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nearest neighbor classification; metric learning; metric tensor; local distance functions; taxonomy; database; evaluation		We present a taxonomy for local distance functions where most existing algorithms can be regarded as approximations of the geodesic distance defined by a metric tensor. We categorize existing algorithms by how, where, and when they estimate the metric tensor. We also extend the taxonomy along each axis. How: We introduce hybrid algorithms that use a combination of techniques to ameliorate overfitting. Where: We present an exact polynomial-time algorithm to integrate the metric tensor along the lines between the test and training points under the assumption that the metric tensor is piecewise constant. When: We propose an interpolation algorithm where the metric tensor is sampled at a number of references points during the offline phase. The reference points are then interpolated during the online classification phase. We also present a comprehensive evaluation on tasks in face recognition, object recognition, and digit recognition.	[Ramanan, Deva] Univ Calif Irvine, Irvine, CA 92697 USA; [Baker, Simon] Microsoft Res, Redmond, WA 98052 USA	University of California System; University of California Irvine; Microsoft	Ramanan, D (corresponding author), Univ Calif Irvine, 3019 Donald Bren Hall, Irvine, CA 92697 USA.	dramanan@ics.uci.edu; sbaker@microsoft.com						Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Babenko B., 2009, P IEEE INT C COMP VI; Bar-Hillel AB, 2005, J MACH LEARN RES, V6, P937; Boiman O., 2008, P IEEE C COMP VIS PA; Broomhead D.S., 1988, ROYAL SIGNALS RADAR; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; Cristianini N., 2000, INTRO SUPPORT VECTOR; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Fei-Fei L., 2004, P IEEE C COMP VIS PA; Frome A., 2007, P IEEE INT C COMP VI; Frome A., 2007, ADV NEURAL INFORM PR, V19, P417; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GOLDBERGER J, 2005, P ADV NEUR INF PROC, P513; GONEN M, 2008, P INT C MACH LEARN; Grauman K, 2007, J MACH LEARN RES, V8, P725; Gross Ralph, 2008, P IEEE INT C AUT FAC; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; KAPOOR A, 2009, INT J COMP VIS; Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151; KUMAR M, 2007, P IEEE INT C COMP VI; Labelle F., 2003, P 19 ANN S COMP GEOM, P191, DOI DOI 10.1145/777792.777822; LAZEBNIK S, 2006, IEEE C COMP VIS PATT, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Mahamud S, 2003, PROC CVPR IEEE, P248; Maji S., 2009, P IEEE INT C COMP VI; MALISIEWICZ T., 2008, P IEEE C COMP VIS PA; RAMANAN D, 2009, P IEEE INT C COMP VI; Rifkin R, 2004, J MACH LEARN RES, V5, P101; ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; SIM T, 2002, P IEEE INT C AUT FAC; Simard P., 1993, ADV NEURAL INFORMATI, V5, P50; Torresani L., 2007, ADV NEURAL INFORM PR, V19, P1385; Urtasun R., 2008, P IEEE C COMP VIS PA; VARMA M, 2007, P IEEE INT C COMP VI; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang XG, 2004, PROC CVPR IEEE, P259; WEINBEGER K, 2009, J MACHINE LEARNING R; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]	41	32	32	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					794	806		10.1109/TPAMI.2010.127	http://dx.doi.org/10.1109/TPAMI.2010.127			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	20603519				2022-12-18	WOS:000287370400011
J	Dowson, N; Salvado, O				Dowson, Nicholas; Salvado, Olivier			Hashed Nonlocal Means for Rapid Image Filtering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonlocal means; image filtering	DENSITY-FUNCTION; INFORMATION; SPACE; SHIFT; NOISE	Denoising algorithms can alleviate the trade-off between noise-level and acquisition time that still exists for certain image types. Nonlocal means, a recently proposed technique, outperforms other methods in removing noise while retaining image structure, albeit at prohibitive computational cost. Modifications have been proposed to reduce the cost, but the method is still too slow for practical filtering of 3D images. This paper proposes a hashed approach to explicitly represent two summed frequency ( hash) functions of local descriptors (patches), utilizing all available image data. Unlike other approaches, the hash spaces are discretized on a regular grid, so primarily linear operations are used. The large memory requirements are overcome by recursing the hash spaces. Additional speed gains are obtained by using a marginal linear interpolation method. Careful choice of the patch features results in high computational efficiency, at similar accuracies. The proposed approach can filter a 3D image in less than a minute versus 15 minutes to 3 hours for existing nonlocal means methods.	[Dowson, Nicholas; Salvado, Olivier] Royal Brisbane & Womens Hosp, Australian E Hlth Res Ctr, Herston, Qld 4029, Australia	Commonwealth Scientific & Industrial Research Organisation (CSIRO); Royal Brisbane & Women's Hospital	Dowson, N (corresponding author), Royal Brisbane & Womens Hosp, Australian E Hlth Res Ctr, Level 5,UQ Hlth Sci Bldg, Herston, Qld 4029, Australia.	nicholas.dowson@csiro.au; olivier.salvado@csiro.au	Salvado, Olivier/C-8910-2009; Dowson, Nicholas D H/B-7621-2017; Dowson, Nicholas/A-7537-2011	Salvado, Olivier/0000-0002-2720-8739; Dowson, Nicholas D H/0000-0003-4694-5459; Dowson, Nicholas/0000-0003-4694-5459				Awate SP, 2006, IEEE T PATTERN ANAL, V28, P364, DOI 10.1109/TPAMI.2006.64; Awate SP, 2005, PROC CVPR IEEE, P44; Awate SP, 2007, IEEE T MED IMAGING, V26, P1242, DOI 10.1109/TMI.2007.900319; AZZABOU N, 2006, P 9 EUR C COMP VIS M, V1, P379; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Chu CK, 1998, J AM STAT ASSOC, V93, P526, DOI 10.2307/2670100; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Coupe P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Haacke E. M., 1999, MAGNETIC RESONANCE I; HEINEMAN G, 2008, ALGORITHMS NUTSHELL, P292; HENKELMAN RM, 1985, MED PHYS, V12, P232, DOI 10.1118/1.595711; Huang HC, 1997, GRAPH MODEL IM PROC, V59, P388, DOI 10.1006/gmip.1997.0449; Jones DK, 2004, MAGN RESON MED, V52, P979, DOI 10.1002/mrm.20283; Kervrann C, 2008, INT J COMPUT VISION, V79, P45, DOI 10.1007/s11263-007-0096-2; Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509; Manjon JV, 2008, MED IMAGE ANAL, V12, P514, DOI 10.1016/j.media.2008.02.004; MODDEMEIJER R, 1989, SIGNAL PROCESS, V16, P233, DOI 10.1016/0165-1684(89)90132-1; Mrazek P, 2006, COMP IMAG VIS, P335; MURESAN DD, 2003, P IEEE INT C IM PROC, V1, P101; Narasimhan SG, 2005, IEEE T PATTERN ANAL, V27, P518, DOI 10.1109/TPAMI.2005.76; Nyquist H, 1932, BELL SYST TECH J, V11, P126, DOI 10.1002/j.1538-7305.1932.tb02344.x; PARIS S, 2006, P EUR C COMP VIS MAY, V4, P24; Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; WIESTDAESSLE N, 2008, P INT C MED IM COMP, V2, P171	38	32	35	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					485	499		10.1109/TPAMI.2010.114	http://dx.doi.org/10.1109/TPAMI.2010.114			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	20530811				2022-12-18	WOS:000286204700005
J	Werner, T				Werner, Tomas			Revisiting the Linear Programming Relaxation Approach to Gibbs Energy Minimization and Weighted Constraint Satisfaction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weighted constraint satisfaction; Gibbs distribution; graphical model; Markov random field; linear programming relaxation; marginal polytope; cut polytope; cutting-plane algorithm; global constraint; supermodularity; tree-reweighted max-product		We present a number of contributions to the LP relaxation approach to weighted constraint satisfaction (= Gibbs energy minimization). We link this approach to many works from constraint programming, which relation has so far been ignored in machine vision and learning. While the approach has been mostly considered only for binary constraints, we generalize it to n-ary constraints in a simple and natural way. This includes a simple algorithm to minimize the LP-based upper bound, n-ary max-sum diffusion-however, we consider using other bound-optimizing algorithms as well. The diffusion iteration is tractable for a certain class of high-arity constraints represented as a black box, which is analogical to propagators for global constraints CSP. Diffusion exactly solves permuted n-ary supermodular problems. A hierarchy of gradually tighter LP relaxations is obtained simply by adding various zero constraints and coupling them in various ways to existing constraints. Zero constraints can be added incrementally, which leads to a cutting-plane algorithm. The separation problem is formulated as finding an unsatisfiable subproblem of a CSP.	Czech Tech Univ, Dept Cybernet, Prague 12135, Czech Republic	Czech Technical University Prague	Werner, T (corresponding author), Czech Tech Univ, Dept Cybernet, Karlovo Namesti 13, Prague 12135, Czech Republic.	werner@cmp.felk.cvut.cz	Werner, Tomas/N-4615-2014	Werner, Tomas/0000-0002-6161-7157	European Commission [215078]; Czech government [MSM6840770038]	European Commission(European CommissionEuropean Commission Joint Research Centre); Czech government	This research was supported by the European Commission grant 215078 and the Czech government grant MSM6840770038. The author thanks Mikhail I. Schlesinger for open discussions on his unpublished work. Martin Cooper and Thomas Schiex provided useful remarks on WCSP.	BARAHONA F, 1986, MATH PROGRAM, V36, P157, DOI 10.1007/BF02592023; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; Bessiere C, 2003, LECT NOTES COMPUT SC, V2833, P789; BESSIERE C, 2006, HDB CONSTRAINT PROGR, pCH3; Bliek C, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P456; Cohen David, 2006, HDB CONSTRAINT PROGR; Cohen DA, 2006, ARTIF INTELL, V170, P983, DOI 10.1016/j.artint.2006.04.002; Cooper M., 2008, AAAI08 P 23 NAT C AR, P253; Debruyne R, 2001, J ARTIF INTELL RES, V14, P205, DOI 10.1613/jair.834; Deza M., 1997, GEOMETRY CUTS METRIC; FREUDER EC, 1982, J ACM, V29, P24, DOI 10.1145/322290.322292; GLOBERSON A, 2006, P NEUR INF PROC SYST, P473; Globerson Amir, 2008, ADV NEURAL INFORM PR, P553; Gregoire E, 2007, LECT NOTES COMPUT SC, V4741, P317; Gupta R., 2007, P 24 INT C MACH LEAR, P329; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; HEMERY F, 2006, P 17 EUR C ART INT E, P113; Johnson J., 2007, P ALL C COMM CONTR C; KOLMOGOROV V, 2006, P EUR C COMP VIS, V2, P1; KOLMOGOROV V, 2005, P C UNC ART INT; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Komodakis N., 2007, P INT C COMP VIS; Komodakis Nikos, 2008, P EUR C COMP VIS; Koster AMCA, 1998, OPER RES LETT, V23, P89, DOI 10.1016/S0167-6377(98)00043-1; KOVAL VK, 1976, USSR ACAD SCI AUTOMA, V8, P149; Kovalevsky V. A., 1975, DIFFUSION ALGORITHM; KUMAR MP, 2008, P INT C MACH LEARN, P680; Lauritzen S.L., 1996, OXFORD STAT SCI SERI, V17, P298; MACKWORTH A, 1991, ENCY ARTIFICIAL INTE, P285; Meseguer P., 2006, HDB CONSTRAINT PROGR; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; Pearson J. K., 1997, CSDTR9715 U LOND ROY; RAVIKUMAR P, 2008, P INT C MACH LEARN, P800; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Rossi F, 2006, FOUND ARTIF INTELL, P1; Rother C., 2006, P IEEE C COMP VIS PA; Schlesinger D, 2007, LECT NOTES COMPUT SC, V4679, P28; SCHLESINGER MI, 1976, CYBERNET SYST, V12, P612; SCHLESINGER MI, 2000, COMMUNICATION; SCHLESINGER MI, 2000, P CZECH PATT REC WOR; SCHLESINGER MI, 1976, FALSE MINIMA ALGORIT; SCHLESINGER MI, 2007, UPRAVLYAYUSHCHIE SIS, V1; SCHRAUDOLPH NN, 2008, P NEUR INF PROC SYST, P1417; SONTAG D, 2008, P C UNC ART INT; Szeliski R, 2006, LECT NOTES COMPUT SC, V3952, P16; Topkis D.M., 1998, SUPERMODULARITY COMP; VANHOEVE WJ, 2006, HDB CONSTRAINT PROGR, pCH7; Wainwright M. J., 2008, FDN TRENDS MACHINE L, V1, P1; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Wainwright MJ, 2003, 649 U CAL DEP STAT; WEISS Y, 2007, P C UNC ART INT; WERNER T, 2008, P IEEE COMP VIS PATT; Werner T., 2005, CTUCMP200525; Werner Toma, 2008, INT WORKSH PREF SOFT, P43; Werner Toma, 2007, 12 COMP VIS WINT WOR, P27; Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036; [No title captured]	57	32	34	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1474	1488		10.1109/TPAMI.2009.134	http://dx.doi.org/10.1109/TPAMI.2009.134			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20558878	Green Submitted			2022-12-18	WOS:000278858600009
J	Han, B; Zhu, Y; Comaniciu, D; Davis, LS				Han, Bohyung; Zhu, Ying; Comaniciu, Dorin; Davis, Larry S.			Visual Tracking by Continuous Density Propagation in Sequential Bayesian Filtering Framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian filtering; density interpolation; density approximation; mean shift; density propagation; visual tracking; particle filter		Particle filtering is frequently used for visual tracking problems since it provides a general framework for estimating and propagating probability density functions for nonlinear and non-Gaussian dynamic systems. However, this algorithm is based on a Monte Carlo approach and the cost of sampling and measurement is a problematic issue, especially for high-dimensional problems. We describe an alternative to the classical particle filter in which the underlying density function has an analytic representation for better approximation and effective propagation. The techniques of density interpolation and density approximation are introduced to represent the likelihood and the posterior densities with Gaussian mixtures, where all relevant parameters are automatically determined. The proposed analytic approach is shown to perform more efficiently in sampling in high-dimensional space. We apply the algorithm to real-time tracking problems and demonstrate its performance on real video sequences as well as synthetic examples.	[Han, Bohyung] Mobileye Vis Technol, Adv Project Ctr, Princeton, NJ 08542 USA; [Zhu, Ying] Siemens Corp Res, Real Time Vis Modeling Dept, Princeton, NJ 08540 USA; [Comaniciu, Dorin] Siemens Corp Res, Integrated Syst Dept, Princeton, NJ 08540 USA; [Davis, Larry S.] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	Siemens AG; Siemens AG; University System of Maryland; University of Maryland College Park	Han, B (corresponding author), Mobileye Vis Technol, Adv Project Ctr, 12 Venderventer Ave, Princeton, NJ 08542 USA.	bhhan@cs.umd.edu; yingzhu@siemens.com; dorin.comaniciu@siemens.com; lsd@cs.umd.edu		Comaniciu, Dorin/0000-0002-5238-8647				ABRAMSON IS, 1982, ANN STAT, V10, P1217, DOI 10.1214/aos/1176345986; ADLERS M, 2000, THESIS LINKOPINGS U; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Cantarella J., 2004, TSNNLS SOLVER LARGE; CHAM T, 1999, P IEEE C COMP VIS PA, V2, P219; CHENG C, 2005, P IEEE C COMP VIS PA; Cleveland W.S., 1996, P STAT THEORY COMPUT, P10; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D, 2003, PROC CVPR IEEE, P59; Comaniciu D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P438, DOI 10.1109/ICCV.2001.937550; Deutscher J., 2000, P IEEE C COMP VIS PA; Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038; Doucet A., 2001, SEQUENTIAL MONTE CAR; DOUCET VA, 2003, P 9 INT C COMP VIS, V1; HAN B, 2005, P IEEE INT C COMP VI; Han B., 2004, P IEEE C COMP VIS PA; Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771; Isard M., 1998, INT J COMPUTER VISIO, V29; Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Kotecha JH, 2003, IEEE T SIGNAL PROCES, V51, P2602, DOI 10.1109/TSP.2003.816754; LAUWON CL, 1974, SOLVING LEAST SQUARE; MACCORMICK J, 2000, P EUR C COMP VIS, P3; Merwe R., 2000, CUEDFINFENGTR380; PARK BU, 1990, J AM STAT ASSOC, V85, P66, DOI 10.2307/2289526; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; PHILOMIN V, 2000, P EUR C COMP VIS, V2, P134; Poggio T., 1989, THEORY NETWORKS APPR; Rui Y, 2001, PROC CVPR IEEE, P786; SHEATHER SJ, 1991, J ROY STAT SOC B MET, V53, P683; Sminchisescu C, 2002, LECT NOTES COMPUT SC, V2350, P769; Sminchisescu C, 2001, PROC CVPR IEEE, P447; Sullivan J, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P323, DOI 10.1109/ICCV.2001.937536; TORMA P, 2004, P EUR C COMP VIS, P16; WAN EA, 2000, P S 2001 AD SYST SIG	36	32	36	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					919	930		10.1109/TPAMI.2008.134	http://dx.doi.org/10.1109/TPAMI.2008.134			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19299864				2022-12-18	WOS:000264144500011
J	Goshen, L; Shimshoni, I				Goshen, Liran; Shimshoni, Ilan			Balanced Exploration and Exploitation Model search for efficient epipolar geometry estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fundamental matrix; robust estimation	MOTION	The estimation of the epipolar geometry is especially difficult when the putative correspondences include a low percentage of inlier correspondences and/or a large subset of the inliers is consistent with a degenerate configuration of the epipolar geometry that is totally incorrect. This work presents the Balanced Exploration and Exploitation Model (BEEM) search algorithm, which works very well especially for these difficult scenes. The algorithm handles these two problems in a unified manner. It includes the following main features: 1) balanced use of three search techniques: global random exploration, local exploration near the current best solution, and local exploitation to improve the quality of the model, 2) exploitation of available prior information to accelerate the search process, 3) use of the best found model to guide the search process, escape from degenerate models, and define an efficient stopping criterion, 4) presentation of a simple and efficient method to estimate the epipolar geometry from two scale-invariant feature transform (SIFT) correspondences, and 5) use of the locality-sensitive hashing (LSH) approximate nearest neighbor algorithm for fast putative correspondence generation. The resulting algorithm when tested on real images with or without degenerate configurations gives quality estimations and achieves significant speedups compared to the state-of-the-art algorithms.	[Goshen, Liran] Technion Israel Inst Technol, Fac Ind Engn & Management, IL-32000 Haifa, Israel; [Shimshoni, Ilan] Univ Haifa, Dept Management Informat Syst, IL-31905 Haifa, Israel	Technion Israel Institute of Technology; University of Haifa	Goshen, L (corresponding author), Technion Israel Inst Technol, Fac Ind Engn & Management, IL-32000 Haifa, Israel.	lirang@tx.tecnion.ac.il; ishimshoni@mis.haifa.ac.il						Chen HF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P878, DOI 10.1109/ICCV.2003.1238441; Chum O, 2005, PROC CVPR IEEE, P772; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Chum O., 2004, P ACCV, V2, P812; DOMKE J, 2005, P WORKSH DYN VIS; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Goshen L, 2005, PROC CVPR IEEE, P1105; GOSHEN L, 2006, P 9 EUR C COMP VIS; Grabner M, 2006, LECT NOTES COMPUT SC, V3851, P918; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; IRANI M, 1996, P EUR C COMP VIS, P17; Kadir T., 2004, P 8 EUR C COMP VIS P, P345; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Makadia A, 2005, PROC CVPR IEEE, P796; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; MIKOLAJCZYK K, 2002, P EUR C COMP VIS, P128; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Perd'och M, 2006, INT C PATT RECOG, P215; Rozenfeld S, 2005, PROC CVPR IEEE, P1113; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; SINHA S, 2006, P WORKSH EDG COMP US; TORDOFF B, 2002, P 7 ECCV, V1, P82; Torr P.H.S., 1995, THESIS U OXFORD; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194	30	32	33	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1230	1242		10.1109/TPAMI.2007.70768	http://dx.doi.org/10.1109/TPAMI.2007.70768			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550905				2022-12-18	WOS:000256294100009
J	Chien, JT; Liao, CP				Chien, Jen-Tzung; Liao, Chih-Pin			Maximum confidence hidden Markov Modeling for face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						parameter learning; statistical; classifier design and evaluation; face and gesture recognition; hidden Markov model; confidence measure; discriminative feature extraction; discriminative training; pattern classification; face recognition	HMM	This paper presents a hybrid framework of feature extraction and hidden Markov modeling (HMM) for two-dimensional pattern recognition. Importantly, we explore a new discriminative training criterion to assure model compactness and discriminability. This criterion is derived from the hypothesis test theory via maximizing the confidence of accepting the hypothesis that observations are from target HMM states rather than competing HMM states. Accordingly, we develop the maximum confidence hidden Markov modeling (MC-HMM) for face recognition. Under this framework, we merge a transformation matrix to extract discriminative facial features. The closed-form solutions to continuous-density HMM parameters are formulated. Attractively, the hybrid MC-HMM parameters are estimated under the same criterion and converged through the expectation-maximization procedure. From the experiments on the FERET database and GTFD, we find that the proposed method obtains robust segmentation in the presence of different facial expressions, orientations, and so forth. In comparison with the maximum likelihood and minimum classification error HMMs, the proposed MC-HMM achieves higher recognition accuracies with lower feature dimensions.	[Chien, Jen-Tzung; Liao, Chih-Pin] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan	National Cheng Kung University	Chien, JT (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.	jtchien@mail.ncku.edu.tw; cpliao@chien.csie.ncku.edu.tw		Chien, Jen-Tzung/0000-0003-3466-8941				BAHL L, 1986, P INT C AC SPEECH SI, V1, P49, DOI DOI 10.1109/ICASSP.1986.1169179>; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Ben-Yishai A, 2004, IEEE T SPEECH AUDI P, V12, P204, DOI 10.1109/TSA.2003.822639; BICEGO M, 2000, P IEEE INT C AUT FAC, P257; Chen L, 2005, PATTERN RECOGN, V38, P799, DOI 10.1016/j.patcog.2004.11.003; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Chien JT, 2000, SPEECH COMMUN, V30, P235, DOI 10.1016/S0167-6393(99)00052-7; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 1973, J ROYAL STAT SOC SER; Fisher RA, 1938, ANN EUGENIC, V8, P376, DOI 10.1111/j.1469-1809.1938.tb02189.x; FUKUNAGA F, 1990, INTRO STAT PATTERN R; HUNG J, 2002, P IEEE INT C AC SPEE, V1, P373; HUO Q, 2001, P ICASSP 01 SALT LAK, V3, P1517; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Katagiri S, 1998, P IEEE, V86, P2345, DOI 10.1109/5.726793; Kim MS, 2003, PATTERN RECOGN, V36, P2723, DOI 10.1016/S0031-3203(03)00137-7; Kohir VV, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P226; Kumar N, 1998, SPEECH COMMUN, V26, P283, DOI 10.1016/S0167-6393(98)00061-2; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482; LEVIN E, 1992, P ICASSP, V3, P149; LIAO CP, 2006, P IEEE INT C AC SPEE, V5, P549; LIU C, 2005, P IEEE INT C AC SPEE, V1, P101; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Miller DRH, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P214, DOI 10.1145/312624.312680; Nefian AV, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA133; Nefian AV, 2000, IEEE IMAGE PROC, P33, DOI 10.1109/ICIP.2000.900885; NEFIAN AV, 2009, P IEEE INT C AC SPEE, V6, P3553; Othman H, 2003, IEEE T PATTERN ANAL, V25, P1229, DOI 10.1109/TPAMI.2003.1233897; Park HS, 1998, PATTERN RECOGN, V31, P1849, DOI 10.1016/S0031-3203(98)00057-0; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SAMARIA F, 1994, IMAGE VISION COMPUT, V12, P537, DOI 10.1016/0262-8856(94)90007-8; Sukkar RA, 1996, IEEE T SPEECH AUDI P, V4, P420, DOI 10.1109/89.544527; THOMAE M, 2000, P IEEE INT C AC SPEE, V3, P1615	35	32	36	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					606	616		10.1109/TPAMI.2007.70715	http://dx.doi.org/10.1109/TPAMI.2007.70715			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276967				2022-12-18	WOS:000253135600005
J	Brown, MS; Sun, MX; Yang, RG; Yun, L; Seales, WB				Brown, Michael S.; Sun, Mingxuan; Yang, Ruigang; Yun, Lin; Seales, W. Brent			Restoring 2D content from distorted documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document restoration; geometric correction; shading correction; photometric correction; conformal mapping; document processing	LIGHTNESS; IMAGES	This paper presents a framework to restore the 2D content printed on documents in the presence of geometric distortion and nonuniform illumination. Compared with text-based document imaging approaches that correct distortion to a level necessary to obtain sufficiently readable text or to facilitate optical character recognition ( OCR), our work targets nontextual documents where the original printed content is desired. To achieve this goal, our framework acquires a 3D scan of the document's surface together with a high-resolution image. Conformal mapping is used to rectify geometric distortion by mapping the 3D surface back to a plane while minimizing angular distortion. This conformal "deskewing" assumes no parametric model of the document's surface and is suitable for arbitrary distortions. Illumination correction is performed by using the 3D shape to distinguish content gradient edges from illumination gradient edges in the high-resolution image. Integration is performed using only the content edges to obtain a reflectance image with significantly less illumination artifacts. This approach makes no assumptions about light sources and their positions. The results from the geometric and photometric correction are combined to produce the final output.	Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; Georgia Inst Technol, GVU Ctr, Atlanta, GA 30332 USA; Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA; Univ Kentucky, Lab Adv Networking, Lexington, KY 40506 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University System of Georgia; Georgia Institute of Technology; University of Kentucky; University of Kentucky	Brown, MS (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Blk N4,2A-32,Nanyang Ave, Singapore 639798, Singapore.	msbrown@ntu.edu.sg; cynthia@cc.gatech.edu; ryang@cs.uky.edu; ylin@netlab.uky.edu; seales@netlab.uky.edu		Yang, Ruigang/0000-0001-5296-6307				AGAM G, 2002, LECT NOTES COMPUTER, P2390; AGRAWAL A, 2006, P EUR C COMP VIS; BARROW HG, 1978, RECOVERING INTRINSIC; Bell M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P670, DOI 10.1109/ICCV.2001.937585; BLAKE A, 1985, COMPUT VISION GRAPH, V32, P314, DOI 10.1016/0734-189X(85)90054-4; BROWN M, 2005, COMPUTER VISION PATT; Brown MS, 2006, IEEE T IMAGE PROCESS, V15, P1544, DOI 10.1109/TIP.2006.871082; Brown MS, 2004, IEEE T PATTERN ANAL, V26, P1295, DOI 10.1109/TPAMI.2004.87; BROWN MS, 2001, P INT C COMP VIS JUL; CAO H, 2003, P INT C DOC AN REC; Cao HG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P228, DOI 10.1109/ICCV.2003.1238346; CHUA KB, 2005, P INTL C DOC AN REC; Clarenz U, 2004, COMPUT AIDED GEOM D, V21, P727, DOI 10.1016/j.cagd.2004.07.005; COURANT R, 1977, DIRICHELTS PRINCIPLE, P95; Desbrun M, 2002, COMPUT GRAPH FORUM, V21, P209, DOI 10.1111/1467-8659.00580; DUNHAM JG, 2005, I C COMP SYST APPLIC, pNI533; Finlayson G., 2002, P 7 EUR C COMP VIS 4, P823; Floater MS, 2001, COMPUT AIDED GEOM D, V18, P77, DOI 10.1016/S0167-8396(01)00013-9; FOURNIER A, 1993, P GRAPHICS INTERFACE; FUNT BV, 1992, P EUR C COMP VIS, P123; GUMEROV N, 2004, P EUR C COMP VIS; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; Johnson GM, 1999, IEEE COMPUT GRAPH, V19, P47, DOI 10.1109/38.773963; Kanungo T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P730, DOI 10.1109/ICDAR.1993.395633; KANUNGO T, 1996, THESIS U WASHINGTON; Krantz S.G.., 1999, APPL CAUCHY THEORY, P32; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Levy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590; Liang J., 2005, International Journal on Document Analysis and Recognition, V7, P84, DOI 10.1007/s10032-004-0138-z; Liang J, 2005, PROC CVPR IEEE, P338; Marschner SR, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P262; Oh BM, 2001, COMP GRAPH, P433; Paul D., 1998, P SIGGRAPH 98, P189, DOI [10.1145/280814.280864, DOI 10.1145/280814.280864]; PILU M, 2001, P COMPUTER VISION PA; Tan CL, 2006, IEEE T PATTERN ANAL, V28, P195, DOI 10.1109/TPAMI.2006.40; Tappen M. F., 2003, ADV NEURAL INFORM PR; Tsai R.Y., 1986, P IEEE C COMP VIS PA, P364; TSOI YC, 2004, P COMPUTER VISION PA; Ulges A., 2005, P INT C DOC AN REC; Ulges A., 2004, P ACM S DOC ENG, P198; WADA T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P66, DOI 10.1109/ICCV.1995.466805; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; ZHANG L, 2004, P COMPUTER VISION PA; ZHANG L, 2005, P COMPUTER VISION PA; ZHANG L, 2003, P INT C DOC AN REC	45	32	35	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					1904	1916		10.1109/TPAMI.2007.1118	http://dx.doi.org/10.1109/TPAMI.2007.1118			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848773				2022-12-18	WOS:000249343900003
J	Unal, G; Yezzi, A; Soatto, S; Slabaugh, G				Unal, Gozde; Yezzi, Anthony; Soatto, Stefano; Slabaugh, Greg			A variational approach to problems in calibration of multiple cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						calibration; variational methods; color calibration; lens distortion calibration; camera parameters refinement	SELF-CALIBRATION; DISTORTION; SCENES	This paper addresses the problem of calibrating camera parameters using variational methods. One problem addressed is the severe lens distortion in low-cost cameras. For many computer vision algorithms aiming at reconstructing reliable representations of 3D scenes, the camera distortion effects will lead to inaccurate 3D reconstructions and geometrical measurements if not accounted for. A second problem is the color calibration problem caused by variations in camera responses that result in different color measurements and affects the algorithms that depend on these measurements. We also address the extrinsic camera calibration that estimates relative poses and orientations of multiple cameras in the system and the intrinsic camera calibration that estimates focal lengths and the skew parameters of the cameras. To address these calibration problems, we present multiview stereo techniques based on variational methods that utilize partial and ordinary differential equations. Our approach can also be considered as a coordinated refinement of camera calibration parameters. To reduce computational complexity of such algorithms, we utilize prior knowledge on the calibration object, making a piecewise smooth surface assumption, and evolve the pose, orientation, and scale parameters of such a 3D model object without requiring a 2D feature extraction from camera views. We derive the evolution equations for the distortion coefficients, the color calibration parameters, the extrinsic and intrinsic parameters of the cameras, and present experimental results.	Siemens Corp Res, Princeton, NJ 08540 USA; Georgia Inst Technol, Sch Elect Engn, Atlanta, GA 30332 USA; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	Siemens AG; University System of Georgia; Georgia Institute of Technology; University of California System; University of California Los Angeles	Unal, G (corresponding author), Siemens Corp Res, 755 Coll Rd E, Princeton, NJ 08540 USA.	gozde.unal@siemens.com; ayezzi@ece.gatech.edu; soatto@ucla.edu; greg.slabaugh@siemens.com	Yezzi, Anthony/AAB-4235-2020; Unal, Gozde/A-2360-2013	Unal, Gozde/0000-0001-5942-8966; Slabaugh, Greg/0000-0003-4060-5226				ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; [Anonymous], [No title captured]; BAKER HH, 2002, HPL2002351; BROWN DC, 1966, PHOTOGRAMMETRIC ENG, V32; Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269; Du F., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P477, DOI 10.1109/CVPR.1993.341087; El-Melegy MT, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P554; FAUGERAS O, 1996, VARIATIONAL PRINCIPL; FAUGERAS OD, 1992, P EUR C COMP VIS, P321; Gurdjos P, 2003, PROC CVPR IEEE, P491; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468; Kang S., 1997, 973 CRL; MARSZALEC E, 1994, INT C PATT RECOG, P232, DOI 10.1109/ICPR.1994.576263; Murray R. M., 1994, MATH INTRO ROBOTIC M; Oliensis J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P745, DOI 10.1109/ICCV.1999.790296; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Sawhney HS, 1997, PROC CVPR IEEE, P450, DOI 10.1109/CVPR.1997.609364; Seo Y, 2001, PROC CVPR IEEE, P880; SOBEL I, 1974, ARTIF INTELL, V5, P185, DOI 10.1016/0004-3702(74)90029-0; Sokolowski J., 1992, INTRO SHAPE OPTIMIZA, DOI DOI 10.1007/978-3-642-58106-9; Stein GP, 1997, PROC CVPR IEEE, P602, DOI 10.1109/CVPR.1997.609387; SVOBODA T, 2005, PRESENCE TELEOPERATO, V14; SWAMINATHAN R, 1999, P IEEE C COMP VIS PA, P2413; Triggs B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P278, DOI 10.1109/ICCV.1999.791231; TSAI RY, 1987, J ROBOTICS AUTOMATIO, V3, P323; Unal G, 2004, PROC CVPR IEEE, P172; UNAL G, 2004, HPLTR2004219; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P965, DOI 10.1109/34.159901; Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234; Yezzi AJ, 2003, PROC CVPR IEEE, P525; Zhang Z., 1998, MSRTR9871	33	32	36	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1322	1338		10.1109/TPAMI.2007.1035	http://dx.doi.org/10.1109/TPAMI.2007.1035			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568138	Green Accepted, Green Submitted			2022-12-18	WOS:000247186500003
J	Zimmermann, M; Chappelier, JC; Bunke, H				Zimmermann, M; Chappelier, JC; Bunke, H			Offline grammar-based recognition of handwritten sentences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical character recognition; handwriting analysis; natural language parsing and understanding	LANGUAGE MODEL	This paper proposes a sequential coupling of a Hidden Markov Model (HMM) recognizer for offline handwritten English sentences with a probabilistic bottom-up chart parser using Stochastic Context-Free Grammars (SCFG) extracted from a text corpus. Based on extensive experiments, we conclude that syntax analysis helps to improve recognition rates significantly.	Int Comp Sci Inst, Berkeley, CA 94704 USA; Ecole Polytech Fed Lausanne, IC IIF LIA, Swiss Fed Inst Technol, Stn 14, CH-1015 Lausanne, Switzerland; Univ Bern, Inst Comp Sci & Appl Math IAM, CH-3012 Bern, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; University of Bern	Zimmermann, M (corresponding author), Int Comp Sci Inst, 1947 Ctr St,Suite 600, Berkeley, CA 94704 USA.	zimmerma@icsi.berkeley.edu; jean-cedric.chappelier@epfl.edu; bunke@iam.unibe.ch						CHAPPELIER JC, 1998, ACT TAPD, P133; CHAPPELIER JC, 1999, P 6 C TRAIT AUT LANG, P95; Chelba C, 2000, COMPUT SPEECH LANG, V14, P283, DOI 10.1006/csla.2000.0147; CROWNER C, 1991, P 1 INT C DOC AN REC, V1, P323; ERBACH G, 1994, P 14 INT C COMP LING; Garcia-Hernandez J, 2003, LECT NOTES COMPUT SC, V2652, P271; GARSIDE R, 1995, MANUAL INFORM LANCAS; Gorski N., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P523, DOI 10.1109/ICDAR.1999.791840; Graham S. L., 1980, ACM Transactions on Programming Languages and Systems, V2, P415, DOI 10.1145/357103.357112; Hong T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P222, DOI 10.1109/ICDAR.1993.395744; Hull JJ, 1996, IEEE T PATTERN ANAL, V18, P1251, DOI 10.1109/34.546261; Johansson S., 1986, TAGGED LOB CORPUS US; Johansson S., 1978, MANUAL INFORM ACCOMP; JURAFSKY D, 1995, INT CONF ACOUST SPEE, P189, DOI 10.1109/ICASSP.1995.479396; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; KEENAN FG, 1991, P 1 INT C DOC AN REC, P794; KITA K, 1991, INT CONF ACOUST SPEE, P269, DOI 10.1109/ICASSP.1991.150329; KITA K, 1989, P ICASSP 89, P703; Koerich AL, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P99, DOI 10.1109/IWFHR.2002.1030893; Mahadevan U., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P325, DOI 10.1109/ICDAR.1999.791790; Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071; Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848; Ogawa A, 1998, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1998.674397; Rabiner L., 1993, FUNDAMENTALS SPEECH; Roark B, 2001, COMPUT LINGUIST, V27, P249, DOI 10.1162/089120101750300526; Simard PY, 2003, PROC INT CONF DOC, P958; SRIHARI RK, 1993, P INT WORKSH FRONT H, P284; Uchida S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P499, DOI 10.1109/ICDAR.1999.791834; Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; VOISIN F, 1990, JOURN AFCET GROPLAN; Zimmermann M, 2004, INT C PATT RECOG, P541, DOI 10.1109/ICPR.2004.1334297; Zimmermann M, 2003, PROC INT CONF DOC, P572; Zimmermann M, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P369, DOI 10.1109/IWFHR.2002.1030938; Zimmermann M, 2002, INT C PATT RECOG, P35, DOI 10.1109/ICPR.2002.1047394	36	32	32	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					818	821		10.1109/TPAMI.2006.103	http://dx.doi.org/10.1109/TPAMI.2006.103			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640266	Green Published			2022-12-18	WOS:000235885700012
J	Narasimhamurthy, A				Narasimhamurthy, A			Theoretical bounds of majority voting performance for a binary classification problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classifier design and evaluation; majority voting; theoretical bounds; classifier diversity measures	RECOGNITION; CLASSIFIERS; ACCURACY; FUSION	A number of earlier studies that have attempted a theoretical analysis of majority voting assume independence of the classifiers. We formulate the majority voting problem as an optimization problem with linear constraints. No assumptions on the independence of classifiers are made. For a binary classification problem, given the accuracies of the classifiers in the team, the theoretical upper and lower bounds for performance obtained by combining them through majority voting are shown to be solutions of the corresponding optimization problem. The objective function of the optimization problem is nonlinear in the case of an even number of classifiers when rejection is allowed, for the other cases the objective function is linear and hence the problem is a linear program (LP). Using the framework we provide some insights and investigate the relationship between two candidate classifier diversity measures and majority voting performance.	Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Narasimhamurthy, A (corresponding author), Penn State Univ, Dept Comp Sci & Engn, 341 IST Bldg, University Pk, PA 16802 USA.	narasimh@cse.psu.edu						Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; BOLAND PJ, 1989, STATISTICIAN, V38, P181, DOI 10.2307/2348873; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; CHANDROTH G, 1999, THESIS U SHEFFIELD; Cunningham P., 2000, TCDCS200002; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva LI, 2003, PATTERN ANAL APPL, V6, P22, DOI 10.1007/s10044-002-0173-7; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; NARASIMHAMURTHY A, 2003, P SCAND C IM AN; Shipp C. A., 2002, Information Fusion, V3, P135, DOI 10.1016/S1566-2535(02)00051-9; Tumer K., 1996, Connection Science, V8, P385, DOI 10.1080/095400996116839; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yule GU, 1900, PHILOS T R SOC LOND, V194, P257, DOI 10.1098/rsta.1900.0019	17	32	32	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1988	1995		10.1109/TPAMI.2005.249	http://dx.doi.org/10.1109/TPAMI.2005.249			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16355665				2022-12-18	WOS:000232532600013
J	Ramamoorthi, R; Koudelka, M; Belhumeur, P				Ramamoorthi, R; Koudelka, M; Belhumeur, P			A Fourier theory for cast shadows	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						cast shadows; convolution; Fourier analysis; eigenmodes; V-grooves	REFLECTION; RADIANCE; TEXTURE; IMAGES	Cast shadows can be significant in many computer vision applications, such as lighting-insensitive recognition and surface reconstruction. Nevertheless, most algorithms neglect them, primarily because they involve nonlocal interactions in nonconvex regions, making formal analysis difficult. However, many real instances map closely to canonical configurations like a wall, a V-groove type structure, or a pitted surface. In particular, we experiment with 3D textures like moss, gravel, and a kitchen sponge, whose surfaces include canonical configurations like V-grooves. This paper takes a first step toward a formal analysis of cast shadows, showing theoretically that many configurations can be mathematically analyzed using convolutions and Fourier basis functions. Our analysis exposes the mathematical convolution structure of cast shadows and shows strong connections to recent signal-processing frameworks for reflection and illumination.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; Yale Univ, E Haven, CT 06512 USA	Columbia University; Yale University	Ramamoorthi, R (corresponding author), Columbia Univ, Dept Comp Sci, 450 Comp Sci Bldg,500 W 120 St, New York, NY 10027 USA.	ravir@cs.columbia.edu; melissa.koudelka@yale.edu						Basri R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICCV.2001.937651; Dana KJ, 1998, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.1998.698669; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Epstein J. L., 1995, FAMILY SCH CONNECTIO, P108; GAUTRON P, 2004, P EUR S REND EGSR 04; HALLINAN PW, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P995, DOI 10.1109/CVPR.1994.323941; Koenderink JJ, 1998, J OPT SOC AM A, V15, P2903, DOI 10.1364/JOSAA.15.002903; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P129, DOI 10.1023/A:1008061730969; Makhotkin OA, 1996, J QUANT SPECTROSC RA, V56, P869, DOI 10.1016/S0022-4073(96)00040-4; Mallat S., 1999, WAVELET TOUR SIGNAL, DOI 10.1016/B978-012466606-1/50008-8; Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320; Oren M., 1994, P 21 ANN C COMP GRAP, P239, DOI [10.1145/192161.192213, DOI 10.1145/192161.192213]; Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204; RAMAMOORTHI R, 2001, SPIE PHOTONICS W HUM, V6, P185; RAMAMOORTHI R, 2004, P EUR C COMP VIS ECC, P1146; Sato I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P875, DOI 10.1109/ICCV.1999.790314; Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612; SOLER C, 1998, P SIGGRAPH 98, P321; Suen PH, 1998, PROC CVPR IEEE, P753, DOI 10.1109/CVPR.1998.698688; THORNBER K, 2001, 2001100 NEC TR; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; WESTIN SH, 1992, COMP GRAPH, V26, P255, DOI 10.1145/142920.134075	24	32	32	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2005	27	2					288	295		10.1109/TPAMI.2005.22	http://dx.doi.org/10.1109/TPAMI.2005.22			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	879AR	15688567				2022-12-18	WOS:000225689300013
J	Yang, RG; Zhang, ZY				Yang, RG; Zhang, ZY			Eye gaze correction with stereovision for video-teleconferencing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereoscopic vision; eye-gaze correction; model-based tracking; head tracking; pose determination		The lack of eye contact in desktop video teleconferencing substantially reduces the effectiveness of video contents. While expensive and bulky hardware is available on the market to correct eye gaze, researchers have been trying to provide a practical software-based solution to bring video-teleconferencing one step closer to the mass market. This paper presents a novel approach: Based on stereo analysis combined with rich domain knowledge (a personalized face model), we synthesize, using graphics hardware, a virtual video that maintains eye contact. A 3D stereo head tracker with a personalized face model is used to compute initial correspondences across two views. More correspondences are then added through template and feature matching. Finally, all the correspondence information is fused together for view synthesis using view morphing techniques. The combined methods greatly enhance the accuracy and robustness of the synthesized views. Our current system is able to generate an eye-gaze corrected video stream at five frames per second on a commodity 1 GHz PC.	Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA; Microsoft Corp, Redmond, WA 98052 USA	University of Kentucky; Microsoft	Yang, RG (corresponding author), Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA.	ryang@cs.uky.edu; zhang@microsoft.com	zhang, zheng/HCH-9684-2022	Yang, Ruigang/0000-0001-5296-6307				CHAM TJ, 2002, P INT C AUT ROB CONT; Douglas DH, 1973, CARTOGR INT J GEOGR, V10, P112, DOI [10.3138/fm57-6770-u75u-7727, DOI 10.3138/FM57-6770-U75U-7727]; Gemmell J., 2000, IEEE Multimedia, V7, P26, DOI 10.1109/93.895152; Jones MJ, 1998, INT J COMPUT VISION, V29, P107, DOI 10.1023/A:1008074226832; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOLLARITS R, 1995, SID DIGEST; LIU J, 1995, P INT WORKSH STER 3, P229; Liu W, 2001, J NEW MAT ELECTR SYS, V4, P227; Loop C., 1999, 1999 IEEE COMP SOC C, V1, DOI [10.1109/CVPR.1999.786928, DOI 10.1109/CVPR.1999.786928]; MHLBACH L, 1985, P 11 INT S HUM FACT; OTT M, 1993, P C HUM FACT COMP SY, P119; POLLARD S, 1986, ROBOTICS RES, V30, P19; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; STOKES RR, 1969, IEEE T COMM TECHNOLO, V17; Yang R., 2002, P 5 IEEE INT C AUT F; Yang RG, 2002, LECT NOTES COMPUT SC, V2351, P479; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	17	32	33	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					956	960		10.1109/TPAMI.2004.27	http://dx.doi.org/10.1109/TPAMI.2004.27			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579955				2022-12-18	WOS:000221323900014
J	Pelillo, M				Pelillo, M			Matching free trees, maximal cliques, and monotone game dynamics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph matching; combinatorial optimization; quadratic programming; dynamical systems; evolutionary game theory; shape recognition		Motivated by our recent work on rooted tree matching, in this paper we provide a solution to the problem of matching two free (i.e., unrooted) trees by constructing an association graph whose maximal cliques are in one-to-one correspondence with maximal common subtrees. We then solve the problem using simple payoff-monotonic dynamics from evolutionary game theory. We illustrate the power of the approach by matching articulated and deformed shapes described by shape-axis trees. Experiments on hundreds of larger, uniformly random trees are also presented. The results are impressive: despite the inherent inability of these simple dynamics to escape from local optima, they always returned a globally optimal solution.	Univ Ca Foscari, Dipartimento Informat, I-30172 Venice, Italy	Universita Ca Foscari Venezia	Pelillo, M (corresponding author), Univ Ca Foscari, Dipartimento Informat, Via Torino 155, I-30172 Venice, Italy.	pelillo@dsi.unive.it						BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Bomze IM, 1997, J GLOBAL OPTIM, V10, P143, DOI 10.1023/A:1008230200610; BOMZE IM, 1999, HDB COMBINATORIAL S, VA, P1; Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7; Bunke H, 1999, IEEE T PATTERN ANAL, V21, P917, DOI 10.1109/34.790431; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Klein P, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P696; Klein P.N., 1998, P 6 ANN EUR S ALG ES, P91; MOTZKIN TS, 1965, CANADIAN J MATH, V17, P533, DOI 10.4153/CJM-1965-053-6; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; Pelillo M., 2001, Visual Form 2001. 4th International Workshop on Visual Form IWVF4. Proceedings (Lecture Notes in Computer Science Vol.2059), P583; WILF HS, 1981, J ALGORITHM, V2, P204, DOI 10.1016/0196-6774(81)90021-3; Zhang C, 1996, CHINESE CHEM LETT, V7, P1; Zhu SC, 1996, INT J COMPUT VISION, V20, P187; [No title captured]; [No title captured]; [No title captured]	17	32	32	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1535	1541		10.1109/TPAMI.2002.1046176	http://dx.doi.org/10.1109/TPAMI.2002.1046176			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY		Green Submitted			2022-12-18	WOS:000178846400011
J	Freedman, D				Freedman, D			Efficient simplicial reconstructions of manifolds from their samples	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						machine learning; differentiable manifold; simplicial complex	SKELETON; CRUST	A new algorithm for manifold learning is presented. Given only samples of a finite-dimensional differentiable manifold and no a priori knowledge of the manifold's geometry or topology except for its dimension, the goal is to find a description of the manifold. The learned manifold must approximate the true manifold well, both geometrically and topologically, when the sampling density is sufficiently high. The proposed algorithm constructs a simplicial complex based on approximations to the tangent bundle of the manifold. An important property of the algorithm is that its complexity depends on the dimension of the manifold, rather than that of the embedding space. Successful examples are presented in the cases of learning curves in the plane, curves in space, and surfaces in space; in addition, a case when the algorithm fails is analyzed.	Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Freedman, D (corresponding author), Rensselaer Polytech Inst, Dept Comp Sci, Amos Eaton 205, Troy, NY 12180 USA.	freedman@cs.rpi.edu						Althaus E, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P686; Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947; Amenta N, 1998, GRAPH MODEL IM PROC, V60, P125, DOI 10.1006/gmip.1998.0465; Amenta N, 1999, DISCRETE COMPUT GEOM, V22, P481, DOI 10.1007/PL00009475; AMENTA N, 1999, TR9908 U TEX AUST; BREGLER C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P494, DOI 10.1109/ICCV.1995.466899; CHENG SW, 1999, P ACM S SOL MOD APPL, P322; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Dey T. K., 1999, Proceedings of the Fifteenth Annual Symposium on Computational Geometry, P197, DOI 10.1145/304893.304972; Dey T.K., 1999, P 10 ANN ACM SIAM S, P893; DEY TK, 2001, P 17 ANN S COMP GEOM, P257, DOI DOI 10.1145/378583.378682; DEY TK, 2000, P 16 ANN S COMP GEOM, P233; FREEDMAN D, 2000, P C COMP VIS PATT RE, V1, P139; Gold C, 2001, ALGORITHMICA, V30, P144, DOI 10.1007/s00453-001-0014-x; Haykin S., 2014, ADAPTIVE FILTER THEO, V5th ed.; HOPPE H, 1992, P SIGGRAPH 92, P71, DOI DOI 10.1145/133994.134011; Hoppe H., 1994, P SIGGRAPH 94, P19; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1998, P 5 EUR C COMP VIS, V1, P893; KASS M, 1987, P 1 IEEE INT C COMP; Mulmuley K., 1994, COMPUTATIONAL GEOMET	21	32	36	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2002	24	10					1349	1357		10.1109/TPAMI.2002.1039206	http://dx.doi.org/10.1109/TPAMI.2002.1039206			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	596ZF					2022-12-18	WOS:000178196300005
J	Rosin, PL				Rosin, PL			Fitting superellipses	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						curve; superellipse; fitting; error measure	ELLIPSES; IMAGES; MODELS	In the literature, methods for fitting superellipses to data tend to be computationally expensive due to the nonlinear nature of the problem. This paper describes and tests several fitting techniques which provide different trade-offs between efficiency and accuracy. In addition, we describe various alternative error of fit (EOF) measures that can be applied by most superellipse fitting methods.	Univ Wales Coll Cardiff, Dept Comp Sci, Cardiff CF24 3XF, S Glam, Wales	Cardiff University	Rosin, PL (corresponding author), Univ Wales Coll Cardiff, Dept Comp Sci, Queens Bldg,Newport Rd,POB 916, Cardiff CF24 3XF, S Glam, Wales.							Abramowitz M., 1964, HDB MATH FUNCTIONS; Barr A. H., 1984, Computers & Graphics, V18, P21; Bennamoun M, 1997, IEEE T SYST MAN CY B, V27, P893, DOI 10.1109/3477.650052; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; GROSS A, 1988, P INT C COMP VIS, P690; KNOWLTON W, 1977, TECHNICAL FREEHAND D; LEE R, 1990, PATTERN RECOGN LETT, V11, P405, DOI 10.1016/0167-8655(90)90111-E; NAKAGAWA Y, 1979, PATTERN RECOGN, V11, P133, DOI 10.1016/0031-3203(79)90059-1; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; Pilu M, 1999, PATTERN RECOGN LETT, V20, P463, DOI 10.1016/S0167-8655(99)00011-2; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; Press W. H., 1990, NUMERICAL RECIPES C; ROSIN PL, 1995, IEE P-VIS IMAGE SIGN, V142, P280, DOI 10.1049/ip-vis:19952140; Rosin PL, 1996, GRAPH MODEL IM PROC, V58, P494, DOI 10.1006/gmip.1996.0041; Rosin PL, 1998, GRAPH MODEL IM PROC, V60, P209, DOI 10.1006/gmip.1998.0471; SAFAEERAD R, 1991, CVGIP-IMAG UNDERSTAN, V54, P259, DOI 10.1016/1049-9660(91)90067-Y; STRICKER M, 1994, P INT C AUT ROB COMP, P940; TOUSSAINT GT, 1983, P IEEE MELECON ATH G, P1; Voss K, 1999, IEEE T PATTERN ANAL, V21, P646, DOI 10.1109/34.777376; YOKOYA N, 1992, ICPR92, P168	20	32	34	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2000	22	7					726	732		10.1109/34.865190	http://dx.doi.org/10.1109/34.865190			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347LV					2022-12-18	WOS:000088931800007
J	Tarel, JP; Cooper, DB				Tarel, JP; Cooper, DB			The complex representation of algebraic curves and its simple exploitation for pose estimation and invariant recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						complex polynomials; pose estimation; pose-independent curve recognition; Euclidean invariants; complete-sets of rotation invariants; curve centers; implicit polynomial curves; algebraic curves; shape representation; shape recognition	MODELS	New representations are introduced for handling 2D algebraic curves (implicit polynomial curves) of arbitrary degree in the scope of computer vision applications. These representations permit fast, accurate pose-independent shape recognition under Euclidean transformations with a complete set of invariants, and fast accurate pose-estimation based on all the polynomial coefficients. The latter is accomplished by a new centering of a polynomial based on its coefficients, followed by rotation estimation by decomposing polynomial coefficient space into a union of orthogonal subspaces for which rotations within two-dimensional subspaces or identity transformations within one-dimensional subspaces result from rotations in x, y measured-data space. Angles of these rotations in the two-dimensional coefficient subspaces are proportional to each other and are integer multiples of the rotation angle in the x, y data space. By recasting this approach in terms of a complex variable, i.e., x + iy = z, and complex polynomial-coefficients, further conceptual and computational simplification results. Application to shape-based indexing into databases is presented to illustrate the usefulness and the robustness of the complex representation of algebraic curves.	Lab Cent Ponts & Chaussees, F-75732 Paris, France; Brown Univ, Div Engn, LEMS, Providence, RI 02912 USA	Universite Gustave-Eiffel; Laboratoire Central des Ponts et Chaussees (LCPC); Brown University	Tarel, JP (corresponding author), Lab Cent Ponts & Chaussees, 58 Blvd Lefebvre, F-75732 Paris, France.	tarel@lcpc.fr; cooper@lems.brown.edu	Tarel, Jean-Philippe/A-5598-2013	Tarel, Jean-Philippe/0000-0002-9241-5347				BRUCKSTEIN AM, 1991, VISUAL FORM, P89; Calabi E, 1998, INT J COMPUT VISION, V26, P107, DOI 10.1023/A:1007992709392; DEMA S, 1993, INT J COMPUTER VISIO, V10; Huang ZH, 1996, IEEE T IMAGE PROCESS, V5, P1473, DOI 10.1109/83.536895; LEI Z, 1996, P 3 IEEE WORKSH APPL; LEI Z, 163 LEMS BROWN U; Lei ZB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P827, DOI 10.1109/ICCV.1998.710813; Mokhtarian F., 1996, P BRIT MACH VIS C, P53; Mundy J., 1992, GEOMETRIC INVARIANCE; PONCE J, 1992, CVGIP-IMAG UNDERSTAN, V55, P184, DOI 10.1016/1049-9660(92)90016-V; Reiss T.H., 1993, RECOGNIZING PLANAR O; SCHWARTZ M, 1990, INFORMATION TRANSMIS; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; Tarel J.-P., 1998, P IEEE WORKSH MOD BA, P13; Tarel JP, 1998, PROC CVPR IEEE, P111, DOI 10.1109/CVPR.1998.698596; Tarel JP, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P818, DOI 10.1109/ICIP.1998.723684; Tasdizen T, 2000, IEEE T IMAGE PROCESS, V9, P405, DOI 10.1109/83.826778; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; UNEL M, 1998, P IEE INT C IM PROC; WEISS I, 1993, IEEE T PATTERN ANAL, V15, P943, DOI 10.1109/34.232081	20	32	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2000	22	7					663	674		10.1109/34.865183	http://dx.doi.org/10.1109/34.865183			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347LV					2022-12-18	WOS:000088931800002
J	Lam, W				Lam, W			Bayesian network refinement via machine learning approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						knowledge base refinement; uncertainty reasoning; Bayesian networks; machine learning; data mining	PROBABILISTIC INFERENCE; BELIEF NETWORKS; GRAPHICAL STRUCTURES; EXPERT SYSTEMS	A new approach to refining Bayesian network structures from new data is developed. Most previous work has only considered the refinement of the network's conditional probability parameters and has not addressed the issue of refining the network's structure. We tackle this problem by a machine learning approach based on a formalism known as the Minimum Description Length (MDL) principle. The MDL principle is well suited to this task since it can perform tradeoffs between the accuracy. simplicity, and closeness to the existent structure. Another salient feature of this refinement approach is the capability of refining a network structure using partially specified data. Moreover, a localization scheme is developed for efficient computation of the description lengths since direct evaluation involves exponential time resources.	Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Shatin, Hong Kong	Chinese University of Hong Kong	Lam, W (corresponding author), Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Shatin, Hong Kong.		Lam, Wai/GNW-3026-2022					AGOSTA JM, 1990, UNCERTAINTY ARTIFICI, V4, P397; BEINLICH IA, 1989, P 2 EUR C ART INT ME, P247; BERZUINI R, 1991, P C UNC ART INT, P35; Buntine W., 1991, P 7 C UNC ART INT, P52, DOI DOI 10.1016/B978-1-55860-203-8.50010-3; CHAVEZ RM, 1990, NETWORKS, V20, P661, DOI 10.1002/net.3230200510; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; COWELL RG, 1993, IEEE T PATTERN ANAL, V15, P209, DOI 10.1109/34.204903; Diez F.J., 1993, UNCERTAIN ARTIF INTE, P99, DOI DOI 10.1016/B978-1-4832-1451-1.50016-0; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; HECKERMAN D, 1994, P 5 INT WORKSH PRINC, P121; Henrion M., 1990, INFLUENCE DIAGRAMS B, P385; LAM W, 1993, P 9 C UNC ART INT, P243; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; MILOSAVLJEVIC A, 1993, MACH LEARN, V12, P69, DOI 10.1007/BF00993061; MUSICK R, 1993, P C UNC ART INT, P251; Musman S. A., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P513, DOI 10.1142/S0218001493000261; PEARL J, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P441; PEARL J, 1987, ARTIF INTELL, V32, P245, DOI 10.1016/0004-3702(87)90012-9; QUINLAN JR, 1989, INFORM COMPUT, V80, P227, DOI 10.1016/0890-5401(89)90010-2; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; Robinson RW, 1977, P 5 AUSTR C COMB MAT, P28; SHACHTER RD, 1990, MACH INTELL, V5, P221; Spiegelhalter D. J., 1992, BAYESIAN STAT, V4, P447; Spirtes P., 1995, P 1 INT C KNOWL DISC, P294; VERMA T, 1990, P 6 C UNC ART INT, P220; Wai Lam, 1994, Computational Intelligence, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; [No title captured]	31	32	36	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					240	251		10.1109/34.667882	http://dx.doi.org/10.1109/34.667882			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156					2022-12-18	WOS:000073078400002
J	Miura, J; Ikeuchi, K				Miura, J; Ikeuchi, K			Task-oriented generation of visual sensing strategies in assembly tasks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						task-oriented vision; sensing planning; active vision; CAD-based vision; vision-based assembly	POLYHEDRAL CONVEX CONES; SENSOR; RECOGNITION; VISION; ROBOT	This paper describes a method of systematically generating visual sensing strategies based on knowledge of the assembly task to be performed. Since visual sensing is usually performed with limited resources, visual sensing strategies should be planned so that only necessary information is obtained efficiently. The generation of the appropriate visual sensing strategy entails knowing what information to extract, where to get it, and how to get it. This is facilitated by the knowledge of the task, which describes what objects are involved in the operation, and how they are assembled. In the proposed method, using the task analysis based on face contact relations between objects, necessary information for the current operation is first extracted. Then, visual features to be observed are determined using the knowledge of the sensor, which describes the relationship between a visual feature and information to be obtained. Finally, feasible visual sensing strategies are evaluated based on the predicted success probability, and the best strategy is selected. Our method has been implemented using a laser range finder as the sensor. Experimental results show the feasibility of the method, and point out the importance of task-oriented evaluation of visual sensing strategies.	Osaka Univ, Dept Comp Controlled Mech Syst, Suita, Osaka 565, Japan; Univ Tokyo, Inst Ind Sci, Minato Ku, Tokyo 106, Japan	Osaka University; University of Tokyo	Miura, J (corresponding author), Osaka Univ, Dept Comp Controlled Mech Syst, Suita, Osaka 565, Japan.	jun@mech.eng.osaka-u.ac.jp; ki@cvl.iis.u-tokyo.ac.jp						ALOIMONOS J, 1990, P DARPA IMAGE UNDERS, P816; Aloimonos Y, 1993, ACTIVE PERCEPTION; AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; BALLARD DH, 1989, P INT JOINT C ART IN, P1635; BIRNBAUM L, 1993, P 4 INT C COMP VIS, P49; COWAN CK, 1991, IEEE WORKSH DIR AUT, P22; GREMBAN KD, 1994, INT J COMPUT VISION, V12, P137, DOI 10.1007/BF01421201; HIRAI S, 1993, INT J ROBOT RES, V12, P434, DOI 10.1177/027836499301200504; HORSWILL I, 1993, THESIS MIT; HUTCHINSON S, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1722, DOI 10.1109/ROBOT.1991.131869; HUTCHINSON SA, 1989, IEEE T ROBOTIC AUTOM, V5, P765, DOI 10.1109/70.88098; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; IKEUCHI K, 1994, IEEE T ROBOTIC AUTOM, V10, P368, DOI 10.1109/70.294211; IKEUCHI K, 1991, CMUCS91163 SCH COMP; Kemmotsu K., 1994, Proceedings 1994 IEEE International Conference on Robotics and Automation (Cat. No.94CH3375-3), P1357, DOI 10.1109/ROBOT.1994.351299; KUNIYOSHI Y, 1993, P INT JOINT C ART IN, P1600; LOZANOPEREZ T, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300101; MASON MT, 1981, IEEE T SYST MAN CYB, V11, P418, DOI 10.1109/TSMC.1981.4308708; OZEKI O, 1988, P ROB 12 VIS 88 C DE; PAUL GV, 1995, IEEE INT CONF ROBOT, P421, DOI 10.1109/ROBOT.1995.525320; RIMEY RD, 1993, 468 U ROCH COMP SCI; SAKANE S, 1991, IEEE T ROBOTIC AUTOM, P1080; SCHEINMAN V, 1987, ROBOTICS RES, V4; SPYRIDI AJ, 1994, IEEE INT CONF ROBOT, P1107, DOI 10.1109/ROBOT.1994.351212; TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940; TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P72, DOI 10.1109/70.345939; TSOTSOS JK, 1989, P INT JOINT C ART IN, P1571; WHAITE P, 1991, IEEE T PATTERN ANAL, V13, P1038, DOI 10.1109/34.99237; YANG CC, 1994, IEEE INT CONF ROBOT, P1120, DOI 10.1109/ROBOT.1994.351210; ZHANG H, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P1825, DOI 10.1109/ROBOT.1992.219962	31	32	33	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1998	20	2					126	138		10.1109/34.659931	http://dx.doi.org/10.1109/34.659931			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YZ697		Green Published			2022-12-18	WOS:000072281800003
J	Murino, V; Trucco, A; Regazzoni, CS				Murino, V; Trucco, A; Regazzoni, CS			A probabilistic approach to the coupled reconstruction and restoration of underwater acoustic images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						reconstruction; restoration; Markov random fields; underwater acoustic imaging; beamforming; confidence-based approach; physics-based vision	INTENSITY; SONAR; RANGE; REPRESENTATIONS; SEGMENTATION; OPTIMIZATION; SIMULATION; MODEL	This paper describes a probabilistic technique for the coupled reconstruction and restoration of underwater acoustic images. The technique is founded on the physics of the image-formation process. Beamforming, a method widely applied in acoustic imaging, is used to build a range image from backscattered echoes, associated point by point with another type of information representing the reliability (or confidence) of such an image. Unfortunately, this kind of images is plagued by problems due to the nature of the signal and to the related sensing system. In the proposed algorithm, the range and confidence images are modeled as Markov random fields whose associated probability distributions are specified by a single energy function. This function has been designed to fully embed the physics of the acoustic image-formation process by modeling a priori knowledge of the acoustic system, the considered scene, and the noise-affecting measures and also by integrating reliability information to allow the coupled and simultaneous reconstruction and restoration of both images. Optimal (in the Maximum A-Posteriori probability sense) estimates of the reconstructed range image map and the restored confidence image are obtained by minimizing the energy function using simulated annealing. Experimental results show the improvement of the processed images over those obtained by other methods performing separate reconstruction and restoration processes that disregard reliability information.	Univ Udine, Dept Math & Comp Sci, DIMI, I-33100 Udine, Italy; Univ Genoa, Dept Biophys & Elect Engn, DIBE, I-16145 Genoa, Italy	University of Udine; University of Genoa	Murino, V (corresponding author), Univ Udine, Dept Math & Comp Sci, DIMI, Via Sci 208, I-33100 Udine, Italy.	swan@dimi.uniud.it; fragola@dibe.unige.it	Murino, Vittorio/A-5570-2011; Regazzoni, Carlo S/B-6092-2012	Regazzoni, Carlo S/0000-0001-6617-1417; Murino, Vittorio/0000-0002-8645-2328; Trucco, Andrea/0000-0003-1189-6191				BEATTIE RS, 1995, P INT C SON SIGN PRO, P161; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BESL PJ, 1988, SURFACES RANGE IMAGE; BOZMA O, 1994, IEEE T PATTERN ANAL, V16, P497, DOI 10.1109/34.291448; FUJII H, 1974, OPT COMMUN, V11, P35, DOI 10.1016/0030-4018(74)90327-7; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEORGE O, 1995, IEEE J OCEANIC ENG, V20, P119, DOI 10.1109/48.376675; Gunsel B, 1996, COMPUT VIS IMAGE UND, V63, P353, DOI 10.1006/cviu.1996.0025; GUNSEL B, 1994, P 11 INT C PATT REC, P343; HANSEN RK, 1993, ACOUST IMAG, V20, P723; HENDERSON TL, 1989, IEEE J OCEANIC ENG, V14, P94, DOI 10.1109/48.16819; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; HOUSTON KM, 1995, P OCEANS 95 MTS IEEE, P1174; JAIN A, 1993, 3 DIMENSIONAL OBJECT; JAKEMAN E, 1987, J OPT SOC AM A, V4, P1764, DOI 10.1364/JOSAA.4.001764; JOHNSON B, 1993, P IEEE OC 93 C VICT, V3, P444; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; MARROQUIN J, 1985, THESIS MIT; Murino V., 1994, Acoustics Letters, V17, P169; MURINO V, 1993, IEE P, V140, P46; MURINO V, 1994, P IEEE ULTR S CANN F, P1367; Nielsen R., 1991, SONAR SIGNAL PROCESS; OKINO M, 1986, IEEE J OCEANIC ENG, V11, P474, DOI 10.1109/JOE.1986.1145209; SAUTER D, 1994, IEEE J OCEANIC ENG, V19, P563, DOI 10.1109/48.338392; SHOW S, 1993, P IEEE OCEANS 93 VIC, V2, P89; SUBRAMANIAM LV, 1995, P 8 INT S UNM UNT SU, P290; SUTTON JL, 1979, P IEEE, V67, P554, DOI 10.1109/PROC.1979.11283; SZELINSKY R, 1989, BAYESIAN MODELING UN; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; YU XM, 1994, IEEE T PATTERN ANAL, V16, P530, DOI 10.1109/34.291443; ZHANG GH, 1993, CVGIP-IMAG UNDERSTAN, V58, P191, DOI 10.1006/ciun.1993.1038	32	32	32	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1998	20	1					9	22		10.1109/34.655646	http://dx.doi.org/10.1109/34.655646			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YV876					2022-12-18	WOS:000071872400002
J	Wei, GQ; Hirzinger, G				Wei, GQ; Hirzinger, G			Parametric shape-from-shading by radial basis functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape from shading; radial basis functions; hierarchical structure; depth constraints; normals constraints; qualitative knowledge; stochastic gradient method	IMAGES; VISION; MODEL	In this paper, we present a new method of shape from shading by using radial basis functions to parameterize the object depth. The radial basis functions are deformed by adjusting their centers, widths, and weights such that the intensity errors are minimized. The initial centers and widths are arranged hierarchically to speed up convergence and to stabilize the solution. Although the smoothness constraint is used, ii can be eventually dropped out without causing instabilities in the solution. An important feature of our parametric shape-from-shading method is that it offers a unified framework for integration of multiple sensory information. We show that knowledge about surface depth and/or surface normals anywhere in the image can be easily incorporated into the shape from shading process. It is further demonstrated that even qualitative knowledge can be used in shape from shading to improve 3D reconstruction. Experimental comparisons of our method with several existing ones are made by using both synthetic and real images. Results show that our solution is more accurate than the others.			Wei, GQ (corresponding author), GERMAN AEROSP RES ESTAB,INST ROBOT & SYST DYNAM,DLR,FF DR RS,D-82234 OBERPFAFFENHOFEN,GERMANY.		Elhamod, Mohannad/A-1904-2012					BROOKS MJ, 1986, COMPUTER VISION GRAP, V33, P174; BROOKS MJ, 1985, AUG P INT JOINT C AR, P932; BRUCKSTEIN AM, 1988, COMPUT VISION GRAPH, V44, P139, DOI 10.1016/S0734-189X(88)80002-1; COURANT R, 1953, METHODS MATH PHYSICS, V1; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; Dupuis P., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P453, DOI 10.1109/CVPR.1992.223151; FERRIE FP, 1989, IEEE T PATTERN ANAL, V11, P198, DOI 10.1109/34.16715; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; GOSHTASBY A, 1994, CVGIP-GRAPH MODEL IM, V56, P281, DOI 10.1006/cgip.1994.1025; Hirzinger G., 1996, IEEE T NEURAL NETWOR, V17, P985; Horn B.K.P., 1989, SHAPE SHADING; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; HSIEH JW, 1994, GRAPHICAL MODELS IMA, V57, P343; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; JONES AG, 1994, IMAGE VISION COMPUT, V12, P411, DOI 10.1016/0262-8856(94)90025-6; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P47, DOI 10.1006/cviu.1995.1040; Leclerc Y. G., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P552, DOI 10.1109/CVPR.1991.139752; LEE CH, 1985, ARTIF INTELL, V26, P125, DOI 10.1016/0004-3702(85)90026-8; LEE KM, 1994, CVGIP-IMAG UNDERSTAN, V59, P202, DOI 10.1006/ciun.1994.1013; LEE KM, 1993, IEEE T PATTERN ANAL, V15, P815, DOI 10.1109/34.236247; LEE KM, 1993, J OPT SOC AM A, V10, P855, DOI 10.1364/JOSAA.10.000855; LI SZ, 1995, IEEE T PATTERN ANAL, V17, P576, DOI 10.1109/34.387504; Moody J, 1989, NEURAL COMPUT, V1, P281, DOI 10.1162/neco.1989.1.2.281; Nayar S. K., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P2, DOI 10.1109/ICCV.1990.139482; OLIENSIS J, 1991, INT J COMPUT VISION, V6, P75, DOI 10.1007/BF00128151; Park J, 1991, NEURAL COMPUT, V3, P246, DOI 10.1162/neco.1991.3.2.246; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Powell M.J.D., 1987, ALGORITHMS APPROXIMA, P143; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; SHAO M, 1991, CVGIP-IMAG UNDERSTAN, V53, P219, DOI 10.1016/1049-9660(91)90029-O; SZELISKI R, 1991, COMPUTER VISION GRAP, V53, P125; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; ZHANG R, 1994, P COMP VIS PATT REC, P377; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658	39	32	32	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1997	19	4					353	365		10.1109/34.588016	http://dx.doi.org/10.1109/34.588016			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WW122					2022-12-18	WOS:A1997WW12200006
J	Kramer, J				Kramer, J			Compact integrated motion sensor with three-pixel interaction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion estimation; velocity sensor; optical flow; analog VLSI; robot vision		An integrated circuit with on-chip photoreceptors is described, that computes the bi-directional velocity of a visual stimulus moving along a given axis in the focal plane by measuring the time delay of its detection at two positions. Due to the compactness of the circuit, a dense array of such motion-sensing elements can be monolithically integrated to estimate the velocity field of an image and to extract higher-level image features through local or global interaction.			Kramer, J (corresponding author), CALTECH,DIV BIOL 13974,PASADENA,CA 91125, USA.							Andreou A. G., 1991, P 1991 IEEE INT S CI, P1373; BAIR W, 1991, ADV NEURAL INFORMATI, V3, P399; BARLOW HB, 1965, J PHYSL, V178, P447; BENSON RG, 1991, ADV NEURAL INFORMATI, V4, P756; DELBRUCK T, 1993, IEEE T NEURAL NETWOR, V4, P529, DOI 10.1109/72.217194; DELBRUCK T, 1993, THESIS DEP COMP NEUR; Etienne-Cummings R., 1993, Proceedings. 1993 Computer Architectures for Machine Perception. (Cat. No. 93TH0608-0), P241, DOI 10.1109/CAMP.1993.622478; HASSENSTEIN B, 1956, Z NATURFORSCH PT B, V11, P513; HILDRETH EC, 1987, ANNU REV NEUROSCI, V10, P477, DOI 10.1146/annurev.ne.10.030187.002401; Horiuchi T., 1991, ADV NEURAL INFORMATI, VIII, P406; Koch C., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P312, DOI 10.1109/WVM.1991.212769; KRAMER J, 1995, UNPUB IEEE T CIRCUIT, V2; KRAMER J, 1995, P IEEE INT S CIRC SY, P413; MEAD C, 1990, P IEEE, V78, P1629, DOI 10.1109/5.58356; SARPESHKAR R, 1995, UNPUB P IEEE AUG; Sarpeshkar R., 1993, ADV NEURAL INFORMATI, V5, P781; TANNER JE, 1986, VLSI SIGNAL PROCESSI, V2, P59; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; MOSIS	19	32	32	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					455	460		10.1109/34.491628	http://dx.doi.org/10.1109/34.491628			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345					2022-12-18	WOS:A1996UG34500012
J	Berzuini, C; Larizza, C				Berzuini, C; Larizza, C			A unified approach for modeling longitudinal and failure time data, with application in medical monitoring	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian inference; statistical forecasting; analysis of time series data; analysis of failure data; Markov chain Monte Carlo methods; conditional independence graphs; model determination; medical monitoring	BAYESIAN-APPROACH; INFERENCE; FRAILTY	This paper considers biomedical problems in which a sample of subjects, for example clinical patients, is monitored through time for purposes of individual prediction. Emphasis is on situations in which the monitoring generates data both in the form of a time series and in the form of events (development of a disease, death, etc.) observed on each subject over specified intervals of time. A Bayesian approach to the combined modeling of both types of data for purposes of prediction is presented. The proposed method merges ideas of Bayesian hierarchical modeling, nonparametric smoothing of time series data, survival analysis, and forecasting into a unified framework. Emphasis is on flexible modeling of the time series data based on stochastic process theory. The use of Markov Chain Monte Carlo simulation to calculate the predictions of interest is discussed. Conditional independence graphs are used throughout for a clear presentation of the models. An application in the monitoring of transplant patients is presented.			Berzuini, C (corresponding author), UNIV PAVIA, DIPARTIMENTO INFORMAT & SISTEMIST, I-27100 PAVIA, ITALY.		Berzuini, Carlo/AAA-7023-2019	Berzuini, Carlo/0000-0001-6056-0489; LARIZZA, CRISTIANA/0000-0002-5055-8665				ARJAS E, IN PRESS STATISTICA; Berzuini C., 1992, Artificial Intelligence in Medicine, V4, P243, DOI 10.1016/0933-3657(92)90030-S; BERZUINI C, 1994, STAT MED, V13, P823, DOI 10.1002/sim.4780130804; BERZUINI C, 1994, DYNAMIC GRAPHICAL MO; Berzuini Carlo, 1993, B INT STAT I, V55, P149; Breslow N. E., 1987, STATISTICAL METHODS, VII; BRESLOW NE, 1993, J AM STAT ASSOC, V88, P9, DOI 10.1080/01621459.1993.10594284; CHI EM, 1989, J AM STAT ASSOC, V84, P452, DOI 10.2307/2289929; CLAYTON D, 1988, STAT MED, V7, P819, DOI 10.1002/sim.4780070802; CLAYTON D, 1993, STATISTICAL MODELS E; CLAYTON DG, 1991, BIOMETRICS, V47, P467, DOI 10.2307/2532139; CULLIS BR, 1990, BIOMETRICS, V46, P131, DOI 10.2307/2531636; DAWID AP, 1984, J ROYAL STATISTICA A, V147, P178; DIGGLE PJ, 1988, BIOMETRICS, V44, P959, DOI 10.2307/2531727; FEARN T, 1975, BIOMETRIKA, V62, P89; GAMERMAN D, 1993, J ROY STAT SOC B MET, V55, P629; GAMERMAN D, 1987, STATISTICIAN, V36, P269; GEISSER S, 1975, J AM STAT ASSOC, V70, P320, DOI 10.2307/2285815; GELFAND AE, 1990, J AM STAT ASSOC, V85, P398, DOI 10.2307/2289776; Gelfand AE, 1992, BAYESIAN STATISTICS, V4, P147; GELFAND AE, 1994, P 5 INT M BAY STAT A, P48; Gelman A, 1992, STAT SCI, V7, P136, DOI 10.1214/ss/1177011136; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GILKS WR, 1993, J R STAT SOC B, V55, P39; GILKS WR, 1992, APPL STAT, V41, P337, DOI DOI 10.2307/2347565; GILKS WR, 1994, ADAPTIVE REJECTION M; GORDON K, 1990, J AM STAT ASSOC, V85, P328, DOI 10.2307/2289768; GREEN PJ, 1987, INT STAT REV, V55, P245, DOI 10.2307/1403404; HARRISON PJ, 1976, J R STAT SOC B, V38, P205; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; KALBFLEISCH JD, 1978, J ROY STAT SOC B MET, V40, P214; KONG A, 1994, J AM STAT ASSOC, V89, P278, DOI 10.2307/2291224; LANGE N, 1992, J AM STAT ASSOC, V87, P615, DOI 10.2307/2290194; LAURITZEN SL, 1988, J R STAT SOC B, V50, P202; LEONARD T, 1978, J ROY STAT SOC B MET, V40, P113; LINDLEY DV, 1972, J ROY STAT SOC B, V34, P1; LIU JS, IN PRESS J AM STATIS, V90; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MIGON HS, 1993, J FORECASTING, V12, P573, DOI 10.1002/for.3980120704; PEARL J, 1987, ARTIF INTELL, V32, P245, DOI 10.1016/0004-3702(87)90012-9; RICHARDSON S, 1993, STAT MED, V12, P1703, DOI 10.1002/sim.4780121806; RUBIN DB, 1987, J AM STAT ASSOC, V82, P543, DOI 10.2307/2289460; SMITH AFM, 1983, BIOMETRICS, V39, P867, DOI 10.2307/2531322; SMITH AFM, 1993, J ROY STAT SOC B MET, V55, P3; TAYLOR JMG, 1994, J AM STAT ASSOC, V89, P727; Thomas A, 1992, BAYESIAN STATISTICS, P837; TIERNEY L, 1991, COMPUTING SCIENCE AND STATISTICS, P563; VAUPEL JW, 1979, DEMOGRAPHY, V16, P439, DOI 10.2307/2061224; WAKEFIELD JC, IN PRESS APPL STATIS; West M., 1989, BAYESIAN FORECASTING, DOI 10.1007/978-1-4757-9365-9; WHITTAKER J, 1990, GEOGRAPHICAL MOVES A	53	32	34	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1996	18	2					109	123		10.1109/34.481537	http://dx.doi.org/10.1109/34.481537			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TV669					2022-12-18	WOS:A1996TV66900003
J	Ghosal, S; Vanek, P				Ghosal, S; Vanek, P			A fast scalable algorithm for discontinuous optical flow estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						discontinuous optical flow estimation; weighted anisotropic smoothness; partial differential equation (PDE); scalable algorithm; multilevel iterative methods	SMOOTHNESS CONSTRAINTS; IMAGE SEQUENCES; VECTOR-FIELDS; MOTION; RELAXATION	Multiple moving objects, partially occluded objects, or even a single object moving against the background gives rise to discontinuities in the optical flow field in corresponding image sequences. While uniform global regularization based moderately fast techniques cannot provide accurate estimates of the discontinuous flow field, statistical optimization based accurate techniques suffer from excessive solution time. A 'weighted anisotropic' smoothness based numerically robust algorithm is proposed that can generate discontinuous optical flow field with high speed and linear computational complexity. Weighted sum of the first-order spatial derivatives of the flow field is used for regularization. Less regularization is performed where strong gradient information is available. The flow field at any point is interpolated more from those at neighboring points along the weaker intensity gradient-component. Such intensity gradient weighted regularization leads to Euler-Lagrange equations with strong anisotropies coupled with discontinuities in their coefficients. A robust multilevel iterative technique, that recursively generates coarse-level problems based on intensity gradient weighted smoothing weights, is employed to estimate discontinuous optical flow field. Experimental results are presented to demonstrate the efficacy of the proposed technique.	UNIV COLORADO,CTR COMPUTAT MATH,DENVER,CO 80217	University of Colorado System; University of Colorado Denver	Ghosal, S (corresponding author), AMHERST SYST INC,ADV TECHNOL DEPT,BUFFALO,NY 14221, USA.							ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; BRAMBLE JH, 1991, MATH COMPUT, V57; Briggs W., 1987, MULTIGRID TUTORIAL; Campani M., 1987, P INT C COMP VIS, P22; Campbell F. W., 1966, J PHYSL, V197, P437; ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GHOSAL S, 1994, P IEEE INT C IM PROC, V2, P780; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350; LUCAS BD, 1984, THESIS C MELLON U; MANDEL J, 1991, ADV ELECTRON EL PHYS, V82, P327; McCormick S.F., 1987, MULTIGRID METHODS; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; RUGE JW, FRONTIERS APPL MATH, P73; SINGH A, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P168; SNYDER MA, 1991, IEEE T PATTERN ANAL, V13, P1105, DOI 10.1109/34.103272; SZELISKI R, 1990, IEEE T PATTERN ANAL, V12, P513, DOI 10.1109/34.56188; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; VANEK P, 1992, APPLICATIONS MATH, V37; VANEK P, 1995, 34 U COL CTR COMP MA; VARGA RS, 1992, MATRIX ITERATIVE ANA; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; ZHENG H, 1993, THESIS QUEENS U ONTA; ZHENG H, 1993, P INT C SIGN P BEIJ, V2, P924; Zheng H, 1993, IEEE T IMAGE PROCESS, V2, P246, DOI 10.1109/83.217228	31	32	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1996	18	2					181	194		10.1109/34.481542	http://dx.doi.org/10.1109/34.481542			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TV669					2022-12-18	WOS:A1996TV66900008
J	GORYN, D; HEIN, S				GORYN, D; HEIN, S			ON THE ESTIMATION OF RIGID-BODY ROTATION FROM NOISY DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						COMPUTER VISION; ROTATION ESTIMATION; TOTAL LEAST SQUARES		We derive an exact solution to the problem of estimating the rotation of a rigid body from noisy 3D image data. Our approach is based on total least squares (TLS), but unlike previous work involving TLS, we include the constraint that the transformation matrix should be orthonormal. It turns out that the solution to the estimation problem has the same form as if the data are not noisy, and thus the solution to the standard Procrustes problem can be applied.			GORYN, D (corresponding author), SIEMENS AG, OTTO HAHN RING 6, D-81730 MUNICH, GERMANY.							ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; Golub G. H., 1996, MATRIX COMPUTATIONS; HUANG TS, 1986, P IEEE C COMPUTER VI; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573	5	32	34	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1219	1220		10.1109/34.476514	http://dx.doi.org/10.1109/34.476514			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500009
J	PARIZEAU, M; PLAMONDON, R				PARIZEAU, M; PLAMONDON, R			A FUZZY-SYNTACTIC APPROACH TO ALLOGRAGH MODELING FOR CURSIVE SCRIPT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							ONLINE	This paper presents an original method for creating allograph models and recognizing them within cursive handwriting. This method concentrates on the morphological aspect of cursive script recognition. It uses fuzzy-shape grammars to define the morphological characteristics of conventional allographs which can be viewed as basic knowledge for developing a writer independent recognition system. The system uses no linguistic knowledge to output character sequences that possibly correspond to an unknown cursive word input. The recognition method is tested using multi-writer cursive random letter sequences. For a test dataset containing a handwritten cursive text 600 characters in length written by ten different writers, average character recognition rates of 84.4% to 91.6% are obtained, depending on whether only the best character ter sequence output of the system is considered or if the best of the top 10 is accepted. These results are achieved without any writer-dependent tuning. The same dataset is used to evaluate the performance of human readers. An average recognition rate of 96.0% was reached, using ten different readers, presented with randomized samples of each writer. The worst reader-writer performance was 78.3%. Moreover, results show that system performances are highly correlated with human performances.	UNIV LAVAL,DEPT ELECT ENGN,ST FOY,PQ G1K 7P4,CANADA; ECOLE POLYTECH,DEPT GENIE ELECT & GENIE INFORMAT,MONTREAL,PQ H3C 3A7,CANADA	Laval University; Universite de Montreal; Polytechnique Montreal			Plamondon, Réjean/O-3214-2015	Plamondon, Réjean/0000-0002-4903-7539				BROCKLEHURST ER, 1991, INT J MAN MACH STUD, V34, P69, DOI 10.1016/0020-7373(91)90051-8; DAVIS LS, 1981, IEEE T PATTERN ANAL, V3, P265, DOI 10.1109/TPAMI.1981.4767099; Dubois D., 1980, FUZZY SET SYST; GUERFALI W, 1993, PATTERN RECOGN, V26, P419, DOI 10.1016/0031-3203(93)90169-W; HIGGINS CA, 1984, 1ST P INT 84 IFIP C, V2, P140; MERMELSTEIN P, 1964, INFORM CONTROL, V7, P255, DOI 10.1016/S0019-9958(64)90142-1; MORASSO P, 1993, PATTERN RECOGN, V26, P451, DOI 10.1016/0031-3203(93)90172-S; NOUBOUD F, 1990, PATTERN RECOGN, V23, P1031, DOI 10.1016/0031-3203(90)90111-W; PARIZEAU M, 1992, THESIS ECOLE POLYTEC; PARIZEAU M, 1992, 11TH P INT C PATT RE, V2, P308; PARIZEAU M, 1993, ADV STRUCTURAL SYNTA, P320; PARIZEAU M, 1993, 3RD P INT WORKSH FRO, P252; PLAMONDON R, 1993, ACTA PSYCHOL, V82, P89, DOI 10.1016/0001-6918(93)90006-D; PLAMONDON R, 1989, IEEE T SYST MAN CYB, V19, P1060, DOI 10.1109/21.44021; PLAMONDON R, 1993, BIOL CYBERN, V69, P119, DOI 10.1007/BF00226195; PLAMONDON R, 1992, 11TH P INT C PATT RE, V2, P303; PLAMONDON R, 1991, P 1 INT C DOC AN REC, P361; PLAMONDON R, 1990, COMPUTER PROCESSING; SCHOMAKER L, 1993, PATTERN RECOGN, V26, P443, DOI 10.1016/0031-3203(93)90171-R; TAPPERT CC, 1982, IBM J RES DEV, V26, P765, DOI 10.1147/rd.266.0765; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811	22	32	33	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1995	17	7					702	712		10.1109/34.391412	http://dx.doi.org/10.1109/34.391412			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RF224					2022-12-18	WOS:A1995RF22400006
J	JEON, BW; LANDGREBE, DA				JEON, BW; LANDGREBE, DA			FAST PARZEN DENSITY-ESTIMATION USING CLUSTERING-BASED BRANCH-AND-BOUND	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						PARZEN DENSITY ESTIMATION; BRANCH AND BOUND; PRECLUSTERING; NONPARAMETRIC DISCRIMINANT ANALYSIS	FAST FOURIER-TRANSFORM	This correspondence proposes a fast Parzen density estimation algorithm that would be especially useful in the nonparametric discriminant analysis problems. By preclustering the data and applying a simple branch and bound procedure to the clusters, significant numbers of data samples that would contribute little to the density estimate can be excluded without detriment to actual evaluation via the kernel functions. This technique is especially helpful in the multivariant case, and does not require a uniform sampling grid. The proposed algorithm may also be used in conjunction with the data reduction technique of Fukunaga and Hayes to further reduce the computational load. Experimental results are presented to verify the effectiveness of this algorithm.			JEON, BW (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.		Jeon, Byeungwoo/AAS-1096-2021	Jeon, Byeungwoo/0000-0002-5650-2881				BALL GH, 1965, AD699616; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P423, DOI 10.1109/34.19040; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; FUKUNAGA K, 1990, INTRO STATISTICAL PA; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; SILVERMAN BW, 1982, APPL STAT-J ROY ST C, V31, P93, DOI 10.2307/2347084; Therrien C. W., 1989, DECISION ESTIMATION; [No title captured]	9	32	37	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					950	954		10.1109/34.310693	http://dx.doi.org/10.1109/34.310693			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802					2022-12-18	WOS:A1994PE80200013
J	WAKAHARA, T				WAKAHARA, T			SHAPE-MATCHING USING LAT AND ITS APPLICATION TO HANDWRITTEN NUMERAL RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						2-D SHAPE MATCHING; HANDWRITTEN CHARACTER RECOGNITION; LOCAL AFFINE TRANSFORMATION; WEIGHTED LEAST-SQUARES CRITERION; MULTISCALE REFINEMENT; DEFORMATION CONSTRAINTS	DISPARITY; FEATURES; VISION	This paper describes an iterative technique for gradually deforming a mask binary image with successive local affine transformation (LAT) operations so as to yield the best match to an input binary image as one new and promising approach toward robust handwritten character recognition. The method uses local shapes in the sense that the LAT of each point at one location is optimized using locations of other points by means of least-squares data fitting using Gaussian window functions. It also uses a multiscale refinement technique that employs decreasing the spread of window functions with each iteration. Especially in handwritten character recognition, structural information is indispensable for robust shape matching or discrimination. The method is enhanced to explicitly incorporate structures by weighting the above least-squares criterion with similarity measures of both topological and geometric features of the mask and input images. Moreover, deformation constraints are imposed on each iteration, not only to promote and stabilize matching convergence but also to suppress an excessive matching process. Shape matching experiments have been successfully carried out using skeletons of totally unconstrained handwritten numerals. Furthermore, to evaluate its shape discrimination ability, this method was applied to recognition tests, and a high recognition rate was obtained.			WAKAHARA, T (corresponding author), NIPPON TELEGRAPH TEL CORP,HUMAN INTERFACE LABS,1-2356 TAKE,YOKOSUKA,KANAGAWA 23803,JAPAN.							AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; BAIRD HS, 1985, MODEL BASED IMAGE MA; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; Davis L. S., 1976, 3rd International Joint Conference on Pattern Recognition, P591; DRAPER NR, 1966, APPLIED REGRESSION A; Duda R.O., 1973, J ROYAL STAT SOC SER; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Huang X., 1990, HIDDEN MARKOV MODELS; KASS M, 1987, 1ST P INT C COMP VIS, P259; Lucas B D, 1981, P 7 INT JOINT C ARTI, P674; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; Moravec H., 1977, P 5 INT JOINT C ART, VVolume 1, P584; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; MORI S, 1983, COMPUT PROCESSING CH, V1, P24; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; RANDE S, 1980, PATTERN RECOGN, V12, P269; SUEN CY, 1982, SIGNAL PROCESS, V4, P193, DOI 10.1016/0165-1684(82)90021-4; WAKAHARA T, 1990, 10TH P INT C PATT RE, P837; WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062; WIDROW B, 1973, PATTERN RECOGN, V5, P175, DOI 10.1016/0031-3203(73)90042-3; Wong A. K. C., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P546; Yamada H., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P95; 1977, ENCY DICT MATH	27	32	32	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					618	629		10.1109/34.295906	http://dx.doi.org/10.1109/34.295906			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200006
J	KUC, R				KUC, R			A SPATIAL SAMPLING CRITERION FOR SONAR OBSTACLE DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											KUC, R (corresponding author), YALE UNIV,DEPT ELECT ENGN,INTELLIGENT SENSORS LAB,NEW HAVEN,CT 06520, USA.							BARSHAN B, 1990, IEEE T PATTERN ANAL, V12, P560, DOI 10.1109/34.56192; BORENSTEIN J, 1988, IEEE J ROBOT AUTOM, V4, P213, DOI 10.1109/56.2085; CROWLEY JL, 1985, IEEE T ROBOTIC AUTOM, P128; ELFES A, 1988, P IEEE INT C ROBOTIC; Elfes A., 1987, IEEE J ROBOTIC AUTOM, V3; HONERD G, 1986, P INTELLIGENT AUTONO, P258; KREIGMAN DJ, 1987, IEEE T ROBOTIC AUTOM, P402; KUC R, 1987, IEEE T PATTERN ANAL, V9, P766, DOI 10.1109/TPAMI.1987.4767983; KUC R, IN PRESS INT J ROBOT; KUC R, 1989, IEEE INT C ROB AUT, P1422; LUO R, 1988, P IEEE INT C ROBOTIC; MORAVEC HP, 1985, IEEE T ROBOTIC AUTOM, P116; Morse P. M., 1968, THEORETICAL ACOUSTIC; TACHI S, 1984, 2ND P INT S ROB RES; WALTER SA, 1987, IEEE T ROBOTIC AUTOM, P1574; WEAST RC, 1973, CRC HDB CHEM PHYSICS, pE49; Wells P N T, 1977, BIOMEDICAL ULTRASONI; 1982, ULTRASONIC RANGE FIN	18	32	33	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1990	12	7					686	690		10.1109/34.56211	http://dx.doi.org/10.1109/34.56211			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DK894					2022-12-18	WOS:A1990DK89400009
J	WOLFSON, E; SCHWARTZ, EL				WOLFSON, E; SCHWARTZ, EL			COMPUTING MINIMAL DISTANCES ON POLYHEDRAL SURFACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									COURANT INST MATH SCI,DEPT COMP SCI,NEW YORK,NY 10003		WOLFSON, E (corresponding author), NYU,SCH MED,DEPT PSYCHIAT,COMP NEUROSCI LABS,550 1ST AVE,NEW YORK,NY 10016, USA.							KAPLOW WK, 1986, NYU CNSTR186 MED CTR; MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045; MOUNT DM, 1985, CARTR121 CTR AUT RES, V1496; OROUKE J, 1984, 2ND P S THEOR ASP CO; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506; SCHWARTZ EL, 1985, SOC NEUR ABSTR, V15; SHARIR M, 1986, SIAM J COMPUT, V15, P193, DOI 10.1137/0215014; TOOTELL RBH, 1982, SCIENCE, V218, P902, DOI 10.1126/science.7134981	9	32	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					1001	1005		10.1109/34.35505	http://dx.doi.org/10.1109/34.35505			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800012
J	FLEET, DJ; JEPSON, AD				FLEET, DJ; JEPSON, AD			HIERARCHICAL CONSTRUCTION OF ORIENTATION AND VELOCITY SELECTIVE FILTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											FLEET, DJ (corresponding author), UNIV TORONTO,DEPT COMP SCI,TORONTO M5S 1A4,ONTARIO,CANADA.			/0000-0003-0734-7114				ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ADELSON EH, 1986, MOTION REPRESENTATIO, P151; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; CROWLEY JL, 1982, CMURITR827 CMU ROB I; DAUGMAN JG, 1983, IEEE T SYST MAN CYB, V13, P882, DOI 10.1109/TSMC.1983.6313083; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; FLEET D, 1984, RBCVTR846 U TOR DEP; FLEET DJ, 1985, BIOL CYBERN, V52, P153; FLEET DJ, 1985, RBCVTR858 U TOR TECH; FLEET DJ, 1985, OCT P IEEE COMP VIS, P179; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; HEEGER DJ, 1987, JUN P INT C COMP VIS, P181; HEEGER DJ, 1986, MAY P IEEE WORKSH MO, P131; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; KNUTSSON H, 1980, 5TH P INT C PATT REC, P45; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; Papoulis A., 2002, PROBABILITY RANDOM V; RABINER LR, 1975, DIGITAL SIGNAL PROCE; RICHTER J, 1982, BIOL CYBERN, V43, P127, DOI 10.1007/BF00336975; SCHUNCK B, 1985, JUN P CVPR SAN FRANC, P561; SLEPIAN D, 1983, SIAM REV, V25, P379, DOI 10.1137/1025078; WATSON AB, 1985, J OPT SOC AM A, V2, P322, DOI 10.1364/JOSAA.2.000322; WATSON BA, 1983, BIOL MACHINE VISION; YOUNG R, 1987, IN PRESS SPATIAL VIS; ZUCKER SW, 1985, COMPUT VISION GRAPH, V32, P74, DOI 10.1016/0734-189X(85)90003-9	28	32	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					315	325		10.1109/34.21800	http://dx.doi.org/10.1109/34.21800			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840					2022-12-18	WOS:A1989T384000011
J	SABIN, MJ				SABIN, MJ			CONVERGENCE AND CONSISTENCY OF FUZZY C-MEANS ISODATA ALGORITHMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CALIF BERKELEY,DEPT ELECT ENGN & COMP SCI,BERKELEY,CA 94720	University of California System; University of California Berkeley								Ash R.B., 1972, REAL ANAL PROBABILIT; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; BEZDEK JC, 1987, IN PRESS IEEE T SYST; BUZO A, 1980, IEEE T ACOUST SPEECH, V28, P562, DOI 10.1109/TASSP.1980.1163445; GRAY RM, 1980, INFORM CONTROL, V45, P178, DOI 10.1016/S0019-9958(80)90313-7; Royden H.L., 1968, REAL ANAL; SABIN MJ, 1986, IEEE T INFORM THEORY, V32, P148, DOI 10.1109/TIT.1986.1057168; TSENG HP, 1987, 1987 P IEEE INT C AC, V2, P641	8	32	32	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					661	668		10.1109/TPAMI.1987.4767960	http://dx.doi.org/10.1109/TPAMI.1987.4767960			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869424				2022-12-18	WOS:A1987J739300007
J	JAIN, R; BARTLETT, SL; OBRIEN, N				JAIN, R; BARTLETT, SL; OBRIEN, N			MOTION STEREO USING EGO-MOTION COMPLEX LOGARITHMIC MAPPING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											JAIN, R (corresponding author), UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,COMP VIS RES LAB,ANN ARBOR,MI 48109, USA.							ARSENAULT HH, 1984, OPT ENG, V23, P705, DOI 10.1117/12.7973367; BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; BERTOLD M, 1984, 7TH P INT C PATT REC, V2, P841; BRACCINI C, 1982, BIOL CYBERN, V44, P47, DOI 10.1007/BF00353955; BRUSS AR, 1983, COMPUT VISION GRAPHI, V21; BURR DJ, 1984, 7TH P INT C PATT REC, V1, P669; CAVANAGH P, 1978, PERCEPTION, V7, P167, DOI 10.1068/p070167; CAVANAGH P, 1981, PERCEPTION, V10, P469, DOI 10.1068/p100469; CHAIKIN G, 1979, COMPUTER GRAPHICS IM, V4, P197; CLOCKSIN WF, 1980, PERCEPTION, V9, P253, DOI 10.1068/p090253; Gibson J., 1979, ECOLOGICAL APPROACH; GRIMSON WEL, 1981, IMAGES SURFACES COMP; GRIMSON WEL, 1983, COMPOUT VISION GRAPH, V28, P19; GU WK, 1984, 7TH P INT C PATT REC, V1, P441; HOMMA K, 1984, DEC P IEEE COMP SOC, P14; IKEUCHI K, 1984, 7TH IEEE P INT C PAT, V2, P736; ITOH H, 1984, 7TH P INT C PATT REC, V1, P192; JAIN R, 1984, SPIE             NOV; JAIN R, 1983, APR P SIGGRAPH SIGAR; JAIN RC, 1984, IEEE T PATTERN ANAL, V6, P624, DOI 10.1109/TPAMI.1984.4767575; Kent Elizabeth, COMMUNICATION; LEE DN, 1980, PHILOS T R SOC B, V290, P169, DOI 10.1098/rstb.1980.0089; LUH JYS, 1979, 1ST P INT C COMP APP, P887; Marr D., 1982, VISION; MASSONE L, 1985, COMPUT VISION GRAPH, V30, P169, DOI 10.1016/0734-189X(85)90095-7; MATTIAS LH, 1984, SEP 84 OC C REC WASH, V2, P594; MESSNER RA, 1985, COMPUT VISION GRAPH, V31, P50, DOI 10.1016/S0734-189X(85)80075-X; MORAVEC H, 1981, ROBOT ROVER VISUAL N; NEVATIA R, 1976, COMPUT GRAPH IMAGE P, V5, P203; NISHIHARA HK, 1984, OPT ENG, V23, P536, DOI 10.1117/12.7973334; OBRIEN N, 1984, APR P WORKSH COMP VI, P88; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; REEVES AP, 1984, 7TH P INT C PATT REC, V1, P447; REITBOECK HJ, 1984, BIOL CYBERN, V51, P113, DOI 10.1007/BF00357924; SAFRANEK RJ, 1983, OCT P IEEE INT C COM, P76; SANDINI G, 1980, COMPUT VISION GRAPH, V14, P365, DOI 10.1016/0146-664X(80)90026-X; SCHENKER PS, 1981, P SOC PHOTO-OPT INST, V281, P47, DOI 10.1117/12.965731; SCHWARTZ EL, 1982, BIOL CYBERN, V42, P157; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; SCHWARTZ EL, 1981, PERCEPTION, V10, P455, DOI 10.1068/p100455; SCHWARTZ EL, J THEORETICAL BIOL, V69, P655; SMITLEY DL, 1984, 7TH P INT C PATT REC, V1, P433; STOCKMAN G, 1984, 7TH P INT C PATT REC, V2, P742; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WU CK, 1983, COMPUTER VISION GRAP, V28, P126; ZACHARIAS GL, 1985, J GUID CONTROL DYNAM, V8, P201, DOI 10.2514/3.19960; ZACHARIAS GL, 1983, 1983 P AM CONTR C SA, P1326	47	32	34	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1987	9	3					356	369		10.1109/TPAMI.1987.4767919	http://dx.doi.org/10.1109/TPAMI.1987.4767919			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H0768	22516630	Green Submitted			2022-12-18	WOS:A1987H076800002
J	CHENG, YC; LU, SY				CHENG, YC; LU, SY			WAVEFORM CORRELATION BY TREE MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CHENG, YC (corresponding author), EXXON PROD RES CO,HOUSTON,TX 77001, USA.							EHRICH RW, 1976, IEEE T COMPUT, V25, P725, DOI 10.1109/TC.1976.1674681; KERZNER MG, 1983, LOG ANAL         SEP; LU SY, 1982, OCT INT JOINT C PATT; LU SY, UNPUB IEEE T PATTERN; MARTINSON DG, 1982, J GEOPHYS RES, V87, P4807, DOI 10.1029/JB087iB06p04807; VINCENT P, 1977, 52ND ANN FALL TECH C	6	32	38	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					299	305		10.1109/TPAMI.1985.4767658	http://dx.doi.org/10.1109/TPAMI.1985.4767658			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869264				2022-12-18	WOS:A1985AFM4400004
J	KAHN, G; NOWLAN, S; MCDERMOTT, J				KAHN, G; NOWLAN, S; MCDERMOTT, J			STRATEGIES FOR KNOWLEDGE ACQUISITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CARNEGIE MELLON UNIV,DEPT COMP SCI,PITTSBURGH,PA 15213	Carnegie Mellon University								BOOSE J, 1984, P NAT C ARTIF INTELL; DAVIS R, 1982, KNOWLEDGE BASED SYST; KAHN G, 1984, P ADV ARTIF INTELL P; KAHN G, 1985, MUD DRILLING FLUIDS; KAHN G, 1984, P IEEE C ARTIF INTEL; Shortliffe E.H., 2012, COMPUTER BASED MED C	6	32	34	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	5					511	522		10.1109/TPAMI.1985.4767699	http://dx.doi.org/10.1109/TPAMI.1985.4767699			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AQH94	21869289				2022-12-18	WOS:A1985AQH9400003
J	KIM, CE				KIM, CE			DIGITAL DISKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	KIM, CE (corresponding author), WASHINGTON STATE UNIV,DEPT COMP SCI,PULLMAN,WA 99164, USA.							HARALICK RM, 1974, IEEE T SYST MAN CYB, VSMC4, P394, DOI 10.1109/TSMC.1974.5408463; HODES L, 1970, SIAM J APPL MATH, V19, P477, DOI 10.1137/0119048; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P618, DOI 10.1109/TPAMI.1982.4767315; KIM CE, 1981, IEEE T PATTERN ANAL, V3, P617, DOI 10.1109/TPAMI.1981.4767162; NAKAMURA A, 1982, TR1193 U MAR COMP SC; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SKLANSKY J, 1970, PATTERN RECOGN, V2, P3, DOI 10.1016/0031-3203(70)90037-3	8	32	32	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					372	374		10.1109/TPAMI.1984.4767531	http://dx.doi.org/10.1109/TPAMI.1984.4767531			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SR542	21869205				2022-12-18	WOS:A1984SR54200014
J	KUMAR, V; KANAL, LN				KUMAR, V; KANAL, LN			PARALLEL BRANCH-AND-BOUND FORMULATIONS FOR AND OR TREE-SEARCH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,CTR COMP SCI,COLLEGE PK,MD 20742; LNK CORP,SILVER SPRING,MD	University System of Maryland; University of Maryland College Park	KUMAR, V (corresponding author), UNIV TEXAS,CTR COMP SCI,AUSTIN,TX 78712, USA.							AKL SG, 1982, IEEE T PATTERN ANAL, V4, P192, DOI 10.1109/TPAMI.1982.4767226; [Anonymous], 1980, PRINCIPLES ARTIFICIA; BALAS E, 1968, OPER RES, V16, P442, DOI 10.1287/opre.16.2.442; BAUDET G, 1978, THESIS CARNEGIEMELLO; BERLINER H, 1979, ARTIF INTELL, V12, P23, DOI 10.1016/0004-3702(79)90003-1; CAMPBELL M, 1981, 818 U ALB DEP COMP S; ELDESSOUKI OI, 1980, IEEE T COMPUT, V29, P818, DOI 10.1109/TC.1980.1675681; FINKEL RA, 1982, ARTIF INTELL, V19, P89, DOI 10.1016/0004-3702(82)90022-4; FINKEL RA, 1983, IEEE T PATTERN ANAL, V5, P89, DOI 10.1109/TPAMI.1983.4767350; HALL PAV, 1973, COMMUN ACM, V16, P444, DOI 10.1145/362280.362302; IBARAKI T, 1977, J ACM, V24, P264, DOI 10.1145/322003.322010; IBARAKI T, 1978, INFORM CONTROL, V36, P1, DOI 10.1016/S0019-9958(78)90197-3; IMAI M, 1979, 6TH P INT JOINT C AR, P416; KANAL LN, 1979, IEEE T PATTERN ANAL, V1, P193, DOI 10.1109/TPAMI.1979.4766905; KANAL LN, 1981, AUG P IEEE COMP SOC, P452; KNUTH DE, 1975, ARTIF INTELL, V6, P293, DOI 10.1016/0004-3702(75)90019-3; KOHLER WH, 1974, J ACM, V21, P140, DOI 10.1145/321796.321808; KUMAR V, 1983, ARTIF INTELL, V21, P179, DOI 10.1016/S0004-3702(83)80009-5; KUMAR V, 1982, THESIS U MARYLAND CO; KUNG HT, 1976, ALGORITHMS COMPLEXIT, P153; LAI TH, 1983, 1983 P INT C PAR PRO, P183; LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699; MARSLAND TA, 1982, COMPUT SURV, V14, P533, DOI 10.1145/356893.356895; MITTEN LG, 1971, OPER RES, V19, P550; MITTEN LG, 1970, OPS RES, V18, P23; MOHAN J, 1983, 1983 P INT C PAR PRO, P191; NAU DS, 1984, ARTIFICIAL INTELL; Nilsson N.J., 1971, PROBLEM SOLVING METH; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; PEARL J, 1980, ARTIF INTELL, V14, P113, DOI 10.1016/0004-3702(80)90037-5; POHL I, 1972, 6TH P PRINC IEEE S I, P370; QUINN MJ, 1983, UPPER BOUND SPEEDUP; ROIZEN I, 1983, ARTIF INTELL, V21, P199, DOI 10.1016/S0004-3702(83)80010-1; SLAGLE JR, 1970, THEORETICAL APPROACH; STOCKMAN GC, 1979, ARTIF INTELL, V12, P179, DOI 10.1016/0004-3702(79)90016-X; STOCKMAN GC, 1983, IEEE T PATTERN ANAL, V5, P287, DOI 10.1109/TPAMI.1983.4767391; STOCKMAN GC, 1977, TR538 U MAR DEP COMP; SWAN RJ, 1977, AFIPS C P, V46, P637; WAH B, 1982, 8TH P ANN S COMP ARC, P239; WULF WA, 1972, 1972 AFIPS FALL JOIN	40	32	34	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					768	778		10.1109/TPAMI.1984.4767600	http://dx.doi.org/10.1109/TPAMI.1984.4767600			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499657				2022-12-18	WOS:A1984TX36100010
J	SAMET, H				SAMET, H			COMPUTING PERIMETERS OF REGIONS IN IMAGES REPRESENTED BY QUADTREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SAMET, H (corresponding author), UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742, USA.							DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; HUNTER GM, 1979, COMPUT VISION GRAPH, V10, P289, DOI 10.1016/0146-664X(79)90008-X; HUNTER GM, 1978, THESIS PRINCETON U P; KLINGER A, 1979, IEEE T PATTERN ANAL, V1, P50, DOI 10.1109/TPAMI.1979.4766875; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; KLINGER A, 1971, OPTIMIZING METHODS S; NAUR P, 1960, COMMUN ACM, V3, P299; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836	12	32	35	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					683	687		10.1109/TPAMI.1981.4767171	http://dx.doi.org/10.1109/TPAMI.1981.4767171			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MR996	21868990				2022-12-18	WOS:A1981MR99600010
J	Zhang, XS; Wan, F; Liu, C; Ji, XY; Ye, QX				Zhang, Xiaosong; Wan, Fang; Liu, Chang; Ji, Xiangyang; Ye, Qixiang			Learning to Match Anchors for Visual Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Detectors; Location awareness; Feature extraction; Training; Maximum likelihood estimation; Object detection; Visualization; Object detection; maximum likelihood estimation; learning to match; anchor-free detector; generalized linear model		Modern CNN-based object detectors assign anchors for ground-truth objects under the restriction of object-anchor Intersection-over-Union (IoU). In this study, we propose a learning-to-match (LTM) method to break IoU restriction, allowing objects to match anchors in a flexible manner. LTM updates hand-crafted anchor assignment to "free" anchor matching by formulating detector training in the Maximum Likelihood Estimation (MLE) framework. During the training phase, LTM is implemented by converting the detection likelihood to anchor matching loss functions which are plug-and-play. Minimizing the matching loss functions drives learning and selecting features which best explain a class of objects with respect to both classification and localization. LTM is extended from anchor-based detectors to anchor-free detectors, validating the general applicability of learnable object-feature matching mechanism for visual object detection. Experiments on MS COCO dataset demonstrate that LTM detectors consistently outperform counterpart detectors with significant margins. The last but not the least, LTM requires negligible computational cost in both training and inference phases as it does not involve any additional architecture or parameter. Code has been made publicly available.	[Zhang, Xiaosong; Liu, Chang; Ye, Qixiang] Sch Elect Elect & Commun Engn, Beijing 100049, Peoples R China; [Wan, Fang] Univ Chinese Acad Sci UCAS, Sch Comp Sci & Technol, Beijing 100049, Peoples R China; [Ji, Xiangyang] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Tsinghua University	Ye, QX (corresponding author), Sch Elect Elect & Commun Engn, Beijing 100049, Peoples R China.	zhangxiaosong18@mails.ucas.ac.cn; wanfang@ucas.ac.cn; liuchang615@mails.ucas.ac.cn; xyji@tsinghua.edu.cn; qxye@ucas.ac.cn		Liu, Chang/0000-0001-6747-0646; ye, qi xiang/0000-0003-1215-6259; Wan, Fang/0000-0002-8083-9257	National Natural Science Foundation of China (NSFC) [61836012, 61620106005, 61771447]; Strategic Priority Research Programme of Chinese Academy of Science [XDA27010303]; Post Doctoral Innovative Talent Support Program of China [119103S304]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Strategic Priority Research Programme of Chinese Academy of Science; Post Doctoral Innovative Talent Support Program of China	This work was supported in part by the National Natural Science Foundation of China (NSFC) under Grant 61836012, 61620106005, and 61771447, Strategic Priority Research Programme of Chinese Academy of Science under Grant XDA27010303, and Post Doctoral Innovative Talent Support Program of China under Grant 119103S304.	Agarwal S., 2018, ARXIV 180903193; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667; Fisher R.A., 1922, PHILOS T R SOC LON A, V222, P309, DOI [DOI 10.1098/RSTA.1922.0009, 10.1098/rsta.1922.0009]; Fu C. -Y., 2017, ARXIV17010665; Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Goldman E, 2019, PROC CVPR IEEE, P5222, DOI 10.1109/CVPR.2019.00537; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48; Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45; Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615; Lin T.-Y., 2017, CVPR, P2117, DOI DOI 10.48550/ARXIV.1612.03144; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4; Maron O, 1998, ADV NEUR IN, V10, P570; McCullagh P., 1989, GEN LINEAR MODELS, V2nd; Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890; Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075; Shao S, 2018, ARXIV180500123; Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972; Vu T, 2019, ADV NEUR IN, V32; Wan F, 2019, PROC CVPR IEEE, P2194, DOI 10.1109/CVPR.2019.00230; Wan F, 2019, IEEE T PATTERN ANAL, V41, P2395, DOI 10.1109/TPAMI.2019.2898858; Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Yang T, 2018, ADV NEUR IN, V31; Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975; Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442; Zhang XS, 2019, ADV NEUR IN, V32; Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644; Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094; Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283; Zou Z., 2019, ARXIV190505055V2, P1	44	31	31	28	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3096	3109		10.1109/TPAMI.2021.3050494	http://dx.doi.org/10.1109/TPAMI.2021.3050494			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33434120				2022-12-18	WOS:000803117500023
J	Zhang, CQ; Cui, YJ; Han, ZB; Zhou, JT; Fu, HZ; Hu, QH				Zhang, Changqing; Cui, Yajie; Han, Zongbo; Zhou, Joey Tianyi; Fu, Huazhu; Hu, Qinghua			Deep Partial Multi-View Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Correlation; Encoding; Training; Image reconstruction; Data models; Testing; Neural networks; Multi-view learning; cross partial multi-view networks; latent representation	FRAMEWORK	Although multi-view learning has made significant progress over the past few decades, it is still challenging due to the difficulty in modeling complex correlations among different views, especially under the context of view missing. To address the challenge, we propose a novel framework termed Cross Partial Multi-View Networks (CPM-Nets), which aims to fully and flexibly take advantage of multiple partial views. We first provide a formal definition of completeness and versatility for multi-view representation and then theoretically prove the versatility of the learned latent representations. For completeness, the task of learning latent multi-view representation is specifically translated to a degradation process by mimicking data transmission, such that the optimal tradeoff between consistency and complementarity across different views can be implicitly achieved. Equipped with adversarial strategy, our model stably imputes missing views, encoding information from all views for each sample to be encoded into latent representation to further enhance the completeness. Furthermore, a nonparametric classification loss is introduced to produce structured representations and prevent overfitting, which endows the algorithm with promising generalization under view-missing cases. Extensive experimental results validate the effectiveness of our algorithm over existing state of the arts for classification, representation learning and data imputation.	[Zhang, Changqing; Cui, Yajie; Han, Zongbo; Hu, Qinghua] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China; [Zhou, Joey Tianyi] ASTAR, Inst High Performance Comp IHIC, Singapore 138632, Singapore; [Fu, Huazhu] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates	Tianjin University; Agency for Science Technology & Research (A*STAR)	Zhou, JT (corresponding author), ASTAR, Inst High Performance Comp IHIC, Singapore 138632, Singapore.	zhangchangqing@tju.edu.cn; cuiyajie@tju.edu.cn; zongbo@tju.edu.cn; zhouty@ihpc.a-star.edu.sg; hzfu@ieee.org; huqinghua@tju.edu.cn	Fu, Huazhu/A-1411-2014	Fu, Huazhu/0000-0002-9702-5524	National Key Research and Development Program of China [2019YFB2101901]; National Natural Science Foundation of China [61976151, 61925602, 61732011]; Natural Science Foundation of Tianjin of China [19JCYBJC15200]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Tianjin of China(Natural Science Foundation of Tianjin)	This work was supported in part by the National Key Research and Development Program of China (No. 2019YFB2101901), the National Natural Science Foundation of China (No. 61976151, 61925602 and 61732011), and the Natural Science Foundation of Tianjin of China (No. 19JCYBJC15200).	Akaho Shotaro, 2006, CS0609071 ARXIV; Andrew Galen, 2013, ICML; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Bo TH, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh026; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Cai L, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1158, DOI 10.1145/3219819.3219963; Castrejon L, 2016, PROC CVPR IEEE, P2940, DOI 10.1109/CVPR.2016.321; Chen XH, 2012, PATTERN RECOGN, V45, P2005, DOI 10.1016/j.patcog.2011.11.008; Chung Y.-A., 2018, PROC INT C NEURAL IN, P7365; Dhillon Paramveer, 2011, ADV NEURAL INFORM PR, V24, P199; Enders C. K., 2010, APPL MISSING DATA AN; Gong XL, 2019, AAAI CONF ARTIF INTE, P102; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guo JW, 2019, IEEE ACCESS, V7, P40359, DOI 10.1109/ACCESS.2019.2905264; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Jornsten R, 2005, BIOINFORMATICS, V21, P4155, DOI 10.1093/bioinformatics/bti638; Kim H, 2006, BIOINFORMATICS, V22, P1410, DOI 10.1093/bioinformatics/btk053; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kumar A., 2011, P 28 INT C MACH LEAR, P393, DOI DOI 10.5555/3104482.3104532; Kumar Abhishek, 2011, NEURIPS, P2, DOI DOI 10.5555/2986459.2986617; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Larsen ABL, 2016, PR MACH LEARN RES, V48; Le L, 2018, ADV NEUR IN, V31; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406; Li A, 2019, IEEE I CONF COMP VIS, P8099, DOI 10.1109/ICCV.2019.00819; Li SY, 2014, AAAI CONF ARTIF INTE, P1968; Liu Ming-Yu, 2017, NIPS; [刘威辰 Liu Weichen], 2017, [空军工程大学学报. 自然科学版, Journal of Air Force Engineering University. Natural Science Edition], V18, P1; Liu XW, 2019, IEEE T PATTERN ANAL, V41, P2410, DOI 10.1109/TPAMI.2018.2879108; Mazumder R, 2010, J MACH LEARN RES, V11, P2287; Mingxia Liu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P308, DOI 10.1007/978-3-319-46720-7_36; Ngiam Jiquan, 2011, ICML, DOI DOI 10.5555/3104482.3104569; Oba S, 2003, BIOINFORMATICS, V19, P2088, DOI 10.1093/bioinformatics/btg287; Quoc Le, 2014, P 31 INT C MACHINE L, V32, P1188; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Shang C, 2017, IEEE INT CONF BIG DA, P766, DOI 10.1109/BigData.2017.8257992; Simonyan K., 2015, INT C LEARN REPR ICL; Snell J., 2017, ADV NEURAL INFORM PR, P4077; Tran L., 2017, CVPR; Trivedi A., 2010, P INT C NEUR INF PRO, V224; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Wah C., 2011, TECH REP; Wang W., 2016, DEEP VARIATIONAL CAN; Wang WR, 2015, PR MACH LEARN RES, V37, P1083; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; White Martha, 2012, ADV NEURAL INFORM PR, P1682; Xu C., 2013, ARXIV13045634; Xue Z, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4026; Yang Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2998; Yang ZY, 2019, IEEE T IMAGE PROCESS, V28, P5147, DOI 10.1109/TIP.2019.2913096; Yuan Lei, 2012, KDD, P1149; Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461; Zhang CQ, 2017, IEEE T IMAGE PROCESS, V26, P648, DOI 10.1109/TIP.2016.2627806; Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185; Zhang H, 2017, PROC CVPR IEEE, P2925, DOI 10.1109/CVPR.2017.312; [张华 ZHANG Hua], 2011, [高分子通报, Polymer Bulletin], P1; Zhao HD, 2017, AAAI CONF ARTIF INTE, P2921; Zhou JTY, 2019, J MACH LEARN RES, V20; Zhou JT, 2019, ARTIF INTELL, V275, P310, DOI 10.1016/j.artint.2019.06.001	60	31	32	17	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2402	2415		10.1109/TPAMI.2020.3037734	http://dx.doi.org/10.1109/TPAMI.2020.3037734			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33180720	Green Submitted			2022-12-18	WOS:000792921400015
J	Wang, Q; He, X; Jiang, X; Li, XL				Wang, Qi; He, Xiang; Jiang, Xu; Li, Xuelong			Robust Bi-Stochastic Graph Regularized Matrix Factorization for Data Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Matrix factorization; bi-stochastic graph; data clustering; robustness	TUTORIAL	Data clustering, which is to partition the given data into different groups, has attracted much attention. Recently various effective algorithms have been developed to tackle the task. Among these methods, non-negative matrix factorization (NMF) has been demonstrated to be a powerful tool. However, there are still some problems. First, the standard NMF is sensitive to noises and outliers. Although l(2,1) norm based NMF improves the robustness, it is still affected easily by large noises. Second, for most graph regularized NMF, the performance highly depends on the initial similarity graph. Third, many graph-based NMF models perform the graph construction and matrix factorization in two separated steps. Thus the learned graph structure may not be optimal. To overcome the above drawbacks, we propose a robust bi-stochastic graph regularized matrix factorization (RBSMF) framework for data clustering. Specifically, we present a general loss function, which is more robust than the commonly used L-2 and L-1 functions. Besides, instead of keeping the graph fixed, we learn an adaptive similarity graph. Furthermore, the graph updating and matrix factorization are processed simultaneously, which can make the learned graph more appropriate for clustering. Extensive experiments have shown the proposed RBSMF outperforms other state-of-the-art methods.	[Wang, Qi; He, Xiang; Jiang, Xu; Li, Xuelong] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China; [Wang, Qi; He, Xiang; Jiang, Xu; Li, Xuelong] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University	Li, XL (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Li, XL (corresponding author), Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.	crabwq@gmail.com; xianghe@mail.nwpu.edu.cn; jx19961023@mail.nwpu.edu.cn; xuelong_li@nwpu.edu.cn			National Key R&D Program of China [2017YFB1002202]; National Natural Science Foundation of China [U1864204, 61773316, U1801262, 61871470]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Key R&D Program of China under Grant 2017YFB1002202, National Natural Science Foundation of China under Grant U1864204, 61773316, U1801262, and 61871470.	Belkin M, 2002, ADV NEUR IN, V14, P585; Ben Harnza A, 2006, IEEE T SIGNAL PROCES, V54, P3637, DOI 10.1109/TSP.2006.879282; Bertsekas D.P., 2019, REINFORCEMENT LEARNI; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; CHAN PK, 1994, IEEE T COMPUT AID D, V13, P1088, DOI 10.1109/43.310898; Chen ML, 2017, INT CONF ACOUST SPEE, P1378, DOI 10.1109/ICASSP.2017.7952382; Dheeru D., 2019, UCI MACHINE LEARNING; Ding C, 2005, SIAM PROC S, P606; He XF, 2004, ADV NEUR IN, V16, P153; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hestenes M. R., 1969, Journal of Optimization Theory and Applications, V4, P303, DOI 10.1007/BF00927673; Huang J, 2014, ACM T KNOWL DISCOV D, V8, DOI 10.1145/2601434; Huang SD, 2017, IEEE IJCNN, P486, DOI 10.1109/IJCNN.2017.7965893; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Kong D., 2011, P 20 ACM INT C INFOR, P673, DOI [10.1145/2063576.2063676, DOI 10.1145/2063576.2063676]; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee DD, 2001, ADV NEUR IN, V13, P556; Li SZ, 2001, PROC CVPR IEEE, P207; Li Xuelong, 2017, IEEE Trans Cybern, V47, P3840, DOI 10.1109/TCYB.2016.2585355; Liang Xiong, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P844, DOI 10.1109/ICDM.2011.52; Lijun Zhang, 2011, Frontiers of Electrical and Electronic Engineering in China, V6, P192, DOI 10.1007/s11460-011-0128-0; Lin Z., 2010, ARXIV10095055, DOI DOI 10.1016/J.JSB.2012.10.010; Luo X, 2016, IEEE T NEUR NET LEAR, V27, P579, DOI 10.1109/TNNLS.2015.2415257; Luo X, 2016, IEEE T NEUR NET LEAR, V27, P524, DOI 10.1109/TNNLS.2015.2412037; Luo X, 2014, IEEE T IND INFORM, V10, P1273, DOI 10.1109/TII.2014.2308433; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Neumann, 1950, FUNCTIONAL OPERATORS, V22; Nie FP, 2016, AAAI CONF ARTIF INTE, P1969; Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726; Peng C, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3003730; Peng SY, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351104; Shang FH, 2012, PATTERN RECOGN, V45, P2237, DOI 10.1016/j.patcog.2011.12.015; Shen B, 2014, IEEE IMAGE PROC, P5282, DOI 10.1109/ICIP.2014.7026069; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tao DP, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2987379; Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang F, 2012, KNOWL INF SYST, V32, P351, DOI 10.1007/s10115-011-0433-1; Wang XQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1245, DOI 10.1145/2939672.2939805; Zass R., 2007, ADV NEURAL INFORM PR, P1569; Zhang ZY, 2013, IEEE T PATTERN ANAL, V35, P1717, DOI 10.1109/TPAMI.2012.274; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2; Zong LL, 2017, NEURAL NETWORKS, V88, P74, DOI 10.1016/j.neunet.2017.02.003; Zunyan Xiong, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P348, DOI 10.1007/978-3-319-06605-9_29	45	31	31	33	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					390	403		10.1109/TPAMI.2020.3007673	http://dx.doi.org/10.1109/TPAMI.2020.3007673			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750807				2022-12-18	WOS:000728561300028
J	Oberweger, M; Wohlhart, P; Lepetit, V				Oberweger, Markus; Wohlhart, Paul; Lepetit, Vincent			Generalized Feedback Loop for Joint Hand-Object Pose Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Pose estimation; Solid modeling; Optimization; Feedback loop; Training data; Data models; 3D hand pose estimation; 3D object pose estimation; feedback loop; hand-object manipulation	MOTION	We propose an approach to estimating the 3D pose of a hand, possibly handling an object, given a depth image. We show that we can correct the mistakes made by a Convolutional Neural Network trained to predict an estimate of the 3D pose by using a feedback loop. The components of this feedback loop are also Deep Networks, optimized using training data. This approach can be generalized to a hand interacting with an object. Therefore, we jointly estimate the 3D pose of the hand and the 3D pose of the object. Our approach performs en-par with state-of-the-art methods for 3D hand pose estimation, and outperforms state-of-the-art methods for joint hand-object pose estimation when using depth images only. Also, our approach is efficient as our implementation runs in real-time on a single GPU.	[Oberweger, Markus; Wohlhart, Paul; Lepetit, Vincent] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria; [Wohlhart, Paul] Alphabet Inc, X, Mountain View, CA 94043 USA; [Lepetit, Vincent] Univ Bordeaux, Lab Bordelais Rech Informat, F-33000 Bordeaux, France	Graz University of Technology; UDICE-French Research Universities; Universite de Bordeaux	Oberweger, M (corresponding author), Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria.	oberweger@icg.tugraz.at; pwohlhart@gmail.com; vincent.lepetit@u-bordeaux.fr		Wohlhart, Paul/0000-0002-3669-2809				Ballan L, 2012, LECT NOTES COMPUT SC, V7577, P640, DOI 10.1007/978-3-642-33783-3_46; Bergstra J., 2010, P PYTH SCI COMP C SC, V4, P1, DOI DOI 10.25080/MAJORA-92BF1922-003; Bishop CM, 2006, PATTERN RECOGNITION; Bouchacourt D., 2016, NIPS, P352; Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chang Angel X., 2015, ARXIV151203012CSGR P; Chen XL, 2018, NEUROCOMPUTING, V315, P18, DOI 10.1016/j.neucom.2018.05.018; Crivellaro A, 2015, IEEE I CONF COMP VIS, P4391, DOI 10.1109/ICCV.2015.499; de La Gorce M, 2011, IEEE T PATTERN ANAL, V33, P1793, DOI 10.1109/TPAMI.2011.33; Deng X, 2017, ARXIV170402224; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Drost Bertram, 2010, 2010 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2010.5540108; Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012; Ge LH, 2019, IEEE T PATTERN ANAL, V41, P956, DOI 10.1109/TPAMI.2018.2827052; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goudie D, 2017, IEEE INT CONF AUTOMA, P406, DOI 10.1109/FG.2017.58; Guo HK, 2017, IEEE IMAGE PROC, P4512; Gupta S, 2015, PROC CVPR IEEE, P4731, DOI 10.1109/CVPR.2015.7299105; Hamer H, 2009, IEEE I CONF COMP VIS, P1475, DOI 10.1109/ICCV.2009.5459282; Han SC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201399; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jain A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P1, DOI 10.1109/ICICICT.2014.6781242; KABSCH W, 1976, ACTA CRYSTALLOGR A, V32, P922, DOI 10.1107/S0567739476001873; Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61; Keskin C, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130391; Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437; Kingma D.P, P 3 INT C LEARNING R; Krull A, 2015, IEEE I CONF COMP VIS, P954, DOI 10.1109/ICCV.2015.115; Kulkarni T. D., 2014, APPROX BAYESIAN COMP, P1; Kulkarni TD, 2015, ADV NEUR IN, V28; Kuznetsova A, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P83, DOI 10.1109/ICCVW.2013.18; Kyriazis N, 2014, PROC CVPR IEEE, P3430, DOI 10.1109/CVPR.2014.438; Li YK, 2018, IEEE INT C BIOINFORM, P683, DOI [10.1109/bibm.2018.8621574, 10.1109/BIBM.2018.8621574]; Lin CH, 2017, PROC CVPR IEEE, P2252, DOI 10.1109/CVPR.2017.242; LIU S, 2015, PROC CVPR IEEE, P1419, DOI DOI 10.1109/CVPR.2015.7298748; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Madadi M, 2017, IEEE INT CONF AUTOMA, P230, DOI 10.1109/FG.2017.37; Melax S., 2013, GRAPHICS INTERFACE 2, P63, DOI DOI 10.1145/2448196.2448232; Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013; Mueller F, 2017, IEEE INT CONF COMP V, P1284, DOI 10.1109/ICCVW.2017.82; Nair V, 2008, LECT NOTES COMPUT SC, V5163, P971, DOI 10.1007/978-3-540-87536-9_99; Neverova N, 2017, COMPUT VIS IMAGE UND, V164, P56, DOI 10.1016/j.cviu.2017.10.006; Obermaier M, 2018, COMMUN RES, V45, P1031, DOI 10.1177/0093650215617505; Oberweger M, 2017, IEEE INT CONF COMP V, P585, DOI 10.1109/ICCVW.2017.75; Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379; Oikonomidis I, 2012, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2012.6247885; Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101; Oikonomidis I, 2011, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2011.6126483; Panteleris P, 2018, IEEE WINT CONF APPL, P436, DOI 10.1109/WACV.2018.00054; Panteleris Paschalis, 2015, P BRIT MACH VIS C 20; Plankers R, 2003, IEEE T PATTERN ANAL, V25, P1182, DOI 10.1109/TPAMI.2003.1227995; QIAN C, 2014, PROC CVPR IEEE, P1106, DOI DOI 10.1109/CVPR.2014.145; Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413; Rogez G, 2015, IEEE I CONF COMP VIS, P3889, DOI 10.1109/ICCV.2015.443; Romero J, 2010, IEEE INT CONF ROBOT, P458, DOI 10.1109/ROBOT.2010.5509753; Rosales R, 2006, INT J COMPUT VISION, V67, P251, DOI 10.1007/s11263-006-5165-4; Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10; Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179; Sridhar S, 2016, LECT NOTES COMPUT SC, V9906, P294, DOI 10.1007/978-3-319-46475-6_19; Sridhar S, 2015, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2015.7298941; Sridhar S, 2013, IEEE I CONF COMP VIS, P2456, DOI 10.1109/ICCV.2013.305; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683; Tagliasacchi A, 2015, COMPUT GRAPH FORUM, V34, P101, DOI 10.1111/cgf.12700; Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490; Tang DH, 2013, IEEE I CONF COMP VIS, P3224, DOI 10.1109/ICCV.2013.400; Tang Y., 2014, ADV NEURAL INFORM PR, P1808; Taylor J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925965; Tkach Anastasia, 2017, ACM T GRAPHIC, V36, P6; Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500; Tzionas D, 2016, INT J COMPUT VISION, V118, P172, DOI 10.1007/s11263-016-0895-4; Tzionas D, 2015, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2015.90; Tzionas D, 2014, LECT NOTES COMPUT SC, V8753, P277, DOI 10.1007/978-3-319-11752-2_22; Wagner D, 2008, INT SYM MIX AUGMENT, P121, DOI 10.1109/ISMAR.2008.4637337; Wan Chengde, 2017, CVPR; Wang R., 2011, P 24 ANN ACM S US IN, P549, DOI DOI 10.1145/2047196.2047269; Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930; Xiang Yu, 2018, POSECNN CONVOLUTIONA, V5, P8, DOI [10.15607/RSS.2018.XIV.019, DOI 10.15607/RSS.2018.XIV.019]; Xu C, 2017, INT J COMPUT VISION, V123, P454, DOI 10.1007/s11263-017-0998-6; Xu C, 2013, IEEE I CONF COMP VIS, P3456, DOI 10.1109/ICCV.2013.429; Zamir AR, 2017, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2017.196; Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474; Zhou X., 2016, ARXIV160606854; Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525	87	31	31	6	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1898	1912		10.1109/TPAMI.2019.2907951	http://dx.doi.org/10.1109/TPAMI.2019.2907951			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30932832	Green Submitted			2022-12-18	WOS:000545415400007
J	Sulam, J; Aberdam, A; Beck, A; Elad, M				Sulam, Jeremias; Aberdam, Aviad; Beck, Amir; Elad, Michael			On Multi-Layer Basis Pursuit, Efficient Algorithms and Convolutional Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mathematical model; Convolution; Convolutional codes; Iterative algorithms; Dictionaries; Analytical models; Multi-layer convolutional sparse coding; network unfolding; recurrent neural networks; iterative shrinkage algorithms	LINEAR INVERSE PROBLEMS; THRESHOLDING ALGORITHM; SPARSE REPRESENTATION; DICTIONARIES; SHRINKAGE; RECOVERY	Parsimonious representations are ubiquitous in modeling and processing information. Motivated by the recent Multi-Layer Convolutional Sparse Coding (ML-CSC) model, we herein generalize the traditional Basis Pursuit problem to a multi-layer setting, introducing similar sparse enforcing penalties at different representation layers in a symbiotic relation between synthesis and analysis sparse priors. We explore different iterative methods to solve this new problem in practice, and we propose a new Multi-Layer Iterative Soft Thresholding Algorithm (ML-ISTA), as well as a fast version (ML-FISTA). We show that these nested first order algorithms converge, in the sense that the function value of near-fixed points can get arbitrarily close to the solution of the original problem. We further show how these algorithms effectively implement particular recurrent convolutional neural networks (CNNs) that generalize feed-forward ones without introducing any parameters. We present and analyze different architectures resulting from unfolding the iterations of the proposed pursuit algorithms, including a new Learned ML-ISTA, providing a principled way to construct deep recurrent CNNs. Unlike other similar constructions, these architectures unfold a global pursuit holistically for the entire network. We demonstrate the emerging constructions in a supervised learning setting, consistently improving the performance of classical CNNs while maintaining the number of parameters constant.	[Sulam, Jeremias] Johns Hopkins Univ, Dept Biomed Engn, Math Inst Data Sci MINDS, Baltimore, MD 21218 USA; [Aberdam, Aviad; Elad, Michael] Technion Israel Inst Technol, Dept Elect Engn & Comp Sci, IL-3200003 Haifa, Israel; [Beck, Amir] Tel Aviv Univ, Sch Math Sci, IL-6997801 Tel Aviv, Israel	Johns Hopkins University; Technion Israel Institute of Technology; Tel Aviv University	Sulam, J (corresponding author), Johns Hopkins Univ, Dept Biomed Engn, Math Inst Data Sci MINDS, Baltimore, MD 21218 USA.	jsulam1@jhu.edu; aaberdam@campus.technion.ac.il; becka@tauex.tau.ac.il; elad@cs.technion.ac.il	, Miki/AAH-4640-2019	Elad, Michael/0000-0001-8131-6928; Aberdam, Aviad/0000-0003-0084-5022; Sulam, Jeremias/0000-0003-0946-1957	Israel Science Foundation (ISF) [335/18]; Israel Science Foundation [1821/16]	Israel Science Foundation (ISF)(Israel Science Foundation); Israel Science Foundation(Israel Science Foundation)	The research leading to these results has received funding from the Israel Science Foundation (ISF) grant no. 335/18. The work of Amir Beck was partially supported by the Israel Science Foundation 1821/16. J. Sulam and A. Aberdam contributed equally to this work.	Aberdam A, 2019, SIAM J MATH DATA SCI, V1, P46, DOI 10.1137/18M1183352; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2010, P INT C MACH LEARN; Beck A., 2017, MOS SIAM SERIES OPTI; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bertsekas D.P., 2019, REINFORCEMENT LEARNI; Bioucas-Dias JM, 2008, IEEE IMAGE PROC, P685, DOI 10.1109/ICIP.2008.4711847; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Candes E.J., 2000, CURVELETS SURPRISING; Candes EJ, 2011, APPL COMPUT HARMON A, V31, P59, DOI 10.1016/j.acha.2010.10.002; Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498; Chen G, 1993, SIAM J OPTIMIZ, V3, P538, DOI 10.1137/0803026; CHEN X, 2018, P 32 INT C INF PROC, P9079, DOI DOI 10.5555/3327546.3327581; Combettes PL, 2011, SPRINGER SER OPTIM A, V49, P185, DOI 10.1007/978-1-4419-9569-8_10; Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Giryes R, 2018, IEEE T SIGNAL PROCES, V66, P1676, DOI 10.1109/TSP.2018.2791945; Haeffele BD, 2014, PR MACH LEARN RES, V32, P2007; Henaff M., 2011, ISMIR, V11, P2011; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang YX, 2007, TRANSP RES RECORD, P1, DOI 10.3141/2022-01; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kavukcuoglu Koray, 2010, ADV NEURAL INFORM PR, V23, P1090; Kutyniok G, 2012, APPL NUMER HARMON AN, P1, DOI 10.1007/978-0-8176-8316-0; Lin JH, 2014, APPL COMPUT HARMON A, V37, P126, DOI 10.1016/j.acha.2013.10.003; Liu J., 2018, P INT C LEARN REPR; Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156; Mairal J, 2010, J MACH LEARN RES, V11, P19; Moreau T., 2017, P INT C LEARN REPR; Murdock C., 2018, P EUR C COMP VIS ECC, P820; Nguyen T., 2016, ARXIV161201942; Papyan V, 2018, IEEE SIGNAL PROC MAG, V35, P72, DOI 10.1109/MSP.2018.2820224; Papyan V, 2017, J MACH LEARN RES, V18, P1; Patel AB, 2016, ADV NEUR IN, V29; Sulam J, 2018, IEEE T SIGNAL PROCES, V66, P4090, DOI 10.1109/TSP.2018.2846226; Sulam J, 2016, IEEE T SIGNAL PROCES, V64, P3180, DOI 10.1109/TSP.2016.2540599; Sun XX, 2018, IEEE IMAGE PROC, P346, DOI 10.1109/ICIP.2018.8451701; Tibshirani R., 2015, STAT LEARNING SPARSI; Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x; Tibshirani RJ, 2011, ANN STAT, V39, P1335, DOI 10.1214/11-AOS878; Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957; Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196	50	31	32	6	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1968	1980		10.1109/TPAMI.2019.2904255	http://dx.doi.org/10.1109/TPAMI.2019.2904255			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30869611	Green Submitted			2022-12-18	WOS:000545415400012
J	Shen, ZQ; Liu, Z; Li, JG; Jiang, YG; Chen, YR; Xue, XY				Shen, Zhiqiang; Liu, Zhuang; Li, Jianguo; Jiang, Yu-Gang; Chen, Yurong; Xue, Xiangyang			Object Detection from Scratch with Deep Supervision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; Detectors; Task analysis; Training; Computational modeling; Linear programming; Data models; Object detection; deeply supervised networks; learning from scratch; densely connected layers		In this paper, we propose Deeply Supervised Object Detectors (DSOD), an object detection framework that can be trained from scratch. Recent advances in object detection heavily depend on the off-the-shelf models pre-trained on large-scale classification datasets like ImageNet and OpenImage. However, one problem is that adopting pre-trained models from classification to detection task may incur learning bias due to the different objective function and diverse distributions of object categories. Techniques like fine-tuning on detection task could alleviate this issue to some extent but are still not fundamental. Furthermore, transferring these pre-trained models across discrepant domains will be more difficult (e.g., from RGB to depth images). Thus, a better solution to handle these critical problems is to train object detectors from scratch, which motivates our proposed method. Previous efforts on this direction mainly failed by reasons of the limited training data and naive backbone network structures for object detection. In DSOD, we contribute a set of design principles for learning object detectors from scratch. One of the key principles is the deep supervision, enabled by layer-wise dense connections in both backbone networks and prediction layers, plays a critical role in learning good detectors from scratch. After involving several other principles, we build our DSOD based on the single-shot detection framework (SSD). We evaluate our method on PASCAL VOC 2007, 2012 and COCO datasets. DSOD achieves consistently better results than the state-of-the-art methods with much more compact models. Specifically, DSOD outperforms baseline method SSD on all three benchmarks, while requiring only 1/2 parameters. We also observe that DSOD can achieve comparable/slightly better results than Mask RCNN [1] + FPN [2] (under similar input size) with only 1/3 parameters, using no extra data or pre-trained models.	[Shen, Zhiqiang; Jiang, Yu-Gang; Xue, Xiangyang] Fudan Univ, Sch Comp Sci, Shanghai 200086, Peoples R China; [Shen, Zhiqiang] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA; [Liu, Zhuang] Univ Calif Berkeley, Berkeley Artificial Intelligence Res, Berkeley, CA 94704 USA; [Li, Jianguo; Chen, Yurong] Intel Labs China, Beijing 100080, Peoples R China; [Jiang, Yu-Gang] Jilian Technol Grp Video, Shanghai, Peoples R China	Fudan University; Carnegie Mellon University; University of California System; University of California Berkeley; Intel Corporation	Jiang, YG (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai 200086, Peoples R China.	zhiqians@andrew.cmu.edu; zhuangl@berkeley.edu; jianguo.li@intel.com; ygj@fudan.edu.cn; yurong.chen@intel.com; xyxue@fudan.edu.cn		Xue, Xiangyang/0000-0002-4897-9209; Chen, Yurong/0000-0001-9333-1746; Shen, Zhiqiang/0000-0002-4560-5092	NSF China [61622204, 61572134, 16JC1420400, 2017SHZDZX01, 2018SHZDZX01]; ZJLab	NSF China(National Natural Science Foundation of China (NSFC)); ZJLab	This work was supported in part by two projects from NSF China (61622204, 61572134), one STCSM project (16JC1420400), and two Shanghai Municipal Science and Technology Major Projects (2017SHZDZX01, 2018SHZDZX01) and ZJLab.	Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; [Anonymous], 2019, INT C LEARN REPR; [Anonymous], 2015, ICLR; [Anonymous], ARXIV160808021; [Anonymous], P BRIT MACH VIS C; [Anonymous], 2016, OPENIMAGES PUBLIC DA; Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314; Bosquet B., 2018, BMVC, P253; Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Glorot X., 2010, PROC MACH LEARN RES, P249; Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309; Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He Kaiming, 2018, ARXIV181108883; Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25; Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jegou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557; Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98; Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194; Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24; Liu W, 2016, INT WORKS EARTH OB; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Peng C, 2018, PROC CVPR IEEE, P6181, DOI 10.1109/CVPR.2018.00647; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shen Z., 2017, ARXIV PREPRINT ARXIV; Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212; Shen ZQ, 2017, PROC CVPR IEEE, P5159, DOI 10.1109/CVPR.2017.548; Simonyan K, 2015, 3 INT C LEARN REPR I; Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sun YP, 2015, ADV DIFFER EQU-NY, P1, DOI 10.1186/s13662-015-0433-7; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276; Wang R. J, 2018, NIPS; Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu HY, 2018, LECT NOTES COMPUT SC, V11215, P827, DOI 10.1007/978-3-030-01252-6_49; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442; Zhou K, 2016, DESTECH TRANS COMP; Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062; Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094	75	31	35	7	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					398	412		10.1109/TPAMI.2019.2922181	http://dx.doi.org/10.1109/TPAMI.2019.2922181			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	31199252	Bronze, Green Submitted			2022-12-18	WOS:000508386100012
J	Akhtar, N; Mian, A				Akhtar, Naveed; Mian, Ajmal			Hyperspectral Recovery from RGB Images using Gaussian Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hyperspectral imaging; Gaussian processes; Cameras; Training; Color; Hyperspectral imaging; spectral recovery; gaussian process	IMAGING SPECTROMETER; SPECTRAL REFLECTANCE; SURFACE; RECONSTRUCTION; COLOR	We propose to recover spectral details from RGB images of known spectral quantization by modeling natural spectra under Gaussian Processes and combining them with the RGB images. Our technique exploits Process Kernels to model the relative smoothness of reflectance spectra, and encourages non-negativity in the resulting signals for better estimation of the reflectance values. The Gaussian Processes are inferred in sets using clusters of spatio-spectrally correlated hyperspectral training patches. Each set is transformed to match the spectral quantization of the test RGB image. We extract overlapping patches from the RGB image and match them to the hyperspectral training patches by spectrally transforming the latter. The RGB patches are encoded over the transformed Gaussian Processes related to those hyperspectral patches and the resulting image is constructed by combining the codes with the original processes. Our approach infers the desired Gaussian Processes under a fully Bayesian model inspired by Beta-Bernoulli Process, for which we also present the inference procedure. A thorough evaluation using three hyperspectral datasets demonstrates the effective extraction of spectral details from RGB images by the proposed technique.	[Akhtar, Naveed; Mian, Ajmal] Univ Western Australia, Dept Comp Sci & Software Engn M002, 35 Stirling Highway, Crawley, WA 6009, Australia	University of Western Australia	Akhtar, N (corresponding author), Univ Western Australia, Dept Comp Sci & Software Engn M002, 35 Stirling Highway, Crawley, WA 6009, Australia.	naveed.akhtar@uwa.edu.au; ajmal.mian@uwa.edu.au	AKHTAR, NAVEED/AAT-1283-2020	AKHTAR, NAVEED/0000-0003-3406-673X; Mian, Ajmal/0000-0002-5206-3842	ARC [DP160101458]	ARC(Australian Research Council)	This work is supported by ARC grant DP160101458.	Aeschbacher J, 2017, IEEE INT CONF COMP V, P471, DOI 10.1109/ICCVW.2017.63; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Akhtar N, 2018, IEEE T NEUR NET LEAR, V29, P4038, DOI 10.1109/TNNLS.2017.2742528; Akhtar N, 2016, LECT NOTES COMPUT SC, V9907, P103, DOI 10.1007/978-3-319-46487-9_7; Akhtar N, 2015, PROC CVPR IEEE, P3631, DOI 10.1109/CVPR.2015.7298986; Akhtar N, 2015, IEEE T GEOSCI REMOTE, V53, P2157, DOI 10.1109/TGRS.2014.2356556; Akhtar N, 2014, LECT NOTES COMPUT SC, V8695, P63, DOI 10.1007/978-3-319-10584-0_5; Alvarez-Gila A, 2017, IEEE INT CONF COMP V, P480, DOI 10.1109/ICCVW.2017.64; [Anonymous], P ADV NEUR INF PROC; [Anonymous], P AS C COMP VIS; [Anonymous], VIS SCI PHOTONS PHEN; [Anonymous], 2008, CUCS06108 COL U; Arad B, 2016, LECT NOTES COMPUT SC, V9911, P19, DOI 10.1007/978-3-319-46478-7_2; Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672; Bishop C.M, 2006, PATTERN RECOGN; Brady DJ, 2006, PROC SPIE, V6246, DOI 10.1117/12.667605; Chakrabarti A, 2011, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2011.5995660; Charles AS, 2011, IEEE J-STSP, V5, P963, DOI 10.1109/JSTSP.2011.2149497; Chi C, 2010, INT J COMPUT VISION, V86, P140, DOI 10.1007/s11263-008-0176-y; COHEN J, 1964, PSYCHON SCI, V1, P369, DOI 10.3758/BF03342963; DESCOUR M, 1995, APPL OPTICS, V34, P4817, DOI 10.1364/AO.34.004817; Dian RW, 2017, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2017.411; DZMURA M, 1992, J OPT SOC AM A, V9, P490, DOI 10.1364/JOSAA.9.000490; Edelman GJ, 2012, FORENSIC SCI INT, V223, P28, DOI 10.1016/j.forsciint.2012.09.012; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Fletcher-Holmes DW, 2005, J OPT A-PURE APPL OP, V7, pS298, DOI 10.1088/1464-4258/7/6/007; Foster DH, 2006, J OPT SOC AM A, V23, P2359, DOI 10.1364/JOSAA.23.002359; Galliani Silvano, 2017, ARXIV170309470; Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013; Goel M, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P145, DOI 10.1145/2750858.2804282; GOETZ AFH, 1985, SCIENCE, V228, P1147, DOI 10.1126/science.228.4704.1147; Green RO, 1998, REMOTE SENS ENVIRON, V65, P227, DOI 10.1016/S0034-4257(98)00064-9; Han JY, 2003, ACM T GRAPHIC, V22, P741, DOI 10.1145/882262.882341; Hardeberg JY, 2002, CGIV'2002: FIRST EUROPEAN CONFERENCE ON COLOUR IN GRAPHICS, IMAGING, AND VISION, CONFERENCE PROCEEDINGS, P480; Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706; Iordache MD, 2011, IEEE T GEOSCI REMOTE, V49, P2014, DOI 10.1109/TGRS.2010.2098413; James J.F., 2007, SPECTROGRAPH DESIGN; Johnson WR, 2006, APPL OPTICS, V45, P1898, DOI 10.1364/AO.45.001898; Kawakami R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2329, DOI 10.1109/CVPR.2011.5995457; Khan Z, 2015, PATTERN RECOGN, V48, P3615, DOI 10.1016/j.patcog.2015.04.008; Kim SJ, 2011, PATTERN RECOGN, V44, P1461, DOI 10.1016/j.patcog.2010.12.019; Kittle D, 2010, APPL OPTICS, V49, P6824, DOI 10.1364/AO.49.006824; Lanaras C, 2015, IEEE I CONF COMP VIS, P3586, DOI 10.1109/ICCV.2015.409; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901; MAIRAL J., 2009, P 26 ANN INT C MACH, P689, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]; Mairal J, 2012, FOUND TRENDS COMPUT, V8, DOI 10.1561/0600000058; MALONEY LT, 1986, J OPT SOC AM A, V3, P1673, DOI 10.1364/JOSAA.3.001673; Manakov A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461937; MILLER PJ, 1995, P SOC PHOTO-OPT INS, V2345, P354, DOI 10.1117/12.198889; Nguyen RMH, 2014, LECT NOTES COMPUT SC, V8695, P186, DOI 10.1007/978-3-319-10584-0_13; Oh SW, 2016, PROC CVPR IEEE, P2461, DOI 10.1109/CVPR.2016.270; OKAMOTO T, 1991, OPT LETT, V16, P1277, DOI 10.1364/OL.16.001277; Paisley J, 2009, P 26 ANN INT C MACH, P777, DOI [10.1145/1553374.1553474, DOI 10.1145/1553374.1553474]; Park JI, 2007, IEEE I CONF COMP VIS, P2049; PARKKINEN JPS, 1989, J OPT SOC AM A, V6, P318, DOI 10.1364/JOSAA.6.000318; Parmar M, 2008, IEEE IMAGE PROC, P473, DOI 10.1109/ICIP.2008.4711794; PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465; Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4; Robles-Kelly A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P251, DOI 10.1145/2733373.2806223; Rubin Michael, 2008, EFFICIENT IMPLEMENTA, P1; Takatani T, 2017, PROC CVPR IEEE, P2692, DOI 10.1109/CVPR.2017.288; Tao Wang, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P98, DOI 10.1109/CVPR.2009.5204095; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8; Tominaga S, 1996, J OPT SOC AM A, V13, P2163, DOI 10.1364/JOSAA.13.002163; Uzair M, 2015, IEEE T IMAGE PROCESS, V24, P1127, DOI 10.1109/TIP.2015.2393057; Uzair M, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.57; Van Nguyen H., 2010, P IEEE COMP VIS PATT, P44; Xing ZM, 2012, SIAM J IMAGING SCI, V5, P33, DOI 10.1137/110837486; Yuhas R. H., 1992, P SUMM 3 ANN JPL AIR, V1, P14; Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391; Zhou QY, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P2295, DOI 10.1109/ROBIO.2009.5420459; Zhou Y, 2014, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2014.394	75	31	32	9	55	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					100	113		10.1109/TPAMI.2018.2873729	http://dx.doi.org/10.1109/TPAMI.2018.2873729			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30295614	Green Submitted			2022-12-18	WOS:000502294300008
J	Ye, J; Qi, GJ; Zhuang, NF; Hu, H; Hua, KA				Ye, Jun; Qi, Guo-Jun; Zhuang, Naifan; Hu, Hao; Hua, Kien A.			Learning Compact Features for Human Activity Recognition Via Probabilistic First-Take-All	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Probabilistic logic; Recurrent neural networks; Heuristic algorithms; Frequency-domain analysis; Activity recognition; Videos; Human activity recognition; temporal orders encoding; wearable sensors; learning to hash	QUANTIZATION	With the popularity of mobile sensor technology, smart wearable devices open a unprecedented opportunity to solve the challenging human activity recognition (HAR) problem by learning expressive representations from the multi-dimensional daily sensor signals. This inspires us to develop a new algorithm applicable to both camera-based and wearable sensor-based HAR systems. Although competitive classification accuracy has been reported, existing methods often face the challenge of distinguishing visually similar activities composed of activity patterns in different temporal orders. In this paper, we propose a novel probabilistic algorithm to compactly encode temporal orders of activity patterns for HAR. Specifically, the algorithm learns an optimal set of latent patterns such that their temporal structures really matter in recognizing different human activities. Then, a novel probabilistic First-Take-All (pFTA) approach is introduced to generate compact features from the orders of these latent patterns to encode the entire sequence, and the temporal structural similarity between different sequences can be efficiently measured by the Hamming distance between compact features. Experiments on three public HAR datasets show the proposed pFTA approach can achieve competitive performance in terms of accuracy as well as efficiency.	[Ye, Jun] Microsoft, Redmond, WA 98052 USA; [Qi, Guo-Jun] Huawei Cloud, Bellevue, WA 98004 USA; [Zhuang, Naifan; Hu, Hao; Hua, Kien A.] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA	Microsoft; Huawei Technologies; State University System of Florida; University of Central Florida	Ye, J (corresponding author), Microsoft, Redmond, WA 98052 USA.; Qi, GJ (corresponding author), Huawei Cloud, Bellevue, WA 98004 USA.	yeju@microsoft.com; guojun.qi@huawei.com; zhuangnaifan@knights.ucf.edu; hao_hu@knights.ucf.edu; kienhua@eecs.ucf.edu		Qi, Guo-Jun/0000-0003-3508-1851	NASA [NNX15AV40A]; US National Science Foundation [1560302]	NASA(National Aeronautics & Space Administration (NASA)); US National Science Foundation(National Science Foundation (NSF))	This material is partially supported by NASA under Grant Number NNX15AV40A and US National Science Foundation under Grant Number 1560302. Any opinions, findings, and conclusions or recommendations expressed in this materials are those of the authors and do not necessarily reflect the views of NASA or US National Science Foundation. J. Ye and G.-J. Qi was with the Department of Computer Science, University of Central Florida, Orlando, while this workwas done.	Altun K, 2010, PATTERN RECOGN, V43, P3605, DOI 10.1016/j.patcog.2010.04.019; Anguita D., 2013, PROC 21TH EUR S ARTI, P437; [Anonymous], CORR; Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4; Berndt D. J., 1994, P 3 INT C KNOWL DISC, P359; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI [10.1145/1961189.1961199, DOI 10.1145/1961189.1961199]; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Ermes M, 2008, IEEE ENG MED BIO, P4451, DOI 10.1109/IEMBS.2008.4650199; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu H., 2017, P INT C MACH LEARN, P1568; Hu H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P905, DOI 10.1145/2939672.2939774; Hu H, 2017, IEEE COMPUT SOC CONF, P2192, DOI 10.1109/CVPRW.2017.272; Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437; Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192; Maurer U., 2006, BSN 2006. International Workshop on Wearable and Implantable Body Sensor Networks; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Parkka J, 2006, IEEE T INF TECHNOL B, V10, P119, DOI 10.1109/TITB.2005.856863; Politi O, 2014, EUR SIGNAL PR CONF, P2315; Ravi Nishkam, 2005, P 17 C INN APPL ART, V3, P1541, DOI DOI 10.1007/978-3-642-02481-8_120; Reyes-Ortiz JL, 2016, NEUROCOMPUTING, V171, P754, DOI 10.1016/j.neucom.2015.07.085; Ribeiro A, 2005, INT CONF ACOUST SPEE, P61; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Tang J., 2007, P 15 ACM INT C MULT, P297, DOI 10.1145/1291233.1291296.; Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108; Yin J, 2008, IEEE T KNOWL DATA EN, V20, P1082, DOI 10.1109/TKDE.2007.1042; Zhao WT, 2012, INT C APPL ROBOT POW, P557, DOI 10.1109/CARPI.2012.6356377; Zhao X., 2013, P 21 ACM INT C MULT, P23	34	31	30	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					126	139		10.1109/TPAMI.2018.2874455	http://dx.doi.org/10.1109/TPAMI.2018.2874455			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30296212				2022-12-18	WOS:000502294300010
J	Kang, GL; Li, J; Tao, DC				Kang, Guoliang; Li, Jun; Tao, Dacheng			Shakeout: A New Approach to Regularized Deep Neural Network Training	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shakeout; dropout; regularization; sparsity; deep neural network	SELECTION	Recent years have witnessed the success of deep neural networks in dealing with a plenty of practical problems. Dropout has played an essential role in many successful deep neural networks, by inducing regularization in the model training. In this paper, we present a new regularized training approach: Shakeout. Instead of randomly discarding units as Dropout does at the training stage, Shakeout randomly chooses to enhance or reverse each unit's contribution to the next layer. This minor modification of Dropout has the statistical trait: the regularizer induced by Shakeout adaptively combines L-0, L-1 and L-2 regularization terms. Our classification experiments with representative deep architectures on image datasets MNIST, CIFAR-10 and ImageNet show that Shakeout deals with over-fitting effectively and outperforms Dropout. We empirically demonstrate that Shakeout leads to sparser weights under both unsupervised and supervised settings. Shakeout also leads to the grouping effect of the input units in a layer. Considering the weights in reflecting the importance of connections, Shakeout is superior to Dropout, which is valuable for the deep model compression. Moreover, we demonstrate that Shakeout can effectively reduce the instability of the training process of the deep architecture.	[Kang, Guoliang; Li, Jun] Univ Technol Sydney, Fac Engn & Informat Technol, Ctr AI, Ultimo, NSW, Australia; [Tao, Dacheng] Univ Sydney, UBTech Sydney Artificial Intelligence Inst, Darlington, NSW 2008, Australia; [Tao, Dacheng] Univ Sydney, Sch Informat Technol, Fac Engn & Informat Technol, Darlington, NSW 2008, Australia	University of Technology Sydney; University of Sydney; University of Sydney	Kang, GL (corresponding author), Univ Technol Sydney, Fac Engn & Informat Technol, Ctr AI, Ultimo, NSW, Australia.	Guoliang.Kang@student.uts.edu.au; junjy007@googlemail.com; dacheng.tao@sydney.edu.au		Li, Jun/0000-0002-1336-2241	Australian Research Council [FT-130101457, DP-140102164, LP-150100671]	Australian Research Council(Australian Research Council)	This research is supported by Australian Research Council Projects (No. FT-130101457, DP-140102164 and LP-150100671).	[Anonymous], 2015, ARXIV151207030; Arjovsky M., 2017, ARXIV170107875; Arjovsky M., 2017, P NIPS WORKSH ADV TR, V2016; Ba J., 2013, ADV NEURAL INFORM PR, P3084; Baldi P., 2013, ADV NEURAL INFORM PR, V26, P2814, DOI DOI 10.17744/MEHC.25.2.XHYREGGXDCD0Q4NY; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Bergstra J, 2012, J MACH LEARN RES, V13, P281; BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108; Chen N, 2014, AAAI CONF ARTIF INTE, P1752; Chen WL, 2015, PR MACH LEARN RES, V37, P2285; Cun YL., 1990, ADV NEURAL INF PROCE, P598, DOI DOI 10.5555/109230.109298; Denil M., 2013, ADV NEURAL INFORM PR, P2148, DOI DOI 10.5555/2999792.2999852; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gal Y., 2016, P 33 INT C MACH LEAR, P1050, DOI DOI 10.5555/3045390.3045502; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Goodfellow I. J., 2012, ARXIV12013382; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Han Song, 2015, ARXIV151000149, DOI DOI 10.1145/2351676.2351678; Han Song, 2015, ADV NEURAL INFORM PR, P1135, DOI DOI 10.5555/2969239.2969366; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; Helmbold DP, 2015, J MACH LEARN RES, V16, P3403; Hinton G., 2015, ARXIV150302531; Hinton GE, 2012, IMPROVING NEURAL NET, DOI DOI 10.9774/GLEAF.978-1-909493-38-4_2; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kang GL, 2016, AAAI CONF ARTIF INTE, P1751; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Krizhevsky A, 2012, CUDA CONVNET; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li Z, 2016, ADV NEURAL INFORM PR, P2523; Liang PH., 2013, ADV NEURAL INFORM PR, V26; Maaten L., 2013, P 30 INT C MACH LEAR, P410; Maclaurin D, 2015, PR MACH LEARN RES, V37, P2113; Moody J., 1995, ADV NEURAL INFORM PR, V4, P950; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Prechelt L, 1998, NEURAL NETWORKS, V11, P761, DOI 10.1016/S0893-6080(98)00010-0; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Ranzato M., 2008, PROC NEURAL INF PROC, P1185; Rifai S., 2011, ARXIV11043250; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Snoek J, 2012, ADV NEURAL INF PROCE, V25, P2951; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sun Y, 2016, IEEE T PATTERN ANAL, V38, P1997, DOI 10.1109/TPAMI.2015.2505293; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C., 2016, P IEEE C COMP VIS PA, P2818, DOI DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Thom M, 2013, J MACH LEARN RES, V14, P1091; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wan L., 2013, P INT C MACHINE LEAR, P1058; Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311; Warde-Farley D., 2013, ARXIV13126197; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Weihua Jiang, 2015, 2015 42nd IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2015.7180008; Williams D. R. G. H. R., 1986, NATURE; Yuan L, 2013, IEEE T PATTERN ANAL, V35, P2104, DOI 10.1109/TPAMI.2013.17; Zagoruyko S., 2016, P BRIT MACH VIS C YO; Zheng Y, 2016, IEEE T PATTERN ANAL, V38, P1056, DOI 10.1109/TPAMI.2015.2476802; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	65	31	31	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1245	1258		10.1109/TPAMI.2017.2701831	http://dx.doi.org/10.1109/TPAMI.2017.2701831			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28489533	Green Submitted			2022-12-18	WOS:000428901200017
J	Wan, H; Wang, H; Guo, GD; Wei, X				Wan, Huan; Wang, Hui; Guo, Gongde; Wei, Xin			Separability-Oriented Subclass Discriminant Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; feature extraction; linear discriminant analysis; subclass discriminant analysis; classification	ANALYSIS FRAMEWORK; FEATURE-EXTRACTION; LDA; RECOGNITION; MATRIX	Linear discriminant analysis (LDA) is a classical method for discriminative dimensionality reduction. The original LDA may degrade in its performance for non-Gaussian data, and may be unable to extract sufficient features to satisfactorily explain the data when the number of classes is small. Two prominent extensions to address these problems are subclass discriminant analysis (SDA) and mixture subclass discriminant analysis (MSDA). They divide every class into subclasses and re-define the within-class and between-class scatter matrices on the basis of subclass. In this paper we study the issue of how to obtain subclasses more effectively in order to achieve higher class separation. We observe that there is significant overlap between models of the subclasses, which we hypothesise is undesirable. In order to reduce their overlap we propose an extension of LDA, separability oriented subclass discriminant analysis (SSDA), which employs hierarchical clustering to divide a class into subclasses using a separability oriented criterion, before applying LDA optimisation using re-defined scatter matrices. Extensive experiments have shown that SSDA has better performance than LDA, SDA and MSDA in most cases. Additional experiments have further shown that SSDA can project data into LDA space that has higher class separation than LDA, SDA and MSDA in most cases.	[Wan, Huan; Guo, Gongde; Wei, Xin] Fujian Normal Univ, Key Lab Network Secur & Cryptol, Sch Math & Comp Sci, Fuzhou 350000, Fujian, Peoples R China; [Wang, Hui] Ulster Univ, Sch Comp & Math, Coleraine BT52 1SA, Londonderry, North Ireland; [Wang, Hui] Fujian Normal Univ, Fuzhou 350000, Fujian, Peoples R China	Fujian Normal University; Ulster University; Fujian Normal University	Wan, H (corresponding author), Fujian Normal Univ, Key Lab Network Secur & Cryptol, Sch Math & Comp Sci, Fuzhou 350000, Fujian, Peoples R China.	huanwan.mail@qq.com; h.wang@ulster.ac.uk; ggd@fjnu.edu.cn; xinwei.mail@qq.com		Wang, Hui/0000-0003-2633-6015	National Natural Science Foundation of China [61672157]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	G. Guo is corresponding author and the work was supported by the National Natural Science Foundation of China under Grant No. 61672157.	Alcala-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Chu DL, 2015, IEEE T NEUR NET LEAR, V26, P2716, DOI 10.1109/TNNLS.2015.2391201; Clemmensen L, 2011, TECHNOMETRICS, V53, P406, DOI 10.1198/TECH.2011.08118; Dunn J.C., 1973, J CYBERNETICS, V3, P32, DOI [10.1080/ 01969727308546046, DOI 10.1080/01969727308546046]; Fan ZZ, 2011, IEEE T NEURAL NETWOR, V22, P1119, DOI 10.1109/TNN.2011.2152852; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fukunaga K., 2013, INTRO STAT PATTERN R; Ghassabeh YA, 2015, PATTERN RECOGN, V48, P1999, DOI 10.1016/j.patcog.2014.12.012; Gkalelis N, 2013, IEEE T NEUR NET LEAR, V24, P8, DOI 10.1109/TNNLS.2012.2216545; Gkalelis N, 2011, IEEE SIGNAL PROC LET, V18, P319, DOI 10.1109/LSP.2011.2127474; Guo YQ, 2007, BIOSTATISTICS, V8, P86, DOI 10.1093/biostatistics/kxj035; He CL, 2011, INT J DOC ANAL RECOG, V14, P263, DOI 10.1007/s10032-011-0154-8; He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692; Heikkila M, 2006, LECT NOTES COMPUT SC, V4338, P58; Huang B.G., 2007, 0749 U MASS AMH; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; Kan MN, 2013, IEEE T IMAGE PROCESS, V22, P3310, DOI 10.1109/TIP.2013.2256918; Kim TK, 2011, INT J COMPUT VISION, V91, P216, DOI 10.1007/s11263-010-0381-3; Lei Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1237, DOI 10.1109/ICPR.2010.308; Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007; Li ZF, 2009, IEEE T PATTERN ANAL, V31, P755, DOI 10.1109/TPAMI.2008.174; Lichman M., 2013, UCI MACHINE LEARNING; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Martinez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744; Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300; Sharma A, 2015, NEUROCOMPUTING, V151, P207, DOI 10.1016/j.neucom.2014.09.051; Sharma A, 2014, MACH VISION APPL, V25, P775, DOI 10.1007/s00138-013-0577-y; Sharma A, 2012, PATTERN RECOGN, V45, P2205, DOI 10.1016/j.patcog.2011.11.018; Shu X, 2014, APPL INTELL, V40, P724, DOI 10.1007/s10489-013-0485-x; Wan H., 2015, NEW LINEAR DISCRIMIN; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wolf L, 2010, LECT NOTES COMPUT SC, V5995, P88; Zhu M.., 2004, P IEEE C COMP VIS PA, P97; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	38	31	31	2	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					409	422		10.1109/TPAMI.2017.2672557	http://dx.doi.org/10.1109/TPAMI.2017.2672557			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28237920	Green Submitted			2022-12-18	WOS:000422706000011
J	Amirkhani, H; Rahmati, M; Lucas, PJF; Hommersom, A				Amirkhani, Hossein; Rahmati, Mohammad; Lucas, Peter J. F.; Hommersom, Arjen			Exploiting Experts' Knowledge for Structure Learning of Bayesian Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian networks; structure learning; experts' knowledge; experts' accuracy; marginalization-based score	PROBABILISTIC NETWORKS; EQUIVALENCE CLASSES; INFORMATION; ALGORITHMS	Learning Bayesian network structures from data is known to be hard, mainly because the number of candidate graphs is super-exponential in the number of variables. Furthermore, using observational data alone, the true causal graph is not discernible from other graphs that model the same set of conditional independencies. In this paper, it is investigated whether Bayesian network structure learning can be improved by exploiting the opinions of multiple domain experts regarding cause-effect relationships. In practice, experts have different individual probabilities of correctly labeling the inclusion or exclusion of edges in the structure. The accuracy of each expert is modeled by three parameters. Two new scoring functions are introduced that score each candidate graph based on the data and experts' opinions, taking into account their accuracy parameters. In the first scoring function, the experts' accuracies are estimated using an expectation-maximization-based algorithm and the estimated accuracies are explicitly used in the scoring process. The second function marginalizes out the accuracy parameters to obtain more robust scores when it is not possible to obtain a good estimate of experts' accuracies. The experimental results on simulated and real world datasets show that exploiting experts' knowledge can improve the structure learning if we take the experts' accuracies into account.	[Amirkhani, Hossein; Rahmati, Mohammad] Amirkabir Univ Technol, Comp Engn & Informat Technol, Tehran 64540, Iran; [Amirkhani, Hossein] Univ Qom, Technol & Engn Dept, Qom 3718117469, Iran; [Lucas, Peter J. F.; Hommersom, Arjen] Radboud Univ Nijmegen, Inst Comp & Informat Sci, NL-6525 Nijmegen, Netherlands; [Hommersom, Arjen] Open Univ, Fac Sci Management & Technol, NL-6419 Heerlen, Netherlands	Amirkabir University of Technology; Radboud University Nijmegen; Open University Netherlands	Amirkhani, H (corresponding author), Amirkabir Univ Technol, Comp Engn & Informat Technol, Tehran 64540, Iran.; Amirkhani, H (corresponding author), Univ Qom, Technol & Engn Dept, Qom 3718117469, Iran.	amirkhani@aut.ac.ir; rahmati@aut.ac.ir; plucas@liacs.nl; arjenh@cs.ru.nl		Lucas, Peter/0000-0001-5454-2428; Amirkhani, Hossein/0000-0002-8679-0634				Abramson B, 1996, INT J FORECASTING, V12, P57, DOI 10.1016/0169-2070(95)00664-8; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Amirkhani H., 2014, INT WORKSH MULT PRED; Amirkhani H, 2015, INTELL DATA ANAL, V19, P1003, DOI 10.3233/IDA-150755; Amirkhani H, 2014, APPL INTELL, V41, P212, DOI 10.1007/s10489-014-0516-2; Andersson SA, 1997, ANN STAT, V25, P505; [Anonymous], 2003, P 20 INT C MACH LEAR; Beinlich I. A., 1989, AIME 89. Second European Conference on Artificial Intelligence in Medicine Proceedings, P247; Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; Buntine W., 1991, P 7 C UNC ART INT, P52, DOI DOI 10.1016/B978-1-55860-203-8.50010-3; Cano A, 2011, IEEE T SYST MAN CY B, V41, P1382, DOI 10.1109/TSMCB.2011.2148197; Castelo R, 2000, INT J APPROX REASON, V24, P39, DOI 10.1016/S0888-613X(99)00041-9; Chickering D. M., 2003, Journal of Machine Learning Research, V3, P507, DOI 10.1162/153244303321897717; Chickering DM, 2004, J MACH LEARN RES, V5, P1287; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; Dawid A.P., 1979, APPL STAT, V28, P20, DOI [10.2307/2346806, DOI 10.2307/2346806]; de Campos CP, 2011, J MACH LEARN RES, V12, P663; de Campos LM, 2007, INT J APPROX REASON, V45, P233, DOI 10.1016/j.ijar.2006.06.009; de Campos LM, 2006, J MACH LEARN RES, V7, P2149; de Jongh Martijn, 2009, RECENT ADV INTELLIGE, P443; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Heng X. C., 2006, INF TECHNOL J, V5, P540; Huang S, 2013, IEEE T PATTERN ANAL, V35, P1328, DOI 10.1109/TPAMI.2012.129; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Leray P., 2004, TECH REP; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; Masegosa AR, 2013, INT J APPROX REASON, V54, P1168, DOI 10.1016/j.ijar.2013.03.009; Murphy K., 2001, COMPUTING SCI STAT, V33, P1024; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Raykar VC, 2010, J MACH LEARN RES, V11, P1297; Robinson R., 1977, LECT NOTES MATH, V622, P220; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Spirtes P., 2000, CAUSATION PREDICTION, V81; Studeny M, 2014, INT J APPROX REASON, V55, P1043, DOI 10.1016/j.ijar.2013.09.016; Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7; Velikova M, 2013, ARTIF INTELL MED, V57, P73, DOI 10.1016/j.artmed.2012.12.004; Velikova M, 2012, MED IMAGE ANAL, V16, P865, DOI 10.1016/j.media.2012.01.003; Yet B, 2014, J BIOMED INFORM, V48, P28, DOI 10.1016/j.jbi.2013.10.012	42	31	32	1	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2154	2170		10.1109/TPAMI.2016.2636828	http://dx.doi.org/10.1109/TPAMI.2016.2636828			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	28114005	Green Published			2022-12-18	WOS:000412028600004
J	Anirudh, R; Turaga, P; Su, JY; Srivastava, A				Anirudh, Rushil; Turaga, Pavan; Su, Jingyong; Srivastava, Anuj			Elastic Functional Coding of Riemannian Trajectories	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Riemannian geometry; activity recognition; dimensionality reduction; visualization	K-SVD; MOVEMENT; RECOGNITION; MANIFOLDS; FRAMEWORK; VIDEO	Visual observations of dynamic phenomena, such as human actions, are often represented as sequences of smoothly-varying features. In cases where the feature spaces can be structured as Riemannian manifolds, the corresponding representations become trajectories on manifolds. Analysis of these trajectories is challenging due to non-linearity of underlying spaces and high-dimensionality of trajectories. In vision problems, given the nature of physical systems involved, these phenomena are better characterized on a low-dimensional manifold compared to the space of Riemannian trajectories. For instance, if one does not impose physical constraints of the human body, in data involving human action analysis, the resulting representation space will have highly redundant features. Learning an effective, low-dimensional embedding for action representations will have a huge impact in the areas of search and retrieval, visualization, learning, and recognition. Traditional manifold learning addresses this problem for static points in the euclidean space, but its extension to Riemannian trajectories is non-trivial and remains unexplored. The difficulty lies in inherent non-linearity of the domain and temporal variability of actions that can distort any traditional metric between trajectories. To overcome these issues, we use the framework based on transported square-root velocity fields (TSRVF); this framework has several desirable properties, including a rate-invariant metric and vector space representations. We propose to learn an embedding such that each action trajectory is mapped to a single point in a low-dimensional euclidean space, and the trajectories that differ only in temporal rates map to the same point. We utilize the TSRVF representation, and accompanying statistical summaries of Riemannian trajectories, to extend existing coding methods such as PCA, KSVD and Label Consistent KSVD to Riemannian trajectories or more generally to Riemannian functions. We show that such coding efficiently captures trajectories in applications such as action recognition, stroke rehabilitation, visual speech recognition, clustering and diverse sequence sampling. Using this framework, we obtain state-of-the-art recognition results, while reducing the dimensionality/complexity by a factor of 100-250x. Since these mappings and codes are invertible, they can also be used to interactively visualize Riemannian trajectories and synthesize actions.	[Anirudh, Rushil; Turaga, Pavan] Arizona State Univ, Sch Arts Media & Engn, Tempe, AZ 85281 USA; [Anirudh, Rushil; Turaga, Pavan] Arizona State Univ, Dept Elect Comp & Energy Engn, Tempe, AZ 85281 USA; [Su, Jingyong] Texas Tech Univ, Dept Math & Stat, Lubbock, TX 79409 USA; [Srivastava, Anuj] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA	Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe; Texas Tech University System; Texas Tech University; State University System of Florida; Florida State University	Anirudh, R (corresponding author), Arizona State Univ, Sch Arts Media & Engn, Tempe, AZ 85281 USA.; Anirudh, R (corresponding author), Arizona State Univ, Dept Elect Comp & Energy Engn, Tempe, AZ 85281 USA.	ranirudh@asu.edu; pturaga@asu.edu; jingyong.su@ttu.edu; anuj@stat.fsu.edu	Turaga, Pavan/W-6186-2019; Anirudh, Rushil/R-5994-2019; Srivastava, Anuj/L-4705-2019	Anirudh, Rushil/0000-0002-4186-3502; Turaga, Pavan/0000-0002-5263-5943; Srivastava, Anuj/0000-0001-7406-0338	NSF CCF CIF [1320267, 1319658]; Direct For Computer & Info Scie & Enginr [1319658] Funding Source: National Science Foundation	NSF CCF CIF; Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	Rushil Anirudh and Pavan Turaga were supported by NSF CCF CIF grant #1320267. Anuj Srivastava was supported by NSF CCF CIF grant #1319658.	Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Anirudh R., 2015, INT J COMPUT VISION, P1; Anirudh R, 2015, PROC CVPR IEEE, P3147, DOI 10.1109/CVPR.2015.7298934; Begelfor E., 2006, 2006 IEEE COMPUTER S, V2, P2087, DOI DOI 10.1109/CVPR.2006.50; Berndt D. J., 1994, P 3 INT C KNOWL DISC, P359; Biess A, 2007, J NEUROSCI, V27, P13045, DOI 10.1523/JNEUROSCI.4334-06.2007; Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821; Chen YP, 2011, AIP CONF PROC, V1371, P317, DOI 10.1063/1.3596656; Danziger Z, 2012, J NEUROSCI, V32, P9859, DOI 10.1523/JNEUROSCI.5528-11.2012; Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774; Duan XM, 2013, SCI WORLD J, DOI 10.1155/2013/292787; Faraki M, 2015, PROC CVPR IEEE, P4951, DOI 10.1109/CVPR.2015.7299129; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; Goodall CR, 1999, J COMPUT GRAPH STAT, V8, P143, DOI 10.2307/1390631; Harandi M, 2013, IEEE I CONF COMP VIS, P3120, DOI 10.1109/ICCV.2013.387; Harandi MT, 2014, LECT NOTES COMPUT SC, V8690, P17, DOI 10.1007/978-3-319-10605-2_2; He ZS, 2009, SIGNAL PROCESS, V89, P1011, DOI 10.1016/j.sigpro.2008.12.005; Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88; Jost J, 2011, RIEMANNIAN GEOMETRY, DOI DOI 10.1007/978-3-642-21298-7; Lawrence ND, 2004, ADV NEUR IN, V16, P329; Lewandowski M, 2014, IEEE T CYBERNETICS, V44, P936, DOI 10.1109/TCYB.2013.2277664; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Lu Xia, 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233; Murray R. M., 1994, MATH INTRO ROBOTIC M; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77; Shroff N., 2011, ADV NEURAL INFORM PR, P154; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Srivastava A, 2004, ADV APPL PROBAB, V36, P43, DOI 10.1239/aap/1077134463; Su J, 2012, IMAGE VISION COMPUT, V30, P428, DOI 10.1016/j.imavis.2011.09.006; Su JY, 2014, PROC CVPR IEEE, P620, DOI 10.1109/CVPR.2014.86; Su JY, 2014, ANN APPL STAT, V8, P530, DOI 10.1214/13-AOAS701; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2; Turaga Pavan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2435, DOI 10.1109/CVPRW.2009.5206710; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246; Veeraraghavan A, 2006, 2006 IEEE COMPUTER S, V1, P959; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Venkataraman V, 2013, IEEE COMPUT SOC CONF, P514, DOI 10.1109/CVPRW.2013.82; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wolf SL, 2001, STROKE, V32, P1635, DOI 10.1161/01.STR.32.7.1635; Xie Yuchen, 2013, JMLR Workshop Conf Proc, V28, P1480; Zhang Z., 2015, CORR; Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637; Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812	50	31	34	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					922	936		10.1109/TPAMI.2016.2564409	http://dx.doi.org/10.1109/TPAMI.2016.2564409			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	28113699	Green Submitted, hybrid			2022-12-18	WOS:000399250000007
J	Diaz, M; Ferrer, MA; Eskander, GS; Sabourin, R				Diaz, Moises; Ferrer, Miguel A.; Eskander, George S.; Sabourin, Robert			Generation of Duplicated Off-Line Signature Images for Verification Systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometric signature identification; signature synthesis; off-line signature verification; performance evaluation; off-line signature recognition; equivalence theory	MOTOR CONTROL; ONLINE; RECOGNITION; IDENTIFICATION; REPRESENTATION; PARAMETERS; MECHANISMS; RECOVERY	Biometric researchers have historically seen signature duplication as a procedure relevant to improving the performance of automatic signature verifiers. Different approaches have been proposed to duplicate dynamic signatures based on the heuristic affine transformation, nonlinear distortion and the kinematic model of the motor system. The literature on static signature duplication is limited and as far as we know based on heuristic affine transforms and does not seem to consider the recent advances in human behavior modeling of neuroscience. This paper tries to fill this gap by proposing a cognitive inspired algorithm to duplicate off-line signatures. The algorithm is based on a set of nonlinear and linear transformations which simulate the human spatial cognitive map and motor system intra-personal variability during the signing process. The duplicator is evaluated by increasing artificially a training sequence and verifying that the performance of four state-of-the-art off-line signature classifiers using two publicly databases have been improved on average as if we had collected three more real signatures.	[Diaz, Moises; Ferrer, Miguel A.] Univ Las Palmas Gran Canaria, Inst Univ Desarrollo Tecnol & Innovac Comunicac, Las Palmas Gran Canaria 35017, Spain; [Eskander, George S.; Sabourin, Robert] Univ Quebec, Ecole Technol Super, Lab Imagerie Vis & Intelligence Artificielle, 1100 Rue Notre Dame Ouest,Room A-3600, Montreal, PQ H3C 1K3, Canada	Universidad de Las Palmas de Gran Canaria; University of Quebec; Ecole de Technologie Superieure - Canada; University of Quebec Montreal	Diaz, M (corresponding author), Univ Las Palmas Gran Canaria, Inst Univ Desarrollo Tecnol & Innovac Comunicac, Las Palmas Gran Canaria 35017, Spain.	mdiaz@idetic.eu; mferrer@idetic.eu; geskander@livia.etsmtl.ca; robert.sabourin@etsmtl.ca	Ferrer, Miguel/AFU-8286-2022; Ferrer, Miguel A A/L-3863-2013; Diaz, Moises/L-3637-2013	Ferrer, Miguel A A/0000-0002-2924-1225; Diaz, Moises/0000-0003-3878-3867	ULPGC	ULPGC	The authors would like to thank Elias N. Zois for providing them with the System D code. M. Diaz is supported by a PhD fellowship from the ULPGC.	[Anonymous], P 9 IAPR INT WORKSHO, DOI [10.1145/1815330.1815390, DOI 10.1145/1815330.1815390]; Bernstein NA., 1967, COORDINATION REGULAT; Blumenstein M., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P721, DOI 10.1109/ICFHR.2010.117; Diaz M, 2015, PROC INT CONF DOC, P631, DOI 10.1109/ICDAR.2015.7333838; Diaz-Cabrera Moises, 2014, Advances in Digital Handwritten Signature Processing: A Human Artefact for e-Society, P111; Diaz-Cabrera M, 2014, INT CONF FRONT HAND, P482, DOI 10.1109/ICFHR.2014.87; Diaz-Cabrera M, 2014, INT CONF FRONT HAND, P61, DOI 10.1109/ICFHR.2014.18; Diaz-Cabrera M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123254; Doermann D, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P375, DOI 10.1109/IWFHR.2002.1030939; Eskander GS, 2013, IET BIOMETRICS, V2, P169, DOI 10.1049/iet-bmt.2013.0024; Fairhurst MC, 1997, ELECTRON COMMUN ENG, V9, P273, DOI 10.1049/ecej:19970606; Ferrer M. A., 2013, P IEEE INT CARN C SE, P116; Ferrer MA, 2005, IEEE T PATTERN ANAL, V27, P993, DOI 10.1109/TPAMI.2005.125; Ferrer MA, 2015, IEEE T PATTERN ANAL, V37, P667, DOI 10.1109/TPAMI.2014.2343981; Ferrer MA, 2012, IEEE T INF FOREN SEC, V7, P966, DOI 10.1109/TIFS.2012.2190281; Fierrez J., 2008, ON LINE SIGNATURE VE, P189; Fierrez-Aguilar J, 2005, IEEE T SYST MAN CY C, V35, P418, DOI 10.1109/TSMCC.2005.848181; Frias-Martinez E, 2006, ENG APPL ARTIF INTEL, V19, P693, DOI 10.1016/j.engappai.2005.12.006; Fu HB, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024167; Galbally Javier, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1295, DOI 10.1109/ICDAR.2009.38; Galbally J, 2015, PATTERN RECOGN, V48, P2921, DOI 10.1016/j.patcog.2015.03.019; Guest RM, 2014, IET BIOMETRICS, V3, P159, DOI 10.1049/iet-bmt.2013.0022; Hafemann L. G., 2015, ABS150707909 CORR; Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721; Haralick RM., 1992, COMPUTER ROBOT VISIO; Hebb D.O., 1949, ORG BEHAV NEUROPSYCH; Impedovo D, 2012, INT CONF FRONT HAND, P367, DOI 10.1109/ICFHR.2012.211; Jain AK, 2002, IEEE IMAGE PROC, P57; Kawato M, 1999, CURR OPIN NEUROBIOL, V9, P718, DOI 10.1016/S0959-4388(99)00028-8; Kotz S, 2000, EXTREME VALUE DISTRI; Lashley KS, 1930, PSYCHOL REV, V37, P1, DOI 10.1037/h0074134; Leclerc F., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P643, DOI 10.1142/S0218001494000346; LEE S, 1992, IEEE T SYST MAN CYB, V22, P755, DOI 10.1109/21.156588; Lee S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P176, DOI 10.1109/CVPR.1992.223276; Liwicki M, 2014, PATTERN RECOGN LETT, V35, P246, DOI 10.1016/j.patrec.2012.09.001; Liwicki M, 2011, PROC INT CONF DOC, P1384, DOI 10.1109/ICDAR.2011.278; Marcelli A, 2013, P 2 WORKSH AUT FOR H, P6, DOI DOI 10.HTTP://CEUR-WS.ORG/VOL-1022/; Munich ME, 2003, IEEE T PATTERN ANAL, V25, P200, DOI 10.1109/TPAMI.2003.1177152; O'Reilly C, 2009, PATTERN RECOGN, V42, P3324, DOI 10.1016/j.patcog.2008.10.017; Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Plamondon R, 1999, IEEE T IMAGE PROCESS, V8, P80, DOI 10.1109/83.736691; PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Rabasse C, 2008, IEEE T SYST MAN CY B, V38, P691, DOI 10.1109/TSMCB.2008.918575; Thomas AO, 2009, PATTERN RECOGN, V42, P3365, DOI 10.1016/j.patcog.2008.12.018; Wing AM, 2000, CURR BIOL, V10, pR245, DOI 10.1016/S0960-9822(00)00375-4; Yang SH, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/692782; Zois EN, 2016, PATTERN RECOGN, V54, P162, DOI 10.1016/j.patcog.2016.01.009	49	31	31	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					951	964		10.1109/TPAMI.2016.2560810	http://dx.doi.org/10.1109/TPAMI.2016.2560810			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	28113540				2022-12-18	WOS:000399250000009
J	Davis, A; Bouman, KL; Chen, JG; Rubinstein, M; Buyukozturk, O; Durand, F; Freeman, WT				Davis, Abe; Bouman, Katherine L.; Chen, Justin G.; Rubinstein, Michael; Buyukozturk, Oral; Durand, Fredo; Freeman, William T.			Visual Vibrometry: Estimating Material Properties from Small Motions in Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Material properties; vibration; small motion; computational photography; computational imaging		The estimation of material properties is important for scene understanding, with many applications in vision, robotics, and structural engineering. This paper connects fundamentals of vibration mechanics with computer vision techniques in order to infer material properties from small, often imperceptible motions in video. Objects tend to vibrate in a set of preferred modes. The frequencies of these modes depend on the structure and material properties of an object. We show that by extracting these frequencies from video of a vibrating object, we can often make inferences about that object's material properties. We demonstrate our approach by estimating material properties for a variety of objects by observing their motion in high-speed and regular frame rate video.	[Davis, Abe; Bouman, Katherine L.; Chen, Justin G.; Buyukozturk, Oral; Durand, Fredo; Freeman, William T.] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Rubinstein, Michael; Freeman, William T.] Google Res, Cambridge, England; [Rubinstein, Michael] Microsoft Res, Cambridge, MA 02142 USA	Massachusetts Institute of Technology (MIT); Google Incorporated; Microsoft	Davis, A (corresponding author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	abedavis@mit.edu; klbouman@mit.edu; ju21743@mit.edu; mrub@google.com; obuyuk@mit.edu; fredo@mit.edu; billf@mit.edu		Davis, Abe/0000-0003-1469-2696	US National Science Foundation [1212849]; NSF [CGV-1111415]; Shell Research; Qatar Computing Research Institute; US National Science Foundation GRFP fellowships	US National Science Foundation(National Science Foundation (NSF)); NSF(National Science Foundation (NSF)); Shell Research; Qatar Computing Research Institute(Qatar Foundation (QF)Qatar National Research Fund (QNRF)); US National Science Foundation GRFP fellowships	Dr. Dirk Smit of Shell Research proposed to us the analysis of small displacements for structural health monitoring. We would also like to thank Neal Wadhwa, Gautham J. Mysore, and Danny M. Kaufman. This work was supported by US National Science Foundation Robust Intelligence 1212849 Reconstructive Recognition, NSF CGV-1111415, Shell Research, and Qatar Computing Research Institute. A. Davis and K. Bouman were partially supported by US National Science Foundation GRFP fellowships.	[Anonymous], 2010, E75605 ASTM INT; Aranchuk V, 2006, OPT ENG, V45, DOI 10.1117/1.2358975; Baker W. E., 1967, INT J MECH SCI, V9, P43; Bhat K. S., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P37; Bouman KL, 2013, IEEE I CONF COMP VIS, P1984, DOI 10.1109/ICCV.2013.455; Buyukozturk O., 2013, NONDESTRUCTIVE TESTI, P19; Castellini P, 1996, OPT LASER ENG, V25, P227, DOI 10.1016/0143-8166(95)00073-9; Chen J. G., 2014, TOPICS MODAL ANAL, P191, DOI DOI 10.1007/978-3-319-04753-9_19; Chen JG, 2015, J SOUND VIB, V345, P58, DOI 10.1016/j.jsv.2015.01.024; Chen JG, 2014, MATER EVAL, V72, P1305; Collini L, 2011, NDT&E INT, V44, P152, DOI 10.1016/j.ndteint.2010.11.008; Cremer L., 2013, STRUCTURE BORNE SOUN; Davis A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818095; Davis A, 2015, PROC CVPR IEEE, P5335, DOI 10.1109/CVPR.2015.7299171; Davis A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601119; Durst F., 1976, PRINCIPLES PRACTICE, V76; Emge T, 2012, MATER EVAL, V70, P1401; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; Fleming RW, 2003, J VISION, V3, P347, DOI 10.1167/3.5.3; Haupt R. W., 2005, Lincoln Laboratory Journal, V15, P3; Ho YX, 2006, J VISION, V6, P634, DOI 10.1167/6.5.8; Jojic N., 1997, P INT WORKSH SYNTH N, P73; KAWABATA S, 1989, J TEXT I, V80, P19, DOI 10.1080/00405008908659184; KU HH, 1966, J RES NBS C ENG INST, VC 70, P263, DOI 10.6028/jres.070C.025; Liu C, 2010, PROC CVPR IEEE, P239, DOI 10.1109/ICCET.2010.5485248; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; Rubinstein M., 2014, THESIS; Santulli C., 2006, NDT NET, V11; Shabana A. A., 1991, THEORY OF VIBRATION, V2; Sharan L, 2008, J OPT SOC AM A, V25, P846, DOI 10.1364/JOSAA.25.000846; Shull P., 2002, NONDESTRUCTIVE EVALU, V142; Simoncelli E. P., 1992, IEEE T INFORM THEORY, V2, P87; Stanbridge AB, 1999, MECH SYST SIGNAL PR, V13, P255, DOI 10.1006/mssp.1998.1209; Wadhwa N., 2014, IEEE INT C COMP PHOT, P1, DOI DOI 10.1109/ICCPHOT.2014.6831820; Wadhwa N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461966; Wang H., 2011, P ACM SIGGRAPH; Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561	37	31	34	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					732	745		10.1109/TPAMI.2016.2622271	http://dx.doi.org/10.1109/TPAMI.2016.2622271			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	27875214	Green Submitted, hybrid			2022-12-18	WOS:000397717600010
J	Gorelick, L; Veksler, O; Boykov, Y; Nieuwenhuis, C				Gorelick, Lena; Veksler, Olga; Boykov, Yuri; Nieuwenhuis, Claudia			Convexity Shape Prior for Binary Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Segmentation; convexity shape prior; high-order functionals; trust region; graph cuts	MODELS	Convexity is a known important cue in human vision. We propose shape convexity as a new high-order regularization constraint for binary image segmentation. In the context of discrete optimization, object convexity is represented as a sum of three-clique potentials penalizing any 1-0-1 configuration on all straight lines. We show that these non-submodular potentials can be efficiently optimized using an iterative trust region approach. At each iteration the energy is linearly approximated and globally optimized within a small trust region around the current solution. While the quadratic number of all three-cliques is prohibitively high, we design a dynamic programming technique for evaluating and approximating these cliques in linear time. We also derive a second order approximation model that is more accurate but computationally intensive. We discuss limitations of our local optimization and propose gradual non-submodularization scheme that alleviates some limitations. Our experiments demonstrate general usefulness of the proposed convexity shape prior on synthetic and real image segmentation examples. Unlike standard second-order length regularization, our convexity prior does not have shrinking bias, and is robust to changes in scale and parameter selection.	[Gorelick, Lena; Veksler, Olga; Boykov, Yuri] Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; [Nieuwenhuis, Claudia] Univ Calif Berkeley, Int Comp Sci Inst, Berkeley, CA USA	Western University (University of Western Ontario); University of California System; University of California Berkeley	Gorelick, L (corresponding author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.	lenagorelick@gmail.com; olga@csd.uwo.ca; yuri@csd.uwo.ca; claudia.nieuwenhuis@in.tum.de			Canadian NSERC Discovery Program; Canadian NSERC RTI Program	Canadian NSERC Discovery Program; Canadian NSERC RTI Program	We are thankful for generous support by Canadian NSERC Discovery and RTI Programs.	Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Boykov Y, 2006, LECT NOTES COMPUT SC, V3953, P409, DOI 10.1007/11744078_32; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Bredies K, 2013, J MATH IMAGING VIS, V47, P278, DOI 10.1007/s10851-012-0347-x; Felzenszwalb PF, 2010, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2010.5540067; Fujishige S., 2005, ANN DISCRETE MATH; Gorelick L, 2014, PROC CVPR IEEE, P1154, DOI 10.1109/CVPR.2014.151; Gorelick L, 2013, PROC CVPR IEEE, P1714, DOI 10.1109/CVPR.2013.224; Jegelka S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1897, DOI 10.1109/CVPR.2011.5995589; Kohli P, 2013, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2013.257; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V., 2012, ARXIV12056352; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Liu XQ, 2010, IEEE T PATTERN ANAL, V32, P1182, DOI 10.1109/TPAMI.2009.120; Liu ZL, 1999, VISION RES, V39, P4244, DOI 10.1016/S0042-6989(99)00141-8; Mamassian P, 1998, VISION RES, V38, P2817, DOI 10.1016/S0042-6989(97)00438-0; Nieuwenhuis C, 2014, PROC CVPR IEEE, P4098, DOI 10.1109/CVPR.2014.522; Nowozin S, 2010, SIAM J IMAGING SCI, V3, P1048, DOI 10.1137/090752614; Olsson C, 2013, IEEE I CONF COMP VIS, P2936, DOI 10.1109/ICCV.2013.365; Pock T, 2010, SIAM J IMAGING SCI, V3, P1122, DOI 10.1137/090757617; Schoenemann T, 2012, INT J COMPUT VISION, V99, P53, DOI 10.1007/s11263-012-0518-7; Strekalovskiy E, 2011, IEEE I CONF COMP VIS, P2619, DOI 10.1109/ICCV.2011.6126551; Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222; Veksler O, 2008, LECT NOTES COMPUT SC, V5304, P454, DOI 10.1007/978-3-540-88690-7_34; Vicente S, 2008, PROC CVPR IEEE, P767; Winn J., 2006, CVPR; Yuan Y., 1999, P 4 INT C IND APPL M	30	31	33	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					258	271		10.1109/TPAMI.2016.2547399	http://dx.doi.org/10.1109/TPAMI.2016.2547399			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	28103187				2022-12-18	WOS:000395553400004
J	Qu, HB; Wang, JQ; Li, B; Yu, M				Qu, Han-Bing; Wang, Jia-Qiang; Li, Bin; Yu, Ming			Probabilistic Model for Robust Affine and Non-Rigid Point Set Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Point set matching; graphical model; variational inference; gaussian mixture model; robust estimation; affine transformation; non-rigid registration	REGISTRATION	In this work, we propose a combinative strategy based on regression and clustering for solving point set matching problems under a Bayesian framework, in which the regression estimates the transformation from the model to the sceneand the clustering establishes the correspondence between two point sets. The point set matching model is illustrated by a hierarchical directed graph, and the matching uncertainties are approximated by a coarse-to-fine variational inference algorithm. Furthermore, two Gaussian mixtures are proposed for the estimation of heteroscedastic noise and spurious outliers, and an isotropic or anisotropic covariance can be imposed on each mixture in terms of the transformed model points. The experimental results show that the proposed approach achieves comparable performance to state-of-the-art matching or registration algorithms in terms of both robustness and accuracy.	[Qu, Han-Bing; Wang, Jia-Qiang] Beijing Acad Sci & Technol, Key Lab Pattern Recognit, Beijing 100094, Peoples R China; [Wang, Jia-Qiang] Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin 300401, Peoples R China; [Li, Bin] Beijing Acad Sci & Technol, Beijing Inst New Technol Applicat, Beijing 100094, Peoples R China; [Yu, Ming] Hebei Univ Technol, Sch Comp Sci & Engn, Tianjin 300401, Peoples R China	Beijing Academy of Science & Technology; Hebei University of Technology; Beijing Academy of Science & Technology; Hebei University of Technology	Qu, HB (corresponding author), Beijing Acad Sci & Technol, Key Lab Pattern Recognit, Beijing 100094, Peoples R China.	quhanbing@gmail.com; jiaqiangwangbj@gmail.com; lbn@hit.edu.cn; yuming@hebut.edu.cn			Innovation Group Plan of the Beijing Academy of Science [IG201506N]; Youth Core Plan of the Beijing Academy of Science and Technology [2014-30]; Tianjin Science and Technology Projects [14RCGFGX00846]	Innovation Group Plan of the Beijing Academy of Science; Youth Core Plan of the Beijing Academy of Science and Technology; Tianjin Science and Technology Projects	This work is supported in part by the Innovation Group Plan of the Beijing Academy of Science (No. IG201506N), the Youth Core Plan of the Beijing Academy of Science and Technology (No. 2014-30) and the Tianjin Science and Technology Projects (No. 14RCGFGX00846). The authors are grateful to the anonymous reviewers and editors for the comments on the manuscript. The source code of our algorithm be downloaded from: https://www.researchgate.net/publication/281071233_VBPSM_toolbox_v1.0a.	Almhdie A., 2007, PATTERN RECOGN LETT, V28, P792; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Beal M.J, 2003, THESIS; Beal MJ, 2003, BAYESIAN STATISTICS 7, P453; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bishop C.M, 2006, PATTERN RECOGN; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; Choudrey R. A., 2002, THESIS; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377; Cu L, 2008, LECT NOTES COMPUT SC, V5302, P413, DOI 10.1007/978-3-540-88682-2_32; Czogiel I, 2011, ANN APPL STAT, V5, P2603, DOI 10.1214/11-AOAS486; Dorai C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P770, DOI 10.1109/ICPR.1996.546128; DSouza A., 2004, P 21 INT C MACH LEAR, P31; Evangelidis GD, 2014, LECT NOTES COMPUT SC, V8695, P109, DOI 10.1007/978-3-319-10584-0_8; Govindu VM, 2004, IMAGE VISION COMPUT, V22, P1157, DOI 10.1016/j.imavis.2004.03.019; Haehnel D., 2003, P INT C ART INT IJCA, V3, P915; Hastie T.J., 1990, GEN ADDITIVE MODELS, V43; Horaud R, 2011, IEEE T PATTERN ANAL, V33, P587, DOI 10.1109/TPAMI.2010.94; Hou S., 2008, P IEEE CVPR 05 JUN, P1; Hu BG, 2009, INFORM SCIENCES, V179, P1929, DOI 10.1016/j.ins.2009.02.006; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Lawrence N. D., 2000, TECH REP; Li Chen, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2169, DOI 10.1109/ICIP.2011.6116041; Liu YG, 2005, PATTERN RECOGN, V38, P1615, DOI 10.1016/j.patcog.2005.01.008; Liu YH, 2006, IMAGE VISION COMPUT, V24, P762, DOI 10.1016/j.imavis.2006.01.009; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lu C.P., 1994, ADV NEURAL INFORM PR, V6, P985; Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434; MacKay DJC, 1994, ASHRAE T, V100, P1053; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Pachauri D., 2013, ADV NEURAL INFORM PR, V26, P1860; Pilet J, 2005, PROC CVPR IEEE, P822, DOI 10.1109/CVPR.2005.293; Pizarro D, 2012, INT J COMPUT VISION, V97, P54, DOI 10.1007/s11263-011-0452-0; Qu HB, 2009, ECOL INFORM, V4, P163, DOI 10.1016/j.ecoinf.2009.06.004; Roberts SJ, 2002, IEEE T SIGNAL PROCES, V50, P2245, DOI 10.1109/TSP.2002.801921; SCHMIDLER S. C, 2007, BAYESIAN STAT, V8, P471; Simpson IJA, 2012, NEUROIMAGE, V59, P2438, DOI 10.1016/j.neuroimage.2011.09.002; Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558; Van Wamelen PB, 2004, PATTERN RECOGN, V37, P1699, DOI 10.1016/j.patcog.2003.12.009; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zhao J, 2011, PROC CVPR IEEE, P2977, DOI 10.1109/CVPR.2011.5995336	45	31	38	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					371	384		10.1109/TPAMI.2016.2545659	http://dx.doi.org/10.1109/TPAMI.2016.2545659			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	27019474				2022-12-18	WOS:000395553400012
J	Liang, XD; Xu, CY; Shen, XH; Yang, JC; Tang, JH; Lin, L; Yan, SC				Liang, Xiaodan; Xu, Chunyan; Shen, Xiaohui; Yang, Jianchao; Tang, Jinhui; Lin, Liang; Yan, Shuicheng			Human Parsing with Contextualized Convolutional Neural Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human parsing; fully convolutional network; context modeling; semantic labeling		In this work, we address the human parsing task with a novel Contextualized Convolutional Neural Network (Co-CNN) architecture, which well integrates the cross-layer context, global image-level context, semantic edge context, within-super-pixel context and cross-super-pixel neighborhood context into a unified network. Given an input human image, Co-CNN produces the pixel-wise categorization in an end-to-end way. First, the cross-layer context is captured by our basic local-to-global-to-local structure, which hierarchically combines the global semantic information and the local fine details across different convolutional layers. Second, the global image-level label prediction is used as an auxiliary objective in the intermediate layer of the Co-CNN, and its outputs are further used for guiding the feature learning in subsequent convolutional layers to leverage the global image-level context. Third, semantic edge context is further incorporated into Co-CNN, where the high-level semantic boundaries are leveraged to guide pixel-wise labeling. Finally, to further utilize the local super-pixel contexts, the within-super-pixel smoothing and cross-super-pixel neighbourhood voting are formulated as natural sub-components of the Co-CNN to achieve the local label consistency in both training and testing process. Comprehensive evaluations on two public datasets well demonstrate the significant superiority of our Co-CNN over other state-of-the-arts for human parsing. In particular, the F-1 score on the large dataset [1] reaches 81: 72 percent by Co-CNN, significantly higher than 62: 81 percent and 64: 38 percent by the state-of-the-art algorithms, M-CNN [2] and ATR [1], respectively. By utilizing our newly collected large dataset for training, our Co-CNN can achieve 85: 36 percent in F-1 score.	[Liang, Xiaodan; Lin, Liang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China; [Xu, Chunyan] Huazhong Univ Sci & Technol, Sch Comp Sci, Wuhan, Hubei, Peoples R China; [Shen, Xiaohui; Yang, Jianchao] Adobe Res, San Jose, CA 95110 USA; [Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Engn & Comp Sci, Nanjing, Jiangsu, Peoples R China; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	Sun Yat Sen University; Huazhong University of Science & Technology; Adobe Systems Inc.; Nanjing University of Science & Technology; National University of Singapore	Liang, XD (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China.	xdliang328@gmail.com; xuchunyan01@gmail.com; xshen@adobe.com; jiayang@adobe.com; jinhuitang@mail.njust.edu.cn; linliang@ieee.org; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022	Tang, Jinhui/0000-0001-9008-222X	973 Program of China [2014CB347600]; National Natural Science Foundation of China [61522203, 61328205]; Guangdong Natural Science Foundation [2014A030313201]; Program of Guangzhou Zhujiang Star of Science and Technology [2013J2200067]; Guangdong Science and Technology Program [2015B010128009]; Adobe Research	973 Program of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Guangdong Natural Science Foundation(National Natural Science Foundation of Guangdong Province); Program of Guangzhou Zhujiang Star of Science and Technology; Guangdong Science and Technology Program; Adobe Research	This work was partially supported by the 973 Program of China (Project No. 2014CB347600), and the National Natural Science Foundation of China (Grant No. 61522203, 61328205). This work was also supported in part by the Guangdong Natural Science Foundation under Grant 2014A030313201, in part by the Program of Guangzhou Zhujiang Star of Science and Technology under Grant 2013J2200067, and in part by Guangdong Science and Technology Program under Grant 2015B010128009. This work was also partly supported by gift funds from Adobe Research. Liang Lin is the corresponding author.	Alan L.Y., 2015, P IEEE INT C COMP VI; Bertasius G., 2015, P IEEE C COMP VIS PA; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Chen L.C., 2014, ICLR; Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391; Dong J, 2013, IEEE I CONF COMP VIS, P3408, DOI 10.1109/ICCV.2013.423; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Girshick R., 2014, COMPUT VIS PATTERN R; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kalantidis Y., 2013, P 3 ACM C INT C MULT, P105, DOI DOI 10.1145/2461466.2461485; Liang X., 2016, P IEEE C COMP VIS PA; Liang X., 2015, ARXIV150902636; Liang X., 2015, P IEEE INT C COMP VI; Liang XD, 2015, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2015.120; Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360; Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748; Liu S, 2015, IEEE T MULTIMEDIA, V17, P1347, DOI 10.1109/TMM.2015.2443559; Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI 10.1109/CVPR.2015.7298965; Mairal J, 2010, J MACH LEARN RES, V11, P19; Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323; Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959; Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024; Simo-Serra E., 2014, AS C COMP VIS ACCV S, P64; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Toshev A., 2014, P INT C COMP VIS PAT; Wang Y, 2012, J MACH LEARN RES, V13, P3075; Wei Di, 2013, 2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P8, DOI 10.1109/CVPRW.2013.6; Xie Saining, 2015, ARXIV150406375; Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437; Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101; Yang W, 2014, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR.2014.407; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460	34	31	35	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					115	127		10.1109/TPAMI.2016.2537339	http://dx.doi.org/10.1109/TPAMI.2016.2537339			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26955019				2022-12-18	WOS:000390421300011
J	Amer, MR; Todorovic, S				Amer, Mohamed R.; Todorovic, Sinisa			Sum Product Networks for Activity Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sum-product networks; activity recognition; hierarchical models	MODELS; CONTEXT	This paper addresses detection and localization of human activities in videos. We focus on activities that may have variable spatiotemporal arrangements of parts, and numbers of actors. Such activities are represented by a sum-product network (SPN). A product node in SPN represents a particular arrangement of parts, and a sum node represents alternative arrangements. The sums and products are hierarchically organized, and grounded onto space-time windows covering the video. The windows provide evidence about the activity classes based on the Counting Grid (CG) model of visual words. This evidence is propagated bottom-up and top-down to parse the SPN graph for the explanation of the video. The node connectivity and model parameters of SPN and CG are jointly learned under two settings, weakly supervised, and supervised. For evaluation, we use our new Volleyball dataset, along with the benchmark datasets VIRAT, UT-Interactions, KTH, and TRECVID MED 2011. Our video classification and activity localization are superior to those of the state of the art on these datasets.	[Amer, Mohamed R.] SRI Int, 201 Washington Rd, Princeton, NJ 08540 USA; [Todorovic, Sinisa] Oregon State Univ, Sch Elect Engn & Comp Sci, Kelley Engn Ctr 1148, Off 2107, Corvallis, OR 97331 USA	SRI International; Oregon State University	Amer, MR (corresponding author), SRI Int, 201 Washington Rd, Princeton, NJ 08540 USA.; Todorovic, S (corresponding author), Oregon State Univ, Sch Elect Engn & Comp Sci, Kelley Engn Ctr 1148, Off 2107, Corvallis, OR 97331 USA.	mohamed.rabie.amer@gmail.com; sinisa@eecs.oregonstate.edu			NSF RI [1302700]; DARPA MSEE FA [8650-11-1-7149]	NSF RI(National Science Foundation (NSF)); DARPA MSEE FA	This work was supported in part by NSF RI 1302700, and DARPA MSEE FA 8650-11-1-7149.	Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Amer M., 2012, VOLLEYBALL DATASET; Amer MR, 2013, IEEE I CONF COMP VIS, P1353, DOI 10.1109/ICCV.2013.171; Amer MR, 2012, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2012.6247816; Amer MR, 2011, IEEE I CONF COMP VIS, P786, DOI 10.1109/ICCV.2011.6126317; Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4; Bhattacharya S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2593, DOI 10.1109/CVPR.2011.5995746; Bhattacharya S, 2014, PROC CVPR IEEE, P2243, DOI 10.1109/CVPR.2014.287; Brendel W., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3329, DOI 10.1109/CVPR.2011.5995491; Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Domingos P, 2012, ADV NEURAL INFORM PR, P3239; Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jojic N., 2011, 27 C UNC ART INT BAR; Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881; Lan T, 2012, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2012.6247821; Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228; Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Liu L, 2012, J BIOMED BIOTECHNOL, DOI 10.1155/2012/251364; Morariu V. I., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3289, DOI 10.1109/CVPR.2011.5995386; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Odashima S, 2012, LECT NOTES COMPUT SC, V7585, P243, DOI 10.1007/978-3-642-33885-4_25; Over P., 2011, TREC VIDEO RETRIEVAL; Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279; Perina A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1985, DOI 10.1109/CVPR.2011.5995742; Poon H., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P689, DOI 10.1109/ICCVW.2011.6130310; Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361; Ryoo M. S., 2010, P INT C PATT REC CON, P1; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Si ZZ, 2011, IEEE I CONF COMP VIS, P41, DOI 10.1109/ICCV.2011.6126223; Song X, 2013, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2013.421; Tang KV, 2013, IEEE I CONF COMP VIS, P2696, DOI 10.1109/ICCV.2013.335; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Tran SD, 2008, LECT NOTES COMPUT SC, V5303, P610, DOI 10.1007/978-3-540-88688-4_45; Tu K., 2013, ADV NEURAL INFORM PR, P1322; Ullah M. M., 2010, P BMVC, DOI 10.5244/c.24.95; Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002; Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624; Xu ZW, 2014, PROC CVPR IEEE, P97, DOI 10.1109/CVPR.2014.20; Zeng Z, 2010, LECT NOTES COMPUT SC, V6316, P532, DOI 10.1007/978-3-642-15567-3_39; Zhu L, 2011, J MATH IMAGING VIS, V41, P122, DOI 10.1007/s10851-011-0282-2; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018; Zhu YY, 2013, PROC CVPR IEEE, P2491, DOI 10.1109/CVPR.2013.322	49	31	33	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					800	813		10.1109/TPAMI.2015.2465955	http://dx.doi.org/10.1109/TPAMI.2015.2465955			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26390445	Green Submitted			2022-12-18	WOS:000372549700015
J	Estrada, R; Tomasi, C; Schmidler, SC; Farsiu, S				Estrada, Rolando; Tomasi, Carlo; Schmidler, Scott C.; Farsiu, Sina			Tree Topology Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; graph theory; image analysis; stochastic processes; tree topology	SPANNING-TREES; RECONSTRUCTION; TRACKING; SET	Tree-like structures are fundamental in nature, and it is often useful to reconstruct the topology of a tree-what connects to what-from a two-dimensional image of it. However, the projected branches often cross in the image: the tree projects to a planar graph, and the inverse problem of reconstructing the topology of the tree from that of the graph is ill-posed. We regularize this problem with a generative, parametric tree-growth model. Under this model, reconstruction is possible in linear time if one knows the direction of each edge in the graph-which edge endpoint is closer to the root of the tree-but becomes NP-hard if the directions are not known. For the latter case, we present a heuristic search algorithm to estimate the most likely topology of a rooted, three-dimensional tree from a single two-dimensional image. Experimental results on retinal vessel, plant root, and synthetic tree data sets show that our methodology is both accurate and efficient.	[Estrada, Rolando; Farsiu, Sina] Duke Univ, Dept Ophthalmol, Durham, NC 27707 USA; [Tomasi, Carlo; Schmidler, Scott C.; Farsiu, Sina] Duke Univ, Dept Comp Sci, Durham, NC 27707 USA; [Schmidler, Scott C.] Duke Univ, Dept Stat Sci, Durham, NC 27707 USA; [Farsiu, Sina] Duke Univ, Dept Biomed Engn, Durham, NC 27707 USA; [Farsiu, Sina] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27707 USA	Duke University; Duke University; Duke University; Duke University; Duke University	Estrada, R (corresponding author), Duke Univ, Dept Ophthalmol, Durham, NC 27707 USA.	restradacr@gmail.com; tomasi@cs.duke.edu; schmidler@stat.duke.edu; sina.farsiu@duke.edu		Farsiu, Sina/0000-0003-4872-2902	NIH [R01-EY022691, R01-GM090201]; NATIONAL EYE INSTITUTE [R01EY022691] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES [R01GM090201] Funding Source: NIH RePORTER	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS))	This research was supported in part by NIH grant R01-EY022691 and SCS was partially supported by NIH grant R01-GM090201. The authors thank Prof. P. S. Mettu for providing the retinal images of the WIDE data set, as well as Prof. P. Benfey and Dr. C. Topp for providing the rice plant images of the RICE data set. The authors also thank Prof. X. Chen for sharing her tree sketching software and Prof. V. Conitzer for his valuable comments on our NP-hardness proof. R. Estrada is the corresponding author.	AONO M, 1984, IEEE COMPUT GRAPH, V4, P10, DOI 10.1109/MCG.1984.276141; Austrin P, 2009, ANN IEEE CONF COMPUT, P74, DOI 10.1109/CCC.2009.38; Band LR, 2012, PLANT CELL, V24, P3892, DOI 10.1105/tpc.112.101550; Bejan A, 2010, PHILOS T R SOC B, V365, P1335, DOI 10.1098/rstb.2009.0302; Benmansour F, 2011, INT J COMPUT VISION, V92, P192, DOI 10.1007/s11263-010-0331-0; Buchin K, 2010, LECT NOTES COMPUT SC, V6346, P110, DOI 10.1007/978-3-642-15775-2_10; Chen XJ, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409062; Dashtbozorg B., 2013, IEEE T IMAGE PROCESS, V23, P1073, DOI DOI 10.1109/TIP.2013.2263809; de Reffye P, 2012, ANN FOREST SCI, V69, P153, DOI 10.1007/s13595-011-0151-6; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390; Estrada R., 2013, THESIS DUKE U DURHAM; Estrada R, 2012, BIOMED OPT EXPRESS, V3, P327, DOI 10.1364/BOE.3.000327; Estrada R, 2011, BIOMED OPT EXPRESS, V2, P2871, DOI 10.1364/BOE.2.002871; Friman O, 2010, MED IMAGE ANAL, V14, P160, DOI 10.1016/j.media.2009.12.003; Garey M.R., 1979, COMPUTERS INTRACTABI; Gonzalez G, 2010, PROC CVPR IEEE, P2799, DOI 10.1109/CVPR.2010.5540010; Gou XQ, 2009, ATMOS RES, V91, P410, DOI 10.1016/j.atmosres.2008.04.012; Graham MW, 2008, PROC SPIE, V6914, DOI 10.1117/12.768706; Gulsun MA, 2008, LECT NOTES COMPUT SC, V5241, P602, DOI 10.1007/978-3-540-85988-8_72; Hendargo HC, 2013, BIOMED OPT EXPRESS, V4, P803, DOI 10.1364/BOE.4.000803; Ishikawa H, 2005, IEEE I CONF COMP VIS, P1132; Iyer-Pascuzzi Anjali S, 2013, Methods Mol Biol, V959, P177, DOI 10.1007/978-1-62703-221-6_11; Kapoor S, 2000, ALGORITHMICA, V27, P120, DOI 10.1007/s004530010008; KHATRI CG, 1977, J ROY STAT SOC B MET, V39, P95; KHULLER S, 1995, ALGORITHMICA, V14, P305, DOI 10.1007/BF01294129; Koene RA, 2009, NEUROINFORMATICS, V7, P195, DOI 10.1007/s12021-009-9052-3; LAMBERT D, 1992, TECHNOMETRICS, V34, P1, DOI 10.2307/1269547; Lo P, 2010, MED IMAGE ANAL, V14, P527, DOI 10.1016/j.media.2010.03.004; Lopez LD, 2010, COMPUT GRAPH FORUM, V29, P2075, DOI 10.1111/j.1467-8659.2010.01794.x; Lopez-Cruz PL, 2011, NEUROINFORMATICS, V9, P347, DOI 10.1007/s12021-011-9103-4; Lynn BH, 2012, WEATHER FORECAST, V27, P1470, DOI 10.1175/WAF-D-11-00144.1; Pechaud M, 2009, PROC CVPR IEEE, P336, DOI 10.1109/CVPRW.2009.5206782; Perfahl H, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0014790; Prusinkiewicz P., 1991, ALGORITHMIC BEAUTY P; Quinas-Guerra M.M., 2012, SYSTEMS BIOL CANC RE, P197, DOI [10.1007/978-94-007-4819-4_8, DOI 10.1007/978-94-007-4819-4_8]; Rothaus K, 2007, LECT NOTES COMPUT SC, V4538, P251; Schaap M, 2007, LECT NOTES COMPUT SC, V4584, P74; Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967; Tan P, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409061; TARJAN RE, 1976, ACTA INFORM, V6, P171, DOI 10.1007/BF00268499; Turetken E, 2011, NEUROINFORMATICS, V9, P279, DOI 10.1007/s12021-011-9122-1; Willard S., 2004, GEN TOPOLOGY; Xiao CY, 2013, IEEE T IMAGE PROCESS, V22, P174, DOI 10.1109/TIP.2012.2216277; Yedidya Tamir, 2008, 2008 Digital Image Computing: Techniques and Applications, P52, DOI 10.1109/DICTA.2008.72; Zeng JG, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P445; Zheng Y, 2011, IEEE I CONF COMP VIS, P2026, DOI 10.1109/ICCV.2011.6126475	46	31	32	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1688	1701		10.1109/TPAMI.2014.2382116	http://dx.doi.org/10.1109/TPAMI.2014.2382116			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26353004	Green Submitted, Green Accepted			2022-12-18	WOS:000357591900012
J	Kolmogorov, V				Kolmogorov, Vladimir			A New Look at Reweighted Message Passing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graphical models; MAP estimation; message passing algorithms		We propose a new family of message passing techniques for MAP estimation in graphical models which we call Sequential Reweighted Message Passing (SRMP). Special cases include well-known techniques such as Min-Sum Diffusion (MSD) and a faster Sequential Tree-Reweighted Message Passing (TRW-S). Importantly, our derivation is simpler than the original derivation of TRW-S, and does not involve a decomposition into trees. This allows easy generalizations. The new family of algorithms can be viewed as a generalization of TRW-S from pairwise to higher-order graphical models. We test SRMP on several real-world problems with promising results.	IST Austria, A-3400 Klosterneuburg, Austria	Institute of Science & Technology - Austria	Kolmogorov, V (corresponding author), IST Austria, A-3400 Klosterneuburg, Austria.	vnk@ist.ac.at			European Research Council under the European Unions/ERC [616160]	European Research Council under the European Unions/ERC	I thank Thomas Schoenemann for his help with the experimental section and providing some of the data. This work was in parts funded by the European Research Council under the European Unions Seventh Framework Programme (FP7/2007-2013)/ERC grant agreement no 616160.	Figueiredo Mario A. T., 2011, P 28 INT C MACH LEAR, P169; Globerson A., 2012, MPLP CODE VERSION 2; Globerson Amir, 2007, P NIPS, V20, P553; Hazan T, 2010, IEEE T INFORM THEORY, V56, P6294, DOI 10.1109/TIT.2010.2079014; Johnson J., 2007, P 45 ANN ALL C COMM; Jojic V., 2010, P 27 INT C MACH LEAR, P503; Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175; Kappes JH, 2012, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2012.6247863; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Kolmogorov V, 2013, LECT NOTES COMPUT SC, V7965, P625, DOI 10.1007/978-3-642-39206-1_53; Komodakis Nikos, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2985, DOI 10.1109/CVPRW.2009.5206846; Komodakis N, 2008, LECT NOTES COMPUT SC, V5304, P806, DOI 10.1007/978-3-540-88690-7_60; Kumar M.P., 2008, P 25 INT C MACH LEAR, P680; Luong DVN, 2012, LECT NOTES COMPUT SC, V7431, P587, DOI 10.1007/978-3-642-33179-4_56; Meltzer T., 2009, P UAI, P393; Meshi O, 2011, LECT NOTES ARTIF INT, V6912, P470, DOI 10.1007/978-3-642-23783-6_30; Pock T, 2009, IEEE I CONF COMP VIS, P1133, DOI 10.1109/ICCV.2009.5459348; Ravikumar P, 2010, J MACH LEARN RES, V11, P1043; Savchynskyy Bogdan, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1817, DOI 10.1109/CVPR.2011.5995652; Savchynskyy B., 2012, UAI P, P746; Schlesinger M. I., 2007, Upravlyayushchie Sistemy i Mashiny, P3; Schmidt Stefan, 2011, Energy Minimization Methods in Computer Vision and Pattern Recognition. Proceedings 8th International Conference, EMMCVPR 2011, P89, DOI 10.1007/978-3-642-23094-3_7; Schoenemann T., 2014, ADV STRUCTURED PREDI; Sontag D., 2010, THESIS MIT CAMBRIDGE; Sontag D., 2012, UAI, P795; Sontag D., 2009, JMLR WORKSH C P, P544; Sontag D, 2012, OPTIMIZATION FOR MACHINE LEARNING, P219; Storvik G, 2000, IEEE T IMAGE PROCESS, V9, P469, DOI 10.1109/83.826783; Thapper J, 2012, ANN IEEE SYMP FOUND, P669, DOI 10.1109/FOCS.2012.25; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Wang Huayan, 2013, ICML 2, P190; Weiss Y., 2008, P UAI, P503; Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036; Werner T, 2010, IEEE T PATTERN ANAL, V32, P1474, DOI 10.1109/TPAMI.2009.134; WOODFORD O. J., 2008, P IEEE C COMP VIS PA, V31, P2115; Zheng Y, 2012, PROC CVPR IEEE, P1696, DOI 10.1109/CVPR.2012.6247864	36	31	32	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					919	930		10.1109/TPAMI.2014.2363465	http://dx.doi.org/10.1109/TPAMI.2014.2363465			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353318	Green Accepted			2022-12-18	WOS:000352533000002
J	Serradell, E; Pinheiro, MA; Sznitman, R; Kybic, J; Moreno-Noguer, F; Fua, P				Serradell, Eduard; Pinheiro, Miguel Amavel; Sznitman, Raphael; Kybic, Jan; Moreno-Noguer, Francesc; Fua, Pascal			Non-Rigid Graph Registration Using Active Testing Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph matching; non-rigid registration; active testing search	ASSIGNMENT; ALGORITHM; PRIORS; MODEL	We present a new approach for matching sets of branching curvilinear structures that form graphs embedded in R-2 or R-3 and may be subject to deformations. Unlike earlier methods, ours does not rely on local appearance similarity nor does require a good initial alignment. Furthermore, it can cope with non-linear deformations, topological differences, and partial graphs. To handle arbitrary non-linear deformations, we use Gaussian process regressions to represent the geometrical mapping relating the two graphs. In the absence of appearance information, we iteratively establish correspondences between points, update the mapping accordingly, and use it to estimate where to find the most likely correspondences that will be used in the next step. To make the computation tractable for large graphs, the set of new potential matches considered at each iteration is not selected at random as with many RANSAC-based algorithms. Instead, we introduce a so-called Active Testing Search strategy that performs a priority search to favor the most likely matches and speed-up the process. We demonstrate the effectiveness of our approach first on synthetic cases and then on angiography data, retinal fundus images, and microscopy image stacks acquired at very different resolutions.	[Serradell, Eduard; Moreno-Noguer, Francesc] UPC, CSIC, Inst Robot & Informat Ind, Barcelona, Spain; [Pinheiro, Miguel Amavel; Kybic, Jan] Czech Tech Univ, Ctr Machine Percept, Prague, Czech Republic; [Sznitman, Raphael; Fua, Pascal] Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland	Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII); Universitat Politecnica de Catalunya; Czech Technical University Prague; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Serradell, E (corresponding author), UPC, CSIC, Inst Robot & Informat Ind, Barcelona, Spain.	eserradell@iri.upc.edu; amavemig@cmp.felk.cvut.cz; raphael.sznitman@epfl.ch; kybic@fel.cvut.cz; fmoreno@iri.upc.edu; pascal.fua@epfl.ch	Jan, Kybic/K-8071-2017	Sznitman, Raphael/0000-0001-6791-4753; Fua, Pascal/0000-0002-6702-9970; Pinheiro, Miguel Amavel/0000-0003-3813-2562	EU Micro Nano; ERA-Net Chistera project ViSen [PCIN-2013-047]; Spanish Ministry of Economy and Competitiveness [PAU+ DPI2011-27510]; Czech Science Foundation [P202/11/0111]	EU Micro Nano; ERA-Net Chistera project ViSen; Spanish Ministry of Economy and Competitiveness(Spanish Government); Czech Science Foundation(Grant Agency of the Czech Republic)	This work has been partially funded by the EU Micro Nano and the ERA-Net Chistera project ViSen PCIN-2013-047, by the Spanish Ministry of Economy and Competitiveness under project PAU+ DPI2011-27510, and by the Czech Science Foundation project P202/11/0111.	Aguilar W, 2009, IMAGE VISION COMPUT, V27, P897, DOI 10.1016/j.imavis.2008.05.004; Amberg Brian, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1; Benmansour F., 2012, TUBULAR GEODESICS FI; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bishop C.M, 2006, PATTERN RECOGN; Chin TJ, 2012, IEEE T PATTERN ANAL, V34, P625, DOI 10.1109/TPAMI.2011.169; Chli M, 2008, LECT NOTES COMPUT SC, V5302, P72, DOI 10.1007/978-3-540-88682-2_7; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Davison AJ, 2005, IEEE I CONF COMP VIS, P66; Deng K., 2010, INT J BIOMED IMAGING, V2010, P1; Enqvist O, 2009, IEEE I CONF COMP VIS, P1295, DOI 10.1109/ICCV.2009.5459319; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fujiwara K, 2011, IEEE I CONF COMP VIS, P1527, DOI 10.1109/ICCV.2011.6126411; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x; Moreno-Noguer F, 2008, LECT NOTES COMPUT SC, V5303, P405, DOI 10.1007/978-3-540-88688-4_30; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Paragios N, 2003, COMPUT VIS IMAGE UND, V89, P142, DOI 10.1016/S1077-3142(03)00010-9; Pinheiro Miguel Amavel, 2013, Inf Process Med Imaging, V23, P572, DOI 10.1007/978-3-642-38868-2_48; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Rasmussen CE., 2006, GAUSSIAN PROCESS MAC; Sanchez-Riera J, 2010, PROC CVPR IEEE, P1189, DOI 10.1109/CVPR.2010.5539831; Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]; Serradell E., 2012, SPIE MED IMAGING, V8314; Serradell E, 2012, PROC CVPR IEEE, P996, DOI 10.1109/CVPR.2012.6247776; Serradell E, 2011, IEEE I CONF COMP VIS, P850, DOI 10.1109/ICCV.2011.6126325; Serradell E, 2010, LECT NOTES COMPUT SC, V6313, P58; Smeets D., 2010, WORKSH PULM IM AN, P61; Sznitman R, 2010, IEEE T PATTERN ANAL, V32, P1914, DOI 10.1109/TPAMI.2010.106; Tordoff B, 2002, LECT NOTES COMPUT SC, V2350, P82; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	40	31	32	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2015	37	3					625	638		10.1109/TPAMI.2014.2343235	http://dx.doi.org/10.1109/TPAMI.2014.2343235			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VK	26353266	Green Accepted, Green Submitted			2022-12-18	WOS:000349626200011
J	Houle, ME; Nett, M				Houle, Michael E.; Nett, Michael			Rank-Based Similarity Search: Reducing the Dimensional Dependence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nearest neighbor search; intrinsic dimensionality; rank-based search	CLUSTERING-ALGORITHM	This paper introduces a data structure for k-NN search, the Rank Cover Tree (RCT), whose pruning tests rely solely on the comparison of similarity values; other properties of the underlying space, such as the triangle inequality, are not employed. Objects are selected according to their ranks with respect to the query object, allowing much tighter control on the overall execution costs. A formal theoretical analysis shows that with very high probability, the RCT returns a correct query result in time that depends very competitively on a measure of the intrinsic dimensionality of the data set. The experimental results for the RCT show that non-metric pruning strategies for similarity search can be practical even when the representational dimension of the data is extremely high. They also show that the RCT is capable of meeting or exceeding the level of performance of state-of-the-art methods that make use of metric pruning or other selection tests involving numerical constraints on distance values.	[Houle, Michael E.] Res Org Informat & Syst, Natl Inst Informat, Chiyoda Ku, Tokyo 1018430, Japan; [Nett, Michael] Google Japan, Minato Ku, Tokyo 1066126, Japan	Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan; Google Incorporated	Houle, ME (corresponding author), Res Org Informat & Syst, Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsuba Shi, Tokyo 1018430, Japan.	meh@nii.ac.jp; mnett@google.com		Houle, Michael/0000-0001-8486-8015	JSPS Kakenhi Kiban (A) Research Grant [25240036]; JST ERATO Kawarabayashi Large Graph Project; JST ERATO Minato Discrete Structure Manipulation System Project	JSPS Kakenhi Kiban (A) Research Grant; JST ERATO Kawarabayashi Large Graph Project; JST ERATO Minato Discrete Structure Manipulation System Project	Michael Houle acknowledges the financial support of JSPS Kakenhi Kiban (A) Research Grant 25240036, the JST ERATO Kawarabayashi Large Graph Project, and the JST ERATO Minato Discrete Structure Manipulation System Project. We are also grateful to Ilia Zvedeniouk for providing us with patches that allowed us to include the ANN library in our experimental evaluation. Much of Nett's work on this paper was conducted while he was with the University of Tokyo, Japan, and the National Institute of Informatics, Japan.	Abraham I., 2004, P 15 ANN ACM SIAM S, P550; Andoni A., 2005, E2LSH 0 1 USER MANUA; Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49; Asuncion A, 2007, UCI MACHINE LEARNING; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; Beygelzimer A, 2006, P 23 INT C MACH LEAR, P97, DOI DOI 10.1145/1143844.1143857; Bozkaya T, 1999, ACM T DATABASE SYST, V24, P361, DOI 10.1145/328939.328959; Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388; Brin S., 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases, P574; Chan HTH, 2005, PROCEEDINGS OF THE SIXTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P762; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Vries T., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P128, DOI 10.1109/ICDM.2010.151; Ertoz L., 2003, P 2 SIAM INT C DAT M, P1; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Goodman J. E., 1997, HDB DISCRETE COMPUTA; Goyal N., 2008, WSDM, P25; Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3; Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4; Gupta A, 2003, ANN IEEE SYMP FOUND, P534, DOI 10.1109/SFCS.2003.1238226; Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266; Han J, 2006, DATA MINING CONCEPTS; Houle ME, 2005, PROC INT CONF DATA, P619; Houle ME, 2008, STAT ANAL DATA MIN, V1, P157, DOI DOI 10.1002/sam.10013; Houle ME, 2013, LECT NOTES COMPUT SC, V8199, P16, DOI 10.1007/978-3-642-41062-8_3; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Karger D.R., 2002, P 34 ACM S THEORY CO, P741; Katayama N., 1997, SIGMOD Record, V26, P369, DOI 10.1145/253262.253347; Krauthgamer R, 2004, LECT NOTES COMPUT SC, V3142, P858; Krauthgamer R., 2004, P 15 ANN ACM SIAM S, P798; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lifshits Y, 2009, PROCEEDINGS OF THE TWENTIETH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P318; Motwani R, 1996, ACM COMPUT SURV, V28, P33, DOI 10.1145/234313.234327; Mount D. M., 2010, ANN LIB APPROXIMATE; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Navarro G., 1999, 6th International Symposium on String Processing and Information Retrieval. 5th International Workshop on Groupware (Cat. No.PR00268), P141, DOI 10.1109/SPIRE.1999.796589; Pestov V, 2000, INFORM PROCESS LETT, V73, P47, DOI 10.1016/S0020-0190(99)00156-8; Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882; PUGH W, 1990, COMMUN ACM, V33, P668, DOI 10.1145/78973.78977; Reuters Ltd, 2005, REUT CORP, V2; Samet H, 2006, MORGAN KAUFMANN SERI; Sarwar B, 2000, APPL DIMENSIONALLY R; Slivkins A., 2005, P 24 ANN ACM S PRINC, P41; Tschopp D., 2011, ADV NEURAL INFORM PR, V24, P2231; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194; Ye N., 2003, HDB DATA MINING	50	31	31	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					136	150		10.1109/TPAMI.2014.2343223	http://dx.doi.org/10.1109/TPAMI.2014.2343223			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353214				2022-12-18	WOS:000346970600012
J	Baktashmotlagh, M; Harandi, M; Lovell, BC; Salzmann, M				Baktashmotlagh, Mahsa; Harandi, Mehrtash; Lovell, Brian C.; Salzmann, Mathieu			Discriminative Non-Linear Stationary Subspace Analysis for Video Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video classification; stationarity; subspace analysis; kernel methods	RECOGNITION; KERNELS	Low-dimensional representations are key to the success of many video classification algorithms. However, the commonly-used dimensionality reduction techniques fail to account for the fact that only part of the signal is shared across all the videos in one class. As a consequence, the resulting representations contain instance-specific information, which introduces noise in the classification process. In this paper, we introduce non-linear stationary subspace analysis: a method that overcomes this issue by explicitly separating the stationary parts of the video signal (i.e., the parts shared across all videos in one class), from its non-stationary parts (i.e., the parts specific to individual videos). Our method also encourages the new representation to be discriminative, thus accounting for the underlying classification problem. We demonstrate the effectiveness of our approach on dynamic texture recognition, scene classification and action recognition.	[Baktashmotlagh, Mahsa; Lovell, Brian C.] Univ Queensland, Coll Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia; [Harandi, Mehrtash; Salzmann, Mathieu] NICTA, Canberra, ACT 2601, Australia; [Harandi, Mehrtash; Salzmann, Mathieu] Australian Natl Univ, Coll Engn & Comp Sci, Acton, ACT 2601, Australia	University of Queensland; Australian National University; Australian National University	Baktashmotlagh, M (corresponding author), Univ Queensland, Coll Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.	mahsa.baktashmotlagh@nicta.com.au; mehrtash.harandi@nicta.com.au; lovell@itee.uq.edu.au; mathieu.salzmann@nicta.com.au	Harandi, Mehrtash/D-6586-2018	Harandi, Mehrtash/0000-0002-6937-6300; Lovell, Brian/0000-0001-6722-1754; Salzmann, Mathieu/0000-0002-8347-8637	Australian Government, Department of Broadband, Communications and the Digital Economy; Australian Research Council (ARC) through ICT Centre of Excellence program	Australian Government, Department of Broadband, Communications and the Digital Economy(Australian Government); Australian Research Council (ARC) through ICT Centre of Excellence program(Australian Research Council)	NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council (ARC) through the ICT Centre of Excellence program.	Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284; Bishop C.M, 2006, PATTERN RECOGN; Canu S, 2006, NEUROCOMPUTING, V69, P714, DOI 10.1016/j.neucom.2005.12.009; Castrodad A, 2012, INT J COMPUT VISION, V100, P1, DOI 10.1007/s11263-012-0534-7; Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965; Chan AB, 2005, PROC CVPR IEEE, P846; Chan AB, 2007, PROC CVPR IEEE, P208; Chan AB, 2010, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2010.5539878; Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821; Coviello E, 2012, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2012.6247900; de Campos T, 2011, IEEE WORKSH APPL COM, P344; Derpanis K. G., 2011, P IEEE WORKSH APPL C, P606, DOI DOI 10.1109/WACV.2011.5711560; Everts I, 2013, PROC CVPR IEEE, P2850, DOI 10.1109/CVPR.2013.367; Fukunaga K., 1990, INTRODUCTION TO STAT; Ghanem B, 2010, LECT NOTES COMPUT SC, V6312, P223; Globerson A., 2005, NIPS; Gu L, 2001, PROC CVPR IEEE, P116; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; Hara S, 2012, NEURAL NETWORKS, V33, P7, DOI 10.1016/j.neunet.2012.04.001; Harandi MT, 2013, PATTERN RECOGN LETT, V34, P1906, DOI 10.1016/j.patrec.2013.01.008; Hotta K, 2012, PATTERN RECOGN, V45, P3687, DOI 10.1016/j.patcog.2012.04.008; Kim M., 2007, P IEEE MILCOM 07 ORL, P1, DOI DOI 10.1109/MILC0M.2007.4454941; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Klaser A., 2008, P BRIT MACH VIS C; Knopp J, 2010, LECT NOTES COMPUT SC, V6316, P589, DOI 10.1007/978-3-642-15567-3_43; Lanckriet G. R. G., 2003, Journal of Machine Learning Research, V3, P555, DOI 10.1162/153244303321897726; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Liu JG, 2009, PROC CVPR IEEE, P1996; Long F, 2012, NEUROCOMPUTING, V93, P126, DOI 10.1016/j.neucom.2012.04.017; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Muller JS, 2011, J MACH LEARN RES, V12, P3065; Mumtaz A, 2013, IEEE T PATTERN ANAL, V35, P1606, DOI 10.1109/TPAMI.2012.236; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; O'Hara S, 2012, PROC CVPR IEEE, P1210, DOI 10.1109/CVPR.2012.6247803; Ravichandran A, 2009, PROC CVPR IEEE, P1651, DOI 10.1109/CVPRW.2009.5206847; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Saisan P, 2001, PROC CVPR IEEE, P58; Sankaranarayanan AC, 2010, LECT NOTES COMPUT SC, V6311, P129, DOI 10.1007/978-3-642-15549-9_10; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2007, ACM MM, P357; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Smola A., 2002, LEARNING WITH KERNEL; Thurau C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587721; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tseng CC, 2012, PATTERN RECOGN, V45, P3611, DOI 10.1016/j.patcog.2012.04.002; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; von Bunau P, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.214101; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43; Welling M., 2006, TECH REP; Woolfe F, 2006, LECT NOTES COMPUT SC, V3952, P549; Xu Y, 2012, COMPUT VIS IMAGE UND, V116, P999, DOI 10.1016/j.cviu.2012.05.003; Xu Y, 2011, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2011.6126372; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110	54	31	31	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2353	2366		10.1109/TPAMI.2014.2339851	http://dx.doi.org/10.1109/TPAMI.2014.2339851			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353144				2022-12-18	WOS:000344988000003
J	Feragen, A; Lo, PC; de Bruijne, M; Nielsen, M; Lauze, F				Feragen, Aasa; Lo, Pechin; de Bruijne, Marleen; Nielsen, Mads; Lauze, Francois			Toward a Theory of Statistical Tree-Shape Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Trees; tree metric; graph models; shape; anatomical structure; pattern matching; pattern recognition; geometry	PRINCIPAL COMPONENT ANALYSIS; SPACE; SEGMENTATION; DISTANCES; ALGORITHM; AIRWAYS	To develop statistical methods for shapes with a tree-structure, we construct a shape space framework for tree-shapes and study metrics on the shape space. This shape space has singularities which correspond to topological transitions in the represented trees. We study two closely related metrics on the shape space, TED and QED. QED is a quotient euclidean distance arising naturally from the shape space formulation, while TED is the classical tree edit distance. Using Gromov's metric geometry, we gain new insight into the geometries defined by TED and QED. We show that the new metric QED has nice geometric properties that are needed for statistical analysis: Geodesics always exist and are generically locally unique. Following this, we can also show the existence and generic local uniqueness of average trees for QED. TED, while having some algorithmic advantages, does not share these advantages. Along with the theoretical framework we provide experimental proof-of-concept results on synthetic data trees as well as small airway trees from pulmonary CT scans. This way, we illustrate that our framework has promising theoretical and qualitative properties necessary to build a theory of statistical tree-shape analysis.	[Feragen, Aasa; Lo, Pechin; de Bruijne, Marleen; Nielsen, Mads; Lauze, Francois] Univ Copenhagen, Dept Comp Sci, eSci Ctr, DK-2011 Copenhagan, Denmark; [de Bruijne, Marleen] Erasmus MC Univ Med Ctr Rotterdam, Dept Radiol & Med Informat, Biomed Imaging Grp Rotterdam, NL-3000 CA Rotterdam, Netherlands	University of Copenhagen; Erasmus University Rotterdam; Erasmus MC	Feragen, A (corresponding author), Univ Copenhagen, Dept Comp Sci, eSci Ctr, Univ Pk 5, DK-2011 Copenhagan, Denmark.	aasa@diku.dk; pechin@diku.dk; marleen@diku.dk; madsn@diku.dk; francois@diku.dk	Lauze, Francois B/L-8757-2016; de Bruijne, Marleen/G-2662-2010; Feragen, Aasa/G-1465-2013	Lauze, Francois B/0000-0003-2503-6475; de Bruijne, Marleen/0000-0002-6328-902X; Feragen, Aasa/0000-0002-9945-981X	Lundbeck foundation; Danish Council for Strategic Research (NABIIT) [09-065145, 09-061346]; Netherlands Organisation for Scientific Research (NWO); Villum Fonden [00008721] Funding Source: researchfish	Lundbeck foundation(Lundbeckfonden); Danish Council for Strategic Research (NABIIT)(Danske Strategiske Forskningsrad (DSF)); Netherlands Organisation for Scientific Research (NWO)(Netherlands Organization for Scientific Research (NWO)); Villum Fonden(Villum Fonden)	The authors thank the anonymous reviewers for their helpful comments that improved the quality of the paper. This work is partly funded by the Lundbeck foundation, the Danish Council for Strategic Research (NABIIT projects 09-065145 and 09-061346), and the Netherlands Organisation for Scientific Research (NWO). They thank Soren Hauberg for helpful discussions during the preparation of the paper.	Arnaudon M., 2012, MEANS COMPLETE MANIF; Aydin B, 2009, ANN APPL STAT, V3, P1597, DOI 10.1214/09-AOAS263; Bai X, 2009, IEEE I CONF COMP VIS, P575, DOI 10.1109/ICCV.2009.5459188; Baloch SH, 2006, MODEL SIMUL SCI ENG, P61; Billera LJ, 2001, ADV APPL MATH, V27, P733, DOI 10.1006/aama.2001.0759; BRIDSON M. R., 1999, METRIC SPACES NON PO, V319, DOI [10.1007/978-3-662-12494-9, DOI 10.1007/978-3-662-12494-9]; Chalopin C, 2001, MED IMAGE ANAL, V5, P301, DOI 10.1016/S1361-8415(01)00047-0; Demirci MF, 2009, J MATH IMAGING VIS, V35, P103, DOI 10.1007/s10851-009-0157-y; Dugundji J., 1966, TOPOLOGY; Feragen Aasa, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2089, DOI 10.1109/ICPR.2010.513; Feragen A., 2012, P 15 INT C MED IM CO; Feragen A., 2011, P IEEE INT C COMP VI; Feragen A, 2012, LECT NOTES COMPUT SC, V7626, P89, DOI 10.1007/978-3-642-34166-3_10; Feragen A, 2011, LECT NOTES COMPUT SC, V6493, P160; Ferrer M, 2010, PATTERN RECOGN, V43, P1642, DOI 10.1016/j.patcog.2009.10.013; Gromov Mikhael, 1987, MATH SCI RES I PUBL, V8, P75, DOI 10.1007/978-1-4613-9586-7_3; Hillis DM, 2005, SYST BIOL, V54, P471, DOI 10.1080/10635150590946961; Jain BJ, 2009, J MACH LEARN RES, V10, P2667; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Kurtek S, 2012, IEEE T PATTERN ANAL, V34, P1717, DOI 10.1109/TPAMI.2011.233; Lo P, 2012, IEEE T MED IMAGING, V31, P2093, DOI 10.1109/TMI.2012.2209674; Lo P, 2010, MED IMAGE ANAL, V14, P527, DOI 10.1016/j.media.2010.03.004; Mandelbrot, 1982, FRACTAL GEOMETRY NAT, P394; Metzen JH, 2009, IMAGE VISION COMPUT, V27, P923, DOI 10.1016/j.imavis.2008.04.002; Michor PW, 2006, J EUR MATH SOC, V8, P1, DOI 10.4171/JEMS/37; Nye TMW, 2011, ANN STAT, V39, P2716, DOI 10.1214/11-AOS915; Owen M, 2011, IEEE ACM T COMPUT BI, V8, P2, DOI 10.1109/TCBB.2010.3; Riesen K, 2009, INT J PATTERN RECOGN, V23, P1053, DOI 10.1142/S021800140900748X; Schlatholter T, 2002, PROC SPIE, V4684, P103, DOI 10.1117/12.467061; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Small C.G., 1996, STAT THEORY SHAPE; Sorensen L, 2011, LECT NOTES COMPUT SC, V6801, P475, DOI 10.1007/978-3-642-22092-0_39; Sturm K., 2003, HEAT KERNELS ANAL MA, V338, P357, DOI DOI 10.1090/CONM/338/06080; Touzet H, 2005, LECT NOTES COMPUT SC, V3537, P334; Trinh N.H., 2010, CVPR WORKSH, P1; van Ginneken B, 2008, LECT NOTES COMPUT SC, V5241, P219, DOI 10.1007/978-3-540-85988-8_27; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; Wang H, 2007, ANN STAT, V35, P1849, DOI 10.1214/009053607000000217; Washko GR, 2009, J APPL PHYSIOL, V107, P185, DOI 10.1152/japplphysiol.00216.2009	40	31	31	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					2008	2021		10.1109/TPAMI.2012.265	http://dx.doi.org/10.1109/TPAMI.2012.265			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23267202				2022-12-18	WOS:000320381400015
J	Bazin, JC; Li, HD; Kweon, IS; Demonceaux, C; Vasseur, P; Ikeuchi, K				Bazin, Jean-Charles; Li, Hongdong; Kweon, In So; Demonceaux, Cedric; Vasseur, Pascal; Ikeuchi, Katsushi			A Branch-and-Bound Approach to Correspondence and Grouping Problems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mixed integer programming; quadratic constraint; bilinearities; global optimization; branch-and-bound	GLOBAL OPTIMIZATION	Data correspondence/grouping under an unknown parametric model is a fundamental topic in computer vision. Finding feature correspondences between two images is probably the most popular application of this research field, and is the main motivation of our work. It is a key ingredient for a wide range of vision tasks, including three-dimensional reconstruction and object recognition. Existing feature correspondence methods are based on either local appearance similarity or global geometric consistency or a combination of both in some heuristic manner. None of these methods is fully satisfactory, especially in the presence of repetitive image textures or mismatches. In this paper, we present a new algorithm that combines the benefits of both appearance-based and geometry-based methods and mathematically guarantees a global optimization. Our algorithm accepts the two sets of features extracted from two images as input, and outputs the feature correspondences with the largest number of inliers, which verify both the appearance similarity and geometric constraints. Specifically, we formulate the problem as a mixed integer program and solve it efficiently by a series of linear programs via a branch-and-bound procedure. We subsequently generalize our framework in the context of data correspondence/grouping under an unknown parametric model and show it can be applied to certain classes of computer vision problems. Our algorithm has been validated successfully on synthesized data and challenging real images.	[Bazin, Jean-Charles] ETH, CVG CGL, CH-8092 Zurich, Switzerland; [Li, Hongdong] Australian Natl Univ, NICTA, Canberra, ACT 2600, Australia; [Li, Hongdong] Australian Natl Univ, RSISE, Canberra, ACT 2600, Australia; [Kweon, In So] Korea Adv Inst Sci & Technol, Dept Elect Engn, RCV Lab, Taejon 305701, South Korea; [Demonceaux, Cedric] Le2i UMR 5158, F-71200 Le Creusot, France; [Vasseur, Pascal] Univ Rouen, Lab LITIS, F-76801 St Etienne, France; [Ikeuchi, Katsushi] Univ Tokyo, Inst Ind Sci, Comp Vis Lab, Meguo Ku, Tokyo 1538505, Japan	Swiss Federal Institutes of Technology Domain; ETH Zurich; Australian National University; Australian National University; Korea Advanced Institute of Science & Technology (KAIST); Universite de Bourgogne; Universite de Rouen Normandie; University of Tokyo	Bazin, JC (corresponding author), ETH, CVG CGL, Univ Str 6, CH-8092 Zurich, Switzerland.	jebazin@inf.ethz.ch; hongdong.li@anu.edu.au; iskweon@kaist.ac.kr; cedric.demonceaux@ubourgogne.fr; pascal.vasseur@univ-rouen.fr; ki@cvl.iis.utokyo.ac.jp	Demonceaux, Cédric/S-5643-2017; Kweon, In So/C-2023-2011; Bazin, Jean-Charles/M-5124-2017	Demonceaux, Cédric/0000-0001-6916-1273; 	Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative; Australian Research Council (ARC); NRF (National Research Foundation of Korea)-ANR (Agence Nationale de la Recherche-France) International Project DrAACaR [ANR-11-IS03-0003]	Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative(National Research Foundation, Singapore); Australian Research Council (ARC)(Australian Research Council); NRF (National Research Foundation of Korea)-ANR (Agence Nationale de la Recherche-France) International Project DrAACaR(French National Research Agency (ANR))	This research, which has been partially carried out at the BeingThere Centre, is in part supported by the Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office. It is also funded in part by the Australian Research Council (ARC) via Discovery and Linkage grants and by the NRF (National Research Foundation of Korea)-ANR (Agence Nationale de la Recherche-France) International Project DrAACaR (ANR-11-IS03-0003). The authors would also like to thank Jaesik Park and Seunghak Shin for their help during the early experiments on coupled object detection.	Agarwal S., 2009, P IEEE INT C COMP VI; Akbarzadeh A., 2006, P INT S 3D DAT PROC; Bartoli A, 2004, INT J COMPUT VISION, V57, P159, DOI 10.1023/B:VISI.0000013092.07433.82; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Berg A., 2005, P IEEE C COMP VIS PA; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bouguet J.Y., 2013, CAMERA CALIBRATION T; Breuel TM, 2003, COMPUT VIS IMAGE UND, V90, P258, DOI 10.1016/S1077-3142(03)00026-2; Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28; Chandraker M., 2008, P IEEE C COMP VIS PA; Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787; Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Foresti GL, 2000, IEEE T IMAGE PROCESS, V9, P1056, DOI 10.1109/83.846248; Forsyth DA, 2002, PRENT HALL PROF TECH; GENDRON B, 1994, OPER RES, V42, P1042, DOI 10.1287/opre.42.6.1042; Hartley R., 2004, ROBOTICA; Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9; Huttenlocher D.P., 1987, P IEEE INT C COMP VI; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7; Jonasson L., 2005, P INT SOC MAGNETIC R; Kahl F, 2008, INT J COMPUT VISION, V79, P271, DOI 10.1007/s11263-007-0117-1; Kim JS, 2005, IEEE T PATTERN ANAL, V27, P637, DOI 10.1109/TPAMI.2005.80; Lazebnik S., 2006, P IEEE C COMP VIS PA; Leordeanu M., 2005, P IEEE INT C COMP VI; Leordeanu M., 2009, P IEEE C COMP VIS PA; Lhuillier M, 2008, COMPUT VIS IMAGE UND, V109, P186, DOI 10.1016/j.cviu.2007.05.004; Li H., 2007, P IEEE C COMP VIS PA; Li H., 2009, P IEEE INT C COMP VI; Lovasz L., 1986, MATCHING THEORY; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151; Matas J., 2005, P IEEE INT C COMP VI; MCCORMICK GP, 1976, MATH PROGRAM, V10, P147, DOI 10.1007/BF01580665; McLachlan G. J., 2008, EM ALGORITHM EXTENSI; Mikolajczyk K., 2002, P EUR C COMP VIS; O'Leary P, 2005, IEE P-VIS IMAGE SIGN, V152, P687, DOI 10.1049/ip-vis:20045206; Oliveira R., 2006, P EUR C COMP VIS; Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131; Powell W. B., 2012, SUBSET SELECTION PRO; Seo Y., 2009, P IEEE INT C COMP VI; Sherali HD, 1992, J GLOBAL OPTIM, V2, P379, DOI DOI 10.1007/BF00122429; Shi J, 1994, P IEEE C COMP VIS PA; Spampinato D., 2009, P IEEE INT S PAR DIS; Thakoor N., 2008, P IEEE C COMP VIS PA; Torresani L., 2008, P EUR C COMP VIS; Vasconcelos C. N., 2009, P INT C EN MIN METH; Wang M, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899414; ZHANG Q, 2004, P IEEE RSJ INT C INT	50	31	33	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1565	1576		10.1109/TPAMI.2012.264	http://dx.doi.org/10.1109/TPAMI.2012.264			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681987				2022-12-18	WOS:000319060600003
J	Zheng, YJ; Lin, S; Kang, SB; Xiao, R; Gee, JC; Kambhamettu, C				Zheng, Yuanjie; Lin, Stephen; Kang, Sing Bing; Xiao, Rui; Gee, James C.; Kambhamettu, Chandra			Single-Image Vignetting Correction from Gradient Distribution Symmetries	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Vignetting correction; camera calibration; low-level vision; bias correction; nonuniformity correction	RADIOMETRIC CALIBRATION	We present novel techniques for single-image vignetting correction based on symmetries of two forms of image gradients: semicircular tangential gradients (SCTG) and radial gradients (RG). For a given image pixel, an SCTG is an image gradient along the tangential direction of a circle centered at the presumed optical center and passing through the pixel. An RG is an image gradient along the radial direction with respect to the optical center. We observe that the symmetry properties of SCTG and RG distributions are closely related to the vignetting in the image. Based on these symmetry properties, we develop an automatic optical center estimation algorithm by minimizing the asymmetry of SCTG distributions, and also present two methods for vignetting estimation based on minimizing the asymmetry of RG distributions. In comparison to prior approaches to single-image vignetting correction, our methods do not rely on image segmentation and they produce more accurate results. Experiments show our techniques to work well for a wide range of images while achieving a speed-up of 3-5 times compared to a state-of-the-art method.	[Zheng, Yuanjie; Gee, James C.] Univ Penn, Dept Radiol, Philadelphia, PA 19104 USA; [Lin, Stephen] Microsoft Res Asia, Beijing 100080, Peoples R China; [Kang, Sing Bing] Microsoft Corp, Redmond, WA 98052 USA; [Xiao, Rui] Univ Penn, Dept Biostat & Epidemiol, Philadelphia, PA 19104 USA; [Kambhamettu, Chandra] Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA	University of Pennsylvania; Microsoft; Microsoft Research Asia; Microsoft; University of Pennsylvania; University of Delaware	Zheng, YJ (corresponding author), Univ Penn, Dept Radiol, 3600 Market St,Suite 370, Philadelphia, PA 19104 USA.	Yuanjie.Zheng@uphs.upenn.edu; stevelin@microsoft.com; sbkang@microsoft.com; rxiao@mail.med.upenn.edu; James.Gee@uphs.upenn.edu; chandra@cis.udel.edu			US National Science Foundation (NSF) [CDI Type I GEO1124664, ANT0636726]; US National Institutes of Health (NIH) [EB006266, DA022807, NS045839, NS065347]; NATIONAL EYE INSTITUTE [P30EY001583] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R01EB006266] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE [R01NS065347, P30NS045839] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DRUG ABUSE [R01DA022807] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); US National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS)); NATIONAL INSTITUTE ON DRUG ABUSE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Drug Abuse (NIDA)European Commission)	This work was made possible by support from US National Science Foundation (NSF) grants CDI Type I GEO1124664, ANT0636726 and from the US National Institutes of Health (NIH) via grants EB006266, DA022807, NS045839, and NS065347.	APOSTOLOFF NE, 2004, P IEEE C COMP VIS PA; Asada N., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P186, DOI 10.1109/ICPR.1996.546016; Draper N.R., 1998, APPL REGRESSION ANAL; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559; Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P2276, DOI 10.1109/TPAMI.2010.55; Hartley R. I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P510, DOI 10.1109/ICCV.1999.791264; JUANG R, 2007, P IEEE C COMP VIS PA; Kang S.B., 2000, LNCS, V1843, P640; Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732; Kuthirummal S., 2008, P EUR C COMP VIS; LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781; Leong FJWM, 2003, J CLIN PATHOL, V56, P619, DOI 10.1136/jcp.56.8.619; Levin A., 2002, P NEUR INF PROC SYST; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Lin S, 2004, PROC CVPR IEEE, P938; LIN YH, 2007, Patent No. 7307709; Ling-Ling Wang, 1990, Machine Vision and Applications, V3, P129, DOI 10.1007/BF01214426; Litvinov A, 2005, PROC CVPR IEEE, P52; Lyu S., 2010, P IEEE INT C IM PROC; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; MATSUSHITA Y, 2007, P IEEE C COMP VIS PA; Meer P., 2005, ROBUST TECHNIQUES CO, P107; Olsen D, 2010, REMOTE SENS-BASEL, V2, P464, DOI 10.3390/rs2020464; Pouli T., 2011, COMPUT GRAPH FORUM, P1; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Roth S, 2005, PROC CVPR IEEE, P860; SAWCHUK AA, 1977, IEEE T COMPUT, V26, P34, DOI 10.1109/TC.1977.5009271; Strobl K.H., 2013, DLR CALDE DLR CALLAB; Tappen M.F., 2003, P IEEE WORKSH STAT C; Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Uyttendaele M, 2004, IEEE COMPUT GRAPH, V24, P52, DOI 10.1109/MCG.2004.1297011; WEISS Y, 2001, P 8 IEEE INT C COMP; WILLSON R, 1994, THESIS CARNEGIE MELL; WILLSON RG, 1994, J OPT SOC AM A, V11, P2946, DOI 10.1364/JOSAA.11.002946; Yu W, 2004, IEEE T CONSUM ELECTR, V50, P975, DOI 10.1109/TCE.2004.1362487; Zheng Y., 2008, P IEEE C COMP VIS PA; Zheng Y., 2009, P 25 INT C MED IM CO; Zheng Y., 2010, P IEEE C COMP VIS PA; Zheng Y., 2006, P IEEE C COMP VIS PA; Zheng Y.T., 2009, P IEEE C COMP VIS PA; Zheng YJ, 2009, IEEE T PATTERN ANAL, V31, P2243, DOI 10.1109/TPAMI.2008.263; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983	45	31	33	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1480	1494		10.1109/TPAMI.2012.210	http://dx.doi.org/10.1109/TPAMI.2012.210			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599060	Green Accepted			2022-12-18	WOS:000317857900016
J	Nguyen, HV; Porikli, F				Hien Van Nguyen; Porikli, Fatih			Support Vector Shape: A Classifier-Based Shape Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape matching; 2D and 3D representation; support vector machines	APPROXIMATE CONVEX DECOMPOSITION; OBJECT RECOGNITION; IMAGE; SIMILARITY; EFFICIENT; ALGORITHM; SEGMENTATION; ATLAS; MODEL	We introduce a novel implicit representation for 2D and 3D shapes based on Support Vector Machine (SVM) theory. Each shape is represented by an analytic decision function obtained by training SVM, with a Radial Basis Function (RBF) kernel so that the interior shape points are given higher values. This empowers support vector shape (SVS) with multifold advantages. First, the representation uses a sparse subset of feature points determined by the support vectors, which significantly improves the discriminative power against noise, fragmentation, and other artifacts that often come with the data. Second, the use of the RBF kernel provides scale, rotation, and translation invariant features, and allows any shape to be represented accurately regardless of its complexity. Finally, the decision function can be used to select reliable feature points. These features are described using gradients computed from highly consistent decision functions instead from conventional edges. Our experiments demonstrate promising results.	[Hien Van Nguyen] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20740 USA; [Porikli, Fatih] MERL, Cambridge, MA 02472 USA	University System of Maryland; University of Maryland College Park	Nguyen, HV (corresponding author), Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20740 USA.	hien@umd.edu; fatih.porikli@gmail.com						Abbasi S, 1999, MULTIMEDIA SYST, V7, P467, DOI 10.1007/s005300050147; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg A., 2005, P IEEE INT C COMP VI; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; Biswas S, 2010, IEEE T MULTIMEDIA, V12, P372, DOI 10.1109/TMM.2010.2050735; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; Chui H, 2004, IEEE T PATTERN ANAL, V26, P160, DOI 10.1109/TPAMI.2004.1262178; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817; Cossalter M., 2011, P INT C MACH LEARN; Cremers D, 2006, INT J COMPUT VISION, V66, P67, DOI 10.1007/s11263-005-3676-z; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; CURTIS SR, 1987, J OPT SOC AM A, V4, P221, DOI 10.1364/JOSAA.4.000221; Drost Bertram, 2010, 2010 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2010.5540108; Felzenszwalb P., 2007, P IEEE C COMP VIS PA; Flach B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2177, DOI 10.1109/CVPR.2011.5995726; Frome A., 2004, P EUR C COMP VIS; Gopalan R., 2010, P EUR C COMP VIS; Gorelick L., 2004, P IEEE C COMP VIS PA; Gorelick L, 2006, IEEE T PATTERN ANAL, V28, P1991, DOI 10.1109/TPAMI.2006.253; Gunsel B, 1998, PATTERN RECOGN, V31, P931, DOI 10.1016/S0031-3203(97)00076-9; Heitz G, 2009, INT J COMPUT VISION, V84, P40, DOI 10.1007/s11263-009-0228-y; Hua J, 2008, IEEE T VIS COMPUT GR, V14, P1643, DOI 10.1109/TVCG.2008.134; Joachims T., 1999, MAKING LARGE SCALE S, P41, DOI 10.17877/DE290R-5098; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kenong Wu, 1996, Proceedings of the 13th International Conference on Pattern Recognition, P14, DOI 10.1109/ICPR.1996.545983; Kourtzi Z, 2000, J NEUROSCI, V20, P3310, DOI 10.1523/JNEUROSCI.20-09-03310.2000; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Lien JM, 2008, COMPUT AIDED GEOM D, V25, P503, DOI 10.1016/j.cagd.2008.05.003; Lien JM, 2006, COMP GEOM-THEOR APPL, V35, P100, DOI 10.1016/j.comgeo.2005.10.005; Lin LA, 2010, IEEE T PATTERN ANAL, V32, P1426, DOI 10.1109/TPAMI.2009.150; Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Liu HR, 2010, PROC CVPR IEEE, P97, DOI 10.1109/CVPR.2010.5540225; Liu MZ, 2010, PROC CVPR IEEE, P3463, DOI 10.1109/CVPR.2010.5539979; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; McNeill G., 2006, 2012 IEEE C COMP VIS, P885, DOI DOI 10.1109/CVPR.2006.133; Mei Y., 2009, P INT C IM PROC; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Mokhtarian F., 1996, P INT WORKSH IM DAT; Murray SO, 2003, CEREB CORTEX, V13, P508, DOI 10.1093/cercor/13.5.508; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2003, IEEE T MED IMAGING, V22, P773, DOI 10.1109/TMI.2003.814785; Peter A.M., 2008, IEEE C COMP VIS PATT, P1; Prisacariu V. A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2185, DOI 10.1109/CVPR.2011.5995687; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; SLEPIAN D, 1976, P IEEE, V64, P292, DOI 10.1109/PROC.1976.10110; Todd JT, 2004, TRENDS COGN SCI, V8, P115, DOI 10.1016/j.tics.2004.01.006; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Van Nguyen H., 2011, ELSEVIER PATTERN REC; Wang F, 2008, IEEE T PATTERN ANAL, V30, P2011, DOI 10.1109/TPAMI.2007.70829; Yang X., 2009, P IEEE C COMP VIS PA; Zhang H., 2003, P IEEE C COMP VIS PA	60	31	31	1	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					970	982		10.1109/TPAMI.2012.186	http://dx.doi.org/10.1109/TPAMI.2012.186			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	23428433				2022-12-18	WOS:000314931000015
J	Kanatani, K				Kanatani, Kenichi			Calibration of Ultrawide Fisheye Lens Cameras by Eigenvalue Minimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fisheye lens; camera calibration; eigenvalue minimization; perturbation theorem; perspective rectification	DISTORTION	We present a new technique for calibrating ultrawide fisheye lens cameras by imposing the constraint that collinear points be rectified to be collinear, parallel lines to be parallel, and orthogonal lines to be orthogonal. Exploiting the fact that line fitting reduces to an eigenvalue problem in 3D, we do a rigorous perturbation analysis to obtain a practical calibration procedure. Doing experiments, we point out that spurious solutions exist if collinearity and parallelism alone are imposed. Our technique has many desirable properties. For example, no metric information is required about the reference pattern or the camera position, and separate stripe patterns can be displayed on a video screen to generate a virtual grid, eliminating the grid point extraction processing.	Okayama Univ, Dept Comp Sci, Okayama 7008530, Japan	Okayama University	Kanatani, K (corresponding author), Okayama Univ, Dept Comp Sci, Okayama 7008530, Japan.	kanatani@suri.cs.okayama-u.ac.jp			JSPS [24650086]	JSPS(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science)	The author thank Ryota Moriyasu of ERD Corporation and Ryohei Nakamura of Kyocera Corporation for helping with the experiments. This work was supported in part by JSPS Grant-in-Aid for Challenging Exploratory Research (24650086).	Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269; Hartley R., 2004, ROBOTICA; Hartley R, 2007, IEEE T PATTERN ANAL, V29, P1309, DOI 10.1109/TPAMI.2007.1147; Heikkila J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788; Hughes C, 2010, IEEE T PATTERN ANAL, V32, P2289, DOI 10.1109/TPAMI.2010.159; Kanatani K., 1996, STAT OPTIMIZATION GE; Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153; Kase Shota, 2009, Journal of the Japan Society of Precision Engineering, V75, P251, DOI 10.2493/jjspe.75.251; Komagata H., 2006, IEICE T INF SYST, VJ89-D, P64; Liu YC, 2008, LECT NOTES COMPUT SC, V4931, P207; Nakano M., 2005, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ88-D-II, P1847; Nakano M., 2007, IEICE T INF SYST, VJ89-D, P73; Okutsu Ryota, 2010, IEICE Transactions on Information and Systems, VJ93-D, P2645; Okutsu R., 2009, P IAPR C MACH VIS AP, P447; Onodera Y., 1992, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ75D-II, P1009; Papadopoulo T, 2000, LECT NOTES COMPUT SC, V1842, P554; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Swaminathan R, 2000, IEEE T PATTERN ANAL, V22, P1172, DOI 10.1109/34.879797; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	19	31	41	3	60	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					813	822		10.1109/TPAMI.2012.146	http://dx.doi.org/10.1109/TPAMI.2012.146			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22802113	Green Submitted			2022-12-18	WOS:000314931000004
J	Lee, JY; Matsushita, Y; Shi, BX; Kweon, IS; Ikeuchi, K				Lee, Joon-Young; Matsushita, Yasuyuki; Shi, Boxin; Kweon, In So; Ikeuchi, Katsushi			Radiometric Calibration by Rank Minimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Radiometric calibration; camera response function; rank minimization; low-rank structure	CAMERA RESPONSE; SPACE	We present a robust radiometric calibration framework that capitalizes on the transform invariant low-rank structure in the various types of observations, such as sensor irradiances recorded from a static scene with different exposure times, or linear structure of irradiance color mixtures around edges. We show that various radiometric calibration problems can be treated in a principled framework that uses a rank minimization approach. This framework provides a principled way of solving radiometric calibration problems in various settings. The proposed approach is evaluated using both simulation and real-world datasets and shows superior performance to previous approaches.	[Lee, Joon-Young; Kweon, In So] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea; [Matsushita, Yasuyuki] Microsoft Res Asia, Beijing 100080, Peoples R China; [Shi, Boxin; Ikeuchi, Katsushi] Univ Tokyo, Inst Ind Sci, Ikeuchi Lab, Meguro Ku, Tokyo 1538505, Japan	Korea Advanced Institute of Science & Technology (KAIST); Microsoft; Microsoft Research Asia; University of Tokyo	Lee, JY (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, 3210 Elect Engn Bldg E3,291 Daehak Ro, Taejon 305701, South Korea.	jylee@rcv.kaist.ac.kr; yasumat@microsoft.com; shi@cvl.iis.u-tokyo.ac.jp; iskweon@ee.kaist.ac.kr; ki@cvl.iis.u-tokyo.ac.jp	Kweon, In So/C-2023-2011	Matsushita, Yasuyui/0000-0002-1935-4752	National Strategic R&D Program for Industrial Technology, Korea; National Research Foundation of Korea (NRF); Korean government (MEST) [2011-0018250]; Global Research Network program of the National Research Foundation of Korea [D00096(I00363)]	National Strategic R&D Program for Industrial Technology, Korea; National Research Foundation of Korea (NRF)(National Research Foundation of Korea); Korean government (MEST)(Ministry of Education, Science & Technology (MEST), Republic of KoreaKorean Government); Global Research Network program of the National Research Foundation of Korea(National Research Foundation of Korea)	Joon-Young Lee is partially supported by National Strategic R&D Program for Industrial Technology, Korea, and by the National Research Foundation of Korea (NRF) grant funded by the Korean government (MEST) (No. 2011-0018250). The research described in this document conducted by Kausushi Ikeuchi is supported in part by the Global Research Network program (No. D00096(I00363)) of the National Research Foundation of Korea.	Chakrabarti A., 2009, P BRIT MACH VIS C; Debevec P. E., 1997, ACM T GRAPHIC, P369; Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529; Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88; Grossberg MD, 2003, PROC CVPR IEEE, P602; Grossberg MD, 2003, IEEE T PATTERN ANAL, V25, P1455, DOI 10.1109/TPAMI.2003.1240119; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Hwang Y, 2012, IEEE T PATTERN ANAL, V34, P1329, DOI 10.1109/TPAMI.2011.224; Joon-Young Lee, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2337, DOI 10.1109/CVPR.2011.5995409; Kim S-Y, 2008, P IEEE SARN S PRINC, V2008, P1; Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732; Lin H.T., 2011, P IEEE INT C COMP VI; Lin S, 2005, PROC CVPR IEEE, P66; Lin S, 2004, PROC CVPR IEEE, P938; Litvinov A, 2005, PROC CVPR IEEE, P52; Manders C, 2004, IEEE IMAGE PROC, P2965; Mann S, 2001, PROC CVPR IEEE, P842; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Matsushita Y., 2007, 2007 IEEE C COMP VIS, P1; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; Ng T.-T., 2007, PROC IEEE C COMPUT V, P1; Pal C, 2004, PROC CVPR IEEE, P173; Paladini M, 2010, LECT NOTES COMPUT SC, V6312, P15, DOI 10.1007/978-3-642-15552-9_2; Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138; Shafique K, 2004, IEEE IMAGE PROC, P2339; Shi BX, 2010, PROC CVPR IEEE, P1118, DOI 10.1109/CVPR.2010.5540091; Takamatsu J, 2008, LECT NOTES COMPUT SC, V5305, P623, DOI 10.1007/978-3-540-88693-8_46; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wilburn B., 2008, P IEEE C COMP VIS PA, P1; Wright J., 2009, P ADV NEUR INF PROC, V58, P289; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Zhang Zhengdong, 2010, P AS C COMP VIS; Zhengdong Zhang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2321, DOI 10.1109/CVPR.2011.5995548	37	31	34	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					144	156		10.1109/TPAMI.2012.66	http://dx.doi.org/10.1109/TPAMI.2012.66			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22392701				2022-12-18	WOS:000311127700014
J	Esmaeili, MM; Ward, RK; Fatourechi, M				Esmaeili, Mani Malek; Ward, Rabab Kreidieh; Fatourechi, Mehrdad			A Fast Approximate Nearest Neighbor Search Algorithm in the Hamming Space	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nearest neighbor search; Hamming space; multimedia fingerprinting; copy retrieval; binary embedding		A fast approximate nearest neighbor search algorithm for the (binary) Hamming space is proposed. The proposed Error Weighted Hashing (EWH) algorithm is up to 20 times faster than the popular locality sensitive hashing (LSH) algorithm and works well even for large nearest neighbor distances where LSH fails. EWH significantly reduces the number of candidate nearest neighbors by weighing them based on the difference between their hash vectors. EWH can be used for multimedia retrieval and copy detection systems that are based on binary fingerprinting. On a fingerprint database with more than 1,000 videos, for a specific detection accuracy, we demonstrate that EWH is more than 10 times faster than LSH. For the same retrieval time, we show that EWH has a significantly better detection accuracy with a 15 times lower error rate.	[Esmaeili, Mani Malek; Ward, Rabab Kreidieh] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada; [Fatourechi, Mehrdad] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6E 2P4, Canada	University of British Columbia; University of British Columbia	Esmaeili, MM (corresponding author), Univ British Columbia, Dept Elect & Comp Engn, 5500-2332 Main Mall, Vancouver, BC V6T 1Z4, Canada.	manim@ece.ubc.ca; rababw@ece.ubc.ca; mehrdadf@ece.ubc.ca			NSERC [STPGP 365164-08]	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	The authors would like to thank the anonymous reviewers for their insightful comments and suggestions. Their sincere thanks to Raymond Huang for creating the video data set used in this work. This work was supported in part by NSERC Grant STPGP 365164-08.	Bauer C, 2010, IEEE INT CON MULTI, P1667, DOI 10.1109/ICME.2010.5583568; Charikar M.S., 2002, P 34 ANN ACM S THEOR, V34, P380, DOI DOI 10.1145/509907.509965; Chaudhry R, 2010, LECT NOTES COMPUT SC, V6312, P735, DOI 10.1007/978-3-642-15552-9_53; Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593; Fatourechi M, 2012, IMAGE PROCESS SER, P459; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; HAITSMA JA, 2002, Patent No. 20020178410; Hao F, 2008, IEEE T INF FOREN SEC, V3, P203, DOI 10.1109/TIFS.2008.920726; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Malekesmaeili M., 2011, P IEEE INT WORKSH IN; Miller ML, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P182; Oostveen J., 2002, Recent Advances in Visual Information Systems. 5th International Conference VISUAL 2002. Proceedings (Lecture Notes in Computer Science Vol.2314), P117; Salakhutdinov R, 2007, P SIGIR WORKSH INF R; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Swaminathan A., 2008, P 8 ACM WORKSHOP DIG; Weiss Y., 2008, P ANN C NEUR INF PRO	17	31	36	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2481	2488		10.1109/TPAMI.2012.170	http://dx.doi.org/10.1109/TPAMI.2012.170			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22868646				2022-12-18	WOS:000309913700015
J	Domokos, C; Nemeth, J; Kato, Z				Domokos, Csaba; Nemeth, Jozsef; Kato, Zoltan			Nonlinear Shape Registration without Correspondences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image registration; diffeomorphism; nonlinear transformation; planar homography; thin plate spline; shape matching	IMAGE REGISTRATION; RECOGNITION; WARPS	In this paper, we propose a novel framework to estimate the parameters of a diffeomorphism that aligns a known shape and its distorted observation. Classical registration methods first establish correspondences between the shapes and then compute the transformation parameters from these landmarks. Herein, we trace back the problem to the solution of a system of nonlinear equations which directly gives the parameters of the aligning transformation. The proposed method provides a generic framework to recover any diffeomorphic deformation without established correspondences. It is easy to implement, not sensitive to the strength of the deformation, and robust against segmentation errors. The method has been applied to several commonly used transformation models. The performance of the proposed framework has been demonstrated on large synthetic data sets as well as in the context of various applications.	[Domokos, Csaba; Nemeth, Jozsef; Kato, Zoltan] Univ Szeged, Dept Image Proc & Comp Graph, H-6701 Szeged, Hungary	Szeged University	Domokos, C (corresponding author), Univ Szeged, Dept Image Proc & Comp Graph, POB 652, H-6701 Szeged, Hungary.	dcs@inf.u-szeged.hu; nemjozs@inf.u-szeged.hu; kato@inf.u-szeged.hu	Kato, Zoltan/AAD-6406-2019		Hungarian Scientific Research Fund-OTKA [K75637]; National Innovation Office (NIH) [CNK80370]; University of Szeged, Hungary; European Union; European Regional Development Fund [TAMOP-4.2.2/08/1/2008-0008, TAMOP-4.2.1/B-09/1/KONV-2010-0005]; ContiTech Fluid Automotive Hungaria Ltd.	Hungarian Scientific Research Fund-OTKA(Orszagos Tudomanyos Kutatasi Alapprogramok (OTKA)); National Innovation Office (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); University of Szeged, Hungary; European Union(European Commission); European Regional Development Fund(European Commission); ContiTech Fluid Automotive Hungaria Ltd.	This work has been partially supported by the Hungarian Scientific Research Fund-OTKA K75637, the grant CNK80370 of the National Innovation Office (NIH) and the Hungarian Scientific Research Fund (OTKA), a PhD Fellowship of the University of Szeged, Hungary, the European Union and cofinanced by the European Regional Development Fund within the projects TAMOP-4.2.2/08/1/2008-0008 and TAMOP-4.2.1/B-09/1/KONV-2010-0005, and by ContiTech Fluid Automotive Hungaria Ltd. Prostate images were provided by Le2i-UMR CNRS 5158, Universite de Bourgogne, Le Creusot, France, and Computer Vision and Robotics Group, Universitat de Girona, Girona, Spain.	Arsigny V, 2009, J MATH IMAGING VIS, V33, P222, DOI 10.1007/s10851-008-0135-9; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Boudier T., 2011, SNAKE PLUGIN IMAGEJ; Bronstein AM, 2008, INT J COMPUT VISION, V78, P67, DOI 10.1007/s11263-007-0078-4; Domokos C, 2010, PATTERN RECOGN, V43, P569, DOI 10.1016/j.patcog.2009.08.013; Downing M. R., 1997, Sixth International Conference on Image Processing and its Applications (Conf. Publ. No.443), P843, DOI 10.1049/cp:19971015; Florea C, 2007, LECT NOTES COMPUT SC, V4678, P587; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; Flusser J., 2009, MOMENTS MOMENT INVAR; Flusser J, 2010, INT J COMPUT VISION, V86, P72, DOI 10.1007/s11263-009-0259-4; Foulonneau A, 2009, INT J COMPUT VISION, V81, P68, DOI 10.1007/s11263-008-0163-3; Francos JM, 2003, CONF REC ASILOMAR C, P1615; Ghose S., 2010, Proceedings of the Sixth International Conference on Signal-Image Technology & Internet-Based Systems (SITIS 2010), P18, DOI 10.1109/SITIS.2010.14; GOSHTASBY A, 1988, IEEE T GEOSCI REMOTE, V26, P60, DOI 10.1109/36.3000; Guo H, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P924; HANSEN MS, 2007, P INT C COMP VIS RIO, P1; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Jain PK, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P877; Kaneko S, 2003, PATTERN RECOGN, V36, P1165, DOI 10.1016/S0031-3203(02)00081-X; Klein S, 2009, INT J COMPUT VISION, V81, P227, DOI 10.1007/s11263-008-0168-y; Kumar MP, 2004, INT CO SIG PROC COMM, P560, DOI 10.1109/SPCOM.2004.1458522; LeCun Y., 2011, MNIST DATABASE HANDW; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Lourakis M., 2008, HOMEST C C LIBR ROBU; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8; Mann S, 1997, IEEE T IMAGE PROCESS, V6, P1281, DOI 10.1109/83.623191; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; Marsland S, 2004, IEEE T MED IMAGING, V23, P1006, DOI 10.1109/TMI.2004.831228; Merris R., 2003, COMBINATORICS; Mitra J., 2010, Proceedings of the Sixth International Conference on Signal-Image Technology & Internet-Based Systems (SITIS 2010), P7, DOI 10.1109/SITIS.2010.12; Nemeth J., 2009, P IEEE INT C IM PROC, P1001; Nemeth J, 2009, IEEE I CONF COMP VIS, P2170, DOI 10.1109/ICCV.2009.5459474; Nielsen M, 2008, J MATH IMAGING VIS, V31, P221, DOI 10.1007/s10851-008-0083-4; Oprea A., 2007, 2007 INT S SIGN CIRC, V1, P1; Paulo F., 2007, 8 INT WORKSHOP IMAGE, P11; Shekhovtsov A, 2008, COMPUT VIS IMAGE UND, V112, P91, DOI 10.1016/j.cviu.2008.06.006; Simonson KM, 2007, IEEE T PATTERN ANAL, V29, P112, DOI 10.1109/TPAMI.2007.250603; Suk T, 2005, LECT NOTES COMPUT SC, V3708, P100; Suk T, 2004, IEEE T PATTERN ANAL, V26, P1364, DOI 10.1109/TPAMI.2004.89; Tagare HD, 2009, J MATH IMAGING VIS, V34, P61, DOI 10.1007/s10851-008-0129-7; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; Tu ZW, 2008, COMPUT VIS IMAGE UND, V109, P290, DOI 10.1016/j.cviu.2007.04.004; VANGOOL L, 1995, IMAGE VISION COMPUT, V13, P259, DOI 10.1016/0262-8856(95)99715-D; Ventura JA, 1997, IMAGE VISION COMPUT, V15, P889, DOI 10.1016/S0262-8856(97)00038-3; Wang JH, 2006, INT C PATT RECOG, P147; Worz S, 2008, COMPUT VIS IMAGE UND, V111, P263, DOI 10.1016/j.cviu.2007.12.003; Yezzi A, 2001, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P44, DOI 10.1109/MMBIA.2001.991698; Zagorchev L, 2006, IEEE T IMAGE PROCESS, V15, P529, DOI 10.1109/TIP.2005.863114; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	55	31	32	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					943	958		10.1109/TPAMI.2011.200	http://dx.doi.org/10.1109/TPAMI.2011.200			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	22442123				2022-12-18	WOS:000301747400009
J	Zheng, WS; Gong, SG; Xiang, T				Zheng, Wei-Shi; Gong, Shaogang; Xiang, Tao			Quantifying and Transferring Contextual Information in Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Context modeling; object detection; transfer learning		Context is critical for reducing the uncertainty in object detection. However, context modeling is challenging because there are often many different types of contextual information coexisting with different degrees of relevance to the detection of target object(s) in different images. It is therefore crucial to devise a context model to automatically quantify and select the most effective contextual information for assisting in detecting the target object. Nevertheless, the diversity of contextual information means that learning a robust context model requires a larger training set than learning the target object appearance model, which may not be available in practice. In this work, a novel context modeling framework is proposed without the need for any prior scene segmentation or context annotation. We formulate a polar geometric context descriptor for representing multiple types of contextual information. In order to quantify context, we propose a new maximum margin context (MMC) model to evaluate and measure the usefulness of contextual information directly and explicitly through a discriminant context inference method. Furthermore, to address the problem of context learning with limited data, we exploit the idea of transfer learning based on the observation that although two categories of objects can have very different visual appearance, there can be similarity in their context and/or the way contextual information helps to distinguish target objects from nontarget objects. To that end, two novel context transfer learning models are proposed which utilize training samples from source object classes to improve the learning of the context model for a target object class based on a joint maximum margin learning framework. Experiments are carried out on PASCAL VOC2005 and VOC2007 data sets, a luggage detection data set extracted from the i-LIDS data set, and a vehicle detection data set extracted from outdoor surveillance footage. Our results validate the effectiveness of the proposed models for quantifying and transferring contextual information, and demonstrate that they outperform related alternative context models.	[Zheng, Wei-Shi] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China; [Gong, Shaogang; Xiang, Tao] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England	Sun Yat Sen University; University of London; Queen Mary University London	Zheng, WS (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.	wszheng@ieee.org; sgg@eecs.qmul.ac.uk; txiang@eecs.qmul.ac.uk	Zheng, Wei-Shi/J-7661-2016	Zheng, Wei-Shi/0000-0001-8327-0003	EU [217899]; National Natural Science of Foundation of China [61102111]; NSFC-GuangDong [U0835005]; Specialized Research Fund for the Doctoral Program of Higher Education [20110171120051]; Sun Yat-sen University [35000-3181305]; EPSRC [EP/E028594/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/E028594/1] Funding Source: researchfish	EU(European Commission); National Natural Science of Foundation of China(National Natural Science Foundation of China (NSFC)); NSFC-GuangDong(National Natural Science Foundation of Guangdong Province); Specialized Research Fund for the Doctoral Program of Higher Education(Specialized Research Fund for the Doctoral Program of Higher Education (SRFDP)); Sun Yat-sen University; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This research was mainly funded by the EU FP7 project SAMURAI with grant no. 217899. Wei-Shi Zheng was also additionally supported by the National Natural Science of Foundation of China (No. 61102111), the NSFC-GuangDong (No. U0835005), Specialized Research Fund for the Doctoral Program of Higher Education (No. 20110171120051), and the 985 Project at Sun Yat-sen University under grant no. 35000-3181305 for this work. Wei-Shi Zheng was with the School of Electronic Engineering and Computer Science, Queen Mary University of London, United Kingdom.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], 2007, P 15 ACM INT C MULTI; Bao SYZ, 2010, PROC CVPR IEEE, P65, DOI 10.1109/CVPR.2010.5540229; Bar M, 1996, PERCEPTION, V25, P343, DOI 10.1068/p250343; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Bart E, 2005, P IEEE C COMP VIS PA; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X; Bosch A., 2006, P EUR C COMP VIS; CARBONETTO P, 2004, P EUR C COMP VIS; Choi W., 2011, P IEEE INT C COMP VI; Dalal N., 2005, HISTOGRAMS ORIENTED; Divvala S.K., 2009, P IEEE C COMP VIS PA; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Everingham M., 2005, P MACH LEARN CHALL W; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Galleguillos C., 2008, P IEEE C COMP VIS PA; GALLEGUILLOS C., 2010, P IEEE C COMP VIS PA; Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Gupta A., 2008, P EUR C COMP VIS; HEITZ G, 2008, P EUR C COMP VIS; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; i- IDS Team, 2006, P ANN IEEE INT CARN; Kumar S., 2005, P IEEE INT C COMP VI; Lazebnik S., 2006, P IEEE C COMP VIS PA; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Malik J., 2003, P IEEE INT C COMP VI; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; MURPHY K, 2003, ADV NEURAL INFORM PR; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Pan S.J., 2008, AAAI; Pan SJ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1187; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Perko R., 2007, P INT WORKSH ATT COG; Perko R., 2008, P INT WORKSH ATT COG; Rabinovich A., 2007, P IEEE INT C COMP VI; Raina R, 2007, 24 ANN INT C MACH LE, V227, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]; Rohrbach M., 2010, P IEEE INT C COMP VI; Savarese S., 2006, P IEEE CS C COMP VIS; SINGHAL A, 2003, P IEEE C COMP VIS PA; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; TORRALBA A, 2003, P IEEE INT C COMP VI; VEDALDI A., 2009, P IEEE INT C COMP VI; Wolf L, 2006, INT J COMPUT VISION, V69, P251, DOI 10.1007/s11263-006-7538-0; Wongun Choi, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1282, DOI 10.1109/ICCVW.2009.5457461; Zhang Y., 2010, P 24 C UNC ART INT; ZHENG W. S., 2009, P IEEE INT C COMP VI; Zweig A., 2007, P 11 IEEE INT C COMP	52	31	31	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2012	34	4					762	777		10.1109/TPAMI.2011.164	http://dx.doi.org/10.1109/TPAMI.2011.164			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	896PO	21844619	Green Published			2022-12-18	WOS:000300581700010
J	Gallo, O; Manduchi, R				Gallo, Orazio; Manduchi, Roberto			Reading 1D Barcodes with Mobile Phones Using Deformable Templates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Barcodes; UPC-A; mobile devices; deformable templates		Camera cellphones have become ubiquitous, thus opening a plethora of opportunities for mobile vision applications. For instance, they can enable users to access reviews or price comparisons for a product from a picture of its barcode while still in the store. Barcode reading needs to be robust to challenging conditions such as blur, noise, low resolution, or low-quality camera lenses, all of which are extremely common. Surprisingly, even state-of-the-art barcode reading algorithms fail when some of these factors come into play. One reason resides in the early commitment strategy that virtually all existing algorithms adopt: The image is first binarized and then only the binary data are processed. We propose a new approach to barcode decoding that bypasses binarization. Our technique relies on deformable templates and exploits all of the gray-level information of each pixel. Due to our parameterization of these templates, we can efficiently perform maximum likelihood estimation independently on each digit and enforce spatial coherence in a subsequent step. We show by way of experiments on challenging UPC-A barcode images from five different databases that our approach outperforms competing algorithms. Implemented on a Nokia N95 phone, our algorithm can localize and decode a barcode on a VGA image (640 x 480, JPEG compressed) in an average time of 400-500 ms.	[Gallo, Orazio; Manduchi, Roberto] Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA	University of California System; University of California Santa Cruz	Gallo, O (corresponding author), Univ Calif Santa Cruz, 1156 High St, Santa Cruz, CA 95064 USA.	orazio@soe.ucsc.edu; manduchi@soe.ucsc.edu			US National Science Foundation (NSF) [IIS-0835645]; US National Institutes of Health [1 R21 EY017003-01A1]; NATIONAL EYE INSTITUTE [R21EY017003] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI))	This material is based upon work supported in part by the US National Science Foundation (NSF) under Grant No. IIS-0835645 and in part by the the US National Institutes of Health under Grant 1 R21 EY017003-01A1.	ADELMANN R, 2006, P INF WORKSH MOB EMB; Chai D., 2005, 2005 5 INT C INF COM, P1595; Kresic-Juric S, 2006, PATTERN RECOGN LETT, V27, P1665, DOI 10.1016/j.patrec.2006.03.014; Muniz R., 1999, Proceedings 1999 International Conference on Information Intelligence and Systems (Cat. No.PR00446), P313, DOI 10.1109/ICIIS.1999.810282; Ohbuchi E, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P260, DOI 10.1109/CW.2004.23; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PAVLIDIS T, 1990, COMPUTER, V23, P74, DOI 10.1109/2.55471; TEKIN E, 2009, P 6 CAN C COMP ROB V; TROPF A, 2006, P IEEE INT C AC SPEE, V2; *UCSC, 2010, UCSC UPC DAT; Wachenfeld S, 2008, INT C PATT RECOG, P583; Wang KQ, 2007, INT J IMAGE GRAPH, V7, P529, DOI 10.1142/S0219467807002805; Zhang CH, 2006, IEEE IMAGE PROC, P497, DOI 10.1109/ICIP.2006.312435	13	31	37	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1834	1843		10.1109/TPAMI.2010.229	http://dx.doi.org/10.1109/TPAMI.2010.229			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21173448	Green Accepted, Green Submitted			2022-12-18	WOS:000292740000010
J	Li, Y; Gu, L; Kanade, T				Li, Yan; Gu, Leon; Kanade, Takeo			Robustly Aligning a Shape Model and Its Application to Car Alignment of Unknown Pose	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape alignment; RANSAC; ASM	PARAMETER-ESTIMATION; RECOGNITION	Precisely localizing in an image a set of feature points that form a shape of an object, such as car or face, is called alignment. Previous shape alignment methods attempted to fit a whole shape model to the observed data, based on the assumption of Gaussian observation noise and the associated regularization process. However, such an approach, though able to deal with Gaussian noise in feature detection, turns out not to be robust or precise because it is vulnerable to gross feature detection errors or outliers resulting from partial occlusions or spurious features from the background or neighboring objects. We address this problem by adopting a randomized hypothesis-and-test approach. First, a Bayesian inference algorithm is developed to generate a shape-and-pose hypothesis of the object from a partial shape or a subset of feature points. For alignment, a large number of hypotheses are generated by randomly sampling subsets of feature points, and then evaluated to find the one that minimizes the shape prediction error. This method of randomized subset-based matching can effectively handle outliers and recover the correct object shape. We apply this approach on a challenging data set of over 5,000 different-posed car images, spanning a wide variety of car types, lighting, background scenes, and partial occlusions. Experimental results demonstrate favorable improvements over previous methods on both accuracy and robustness.	[Li, Yan] Microsoft Corp, Redmond, WA 98052 USA; [Gu, Leon] WorldQuant LLC, Old Greenwich, CT 06870 USA; [Kanade, Takeo] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Microsoft; Carnegie Mellon University	Li, Y (corresponding author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.	roli@microsoft.com; gu@cs.cmu.edu; tk@cs.cmu.edu						Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; [Anonymous], 2006, COMP VIS PATT REC 20, DOI DOI 10.1109/CVPR.2006.11; BJORCK A, 1996, P SIAM; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BLANZ V, 1999, P 26 ANN C COMP GRAP, P187, DOI DOI 10.1145/311535.311556; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; BUNTINE WL, 1991, ARTIFICIAL INTELLIGE; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COOTES TF, 1997, P BRIT MACH VIS C, P110; COOTES TF, 2000, P 4 IEEE INT C AUT F; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; FELZENSZWALB P, 2007, P IEEE C COMP VIS PA, P1; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gower J. C., 2004, PROCRUSTES PROBLEMS; Jiao F, 2003, PROC CVPR IEEE, P321; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Lepetit V, 2005, PROC CVPR IEEE, P775; LI Y, 2009, THESIS CARNEGIE MELL; LIANG L, 2008, P 10 EUR C COMP VIS; Liang L., 2006, CVPR, V1, P1313; LIU C, 2002, P 7 EUR C COMP VIS; Maree R, 2005, PROC CVPR IEEE, P34; Moosmann F., 2006, ADV NEURAL INF PROCE, V19; MOOSMANN F, 2006, P ECCV WORKSH REPR U; QUINLAN JR, 1987, P APPL EXP SYST; RAVISHANKAR S, 2008, P 10 EUR C COMP VI 1; ROGERS M, 2002, P EUR C COMP VIS; ROMDHANI S, 1999, P BRIT MACH VIS C; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; TU J, 2004, P IEEE CS C COMP VIS; WANG Y, 2008, P IEEE C COMP VIS PA; YAN S, 2003, P 9 IEEE INT C COMP; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2; Zhou Y, 2005, PROC CVPR IEEE, P741; ZHOU Y, 2003, P IEEE CS C COMP VIS; ZUO F, 2004, P INT C IM PROC	43	31	34	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1860	1876		10.1109/TPAMI.2011.40	http://dx.doi.org/10.1109/TPAMI.2011.40			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21358003				2022-12-18	WOS:000292740000012
J	Rajwade, A; Banerjee, A; Rangarajan, A				Rajwade, Ajit; Banerjee, Arunava; Rangarajan, Anand			Probability Density Estimation Using Isocontours and Isosurfaces: Application to Information-Theoretic Image Registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Probability density estimation; isocontours; isosurfaces; level sets; transformation of random variables; computational geometry; image registration	MUTUAL INFORMATION; MAXIMIZATION	We present a new geometric approach for determining the probability density of the intensity values in an image. We drop the notion of an image as a set of discrete pixels and assume a piecewise-continuous representation. The probability density can then be regarded as being proportional to the area between two nearby isocontours of the image surface. Our paper extends this idea to joint densities of image pairs. We demonstrate the application of our method to affine registration between two or more images using information-theoretic measures such as mutual information. We show cases where our method outperforms existing methods such as simple histograms, histograms with partial volume interpolation, Parzen windows, etc., under fine intensity quantization for affine image registration under significant image noise. Furthermore, we demonstrate results on simultaneous registration of multiple images, as well as for pairs of volume data sets, and show some theoretical properties of our density estimator. Our approach requires the selection of only an image interpolant. The method neither requires any kind of kernel functions ( as in Parzen windows), which are unrelated to the structure of the image in itself, nor does it rely on any form of sampling for density estimation.	[Rajwade, Ajit; Banerjee, Arunava; Rangarajan, Anand] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA	State University System of Florida; University of Florida	Rajwade, A (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, CSE Bldg, Gainesville, FL 32611 USA.	avr@cise.ufl.edu; arunava@cise.ufl.edu; anand@cise.ufl.edu	Rangarajan, Anand/A-8652-2009	Rangarajan, Anand/0000-0001-8695-8436; Banerjee, Arunava/0000-0001-9381-4940	US National Science Foundation [IIS-0307712, R01NS046812]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE [R01NS046812] Funding Source: NIH RePORTER	US National Science Foundation(National Science Foundation (NSF)); NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS))	This work is partially supported by US National Science Foundation grant IIS-0307712 and US National Institutes of Healths grant R01NS046812. The authors would like to thank the anonymous reviewers for their thoughtful comments on this paper. The 2D isocontour-based density estimator reported in this paper is available under the terms of the GNU General Public License (GPL version 2) at http://www.cise.ufl.edu/~anand/isomatch.html.	Beirlant J., 1997, INT J MATH STAT SCI, V6, P17; Boes JL, 1999, LECT NOTES COMPUT SC, V1679, P606; Chen HM, 2003, INT J REMOTE SENS, V24, P3701, DOI 10.1080/0143116031000117047; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; COSTA J, 2003, P 37 AS C SIGN SYST, V1, P316; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; De Berg Mark, 1997, COMPUTATIONAL GEOMET; DOWNIE TR, 2001, SANKHY B 2, V63, P181; Dowson NDH, 2006, INT C PATT RECOG, P1186; FELLER W, 1948, ANN MATH STAT, V19, P177, DOI 10.1214/aoms/1177730243; Hadjidemetriou E, 2001, INT J COMPUT VISION, V45, P5, DOI 10.1023/A:1012356022268; KADIR T, 2005, P BRIT MACH VIS C BM, P589; Karacali B, 2007, INT J COMPUT VISION, V72, P219, DOI 10.1007/s11263-006-8704-0; Leventon ME, 1998, LECT NOTES COMPUT SC, V1496, P1057, DOI 10.1007/BFb0056295; Ma B, 2000, IEEE IMAGE PROC, P481, DOI 10.1109/ICIP.2000.901000; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; Maes F, 2003, P IEEE, V91, P1699, DOI 10.1109/JPROC.2003.817864; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Peter AM, 2008, IEEE T IMAGE PROCESS, V17, P458, DOI 10.1109/TIP.2008.918038; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Rajwade A, 2006, I S BIOMED IMAGING, P840; Rajwade Ajit, 2006, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2, P1769; Rao M, 2004, IEEE T INFORM THEORY, V50, P1220, DOI 10.1109/TIT.2004.828057; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; SABUNCU MR, 2005, P IEEE C AC SPEECH S, V2, P253; Shekhar R, 2002, IEEE T MED IMAGING, V21, P9, DOI 10.1109/42.981230; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Thevenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976; *U MANCH, 2008, TIN IS ACR TINA IM D; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Yang CJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P464; Zhang J, 2004, PROC CVPR IEEE, P848; Zhang JY, 2005, IEEE I CONF COMP VIS, P725	35	31	34	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2009	31	3					475	491		10.1109/TPAMI.2008.97	http://dx.doi.org/10.1109/TPAMI.2008.97			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	394VO	19147876	Green Accepted			2022-12-18	WOS:000262480200007
J	Bayerl, P; Neumann, H				Bayerl, Pierre; Neumann, Heiko			A fast biologically inspired algorithm for recurrent motion estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion estimation; computational models of vision; recurrent information processing; motion aperture problem; algorithms	VISUAL AREA; NEURAL MECHANISMS; SELECTION MODEL; MT; PERCEPTION; DIRECTION; NEURONS; MONKEY; FIELDS	We have previously developed a neurodynamical model of motion segregation in cortical visual area V1 and MT of the dorsal stream. The model explains how motion ambiguities caused by the motion aperture problem can be solved for coherently moving objects of arbitrary size by means of cortical mechanisms. The major bottleneck in the development of a reliable biologically inspired technical system with real-time motion analysis capabilities based on this neural model is the amount of memory necessary for the representation of neural activation in velocity space. We propose a sparse coding framework for neural motion activity patterns and suggest a means by which initial activities are detected efficiently. We realize neural mechanisms such as shunting inhibition and feedback modulation in the sparse framework to implement an efficient algorithmic version of our neural model of cortical motion segregation. We demonstrate that the algorithm behaves similarly to the original neural model and is able to extract image motion from real world image sequences. Our investigation transfers a neuroscience model of cortical motion computation to achieve technologically demanding constraints such as real-time performance and hardware implementation. In addition, the proposed biologically inspired algorithm provides a tool for modeling investigations to achieve acceptable simulation time.	Univ Ulm, Dept Neural Informat Proc, D-89069 Ulm, Germany	Ulm University	Bayerl, P (corresponding author), Univ Ulm, Dept Neural Informat Proc, D-89069 Ulm, Germany.	pierre.bayerl@uni-ulm.de; heiko.neumann@uni-ulm.de						ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ALBRIGHT TD, 1984, J NEUROPHYSIOL, V52, P1106, DOI 10.1152/jn.1984.52.6.1106; ALBRIGHT TD, 1987, EXP BRAIN RES, V65, P582; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Bayerl P, 2004, NEURAL COMPUT, V16, P2041, DOI 10.1162/0899766041732404; BROX T, 2004, P 8 EUR C COMP VIS, V4, P25; Deneve S, 1999, NAT NEUROSCI, V2, P740, DOI 10.1038/11205; DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193; Forstner W., 1986, S INT SOC PHOT REM S, V26, P150; GROSSBERG S, 1980, PSYCHOL REV, V87, P1, DOI 10.1037/0033-295X.87.1.1; Harris JW, 1998, HDB MATH COMPUTATION, P824; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455; Kalman RE., 1960, J BASIC ENG-T ASME, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; KNUDSEN EI, 1987, ANNU REV NEUROSCI, V10, P41, DOI 10.1146/annurev.ne.10.030187.000353; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; MAUNSELL JHR, 1983, J NEUROPHYSIOL, V49, P1127, DOI 10.1152/jn.1983.49.5.1127; MISHKIN M, 1983, TRENDS NEUROSCI, V6, P414, DOI 10.1016/0166-2236(83)90190-X; Movshon J. A., 1985, EXPT BRAIN RES S, V11, P117, DOI DOI 10.1007/978-3-662-09224-8_7.; Musser DR, 1997, SOFTWARE PRACT EXPER, V27, P983, DOI 10.1002/(SICI)1097-024X(199708)27:8<983::AID-SPE117>3.0.CO;2-#; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; Nicolescu M, 2003, IEEE T PATTERN ANAL, V25, P492, DOI 10.1109/TPAMI.2003.1190574; NOWLAN SJ, 1995, J NEUROSCI, V15, P1195; NOWLAN SJ, 1994, J OPT SOC AM A, V11, P3177, DOI 10.1364/JOSAA.11.003177; QIAN N, 1994, J NEUROSCI, V14, P7381; Simoncelli EP, 1998, VISION RES, V38, P743, DOI 10.1016/S0042-6989(97)00183-1; SPORNS O, 1989, P NATL ACAD SCI USA, V86, P7265, DOI 10.1073/pnas.86.18.7265; Stein F, 2004, LECT NOTES COMPUT SC, V3175, P79; VANESSEN DC, 1994, NEURON, V13, P1, DOI 10.1016/0896-6273(94)90455-3; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weiss Y, 2002, NAT NEUROSCI, V5, P598, DOI 10.1038/nn858; [No title captured]; [No title captured]; [No title captured]; [No title captured]	35	31	35	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					246	260		10.1109/TPAMI.2007.24	http://dx.doi.org/10.1109/TPAMI.2007.24			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV	17170478	Green Submitted			2022-12-18	WOS:000242826900006
J	Marinai, S; Marino, E; Soda, G				Marinai, Simone; Marino, Emanuele; Soda, Giovanni			Font adaptive word indexing of modern printed documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; digital libraries; document image retrieval; heuristic oversegmentation; holistic word representation; modern documents; self organizing map	RETRIEVAL; RECOGNITION	We propose an approach for the word- level indexing of modern printed documents which are difficult to recognize using current OCR engines. By means of word- level indexing, it is possible to retrieve the position of words in a document, enabling queries involving proximity of terms. Web search engines implement this kind of indexing, allowing users to retrieve Web pages on the basis of their textual content. Nowadays, digital libraries hold collections of digitized documents that can be retrieved either by browsing the document images or relying on appropriate metadata assembled by domain experts. Word indexing tools would therefore increase the access to these collections. The proposed system is designed to index homogeneous document collections by automatically adapting to different languages and font styles without relying on OCR engines for character recognition. The approach is based on three main ideas: the use of Self Organizing Maps ( SOM) to perform unsupervised character clustering, the definition of one suitable vector- based word representation whose size depends on the word aspect- ratio, and the run- time alignment of the query word with indexed words to deal with broken and touching characters. The most appropriate applications are for processing modern printed documents ( 17th to 19th centuries) where current OCR engines are less accurate. Our experimental analysis addresses six data sets containing documents ranging from books of the 17th century to contemporary journals.	Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy	University of Florence	Marinai, S (corresponding author), Univ Florence, Dipartimento Sistemi & Informat, Via S Marta 3, I-50139 Florence, Italy.	marinai@dsi.unifi.it; marino@dsi.unifi.it; soda@dsi.unifi.it		MARINAI, SIMONE/0000-0002-6702-2277				BAEZAYATES R, 1999, MODERN INFORMATION R; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; Cesarini F, 1998, IEEE T PATTERN ANAL, V20, P730, DOI 10.1109/34.689303; DECURTINS J, 1995, P SOC PHOTO-OPT INS, V2422, P270, DOI 10.1117/12.205829; Doermann D, 1998, COMPUT VIS IMAGE UND, V70, P287, DOI 10.1006/cviu.1998.0692; Haffner P., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P625, DOI 10.1109/ICDAR.1999.791865; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9; Kohonen T., 2001, SPRINGER SERIES INFO; Konig A, 2000, IEEE T NEURAL NETWOR, V11, P615, DOI 10.1109/72.846733; Lopresti DP, 1996, PROCEEDINGS OF THE THIRD FORUM ON RESEARCH AND TECHNOLOGY ADVANCES IN DIGITAL LIBRARIES (ADL '96), P76, DOI 10.1109/ADL.1996.502518; Lu Y, 2004, IEEE T KNOWL DATA EN, V16, P1398, DOI 10.1109/TKDE.2004.76; LU Y, 1995, PATTERN RECOGN, V28, P67, DOI 10.1016/0031-3203(94)00068-W; Madhvanath S, 2001, IEEE T PATTERN ANAL, V23, P149, DOI 10.1109/34.908966; Marinai S, 2005, PROC INT CONF DOC, P432, DOI 10.1109/ICDAR.2005.150; Marinai S, 2005, IEEE T PATTERN ANAL, V27, P23, DOI 10.1109/TPAMI.2005.4; Marinai S, 2003, PROC INT CONF DOC, P223; Marukawa K, 1997, PATTERN RECOGN, V30, P1361, DOI 10.1016/S0031-3203(96)00155-0; Mitra M., 2000, Information Retrieval, V2, P141, DOI 10.1023/A:1009950525500; Nagasaki T, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P280, DOI 10.1109/IWFHR.2004.36; Rath T. M., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P369, DOI 10.1145/1008992.1009056; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Smeaton AF, 1997, PROC INT CONF DOC, P974, DOI 10.1109/ICDAR.1997.620655; Taghva K, 1996, ACM T INFORM SYST, V14, P64, DOI 10.1145/214174.214180; Tan CL, 2002, IEEE T PATTERN ANAL, V24, P838, DOI 10.1109/TPAMI.2002.1008389; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Terasawa K, 2005, PROC INT CONF DOC, P437; Trenkle J. M., 1993, Proceedings. Second Annual Symposium on Document Analysis and Information Retrieval, P105; Williams DP, 2000, MATER RES INNOV, V3, P226, DOI 10.1007/s100190050007; Witten I.H., 1999, MORGAN KAUFMANN SERI	31	31	36	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1187	1199		10.1109/TPAMI.2006.162	http://dx.doi.org/10.1109/TPAMI.2006.162			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886856				2022-12-18	WOS:000238162400002
J	Yang, L				Yang, L			Building k-connected neighborhood graphs for isometric data embedding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data embedding; graph connectivity; manifold learning; network flow	PROJECTION; NETWORK	Isometric data embedding using geodesic distance requires the construction of a connected neighborhood graph so that the geodesic distance between every pair of data points can be estimated. This paper proposes an approach for constructing k-connected neighborhood graphs. The approach works by applying a greedy algorithm to add each edge, in a nondecreasing order of edge length, to a neighborhood graph if end vertices of the edge are not yet k-connected on the graph. The k-connectedness between vertices is tested using a network flow technique by assigning every vertex a unit flow capacity. This approach is applicable to a wide range of data. Experiments show that it gives better estimation of geodesic distances than other approaches, especially when the data are undersampled or nonuniformly distributed.	Western Michigan Univ, Dept Comp Sci, Kalamazoo, MI 49008 USA	Western Michigan University	Yang, L (corresponding author), Western Michigan Univ, Dept Comp Sci, 1903 W Michigan Ave, Kalamazoo, MI 49008 USA.	li.yang@wmich.edu						Balasubramanian M, 2002, SCIENCE, V295; Cox T.F., 2001, MULTIDIMENSIONAL SCA, V2nd; Demartines P, 1997, IEEE T NEURAL NETWOR, V8, P148, DOI 10.1109/72.554199; Dinitz Y, 1970, DOKL AKAD NAUK SSSR, V11, P1277; EDMONDS J, 1972, J ACM, V19, P248, DOI 10.1145/321694.321699; Even S., 1975, SIAM Journal on Computing, V4, P507, DOI 10.1137/0204043; Ford L. R. J., 1962, FLOWS NETWORKS; Garay M., 1979, COMPUTERS INTRACTABI; KRUSKAL JB, 1971, IEEE T COMPUT, VC 20, P1614, DOI 10.1109/T-C.1971.223184; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Lee JA, 2004, NEUROCOMPUTING, V57, P49, DOI 10.1016/j.neucom.2004.01.007; MATULA DW, 1978, J COMB THEORY B, V24, P1, DOI 10.1016/0095-8956(78)90071-0; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Tarjan RE., 1974, P 6 ANN ACM S THEOR, P185; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Yang L, 2005, IEEE T PATTERN ANAL, V27, P1680, DOI 10.1109/TPAMI.2005.192; Yang L, 2004, INT C PATT RECOG, P196; Yang L, 2004, IEEE T PATTERN ANAL, V26, P1243, DOI 10.1109/TPAMI.2004.66; YANG L, 2005, PATTERN RECOGN, V26, P2015; ZHA H, 2003, P 20 INT C MACH LEAR, P864	20	31	38	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					827	831		10.1109/TPAMI.2006.89	http://dx.doi.org/10.1109/TPAMI.2006.89			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640268				2022-12-18	WOS:000235885700014
J	Munoz, A; Moguerza, JM				Munoz, A; Moguerza, JM			Estimation of high-density regions using one-class neighbor machines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						density estimation; kernel methods; One-Class Support Vector Machines	SUPPORT	In this paper, we investigate the problem of estimating high-density regions from univariate or multivariate data samples. We estimate minimum volume sets, whose probability is specified in advance, known in the literature as density contour clusters. This problem is strongly related to One-Class Support Vector Machines (OCSVM). We propose a new method to solve this problem, the One-Class Neighbor Machine (OCNM) and we show its properties. In particular, the OCNM solution asymptotically converges to the exact minimum volume set prespecified. Finally, numerical results illustrating the advantage of the new method are shown.	Univ Carlos 3, Dept Stat, Getafe 28903, Madrid, Spain; Univ Rey Juan Carlos, Sch Engn, Mostoles 28933, Madrid, Spain	Universidad Carlos III de Madrid; Universidad Rey Juan Carlos	Munoz, A (corresponding author), Univ Carlos 3, Dept Stat, C-Madrid 126, Getafe 28903, Madrid, Spain.	alberto.munoz@uc3m.es; javier.moguerza@urjc.es	Moguerza, Javier M./AAA-6836-2020	M. Moguerza, Javier/0000-0003-1415-1961; MUNOZ, ALBERTO/0000-0001-8982-0678				Alpaydin E, 1998, KYBERNETIKA, V34, P369; Devroye L, 1999, STAT PROBABIL LETT, V44, P299, DOI 10.1016/S0167-7152(99)00021-8; Devroye L., 1979, CAN J STAT, V7, P159, DOI [10.2307/3315115, DOI 10.2307/3315115]; Mangasarian O.L., 1990, SIAM NEWS, V23, P1; Ratsch G, 2002, IEEE T PATTERN ANAL, V24, P1184, DOI 10.1109/TPAMI.2002.1033211; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B., 1995, KDD; Silverman B.W., 1990, DENSITY ESTIMATION S; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Tsybakov AB, 1997, ANN STAT, V25, P948, DOI 10.1214/aos/1069362732	10	31	33	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					476	480		10.1109/TPAMI.2006.52	http://dx.doi.org/10.1109/TPAMI.2006.52			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526433				2022-12-18	WOS:000234517900013
J	Veeramachaneni, S; Nagy, G				Veeramachaneni, S; Nagy, G			Style context with second-order statistics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						interpattern feature dependence; writer consistency; continuous styles; quadratic discriminant classifier	SEGMENTATION; RECOGNITION	Patterns often occur as homogeneous groups or fields generated by the same source. In multisource recognition problems, such isogeny induces statistical dependencies between patterns ( termed style context). We model these dependencies by second-order statistics and formulate the optimal classifier for normally distributed styles. We show that model parameters estimated only from pairs of classes suffice to train classifiers for any test field length. Although computationally expensive, the style-conscious classifier reduces the field error rate by up to 20 percent on quadruples of handwritten digits from standard NIST data sets.	Ist Ric Sci & Tecnol, Automated Reasoning Div, I-38050 Trento, Italy; Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Johnsson Engn Ctr 6020, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Veeramachaneni, S (corresponding author), Ist Ric Sci & Tecnol, Automated Reasoning Div, Via Sommarive 18, I-38050 Trento, Italy.	sriharsha@itc.it; nagy@ecse.rpi.edu		Nagy, George/0000-0002-0521-1443				Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; Dehkordi M. E., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P781, DOI 10.1109/ICDAR.1999.791904; Duda R.O., 1973, J ROYAL STAT SOC SER; FUJISAWA H, 1992, P IEEE, V80, P1079, DOI 10.1109/5.156471; Fukunaga K., 1972, INTRO STAT PATTERN R; Gilloux M., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P299, DOI 10.1109/ICDAR.1993.395727; Grother P., 1995, 19 NIST; HONG T, 1995, P 3 INT C DOC AN REC, V1, P442; KAWATANI T, 1995, P 3 INT C DOC AN REC, V1, P98; Koshinaka T., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P154, DOI 10.1109/ICDAR.2001.953774; LIU CL, 2002, INT J DOC ANAL RECOG, V4, P191; NAGY G, 1992, P 11 INT C PATT REC, V2, P225; PLAMONDON R, 1999, WILEY ENCY ELECT ELE, V15, P123; Sarkar P, 2005, IEEE T PATTERN ANAL, V27, P88, DOI 10.1109/TPAMI.2005.18; Sarkar P, 2001, PROC INT CONF DOC, P1169, DOI 10.1109/ICDAR.2001.953969; SARKAR P, 2000, THESIS RENSSELAER PO; SHI H, 1997, P 4 INT C DOC AN REC, V1, P39; SHRIDAR M, 1995, P IEEE INT C SYST MA, V3, P2341; VEERAMACHANENI S, 2002, THESIS RENSSELAER PO; Zramdini A, 1998, IEEE T PATTERN ANAL, V20, P877, DOI 10.1109/34.709616	21	31	34	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2005	27	1					14	22		10.1109/TPAMI.2005.19	http://dx.doi.org/10.1109/TPAMI.2005.19			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	870BE	15628265				2022-12-18	WOS:000225028200003
J	Preece, SJ; Claridge, E				Preece, SJ; Claridge, E			Spectral filter optimization for the recovery of parameters which describe human skin	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color; image analysis; spectral filters; optimization; skin color; medical imaging	BAND SELECTION; COLOR CONSTANCY; REFLECTANCE	This paper presents a method for finding spectral filters that minimize the error associated with histological parameters characterizing normal skin tissue. These parameters can be recovered from digital images of the skin using a physics-based model of skin coloration. The relationship between the image data and histological parameter values is defined as a mapping function from the image space to the parameter space. The accuracy of this function is determined by the choice of optical filters. An optimization criterion for finding the optimal filters is defined by combing methodology from differential geometry with statistical error analysis. It is shown that the magnitude of errors associated with the optimal filters is typically half of that for typical RGB filters on a three-parameter model of human skin coloration. Finally, other medical image applications are identified to which this generic methodology could be applied.	Astron Clin, Cambridge CB3 7RY, England; Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England	University of Cambridge; University of Birmingham	Preece, SJ (corresponding author), Astron Clin, Cambridge CB3 7RY, England.	sjp@cs.bham.ac.uk; E.Claridge@cs.bham.ac.uk						ANDERSON RR, 1981, J INVEST DERMATOL, V77, P13, DOI 10.1111/1523-1747.ep12479191; Angelopoulou E, 2001, PROC CVPR IEEE, P635; Arridge SR, 1997, PHYS MED BIOL, V42, P841, DOI 10.1088/0031-9155/42/5/008; Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2631, DOI 10.1109/36.803411; Claridge E, 2003, LECT NOTES COMPUT SC, V2732, P306; Cotton S, 1997, LECT NOTES COMPUT SC, V1230, P501; Cotton SD, 1996, P SOC PHOTO-OPT INS, V2708, P814, DOI 10.1117/12.237846; Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885; HEALEY G, 1994, J OPT SOC AM A, V11, P3003, DOI 10.1364/JOSAA.11.003003; Karlholm J, 2002, APPL OPTICS, V41, P6786, DOI 10.1364/AO.41.006786; Kendall M.G., 1969, ADV THEORY STAT, V1; Kubelka P., 1931, Z TECH PHYS, V12, P593, DOI DOI 10.4236/MSCE.2014.28004; LIPSCHULTZ M, 1969, DIFFERENTIAL GEOMETR; Lyons L., 1986, STAT NUCL PARTICLE P; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; Moncrieff M, 2002, BRIT J DERMATOL, V146, P448, DOI 10.1046/j.1365-2133.2002.04569.x; Ohtsuki T, 1998, J IMAGING SCI TECHN, V42, P554; Prahl SA., 1989, SPIE SERIES, V10305, DOI DOI 10.1117/12.2283590; Preece SJ, 2002, PHYS MED BIOL, V47, P2863, DOI 10.1088/0031-9155/47/16/303; Price JC, 1998, REMOTE SENS ENVIRON, V64, P316, DOI 10.1016/S0034-4257(98)00008-X; Shen SS, 2002, PROC SPIE, V4725, P18, DOI 10.1117/12.478755; STOERRING MAH, 2001, J ROBOTICS AUTONOMOU, V35, P131; Tsumura N, 1999, J OPT SOC AM A, V16, P2169, DOI 10.1364/JOSAA.16.002169; WAN S, 1981, PHOTOCHEM PHOTOBIOL, V34, P493, DOI 10.1111/j.1751-1097.1981.tb09391.x	24	31	32	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					913	922		10.1109/TPAMI.2004.36	http://dx.doi.org/10.1109/TPAMI.2004.36			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579949	Green Submitted			2022-12-18	WOS:000221323900008
J	Vega, IR; Sarkar, S				Vega, IR; Sarkar, S			Statistical motion model based on the change of feature relationships: Human gait-based recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; gait recognition; relational statistics; probabilistic modeling		We offer a novel representation scheme for view-based motion analysis using just the change in the relational statistics among the detected image features, without the need for object models, perfect segmentation, or part-level tracking. We model the relational statistics using the probability that a random group of features in an image would exhibit a particular relation. To reduce the representational combinatorics of these relational distributions, we represent them in a Space of Probability Functions (SoPF), where the Euclidean distance is related to the Bhattacharya distance between probability functions. Different motion types sweep out different traces in this space. We demonstrate and evaluate the effectiveness of this representation in the context of recognizing persons from gait. In particular, on outdoor sequences 1) we demonstrate the possibility of recognizing persons from not only walking gait, but running and jogging gaits as well, 2) we study recognition robustness with respect to view-point variation, and 3) we benchmark the recognition performance on a database of 71 subjects walking on soft grass surface, where we achieve around 90 percent recognition rates in the presence of viewpoint variation.	Technol Inst Chihuahua, Chihuahua 31310, Chih, Mexico; Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	State University System of Florida; University of South Florida	Vega, IR (corresponding author), Technol Inst Chihuahua, Ave Tecnol 2909, Chihuahua 31310, Chih, Mexico.	irobledo@itchihuahua.edu.mx; sarkar@csee.usf.edu	Sarkar, Sudeep/ABD-7629-2021; Robledo, Isidro/AAR-9185-2020; Sarkar, Sudeep/A-8213-2009	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207; Robledo-Vega, Isidro/0000-0002-5180-3124				BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P267, DOI 10.1109/AFGR.2002.1004165; BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P372, DOI 10.1109/AFGR.2002.1004182; BLACK MJ, 1996, P EUR C COMP VIS, P329; BOBICK A, 2001, COMPUTER VISION PATT, P423; Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181; Davis JW, 2001, LECT NOTES COMPUT SC, V2091, P295; HAYFRONACQUAH JB, 2001, P 3 INT C AUD VID BA, P272; Huet B, 1999, IEEE T PATTERN ANAL, V21, P1363, DOI 10.1109/34.817414; Kale A, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P336, DOI 10.1109/AFGR.2002.1004176; Kepp Kevin., 2000, REFORMERS CRITICS PA, P291, DOI DOI 10.1109/IAI.2000.839618; LITTLE J, 1998, MIT PRESS J VIDERE, V1, P1; NIYOGI S, 1994, COMPUTER VISION PATT; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 2002, INT C PATT RECOG, P385, DOI 10.1109/ICPR.2002.1044731; SANOCKI T, 2000, STUDENT FRIENDLY STA; SARKAR S, 2001, COMPUTER VISION PATT, P976; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; SHAKHNAROVICH G, 2001, COMPUTER VISION PATT, P439; Vega IR, 2002, INT C PATT RECOG, P1, DOI 10.1109/ICPR.2002.1044574; VEGA IR, 2002, THESIS U S FLORIDA; Yam CY, 2001, LECT NOTES COMPUT SC, V2091, P278	21	31	34	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1323	1328		10.1109/TPAMI.2003.1233906	http://dx.doi.org/10.1109/TPAMI.2003.1233906			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE		Green Submitted			2022-12-18	WOS:000185460800012
J	Bredno, J; Lehmann, TM; Spitzer, K				Bredno, J; Lehmann, TM; Spitzer, K			A general discrete contour model in two, three, and four dimensions for topology-adaptive multichannel segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						discrete contour model; segmentation; volumetric; spatio-temporal; multichannel; topology-adaptive; tracking	MEDICAL IMAGE SEGMENTATION; ACTIVE CONTOUR; SURFACE SIMPLIFICATION; DEFORMABLE SURFACES; 3-D IMAGES; TRACKING; SHAPE; COLOR; ALGORITHMS; SNAKES	We present a discrete contour model for the segmentation of image data with any dimension of image domain and value range. The model consists of a representation using simplex meshes and a mechanical formulation of influences that drive an iterative segmentation. The object's representation as well as the influences are valid for any dimension of the image domain. The image influences introduced here, can combine information from independent channels of higher-dimensional value ranges. Additionally, the topology of the model automatically adapts to objects contained in images. Noncontextual tests have validated the ability of the model to reproducibly delineate synthetic objects. In particular, images with a signal to noise ratio of SNR < 0.5 are delineated within two pixels of their ground truth contour. Contextual validations have shown the applicability of the model for medical image analysis in image domains of two, three, and four dimensions in single as well as multichannel value ranges.	Philips Res Labs, D-52066 Aachen, Germany; Aachen Univ Technol RWTH, Inst Med Informat, D-52057 Aachen, Germany	Philips; Philips Research; RWTH Aachen University	Bredno, J (corresponding author), Philips Res Labs, Weisshausstr 2, D-52066 Aachen, Germany.	joerg.bredno@philips.com; lehmann@computer.org; spitzer@mi.rwth-aachen.de		Bredno, Joerg/0000-0002-2302-2339				Alexa M, 2000, VISUAL COMPUT, V16, P26, DOI 10.1007/PL00007211; Bamford P, 1998, INT C PATT RECOG, P133, DOI 10.1109/ICPR.1998.711098; Bredno J, 2000, PROC SPIE, V3979, P1185, DOI 10.1117/12.387624; Bulpitt AJ, 1996, IMAGE VISION COMPUT, V14, P573, DOI 10.1016/0262-8856(96)01102-X; Cagnoni S, 1999, IMAGE VISION COMPUT, V17, P881, DOI 10.1016/S0262-8856(98)00166-8; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chalana V, 1997, IEEE T MED IMAGING, V16, P642, DOI 10.1109/42.640755; Chalana V, 1998, P SOC PHOTO-OPT INS, V3338, P947, DOI 10.1117/12.310973; Chen CM, 1998, P SOC PHOTO-OPT INS, V3338, P959, DOI 10.1117/12.310974; COHEN I, 1992, CVGIP-IMAG UNDERSTAN, V56, P242, DOI 10.1016/1049-9660(92)90041-Z; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Delingette H, 2001, COMPUT VIS IMAGE UND, V83, P140, DOI 10.1006/cviu.2001.0920; Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576; Dubuisson-Jolly MP, 2000, IMAGE VISION COMPUT, V18, P823, DOI 10.1016/S0262-8856(99)00050-5; Fritsch D, 1997, LECT NOTES COMPUT SC, V1230, P127; Gibson S, 1998, Med Image Anal, V2, P121, DOI 10.1016/S1361-8415(98)80007-8; Grzeszczuk RP, 1997, IEEE T PATTERN ANAL, V19, P1100, DOI 10.1109/34.625111; GUNN SR, 1995, LECT NOTES COMPUTER, V970, P600; HAYNOR DR, 2000, P SOC PHOTO-OPT INS, V1, P18; Heigl B., 1999, Pattern Recognition and Image Analysis, V9, P648; Herman GT, 1998, PATTERN ANAL APPL, V1, P2, DOI 10.1007/BF01238022; Horritt MS, 1999, IMAGE VISION COMPUT, V17, P213, DOI 10.1016/S0262-8856(98)00101-2; Ivins J, 1998, COMPUT VIS IMAGE UND, V72, P54, DOI 10.1006/cviu.1997.0653; Johnson AE, 1998, GRAPH MODEL IM PROC, V60, P261, DOI 10.1006/gmip.1998.0474; Juarez EL, 2000, P SOC PHOTO-OPT INS, V3958, P144, DOI 10.1117/12.380034; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kauffmann C, 1998, P SOC PHOTO-OPT INS, V3338, P663, DOI 10.1117/12.310944; Kim D, 1999, GRAPH MODEL IM PROC, V61, P363, DOI 10.1006/gmip.1999.0506; Kobbelt LP, 2000, VISUAL COMPUT, V16, P142, DOI 10.1007/s003710050204; Kochner B, 1998, P SOC PHOTO-OPT INS, V3338, P755, DOI 10.1117/12.310955; Lachaud J O, 1999, Med Image Anal, V3, P187, DOI 10.1016/S1361-8415(99)80012-7; Lam CL, 1998, PATTERN RECOGN LETT, V19, P491, DOI 10.1016/S0167-8655(98)00015-4; Lehmann TM, 2001, PROC SPIE, V4322, P214, DOI 10.1117/12.431091; Lehmann TM, 2001, IEEE T BIO-MED ENG, V48, P706, DOI 10.1109/10.923788; LEHMANN TM, UNPUB METHODS INFORM; LEHMANN TM, 2001, LECT NOTES COMPUTER, V2013, P387; LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733; Li P, 2000, P SOC PHOTO-OPT INS, V3958, P172, DOI 10.1117/12.380038; Liang JM, 1999, LECT NOTES COMPUT SC, V1679, P116; LOBREGT S, 1995, IEEE T MED IMAGING, V14, P12, DOI 10.1109/42.370398; Lurig C, 2000, GRAPH MODELS, V62, P2, DOI 10.1006/gmod.1999.0515; Lynch JA, 2000, PROC SPIE, V3979, P925, DOI 10.1117/12.387758; Malassiotis S, 1999, IEEE T MED IMAGING, V18, P282, DOI 10.1109/42.764905; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9; McInerney T, 1999, IEEE T MED IMAGING, V18, P840, DOI 10.1109/42.811261; Metzler V, 1998, P SOC PHOTO-OPT INS, V3338, P1246, DOI 10.1117/12.310852; NASTAR C, 1993, LECT NOTES COMPUTER, V687, P17; Ngoi KP, 1999, IMAGE VISION COMPUT, V17, P955, DOI 10.1016/S0262-8856(98)00169-3; Pardo JM, 1997, PATTERN RECOGN LETT, V18, P1529, DOI 10.1016/S0167-8655(97)00135-9; Peterfreund N, 1999, COMPUT VIS IMAGE UND, V73, P346, DOI 10.1006/cviu.1998.0732; Radea P, 1998, P SOC PHOTO-OPT INS, V3338, P1345, DOI 10.1117/12.310865; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; Rueckert D, 1997, IEEE T MED IMAGING, V16, P581, DOI 10.1109/42.640747; Saha PK, 1998, GRAPH MODEL IM PROC, V60, P423, DOI 10.1006/gmip.1998.0481; Sitnik R, 2000, P SOC PHOTO-OPT INS, V3958, P36, DOI 10.1117/12.380053; Smith ADC, 1998, P SOC PHOTO-OPT INS, V3338, P652, DOI 10.1117/12.310943; Undrill PE, 1997, PATTERN RECOGN, V30, P217, DOI 10.1016/S0031-3203(96)00074-X; Velho L, 1999, VISUAL COMPUT, V15, P21, DOI 10.1007/s003710050160; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Yu DN, 2000, PROC SPIE, V3979, P1593, DOI 10.1117/12.387673; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; Zhu YD, 1999, IEEE T MED IMAGING, V18, P557, DOI 10.1109/42.790456	63	31	31	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2003	25	5					550	563		10.1109/TPAMI.2003.1195990	http://dx.doi.org/10.1109/TPAMI.2003.1195990			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	669FY					2022-12-18	WOS:000182342300002
J	Hartelius, K; Carstensen, JM				Hartelius, K; Carstensen, JM			Bayesian grid matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						deformable model; Markov random field; ensemble annealing; graph matching; high-throughput screening; textile analysis	MODEL	A method for locating distorted grid structures in images is presented. The method is based on the theories of template matching and Bayesian image restoration. The grid is modeled as a deformable template. Prior knowledge of the grid Is described through a Markov Random Field (MRF) model which represents the spatial coordinates of the grid nodes. Knowledge of how grid nodes are depicted in the observed image is described through the observation model. The prior consists of a node prior and an arc (edge) prior, both modeled as Gaussian MRFs, The node prior models variations in the positions of grid nodes and the are prior models variations in row and column spacing across the grid. Grid matching is done by placing an initial rough grid over the image and applying an ensemble annealing scheme to maximize the posterior distribution of the grid. The method can be applied to noisy images with missing grid nodes and grid-node artifacts and the method accommodates a wide range of grid distortions including: large-scale warping, varying row/column spacing, as well as nonrigid random fluctuations of the grid nodes. The methodology is demonstrated in two case studies concerning 1) localization of DNA signals in hybridization filters and 2) localization of knit units in textile samples.	Via Vis AS, DK-2790 Horsholm, Denmark; Tech Univ Denmark, Informat & Math Modeling Dept, DK-2800 Lyngby, Denmark	Technical University of Denmark	Hartelius, K (corresponding author), Via Vis AS, DK-2790 Horsholm, Denmark.	kah@vlavision.dk; jmc@imm.dtu.dk						Amit Y, 1996, IEEE T PATTERN ANAL, V18, P225, DOI 10.1109/34.485529; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1977, BIOMETRIKA, V64, P616, DOI 10.1093/biomet/64.3.616; Besag J. E., 1989, J APPL STAT, V16, P395, DOI [10.1080/02664768900000049, DOI 10.1080/02664768900000049]; Boykov Y., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P517, DOI 10.1109/CVPR.1999.784730; Carstensen JM, 1996, COMPUT VIS IMAGE UND, V63, P380, DOI 10.1006/cviu.1996.0027; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; DELAGNES P, 1997, P 13 INT C PATT REC, V2, P800; Felzenszwalb PF, 2000, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.2000.854739; FRENANDER U, 1991, HANDS PATTERN THEORE, P128; FROST R, 1997, P INT C PAR DISTR PR; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Glasbey CA, 1998, J APPL STAT, V25, P155, DOI 10.1080/02664769823151; GRENANDER U, 1988, REPORTS PATTERN ANAL, V1; GRENANDER U, 1989, J APPLIED STATISTICS, V16, P207; Gudukbay U, 1997, COMPUT GRAPH-UK, V21, P335, DOI 10.1016/S0097-8493(97)00011-3; HARTELIUS K, 1998, ISPOT QUANTITATIVE A; HARTELIUS K, 1996, ANAL IRREGULARLY DIS, P260; JENSEN KL, 2000, FUZZ PILLS EVALUATIO, P100; KUNSCH HR, 1987, BIOMETRIKA, V74, P517, DOI 10.2307/2336690; Lee D, 1997, LECT NOTES COMPUT SC, V1230, P495; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; RUPPEINER G, 1991, J PHYS I, V1, P455, DOI 10.1051/jp1:1991146; WU FY, 1982, REV MOD PHYS, V54, P235, DOI 10.1103/RevModPhys.54.235	26	31	33	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2003	25	2					162	173		10.1109/TPAMI.2003.1177149	http://dx.doi.org/10.1109/TPAMI.2003.1177149			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	637NX					2022-12-18	WOS:000180519800002
J	Ma, CM; Wan, SY; Lee, JD				Ma, CM; Wan, SY; Lee, JD			Three-dimensional topology preserving reduction on the 4-subfields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						topology preservation; connectivity preservation; 3D thinning algorithm; thinning; 4-subfield thinning	THINNING ALGORITHM; DIGITAL-TOPOLOGY; PRESERVATION	This paper discusses thinning on 3D binary images with the 4-subfield approach. Although a thinning algorithm concerns binary images, the algorithm itself can be represented as a set of three-color reduction templates. A thinning algorithm is topology preserving if the set of all three-color templates is topology preserving. Sufficient and necessary conditions of time complexity 0(n) were proposed for verifying the topological soundness of a 3D 4-subfield thinning algorithm of n three-color templates. Theories and techniques for computerizing such conditions were discussed. Two 4-subfield thinning algorithms on 3D images, one for generating medial curves, and the other one for generating medial surfaces, are proposed and proved to preserve topology by our sufficient and necessary conditions.	Chang Gung Univ, Dept Informat Management, Tao Yuan 333, Taiwan; Chang Gung Univ, Dept Comp Sci & Informat Engn, Tao Yuan 333, Taiwan; Chang Gung Univ, Dept Elect Engn, Tao Yuan 333, Taiwan	Chang Gung University; Chang Gung University; Chang Gung University	Ma, CM (corresponding author), Chang Gung Univ, Dept Informat Management, 259 Wen Hua 1st Rd, Tao Yuan 333, Taiwan.		Wan, Shu-Yen/A-2054-2014; Lee, Jiann-Der/AAE-2442-2022	Wan, Shu-Yen/0000-0002-8959-2748; Lee, Jiann-Der/0000-0001-6310-0488				BERTRAND G, 1994, P SPIE C VISION GEOM, V2356, P113; GUO ZC, 1989, COMMUN ACM, V32, P359, DOI 10.1145/62065.62074; HALL RW, 1992, TOPOL APPL, V46, P199, DOI 10.1016/0166-8641(92)90015-R; HALL RW, 1992, P 1992 SPIE C VIS GE, P172; HOLT CM, 1987, COMMUN ACM, V30, P156, DOI 10.1145/12527.12531; KONG TY, 1992, TOPOL APPL, V46, P219, DOI 10.1016/0166-8641(92)90016-S; KONG TY, 1989, COMPUT GRAPH, V13, P159, DOI 10.1016/0097-8493(89)90058-7; KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3; KONG TY, 1993, P SOC PHOTO-OPT INS, V2060, P69, DOI 10.1117/12.165013; KONG TY, 1995, INT J PATTERN RECOGN, V9, P813, DOI 10.1142/S0218001495000341; LATECKI L, 1996, COMPUTER VISION IMAG, V63, P393; LOHOU C, 2002, P 10 INT C DISCR GEO, P102; LOHOU C, 2002, P SPIE VISION GEOMET, V9; Ma CM, 2001, PATTERN RECOGN LETT, V22, P1439, DOI 10.1016/S0167-8655(01)00083-6; MA CM, 1994, CVGIP-IMAG UNDERSTAN, V59, P328, DOI 10.1006/ciun.1994.1023; MALANDAIN G, 1992, 11TH INT C PATT REC, V3, P232; Manzanera A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P337, DOI 10.1109/ICCV.1999.791239; MANZANERA A, 1999, P SPIE C, V3811, P18; MORGENTHALER DG, 1981, 1005 U MAR; Palagyi K, 1998, PATTERN RECOGN LETT, V19, P613, DOI 10.1016/S0167-8655(98)00031-2; PARK CM, 1971, 156 U MAR; RONSE C, 1986, THEOR COMPUT SCI, V43, P31, DOI 10.1016/0304-3975(86)90164-7; RONSE C, 1988, DISCRETE APPL MATH, V21, P67, DOI 10.1016/0166-218X(88)90034-0; ROSENFELD A, 1975, INFORM CONTROL, V29, P286, DOI 10.1016/S0019-9958(75)90448-9; SAHA P, 1991, TRKBCS291 NCKBCS LIB; Saha PK, 2000, PATTERN RECOGN, V33, P105, DOI 10.1016/S0031-3203(99)00037-0; TSAO YF, 1981, COMPUTER GRAPHICS IM, V17, P513	27	31	33	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1594	1605		10.1109/TPAMI.2002.1114851	http://dx.doi.org/10.1109/TPAMI.2002.1114851			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	618YA					2022-12-18	WOS:000179444600004
J	Mayraz, G; Hinton, GE				Mayraz, G; Hinton, GE			Recognizing handwritten digits using hierarchical products of experts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						neural networks; products of experts; handwriting recognition; feature extraction; shape recognition; Boltzmann machines; model-based recognition; generative models		The product of experts learning procedure [1] can discover a set of stochastic binary features that constitute a nonlinear generative model of handwritten images of digits. The quality of generative models learned in this way can be assessed by learning a separate model for each class of digit and then comparing the unnormalized probabilities of test images under the 10 different class-specific models. To improve discriminative performances a hierarchy of separate models can be learned for each digit class. Each model in the hierarchy learns a layer of binary feature detectors that model the probability distribution of vectors of activity of feature detectors in the layer below. The models in the hierarchy are trained sequentially and each model uses a layer of binary feature detectors to learn a generative model of the patterns of feature activities in the preceding layer. After training, each layer of feature dectectors produces a separate, unnormalized log probability score. With three layers of feature detectors for each of the 10 digit classes, a test image produces 30 scores which can be used as inputs to a supervised, logistic classification network that is trained on separate data. On the MNIST database, our system is comparable with current state-of-the-art discriminative methods, demonstrating that the product of experts learning procedure can produce effective hierarchies of generative models of high-dimensional data.	UCL, Gatsby Computat Neurosci Unit, London WCIN 3AR, England	University of London; University College London	Mayraz, G (corresponding author), UCL, Gatsby Computat Neurosci Unit, 17 Queen Sq, London WCIN 3AR, England.	gmz@gatsby.ucl.ac.uk; hinton@gatsby.ucl.ac.uk	Mayraz, Guy/N-9511-2015	Mayraz, Guy/0000-0002-4419-2900				[Anonymous], P ICNN PERTH WA AUST; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Burges CJC, 1997, ADV NEUR IN, V9, P375; FREUND Y, 1992, ADV NEUR IN, V4, P912; Heskes T, 1998, NEURAL COMPUT, V10, P1425, DOI 10.1162/089976698300017232; Hinton G. E., 2000, 2000004 GCNU TR; Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79; McClelland JL, 1986, PARALLEL DISTRIBUTED, V1, P1; SIMARD P, 1992, P INT C PATT REC; Smolensky P, 1986, PARALLEL DISTRIBUTED, V1; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; ZEMEL RS, 2001, ADV NEURAL INFORMATI, V13	12	31	33	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2002	24	2					189	197		10.1109/34.982899	http://dx.doi.org/10.1109/34.982899			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	516DC					2022-12-18	WOS:000173535700004
J	Lee, BU; Kim, CM; Park, RH				Lee, BU; Kim, CM; Park, RH			An orientation reliability matrix for the iterative closest point algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ICP algorithm; 3D registration; range data; volumetric modeling; pose estimation	REGISTRATION	This paper proposes a matrix which represents the reliability of the rotation components of the iterative closest point (ICP) algorithm in range image registration. We show that the reliability of the ICP algorithm depends on the surface normal vectors of the object.	Ewha Womans Univ, Dept Informat Elect, Seoul 120750, South Korea; Samsung Elect Co Ltd, SOC Dev Team, Syst LSI Businesss, Suwon 449711, South Korea; Sogang Univ, Dept Elect Engn, Seoul 100611, South Korea	Ewha Womans University; Samsung; Samsung Electronics; Sogang University	Lee, BU (corresponding author), Ewha Womans Univ, Dept Informat Elect, 11-1 Daehyun Dong, Seoul 120750, South Korea.		Park, Rae-Hong/Q-7955-2019; Park, Rae-Hong/Q-7908-2019	Park, Rae-Hong/0000-0002-4792-2980; Lee, Byung-Uk/0000-0002-3452-3016				BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BLOSTEIN SD, 1987, IEEE T PATTERN ANAL, V9, P752, DOI 10.1109/TPAMI.1987.4767982; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chung DH, 1998, PATTERN RECOGN, V31, P457, DOI 10.1016/S0031-3203(97)00063-0; CURLESS B, 1996, P SIGGRAPH 96, P303; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1131, DOI 10.1109/34.625115; Hogg R.V., 1997, TANIS PROBABILITY ST; Lee BU, 1999, P SOC PHOTO-OPT INS, V3640, P146, DOI 10.1117/12.341056; Masuda T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P879, DOI 10.1109/ICPR.1996.546150; MATTHIES L, 1987, IEEE T ROBOTIC AUTOM, V3, P239, DOI 10.1109/JRA.1987.1087097; SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651; Simon D., 1996, CMURITR9645	13	31	33	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1205	1208		10.1109/34.879805	http://dx.doi.org/10.1109/34.879805			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ					2022-12-18	WOS:000165067100015
J	Lim, JH; Leonard, JJ				Lim, JH; Leonard, JJ			Mobile robot relocation from echolocation constraints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						localization; mobile robots; navigation; sonar	LOCALIZATION; NAVIGATION; SONAR; SENSOR; MODEL	This paper presents a method for relocation of a mobile robot using sonar data. The process of determining the pose of a mobile robot with respect to a global reference frame in situations where no a priori estimate of the robot's location is available is cast as a problem of searching for correspondences between measurements and an a priori map of the environment. A physically-based based sonar sensor model is used to characterize the geometric constraints provided by echolocation measurements of different types of objects. Individual range returns are used as data features in a constraint-based search to determine the robot's position. A hypothesize and test technique is employed in which positions of the robot are calculated from all possible combinations of two range returns that satisfy the measurement model. The algorithm determines the positions which provide the best match between the range returns and the environment model. The performance of the approach is demonstrated using data both a single scanning Polaroid sonar and from a ring of Polaroid sonar sensors.	Jeju Natl Univ, Dept Mech Engn, Cheju, South Korea; MIT, Dept Ocean Engn, Cambridge, MA 02139 USA	Jeju National University; Massachusetts Institute of Technology (MIT)	Lim, JH (corresponding author), Jeju Natl Univ, Dept Mech Engn, Cheju, South Korea.	jhlim@cheju.ac.kr; jleonard@mit.edu						Au W. W., 1993, SONAR DOLPHINS; BARSHAN B, 1990, IEEE T PATTERN ANAL, V12, P560, DOI 10.1109/34.56192; BOZMA O, 1991, J ACOUST SOC AM, V89, P2519, DOI 10.1121/1.400692; BOZMA O, 1991, IEEE T PATTERN ANAL, V13, P1260, DOI 10.1109/34.107000; CASTELLANOS JA, 1996, IEE              JAN; CASTELLANOS JA, 1989, THESIS U ZARAGOZA SP; Cox IJ, 1990, AUTONOMOUS ROBOT VEH; DELLAERT F, 1999, P IEEE INT C ROB AUT; DRUMHELLER M, 1987, IEEE T PATTERN ANAL, V9, P325, DOI 10.1109/TPAMI.1987.4767907; ELFES A, 1987, IEEE T ROBOTIC AUTOM, V3, P249, DOI 10.1109/JRA.1987.1087096; Feder HJS, 1999, INT J ROBOT RES, V18, P650, DOI 10.1177/02783649922066484; Grimson W. E. L., 1990, OBJECT RECOGNITION C; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; KUC R, 1987, IEEE T PATTERN ANAL, V9, P766, DOI 10.1109/TPAMI.1987.4767983; LEONARD JJ, 1991, IEEE T ROBOTIC AUTOM, V7, P376, DOI 10.1109/70.88147; LEONARD JJ, 1992, DIRECTED SONAR SENSI; LIM JH, 1994, THESIS POHANG I SCI; MORAVEC H, 1989, NATO ASI SER, P253; Morse P. M., 1968, THEORETICAL ACOUSTIC; Schultz AC, 1998, IEEE INT CONF ROBOT, P2833, DOI 10.1109/ROBOT.1998.680595; SMITH RC, 1990, AUTONOMOUS ROBOT VEH; THRUN S, 1998, P AM ASS ARTIFICIAL; Yamauchi B, 1998, IEEE INT CONF ROBOT, P3715, DOI 10.1109/ROBOT.1998.681416	23	31	32	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2000	22	9					1035	1041						7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	361TY					2022-12-18	WOS:000089741300009
J	Chen, J; Sato, Y; Tamura, S				Chen, J; Sato, Y; Tamura, S			Orientation space filtering for multiple orientation line segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						line segmentation; multiple orientation lines; junctions; orientation bandwidth; orientation space	SCALE-SPACE; SELECTION; CURVES; MOTION; IMAGES	The goal of this paper is to present an appropriate method for the segmentation of lines at intersections (X-junctions) and branches (T-junctions), which can be regarded as local regions where lines occur at multiple orientations. A novel representation called "orientation space" is proposed, which is derived by adding the orientation axis to the abscissa and the ordinate of the image. The orientation space representation is constructed by treating the orientation parameter, to which Gabor filters can be tuned, as a continuous variable. The problem of segmenting lines at multiple orientations is dealt with by thresholding 3D images in the orientation space and then detecting the connected components therein. In this way, X-junctions and T-junctions can be separated effectively. Curve grouping can also be accomplished. The segmentation of mathematically modeled X-, T-, and L-junctions is demonstrated and analyzed. The sensitivity limits of the method are also discussed. Experimental results using both synthesized and real images show the method to be effective for junction segmentation and curve grouping.	Cornell Univ, Weill Med Coll, Dept Radiol, New York, NY 10021 USA; Osaka Univ, Grad Sch Med, Div Funct Diagnost Imaging, Biomed Res Ctr, Suita, Osaka 5650871, Japan	Cornell University; Osaka University	Chen, J (corresponding author), Cornell Univ, Weill Med Coll, Dept Radiol, 515 East 71st St,S Bldg, New York, NY 10021 USA.	jic2003@med.cornell.edu; yoshi@image.med.osaka-u.ac.jp; tamuras@image.med.osaka-u.ac.jp	Sato, Yoshinobu/C-9361-2009					BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; Chen J, 1998, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.1998.698625; Chen JM, 1996, IMAGE VISION COMPUT, V14, P71, DOI 10.1016/0262-8856(95)01042-4; Chen LH, 1996, IMAGE VISION COMPUT, V14, P753, DOI 10.1016/0262-8856(96)01081-5; COX IJ, 1992, P 2 EUR C COMP VIS, P72; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; ELDER JH, 1996, P 4 EUR CC OMP VIS, V2, P397; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GRANLUND GH, 1978, COMPUT VISION GRAPH, V8, P155, DOI 10.1016/0146-664X(78)90047-3; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; KATZIR N, 1994, IEEE T PATTERN ANAL, V16, P513, DOI 10.1109/34.291446; KOLLER TM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P864, DOI 10.1109/ICCV.1995.466846; Lindeberg T, 1996, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.1996.517113; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Merlet N, 1996, IEEE T PATTERN ANAL, V18, P426, DOI 10.1109/34.491623; MICHAELIS M, 1992, P 2 EUR C COMP VIS, P101; MORI S, 1984, P 7 INT C PATT REC, P366; MUKHERJEE A, 1994, INT C PATT RECOG, P514, DOI 10.1109/ICPR.1994.576339; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; Perona P., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P52, DOI 10.1109/ICCV.1990.139492; PERONA P, 1992, P EUR C COMP VIS, P3; ROSENTHALER L, 1992, LECT NOTES COMPUT SC, V588, P78; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; Sato Y, 1997, IEEE T BIO-MED ENG, V44, P225, DOI 10.1109/10.563292; Sato Y, 1998, Med Image Anal, V2, P143, DOI 10.1016/S1361-8415(98)80009-1; SATO Y, 1995, P 1 INT C COMP VIS V, P302; Steger C, 1998, IEEE T PATTERN ANAL, V20, P113, DOI 10.1109/34.659930; TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]; ZHANG ZY, 1995, IEEE T PATTERN ANAL, V17, P1129; ZUCKER SW, 1985, COMPUT VISION GRAPH, V32, P74, DOI 10.1016/0734-189X(85)90003-9	33	31	38	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2000	22	5					417	429						13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	337FV					2022-12-18	WOS:000088347500001
J	Kesidis, AL; Papamarkos, N				Kesidis, AL; Papamarkos, N			On the Inverse Hough Transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hough Transform; edge extraction; line detection; nonlinear filtering	RADON-TRANSFORM; PICTURES; LINES	In this paper, an Inverse Hough Transform algorithm is proposed. This algorithm reconstructs correctly the original image, using only the data of the Hough Transform space and it is applicable to any binary image. As a first application, the Inverse Hough Transform algorithm is used for straight-line detection and filtering. The lines are detected not just as continuous straight lines, which is the case of the standard Hough Transform, but as they really appear in the original image, i.e., pixel by pixel. To avoid the quantization effects in the Hough Transform space, inversion conditions are defined, which are associated only with the dimensions of the images. Experimental results indicate that the Inverse Hough Transform algorithm is robust and accurate.	Democritus Univ Thrace, Dept Elect & Comp Engn, Elect Circuits Anal Lab, GR-67100 Xanthi, Greece	Democritus University of Thrace	Kesidis, AL (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Elect Circuits Anal Lab, GR-67100 Xanthi, Greece.		Kesidis, Anastasios/ABF-9609-2021	Kesidis, Anastasios/0000-0002-8912-7352				BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Ben-Tzvi D., 1990, Proceedings of the 5th International Conference on Image Analysis and Processing. Progress in Image Analysis and Processing, P152; BEYLKIN G, 1987, IEEE T ACOUST SPEECH, V35, P162, DOI 10.1109/TASSP.1987.1165108; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DAGEON D, 1984, MULTIDIMENSIONAL DIG; Davies ER, 1997, MACHINE VISION; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Gatos B, 1996, ELECTRON LETT, V32, P730, DOI 10.1049/el:19960510; Guo LF, 1999, PATTERN RECOGN, V32, P635, DOI 10.1016/S0031-3203(98)00116-2; Gustafsson B, 1996, PHYS SCRIPTA, VT61, P38, DOI 10.1088/0031-8949/1996/T61/006; Hansen KV, 1996, IEEE T IMAGE PROCESS, V5, P1651, DOI 10.1109/83.544572; Hough P. V. C., 1962, U.S. Patent, DOI 10.1007/s10811-008-9353-1, Patent No. [069 654, 069654, 3, 069,654]; Hsung TC, 1996, IEEE T SIGNAL PROCES, V44, P2651, DOI 10.1109/78.539055; ILLINGWORTH J, 1987, IEEE T PATTERN ANAL, V9, P690, DOI 10.1109/TPAMI.1987.4767964; JAIN AK, 1989, FUNDAMENTAL DIGITAL; KIRYATI N, 1991, CVGIP-GRAPH MODEL IM, V53, P213, DOI 10.1016/1049-9652(91)90043-J; KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E; LAM WCY, 1994, PATTERN RECOGN LETT, V15, P1127, DOI 10.1016/0167-8655(94)90128-7; LEUNG DNK, 1993, PATTERN RECOGN LETT, V14, P181, DOI 10.1016/0167-8655(93)90070-T; Neri A, 1996, IEEE T IMAGE PROCESS, V5, P787, DOI 10.1109/83.499918; Niblack W., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P574, DOI 10.1109/CVPR.1988.196293; PALMER PL, 1994, PATTERN RECOGN, V27, P1127, DOI 10.1016/0031-3203(94)90001-9; Perantonis SJ, 1999, PATTERN RECOGN, V32, P811, DOI 10.1016/S0031-3203(98)00125-3; RISSE T, 1989, COMPUT VISION GRAPH, V46, P327, DOI 10.1016/0734-189X(89)90036-4; Shapiro VA, 1996, PATTERN RECOGN, V29, P589, DOI 10.1016/0031-3203(95)00116-6; Soffer M, 1998, COMPUT VIS IMAGE UND, V69, P119, DOI 10.1006/cviu.1997.0557; SVALBE ID, 1989, IEEE T PATTERN ANAL, V11, P941, DOI 10.1109/34.35497; Toft P., 1996, THESIS TU DENMARK; VANVEEN TM, 1981, PATTERN RECOGN, V14, P137, DOI 10.1016/0031-3203(81)90055-8; XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z; Yuen S.Y.K., 1991, P 7 SCAND C IM AN, P733; Zhang YF, 1996, PATTERN RECOGN, V29, P255, DOI 10.1016/0031-3203(95)00083-6	32	31	40	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1999	21	12					1329	1343		10.1109/34.817411	http://dx.doi.org/10.1109/34.817411			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	275PG					2022-12-18	WOS:000084828100006
J	Rodriguez-Sanchez, R; Garcia, JA; Fdez-Valdivia, J; Fdez-Vidal, XR				Rodriguez-Sanchez, R; Garcia, JA; Fdez-Valdivia, J; Fdez-Vidal, XR			The RGFF representational model: A system for the automatically learned partitioning of "visual patterns" in digital images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						visual patterns; image statistics; Log-Gabor filters; strongly responding units; integral features; invariance across orientations and scales; dynamic clustering	DISCRIMINATION; FEATURES; TEXTURE; VISION; ENERGY	This paper describes a system for the automatically learned partitioning of "visual patterns" in 2D images, based on a sophisticated, band-pass, filtering operation with fixed scale and orientation sensitivity. In this scheme, the "visual patterns" are defined as the features which have the highest degree of alignment in the statistical structure across different frequency bands. The analysis reorganizes the image according to a constraint of invariance in statistical structure and consists of three stages: 1) pre-attentive stage, 2) integration stage, and 3) learning stage. The first stage takes the input image and performs filtering with a set of log-Gabor filters. Based on their responses, activated filters which are selectively sensitive to patterns in the image are short listed. In the integration stage, common grounds between several activated sensors are explored. The filtered responses are analyzed through a family of statistics. For any given two activated filters, a distance between them is derived via distances between their statistics. The third stage, the learning stage, performs cluster partitioning as a mechanism for learning the subspace of log-Gabor filters needed to partition the image data. The clustering is based on a dissimilarity measure intended to highlight scale and orientation invariance of the filtered responses. The technique is illustrated on real and simulated data sets. Finally, this paper presents a computational visual distinctness measure computed from the image representational model based on visual patterns. It is applied to quantity the visual distinctness of targets in complex natural scenes. Several experiments are performed to investigate the relation between the computational distinctness measure and the visual target distinctness measured by human observers.	Univ Jaen, Escuela Politecn Super, Dept Informat, Jaen 23071, Spain; Univ Granada, Dept Ciencias Computac, E-18071 Granada, Spain; Univ Granada, ETS Ingn Informat, IA, E-18071 Granada, Spain; Univ Santiago de Compostela, Fac Fis, Dept Fis, Santiago De Compostela 15706, Spain	Universidad de Jaen; University of Granada; University of Granada; University of Sevilla; Universidade de Santiago de Compostela	Rodriguez-Sanchez, R (corresponding author), Univ Jaen, Escuela Politecn Super, Dept Informat, Jaen 23071, Spain.	jags@decsai.ugr.es	Fdez-Valdivia, J/B-1844-2012; Sanchez, Rosa Maria Rodriguez/B-1847-2012; Fdez-Vidal, Xose R./L-5740-2014; Garcia, Jose A./C-1703-2010	Fdez-Valdivia, J/0000-0001-7181-1554; Sanchez, Rosa Maria Rodriguez/0000-0001-7886-9329; Fdez-Vidal, Xose R./0000-0001-9388-7461; Garcia, Jose A./0000-0001-7742-7270				CANNY J, 1996, IEEE T PATTERN ANAL, V18, P679; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; Fdez-Valdivia J, 1998, IEEE T PATTERN ANAL, V20, P458, DOI 10.1109/34.682176; Fdez-Vidal XR, 1997, PATTERN RECOGN LETT, V18, P733, DOI 10.1016/S0167-8655(97)00053-6; FdezValdivia J, 1996, INT J PATTERN RECOGN, V10, P769, DOI 10.1142/S0218001496000451; FDEZVIDAL XR, 1998, 980322 U GRAN DEP CO; FDEZVIDAL XR, 1998, 980327 U GRAN DEP CO; FDEZVIDAL XR, 1998, 980330 U GRAN DEP CO; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Field DJ, 1993, WAVELETS FRACTALS FO, P151; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GARCIA JA, 1995, SIGNAL PROCESS, V44, P181, DOI 10.1016/0165-1684(95)00023-7; GRAHAM N, 1997, TM97A039 TNO HUM FAC, P74; Green P., 1989, MULTIDIMENSIONAL SCA; JULESZ B, 1975, SCI AM, V232, P34, DOI 10.1038/scientificamerican0475-34; Kovesi Peter, 1995, 954 U W AUSTR DEP CO; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; Moore E. F., 1957, P INT S THEOR SWITCH, P285; MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073; MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4; OLZAK L, 1986, HDB PERCEPTION HUMAN, V1; QUICK RF, 1974, KYBERNETIK, V16, P65, DOI 10.1007/BF00271628; Rao C. R, 1973, LINEAR STAT INFERENC; RIDDER H, 1992, SPIE, V1666, P16; ROBBINS B, 1996, THESIS U W AUSTR; Rodriguez-Sanchez R, 1998, PATTERN RECOGN, V31, P1797, DOI 10.1016/S0031-3203(98)00026-0; Rohaly AM, 1997, VISION RES, V37, P3225, DOI 10.1016/S0042-6989(97)00156-9; TOET A, 1997, TM97A036 TNO HUM FAC, P35; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; VENKATESH S, 1990, PATTERN RECOGN LETT, V11, P339, DOI 10.1016/0167-8655(90)90043-2; Wertheimer M., 1958, READINGS PERCEPTION, P115; WITKIN AP, 1983, P 8 INT JOINT C ART, P559	34	31	33	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1999	21	10					1044	1073		10.1109/34.799910	http://dx.doi.org/10.1109/34.799910			30	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	248DB					2022-12-18	WOS:000083259100007
J	McLaughlin, RA; Alder, MD				McLaughlin, RA; Alder, MD			The Hough Transform versus the UpWrite	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hough transform; probabilistic Hough transform; randomized Hough transform; hierarchical Hough transform; UpWrite	EXTRACTION	This paper compares the Hough Transform and the UpWrite for the detection of lines, circles, and ellipses. Both ideal and noisy images are tested. The UpWrite is found to be more robust for images containing perturbation noise. For ideal images and images with speckle noise, the results are found to depend on the complexity of the object being detected, with more complex objects favoring the UpWrite. A program allowing the reader to experiment with these algorithms can be found at the following World Wide Web address: http://ciips.ee.uwa.edu,au/Papers/Journal_Papers/1998/02/Index.html.	Univ Western Australia, Ctr Intelligent Informat Proc Syst, Nedlands, WA 6907, Australia; Univ Western Australia, Dept Math, Nedlands, WA 6907, Australia	University of Western Australia; University of Western Australia	McLaughlin, RA (corresponding author), Univ Western Australia, Ctr Intelligent Informat Proc Syst, Nedlands, WA 6907, Australia.	ram@ee.uwa.edu.au; mike@maths.uwa.edu.au	McLaughlin, Robert A/E-1430-2011	McLaughlin, Robert A/0000-0001-6947-5061				ALDER MD, 1994, PATTERN RECOGN, V4, P45; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BOLDT M, 1989, IEEE T SYST MAN CYB, V19, P1581, DOI 10.1109/21.44073; Born M, 1975, PRINCIPLES OPTICS EL; Davies Machine Vision, 1990, MACHINE VISION THEOR, P91; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DOLAN J, 1988, P SPIE INT SOC OPTIC, V1002, P356; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; KHOTANZAD A, 1990, IEEE T ACOUST SPEECH, V38, P1028, DOI 10.1109/29.56063; KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E; LEAVERS VF, 1993, CVGIP-IMAG UNDERSTAN, V58, P250, DOI 10.1006/ciun.1993.1041; MCLAUGHLIN RA, 1994, PATTERN RECOGN, V4, P59; PRINCEN J, 1990, COMPUT VISION GRAPH, V52, P57, DOI 10.1016/0734-189X(90)90123-D; STOCKMAN GC, 1977, COMMUN ACM, V20, P820, DOI 10.1145/359863.359882; XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z; YUEN HK, 1989, IMAGE VISION COMPUT, V7, P31, DOI 10.1016/0262-8856(89)90017-6; [No title captured]; [No title captured]	18	31	35	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1998	20	4					396	400		10.1109/34.677267	http://dx.doi.org/10.1109/34.677267			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZP214					2022-12-18	WOS:000073729200005
J	Kruger, N				Kruger, N			An algorithm for the learning of weights in discrimination functions using a priori constraints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						discrimination functions; a priori knowledge; weighting; face recognition; elastic graph matching		We introduce a learning algorithm for the weights in a very common class of discrimination functions usually called ''weighted average.'' The learning algorithm can reduce the number of free variables by simple but effective a priori criteria about significant features. Here we apply our algorithm to three tasks of different dimensionality all concerned with face recognition.			Kruger, N (corresponding author), RUHR UNIV BOCHUM, INST NEUROINFORMAT, ND 03, UNIV STR 150, D-44801 BOCHUM, GERMANY.		Kruger, Norbert/P-6315-2015	Kruger, Norbert/0000-0002-3931-116X				[Anonymous], 1989, SPRINGER SERIES INFO; Berger J.O., 1985, STAT DECISION THEORY, P74; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; FUKUNAGA K, 1990, INTRO STATISTICAL PA; Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229; KRUGER N, P EUR S ART NEUR NET, P61; KRUGER N, IRINI0895; KRUGER N, 1996, P BMVC; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; LANDY MS, 1995, VISION RES, V35, P389, DOI 10.1016/0042-6989(94)00176-M; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; Rabiner L., 1978, DIGITAL PROCESSING S; Wiskott L., 1995, P INT WORKSH AUT FAC; [No title captured]	15	31	47	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1997	19	7					764	768		10.1109/34.598233	http://dx.doi.org/10.1109/34.598233			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM693					2022-12-18	WOS:A1997XM69300010
J	VANDERHEIJDEN, F				VANDERHEIJDEN, F			EDGE AND LINE FEATURE-EXTRACTION BASED ON COVARIANCE-MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EDGE DETECTION; LINE DETECTION; IMAGE PROCESSING; IMAGE SEGMENTATION; FEATURE EXTRACTION; MRF	FILTER	Image segmentation based on contour extraction usually involves three stages of image operations: feature extraction, edge detection and edge linking. This paper is devoted to the first stage: a method to design feature extractors used to detect edges from noisy and/or blurred images. The method relies on a model that describes the existence of image discontinuities (e.g. edges) in terms of covariance functions. The feature extractor transforms the input image into a ''log-likelihood ratio'' image. Such an image is a good starting point of the edge detection stage since it represents a balanced trade-off between signal-to-noise ratio and the ability to resolve detailed structures. For 1-D signals, the performance of the edge detector based on this feature extractor is quantitatively assessed by the so called ''average risk measure.'' The results are compared with the performances of 1-D edge detectors known from literature. Generalizations to 2-D operators are given. Applications on real world images are presented showing the capability of the covariance model to build edge and line feature extractors. Finally it is shown that the covariance model can be coupled to a MRF-model of edge configurations so as to arrive at a maximum a posteriori estimate of the edges or lines in the image.			VANDERHEIJDEN, F (corresponding author), UNIV TWENTE,DEPT ELECT ENGN,PO 217,7500 AE ENSCHEDE,NETHERLANDS.			van der Heijden, Ferdinand/0000-0001-8065-8053				BESAG J, 1974, J ROYAL STATISTICA B, V36; BEUTLER FJ, 1968, INFORM CONTROL, V12, P236, DOI 10.1016/S0019-9958(68)90327-6; BEUTLER FJ, 1971, INFORM CONTROL, V18, P326, DOI 10.1016/S0019-9958(71)90437-2; Boie R. A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P100; Boie R. A., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P450; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHEN MH, 1991, IEEE T PATTERN ANAL, V13, P30, DOI 10.1109/34.67628; DERICHE R, 1987, INT J COMPUT VISION, P167; Devijver PA, 1982, PATTERN RECOGNITION; GEMAN D, 1987, PATTERN RECOGNITION; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HARALICK RM, 1983, IEEE T PATTERN ANAL, V5, P417, DOI 10.1109/TPAMI.1983.4767411; HONGO S, 1989, P IJCNN, V1, P161; KOENDERINK JJ, 1992, IEEE T PATTERN ANAL, V14, P597, DOI 10.1109/34.141551; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Papoulis A., 2002, PROBABILITY RANDOM V; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275; SHANMUGAM KS, 1979, IEEE T PATTERN ANAL, V1, P37, DOI 10.1109/TPAMI.1979.4766874; SHEN J, 1992, CVGIP-GRAPH MODEL IM, V54, P112, DOI 10.1016/1049-9652(92)90060-B; SPACEK LA, 1986, IMAGE VISION COMPUT, V4, P43, DOI 10.1016/0262-8856(86)90007-7; SPREEUWERS LJ, 1992, 11TH IAPR INT C PATT; THERRIEN CW, 1983, COMPUT VISION GRAPH, V22, P313, DOI 10.1016/0734-189X(83)90079-8; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; VANDERHEIJDEN F, 1989, 3RD P INT C IM PROC; VANDERHEIJDEN F, 1992, THESIS U TWENTE ENSC; VANDERHEIJDEN F, 1993, BSC93M271 U TWENT IN; ZIOU D, 1991, PATTERN RECOGN, V24, P465, DOI 10.1016/0031-3203(91)90014-V	28	31	31	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1995	17	1					16	33		10.1109/34.368155	http://dx.doi.org/10.1109/34.368155			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QB394					2022-12-18	WOS:A1995QB39400003
J	LEE, D				LEE, D			COPING WITH DISCONTINUITIES IN COMPUTER VISION - THEIR DETECTION, CLASSIFICATION, AND MEASUREMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											LEE, D (corresponding author), AT&T BELL LABS, COMP SCI RES CTR, MURRAY HILL, NJ 07974 USA.							BENDAT JS, 1958, PRINCIPLES APPLICATI; BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; Blake A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P656; Blake A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P62; BOIE A, 1987, 1ST P INT C COMP VIS, P450; Burton T.A., 1983, VOLTERRA INTEGRAL DI; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Castleman KR., 1979, DIGITAL IMAGE PROCES; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; De Boor C., 1978, PRACTICAL GUIDE SPLI; GAMBER HA, 1979, COMMUN STAT A-THEOR, V8, P1425; GELFAND IM, 1964, GENERALIZED FUNCTION; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; GRIMSON WEL, 1987, 1ST P INT C COMP VIS, P93; GRIMSON WEL, 1981, IMAGES SURFACES; GROSSE E, 1989, ALGORITHMS APPROXIMA, V2; Lee D., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P215, DOI 10.1109/CVPR.1988.196239; LEE D, 1988, IEEE T PATTERN ANAL, V10, P822, DOI 10.1109/34.9105; LEE D, IN PRESS SIAM J SCI; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; Papoulis A., 2002, PROBABILITY RANDOM V; Pavlidis T., 1977, STRUCTURAL PATTERN R; POGGIO T, 1985, MIT AI833 MEM; POWELL MJD, 1970, NUMERICAL APPROXIMAT, P65; RABINER LR, 1975, THEORY APPLICATION D; SHIAU JH, 1985, THESIS U WISCONSIN M; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TITCHMARSH E. C., 1939, THEORY FUNCTIONS, V2nd; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; TRAUB JF, 1980, GENERAL THEORY OPTIM; Volterra V., 1959, THEORY FUNCTIONALS I; WAHBA G, 1980, MON WEATHER REV, V108, P1122, DOI 10.1175/1520-0493(1980)108<1122:SNMMFV>2.0.CO;2; WAHBA G, 1984, STATISTICS APPRAISAL; Wiener N., 1949, EXTRAPOLATION INTERP, DOI 10.7551/mitpress/2946.00 1.0001	40	31	32	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1990	12	4					321	344		10.1109/34.50620	http://dx.doi.org/10.1109/34.50620			24	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CV929					2022-12-18	WOS:A1990CV92900001
J	ALVERTOS, N; BRZAKOVIC, D; GONZALEZ, RC				ALVERTOS, N; BRZAKOVIC, D; GONZALEZ, RC			CAMERA GEOMETRIES FOR IMAGE MATCHING IN 3-D MACHINE VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PERCEPT CORP,KNOXVILLE,TN 37933; UNIV TENNESSEE,DEPT ELECT & COMP ENGN,KNOXVILLE,TN 37996	University of Tennessee System; University of Tennessee Knoxville								ALVERTOS N, 1986, SPIE, V726, P131; BALLARD DH, 1982, COMPUTER VISION, P199; BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; BURR DJ, 1984, 7TH IEEE P INT C PAT, V2, P669; Fu K.S., 1987, ROBOTICS CONTROL SEN; Gonzalez R. C., 1987, DIGITAL IMAGE PROCES; GRIMSON WEL, 1980, APR P DARPA IM UND W, P128; GRIMSON WEL, 1981, IMAGES SURFACES; HADDOW ER, 1985, IMAGE ANAL, P175; Horn B., 1986, ROBOT VISION, P1; HWANG JJ, 1980, COMPUTER STEREO VISI; IKEUCHI K, 1984, 7TH IEEE P INT C PAT, V2, P736; ITOH H, 1984, 7TH P INT C PATT REC, V1, P192; JAIN R, 1987, IEEE T PATTERN ANAL, V9, P356, DOI 10.1109/TPAMI.1987.4767919; JINGYU Y, 1985, IMAGE ANAL, P183; KASS M, 1986, PIXELS PREDICATES, P78; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1977, MIT AP451 TECH REP; OBRIEN N, 1984, APR P WORKSH COMP VI, P88; TORRE V, 1986, ROBOTICS RES, V3, P5; TSAI RY, 1983, IEEE T PATTERN ANAL, V5, P159, DOI 10.1109/TPAMI.1983.4767368; WILLIAMS TD, 1980, IEEE T PATTERN ANAL, V2, P511, DOI 10.1109/TPAMI.1980.6447697; WOODHAM RJ, 1985, JUN IEEE P COMP VIS, P2; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0	24	31	31	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					897	915		10.1109/34.35494	http://dx.doi.org/10.1109/34.35494			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800001
J	SVALBE, ID				SVALBE, ID			NATURAL REPRESENTATIONS FOR STRAIGHT-LINES AND THE HOUGH TRANSFORM ON DISCRETE ARRAYS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV WASHINGTON,DEPT COMP SCI,SEATTLE,WA 98195	University of Washington; University of Washington Seattle	SVALBE, ID (corresponding author), CHISHOLM INST TECHNOL,DEPT APPL PHYS,COMP IMAGING GRP,MELBOURNE,VIC 3145,AUSTRALIA.							AMBS P, 1986, APPL OPTICS, V25, P4039, DOI 10.1364/AO.25.004039; BELLMAN R, 1980, ANAL NUMBER THEORY I, P3; BRONS R, 1985, NATO ASI SERIES F, P19; BROWN CM, 1983, IEEE T PATTERN ANAL, V5, P493, DOI 10.1109/TPAMI.1983.4767428; COHEN M, 1977, PATTERN RECOGN, V9, P95, DOI 10.1016/0031-3203(77)90020-6; DAVIES ER, 1987, IMAGE VISION COMPUT, V5, P279, DOI 10.1016/0262-8856(87)90004-7; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; DORST L, 1984, IEEE T PATTERN ANAL, V6, P632, DOI 10.1109/TPAMI.1984.4767577; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; GORDON SJ, 1986, IEEE COMPUT SOC P RO, P931; HANAHARA K, 1988, IEEE T PATTERN ANAL, V10, P121, DOI 10.1109/34.3876; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Iannino A., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P32; KRISHNASWAMY R, 1987, IEEE T PATTERN ANAL, V9, P316, DOI 10.1109/TPAMI.1987.4767905; LI HW, 1986, COMPUT VISION GRAPH, V36, P139, DOI 10.1016/0734-189X(86)90073-3; MAITRE H, 1986, IEEE T PATTERN ANAL, V8, P669, DOI 10.1109/TPAMI.1986.4767840; MERLIN PM, 1975, IEEE T COMPUT, VC 24, P96, DOI 10.1109/T-C.1975.224087; RHODES FM, 1988, IEEE T PATTERN ANAL, V10, P106, DOI 10.1109/34.3873; ROSENFELD A, 1988, COMPUT VISION GRAPH, V41, P293, DOI 10.1016/0734-189X(88)90104-1; SHAPIRO SD, 1979, IEEE T PATTERN ANAL, V1, P310, DOI 10.1109/TPAMI.1979.4766929; STEIER WH, 1986, APPL OPTICS, V25, P2734, DOI 10.1364/AO.25.002734; SVALBE ID, 1987, FR35 U WASH DEP COMP; VANVEEN TM, 1981, PATTERN RECOGN, V14, P137, DOI 10.1016/0031-3203(81)90055-8; Wallace R. S., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P665	24	31	31	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					941	950		10.1109/34.35497	http://dx.doi.org/10.1109/34.35497			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800004
J	OOMMEN, BJ				OOMMEN, BJ			RECOGNITION OF NOISY SUBSEQUENCES USING CONSTRAINED EDIT DISTANCES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											OOMMEN, BJ (corresponding author), CARLETON UNIV, SCH COMP SCI, OTTAWA K1S 5B6, ONTARIO, CANADA.		Oommen, B. John/P-6323-2017	Oommen, B. John/0000-0002-5105-1575				Aho A. V., 1972, SIAM Journal on Computing, V1, P305, DOI 10.1137/0201022; AHO AV, 1976, J ACM, V23, P1, DOI 10.1145/321921.321922; BAHL LR, 1975, IEEE T INFORM THEORY, V21, P404, DOI 10.1109/TIT.1975.1055419; Berlekamp E.R., 1968, ALGEBRAIC CODING THE; Blair CR., 1960, INF CONTROL, V3, P60; DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994; Denning D.E.R., 1982, CRYPTOGRAPHY DATA SE; Duda R.O., 1973, J ROYAL STAT SOC SER; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; FUNG LW, 1975, IEEE T COMPUT, VC 24, P662, DOI 10.1109/T-C.1975.224278; HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830; HUNT JW, 1977, COMMUN ACM, V20, P350, DOI 10.1145/359581.359603; Kashyap R. L., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P28; KASHYAP RL, 1983, IEEE T SOFTWARE ENG, V9, P365, DOI 10.1109/TSE.1983.237018; KASHYAP RL, 1979, IEEE T PATTERN ANAL, V1, P154, DOI 10.1109/TPAMI.1979.4766901; KASHYAP RL, 1981, INFORM SCIENCES, V23, P123, DOI 10.1016/0020-0255(81)90052-9; Kruskal J.B., 1983, TIME WARPS STRING ED; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; LU SY, 1977, 1ST P IEEE COMP SOC, P492; MAIER D, 1978, J ACM, V25, P322, DOI 10.1145/322063.322075; MASEK WJ, 1980, J COMPUT SYST SCI, V20, P18, DOI 10.1016/0022-0000(80)90002-1; NEUHOFF DL, 1975, IEEE T INFORM THEORY, V21, P222, DOI 10.1109/TIT.1975.1055355; OKUDA T, 1976, IEEE T COMPUT, V25, P172, DOI 10.1109/TC.1976.5009232; OOMMEN BJ, 1986, INFORM SCIENCES, V40, P267, DOI 10.1016/0020-0255(86)90061-7; Peterson W.W., 1981, ERROR CORRECTING COD; RAVIV J, 1967, IEEE T INFORM THEORY, V13, P536, DOI 10.1109/TIT.1967.1054060; SANKOFF D, 1972, P NATL ACAD SCI USA, V69, P4, DOI 10.1073/pnas.69.1.4; SHINGHAL R, 1979, IEEE T PATTERN ANAL, V1, P184, DOI 10.1109/TPAMI.1979.4766904; SRIHARI S, 1984, COMPUTER TEXT RECOGN; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WONG CK, 1976, J ACM, V23, P13, DOI 10.1145/321921.321923	33	31	31	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					676	685		10.1109/TPAMI.1987.4767962	http://dx.doi.org/10.1109/TPAMI.1987.4767962			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869426				2022-12-18	WOS:A1987J739300009
J	ITO, M; ISHII, A				ITO, M; ISHII, A			3-VIEW STEREO ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											ITO, M (corresponding author), NIPPON TELEGRAPH & TEL PUBL CORP, MUSASHINO ELECT COMMUN LAB, 3-9-11 MIDORI CHO, MUSASHINO, TOKYO 180, JAPAN.							BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; GRIMSON WEL, 1981, PHILOS T ROY SOC B, V292, P217, DOI 10.1098/rstb.1981.0031; GRIMSON WEL, 1982, MIT AI697 MEM; HENDERSON RL, 1979, SPIE, V186; ITO M, 1985, IECE PRL8516 TECH PA; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MORAVEC HP, 1979, 6TH P INT JOINT C AR, V1, P598; OHTA Y, 1984, 29 INF PROC SOC JAP; Robinson G.S., 1977, COMPUT VISION GRAPH, V6, P492, DOI 10.1016/s0146-664x(77)80024-5; Yagi, 1973, COMPUT VISION GRAPH, V2, P131; Yasuye T., 1973, Bulletin of the Electrotechnical Laboratory, V37, P1101	14	31	33	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					524	532		10.1109/TPAMI.1986.4767817	http://dx.doi.org/10.1109/TPAMI.1986.4767817			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000012
J	PITAS, I; VENETSANOPOULOS, AN				PITAS, I; VENETSANOPOULOS, AN			EDGE DETECTORS BASED ON NONLINEAR FILTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV TORONTO,DEPT ELECT ENGN,TORONTO M5S 1A4,ONTARIO,CANADA	University of Toronto	PITAS, I (corresponding author), ARISTOTELIAN UNIV SALONIKA,DEPT ELECT ENGN,SALONIKA,GREECE.							ABDOU IE, 1979, P IEEE, V67; DAVID HA, 1981, ORDER STATISTICS; FUKUNAGA K, 1968, IEEE T INFORM THEORY, V14, P780, DOI 10.1109/TIT.1968.1054204; GEUEN W, 1983, SIGNAL PROCESSING, V2; JUSTUSSON BJ, 1981, 2 DIMENSIONAL DIGITA, V2; KENDALL MG, 1973, ADV THEORY STATISTIC, V1; Knuth D., 1973, ART COMPUTER PROGRAM, V3; MODESTINO JW, 1977, COMPUT GRAPHICS IMAG, V6, P409; PITAS I, 1984, OCT P IEEE INT C COM; Pratt W. K., 1978, DIGITAL IMAGE PROCES; PRICE R, 1964, MIT338 LINC LAB TECH	11	31	32	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					538	550		10.1109/TPAMI.1986.4767819	http://dx.doi.org/10.1109/TPAMI.1986.4767819			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000014
J	SATHI, A; FOX, MS; GREENBERG, M				SATHI, A; FOX, MS; GREENBERG, M			REPRESENTATION OF ACTIVITY KNOWLEDGE FOR PROJECT-MANAGEMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CARNEGIE MELLON UNIV,INST ROBOT,INTELLIGENT SYST LAB,PITTSBURGH,PA 15213; UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,AMHERST,MA 01003	Carnegie Mellon University; University of Massachusetts System; University of Massachusetts Amherst								ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; ALLEN JF, 1984, ARTIF INTELL, V23; BOBROW D, 1977, COGN SCI, V1; Brachman R.J., 1979, ASS NETWORKS REPRESE, P3, DOI 10.1016/B978-0-12-256380-5.50007-4; BRACHMAN RJ, 1983, IEEE T COMPUT, V32, P30; BRACHMAN RJ, 1977, THESIS HARVARD U CAM; BRUCE BC, 1972, ARTIF INTELL, V3, P1, DOI 10.1016/0004-3702(72)90040-9; ELLIS C, 1979, P ACM C SIMULATION M; FAHLMAN SE, 1977, THESIS MIT CAMBRIDGE; FINDLER NV, 1971, 2 INT JOINT C ART IN, P531; FOX MS, 1979, 6TH P INT JOINT C AR; FOX MS, 1983, THESIS CARNEGIEMELLO; GOLDSTEIN IP, 1977, 5TH INT JOINT C ART, P257; HAYES PJ, 1979, EXPERT SYSTEMS MICRO, P243; HENDRIX G, 1979, ASS NETWORKS REPRESE; HENDRIX GG, 1973, ARTIF INTELL, V4, P145, DOI 10.1016/0004-3702(73)90010-6; HENDRIX GG, 1975, 4TH INT JOINT C ART; KAHN K, 1977, ARTIF INTELL, V9, P87, DOI 10.1016/0004-3702(77)90015-7; KEDZIERSKI BI, KESU833 KESTR I TECH; KEDZIERSKI BI, 1983, THESIS U SW LOUISIAN; KELLEY JE, 1959, P E JOINT COMPUT C; LEE RM, 1980, THESIS U PENNSYLVANI; LENET D, 1976, THESIS STANFORD U PA; LEVY FK, 1963, HARVARD BUSINESS OCT; MALCOLM DG, 1959, OPER RES         SEP; MCCARTHY J, 1963, AIM2 STANF U TECH RE; MCDERMOTT D, 1982, COGNITIVE SCI, V6, P101, DOI 10.1207/s15516709cog0602_1; MEEHAN JR, 1980, 1ST NAT C ART INT; PETERSON JL, 1977, COMPUTING SUVEYS, V9, P224; QUILLIAN MR, 1966, THESIS CARNEGIEMELLO; RIEGER C, 1977, 5TH P INT JOINT C AR, P250; ROBERTS RB, 1977, MIT408 ART INT LAB T; SACERDOTI E, 1973, 3RD P INT JOINT C AR, P412; SACERDOTI ED, 1974, ARTIF INTELL, V5, P115, DOI 10.1016/0004-3702(74)90026-5; SATHI A, 1985, CALLISTO INTELLIGENT; SATHI A, UNPUB MODELLING PROJ; SCHANK R, 1977, SCRIPS PLANS GOALS U; SCHUBERT LK, 1976, ARTIF INTELL, V7, P163, DOI 10.1016/0004-3702(76)90003-5; SMITH SF, 1983, CMUR1TR8312 CARN U I; STEFIK M, 1979, 6TH P INT JOINT C AR; TATE A, 1977, 5TH P INT JOINT C AR, P888; TURBAN E, 1976, PROJECT MANAGEMENT T, P39; WEBSTER AM, 1983, WEBSTERS 9TH NEW COL; Woods W. A., 1975, REPRESENTATION UNDER; WRIGHT JM, 1984, SRL 2 USERS MANUAL	45	31	31	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	5					531	552		10.1109/TPAMI.1985.4767701	http://dx.doi.org/10.1109/TPAMI.1985.4767701			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AQH94	21869291	Green Submitted			2022-12-18	WOS:A1985AQH9400005
J	FUKUNAGA, K; MANTOCK, JM				FUKUNAGA, K; MANTOCK, JM			NONPARAMETRIC DATA REDUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									AEROSPACE CORP,LOS ANGELES,CA 90009	Aerospace Corporation - USA	FUKUNAGA, K (corresponding author), PURDUE UNIV,DEPT ELECT ENGN,W LAFAYETTE,IN 47907, USA.							KULLBACK S, 1959, INFORMATION THEORY S; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079	2	31	31	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	1					115	118		10.1109/TPAMI.1984.4767485	http://dx.doi.org/10.1109/TPAMI.1984.4767485			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SB213	21869175				2022-12-18	WOS:A1984SB21300016
J	KIM, CE				KIM, CE			3-DIMENSIONAL DIGITAL PLANES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											KIM, CE (corresponding author), WASHINGTON STATE UNIV,DEPT COMP SCI,PULLMAN,WA 99164, USA.							AGIN GJ, 1981, IEEE T PATTERN ANAL, V3, P197, DOI 10.1109/TPAMI.1981.4767079; ARTZY E, 1981, COMPUT VISION GRAPH, V15, P1, DOI 10.1016/0146-664X(81)90103-9; BROOKS RA, 1976, PHYS MED BIOL, V21, P689, DOI 10.1088/0031-9155/21/5/001; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; HERMAN GT, 1978, COMPUT VISION GRAPH, V7, P130, DOI 10.1016/S0146-664X(78)80018-5; KIM CE, 1983, IEEE T PATTERN ANAL, V5, P231, DOI 10.1109/TPAMI.1983.4767379; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P618, DOI 10.1109/TPAMI.1982.4767315; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P612, DOI 10.1109/TPAMI.1982.4767314; KIM CE, 1981, IEEE T PATTERN ANAL, V3, P617, DOI 10.1109/TPAMI.1981.4767162; MORGENTHALER DG, 1981, IEEE T PATTERN ANAL, V3, P482, DOI 10.1109/TPAMI.1981.4767134; MORGENTHALER DG, 1981, THESIS U MARYLAND CO; PREPARATA FP, 1977, COMMUN ACM, V20, P87, DOI 10.1145/359423.359430; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; TSAO YF, UNPUB COMPUT GRAPHIC; UDUPA JK, 1982, IEEE T PATTERN ANAL, V4, P41, DOI 10.1109/TPAMI.1982.4767193; WALLACE TP, 1981, IEEE T PATTERN ANAL, V3, P310, DOI 10.1109/TPAMI.1981.4767104; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P324, DOI 10.1109/TPAMI.1981.4767105	18	31	31	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					639	645		10.1109/TPAMI.1984.4767578	http://dx.doi.org/10.1109/TPAMI.1984.4767578			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813	21869233				2022-12-18	WOS:A1984TM81300010
J	KIM, CE				KIM, CE			DIGITAL CONVEXITY, STRAIGHTNESS, AND CONVEX POLYGONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								FENG HYF, 1975, IEEE T COMPUT, VC 24, P636, DOI 10.1109/T-C.1975.224276; Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2; Hirschberg DS, 1976, P 8 ANN ACM S THEOR, P55; HODES L, 1970, SIAM J APPL MATH, V19, P477, DOI 10.1137/0119048; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P612, DOI 10.1109/TPAMI.1982.4767314; KIM CE, 1982, COMPUT VISION GRAPH, V18, P369, DOI 10.1016/0146-664X(82)90005-3; KIM CE, 1981, IEEE T PATTERN ANAL, V3, P617, DOI 10.1109/TPAMI.1981.4767162; KIM CE, UNPUB PATTERN RECOGN; KIM CE, 1980, TR951 U MAR COMP SCI; KIM CE, 1980, TR929 U MAR COMP SCI; KIM CE, 1981, P ACM STOC, P80; MINSKY M, 1968, PERCEPTRONS; MONTANARI U, 1970, J ASS COMPUT MACH, V17, P348; NASSIMI D, 1980, SIAM J COMPUT, V9, P744, DOI 10.1137/0209058; PAVLIDIS T, 1968, PATTERN RECOGN, V1, P165, DOI 10.1016/0031-3203(68)90006-X; Pavlidis T., 1977, STRUCTURAL PATTERN R; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SKLANSKY J, 1970, PATTERN RECOGN, V2, P3, DOI 10.1016/0031-3203(70)90037-3; SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P260, DOI 10.1109/TC.1972.5008948	21	31	31	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					618	626		10.1109/TPAMI.1982.4767315	http://dx.doi.org/10.1109/TPAMI.1982.4767315			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499636				2022-12-18	WOS:A1982PS23700007
J	PECK, R; VANNESS, J				PECK, R; VANNESS, J			THE USE OF SHRINKAGE ESTIMATORS IN LINEAR DISCRIMINANT-ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											PECK, R (corresponding author), UNIV TEXAS DALLAS,PROGRAM MATH SCI,RICHARDSON,TX 75080, USA.							Anderson T.W, 1958, INTRO MULTIVARIATE S; Barnard MM, 1935, ANN EUGENIC, V6, P352, DOI 10.1111/j.1469-1809.1935.tb02117.x; CAMPBELL NA, 1978, J INT ASS MATH GEOL, V10, P347, DOI 10.1007/BF01031739; CAMPBELL NA, 1980, APPL STATIST, V29, P5; DASGUPTA S, 1965, ANN MATH STAT, V36, P1174; DASGUPTA S, 1973, DISCRIMINANT ANAL AP, P00077; DIPILLO PJ, 1979, COMMUN STAT A-THEOR, V8, P1447, DOI 10.1080/03610927908827842; DIPILLO PJ, 1977, COMMUN STAT A-THEOR, V6, P933, DOI 10.1080/03610927708827542; DIPILLO PJ, 1976, COMMUN STAT A-THEOR, V5, P843, DOI 10.1080/03610927608827401; EFRON B, 1976, ANN STAT, V4, P22, DOI 10.1214/aos/1176343345; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; GLICK N, 1980, MAR NASA WORKSH DIG; HAFF LR, 1980, ANN STAT, V8, P586, DOI 10.1214/aos/1176345010; HAFF LR, 1979, ANN STAT, V7, P1264, DOI 10.1214/aos/1176344845; HAMMERSLEY J, 1967, MONTE CARLO METHODS; JOHN S, 1961, ANN MATH STAT, V32, P1125, DOI 10.1214/aoms/1177704851; LIN SP, 1979, 791 MEMPH STAT U DEP; LIN SP, 1978, 787 MEMPH STAT U DEP; MURPHY BJ, 1979, COMP PARAMETRIC KERN; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; RAO CR, 1954, ANN MATH STAT, V25, P651, DOI 10.1214/aoms/1177728653; REMME J, 1978, SIMULATIVE COMP LINE; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; STEIN C, 1975, RIETZ LECTURE NOTES; VANNESS J, 1979, TECHNOMETRICS, V21, P119, DOI 10.2307/1268588; VANNESS J, 1980, PATTERN RECOGNITION; VANNESS J, 1979, 46 U TEX MATH SCI PR; VANNESS JW, 1976, TECHNOMETRICS, V18, P175, DOI 10.2307/1267520; Wald A, 1944, ANN MATH STAT, V15, P145, DOI 10.1214/aoms/1177731280	30	31	32	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	5					530	537		10.1109/TPAMI.1982.4767298	http://dx.doi.org/10.1109/TPAMI.1982.4767298			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PG894	21869073				2022-12-18	WOS:A1982PG89400010
J	WU, AY; HONG, TH; ROSENFELD, A				WU, AY; HONG, TH; ROSENFELD, A			THRESHOLD SELECTION USING QUADTREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											WU, AY (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							KIRBY RL, 1979, IEEE T SYST MAN CYB, V9, P860; Klinger A., 1973, 1st International Joint Conference on Pattern Recognition, P497; MILGRAM DL, 1978, ALGORITHMS HARDWARE; PAVLIDIS T, 1977, STRUCTURAL PATTERN R, pCH5; RANADE S, 1980, TR862 U MAR COMP SCI; RANADE S, 1980, TR878 U MAR COMP SCI; WESZKA JS, 1979, IEEE T SYST MAN CYB, V9, P38; WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8	8	31	34	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					90	94		10.1109/TPAMI.1982.4767203	http://dx.doi.org/10.1109/TPAMI.1982.4767203			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21869011				2022-12-18	WOS:A1982MY53400017
J	QUINQUETON, J; BERTHOD, M				QUINQUETON, J; BERTHOD, M			A LOCALLY ADAPTIVE PEANO SCANNING ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											QUINQUETON, J (corresponding author), INST NATL RECH INFORMAT & AUTOMAT,PATTERN RECOGINAT GRP,ROCQUENCOURT,FRANCE.							ALEXANDROV VV, 1978, TECH CYBERN; ALEXANDROV VV, 1979, RECURSIVE ALGORITHMS; ALEXANDROV VV, 1978, FEB AFCET IRIA C PAR; [Anonymous], 1969, J COMPUT SYST SCI, DOI DOI 10.1016/S0022-0000(69)80010-3; BERTHOD M, 1976, IRIALABORIA174 RES R; BIALLY T, 1969, IEEE T INFORM THEORY, V15; BUTZ AR, 1968, INFORM CONTROL, V12, P314, DOI 10.1016/S0019-9958(68)90367-7; BUTZ AR, 1971, IEEE T COMPUT      C, V20; DIDAY E, 1976, DIGITAL PATTERN RECO; Fisher R.A., 1936, ANN EUGEN, V7, P178; FLAJOLET P, UNPUBLISHED; GIPS J, 1975, SHAPE GRAMMARS THEIR, P38; GOVAERT G, 1975, THESIS PARIS 4 U PAR; HAWKES J, 1974, P LONDON MATH SOC, V3, P700; Hilbert D., 1891, MATH ANN, V38, P459, DOI [10.1007/bf01199431, DOI 10.1007/BF01199431, 10.1007/978-3-662-38452-7_1, 10.1007/BF01199431]; HOBSON EW, 1957, THEORY FUNCTIONS REA, P451; KANAL LN, 1965, IEEE T INFORM THEORY, V11; KOENDERINK JJ, 1979, P IEEE, V67; LOUIT G, 1971, ALGORITHMES TRI; Mandelbrot B.B., 1977, FRACTALS FORM CHANCE; PATRICK EA, 1968, IEEE T COMPUT      C, V17; Peano G, 1890, MATH ANN, V36; QUINQUETON J, 1978, P INT JOINT C PATTER, V4, P292; QUINQUETON J, 1979, FRENCH CLASSIFICATIO; SIMON JC, 1978, FRENCH ACAD SCI REP, V286, P655; STEVENS R, UNPUBLISHED; TOUSSAINT GT, 1977, PATTERN RECOGNITION, V2	27	31	31	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					403	412		10.1109/TPAMI.1981.4767126	http://dx.doi.org/10.1109/TPAMI.1981.4767126			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ357	21868961				2022-12-18	WOS:A1981MQ35700005
J	CHAKRAVARTY, I				CHAKRAVARTY, I			GENERALIZED LINE AND JUNCTION LABELING SCHEME WITH APPLICATIONS TO SCENE ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											CHAKRAVARTY, I (corresponding author), RENSSELAER POLYTECH INST,DEPT ELECT & SYST ENGN,TROY,NY 12181, USA.							CHAKRAVARTY I, 1977, CRL55 RENSS POL I TE; CLOWES MB, 1970, ARTIF INTELL, V1, P79; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; SANKAR K, 1977, COMPUT GRAPHICS IMAG, V6, P61; SHAPIRA R, UNPUBLISHED; SHAPIRA R, 1976, CRL48 RENSS POL I TE; TURNER KJ, 1975, JUL AISB SUMM C BRIG; WALTZ D, 1975, PSYCHOLOGY COMPUTER	8	31	35	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					202	205		10.1109/TPAMI.1979.4766906	http://dx.doi.org/10.1109/TPAMI.1979.4766906			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA304	21868849				2022-12-18	WOS:A1979HA30400010
J	Li, ZC; Sun, YP; Zhang, LY; Tang, JH				Li, Zechao; Sun, Yanpeng; Zhang, Liyan; Tang, Jinhui			CTNet: Context-Based Tandem Network for Semantic Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Image segmentation; Feature extraction; Correlation; Computational modeling; Task analysis; Convolution; Semantic segmentation; channel context; spatial context; tandem network		Contextual information has been shown to be powerful for semantic segmentation. This work proposes a novel Context-based Tandem Network (CTNet) by interactively exploring the spatial contextual information and the channel contextual information, which can discover the semantic context for semantic segmentation. Specifically, the Spatial Contextual Module (SCM) is leveraged to uncover the spatial contextual dependency between pixels by exploring the correlation between pixels and categories. Meanwhile, the Channel Contextual Module (CCM) is introduced to learn the semantic features including the semantic feature maps and class-specific features by modeling the long-term semantic dependence between channels. The learned semantic features are utilized as the prior knowledge to guide the learning of SCM, which can make SCM obtain more accurate long-range spatial dependency. Finally, to further improve the performance of the learned representations for semantic segmentation, the results of the two context modules are adaptively integrated to achieve better results. Extensive experiments are conducted on four widely-used datasets, i.e., PASCAL-Context, Cityscapes, ADE20K and PASCAL VOC2012. The results demonstrate the superior performance of the proposed CTNet by comparison with several state-of-the-art methods. The source code and models are available at https://github.com/syp2ysy/CTNet.	[Li, Zechao; Sun, Yanpeng; Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China; [Zhang, Liyan] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 210095, Peoples R China	Nanjing University of Science & Technology; Nanjing University of Aeronautics & Astronautics	Tang, JH (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.	zechao.li@njust.edu.cn; yanpeng_sun@njust.edu.cn; zhangliyan@nuaa.edu.cn; jinhuitang@njust.edu.cn		Zhang, Liyan/0000-0002-1549-3317	National Key Research and Development Program of China [2018AAA0102002]; National Natural Science Foundation of China [U20B2064, 61772268, 61925204]; Natural Science Foundation of Jiangsu Province [BK20190065]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Jiangsu Province(Natural Science Foundation of Jiangsu Province)	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0102002, in part by the National Natural Science Foundation of China under Grants U20B2064, 61772268, and 61925204, and in part by the Natural Science Foundation of Jiangsu Province under Grant BK20190065.	Alexander C. Berg, 2015, Arxiv, DOI arXiv:1506.04579; Wong ALXD, 2021, Arxiv, DOI arXiv:2104.14623; Bai S., 2020, PROC INT C NEURAL IN; Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246; Changqian Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12413, DOI 10.1109/CVPR42600.2020.01243; Chao Zhang, 2019, Arxiv, DOI arXiv:1907.12273; Chen LC., ARXIV 2015ABS1412706; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen YP, 2018, ADV NEUR IN, V31; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Ding HH, 2019, PROC CVPR IEEE, P8877, DOI 10.1109/CVPR.2019.00909; Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254; Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352; Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200; Dong Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P323, DOI 10.1007/978-3-030-58604-1_20; Dosovitskiy Alexey., 2020, P INT C LEARN REPR I; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Florian Schroff, 2017, Arxiv, DOI arXiv:1706.05587; Fu J, 2019, IEEE I CONF COMP VIS, P6747, DOI 10.1109/ICCV.2019.00685; Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326; Fu J, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2019.107152; Fan HQ, 2021, Arxiv, DOI arXiv:2104.11227; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069; Huikai Wu, 2019, Arxiv, DOI arXiv:1903.11816; Hung WC, 2017, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2017.287; Ke TW, 2018, LECT NOTES COMPUT SC, V11205, P605, DOI 10.1007/978-3-030-01246-5_36; Kirillov Alexander, 2020, CVPR; Li Hanchao, 2018, ARXIV180510180; Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926; Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060; Li Y, 2018, ADV NEUR IN, V31; Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750; Lin D, 2018, LECT NOTES COMPUT SC, V11207, P622, DOI 10.1007/978-3-030-01219-9_37; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin GS, 2018, IEEE T PATTERN ANAL, V40, P1352, DOI 10.1109/TPAMI.2017.2708714; Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Minghao Yin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P191, DOI 10.1007/978-3-030-58555-6_12; Ni ZL, 2019, LECT NOTES COMPUT SC, V11954, P139, DOI 10.1007/978-3-030-36711-4_13; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155; Ranftl R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12159, DOI 10.1109/ICCV48922.2021.01196; Seyedhosseini M, 2016, IEEE T PATTERN ANAL, V38, P951, DOI 10.1109/TPAMI.2015.2473846; Shen D., 2020, PROC INT C NEURAL IN; Vaswani A, 2017, ADV NEUR IN, V30; Vemulapalli R, 2016, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2016.351; Wang GR, 2017, PROC CVPR IEEE, P5235, DOI 10.1109/CVPR.2017.556; Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xiangtai Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P435, DOI 10.1007/978-3-030-58520-4_26; Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26; Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11; Zhang D., 2020, PROC INT C NEURAL IN; Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064; Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747; Zhang R, 2017, IEEE I CONF COMP VIS, P2050, DOI 10.1109/ICCV.2017.224; Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544; Zhu L., 2010, PROC IEEE C COMPUT V, P12537; Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068	75	30	30	6	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					9904	9917		10.1109/TPAMI.2021.3132068	http://dx.doi.org/10.1109/TPAMI.2021.3132068			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34855586	Green Submitted			2022-12-18	WOS:000880661400096
J	Xu, X; Lin, KY; Yang, Y; Hanjalic, A; Shen, HT				Xu, Xing; Lin, Kaiyi; Yang, Yang; Hanjalic, Alan; Shen, Heng Tao			Joint Feature Synthesis and Embedding: Adversarial Cross-Modal Retrieval Revisited	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cross-modal retrieval; embedding features; adversarial learning; zero-shot learning; knowledge transfer	REPRESENTATION	Recently, generative adversarial network (GAN) has shown its strong ability on modeling data distribution via adversarial learning. Cross-modal GAN, which attempts to utilize the power of GAN to model the cross-modal joint distribution and to learn compatible cross-modal features, is becoming the research hotspot. However, the existing cross-modal GAN approaches typically 1) require labeled multimodal data of massive labor cost to establish cross-modal correlation; 2) utilize the vanilla GAN model that results in unstable training procedure and meaningless synthetic features; and 3) lack of extensibility for retrieving cross-modal data of new classes. In this article, we revisit the adversarial learning in existing cross-modal GAN methods and propose Joint Feature Synthesis and Embedding (JFSE), a novel method that jointly performs multimodal feature synthesis and common embedding space learning to overcome the above three shortcomings. Specifically, JFSE deploys two coupled conditional Wassertein GAN modules for the input data of two modalities, to synthesize meaningful and correlated multimodal features under the guidance of the word embeddings of class labels. Moreover, three advanced distribution alignment schemes with advanced cycle-consistency constraints are proposed to preserve the semantic compatibility and enable the knowledge transfer in the common embedding space for both the true and synthetic cross-modal features. All these add-ons in JFSE not only help to learn more effective common embedding space that effectively captures the cross-modal correlation but also facilitate to transfer knowledge to multimodal data of new classes. Extensive experiments are conducted on four widely used cross-modal datasets, and the comparisons with more than ten state-of-the-art approaches show that our JFSE method achieves remarkably accuracy improvement on both standard retrieval and the newly explored zero-shot and generalized zero-shot retrieval tasks.	[Xu, Xing; Lin, Kaiyi; Yang, Yang; Shen, Heng Tao] Univ Elect Sci & Technol China, Ctr Future Media & Sch Comp Sci & Engn, Chengdu 611731, Peoples R China; [Hanjalic, Alan] Delft Univ Technol, Fac Elect Engn Math & Comp Sci, NL-2628 Delft, Netherlands	University of Electronic Science & Technology of China; Delft University of Technology	Shen, HT (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media & Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.	xing.xu@uestc.edu.cn; lky.linkaiyi@gmail.com; dlyyang@gmail.com; A.Hanjalic@tudelft.nl; shenhengtao@hotmail.com	yang, yang/GVT-5210-2022; yang, yang/HGT-7999-2022	Hanjalic, Alan/0000-0002-5771-2549	National Natural Science Foundation of China [61976049, 61632007]; Fundamental Research Funds for the Central Universities [ZYGX2019Z015]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported in part by the National Natural Science Foundation of China under Project 61976049 and 61632007; and the Fundamental Research Funds for the Central Universities under Project (ZYGX2019Z015).	Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Aytar Y, 2018, IEEE T PATTERN ANAL, V40, P2303, DOI 10.1109/TPAMI.2017.2753232; Ba J., 2017, P 3 INT C LEARN REPR; Ballan L., 2014, P INT C MULT RETR, P73; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Chi JZ, 2020, IEEE T CIRC SYST VID, V30, P1173, DOI 10.1109/TCSVT.2019.2900171; Chi JZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P663; Chua T.-S., 2009, P ACM INT C IM VID R, P1, DOI 10.1145/1646396.1646452; Dey S, 2019, PROC CVPR IEEE, P2174, DOI 10.1109/CVPR.2019.00228; Dutta A, 2019, PROC CVPR IEEE, P5084, DOI 10.1109/CVPR.2019.00523; Dutta T, 2019, IEEE T IMAGE PROCESS, V28, P5953, DOI 10.1109/TIP.2019.2923287; Felix R, 2018, LECT NOTES COMPUT SC, V11210, P21, DOI 10.1007/978-3-030-01231-1_2; Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Gao LL, 2019, AAAI CONF ARTIF INTE, P8312; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gretton A, 2012, J MACH LEARN RES, V13, P723; Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hoffman J, 2018, PR MACH LEARN RES, V80; Hu MQ, 2019, IEEE T IMAGE PROCESS, V28, P2770, DOI 10.1109/TIP.2018.2890144; Huang X, 2018, PROC CVPR IEEE, P8837, DOI 10.1109/CVPR.2018.00921; Huang X, 2020, IEEE T CYBERNETICS, V50, P1047, DOI 10.1109/TCYB.2018.2879846; Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499; Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336; Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Li D., 2003, P 11 ACM INT C MULTI, P604, DOI DOI 10.1145/957013.957143; Liu  Ruoyu, 2017, ARXIV170303567; Mikolov T., 2013, ARXIV; Mirza M., 2014, ARXIV; Mishra A, 2018, IEEE COMPUT SOC CONF, P2269, DOI 10.1109/CVPRW.2018.00294; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Peng Y., 2016, IJCAI, P3846, DOI DOI 10.5555/3061053.3061157; Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068; Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750; Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P5585, DOI 10.1109/TIP.2018.2852503; Peng YX, 2018, IEEE T MULTIMEDIA, V20, P405, DOI 10.1109/TMM.2017.2742704; Qi JW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2630; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.1002/ACP.3140; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Salvador A, 2017, PROC CVPR IEEE, P3068, DOI 10.1109/CVPR.2017.327; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Verma VK, 2018, PROC CVPR IEEE, P4281, DOI 10.1109/CVPR.2018.00450; Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326; Wang D, 2019, IEEE T PATTERN ANAL, V41, P2466, DOI 10.1109/TPAMI.2018.2861000; Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311; Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581; Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768; Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328; Xu X, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1419, DOI 10.1145/3397271.3401149; Xu X, 2020, IEEE T CYBERNETICS, V50, P2400, DOI [10.1109/TCYB.2019.2928180, 10.1080/00207543.2019.1579935]; Xu X, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P46, DOI 10.1145/3206025.3206033; Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345; Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966; Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704; Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629; Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321; Zhang Y, 2018, LECT NOTES COMPUT SC, V11205, P707, DOI 10.1007/978-3-030-01246-5_42; Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064; Zheng F, 2018, IEEE T PATTERN ANAL, V40, P1059, DOI 10.1109/TPAMI.2016.2645565; Zhu B, 2019, PROC CVPR IEEE, P11469, DOI 10.1109/CVPR.2019.01174; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	67	30	31	27	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3030	3047		10.1109/TPAMI.2020.3045530	http://dx.doi.org/10.1109/TPAMI.2020.3045530			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33332264				2022-12-18	WOS:000803117500019
J	Sindagi, VA; Yasarla, R; Patel, VM				Sindagi, Vishwanath A.; Yasarla, Rajeev; Patel, Vishal M.			JHU-CROWD plus plus : Large-Scale Crowd Counting Dataset and A Benchmark Method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Annotations; Task analysis; Training; Head; Meteorology; Benchmark testing; Learning systems; Crowd counting; dataset		We introduce a new large scale unconstrained crowd counting dataset (JHU-CROWD++) that contains "4,372" images with "1.51 million" annotations. In comparison to existing datasets, the proposed dataset is collected under a variety of diverse scenarios and environmental conditions. Specifically, the dataset includes several images with weather-based degradations and illumination variations, making it a very challenging dataset. Additionally, the dataset consists of a rich set of annotations at both image-level and head-level. Several recent methods are evaluated and compared on this dataset. The dataset can be downloaded from http://www.crowd-counting.com. Furthermore, we propose a novel crowd counting network that progressively generates crowd density maps via residual error estimation. The proposed method uses VGG16 as the backbone network and employs density map generated by the final layer as a coarse prediction to refine and generate finer density maps in a progressive fashion using residual learning. Additionally, the residual learning is guided by an uncertainty-based confidence weighting mechanism that permits the flow of only high-confidence residuals in the refinement path. The proposed Confidence Guided Deep Residual Counting Network (CG-DRCN) is evaluated on recent complex datasets, and it achieves significant improvements In errors.	[Sindagi, Vishwanath A.; Yasarla, Rajeev; Patel, Vishal M.] Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA	Johns Hopkins University	Sindagi, VA (corresponding author), Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA.	vishwanathsindagi@jhu.edu; ryasarlal9@jhu.edu; vpatel36@jhu.edu			NSF [1910141]	NSF(National Science Foundation (NSF))	This work was supported by the NSF Grant 1910141. The authors would like to express our deep gratitude to everyone who contributed to the creation of this dataset including the members of the JHU-VIU lab and the numerous Amazon Mturk workers. They would like to specially thank Kumar Siddhanth, Poojan Oza, A. N. Sindagi, Jayadev S, Supriya S, Shruthi S, and S. Sreevali for providing assistance in annotation and verification efforts.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arteta C, 2016, LECT NOTES COMPUT SC, V9911, P483, DOI 10.1007/978-3-319-46478-7_30; Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300; Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45; Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569; Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191; Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21; Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319; DeVries T., 2018, ARXIV 180204865; French G., 2015, CONVOLUTIONAL NEURAL, DOI [10.5244/C.29.MVAB.7, DOI 10.5244/C.29.MVAB.7]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33; Jiang Xiaolong, 2019, IEEE C COMP VIS PATT; Ke W, 2017, PROC CVPR IEEE, P302, DOI 10.1109/CVPR.2017.40; Kendall A., 2017, WHAT UNCERTAINTIES W, V3, P4; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Lempitsky V., 2010, NIPS, V23, P1324; Li M, 2008, INT C PATT RECOG, P1998; Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029; Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111; Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120; Lim B., 2017, P APSIPA ANN SUMM C, P4; Liu LB, 2019, IEEE I CONF COMP VIS, P1774, DOI 10.1109/ICCV.2019.00186; Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334; Liu Q., 2020, ARXIV 200312783; Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524; Liu XL, 2018, PROC CVPR IEEE, P7661, DOI 10.1109/CVPR.2018.00799; Loy C. C., 2013, MODELING SIMULATION, DOI 10.1007/978-1-4614-8483-7_14; Lu H, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0224-0; Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624; Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872; Marsden M, 2018, PROC CVPR IEEE, P8070, DOI 10.1109/CVPR.2018.00842; O~noro-Rubio D., 2018, P BRIT MACH VIS C, P262; Onoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38; Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233; Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17; Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22; Sam DB, 2019, AAAI CONF ARTIF INTE, P8868; Sam DB, 2021, IEEE T PATTERN ANAL, V43, P2739, DOI 10.1109/TPAMI.2020.2974830; Sam DB, 2018, AAAI CONF ARTIF INTE, P7323; Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381; Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550; Shi ML, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON INDUSTRIAL ARTIFICIAL INTELLIGENCE (IAI 2019); Shi ZL, 2018, PROC CVPR IEEE, P5382, DOI 10.1109/CVPR.2018.00564; Sindagi V. A., 2017, ADV VIDEO SIGNAL BAS, V14, P1, DOI DOI 10.1109/AVSS.2017.8078491; Sindagi VA, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Sindagi VA, 2019, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2019.00131; Sindagi VA, 2019, IEEE I CONF COMP VIS, P1002, DOI 10.1109/ICCV.2019.00109; Sindagi VA, 2020, IEEE T IMAGE PROCESS, V29, P323, DOI 10.1109/TIP.2019.2928634; Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206; Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372; Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41; Wan J, 2019, IEEE I CONF COMP VIS, P1130, DOI 10.1109/ICCV.2019.00122; Wan J, 2019, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2019.00416; Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01; Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269; Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839; Wang Ze, 2018, ARXIV180806133, P78; Xu BL, 2016, IEEE WINT CONF APPL; Yasarla R, 2019, PROC CVPR IEEE, P8397, DOI 10.1109/CVPR.2019.00860; Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4; Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684; Zhang C, 2016, IEEE T MULTIMEDIA, V18, P1048, DOI 10.1109/TMM.2016.2542585; Zhang Q, 2020, AAAI CONF ARTIF INTE, V34, P12837; Zhang Q, 2019, PROC CVPR IEEE, P8289, DOI 10.1109/CVPR.2019.00849; Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70; Zhao MM, 2019, PROC CVPR IEEE, P12728, DOI 10.1109/CVPR.2019.01302; Zhu F, 2014, LECT NOTES COMPUT SC, V8694, P139, DOI 10.1007/978-3-319-10599-4_10; Zhu Jun-Yan, 2017, ICCV; Zhu LX, 2017, INT CONF DAT MIN WOR, P103, DOI 10.1109/ICDMW.2017.19	76	30	31	12	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2594	2609		10.1109/TPAMI.2020.3035969	http://dx.doi.org/10.1109/TPAMI.2020.3035969			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33147141	Green Submitted			2022-12-18	WOS:000792921400028
J	Wang, LG; Guo, YL; Wang, YQ; Liang, ZF; Lin, ZP; Yang, JG; An, W				Wang, Longguang; Guo, Yulan; Wang, Yingqian; Liang, Zhengfa; Lin, Zaiping; Yang, Jungang; An, Wei			Parallax Attention for Unsupervised Stereo Correspondence Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Three-dimensional displays; Cameras; Correlation; Aggregates; Parallax attention; stereo matching; image super-resolution; unsupervised learning; stereo correspondence	NETWORKS	Stereo image pairs encode 3D scene cues into stereo correspondences between the left and right images. To exploit 3D cues within stereo images, recent CNN based methods commonly use cost volume techniques to capture stereo correspondence over large disparities. However, since disparities can vary significantly for stereo cameras with different baselines, focal lengths and resolutions, the fixed maximum disparity used in cost volume techniques hinders them to handle different stereo image pairs with large disparity variations. In this paper, we propose a generic parallax-attention mechanism (PAM) to capture stereo correspondence regardless of disparity variations. Our PAM integrates epipolar constraints with attention mechanism to calculate feature similarities along the epipolar line to capture stereo correspondence. Based on our PAM, we propose a parallax-attention stereo matching network (PASMnet) and a parallax-attention stereo image super-resolution network (PASSRnet) for stereo matching and stereo image super-resolution tasks. Moreover, we introduce a new and large-scale dataset named Flickr1024 for stereo image super-resolution. Experimental results show that our PAM is generic and can effectively learn stereo correspondence under large disparity variations in an unsupervised manner. Comparative results show that our PASMnet and PASSRnet achieve the state-of-the-art performance.	[Wang, Longguang; Guo, Yulan; Wang, Yingqian; Lin, Zaiping; Yang, Jungang; An, Wei] Nat Univ Def Technol NUDT, Coll Elect Sci & Technol, Changsha 410073, Peoples R China; [Guo, Yulan] Sun Yat Sen Univ, Sch Elect & Commun Engn, Guangzhou 510275, Peoples R China; [Liang, Zhengfa] Natl Key Lab Sci & Technol Blind Signal Proc, Chengdu 610041, Peoples R China	National University of Defense Technology - China; Sun Yat Sen University	Guo, YL (corresponding author), Nat Univ Def Technol NUDT, Coll Elect Sci & Technol, Changsha 410073, Peoples R China.	wanglongguang15@nudt.edu.cn; yulan.guo@nudt.edu.cn; wangyingqian16@nudt.edu.cn; liangzhengfa10@nudt.edu.cn; linzaiping@nudt.edu.cn; yangjungang@nudt.edu.cn; anwei@nudt.edu.cn	guo, yu/GQZ-1392-2022; Wang, Yingqian/AAW-4092-2020; Guo, Yulan/E-7102-2014	Wang, Yingqian/0000-0002-9081-6227; Guo, Yulan/0000-0001-7051-841X; Yang, Jungang/0000-0002-3127-8705	National Natural Science Foundation of China [61972435]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Natural Science Foundation of China (No. 61972435). The authors would like to thank Sascha Becher and Tom Bentz for the approval of using their cross-eye stereo photographs on Flickr. Longguang Wang and Yulan Guo contributed equally to this work and are the co-first authors.	Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150; Ahmadi A, 2016, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2016.7532634; Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Bhavsar AV, 2010, IEEE T PATTERN ANAL, V32, P1721, DOI 10.1109/TPAMI.2010.90; Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567; Chen DD, 2018, PROC CVPR IEEE, P6654, DOI 10.1109/CVPR.2018.00696; Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339; Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434; Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828; Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Jeon DS, 2018, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2018.00185; Jie ZQ, 2018, PROC CVPR IEEE, P3838, DOI 10.1109/CVPR.2018.00404; Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224; Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kingma D.P., 2015, ICLR, P1; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Li A., 2018, PROC ASIAN C COMPUT, P197; Li B, 2018, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2018.00682; Liang ZF, 2021, IEEE T PATTERN ANAL, V43, P300, DOI 10.1109/TPAMI.2019.2928550; Liang ZF, 2018, PROC CVPR IEEE, P2811, DOI 10.1109/CVPR.2018.00297; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6; Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614; Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108; Park H, 2017, IEEE SIGNAL PROC LET, V24, P1788, DOI 10.1109/LSP.2016.2637355; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3; Sener O, 2018, ADV NEUR IN, V31; Shaked A, 2017, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2017.730; Song W, 2020, AAAI CONF ARTIF INTE, V34, P12031; T_ackstr_om O, 2016, P 2016 C EMP METH NA; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479; Vaswani A, 2017, ADV NEUR IN, V30; Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253; Wang LG, 2020, IEEE T IMAGE PROCESS, V29, P4323, DOI 10.1109/TIP.2020.2967596; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247; Wang Y., 2020, P EUR C COMP VIS; Wang YQ, 2019, IEEE INT CONF COMP V, P3852, DOI 10.1109/ICCVW.2019.00478; Wang YQ, 2019, IEEE SIGNAL PROC LET, V26, P204, DOI 10.1109/LSP.2018.2885213; Wang YL, 2018, IEEE T IMAGE PROCESS, V27, P4274, DOI 10.1109/TIP.2018.2834819; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39; Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212; Yu JJ, 2016, LECT NOTES COMPUT SC, V9915, P3, DOI 10.1007/978-3-319-49409-8_1; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767; Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027; Zhang H, 2019, PR MACH LEARN RES, V97; Zhang SF, 2019, PROC CVPR IEEE, P919, DOI 10.1109/CVPR.2019.00101; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17; Zhou C, 2017, IEEE I CONF COMP VIS, P1576, DOI 10.1109/ICCV.2017.174; Zhou SC, 2019, PROC CVPR IEEE, P10988, DOI 10.1109/CVPR.2019.01125; Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323	70	30	30	31	64	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2108	2125		10.1109/TPAMI.2020.3026899	http://dx.doi.org/10.1109/TPAMI.2020.3026899			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	32976095	Green Submitted			2022-12-18	WOS:000764815300033
J	Hui, TW; Tang, X; Loy, CC				Hui, Tak-Wai; Tang, Xiaoou; Loy, Chen Change			A Lightweight Optical Flow CNN -Revisiting Data Fidelity and Regularization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optical imaging; Adaptive optics; Estimation; Optical computing; Convolutional codes; Optical network units; Convolutional neural network; cost volume; deep learning; optical flow; regularization; spatial pyramid; and warping	DETERMINING SHAPE; MOTION; FRAMEWORK; CAMERA	Over four decades, the majority addresses the problem of optical flow estimation using variational methods. With the advance of machine learning, some recent works have attempted to address the problem using convolutional neural network (CNN) and have showed promising results. FlowNet2 [1] , the state-of-the-art CNN, requires over 160M parameters to achieve accurate flow estimation. Our LiteFlowNet2 outperforms FlowNet2 on Sintel and KITTI benchmarks, while being 25.3 times smaller in the model size and 3.1 times faster in the running speed. LiteFlowNet2 is built on the foundation laid by conventional methods and resembles the corresponding roles as data fidelity and regularization in variational methods. We compute optical flow in a spatial-pyramid formulation as SPyNet [2] but through a novel lightweight cascaded flow inference. It provides high flow estimation accuracy through early correction with seamless incorporation of descriptor matching. Flow regularization is used to ameliorate the issue of outliers and vague flow boundaries through feature-driven local convolutions. Our network also owns an effective structure for pyramidal feature extraction and embraces feature warping rather than image warping as practiced in FlowNet2 and SPyNet. Comparing to LiteFlowNet [3] , LiteFlowNet2 improves the optical flow accuracy on Sintel Clean by 23.3 percent, Sintel Final by 12.8 percent, KITTI 2012 by 19.6 percent, and KITTI 2015 by 18.8 percent, while being 2.2 times faster. Our network protocol and trained models are made publicly available on https://github.com/twhui/LiteFlowNet2.	[Hui, Tak-Wai; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Peoples R China; [Loy, Chen Change] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore	Chinese University of Hong Kong; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Hui, TW (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Peoples R China.	twhui@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk; ccloy@ntu.edu.sg		Hui, Tak-Wai/0000-0002-1441-9289; Loy, Chen Change/0000-0001-5345-1591	General Research Fund of Hong Kong [CHUK 14209217, 14241716, 14224316]; Singapore MOE AcRF Tier 1 [2018-T1-002-056]; NTU SUG; NTU NAP	General Research Fund of Hong Kong; Singapore MOE AcRF Tier 1(Ministry of Education, Singapore); NTU SUG(Nanyang Technological University); NTU NAP	This work was partially supported by the General Research Fund of Hong Kong (CUHK 14209217, 14241716, 14224316), Singapore MOE AcRF Tier 1 (2018-T1-002-056), NTU SUG, and NTU NAP.	Bailer C, 2015, IEEE I CONF COMP VIS, P4015, DOI 10.1109/ICCV.2015.457; Bailer Christian, 2017, P C COMP VIS PATT RE, P3250; Black M. J., 1997, P C COMP VIS PATT RE, P674; Brabandere B.D., 2016, ADV NEURAL INFORM PR, P667; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Guney F, 2017, LECT NOTES COMPUT SC, V10114, P207, DOI 10.1007/978-3-319-54190-7_13; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936; Hui TW, 2015, PATTERN RECOGN, V48, P422, DOI 10.1016/j.patcog.2014.08.012; Hui TW, 2013, PROC CVPR IEEE, P2267, DOI 10.1109/CVPR.2013.294; Hui TW, 2013, COMPUT VIS IMAGE UND, V117, P947, DOI 10.1016/j.cviu.2013.04.007; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jaderberg M, 2015, ADV NEUR IN, V28; Kim T. H., 2013, P IEEE INT C COMP VI, P2373; Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10; Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Nir T, 2008, INT J COMPUT VISION, V76, P205, DOI 10.1007/s11263-007-0051-2; Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y; Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Rosenbaum D., 2013, ADV NEURAL INFORM PR, V26, P2373; Roth S, 2005, IEEE I CONF COMP VIS, P42; Roth S, 2005, PROC CVPR IEEE, P860; Sun DQ, 2008, LECT NOTES COMPUT SC, V5304, P83; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x; Sun Deqing, 2019, IEEE T PATTERN ANAL; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tschumperle D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87; Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175; Werlberger M., 2009, P BRIT MACH VIS C; Wulff J, 2015, PROC CVPR IEEE, P120, DOI 10.1109/CVPR.2015.7298607; Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211; Xu J., 2017, P C COMP VIS PATT RE, P1289; Yu JJ, 2016, LECT NOTES COMPUT SC, V9915, P3, DOI 10.1007/978-3-319-49409-8_1; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zimmer H, 2011, INT J COMPUT VISION, V93, P368, DOI 10.1007/s11263-011-0422-6; Zweig S, 2017, PROC CVPR IEEE, P6363, DOI 10.1109/CVPR.2017.674	48	30	30	4	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2555	2569		10.1109/TPAMI.2020.2976928	http://dx.doi.org/10.1109/TPAMI.2020.2976928			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32142417	Green Submitted			2022-12-18	WOS:000670578800003
J	Chen, C; Xiong, ZW; Tian, XM; Zha, ZJ; Wu, F				Chen, Chang; Xiong, Zhiwei; Tian, Xinmei; Zha, Zheng-Jun; Wu, Feng			Real-World Image Denoising with Deep Boosting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Neural networks; Noise reduction; Image denoising; Task analysis; Image restoration; Transform coding; Computational modeling; Boosting; convolutional neural networks; image denoising; JPEG image deblocking; real-world noise	SPARSE REPRESENTATION; NONLOCAL IMAGE; FRAMEWORK; CNN	We propose a Deep Boosting Framework (DBF) for real-world image denoising by integrating the deep learning technique into the boosting algorithm. The DBF replaces conventional handcrafted boosting units by elaborate convolutional neural networks, which brings notable advantages in terms of both performance and speed. We design a lightweight Dense Dilated Fusion Network (DDFN) as an embodiment of the boosting unit, which addresses the vanishing of gradients during training due to the cascading of networks while promoting the efficiency of limited parameters. The capabilities of the proposed method are first validated on several representative simulation tasks including non-blind and blind Gaussian denoising and JPEG image deblocking. We then focus on a practical scenario to tackle with the complex and challenging real-world noise. To facilitate leaning-based methods including ours, we build a new Real-world Image Denoising (RID) dataset, which contains 200 pairs of high-resolution images with diverse scene content under various shooting conditions. Moreover, we conduct comprehensive analysis on the domain shift issue for real-world denoising and propose an effective one-shot domain transfer scheme to address this issue. Comprehensive experiments on widely used benchmarks demonstrate that the proposed method significantly surpasses existing methods on the task of real-world image denoising. Code and dataset are available at https://github.com/ngchc/deepBoosting.	[Chen, Chang; Xiong, Zhiwei; Tian, Xinmei; Zha, Zheng-Jun; Wu, Feng] Univ Sci & Technol China, Hefei 230052, Anhui, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS	Xiong, ZW (corresponding author), Univ Sci & Technol China, Hefei 230052, Anhui, Peoples R China.	changc@mail.ustc.edu.cn; zwxiong@ustc.edu.cn; xinmei@ustc.edu.cn; zhazj@ustc.edu.cn; fengwu@ustc.edu.cn			National Key R&D Program of China [2017YFA0700800]; National Natural Science Foundation of China [61671419, 61425026, 61622211, 61620106009]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was partially supported by the National Key R&D Program of China under Grant 2017YFA0700800, and the National Natural Science Foundation of China under Grants 61671419, 61425026, 61622211 and 61620106009.	Abdelhamed A, 2018, PROC CVPR IEEE, P1692, DOI 10.1109/CVPR.2018.00182; ABSoft, 2014, NEAT IM; Anaya J, 2018, J VIS COMMUN IMAGE R, V51, P144, DOI 10.1016/j.jvcir.2018.01.012; [Anonymous], 2015, ICLR; Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952; Charest MR, 2006, 2006 40TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-4, P452, DOI 10.1109/CISS.2006.286510; Chen C, 2018, LECT NOTES COMPUT SC, V11215, P3, DOI 10.1007/978-3-030-01252-6_1; Chen GY, 2015, IEEE I CONF COMP VIS, P477, DOI 10.1109/ICCV.2015.62; Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333; Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743; Dabov K, 2007, IEEE IMAGE PROC, P313, DOI 10.1109/icip.2007.4378954; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729; Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hong J, 2016, INT SOC DESIGN CONF, P109, DOI 10.1109/ISOCC.2016.7799757; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kim Y, 2017, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2017.38; Kingma D.P., 2015, 3 INT C LEARN REPR I, P1, DOI DOI 10.1007/S11390-017-1754-7; Le L, 2016, 2016 3RD IEEE/ACM INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING, APPLICATIONS AND TECHNOLOGIES (BDCAT), P1, DOI 10.1145/3006299.3006312; Lebrun M, 2014, IEEE IMAGE PROC, P2674, DOI 10.1109/ICIP.2014.7025541; Lefkimmiatis S, 2018, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2018.00338; Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623; Liu D, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P842; Liu HF, 2015, PROC CVPR IEEE, P484, DOI 10.1109/CVPR.2015.7298646; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329; Nair V., 2010, P 27 INT C MACHINE L, P807, DOI DOI 10.5555/3104322.3104425; Nam S, 2016, PROC CVPR IEEE, P1683, DOI 10.1109/CVPR.2016.186; Plotz T, 2017, PROC CVPR IEEE, P2750, DOI 10.1109/CVPR.2017.294; Remez T, 2017, IEEE IMAGE PROC, P1895; Romano Y, 2015, SIAM J IMAGING SCI, V8, P1187, DOI 10.1137/140990978; Roth S, 2005, PROC CVPR IEEE, P860; Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349; Shi Z, 2018, IEEE COMPUT SOC CONF, P1052, DOI 10.1109/CVPRW.2018.00139; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; Talebi H, 2013, IEEE T IMAGE PROCESS, V22, P1468, DOI 10.1109/TIP.2012.2231691; Vemulapalli R, 2016, PROC CVPR IEEE, P4801, DOI 10.1109/CVPR.2016.519; Xiong RQ, 2016, IEEE T IMAGE PROCESS, V25, P5793, DOI 10.1109/TIP.2016.2614160; Xu, 2018, ARXIV180402603; Xu J, 2018, IEEE T IMAGE PROCESS, V27, P2996, DOI 10.1109/TIP.2018.2811546; Xu J, 2017, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2017.125; Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	61	30	30	9	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2020	42	12					3071	3087		10.1109/TPAMI.2019.2921548	http://dx.doi.org/10.1109/TPAMI.2019.2921548			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OP2KH	31180840				2022-12-18	WOS:000587912800008
J	Liu, XW; Wang, L; Zhu, XZ; Li, MM; Zhu, E; Liu, TL; Liu, L; Dou, Y; Yin, JP				Liu, Xinwang; Wang, Lei; Zhu, Xinzhong; Li, Miaomiao; Zhu, En; Liu, Tongliang; Liu, Li; Dou, Yong; Yin, Jianping			Absent Multiple Kernel Learning Algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel; Optimization; Signal processing algorithms; Clustering algorithms; Classification algorithms; Pattern analysis; Absent data learning; multiple kernel learning; max-margin classification	MATRIX; RECOGNITION; MARGIN	Multiple kernel learning (MKL) has been intensively studied during the past decade. It optimally combines the multiple channels of each sample to improve classification performance. However, existing MKL algorithms cannot effectively handle the situation where some channels of the samples are missing, which is not uncommon in practical applications. This paper proposes three absent MKL (AMKL) algorithms to address this issue. Different from existing approaches where missing channels are first imputed and then a standard MKL algorithm is deployed on the imputed data, our algorithms directly classify each sample based on its observed channels, without performing imputation. Specifically, we define a margin for each sample in its own relevant space, a space corresponding to the observed channels of that sample. The proposed AMKL algorithms then maximize the minimum of all sample-based margins, and this leads to a difficult optimization problem. We first provide two two-step iterative algorithms to approximately solve this problem. After that, we show that this problem can be reformulated as a convex one by applying the representer theorem. This makes it readily be solved via existing convex optimization packages. In addition, we provide a generalization error bound to justify the proposed AMKL algorithms from a theoretical perspective. Extensive experiments are conducted on nine UCI and six MKL benchmark datasets to compare the proposed algorithms with existing imputation-based methods. As demonstrated, our algorithms achieve superior performance and the improvement is more significant with the increase of missing ratio.	[Liu, Xinwang; Li, Miaomiao; Zhu, En; Dou, Yong] Natl Univ Def Technol, Coll Comp, Changsha 410073, Peoples R China; [Wang, Lei] Univ Wollongong, Sch Comp & Informat Technol, Wollongong, NSW 2522, Australia; [Zhu, Xinzhong] Zhejiang Normal Univ, Coll Math & Comp Sci, Jinhua 321004, Zhejiang, Peoples R China; [Zhu, Xinzhong] Ningbo Cixing Co Ltd, Res Inst, Ningbo 315336, Peoples R China; [Liu, Tongliang] Univ Sydney, UBTECH Sydney Artificial Intelligence Ctr, 112 Cleveland St, Darlington, NSW 2008, Australia; [Liu, Tongliang] Univ Sydney, Sch Informat Technol, Fac Engn & Informat Technol, 112 Cleveland St, Darlington, NSW 2008, Australia; [Liu, Li] Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Peoples R China; [Liu, Li] Univ Oulu, Camperdown 2006, NSW, Finland; [Yin, Jianping] Dongguan Univ Technol, Dongguan 511700, Guangdong, Peoples R China	National University of Defense Technology - China; University of Wollongong; Zhejiang Normal University; University of Sydney; University of Sydney; National University of Defense Technology - China; University of Oulu; Dongguan University of Technology	Zhu, XZ (corresponding author), Zhejiang Normal Univ, Coll Math & Comp Sci, Jinhua 321004, Zhejiang, Peoples R China.	xinwangliu@nudt.edu.cn; leiw@uow.edu.au; zxz@zjnu.edu.cn; miaomiaolinudt@gmail.com; enzhu@nudt.edu.cn; tongliang.liu@sydney.edu.au; li.liu@oulu.fi; yongdou@nudt.edu.cn; jpyin@dgut.edu.cn	LIU, Xinwang/L-8089-2019; Liu, Tongliang/AAA-1506-2021; Wang, Lei/D-9079-2013	LIU, Xinwang/0000-0001-9066-1475; Liu, Tongliang/0000-0002-9640-6472; Wang, Lei/0000-0002-0961-0441; Liu, li/0000-0002-2011-2873; Li, Miaomiao/0000-0001-7678-687X	National Key R&D Program of China [2018YFB1003203]; Natural Science Foundation of China [61701451, 61672528]	National Key R&D Program of China; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by National Key R&D Program of China 2018YFB1003203, and the Natural Science Foundation of China (project no. 61701451 and 61672528). The authors wish to gratefully acknowledge Prof. Huiying Xu from Zhejiang Normal University for her help in the proofreading of this paper. Xinzhong Zhu, Xinwang Liu and Lei Wang equally contribute to the paper.	[Anonymous], 2010, ADV NEURAL INFORM PR; [Anonymous], 2012, CVX MATL SOFTW DISC; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7; Bach F.R., 2004, P 21 INT C MACH LEAR, P6, DOI DOI 10.1145/1015330.1015424; Bucak SS, 2014, IEEE T PATTERN ANAL, V36, P1354, DOI 10.1109/TPAMI.2013.212; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061; Chechik G, 2008, J MACH LEARN RES, V9, P1; Cortes C., 2009, P INT C NEUR INF PRO, V22, P396; Cortes C., 2013, ADV NEURAL INFORM PR, P2760; Cortes C., 2010, ICML, P239; Cortes C, 2012, J MACH LEARN RES, V13, P795; Damoulas T, 2008, BIOINFORMATICS, V24, P1264, DOI 10.1093/bioinformatics/btn112; Dekel O., 2008, P INT C MACH LEARN, P216; Do H, 2009, LECT NOTES ARTIF INT, V5781, P330; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Ghahramani Z., 1993, ADV NEURAL INFORM PR, P120; Gonen M, 2014, IEEE T PATTERN ANAL, V36, P2047, DOI 10.1109/TPAMI.2014.2313125; Gonen M, 2012, P 29 INT COF INT C M, P91; Gonen M, 2014, ADV NEUR IN, V27; Gong BQ, 2014, INT J COMPUT VISION, V109, P3, DOI 10.1007/s11263-014-0718-4; Gu┬nen M., 2008, P 25 INT C MACH LEAR, P352, DOI DOI 10.1145/1390156.1390201; Jain RK, 2012, RIVER FLOW 2012, VOLS 1 AND 2, P1331; Kembhavi A, 2009, IEEE I CONF COMP VIS, P638, DOI 10.1109/ICCV.2009.5459179; Kloft M, 2011, J MACH LEARN RES, V12, P953; Kloft M, 2010, LECT NOTES ARTIF INT, V6322, P66, DOI 10.1007/978-3-642-15883-4_5; Lampert CH, 2008, FOUND TRENDS COMPUT, V4, P193, DOI 10.1561/0600000027; Lin YY, 2011, IEEE T PATTERN ANAL, V33, P1147, DOI 10.1109/TPAMI.2010.183; Liu XW, 2015, AAAI CONF ARTIF INTE, P2807; Liu XW, 2016, AAAI CONF ARTIF INTE, P1888; Liu XW, 2014, AAAI CONF ARTIF INTE, P1975; Liu XW, 2013, IEEE T CYBERNETICS, V43, P557, DOI 10.1109/TSMCB.2012.2212243; Marlin B.M., 2008, THESIS; Micchelli CA, 2005, J MACH LEARN RES, V6, P1099; Nilsback M-E., 2006, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2006., DOI 10.1109/CVPR.2006.42]; Nunez AA, 2013, ADV IND CONTROL, P45, DOI 10.1007/978-1-4471-4351-2_3; Orabona Francesco, 2011, P 28 INT C MACH LEAR, P249; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416, DOI 10.1007/3-540-44581-1_27; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Smola AJ, 2005, P 10 INT WORKSH ART, P325; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Subrahmanya N, 2010, IEEE T PATTERN ANAL, V32, P788, DOI 10.1109/TPAMI.2009.98; Xia H, 2014, IEEE T PATTERN ANAL, V36, P536, DOI 10.1109/TPAMI.2013.149; Xu XX, 2015, IEEE T NEUR NET LEAR, V26, P3150, DOI 10.1109/TNNLS.2015.2405574; Xu Z., 2010, P 27 INT C MACHINE L, P1175; Xu Z., 2008, ADV NEURAL INFORM PR, V21, P1825; Yan F, 2012, J MACH LEARN RES, V13, P607; Yang HQ, 2011, IEEE T NEURAL NETWOR, V22, P433, DOI 10.1109/TNN.2010.2103571; Ye JP, 2008, J MACH LEARN RES, V9, P719; Yu S, 2012, IEEE T PATTERN ANAL, V34, P1031, DOI 10.1109/TPAMI.2011.255; Yuan Lei, 2012, KDD, P1149; Yuan L, 2012, NEUROIMAGE, V61, P622, DOI 10.1016/j.neuroimage.2012.03.059; Zien A., 2007, P 24 INT C MACH LEAR, V1, P1191, DOI DOI 10.1145/1273496.1273646	55	30	33	4	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1303	1316		10.1109/TPAMI.2019.2895608	http://dx.doi.org/10.1109/TPAMI.2019.2895608			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30703009	Green Accepted			2022-12-18	WOS:000535615700002
J	Luo, WH; Sun, P; Zhong, FW; Liu, W; Zhang, T; Wang, YZ				Luo, Wenhan; Sun, Peng; Zhong, Fangwei; Liu, Wei; Zhang, Tong; Wang, Yizhou			End-to-End Active Object Tracking and Its Real-World Deployment via Reinforcement Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object tracking; Cameras; Target tracking; Reinforcement learning; Robot vision systems; Active object tracking; reinforcement learning; environment augmentation	VISUAL TRACKING; NETWORKS	We study active object tracking, where a tracker takes visual observations (i.e., frame sequences) as input and produces the corresponding camera control signals as output (e.g., move forward, turn left, etc.). Conventional methods tackle tracking and camera control tasks separately, and the resulting system is difficult to tune jointly. These methods also require significant human efforts for image labeling and expensive trial-and-error system tuning in the real world. To address these issues, we propose, in this paper, an end-to-end solution via deep reinforcement learning. A ConvNet-LSTM function approximator is adopted for the direct frame-to-action prediction. We further propose an environment augmentation technique and a customized reward function, which are crucial for successful training. The tracker trained in simulators (ViZDoom and Unreal Engine) demonstrates good generalization behaviors in the case of unseen object moving paths, unseen object appearances, unseen backgrounds, and distracting objects. The system is robust and can restore tracking after occasional lost of the target being tracked. We also find that the tracking ability, obtained solely from simulators, can potentially transfer to real-world scenarios. We demonstrate successful examples of such transfer, via experiments over the VOT dataset and the deployment of a real-world robot using the proposed active tracker trained in simulation.	[Luo, Wenhan; Sun, Peng; Liu, Wei; Zhang, Tong] Tencent AI Lab, Shenzhen 518057, Peoples R China; [Zhong, Fangwei; Wang, Yizhou] Peking Univ, Natl Engn Lab Video Technol, Key Lab Machine Percept MoE, Comp Sci Dept, Beijing 100871, Peoples R China; [Zhong, Fangwei; Wang, Yizhou] Peng Cheng Lab, Cooperat Medianet Innovat Ctr, Shenzhen, Peoples R China	Tencent; Peking University; Peng Cheng Laboratory	Luo, WH (corresponding author), Tencent AI Lab, Shenzhen 518057, Peoples R China.	whluo.china@gmail.com; pengsun000@gmail.com; zfw@pku.edu.cn; wl2223@columbia.edu; tongzhang@tongzhang-ml.org; Yizhou.Wang@pku.edu.cn	Zhong, Fangwei/ABC-7632-2020; Luo, Wenhan/GZL-0535-2022; Zhang, Tong/HGC-1090-2022	Liu, Wei/0000-0002-3865-8145; Zhong, Fangwei/0000-0002-0428-4552	Tencent AI Lab Rhino-Bird Focused Research Program [JR201851]; Qualcomm University Collaborative Research Program;  [NSFC-61625201];  [NSFC61527804]	Tencent AI Lab Rhino-Bird Focused Research Program; Qualcomm University Collaborative Research Program; ; 	The authors would like to thank Jia Xu for his helpful discussion, Tingyun Yan for his help in building virtual environment, and Chao Zhang for setting up the robot in our early work. Fangwei Zhong and Yizhou Wang were supported in part by the following grants: NSFC-61625201, NSFC61527804, Tencent AI Lab Rhino-Bird Focused Research Program No.JR201851, Qualcomm University Collaborative Research Program. Wenhan Luo, Peng Sun, and Fangwei Zhong contributed equally to this work.	Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; Brockman G., 2016, OPENAI GYM; Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Choi J, 2018, COMPUT VIS IMAGE UND, V171, P10, DOI 10.1016/j.cviu.2018.05.009; Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Cui Z, 2016, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2016.161; Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733; Danelljan Martin, 2014, BRIT MACH VIS C NOTT; DAS S, 2018, ADV COMPUTATIONAL CO, P293, DOI DOI 10.1109/ISVLSI.2018.00061; Deneme S, 2017, ADV HIGH ED PROF DEV, P1, DOI 10.4018/978-1-5225-1747-4.ch001; DENZLER J, 1994, IEEE IMAGE PROC, P635, DOI 10.1109/ICIP.1994.413812; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hong ZW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4912; Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42; Huang C, 2017, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2017.21; James S., 2017, C ROB LEARN CORL; Jie ZQ, 2016, ADV NEUR IN, V29; John Christopher, 1989, THESIS; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kim KK, 2005, 7TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P817; Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kylberg G., 2011, BLUE SERIES, V35; Levine S, 2016, J MACH LEARN RES, V17; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luo WH, 2018, PR MACH LEARN RES, V80; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292; Mnih V, 2016, PR MACH LEARN RES, V48; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; MURRAY D, 1994, IEEE T PATTERN ANAL, V16, P449, DOI 10.1109/34.291452; NAM H, 2016, PROC CVPR IEEE, P4293, DOI DOI 10.1109/CVPR.2016.465; Peng XB, 2018, IEEE INT CONF ROBOT, P3803, DOI 10.1109/ICCABS.2018.8541936; Qiu WC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1221, DOI 10.1145/3123266.3129396; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Sadeghi F., 2017, ROBOTICS SCI SYSTEMS, V12, P1; Sadeghi F, 2018, PROC CVPR IEEE, P4691, DOI 10.1109/CVPR.2018.00493; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Supancic J, 2017, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2017.43; Sutton R.S., 1998, INTRO REINFORCEMENT, DOI [10.1109/TNN.1998.712192, DOI 10.1109/TNN.1998.712192]; Sutton RS, 2000, ADV NEUR IN, V12, P1057; Tobin J, 2017, IEEE INT C INT ROBOT, P23; Torkaman B., 2012, 2012 20th Iranian Conference on Electrical Engineering (ICEE 2012), P928, DOI 10.1109/IranianCEE.2012.6292486; Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531; Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153; Wang N, 2013, ADV NEURAL INFORM PR, DOI DOI 10.5555/2999611.2999702; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Wu Y., 2017, P IEEE INT C LEARN R; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Wydmuch M., 2016, ARXIV160502097, P1, DOI DOI 10.1109/CIG.2016.7860433; Xing J., 2014, ARXIV PREPRINT ARXIV; Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148; Zhong F., 2017, GYM UNREALCV REALIST; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009; Zhou XS, 2003, DIGITAL MEDIA: PROCESSING MULTIMEDIA INTERACTIVE SERVICES, P1, DOI 10.1142/9789812704337_0001; Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108	65	30	30	18	81	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1317	1332		10.1109/TPAMI.2019.2899570	http://dx.doi.org/10.1109/TPAMI.2019.2899570			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30762532	Green Submitted			2022-12-18	WOS:000535615700003
J	Liu, F; Zhao, QJ; Liu, XM; Zeng, D				Liu, Feng; Zhao, Qijun; Liu, Xiaoming; Zeng, Dan			Joint Face Alignment and 3D Face Reconstruction with Application to Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Three-dimensional displays; Two dimensional displays; Shape; Image reconstruction; Face recognition; Solid modeling; 3D face reconstruction; face alignment; cascaded regression; pose and expression normalization; face recognition	SHAPE; REGISTRATION; MODEL	Face alignment and 3D face reconstruction are traditionally accomplished as separated tasks. By exploring the strong correlation between 2D landmarks and 3D shapes, in contrast, we propose a joint face alignment and 3D face reconstruction method to simultaneously solve these two problems for 2D face images of arbitrary poses and expressions. This method, based on a summation model of 3D faces and cascaded regression in 2D and 3D shape spaces, iteratively and alternately applies two cascaded regressors, one for updating 2D landmarks and the other for 3D shape. The 3D shape and the landmarks are correlated via a 3D-to-2D mapping matrix, which is updated in each iteration to refine the location and visibility of 2D landmarks. Unlike existing methods, the proposed method can fully automatically generate both pose-and-expression-normalized (PEN) and expressive 3D faces and localize both visible and invisible 2D landmarks. Based on the PEN 3D faces, we devise a method to enhance face recognition accuracy across poses and expressions. Both linear and nonlinear implementations of the proposed method are presented and evaluated in this paper. Extensive experiments show that the proposed method can achieve the state-of-the-art accuracy in both face alignment and 3D face reconstruction, and benefit face recognition owing to its reconstructed PEN 3D face.	[Liu, Feng; Zhao, Qijun; Zeng, Dan] Sichuan Univ, Coll Comp Sci, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610065, Sichuan, Peoples R China; [Liu, Xiaoming] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Sichuan University; Michigan State University	Zhao, QJ (corresponding author), Sichuan Univ, Coll Comp Sci, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610065, Sichuan, Peoples R China.	liuf1989@yeah.net; qjzhao@scu.edu.cn; liuxm@cse.msu.edu; zengdan_scu@126.com	Zeng, Dan/M-4615-2019	Zeng, Dan/0000-0002-9036-7791	National Key Research and Development Program of China [2017YFB0802300]; National Natural Science Foundation of China [61773270]; National Key Scientific Instrument and Equipment Development Projects of China [2013YQ49087904]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Scientific Instrument and Equipment Development Projects of China	The authors would like to thank the authors of LDF-Net for sharing us with the match scores of LDF-Net on Multi-PIE. This work is supported by the National Key Research and Development Program of China (2017YFB0802300), the National Natural Science Foundation of China (61773270), and the National Key Scientific Instrument and Equipment Development Projects of China (2013YQ49087904).	Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606; [Anonymous], 2016, AS C COMP VIS WORKSH, P377; Bagdanov Andrew D, 2011, P 2011 JOINT ACM WOR, P79, DOI DOI 10.1145/2072572.2072597; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Bolkart T, 2015, COMPUT VIS IMAGE UND, V131, P100, DOI 10.1016/j.cviu.2014.06.013; Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925873; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Cao Chen, 2013, ACM T GRAPHIC, V32, P4; Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chu B, 2014, PROC CVPR IEEE, P1907, DOI 10.1109/CVPR.2014.245; Cootes T., 1994, P BRIT MACH VIS C, V1, P327; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cristinacce D., 2007, BMVC, P1; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Guler RA, 2017, PROC CVPR IEEE, P2614, DOI 10.1109/CVPR.2017.280; Hu GS, 2017, PATTERN RECOGN, V67, P366, DOI 10.1016/j.patcog.2017.02.007; Hu Han, 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P223, DOI 10.1109/BTAS.2012.6374581; Hu LQ, 2017, IEEE INT CONF AUTOMA, P9, DOI 10.1109/FG.2017.12; Jeni Laszlo A., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163142; Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347; Jourabloo A, 2017, INT J COMPUT VISION, V124, P187, DOI 10.1007/s11263-017-1012-z; Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454; Jourabloo A, 2015, IEEE I CONF COMP VIS, P3694, DOI 10.1109/ICCV.2015.421; Kasabov N, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P15, DOI 10.1109/IS.2016.7737434; Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241; Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Kowalski M, 2017, IEEE COMPUT SOC CONF, P2034, DOI 10.1109/CVPRW.2017.254; Lee Ye-Ming, 2012, Evid Based Complement Alternat Med, V2012, P852362, DOI 10.1155/2012/852362; Lei Z, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4563043; Liu F, 2017, FRONT INFORM TECH EL, V18, P1978, DOI 10.1631/FITEE.1700253; Liu F, 2016, LECT NOTES COMPUT SC, V9909, P545, DOI 10.1007/978-3-319-46454-1_33; Liu XM, 2009, IEEE T PATTERN ANAL, V31, P1941, DOI 10.1109/TPAMI.2008.238; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Messer K., 2005, P 2 INT C AUD VID BA, VVolume 964, P965; Parkhi Omkar M., 2015, BRIT MACH VIS C; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3; Phillips PJ, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870082; Phillips PJ, 2005, PROC CVPR IEEE, P947; Qu CC, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P113, DOI 10.1109/AVSS.2014.6918653; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589; Romdhani S, 2005, PROC CVPR IEEE, P986; Roth J, 2017, IEEE T PATTERN ANAL, V39, P2127, DOI 10.1109/TPAMI.2016.2636829; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sun Y, 2015, ARXIV150200873; Taha ZQ, 2006, IEEE ICC, P1071; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163; Tran L, 2019, IEEE T PATTERN ANAL, V41, P3007, DOI 10.1109/TPAMI.2018.2868350; Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141; Tulyakov S, 2015, IEEE I CONF COMP VIS, P3748, DOI 10.1109/ICCV.2015.427; Tuzel O, 2016, LECT NOTES COMPUT SC, V9909, P825, DOI 10.1007/978-3-319-46454-1_50; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454; Yin Q., 2015, NAIVE DEEP FACE RECO; Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244; Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58; Zhou XW, 2015, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2015.7299074; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679; Zhu Z., 2014, NIPS, P217	78	30	33	7	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					664	678		10.1109/TPAMI.2018.2885995	http://dx.doi.org/10.1109/TPAMI.2018.2885995			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30530314	Green Submitted			2022-12-18	WOS:000525365300011
J	Wan, F; Wei, PX; Han, ZJ; Jiao, JB; Ye, QX				Wan, Fang; Wei, Pengxu; Han, Zhenjun; Jiao, Jianbin; Ye, Qixiang			Min-Entropy Latent Model for Weakly Supervised Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weakly supervised learning; object detection; min-entropy latent model; recurrent learning	LOCALIZATION	Weakly supervised object detection is a challenging task when provided with image category supervision but required to learn, at the same time, object locations and object detectors. The inconsistency between the weak supervision and learning objectives introduces significant randomness to object locations and ambiguity to detectors. In this paper, a min-entropy latent model (MELM) is proposed for weakly supervised object detection. Min-entropy serves as a model to learn object locations and a metric to measure the randomness of object localization during learning. It aims to principally reduce the variance of learned instances and alleviate the ambiguity of detectors. MELM is decomposed into three components including proposal clique partition, object clique discovery, and object localization. MELM is optimized with a recurrent learning algorithm, which leverages continuation optimization to solve the challenging non-convexity problem. Experiments demonstrate that MELM significantly improves the performance of weakly supervised object detection, weakly supervised object localization, and image classification, against the state-of-the-art approaches.	[Wan, Fang; Han, Zhenjun; Jiao, Jianbin; Ye, Qixiang] UCAS, Sch Elect Elect & Commun Engn, Beijing 100049, Peoples R China; [Wei, Pengxu] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China	Sun Yat Sen University	Ye, QX (corresponding author), UCAS, Sch Elect Elect & Commun Engn, Beijing 100049, Peoples R China.	wanfang13@mails.ucas.ac.cn; weipengxu11@mails.ucas.ac.cn; hanzhj@ucas.ac.cn; jiaojb@ucas.ac.cn; qxye@ucas.ac.cn		Wan, Fang/0000-0002-8083-9257; ye, qi xiang/0000-0003-1215-6259; Han, Zhenjun/0000-0002-9970-5152; wei, pengxu/0000-0002-2190-0767	NSFC [61836012, 61671427, 61771447]; Beijing Municipal Science and Technology Commission [Z181100008918014]	NSFC(National Natural Science Foundation of China (NSFC)); Beijing Municipal Science and Technology Commission(Beijing Municipal Science & Technology Commission)	This work was supported in part by the NSFC under Grant 61836012, 61671427, and 61771447, and Beijing Municipal Science and Technology Commission under Grant Z181100008918014.	Aczul J., 1963, ACTA MATH ACAD SCI H, V14, P95, DOI DOI 10.1007/BF01901932; Allgower E. L., 1990, NUMERICAL CONTINUATI; Andrews S., 2002, NIPS, V2, P561; Bagherinezhad H, 2018, ARXIV180502641; Bency AJ, 2016, LECT NOTES COMPUT SC, V9905, P714, DOI 10.1007/978-3-319-46448-0_43; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bilen H, 2014, P BMVC 2014, P1997; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711; Bouchacourt D, 2015, IEEE I CONF COMP VIS, P2920, DOI 10.1109/ICCV.2015.334; Chatterjee K, 2014, LECT NOTES COMPUT SC, V8634, P1, DOI 10.1007/978-3-662-44522-8_1; Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Diba A, 2017, PROC CVPR IEEE, P5131, DOI 10.1109/CVPR.2017.545; Everingham Mark, 2010, IJCV; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gokberk Cinbis Ramazan, 2014, P IEEE INT C COMP VI, P2409; Gulcehre C., 2017, P INT C LEARN REPR; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hoffman J, 2015, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2015.7298906; Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25; Jie ZQ, 2017, PROC CVPR IEEE, P4294, DOI 10.1109/CVPR.2017.457; Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22; Karen S., 2015, ICLR 2015; Ke W, 2017, PROC CVPR IEEE, P302, DOI 10.1109/CVPR.2017.40; Kim D, 2017, IEEE I CONF COMP VIS, P3554, DOI 10.1109/ICCV.2017.382; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li Y, 2016, LECT NOTES COMPUT SC, V9906, P19, DOI 10.1007/978-3-319-46475-6_2; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4; [刘伟民 Liu Weimin], 2018, [海洋科学进展, Advances in Marine Science], V36, P1; OQUAB M, 2015, PROC CVPR IEEE, P685, DOI DOI 10.1109/CVPR.2015.7298668; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren WQ, 2016, IEEE T PATTERN ANAL, V38, P405, DOI 10.1109/TPAMI.2015.2456908; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Shi MJ, 2017, IEEE I CONF COMP VIS, P3401, DOI 10.1109/ICCV.2017.366; Shi MJ, 2016, LECT NOTES COMPUT SC, V9909, P105, DOI 10.1007/978-3-319-46454-1_7; Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381; Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261; Song HO., 2014, ADV NEURAL INFORM PR, V2, P1637; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Sun C, 2016, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2016.379; Tang P, 2018, LECT NOTES COMPUT SC, V11215, P370, DOI 10.1007/978-3-030-01252-6_22; Tang P, 2020, IEEE T PATTERN ANAL, V42, P176, DOI 10.1109/TPAMI.2018.2876304; Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wan F, 2018, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2018.00141; Wang C, 2015, IEEE T IMAGE PROCESS, V24, P1371, DOI 10.1109/TIP.2015.2396361; Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28; Wang XG, 2015, IEEE I CONF COMP VIS, P1224, DOI 10.1109/ICCV.2015.145; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wei YC, 2018, LECT NOTES COMPUT SC, V11215, P454, DOI 10.1007/978-3-030-01252-6_27; Wu JJ, 2015, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2015.7298968; Wu XZ, 2017, PR MACH LEARN RES, V70; Ye QX, 2017, PROC CVPR IEEE, P2057, DOI 10.1109/CVPR.2017.222; Zhang Y., 2010, P BRIT MACH VIS C, P1; ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319; Zhu Y, 2017, IEEE I CONF COMP VIS, P1859, DOI 10.1109/ICCV.2017.204; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	64	30	30	10	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2395	2409		10.1109/TPAMI.2019.2898858	http://dx.doi.org/10.1109/TPAMI.2019.2898858			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30762529	Green Submitted			2022-12-18	WOS:000489763000009
J	Liang, JW; Jiang, L; Cao, LL; Kalantidis, Y; Li, LJ; Hauptmann, AG				Liang, Junwei; Jiang, Lu; Cao, Liangliang; Kalantidis, Yannis; Li, Li-Jia; Hauptmann, Alexander G.			Focal Visual-Text Attention for Memex Question Answering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photo albums; question answering; vision and language; focal attention; memex		Recent insights on language and vision with neural networks have been successfully applied to simple single-image visual question answering. However, to tackle real-life question answering problems on multimedia collections such as personal photo albums, we have to look at whole collections with sequences of photos. This paper proposes a new multimodal MemexQA task: given a sequence of photos from a user, the goal is to automatically answer questions that help users recover their memory about an event captured in these photos. In addition to a text answer, a few grounding photos are also given to justify the answer. The grounding photos are necessary as they help users quickly verifying the answer. Towards solving the task, we 1) present the MemexQA dataset, the first publicly available multimodal question answering dataset consisting of real personal photo albums; 2) propose an end-to-end trainable network that makes use of a hierarchical process to dynamically determine what media and what time to focus on in the sequential data to answer the question. Experimental results on the MemexQA dataset demonstrate that our model outperforms strong baselines and yields the most relevant grounding photos on this challenging task.	[Liang, Junwei; Hauptmann, Alexander G.] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Jiang, Lu; Li, Li-Jia] Google AI, Mountain View, CA 94043 USA; [Cao, Liangliang] Univ Massachusetts, Amherst, MA 01003 USA; [Kalantidis, Yannis] Facebook Res, Menlo Pk, CA 94025 USA	Carnegie Mellon University; University of Massachusetts System; University of Massachusetts Amherst; Facebook Inc	Jiang, L (corresponding author), Google AI, Mountain View, CA 94043 USA.	junweil@cs.cmu.edu; lujiang@google.com; llcao@cs.umass.edu; yannisk@fb.com; lijiali@google.com; alex@cs.cmu.edu	Liang, Junwei/AAC-2513-2019	Liang, Junwei/0000-0003-2219-5569; Jiang, Lu/0000-0003-0286-8439; Li, Jia/0000-0001-5850-7013	Yahoo InMind project; Flickr Computer Vision and Machine Learning group; U.S. Department of Commerce, National Institute of Standards and Technology (NIST) [60NANB17D156]; Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DOI/IBC) [D17PC00340]	Yahoo InMind project; Flickr Computer Vision and Machine Learning group; U.S. Department of Commerce, National Institute of Standards and Technology (NIST)(National Institute of Standards & Technology (NIST) - USA); Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DOI/IBC)	We would like to thank anonymous reviewers as well as our colleagues Yale Song and Sachin Farfade for their useful comments and suggestions. Google Cloud provided GCP research credits for computation. This work was partially supported by Yahoo InMind project and Flickr Computer Vision and Machine Learning group. Yannis' work was performed while he was at Yahoo Research. This work was partially supported by the financial assistance award 60NANB17D156 from U.S. Department of Commerce, National Institute of Standards and Technology (NIST). This work was also supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DOI/IBC) contract number D17PC00340. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation/herein. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, NIST, DOI/IBC, or the U.S. Government.	Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285; Bush V., 1945, ATLANTIC MONTHLY, V176, P101, DOI DOI 10.1145/227181.227186; Cao Liangliang, 2008, P 16 ACM INT C MULT, P121, DOI DOI 10.1145/1459359.1459376; Cao L, 2008, CONSUM COMM NETWORK, P13, DOI 10.1109/ccnc08.2007.9; Cui JY, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P367; Das A, 2018, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2018.00008; Das A, 2017, COMPUT VIS IMAGE UND, V163, P90, DOI 10.1016/j.cviu.2017.10.001; Davies S, 2011, COMMUN ACM, V54, P80, DOI 10.1145/1897816.1897840; Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637; Fukui Akira, 2016, ARXIV160601847; Gao H., 2015, ADV NEURAL INFORM PR, V28, P2296, DOI DOI 10.1145/2733373.2807418; Gordon D, 2018, PROC CVPR IEEE, P4089, DOI 10.1109/CVPR.2018.00430; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Gurari D, 2018, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR.2018.00380; Hermann KM, 2015, ADV NEUR IN, V28; Huang Ting-Hao Kenneth, 2016, P 2016 C N AM CHAPT, P1233, DOI DOI 10.18653/V1/N16-1147; Jang Y, 2017, PROC CVPR IEEE, P1359, DOI 10.1109/CVPR.2017.149; Jiang L., 2017, CORR; Jiang L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P801, DOI 10.1145/3018661.3018736; Jiang L, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P27, DOI 10.1145/2671188.2749399; Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215; Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592; Kafle K, 2017, IEEE I CONF COMP VIS, P1983, DOI 10.1109/ICCV.2017.217; Kim KM, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2016; Kim Y., 2014, P 2014 C EMP METH NA; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Li HX, 2016, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2016.145; Li Y, 2017, PROC CVPR IEEE, P5660, DOI 10.1109/CVPR.2017.600; Liang JW, 2018, PROC CVPR IEEE, P6135, DOI 10.1109/CVPR.2018.00642; Lin DH, 2010, LECT NOTES COMPUT SC, V6311, P243; Liu Dong, 2009, P ACM INT C MULT MM, P809; Liu F, 2018, PROC CVPR IEEE, P8611, DOI 10.1109/CVPR.2018.00898; Lu JH, 2016, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING TECHNOLOGY (CSET2015), MEDICAL SCIENCE AND BIOLOGICAL ENGINEERING (MSBE2015), P289; Malinowski M., 2014, ADV NEURAL INFORM PR, V27, P1682; Miech A., 2018, CORR; Na S, 2017, IEEE I CONF COMP VIS, P677, DOI 10.1109/ICCV.2017.80; Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232; Patro B, 2018, PROC CVPR IEEE, P7680, DOI 10.1109/CVPR.2018.00801; Pennington J, 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/d14-1162, DOI 10.3115/V1/D14-1162, 10.3115/v1/D14-1162]; Rajpurkar P., 2016, CORR, P2383, DOI [10.18653/v1/D16-1264, DOI 10.18653/V1/D16-1264]; Ren M., 2015, P 28 INT C NEUR INF, V2, P2953, DOI [10.5555/2969442.2969570, DOI 10.5555/2969442.2969570]; Seo M. J., 2016, CORR; Shen YL, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1047, DOI 10.1145/3097983.3098177; Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501; Wang P., 2016, CORR; Wang Shuohang, 2016, CORR; Xiong CM, 2016, PR MACH LEARN RES, V48; Xu DJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1645, DOI 10.1145/3123266.3123427; Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28; Yang H, 2003, IEEE RAD FREQ INTEGR, P663, DOI 10.1109/RFIC.2003.1214034; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yu LC, 2015, IEEE I CONF COMP VIS, P2461, DOI 10.1109/ICCV.2015.283; Zeiler Matthew D., 2012, CORR; Zhao M, 2006, LECT NOTES COMPUT SC, V4071, P163; Zhi CH, 2011, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2011.5995680; Zhu LC, 2017, INT J COMPUT VISION, V124, P409, DOI 10.1007/s11263-017-1033-7; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540	63	30	32	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1893	1908		10.1109/TPAMI.2018.2890628	http://dx.doi.org/10.1109/TPAMI.2018.2890628			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30624212	hybrid, Green Submitted			2022-12-18	WOS:000473598800008
J	Wang, T; Ling, HB; Lang, CY; Feng, SH				Wang, Tao; Ling, Haibin; Lang, Congyan; Feng, Songhe			Graph Matching with Adaptive and Branching Path Following	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph matching; path following; singular point; branch switching; adaptive path estimation	COMPUTATION; ALGORITHM; MODELS	Graph matching aims at establishing correspondences between graph elements, and is widely used in many computer vision tasks. Among recently proposed graph matching algorithms, those utilizing the path following strategy have attracted special research attentions due to their exhibition of state-of-the-art performances. However, the paths computed in these algorithms often contain singular points, which could hurt the matching performance if not dealt properly. To deal with this issue, we propose a novel path following strategy, named branching path following (BPF), to improve graph matching accuracy. In particular, we first propose a singular point detector by solving a KKTsystem, and then design a branch switching method to seek for better paths at singular points. Moreover, to reduce the computational burden of the BPF strategy, an adaptive path estimation (APE) strategy is integrated into BPF to accelerate the convergence of searching along each path. A new graph matching algorithm named ABPF-G is developed by applying APE and BPF to a recently proposed path following algorithm named GNCCP (Liu & Qiao 2014). Experimental results reveal how our approach consistently outperforms state-of-the-art algorithms for graph matching on five public benchmark datasets.	[Wang, Tao; Lang, Congyan; Feng, Songhe] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China; [Ling, Haibin] Temple Univ, Comp & Informat Sci Dept, Philadelphia, PA 19122 USA; [Ling, Haibin] HiScene Informat Technol, Shanghai 201210, Peoples R China	Beijing Jiaotong University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Ling, HB (corresponding author), Temple Univ, Comp & Informat Sci Dept, Philadelphia, PA 19122 USA.; Ling, HB (corresponding author), HiScene Informat Technol, Shanghai 201210, Peoples R China.	twang@bjtu.edu.cn; hbling@temple.edu; cylang@bjtu.edu.cn; shfeng@bjtu.edu.cn		Ling, Haibin/0000-0003-4094-8413	China National Key Research and Development Plan [2016YFB1001200]; National Nature Science Foundation of China [61673048, 61672088, 61671048, 61472028]; Fundamental Research Funds for the Central universities [2017JBZ108]; US National Science Foundation [1618398, 1449860, 1350521]	China National Key Research and Development Plan; National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central universities(Fundamental Research Funds for the Central Universities); US National Science Foundation(National Science Foundation (NSF))	This work is supported by the China National Key Research and Development Plan (Grant No. 2016YFB1001200), National Nature Science Foundation of China (nos. 61673048, 61672088, 61671048 and 61472028), the Fundamental Research Funds for the Central universities (2017JBZ108), and in part by US National Science Foundation Grants 1618398, 1449860 and 1350521.	Adamczewski K, 2015, IEEE I CONF COMP VIS, P109, DOI 10.1109/ICCV.2015.21; Albarelli A, 2009, IEEE I CONF COMP VIS, P1319, DOI 10.1109/ICCV.2009.5459312; Allgower E. L., 1990, NUMERICAL CONTINUATI; ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474; Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85; Branch MA, 1999, SIAM J SCI COMPUT, V21, P1, DOI 10.1137/S1064827595289108; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; Cai ZW, 2014, IEEE T IMAGE PROCESS, V23, P5497, DOI 10.1109/TIP.2014.2364919; Chen C, 2012, IEEE POSITION LOCAT, P1274, DOI 10.1109/PLANS.2012.6236984; Cho MS, 2013, IEEE I CONF COMP VIS, P25, DOI 10.1109/ICCV.2013.11; Cho M, 2009, IEEE I CONF COMP VIS, P1280, DOI 10.1109/ICCV.2009.5459322; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cour Timothee, 2006, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0044; Dankowicz H, 2011, J COMPUT NONLIN DYN, V6, DOI 10.1115/1.4002684; Deuflhard P, 2006, NEWTON METHODS NONLI; Dickson KI, 2007, SIAM J NUMER ANAL, V45, P263, DOI 10.1137/060654384; Donoser M., 2006, 2006 IEEE COMPUTER S, V1, P553, DOI DOI 10.1109/CVPR.2006.107; Duchenne O, 2009, PROC CVPR IEEE, P1980, DOI 10.1109/CVPRW.2009.5206619; Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51; Everingham M., 2007, PASCAL VISUAL OBJECT, DOI DOI 10.1007/S11263-014-0733-5; Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Jiang B, 2017, PATTERN RECOGN, V61, P255, DOI 10.1016/j.patcog.2016.07.021; Jiang XY, 1999, PATTERN RECOGN, V32, P1273, DOI 10.1016/S0031-3203(98)00145-9; Justice D, 2006, IEEE T PATTERN ANAL, V28, P1200, DOI 10.1109/TPAMI.2006.152; Keller H.B., 1987, LECT NUMERICAL METHO; Kudryavtsev L. D., 2001, ENCY MATH; Kuhn H., 1951, P 2 BERK S MATH STAT, P481, DOI DOI 10.1007/BF01582292; LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M, 2012, INT J COMPUT VISION, V96, P28, DOI 10.1007/s11263-011-0442-2; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Liu ZY, 2014, INT J COMPUT VISION, V109, P169, DOI 10.1007/s11263-014-0707-7; Liu ZY, 2014, IEEE T PATTERN ANAL, V36, P1258, DOI 10.1109/TPAMI.2013.223; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu Y, 2016, PATTERN RECOGN, V60, P971, DOI 10.1016/j.patcog.2016.07.015; Lyzinski V, 2016, IEEE T PATTERN ANAL, V38, P60, DOI 10.1109/TPAMI.2015.2424894; Michel D, 2011, IMAGE VISION COMPUT, V29, P459, DOI 10.1016/j.imavis.2011.01.008; Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9; Riesen K, 2009, IMAGE VISION COMPUT, V27, P950, DOI 10.1016/j.imavis.2008.04.004; Rodola E, 2012, PROC CVPR IEEE, P182, DOI 10.1109/CVPR.2012.6247674; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; Serradell E, 2015, IEEE T PATTERN ANAL, V37, P625, DOI 10.1109/TPAMI.2014.2343235; Serratosa F, 2014, PATTERN RECOGN LETT, V45, P244, DOI 10.1016/j.patrec.2014.04.015; SHACHAM M, 1986, INT J NUMER METH ENG, V23, P1455, DOI 10.1002/nme.1620230805; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; Wang JQ, 2012, PROCEEDINGS OF THE 8TH EURO-ASIA CONFERENCE ON ENVIRONMENT AND CSR: TOURISM, MICE, HOSPITALITY MANAGEMENT AND EDUCATION SESSION, PT III, P179; Wang T, 2016, AAAI CONF ARTIF INTE, P3625; Wang T, 2018, IEEE T PATTERN ANAL, V40, P1494, DOI 10.1109/TPAMI.2017.2716350; Wang T, 2016, LECT NOTES COMPUT SC, V9906, P508, DOI 10.1007/978-3-319-46475-6_32; Wang T, 2016, PATTERN RECOGN, V60, P657, DOI 10.1016/j.patcog.2016.06.022; Wu J, 2013, PATTERN RECOGN, V46, P2927, DOI 10.1016/j.patcog.2013.04.008; Yan JC, 2015, PROC CVPR IEEE, P1520, DOI 10.1109/CVPR.2015.7298759; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zass R, 2008, PROC CVPR IEEE, P1221; Zhang QS, 2015, IEEE I CONF COMP VIS, P55, DOI 10.1109/ICCV.2015.15; Zhou F, 2016, IEEE T PATTERN ANAL, V38, P1774, DOI 10.1109/TPAMI.2015.2501802; Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667	61	30	30	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2853	2867		10.1109/TPAMI.2017.2767591	http://dx.doi.org/10.1109/TPAMI.2017.2767591			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29989966	hybrid			2022-12-18	WOS:000449355500005
J	Masse, B; Ba, S; Horaud, R				Masse, Benoit; Ba, Sileye; Horaud, Radu			Tracking Gaze and Visual Focus of Attention of People Involved in Social Interaction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual focus of attention; eye gaze; head pose; dynamic Bayesian models; switching state-space models; multi-party interaction; human-robot interaction	HEAD-POSE ESTIMATION; COORDINATION	The visual focus of attention (VFOA) has been recognized as a prominent conversational cue. We are interested in estimating and tracking the VFOAs associated with multi-party social interactions. We note that in this type of situations the participants either look at each other or at an object of interest; therefore their eyes are not always visible. Consequently both we and VFOA estimation cannot be based on eye detection and tracking. We propose a method that exploits the correlation between eye gaze and head movements. Both VFOA and gaze are modeled as latent variables in a Bayesian switching state-space model (also referred switching Kalman filter). The proposed formulation leads to a tractable learning method and to an efficient online inference procedure that simultaneously tracks gaze and visual focus. The method is tested and benchmarked using two publicly available datasets, Vernissage and LAEO, that contain typical multi-party human-robot and human-human interactions.	[Masse, Benoit; Horaud, Radu] INRIA Grenoble Rhone Alpes, F-38400 Montbonnot St Martin, St Martin, France; [Masse, Benoit; Horaud, Radu] Univ Grenoble Alpes, F-38400 Montbonnot St Martin, St Martin, France; [Ba, Sileye] Dailymotion, F-75017 Paris, France	Communaute Universite Grenoble Alpes; UDICE-French Research Universities; Universite Grenoble Alpes (UGA)	Horaud, R (corresponding author), INRIA Grenoble Rhone Alpes, F-38400 Montbonnot St Martin, St Martin, France.; Horaud, R (corresponding author), Univ Grenoble Alpes, F-38400 Montbonnot St Martin, St Martin, France.	benoit.masse@inria.fr; sileye.ba@inria.fr; radu.horaud@inria.fr	Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X; Masse, Benoit/0000-0003-4111-6360	ERC Advanced Grant VHIA [340113]	ERC Advanced Grant VHIA	The authors would like to thank Vincent Drouard for his valuable expertise in head pose estimation and tracking. This work is supported by ERC Advanced Grant VHIA #340113.	Asteriadis S, 2014, INT J COMPUT VISION, V107, P293, DOI 10.1007/s11263-013-0691-3; Ba SO, 2009, IEEE T SYST MAN CY B, V39, P16, DOI 10.1109/TSMCB.2008.927274; Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159; Bishop C.M, 2006, PATTERN RECOGN; Chamveha I, 2013, COMPUT VIS IMAGE UND, V117, P1502, DOI 10.1016/j.cviu.2013.06.005; Drouard V, 2017, IEEE T IMAGE PROCESS, V26, P1428, DOI 10.1109/TIP.2017.2654165; Duffner S, 2016, IEEE T CIRC SYST VID, V26, P2264, DOI 10.1109/TCSVT.2015.2501920; Freedman EG, 2008, EXP BRAIN RES, V190, P369, DOI 10.1007/s00221-008-1504-8; Freedman EG, 1997, J NEUROPHYSIOL, V77, P2328, DOI 10.1152/jn.1997.77.5.2328; Gebru ID, 2018, IEEE T PATTERN ANAL, V40, P1086, DOI 10.1109/TPAMI.2017.2648793; Goossens HHLM, 1997, EXP BRAIN RES, V114, P542, DOI 10.1007/PL00005663; Hong AKA, 2012, 2012 WESTERN NEW YORK IMAGE PROCESSING WORKSHOP (WNYIPW), P1, DOI 10.1109/WNYIPW.2012.6466645; Jayagopi D. B., 2012, 182715 EPFL; Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239; Kurzhals K, 2017, IEEE T VIS COMPUT GR, V23, P301, DOI 10.1109/TVCG.2016.2598695; Lanillos P, 2017, INT J APPROX REASON, V87, P1, DOI 10.1016/j.ijar.2017.04.007; Li XF, 2017, IEEE-ACM T AUDIO SPE, V25, P1997, DOI 10.1109/TASLP.2017.2740001; Lovegrove S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.93; Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123; Lu F, 2014, IMAGE VISION COMPUT, V32, P169, DOI 10.1016/j.imavis.2014.01.005; Marin-Jimenez MJ, 2014, INT J COMPUT VISION, V106, P282, DOI 10.1007/s11263-013-0655-7; Masse B., 2016, P IEEE INT C MULT EX, P1; Matsumoto Y, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P2127, DOI 10.1109/IROS.2000.895285; Murphy K.P., 1998, SWITCHING KALMAN FIL; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Ohno T., 2004, P 2004 S EYE TRACKIN, V22, P115, DOI [10.1145/968363.968387, DOI 10.1145/968363.968387]; Otsuka K, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P949, DOI 10.1109/ICME.2006.262677; Qin Z, 2016, IEEE T PATTERN ANAL, V38, P2082, DOI 10.1109/TPAMI.2015.2505292; Rajagopal AK, 2014, INT J COMPUT VISION, V109, P146, DOI 10.1007/s11263-013-0692-2; Sheikhi Samira, 2012, Human Behavior Understanding. Proceedings of the Third International Workshop, HBU 2012, P99, DOI 10.1007/978-3-642-34014-7_9; Sheikhi S, 2015, PATTERN RECOGN LETT, V66, P81, DOI 10.1016/j.patrec.2014.10.002; Simon D, 2010, IET CONTROL THEORY A, V4, P1303, DOI 10.1049/iet-cta.2009.0032; Smith P, 2003, IEEE T INTELL TRANSP, V4, P205, DOI 10.1109/TITS.2003.821342; Stahl JS, 1999, EXP BRAIN RES, V126, P41, DOI 10.1007/s002210050715; Stiefelhagen R., 2002, CHI 2002 EXT ABSTR H, P858, DOI DOI 10.1145/506443.506634.; Toyama T., 2012, P 2012 ACM S EYE TRA, P91; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843; Yu LH, 2004, IEEE T BIO-MED ENG, V51, P1765, DOI 10.1109/TBME.2004.831523; Yucel Z, 2013, IEEE T CYBERNETICS, V43, P829, DOI 10.1109/TSMCB.2012.2216979; Zabulis X., 2009, P BRIT MACH VIS ASS, P1	41	30	31	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2711	2724		10.1109/TPAMI.2017.2782819	http://dx.doi.org/10.1109/TPAMI.2017.2782819			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29990014	Green Submitted			2022-12-18	WOS:000446683700014
J	Shi, ZY; Yang, YX; Hospedales, TM; Xiang, T				Shi, Zhiyuan; Yang, Yongxin; Hospedales, Timothy M.; Xiang, Tao			Weakly-Supervised Image Annotation and Segmentation with Objects and Attributes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weakly supervised learning; object-attribute association; semantic segmentation; non-parametric Bayesian model; Indian buffet process	CLASSIFICATION; LOCALIZATION; MODELS	We propose to model complex visual scenes using a non-parametric Bayesian model learned from weakly labelled images abundant on media sharing sites such as Flickr. Given weak image-level annotations of objects and attributes without locations or associations between them, our model aims to learn the appearance of object and attribute classes as well as their association on each object instance. Once learned, given an image, our model can be deployed to tackle a number of vision problems in a joint and coherent manner, including recognising objects in the scene (automatic object annotation), describing objects using their attributes (attribute prediction and association), and localising and delineating the objects (object detection and semantic segmentation). This is achieved by developing a novel Weakly Supervised Markov Random Field Stacked Indian Buffet Process (WS-MRF-SIBP) that models objects and attributes as latent factors and explicitly captures their correlations within and across superpixels. Extensive experiments on benchmark datasets demonstrate that our weakly supervised model significantly outperforms weakly supervised alternatives and is often comparable with existing strongly supervised models on a variety of tasks including semantic segmentation, automatic image annotation and retrieval based on object-attribute associations.	[Shi, Zhiyuan; Yang, Yongxin; Hospedales, Timothy M.; Xiang, Tao] Queen Mary Univ London, Dept EECS, London E1 4NS, England	University of London; Queen Mary University London	Shi, ZY (corresponding author), Queen Mary Univ London, Dept EECS, London E1 4NS, England.	z.shi@qmul.ac.uk; yongxin.yang@qmul.ac.uk; t.hospedales@qmul.ac.uk; t.xiang@qmul.ac.uk		Shi, Zhiyuan/0000-0002-7073-2245; Hospedales, Timothy/0000-0003-4867-7486				[Anonymous], P INT C LEARN REPR W; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; BERG TL, 2010, P ECCV, V6311, P663; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bishop C.M, 2006, PATTERN RECOGN; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bolei Zhou, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3441, DOI 10.1109/CVPR.2011.5995459; Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413; Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44; Chen L.-C., 2015, COMPUT SCI; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Dong J, 2014, LECT NOTES COMPUT SC, V8693, P299, DOI 10.1007/978-3-319-10602-1_20; Doshi-Velez F., 2009, UNCERTAINTY ARTIFICI, V25, P143; Doshi-Velez F., 2009, CBL2009001 U COMBR; Everingham M., PASCAL VISUAL OBJECT; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Feng ZY, 2013, IEEE I CONF COMP VIS, P1609, DOI 10.1109/ICCV.2013.203; Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128; Gould S, 2014, LECT NOTES COMPUT SC, V8689, P632, DOI 10.1007/978-3-319-10590-1_41; Griffiths TL, 2011, J MACH LEARN RES, V12, P1185; Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kovashka A, 2013, IEEE I CONF COMP VIS, P3432, DOI 10.1109/ICCV.2013.426; Kovashka A, 2011, IEEE I CONF COMP VIS, P1403, DOI 10.1109/ICCV.2011.6126395; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718; Li ZY, 2014, LECT NOTES COMPUT SC, V8694, P350, DOI 10.1007/978-3-319-10599-4_23; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Liu Y, 2013, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR.2013.270; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mahajan D, 2011, IEEE I CONF COMP VIS, P1227, DOI 10.1109/ICCV.2011.6126373; Nam Nguyen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P384, DOI 10.1109/ICDM.2010.109; Ordonez V, 2013, IEEE I CONF COMP VIS, P2768, DOI 10.1109/ICCV.2013.344; Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.1002/ACP.3140; Rasiwasia N, 2013, IEEE T PATTERN ANAL, V35, P2665, DOI 10.1109/TPAMI.2013.69; Rastegari M, 2013, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2013.425; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Rubinstein M, 2012, LECT NOTES COMPUT SC, V7574, P85, DOI 10.1007/978-3-642-33712-3_7; Russakovsky Olga, 2010, TRENDS TOPICS COMPUT, P1, DOI DOI 10.1007/978-3-642-35749-7_1; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; Scheirer WJ, 2012, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2012.6248021; Shi Z, 2013, IEEE I CONF COMP VIS, P2984, DOI 10.1109/ICCV.2013.371; Shi ZY, 2014, LECT NOTES COMPUT SC, V8690, P472, DOI 10.1007/978-3-319-10605-2_31; Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329; Singh G, 2013, PROC CVPR IEEE, P3151, DOI 10.1109/CVPR.2013.405; Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112; Tighe J, 2015, INT J COMPUT VISION, V112, P150, DOI 10.1007/s11263-014-0778-5; Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z; Turakhia N, 2013, IEEE I CONF COMP VIS, P1225, DOI 10.1109/ICCV.2013.155; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; Verbeek J., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383098; Vezhnevets A, 2012, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2012.6247757; Vezhnevets A, 2011, IEEE I CONF COMP VIS, P643, DOI 10.1109/ICCV.2011.6126299; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang G, 2009, IEEE I CONF COMP VIS, P537, DOI 10.1109/ICCV.2009.5459194; Wang S, 2013, PROC CVPR IEEE, P3111, DOI 10.1109/CVPR.2013.400; Wang XY, 2013, IEEE I CONF COMP VIS, P2120, DOI 10.1109/ICCV.2013.264; Wang YJ, 2010, PRODUCTION GRIDS IN ASIA: APPLICATIONS, DEVELOPMENTS AND GLOBAL TIES, P155, DOI 10.1007/978-1-4419-0046-3_13; Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124; Xu J, 2015, PROC CVPR IEEE, P3781, DOI 10.1109/CVPR.2015.7299002; Xu J, 2014, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2014.408; Yang JM, 2014, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2014.415; Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96; ZHAO B, 2010, P 11 EUR C COMP VIS, V6315, P785; Zheng S, 2014, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2014.411; Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002	76	30	31	4	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2525	2538		10.1109/TPAMI.2016.2645157	http://dx.doi.org/10.1109/TPAMI.2016.2645157			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28026753	Green Submitted, Green Accepted			2022-12-18	WOS:000414395400015
J	Husain, SS; Bober, M				Husain, Syed Sameed; Bober, Miroslaw			Improving Large-Scale Image Retrieval Through Robust Aggregation of Local Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual search; image retrieval; local descriptor aggregation; global descriptor		Visual search and image retrieval underpin numerous applications, however the task is still challenging predominantly due to the variability of object appearance and ever increasing size of the databases, often exceeding billions of images. Prior art methods rely on aggregation of local scale-invariant descriptors, such as SIFT, via mechanisms including Bag of Visual Words (BoW), Vector of Locally Aggregated Descriptors (VLAD) and Fisher Vectors (FV). However, their performance is still short of what is required. This paper presents a novel method for deriving a compact and distinctive representation of image content called Robust Visual Descriptor with Whitening (RVD-W). It significantly advances the state of the art and delivers world-class performance. In our approach local descriptors are rank-assigned to multiple clusters. Residual vectors are then computed in each cluster, normalized using a direction-preserving normalization function and aggregated based on the neighborhood rank. Importantly, the residual vectors are de-correlated and whitened in each cluster before aggregation, leading to a balanced energy distribution in each dimension and significantly improved performance. We also propose a new post-PCA normalization approach which improves separability between the matching and non-matching global descriptors. This new normalization benefits not only our RVD-W descriptor but also improves existing approaches based on FV and VLAD aggregation. Furthermore, we show that the aggregation framework developed using hand-crafted SIFT features also performs exceptionally well with Convolutional Neural Network (CNN) based features. The RVD-W pipeline outperforms state-of-the-art global descriptors on both the Holidays and Oxford datasets. On the large scale datasets, Holidays1M and Oxford1M, SIFT-based RVD-W representation obtains a mAP of 45.1 and 35.1 percent, while CNN-based RVD-W achieve a mAP of 63.5 and 44.8 percent, all yielding superior performance to the state-of-the-art.	[Husain, Syed Sameed; Bober, Miroslaw] Univ Surrey, Ctr Vis Speech & Signal Proc, Dept Elect Engn, Guildford GU2 7XH, Surrey, England	University of Surrey	Husain, SS (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Dept Elect Engn, Guildford GU2 7XH, Surrey, England.	sh0057@surrey.ac.uk; m.bober@surrey.ac.uk		Bober, Miroslaw/0000-0001-9484-9125	European Commission 7th Framework Programme [610691]	European Commission 7th Framework Programme(European Commission)	This research has received funding from the European Commission 7th Framework Programme under grant agreement Nr. 610691.	Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420; Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Babenko A., 2015, CORR; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bober M., 2013, MPEG STAND M VIENN A; Bober M., 2015, WO Patent, Patent No. [PCT/ GB2014/ 052,058, 2014052058]; Delhumeau Jonathan, 2013, ACM MM, P653, DOI DOI 10.1145/2502081.2502171; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Douze M., 2009, P ACM INT C IM VID R; Eggert C, 2014, IEEE IMAGE PROC, P3018, DOI 10.1109/ICIP.2014.7025610; Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Husain S, 2014, IEEE IMAGE PROC, P2799, DOI 10.1109/ICIP.2014.7025566; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Liu Z, 2016, IEEE T CIRC SYST VID, V26, P375, DOI 10.1109/TCSVT.2015.2409693; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Negrel R, 2013, IEEE MULTIMEDIA, V20, P24, DOI 10.1109/MMUL.2013.14; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009; Philbin J, 2007, CVPR; Picard D, 2011, IEEE IMAGE PROC, P669, DOI 10.1109/ICIP.2011.6116641; Razavian A.S., 2014, CORR; Simonyan K., 2015, ARXIV PREPRINT ARXIV; SIVIC J, 2006, CATEGORY LEVEL OBJEC; Sivic J., 2008, COMPUTER VISION PATT, P1, DOI 10.1109/CVPR.2008.4587635; Spyromitros-Xioufis E, 2014, IEEE T MULTIMEDIA, V16, P1713, DOI 10.1109/TMM.2014.2329648; Do TT, 2015, PROC CVPR IEEE, P3556, DOI 10.1109/CVPR.2015.7298978; Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839	34	30	34	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1783	1796		10.1109/TPAMI.2016.2613873	http://dx.doi.org/10.1109/TPAMI.2016.2613873			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	28114059	Green Submitted			2022-12-18	WOS:000406840800007
J	Punjani, A; Brubaker, MA; Fleet, DJ				Punjani, Ali; Brubaker, Marcus A.; Fleet, David J.			Building Proteins in a Day: Efficient 3D Molecular Structure Estimation with Electron Cryomicroscopy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; molecular structure; electron cryomicroscopy; single particle; importance sampling; stochastic optimization	MACROMOLECULES; SUITE	Discovering the 3D atomic-resolution structure of molecules such as proteins and viruses is one of the foremost research problems in biology and medicine. Electron Cryomicroscopy ( cryo-EM) is a promising vision-based technique for structure estimation which attempts to reconstruct 3D atomic structures from a large set of 2D transmission electron microscope images. This paper presents a new Bayesian framework for cryo-EM structure estimation that builds on modern stochastic optimization techniques to allow one to scale to very large datasets. We also introduce a novel Monte-Carlo technique that reduces the cost of evaluating the objective function during optimization by over five orders of magnitude. The net result is an approach capable of estimating 3D molecular structure from large-scale datasets in about a day on a single CPU workstation.	[Punjani, Ali; Fleet, David J.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S, Canada; [Brubaker, Marcus A.] York Univ, Elect Engn & Comp Sci, Toronto, ON M3J 1P3, Canada	University of Toronto; York University - Canada	Punjani, A (corresponding author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S, Canada.	alipunjani@cs.toronto.edu; mab@eecs.yorku.ca; fleet@cs.toronto.edu		Brubaker, Marcus/0000-0002-7892-9026; /0000-0003-0734-7114	NSERC Canada; CIFAR Learning in Machines and Brains Program; NSERC	NSERC Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); CIFAR Learning in Machines and Brains Program; NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	Financial support was provided to DJF from NSERC Canada and the CIFAR Learning in Machines and Brains Program. MAB was funded in part by an NSERC Postdoctoral Fellowship. The authors would like thank John L. Rubinstein for providing data and invaluable feedback.	Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Almen MS, 2009, BMC BIOL, V7, DOI 10.1186/1741-7007-7-50; Amari S, 2000, NEURAL COMPUT, V12, P1399, DOI 10.1162/089976600300015420; Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; [Anonymous], 2013, ICML 3; [Anonymous], 1964, COMP MATH MATH PHYS+; Baxter WT, 2009, J STRUCT BIOL, V166, P126, DOI 10.1016/j.jsb.2009.02.012; BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782; Bhotika R, 2002, LECT NOTES COMPUT SC, V2352, P112; Brubaker MA, 2015, PROC CVPR IEEE, P3099, DOI 10.1109/CVPR.2015.7298929; Callaway E, 2015, NATURE, V525, P172, DOI 10.1038/525172a; de la Rosa-Trevin JM, 2013, J STRUCT BIOL, V184, P321, DOI 10.1016/j.jsb.2013.09.015; Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038; Fleishman SJ, 2006, TRENDS BIOCHEM SCI, V31, P106, DOI 10.1016/j.tibs.2005.12.005; Graf M, 2009, NUMER FUNC ANAL OPT, V30, P665, DOI 10.1080/01630560903163508; Gregson J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185548; Grigorieff N, 2007, J STRUCT BIOL, V157, P117, DOI 10.1016/j.jsb.2006.05.004; Henderson R, 2012, STRUCTURE, V20, P205, DOI 10.1016/j.str.2011.12.014; Hsieh J., 2003, COMPUTED TOMOGRAPHY; Jaitly N, 2010, BIOINFORMATICS, V26, P2406, DOI 10.1093/bioinformatics/btq456; Keeler J, 2010, UNDERSTANDING NMR SP; Kirkland E.J., 2010, ADV COMPUTING ELECT, V2nd; Kohl H., 2008, TRANSMISSION ELECT M, V5th; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Langlois R, 2014, J STRUCT BIOL, V186, P1, DOI 10.1016/j.jsb.2014.03.001; Lau WCY, 2012, NATURE, V481, P214, DOI 10.1038/nature10699; Le Roux N., 2010, P 27 INT C MACH LEAR, P623; Le Roux N., 2012, P ADV NEUR INF PROC, P2672; Lebedev V.I., 1999, DOKL MATH, V59, P477; Li XM, 2013, NAT METHODS, V10, P584, DOI 10.1038/nmeth.2472; Mallick S, 2006, 2006 IEEE COMP SOC C, V2, P2253, DOI [10.1109/CVPR.2006.295, DOI 10.1109/CVPR.2006.295]; MALZBENDER T, 1993, ACM T GRAPHIC, V12, P233, DOI 10.1145/169711.169705; Martens J., 2010, P 27 INT C MACH LEAR, P735; Mindell JA, 2003, J STRUCT BIOL, V142, P334, DOI 10.1016/S1047-8477(03)00069-8; Nesterov Y., 1983, SOV MATH DOKL, V27, P372; Punjani A., 2014, P NEUR INF PROC SYST; ROUx N. L., 2008, ADV NEURAL INFORM PR, V20, P849; Rubinstein JL, 2003, EMBO J, V22, P6182, DOI 10.1093/emboj/cdg608; Rupp B, 2010, BIOMOLECULAR CRYSTALLOGRAPHY: PRINCIPLES, PRACTICE, AND APPLICATION TO STRUCTURAL BIOLOGY, P1; Saff EB, 1997, MATH INTELL, V19, P5, DOI 10.1007/BF03024331; Scheres SHW, 2007, NAT METHODS, V4, P27, DOI 10.1038/NMETH992; Scheres SHW, 2012, J STRUCT BIOL, V180, P519, DOI 10.1016/j.jsb.2012.09.006; Sigworth FJ, 1998, J STRUCT BIOL, V122, P328, DOI 10.1006/jsbi.1998.4014; Tang G, 2007, J STRUCT BIOL, V157, P38, DOI 10.1016/j.jsb.2006.05.009; Tokdar ST, 2010, WILEY INTERDISCIP RE, V2, P54, DOI 10.1002/wics.56; Xu ZH, 1997, NATURE, V388, P741, DOI 10.1038/41944; Zhao JH, 2013, J STRUCT BIOL, V181, P234, DOI 10.1016/j.jsb.2012.12.010	47	30	31	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					706	718		10.1109/TPAMI.2016.2627573	http://dx.doi.org/10.1109/TPAMI.2016.2627573			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	27849524				2022-12-18	WOS:000397717600008
J	Tulsiani, S; Kar, A; Carreira, J; Malik, J				Tulsiani, Shubham; Kar, Abhishek; Carreira, Joao; Malik, Jitendra			Learning Category-Specific Deformable 3D Models for Object Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object reconstruction; 3D shape modeling; viewpoint estimation; scene understanding	SHAPE	We address the problem of fully automatic object localization and reconstruction from a single image. This is both a very challenging and very important problem which has, until recently, received limited attention due to difficulties in segmenting objects and predicting their poses. Here we leverage recent advances in learning convolutional networks for object detection and segmentation and introduce a complementary network for the task of camera viewpoint prediction. These predictors are very powerful, but still not perfect given the stringent requirements of shape reconstruction. Our main contribution is a new class of deformable 3D models that can be robustly fitted to images based on noisy pose and silhouette estimates computed upstream and that can be learned directly from 2D annotations available in object detection datasets. Our models capture top-down information about the main global modes of shape variation within a class providing a "low-frequency" shape. In order to capture fine instance-specific shape details, we fuse it with a high-frequency component recovered from shading cues. A comprehensive quantitative analysis and ablation study on the PASCAL 3D+ dataset validates the approach as we show fully automatic reconstructions on PASCAL VOC as well as large improvements on the task of viewpoint prediction.	[Tulsiani, Shubham; Kar, Abhishek; Carreira, Joao; Malik, Jitendra] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA; [Carreira, Joao] Google DeepMind, London, England	University of California System; University of California Berkeley; Google Incorporated	Tulsiani, S (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.	shubhtuls@eecs.berkeley.edu; akar@eecs.berkeley.edu; joaoluis@google.com; malik@eecs.berkeley.edu			NSF [IIS-1212798]; ONR [MURI-N00014-10-1-0933]; Berkeley fellowship; Portuguese Science Foundation, FCT [SFRH/BPD/84194/2012]	NSF(National Science Foundation (NSF)); ONR(Office of Naval Research); Berkeley fellowship; Portuguese Science Foundation, FCT(Portuguese Foundation for Science and Technology)	This work was supported in part by NSF Award IIS-1212798 and ONR MURI-N00014-10-1-0933. Shubham Tulsiani was supported by the Berkeley fellowship and Joao Carreira was supported by the Portuguese Science Foundation, FCT, under grant SFRH/BPD/84194/2012. We gratefully acknowledge NVIDIA corporation for the donation of Tesla GPUs for this research. Shubham Tulsiani and Abhishek Kar contributed equally.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879; Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5; BARTOLI A, 2008, IEEE CVPR, V1, P1; Berthold K.P., 1970, TECHNICAL REPORT, P2; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Cashman TJ, 2013, IEEE T PATTERN ANAL, V35, P232, DOI 10.1109/TPAMI.2012.68; Chen Y, 2010, LECT NOTES COMPUT SC, V6313, P300; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Eigen David, 2014, NEURIPS; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168; Ghodrati A., 2014, P BMVC 2014, P1; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641; Gordon I, 2006, LECT NOTES COMPUT SC, V4170, P67; Gu CH, 2010, LECT NOTES COMPUT SC, V6315, P408; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Hejrati M., 2012, NIPS; Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232; Huang QX, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766890; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; Jia Y., 2014, P 22 ACM INT C MULT, P675; Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807; Karsch K, 2013, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2013.281; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372; Nandakumar C, 2011, PERCEPTION, V40, P257, DOI 10.1068/p6762; Nevatia R., 1977, P ART INT, P464; Ozuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633; Pepik B, 2015, LECT NOTES COMPUT SC, V9358, P517, DOI 10.1007/978-3-319-24947-6_43; Pepik B, 2012, PROC CVPR IEEE, P3362, DOI 10.1109/CVPR.2012.6248075; Prasad M, 2010, PROC CVPR IEEE, P1720, DOI 10.1109/CVPR.2010.5539840; Roberts Lawrence G, 1963, THESIS, P2; Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1; Sahilliolu Y., 2006, P MULT CONT REPR CLA, P57; Satkin S, 2015, INT J COMPUT VISION, V111, P69, DOI 10.1007/s11263-014-0734-4; Savarese S, 2008, LECT NOTES COMPUT SC, V5304, P602, DOI 10.1007/978-3-540-88690-7_45; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Su H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601159; Sung M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818094; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tulsiani S, 2015, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2015.7298758; Twarog N. R., 2012, P ACM S APPL PERC, P47; Vicente S, 2014, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2014.13; Vicente S, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P223, DOI 10.1109/3DV.2013.37; Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652; WU ZR, 2015, PROC CVPR IEEE, P1912, DOI DOI 10.1109/CVPR.2015.7298801; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Xiao J., 2012, ADV NEURAL INFORM PR, P755; Xiao JX, 2008, LECT NOTES COMPUT SC, V5304, P725, DOI 10.1007/978-3-540-88690-7_54; Zhu SQ, 2010, PROC CVPR IEEE, P1165, DOI 10.1109/CVPR.2010.5540085; Zia MZ, 2013, IEEE T PATTERN ANAL, V35, P2608, DOI 10.1109/TPAMI.2013.87	68	30	31	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					719	731		10.1109/TPAMI.2016.2574713	http://dx.doi.org/10.1109/TPAMI.2016.2574713			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	27254860	hybrid			2022-12-18	WOS:000397717600009
J	Xu, YC; Carlinet, E; Eraud, TG; Najman, L				Xu, Yongchao; Carlinet, Edwin; Eraud, Thierry G.; Najman, Laurent			Hierarchical Segmentation Using Tree-Based Shape Spaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph; shape space; tree of shapes; minimum spanning tree; alpha-tree; binary partition tree; object spotting; image segmentation; hierarchy; hierarchical segmentation; saliency map	BINARY PARTITION TREE; LEVEL LINES SELECTION; CONNECTED OPERATORS; PATTERN SPECTRA; IMAGE	Current trends in image segmentation are to compute a hierarchy of image segmentations from fine to coarse. A classical approach to obtain a single meaningful image partition from a given hierarchy is to cut it in an optimal way, following the seminal approach of the scale-set theory. While interesting in many cases, the resulting segmentation, being a non-horizontal cut, is limited by the structure of the hierarchy. In this paper, we propose a novel approach that acts by transforming an input hierarchy into a new saliency map. It relies on the notion of shape space: a graph representation of a set of regions extracted from the image. Each region is characterized with an attribute describing it. We weigh the boundaries of a subset of meaningful regions 9local minima) in the shape space by extinction values based on the attribute. This extinction-based saliency map represents a new hierarchy of segmentations highlighting regions having some specific characteristics. Each threshold of this map represents a segmentation which is generally different from any cut of the original hierarchy. This new approach thus enlarges the set of possible partition results that can be extracted from a given hierarchy. Qualitative and quantitative illustrations demonstrate the usefulness of the proposed method.	[Xu, Yongchao; Carlinet, Edwin; Eraud, Thierry G.] EPITA Res & Dev Lab LRDE, 14-16 Rue Voltaire, FR-94270 Le Kremlin Bicetre, France; [Xu, Yongchao; Carlinet, Edwin; Eraud, Thierry G.; Najman, Laurent] Univ Paris Est, Equipe A3SI, ESIEE Paris, Lab Informat Gaspard Monge, F-93160 Noisy Le Grand, France; [Xu, Yongchao] Univ Paris Saclay, CNRS, LTCI, Telecom ParisTech, F-75013 Paris, France	Universite Gustave-Eiffel; ESIEE Paris; Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; UDICE-French Research Universities; Universite Paris Cite; Universite Paris Saclay	Xu, YC (corresponding author), EPITA Res & Dev Lab LRDE, 14-16 Rue Voltaire, FR-94270 Le Kremlin Bicetre, France.; Xu, YC (corresponding author), Univ Paris Est, Equipe A3SI, ESIEE Paris, Lab Informat Gaspard Monge, F-93160 Noisy Le Grand, France.; Xu, YC (corresponding author), Univ Paris Saclay, CNRS, LTCI, Telecom ParisTech, F-75013 Paris, France.	yongchao.xu@lrde.epita.fr; edwin.carlinet@lrde.epita.fr; thierry.geraud@lrde.epita.fr; l.najman@esiee.fr	Xu, Yongchao/F-2080-2019; Najman, Laurent/AAB-4212-2020; Géraud, Thierry/AAT-8485-2020	Xu, Yongchao/0000-0002-7253-3151; Najman, Laurent/0000-0002-6190-0235; Geraud, Thierry/0000-0002-0380-7948				Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Ballester C, 2007, J MATH IMAGING VIS, V27, P5, DOI 10.1007/s10851-006-7252-0; Burie JC, 2015, PROC INT CONF DOC, P1161, DOI 10.1109/ICDAR.2015.7333943; Cao F, 2005, J MATH IMAGING VIS, V22, P159, DOI 10.1007/s10851-005-4888-0; Cardelino J, 2013, SIAM J IMAGING SCI, V6, P1274, DOI 10.1137/11086029X; Carlinet E, 2015, IEEE T IMAGE PROCESS, V24, P5330, DOI 10.1109/TIP.2015.2480599; Caselles V, 2002, J MATH IMAGING VIS, V17, P249, DOI 10.1023/A:1020715626538; Caselles V, 1999, INT J COMPUT VISION, V33, P5, DOI 10.1023/A:1008144113494; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cour T, 2005, PROC CVPR IEEE, P1124; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314; Guigues L, 2006, INT J COMPUT VISION, V68, P289, DOI 10.1007/s11263-005-6299-0; Guimaraes SJF, 2012, LECT NOTES COMPUT SC, V7626, P116, DOI 10.1007/978-3-642-34166-3_13; Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595; Houben S, 2011, IEEE INT VEH SYM, P124, DOI 10.1109/IVS.2011.5940429; KHALIMSKY E, 1990, TOPOL APPL, V36, P1, DOI 10.1016/0166-8641(90)90031-V; Kiran BR, 2014, PATTERN RECOGN, V47, P12, DOI 10.1016/j.patcog.2013.05.012; Kruskal J. B., 1956, P AM MATH SOC, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.2307/2033241]; Lu HH, 2007, IEEE T IMAGE PROCESS, V16, P1131, DOI 10.1109/TIP.2007.891802; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532; Najman Laurent, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P135, DOI 10.1007/978-3-642-38294-9_12; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Najman L, 2010, MATH MORPHOLOGY THEO; Najman L, 2011, J MATH IMAGING VIS, V40, P231, DOI 10.1007/s10851-011-0259-1; Ouzounis GK, 2011, LECT NOTES COMPUT SC, V6671, P108, DOI 10.1007/978-3-642-21569-8_10; Passat N, 2014, J MATH IMAGING VIS, V49, P37, DOI 10.1007/s10851-013-0438-3; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Perret B, 2015, LECT NOTES COMPUT SC, V9082, P39, DOI 10.1007/978-3-319-18720-4_4; Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934; Ruppert David., 2010, ELEMENTS STAT LEARNI, V99, P567, DOI 10.1007/978-0-387-84858-7; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934; Salembier P, 2009, IEEE SIGNAL PROC MAG, V26, P136, DOI 10.1109/MSP.2009.934154; Serra Jean, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P147, DOI 10.1007/978-3-642-38294-9_13; Serra Jean, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P821, DOI 10.1007/978-3-642-33275-3_101; Soille P, 2008, IEEE T PATTERN ANAL, V30, P1132, DOI 10.1109/TPAMI.2007.70817; Song YQ, 2003, MULTIMEDIA SYST, V8, P495, DOI 10.1007/s00530-002-0067-y; Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28; Vachier C., 1995, P IEEE WORKSH NONL S, P254; Vilaplana V, 2008, IEEE T IMAGE PROCESS, V17, P2201, DOI 10.1109/TIP.2008.2002841; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wilkinson M.H.F., 2001, P 4 INT C MED IM COM, V2208, P770, DOI DOI 10.1007/3-540-45468-3_92; Xia GS, 2010, INT J COMPUT VISION, V88, P382, DOI 10.1007/s11263-009-0312-3; Xu YC, 2016, IEEE T PATTERN ANAL, V38, P1126, DOI 10.1109/TPAMI.2015.2441070; Xu YC, 2015, LECT NOTES COMPUT SC, V9082, P693, DOI 10.1007/978-3-319-18720-4_58; Xu YC, 2013, IEEE IMAGE PROC, P1227, DOI 10.1109/ICIP.2013.6738253; Xu YC, 2014, IEEE T IMAGE PROCESS, V23, P5612, DOI 10.1109/TIP.2014.2364127; Xu YC, 2012, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2012.6467175; Yongchao Xu, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P390, DOI 10.1007/978-3-642-38294-9_33	56	30	33	1	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					457	469		10.1109/TPAMI.2016.2554550	http://dx.doi.org/10.1109/TPAMI.2016.2554550			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	27101599	Green Submitted			2022-12-18	WOS:000395555100004
J	Hu, WM; Gao, J; Xing, JL; Zhang, C; Maybank, S				Hu, Weiming; Gao, Jin; Xing, Junliang; Zhang, Chao; Maybank, Stephen			Semi-Supervised Tensor-Based Graph Embedding Learning and Its Application to Visual Discriminant Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Discriminant tracking; tensor samples; semi-supervised learning; graph embedding space	OBJECT TRACKING; FRAMEWORK	An appearance model adaptable to changes in object appearance is critical in visual object tracking. In this paper, we treat an image patch as a two-order tensor which preserves the original image structure. We design two graphs for characterizing the intrinsic local geometrical structure of the tensor samples of the object and the background. Graph embedding is used to reduce the dimensions of the tensors while preserving the structure of the graphs. Then, a discriminant embedding space is constructed. We prove two propositions for finding the transformation matrices which are used to map the original tensor samples to the tensor-based graph embedding space. In order to encode more discriminant information in the embedding space, we propose a transfer-learning-based semi-supervised strategy to iteratively adjust the embedding space into which discriminative information obtained from earlier times is transferred. We apply the proposed semi-supervised tensor-based graph embedding learning algorithm to visual tracking. The new tracking algorithm captures an object's appearance characteristics during tracking and uses a particle filter to estimate the optimal object state. Experimental results on the CVPR 2013 benchmark dataset demonstrate the effectiveness of the proposed tracking algorithm.	[Hu, Weiming; Gao, Jin; Xing, Junliang; Zhang, Chao] Chinese Acad Sci, CAS Ctr Excellence Brain Sci & Intelligence Techn, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Maybank, Stephen] Birkbeck Coll, Dept Comp Sci & Informat Syst, Malet St, London WC1E 7HX, England	Chinese Academy of Sciences; Institute of Automation, CAS; University of London; Birkbeck University London	Hu, WM (corresponding author), Chinese Acad Sci, CAS Ctr Excellence Brain Sci & Intelligence Techn, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.	wmhu@nlpr.ia.ac.cn; jin.gao@nlpr.ia.ac.cn; jlxing@nlpr.ia.ac.cn; 861201030@qq.com; sjmaybank@dcs.bbk.ac.uk	Gao, Jin/U-8481-2019; Xing, Junliang/HGE-9630-2022	Gao, Jin/0000-0002-8925-5215; Xing, Junliang/0000-0001-6801-0510; Zhang, Chao/0000-0002-0152-2586	973 basic research program of China [2014CB349303]; Natural Science Foundation of China [61472421, 61370185]; Strategic Priority Research Program of the CAS [XDB02070003]	973 basic research program of China(National Basic Research Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Strategic Priority Research Program of the CAS	This work is partly supported by the 973 basic research program of China (Grant No. 2014CB349303), the Natural Science Foundation of China (Grant No. 61472421, 61370185), and the Strategic Priority Research Program of the CAS (Grant No. XDB02070003).	Adam A., 2006, IEEE C COMP VIS PATT; Aliaga DG, 2007, IEEE I CONF COMP VIS, P3004; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; BAO CL, 2012, PROC CVPR IEEE, P1830, DOI DOI 10.1109/CVPR.2012.6247881; Bennett K.P., 2002, P 8 ACM SIGKDD INT C, P289; Bischof H., 2006, BMVC, P47; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Dekel S., 2013, INNOVATIONS SHAPE AN, P407; Gao J, 2013, IEEE I CONF COMP VIS, P1569, DOI 10.1109/ICCV.2013.198; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; He X, 2006, ADV NEURAL INFORM PR, P499; He XF, 2009, PROC CVPR IEEE, P65, DOI 10.1109/CVPRW.2009.5206835; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Li GR, 2011, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2011.6126297; Li P, 2011, PROCEDIA ENGINEER, V14, P1681, DOI 10.1016/j.proeng.2011.07.211; Li X, 2012, PROC CVPR IEEE, P1760, DOI 10.1109/CVPR.2012.6247872; Li X, 2011, IEEE I CONF COMP VIS, P1156, DOI 10.1109/ICCV.2011.6126364; Li XH, 2008, 2008 IEEE PHOTONICSGLOBAL@SINGAPORE (IPGC), VOLS 1 AND 2, P341; Mallapragada PK, 2009, IEEE T PATTERN ANAL, V31, P2000, DOI 10.1109/TPAMI.2008.235; Mei X, 2011, PROC CVPR IEEE, P1257; Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292; Oron S, 2015, MACH VISION APPL, V26, P507, DOI 10.1007/s00138-015-0676-z; Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6; Oron S, 2014, LECT NOTES COMPUT SC, V8693, P142, DOI 10.1007/978-3-319-10602-1_10; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pernici F, 2014, IEEE T PATTERN ANAL, V36, P2538, DOI 10.1109/TPAMI.2013.250; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Sugiyama M., 2006, P INT C MACH LEAR IC, P905, DOI DOI 10.1145/1143844.1143958; Sugiyama M, 2007, J MACH LEARN RES, V8, P1027; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Vasilescu MAO, 2004, ACM T GRAPHIC, V23, P336, DOI 10.1145/1015706.1015725; Wang Q, 2011, IEEE T SYST MAN CY B, V41, P385, DOI 10.1109/TSMCB.2010.2056366; Wen J, 2009, IEEE SYS MAN CYBERN, P3688, DOI 10.1109/ICSMC.2009.5346874; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Wu Y, 2009, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2009.5459369; Xiaoqing Li, 2007, 2007 European Conference on Power Electronics and Applications, P1; Yan S., 2007, P IEEE INT C COMP VI, P1; Ye J., 2005, ADV NEURAL INFORM PR, P1569, DOI DOI 10.5555/2976040.2976237; Ye JP, 2005, MACH LEARN, V61, P167, DOI 10.1007/s10994-005-3561-6; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zelnik-Manor Lihi, 2005, P ADV NEUR INF PROC, P1601; Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908; ZHANG TZ, 2015, PROC CVPR IEEE, P150, DOI DOI 10.1109/CVPR.2015.7298610; Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882	54	30	31	1	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					172	188		10.1109/TPAMI.2016.2539944	http://dx.doi.org/10.1109/TPAMI.2016.2539944			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26978551	Green Accepted			2022-12-18	WOS:000390421300015
J	Turetken, E; Benmansour, F; Andres, B; Glowacki, P; Pfister, H; Fua, P				Turetken, Engin; Benmansour, Fethallah; Andres, Bjoern; Glowacki, Przemyslaw; Pfister, Hanspeter; Fua, Pascal			Reconstructing Curvilinear Networks Using Path Classifiers and Integer Programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Curvilinear networks; tubular structures; curvilinear structures; automated reconstruction; integer programming; path classification; minimum arborescence	VESSEL SEGMENTATION; VISUALIZATION; MORPHOLOGY; SOFTWARE; MODELS; IMAGES	We propose a novel approach to automated delineation of curvilinear structures that form complex and potentially loopy networks. By representing the image data as a graph of potential paths, we first show how to weight these paths using discriminatively-rained classifiers that are both robust and generic enough to be applied to very different imaging modalities. We then present an Integer Programming approach to finding the optimal subset of paths, subject to structural and topological constraints that eliminate implausible solutions. Unlike earlier approaches that assume a tree topology for the networks, ours explicitly models the fact that the networks may contain loops, and can reconstruct both cyclic and acyclic ones. We demonstrate the effectiveness of our approach on a variety of challenging datasets including aerial images of road networks and micrographs of neural arbors, and show that it outperforms state-of-the-art techniques.	[Turetken, Engin; Glowacki, Przemyslaw; Fua, Pascal] Ecole Polytech Fed Lausanne, Comp Vis Lab, Lausanne, Switzerland; [Turetken, Engin] Swiss Ctr Elect & Microtechnol CSEM, Neuchatel, Switzerland; [Benmansour, Fethallah] Roche Pharma Res & Early Dev, Roche Innovat Ctr, Basel, Switzerland; [Andres, Bjoern] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Pfister, Hanspeter] Harvard Univ, Visual Comp Grp, Cambridge, MA 02138 USA	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Center for Electronics & Microtechnology (CSEM); Roche Holding; Harvard University; Harvard University	Turetken, E (corresponding author), Ecole Polytech Fed Lausanne, Comp Vis Lab, Lausanne, Switzerland.; Turetken, E (corresponding author), Swiss Ctr Elect & Microtechnol CSEM, Neuchatel, Switzerland.	engin.tueretken@alumni.epfl.ch; fethallah.benmansour@roche.com; bjoern@andres.sc; przemyslaw.glowacki@epfl.ch; pfister@seas.harvard.edu; pascal.fua@epfl.ch		Pfister, Hanspeter/0000-0002-3620-2582; Fua, Pascal/0000-0002-6702-9970	Swiss National Science Foundation (SNSF); Swiss Center for Electronics and Microtechnology (CSEM); EU ERC MicroNano Project	Swiss National Science Foundation (SNSF)(Swiss National Science Foundation (SNSF)); Swiss Center for Electronics and Microtechnology (CSEM); EU ERC MicroNano Project	This work was supported in part by a grant from the Swiss National Science Foundation (SNSF), in part by the Swiss Center for Electronics and Microtechnology (CSEM), and in part by the EU ERC MicroNano Project. The authors also wish to thank Luke Bogart, Maximilian Joesch, Karim Ali, Horesh Ben Shitrit, Verena Kaynig-Fittkau, Takao Hensch, Felix Schurmann, Markus Meister and Jeff Lichtman for generously sharing their image data and insights with them.	Al-Kofahi KA, 2002, IEEE T INF TECHNOL B, V6, P171, DOI 10.1109/TITB.2002.1006304; Ascoli G., 2010, DIGITAL RECONSTRUCTI; Bas E, 2011, NEUROINFORMATICS, V9, P181, DOI 10.1007/s12021-011-9105-2; Benmansour F, 2011, INT J COMPUT VISION, V92, P192, DOI 10.1007/s11263-010-0331-0; Cai HM, 2006, NEUROIMAGE, V32, P1608, DOI 10.1016/j.neuroimage.2006.05.036; Can A, 1999, IEEE Trans Inf Technol Biomed, V3, P125, DOI 10.1109/4233.767088; Choromanska A, 2012, FRONT NEURAL CIRCUIT, V6, DOI 10.3389/fncir.2012.00025; Chothani P, 2011, NEUROINFORMATICS, V9, P263, DOI 10.1007/s12021-011-9121-2; Cuntz H, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000877; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Domanski L., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P649, DOI 10.1109/DICTA.2010.112; Duhamel C, 2008, NETWORKS, V51, P34, DOI 10.1002/net.20194; Fan DP, 2006, THESIS; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; FISCHLER MA, 1981, COMPUT VISION GRAPH, V15, P201, DOI 10.1016/0146-664X(81)90056-3; Fraz MM, 2012, COMPUT METH PROG BIO, V108, P407, DOI 10.1016/j.cmpb.2012.03.009; Law MWK, 2008, LECT NOTES COMPUT SC, V5305, P368, DOI 10.1007/978-3-540-88693-8_27; Law MWK, 2010, LECT NOTES COMPUT SC, V6313, P720; LEE TC, 1994, CVGIP-GRAPH MODEL IM, V56, P462, DOI 10.1006/cgip.1994.1042; Li H, 2007, IEEE T MED IMAGING, V26, P1213, DOI 10.1109/TMI.2007.903696; Livet J, 2007, NATURE, V450, P56, DOI 10.1038/nature06293; Longair MH, 2011, BIOINFORMATICS, V27, P2453, DOI 10.1093/bioinformatics/btr390; Mayerich D, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-S8-S7; Mukherjee A., 2012, P SOC PHOTO-OPT INS, V8314; Myatt DR, 2012, FRONT NEUROINFORM, V6, DOI 10.3389/fninf.2012.00004; Narayanaswamy A, 2011, NEUROINFORMATICS, V9, P219, DOI 10.1007/s12021-011-9116-z; Palagyi K, 1998, PATTERN RECOGN LETT, V19, P613, DOI 10.1016/S0167-8655(98)00031-2; Peng HC, 2011, BIOINFORMATICS, V27, pI239, DOI 10.1093/bioinformatics/btr237; Peng HC, 2011, NEUROINFORMATICS, V9, P103, DOI 10.1007/s12021-010-9090-x; Peng HC, 2010, NAT BIOTECHNOL, V28, P348, DOI 10.1038/nbt.1612; Pool M, 2008, J NEUROSCI METH, V168, P134, DOI 10.1016/j.jneumeth.2007.08.029; Sethian J. A., 1999, LEVEL SET METHODS FA; Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627; Stutzle T, 2004, ANT COLONY OPTIMIZAT; Sun KQ, 2007, LECT NOTES COMPUT SC, V4679, P467; Tempel E., 2014, MON NOT R ASTRON SOC, V438, P407; Turetken E, 2013, IEEE I CONF COMP VIS, P1553, DOI 10.1109/ICCV.2013.196; Turetken E, 2013, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2013.238; Turetken E, 2012, PROC CVPR IEEE, P566, DOI 10.1109/CVPR.2012.6247722; Turetken E, 2011, NEUROINFORMATICS, V9, P279, DOI 10.1007/s12021-011-9122-1; Turetken E., 2013, 182839 EPFL; Vasilkoski Z, 2009, J NEUROSCI METH, V178, P197, DOI 10.1016/j.jneumeth.2008.11.008; Wang Y, 2011, PROC CVPR IEEE, P1105, DOI 10.1109/CVPR.2011.5995620; Wang Y, 2011, NEUROINFORMATICS, V9, P193, DOI 10.1007/s12021-011-9110-5; Wearne SL, 2005, NEUROSCIENCE, V136, P661, DOI 10.1016/j.neuroscience.2005.05.053; Weaver CM, 2004, NEURAL COMPUT, V16, P1353, DOI 10.1162/089976604323057425; Wegner JD, 2013, PROC CVPR IEEE, P1698, DOI 10.1109/CVPR.2013.222; Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635; Xiao H, 2013, BIOINFORMATICS, V29, P1448, DOI 10.1093/bioinformatics/btt170; Xu J, 2009, COMM COM INF SC, V51, P188, DOI 10.1007/978-3-642-04962-0_22; Yedidya Tamir, 2008, 2008 Digital Image Computing: Techniques and Applications, P52, DOI 10.1109/DICTA.2008.72; Zhao T, 2011, NEUROINFORMATICS, V9, P247, DOI 10.1007/s12021-011-9120-3	52	30	30	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2515	2530		10.1109/TPAMI.2016.2519025	http://dx.doi.org/10.1109/TPAMI.2016.2519025			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	26891482	Green Submitted			2022-12-18	WOS:000387984700013
J	Bustos, AP; Chin, TJ; Eriksson, A; Li, HD; Suter, D				Bustos, Alvaro Parra; Chin, Tat-Jun; Eriksson, Anders; Li, Hongdong; Suter, David			Fast Rotation Search with Stereographic Projections for 3D Registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Point cloud registration; rotation search; branch-and-bound; stereographic projections; R-trees	ALGORITHM	Registering two 3D point clouds involves estimating the rigid transform that brings the two point clouds into alignment. Recently there has been a surge of interest in using branch-and-bound (BnB) optimisation for point cloud registration. While BnB guarantees globally optimal solutions, it is usually too slow to be practical. A fundamental source of difficulty lies in the search for the rotational parameters. In this work, first by assuming that the translation is known, we focus on constructing a fast rotation search algorithm. With respect to an inherently robust geometric matching criterion, we propose a novel bounding function for BnB that is provably tighter than previously proposed bounds. Further, we also propose a fast algorithm to evaluate our bounding function. Our idea is based on using stereographic projections to precompute and index all possible point matches in spatial R-trees for rapid evaluations. The result is a fast and globally optimal rotation search algorithm. To conduct full 3D registration, we co-optimise the translation by embedding our rotation search kernel in a nested BnB algorithm. Since the inner rotation search is very efficient, the overall 6DOF optimisation is speeded up significantly without losing global optimality. On various challenging point clouds, including those taken out of lab settings, our approach demonstrates superior efficiency.	[Bustos, Alvaro Parra; Chin, Tat-Jun; Suter, David] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Eriksson, Anders] Queensland Univ Technol, Sch Elect Engn & Comp Sci, Brisbane, Qld, Australia; [Li, Hongdong] Australian Natl Univ, Coll Engn & Comp Sci, Res Sch Engn, Canberra, ACT, Australia	University of Adelaide; Queensland University of Technology (QUT); Australian National University	Bustos, AP (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	aparra@cs.adelaide.edu.au; tjchin@cs.adelaide.edu.au; anders.eriksson@qut.edu.au; hongdong.li@anu.edu.au; dsuter@cs.adelaide.edu.au		Parra, Alvaro/0000-0002-2981-0491; Eriksson, Anders/0000-0003-2652-7110; Suter, David/0000-0001-6306-3023	Australian Research Council [DP130102524, DE130101775, DP120103896, DP130104567, CE14-ACRV]	Australian Research Council(Australian Research Council)	This work was partly supported by the Australian Research Council grants DP130102524, DE130101775, DP120103896, DP130104567 and CE14-ACRV. We thank Maptek for providing the mine dataset used in the experiments.	Aiger D., 2008, P ACM SIGGRAPH, P85; Ask E, 2013, PROC CVPR IEEE, P1722, DOI 10.1109/CVPR.2013.225; Bazin JC, 2013, IEEE T PATTERN ANAL, V35, P1565, DOI 10.1109/TPAMI.2012.264; Bazin Jean-Charles, 2012, P AS C COMP VIS, P2; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Breuel TM, 2002, LECT NOTES COMPUT SC, V2352, P837; Breuel TM, 2003, COMPUT VIS IMAGE UND, V90, P258, DOI 10.1016/S1077-3142(03)00026-2; Bustos AP, 2014, PROC CVPR IEEE, P3930, DOI 10.1109/CVPR.2014.502; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; Chetverikov D, 2002, INT C PATT RECOG, P545, DOI 10.1109/ICPR.2002.1047997; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Enqvist O, 2009, IEEE I CONF COMP VIS, P1295, DOI 10.1109/ICCV.2009.5459319; FITZGIBBON A, 2001, P BRIT MACH VIS C BM, V2, P411; Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507; Gelfand N., 2005, P 3 EUR S GEOM PROC, V2, P5; Gold S., 1998, PATTERN RECOGN, V31, P957; Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9; Horst R., 2003, GLOBAL OPTIMIZATION; Jian B, 2005, IEEE I CONF COMP VIS, P1246; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Makadia A., 2006, P IEEE C COMP VIS PA, V1, P1297, DOI DOI 10.1109/CVPR.2006.122; Manolopoulos Y., 2006, ADV INFO KNOW PROC; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Needham T., 1997, VISUAL COMPLEX ANAL; O'Rourke J, 1998, COMPUTATIONAL GEOMET; Olsson C., 2008, P IEEE C COMP VIS PA, p[1, 1], DOI DOI 10.1007/978-3-319-78199-0_21; Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131; Ruland T, 2012, PROC CVPR IEEE, P1035, DOI 10.1109/CVPR.2012.6247781; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Seo Y, 2009, IEEE I CONF COMP VIS, P1173, DOI 10.1109/ICCV.2009.5459343; Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310; Theiler PW, 2014, ISPRS J PHOTOGRAMM, V96, P149, DOI 10.1016/j.isprsjprs.2014.06.015; Yang JL, 2013, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2013.184; Yu L, 2007, IEEE INT C BIOINFORM, P9, DOI 10.1109/BIBM.2007.19; Zhang Z., 1992, 1658 INRIA ROCQ	35	30	32	2	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2227	2240		10.1109/TPAMI.2016.2517636	http://dx.doi.org/10.1109/TPAMI.2016.2517636			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26766218				2022-12-18	WOS:000385945000007
J	Hong, S; Choi, J; Feyereisl, J; Han, B; Davis, LS				Hong, Seunghoon; Choi, Jonghyun; Feyereisl, Jan; Han, Bohyung; Davis, Larry S.			Joint Image Clustering and Labeling by Matrix Factorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		Image clustering; image labeling; label feature; non-negative matrix factorization with sparsity and orthogonality constraints (SO-NMF)	OBJECT; CLASSIFICATION; ANNOTATION; SCENE; SHAPE	We propose a novel algorithm to cluster and annotate a set of input images jointly, where the images are clustered into several discriminative groups and each group is identified with representative labels automatically. For these purposes, each input image is first represented by a distribution of candidate labels based on its similarity to images in a labeled reference image database. A set of these label-based representations are then refined collectively through a non-negative matrix factorization with sparsity and orthogonality constraints; the refined representations are employed to cluster and annotate the input images jointly. The proposed approach demonstrates performance improvements in image clustering over existing techniques, and illustrates competitive image labeling accuracy in both quantitative and qualitative evaluation. In addition, we extend our joint clustering and labeling framework to solving the weakly-supervised image classification problem and obtain promising results.	[Hong, Seunghoon; Feyereisl, Jan; Han, Bohyung] POSTECH, Dept Comp Sci & Engn, Pohang, South Korea; [Choi, Jonghyun; Davis, Larry S.] Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA	Pohang University of Science & Technology (POSTECH); University System of Maryland; University of Maryland College Park	Hong, S (corresponding author), POSTECH, Dept Comp Sci & Engn, Pohang, South Korea.	maga33@postech.ac.kr; jhchoi@umiacs.umd.edu; thefillm@gmail.com; bhhan@postech.ac.kr; lsd@umiacs.umd.edu	Hong, Seunghoon/AAF-9628-2019; Feyereisl, Jan/P-3740-2019; Feyereisl, Jan/M-2239-2016	Feyereisl, Jan/0000-0002-3829-6105; Feyereisl, Jan/0000-0002-3829-6105; Choi, Jonghyun/0000-0002-7934-8434				Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg A. C., 2006, P COMP VIS PATT REC, V2, P2126; Bergamo A, 2012, PROC CVPR IEEE, P3085, DOI 10.1109/CVPR.2012.6248040; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Cabral R. S., 2011, ADV NEURAL INFORM PR, P190; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Choi J, 2013, PROC CVPR IEEE, P875, DOI 10.1109/CVPR.2013.118; Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPRW.2009.5206800, 10.1109/CVPR.2009.5206800]; Cusano C, 2004, PROC SPIE, V5304, P330; Dai DX, 2012, LECT NOTES COMPUT SC, V7574, P483, DOI 10.1007/978-3-642-33712-3_35; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6; Domeniconi C., 2001, ADV NEURAL INFORM PR, P665; Farhadi A., 2009, P IEEE C COMP VIS PA; Fergus R., 2009, ADV NEURAL INFORM PR, P522; Gaussier E., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P601, DOI 10.1145/1076034.1076148; Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120; Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266; Harchaoui Z, 2012, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2012.6248078; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516; Jia Y., 2013, CAFFE OPEN SOURCE CO; Kim G., 2008, CVPR; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Krizhevsky Alex., 2009, LEARNING MULTIPLE LA, P6; Kumar MP, 2007, IEEE I CONF COMP VIS, P1665; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee YJ, 2011, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2011.5995523; Lee YJ, 2010, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2010.5540237; Li L.-J., 2010, NEURAL INFORM PROCES, P1378; Li T, 2006, IEEE DATA MINING, P362; Li T, 2011, IEEE T IMAGE PROCESS, V20, P2301, DOI 10.1109/TIP.2010.2103081; Li T, 2009, PROC CVPR IEEE, P2270, DOI 10.1109/CVPRW.2009.5206706; Lim J.J., 2011, ADV NEURAL INFORM PR, P118; Liu D, 2007, IEEE I CONF COMP VIS, P191; Liu Y., 2006, AAAI, P421; Loeff N, 2008, LECT NOTES COMPUT SC, V5305, P451, DOI 10.1007/978-3-540-88693-8_33; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Monay F, 2004, P 12 ANN ACM INT C M, P348, DOI DOI 10.1145/1027527.1027608; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Parikh D, 2011, PROC CVPR IEEE, P1681, DOI 10.1109/CVPR.2011.5995451; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; Salakhutdinov R, 2011, PROC CVPR IEEE, P1481, DOI 10.1109/CVPR.2011.5995720; Shrivastava A, 2012, LECT NOTES COMPUT SC, V7574, P369, DOI 10.1007/978-3-642-33712-3_27; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78; Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; Tuytelaars T, 2010, INT J COMPUT VISION, V88, P284, DOI 10.1007/s11263-009-0271-8; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124; Yang C., 2006, COMPUTER VISION PATT, P2057, DOI DOI 10.1109/CVPR.2006.250; Zelnik-Manor Lihi, 2005, P ADV NEUR INF PROC, P1601; Zhou N, 2011, IEEE T PATTERN ANAL, V33, P1281, DOI 10.1109/TPAMI.2010.204; Zhou X., 2007, P 11 INT C COMP VIS, P1971; Zhu G., 2010, ACM MULT, P461	69	30	30	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1411	10.1109/TPAMI.2015.2487982	http://dx.doi.org/10.1109/TPAMI.2015.2487982			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	26452250				2022-12-18	WOS:000377897100011
J	Oxholm, G; Nishino, K				Oxholm, Geoffrey; Nishino, Ko			Shape and Reflectance Estimation in the Wild	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape from shading; multiview stereo; shape estimation; reflectance estimation	MULTIVIEW STEREO; RECONSTRUCTION; IMAGE	Our world is full of objects with complex reflectances situated in rich illumination environments. Though stunning, the diversity of appearance that arises from this complexity is also daunting. For this reason, past work on geometry recovery has tried to frame the problem into simplistic models of reflectance (such as Lambertian, mirrored, or dichromatic) or illumination (one or more distant point light sources). In this work, we directly tackle the problem of joint reflectance and geometry estimation under known but uncontrolled natural illumination by fully exploiting the surface orientation cues that become embedded in the appearance of the object. Intuitively, salient scene features (such as the sun or stained glass windows) act analogously to the point light sources of traditional geometry estimation frameworks by strongly constraining the possible orientations of the surface patches reflecting them. By jointly estimating the reflectance of the object, which modulates the illumination, the appearance of a surface patch can be used to derive a nonparametric distribution of its possible orientations. If only a single image exists, these strongly constrained surface patches may then be used to anchor the geometry estimation and give context to the less-descriptive regions. When multiple images exist, the distribution of possible surface orientations becomes tighter as additional context is given, though integrating the separate views poses additional challenges. In this paper we introduce two methods, one for the single image case, and another for the case of multiple images. The effectiveness of our methods is evaluated extensively on synthetic and real-world data sets that span the wide range of real-world environments and reflectances that lies between the extremes that have been the focus of past work.	[Oxholm, Geoffrey; Nishino, Ko] Drexel Univ, Coll Comp & Informat, Dept Comp, Dept Comp Sci, Philadelphia, PA 19104 USA	Drexel University	Oxholm, G; Nishino, K (corresponding author), Drexel Univ, Coll Comp & Informat, Dept Comp, Dept Comp Sci, Philadelphia, PA 19104 USA.	gao25@drexel.edu; kon@drexel.edu			Office of Naval Research [N00014-11-1-0099, N00014-14-1-0316]; National Science Foundation [IIS-0746717, IIS-0964420, IIS-1353235, IIS-1421094]	Office of Naval Research(Office of Naval Research); National Science Foundation(National Science Foundation (NSF))	This work was supported by the Office of Naval Research grants N00014-11-1-0099 and N00014-14-1-0316, and the National Science Foundation awards IIS-0746717, IIS-0964420, IIS-1353235 and IIS-1421094.	Adato Y, 2010, IEEE T PATTERN ANAL, V32, P2054, DOI 10.1109/TPAMI.2010.126; Alldrin N, 2008, PROC CVPR IEEE, P2447; Alldrin NG, 2007, IEEE I CONF COMP VIS, P417; Barron JT, 2012, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2012.6247693; Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Debevec P., 2012, LIGHT PROBE IMAGE GA; Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576; Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P1060, DOI 10.1109/TPAMI.2009.102; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Huang R, 2011, IEEE IMAGE PROC, P13, DOI 10.1109/ICIP.2011.6115701; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; Jin HL, 2004, PROC CVPR IEEE, P36; Johnson M, 2012, PHILOS PSYCHOL, V25, P409, DOI 10.1080/09515089.2011.579423; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Lombardi S, 2012, LECT NOTES COMPUT SC, V7577, P582, DOI 10.1007/978-3-642-33783-3_42; Lombardi S, 2012, PROC CVPR IEEE, P238, DOI 10.1109/CVPR.2012.6247681; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; Nishino K, 2009, IEEE I CONF COMP VIS, P476, DOI 10.1109/ICCV.2009.5459255; Nishino K, 2011, J OPT SOC AM A, V28, P8, DOI 10.1364/JOSAA.28.000008; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; Rusinkiewicz S. M., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P11; Seitz S., 2006, CVPR, P1; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; Tappen M. F., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2545, DOI 10.1109/CVPR.2011.5995376; Treuille A, 2004, LECT NOTES COMPUT SC, V3022, P457; Vogiatzis G, 2005, PROC CVPR IEEE, P391; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284	35	30	33	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					376	389		10.1109/TPAMI.2015.2450734	http://dx.doi.org/10.1109/TPAMI.2015.2450734			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761741				2022-12-18	WOS:000369989600014
J	Quadrianto, N; Ghahramani, Z				Quadrianto, Novi; Ghahramani, Zoubin			A Very Simple Safe-Bayesian Random Forest	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian methods; random forest; decision trees		Random forests works by averaging several predictions of de-correlated trees. We show a conceptually radical approach to generate a random forest: random sampling of many trees from a prior distribution, and subsequently performing a weighted ensemble of predictive probabilities. Our approach uses priors that allow sampling of decision trees even before looking at the data, and a power likelihood that explores the space spanned by combination of decision trees. While each tree performs Bayesian inference to compute its predictions, our aggregation procedure uses the power likelihood rather than the likelihood and is therefore strictly speaking not Bayesian. Nonetheless, we refer to it as a Bayesian random forest but with a built-in safety. The safeness comes as it has good predictive performance even if the underlying probabilistic model is wrong. We demonstrate empirically that our Safe-Bayesian random forest outperforms MCMC or SMC based Bayesian decision trees in term of speed and accuracy, and achieves competitive performance to entropy or Gini optimised random forest, yet is very simple to construct.	[Quadrianto, Novi] Univ Sussex, Dept Informat, SMiLe CLiNiC, Brighton BN1 9RH, E Sussex, England; [Ghahramani, Zoubin] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	University of Sussex; University of Cambridge	Quadrianto, N (corresponding author), Univ Sussex, Dept Informat, SMiLe CLiNiC, Brighton BN1 9RH, E Sussex, England.	n.quadrianto@sussex.ac.uk; zoubin@eng.cam.ac.uk		Quadrianto, Novi/0000-0001-8819-306X				Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Breiman L., 1999, TR567 UC BERK DEP ST; Breiman L., 2017, CLASSIFICATION REGRE; Buntine W., 1992, Statistics and Computing, V2, P63, DOI 10.1007/BF01889584; Buntine W. L., 1992, THESIS U TECHNOL SYD; Caruana R., 2008, P 25 INT C MACH LEAR, DOI DOI 10.1145/1390156.1390169; Chipman H. A., 2007, ADV NEURAL INFORM PR, P265; Chipman HA, 1998, J AM STAT ASSOC, V93, P935, DOI 10.2307/2669832; Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1561/0600000035, 10.1501/0000000035]; Cutler A., 2001, COMPUTING SCI STAT, V33, P490; Denison DGT, 1998, BIOMETRIKA, V85, P363; Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0; Friel N, 2008, J R STAT SOC B, V70, P589, DOI 10.1111/j.1467-9868.2007.00650.x; Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1; Gramacy R, 2010, STAT COMPUT, V20, P1, DOI 10.1007/s11222-008-9108-5; Grunwald Peter, 2012, Algorithmic Learning Theory. 23rd International Conference (ALT 2012). Proceedings, P169, DOI 10.1007/978-3-642-34106-9_16; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; Ibrahim JG, 2000, STAT SCI, V15, P46; Kim H.-C., 2012, P 15 INT C ARTIFICIA, V22, P619; Lakshminarayanan B., 2013, INT C MACHINE LEARNI, P280; Minka, 2002, BAYESIAN MODEL AVERA; Nowozin S., 2012, ICML, P297; Oliver J. J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P430; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Villalobos I. A., 2012, J COMPUT GRAPH STAT, V22, P801; Walker S, 2001, J ROY STAT SOC B, V63, P811, DOI 10.1111/1467-9868.00314; Zhang T., 2003, P ADV NEUR INF PROC, P1149	31	30	32	5	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1297	1303		10.1109/TPAMI.2014.2362751	http://dx.doi.org/10.1109/TPAMI.2014.2362751			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357350	Green Accepted			2022-12-18	WOS:000354377100014
J	Sivalingam, R; Boley, D; Morellas, V; Papanikolopoulos, N				Sivalingam, Ravishankar; Boley, Daniel; Morellas, Vassilios; Papanikolopoulos, Nikolaos			Tensor Sparse Coding for Positive Definite Matrices	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sparse coding; positive definite matrices; region covariance descriptors; computer vision; optimization	TEXTURE CLASSIFICATION; RIEMANNIAN GEOMETRY; COVARIANCE MATRICES; FACE-RECOGNITION; REPRESENTATION; REGRESSION	In recent years, there has been extensive research on sparse representation of vector-valued signals. In the matrix case, the data points are merely vectorized and treated as vectors thereafter (for example, image patches). However, this approach cannot be used for all matrices, as it may destroy the inherent structure of the data. Symmetric positive definite (SPD) matrices constitute one such class of signals, where their implicit structure of positive eigenvalues is lost upon vectorization. This paper proposes a novel sparse coding technique for positive definite matrices, which respects the structure of the Riemannian manifold and preserves the positivity of their eigenvalues, without resorting to vectorization. Synthetic and real-world computer vision experiments with region covariance descriptors demonstrate the need for and the applicability of the new sparse coding model. This work serves to bridge the gap between the sparse modeling paradigm and the space of positive definite matrices.	[Sivalingam, Ravishankar; Boley, Daniel; Morellas, Vassilios; Papanikolopoulos, Nikolaos] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Sivalingam, R (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, Twin Cities,200 Union St SE, Minneapolis, MN 55455 USA.	ravi@cs.umn.edu; boley@cs.umn.edu; morellas@cs.umn.edu; npapas@cs.umn.edu			US Army Research Laboratory; US Army Research Office [911NF-08-1-0463]; US National Science Foundation [IIP-0443945, CNS-0821474, IIP-0934327, CNS-1039741, IIS-1017344, IIP-1032018, SMA-1028076, IIS-0916750]	US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); US Army Research Office; US National Science Foundation(National Science Foundation (NSF))	This material is based upon the work supported in part by the US Army Research Laboratory and the US Army Research Office under contract #911NF-08-1-0463 (Proposal 55111-CI), and the US National Science Foundation through grants #IIP-0443945, #CNS-0821474, #IIP-0934327, #CNS-1039741, #IIS-1017344, #IIP-1032018, #SMA-1028076, and #IIS-0916750. YALMIP [58] and SDPT3 [59] are used for the tensor sparse coding implementation, and LIBSVM [60] for the SVM implementation. This work is an extended version of an earlier publication: "Tensor Sparse Coding for Region Covariances" published in ECCV 2010.	Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965; Bach F.R., 2004, UCBCSD041307 EECS DE; Bach F.R., 2004, P 21 INT C MACHINE L, P6, DOI 10.1145/ 1015330.1015424; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Bhatia R, 2007, PRINC SER APPL MATH, P1; Bregman L. M., 1967, COMP MATH MATH PHYS+, V7, P200, DOI DOI 10.1016/0041-5553(67)90040-7; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Cargill P. C., 2009, Proceedings of the 28th International Conference of the Chilean Computer Science Society (SCCC 2009), P133, DOI 10.1109/SCCC.2009.7; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Donoho D., 2004, P ADV NEUR INF PROC; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9446, DOI 10.1073/pnas.0502269102; Dryden I.L., 2009, ANN STAT, V3, P1102; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Gelman A., 2003, BAYESIAN DATA ANAL, DOI 10.1201/b16018; Guo K, 2010, INT CONF ACOUST SPEE, P1110, DOI 10.1109/ICASSP.2010.5495354; Hazan T, 2005, IEEE I CONF COMP VIS, P50; Kai Guo, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P188, DOI 10.1109/AVSS.2010.71; Kulis B., 2006, P 23 INT C MACH LEAR, P505; Kulis B, 2009, J MACH LEARN RES, V10, P341; Lee D. D., 2000, NIPS, V13, P535; Lofberg J., 2004, OPTIM, P284, DOI DOI 10.1109/CACSD.2004.1393890; Meyer G, 2011, J MACH LEARN RES, V12, P593; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Nesterov YE, 2002, FOUND COMPUT MATH, V2, P333, DOI 10.1007/s102080010032; Palaio H, 2008, INT C PATT RECOG, P245; Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Pennec X, 2009, LECT NOTES COMPUT SC, V5416, P347; Pfander GE, 2008, IEEE T SIGNAL PROCES, V56, P5376, DOI 10.1109/TSP.2008.928503; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; PORIKLI F, 2010, P JOINT IAPR INT C S, V6218, P20; Porikli F, 2006, 2006 IEEE INT C VIDE, P107; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; Porikli F, 2006, IEEE IMAGE PROC, P1581, DOI 10.1109/ICIP.2006.312610; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Ruta A., 2009, MACH VISION APPL, P1; Sivalingam R, 2009, 2009 THIRD ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P76; Smith ST, 2005, IEEE T SIGNAL PROCES, V53, P1610, DOI 10.1109/TSP.2005.845428; Sra S, 2011, LECT NOTES ARTIF INT, V6913, P318, DOI 10.1007/978-3-642-23808-6_21; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tou JY, 2009, LECT NOTES COMPUT SC, V5507, P745, DOI 10.1007/978-3-642-03040-6_91; Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Tutuncu RH, 2003, MATH PROGRAM, V95, P189, DOI 10.1007/s10107-002-0347-5; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Vandenberghe L, 1998, SIAM J MATRIX ANAL A, V19, P499, DOI 10.1137/S0895479896303430; Wang GG, 2009, ICICTA: 2009 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL I, PROCEEDINGS, P250, DOI 10.1109/ICICTA.2009.68; Wang H., 2010, TR10017 U MINN DEP C; Wang JG, 2010, MAGNETIC FRINGE FIELDS AND INTERFERENCE IN HIGH INTENSITY ACCELERATORS, P1; Wang ZZ, 2005, IEEE T MED IMAGING, V24, P1267, DOI 10.1109/TMI.2005.854516; Wildenauer H, 2007, LECT NOTES COMPUT SC, V4843, P65; Wishart J, 1928, BIOMETRIKA, V20A, P32, DOI 10.2307/2331939; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Ying YM, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-267; Zheng SW, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2993, DOI 10.1109/IROS.2009.5354437	60	30	33	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					592	605		10.1109/TPAMI.2013.143	http://dx.doi.org/10.1109/TPAMI.2013.143			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457513	Green Submitted			2022-12-18	WOS:000331450100015
J	Lin, YW; Tang, YY; Fang, B; Shang, ZW; Huang, YH; Wang, S				Lin, Yuewei; Tang, Yuan Yan; Fang, Bin; Shang, Zhaowei; Huang, Yonghui; Wang, Song			A Visual-Attention Model Using Earth Mover's Distance-Based Saliency Measurement and Nonlinear Feature Combination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual attention; saliency maps; dynamic saliency maps; earth mover's distance (EMD); spatiotemporal receptive field (STRF)	EYE-MOVEMENTS; SEARCH; OVERT; CATS	This paper introduces a new computational visual-attention model for static and dynamic saliency maps. First, we use the Earth Mover's Distance (EMD) to measure the center-surround difference in the receptive field, instead of using the Difference-of-Gaussian filter that is widely used in many previous visual-attention models. Second, we propose to take two steps of biologically inspired nonlinear operations for combining different features: combining subsets of basic features into a set of super features using the L-m-norm and then combining the super features using the Winner-Take-All mechanism. Third, we extend the proposed model to construct dynamic saliency maps from videos by using EMD for computing the center-surround difference in the spatiotemporal receptive field. We evaluate the performance of the proposed model on both static image data and video data. Comparison results show that the proposed model outperforms several existing models under a unified evaluation setting.	[Lin, Yuewei; Wang, Song] Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA; [Tang, Yuan Yan] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China; [Tang, Yuan Yan; Fang, Bin; Shang, Zhaowei; Huang, Yonghui] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China	University of South Carolina; University of South Carolina System; University of South Carolina Columbia; University of Macau; Chongqing University	Lin, YW (corresponding author), Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.	ywlin.cq@gmail.com; yytang@cqu.edu.cn; fb@cqu.edu.cn; szw@cqu.edu.cn; hyh2009@cqu.edu.cn; songwang@cec.sc.edu	Lin, Yuewei/D-9454-2017	Wang, Song/0000-0003-4152-5295	National Natural Science Foundations of China [NSFC-61173130, NSFC-61173129, NSFC-90820306]; Natural Science Foundation of Chongqing, China [CSTC-2009AB5002, CSTC-2010BB2217]; US National Science Foundation (NSF) [IIS-0951754, IIS-1017199]; US Air Force Office of Scientific Research [FA9550-11-1-0327]; US Army Research Laboratory under US Defense Advanced Research Projects Agency (DARPA) Mind's Eye Program [W911NF-10-2-0060];  [SRG010-FST11-TYY];  [MYRG187(Y1-L3)-FST11-TYY];  [MYRG205(Y1-L4)-FST11-TYY]	National Natural Science Foundations of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Chongqing, China(Natural Science Foundation of Chongqing); US National Science Foundation (NSF)(National Science Foundation (NSF)); US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); US Army Research Laboratory under US Defense Advanced Research Projects Agency (DARPA) Mind's Eye Program; ; ; 	This work was supported, in part, by the National Natural Science Foundations of China (NSFC-61173130, NSFC-61173129, and NSFC-90820306), and the Natural Science Foundation of Chongqing, China (CSTC-2009AB5002 and CSTC-2010BB2217), and SRG010-FST11-TYY, MYRG187(Y1-L3)-FST11-TYY, and MYRG205(Y1-L4)-FST11-TYY. This work was also supported, in part, by the US National Science Foundation (NSF) (IIS-0951754 and IIS-1017199), the US Air Force Office of Scientific Research (FA9550-11-1-0327), and the US Army Research Laboratory under Cooperative Agreement Number W911NF-10-2-0060 (US Defense Advanced Research Projects Agency (DARPA) Mind's Eye Program). The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either express or implied, of the Army Research Laboratory or the US Government. The US Government is authorized to reproduce and distribute reprints for Government purposes, notwithstanding any copyright notation herein. Part of this work was conducted while Y. Lin was with Chongqing University. A preliminary version of this work has appeared in a conference proceeding [27].	Allen EA, 2006, J NEUROSCI, V26, P11763, DOI 10.1523/JNEUROSCI.3297-06.2006; [Anonymous], 2006, NIPS; Avraham T, 2010, IEEE T PATTERN ANAL, V32, P693, DOI 10.1109/TPAMI.2009.53; Aziz MZ, 2008, IEEE T IMAGE PROCESS, V17, P633, DOI 10.1109/TIP.2008.919365; Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5; Cai DQ, 1997, J NEUROPHYSIOL, V78, P1045, DOI 10.1152/jn.1997.78.2.1045; Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755; DEANGELIS GC, 1995, TRENDS NEUROSCI, V18, P451, DOI 10.1016/0166-2236(95)94496-R; Draper BA, 2005, COMPUT VIS IMAGE UND, V100, P152, DOI 10.1016/j.cviu.2004.08.006; Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355; Gao DS, 2007, IEEE I CONF COMP VIS, P185; Harel J, 2006, ADV NEURAL INF PROCE, P19; Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267; Hou X., 2008, NIPS, P681; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; ITTI L, 2009, VISION RES, V49, P1295, DOI DOI 10.1016/J.VISRES.2008.09.007; Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007; JUDD T., 2009, P 12 IEEE INT C COMP; Knudsen EI, 2007, ANNU REV NEUROSCI, V30, P57, DOI 10.1146/annurev.neuro.30.051606.094256; Koene AR, 2007, J VISION, V7, DOI 10.1167/7.7.6; Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9; Lin YW, 2010, AAAI CONF ARTIF INTE, P967; Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Liversedge SP, 2000, TRENDS COGN SCI, V4, P6, DOI 10.1016/S1364-6613(99)01418-7; Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4; Poirier FJAM, 2008, J VISION, V8, DOI 10.1167/8.15.14; Rajashekar U, 2008, IEEE T IMAGE PROCESS, V17, P564, DOI 10.1109/TIP.2008.917218; Reinagel P, 1999, NETWORK-COMP NEURAL, V10, P341, DOI 10.1088/0954-898X/10/4/304; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; SHEPARD RN, 1964, J MATH PSYCHOL, V1, P54, DOI 10.1016/0022-2496(64)90017-3; Shic F, 2007, INT J COMPUT VISION, V73, P159, DOI 10.1007/s11263-006-9784-6; Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4; Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017; To M, 2008, P ROY SOC B-BIOL SCI, V275, P2299, DOI 10.1098/rspb.2008.0692; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; Treue S, 2003, CURR OPIN NEUROBIOL, V13, P428, DOI 10.1016/S0959-4388(03)00105-3; TSOTSOS JK, 1990, BEHAV BRAIN SCI, V13, P423, DOI 10.1017/S0140525X00079577; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32	48	30	31	0	53	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					314	328		10.1109/TPAMI.2012.119	http://dx.doi.org/10.1109/TPAMI.2012.119			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22641707	Green Submitted			2022-12-18	WOS:000312560600006
J	Kumar, R; Banerjee, A; Vemuri, BC; Pfister, H				Kumar, Ritwik; Banerjee, Arunava; Vemuri, Baba C.; Pfister, Hanspeter			Trainable Convolution Filters and Their Application to Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; convolution; filtering classifier; Volterra kernels; Fisher's linear discriminant; boosting	APPEARANCE	In this paper, we present a novel image classification system that is built around a core of trainable filter ensembles that we call Volterra kernel classifiers. Our system treats images as a collection of possibly overlapping patches and is composed of three components: 1) A scheme for a single patch classification that seeks a smooth, possibly nonlinear, functional mapping of the patches into a range space, where patches of the same class are close to one another, while patches from different classes are far apart-in the L-2 sense. This mapping is accomplished using trainable convolution filters (or Volterra kernels) where the convolution kernel can be of any shape or order. 2) Given a corpus of Volterra classifiers with various kernel orders and shapes for each patch, a boosting scheme for automatically selecting the best weighted combination of the classifiers to achieve higher per-patch classification rate. 3) A scheme for aggregating the classification information obtained for each patch via voting for the parent image classification. We demonstrate the effectiveness of the proposed technique using face recognition as an application area and provide extensive experiments on the Yale, CMU PIE, Extended Yale B, Multi-PIE, and MERL Dome benchmark face data sets. We call the Volterra kernel classifiers applied to face recognition Volterrafaces. We show that our technique, which falls into the broad class of embedding-based face image discrimination methods, consistently outperforms various state-of-the-art methods in the same category.	[Kumar, Ritwik] IBM Res Almaden, San Jose, CA 95123 USA; [Banerjee, Arunava; Vemuri, Baba C.] Univ Florida, Dept CISE, Gainesville, FL 32611 USA; [Pfister, Hanspeter] Harvard Univ, SEAS, Cambridge, MA 02138 USA	International Business Machines (IBM); State University System of Florida; University of Florida; Harvard University	Kumar, R (corresponding author), IBM Res Almaden, 650 Harry Rd, San Jose, CA 95123 USA.	rkkumar@us.ibm.com; arunava@cise.ufl.edu; vemuri@cise.ufl.edu; pfister@seas.harvard.edu		Banerjee, Arunava/0000-0001-9381-4940; Pfister, Hanspeter/0000-0002-3620-2582	US National Science Foundation (NSF) [PHY-0835713]	US National Science Foundation (NSF)(National Science Foundation (NSF))	A preliminary version of this work appeared in [24]. This work was in part supported by US National Science Foundation (NSF) Grant No. PHY-0835713 to Hanspeter Pfister.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; An S., 2008, P IEEE C COMP VIS PA; An S, 2007, P IEEE C COMP VIS PA; Artiklar M., 2003, P INT JOINT C NEUR N; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Cai D, 2007, P 11 IEEE INT C COMP; Cai D., 2007, P IEEE C COMP VIS PA; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; Cherry J.A., 1994, DISTORTION ANAL WEAK; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Duda R.O., 2000, PATTERN CLASSIFICATI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fu Y, 2008, IEEE T IMAGE PROCESS, V17, P226, DOI 10.1109/TIP.2007.914203; Gross R., 2007, TR0708 CARN MELL U; Han D, 2005, UIUCDCSR20052572; He X., 2005, P C ADV NEUR INF PRO; He X, 2003, NIPS; He X. F., 2005, P 10 IEEE INT C COMP; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; HUA G, 2007, P IEEE C COMP VIS PA; Kumar R., 2010, P IEEE C COMP VIS PA; Kumar R., 2011, P IEEE INT C COMP VI; Kumar R, 2011, IEEE T PATTERN ANAL, V33, P553, DOI 10.1109/TPAMI.2010.67; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; Lee K.C., 2003, P IEEE CS C COMP VIS; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Pang YW, 2004, LECT NOTES COMPUT SC, V3331, P352; Pham D.-S., 2008, P IEEE CS C COMP VIS; Rana S., 2008, P IEEE C COMP VIS PA; Shan H., 2008, P IEEE CS C COMP VIS; Sim T., 2001, P CVPR WORKSH MOD VE; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vasilescu A., 2003, P IEEE CS C COMP VIS; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P., 2003, TR200325 MERL; Volterra V., 1930, THEORY FUNCTIONALS I; Wang F, 2007, P IEEE C COMP VIS PA; Weyrich T, 2006, ACM T GRAPHIC, V25, P1013, DOI 10.1145/1141911.1141987; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097; Ye J., 2004, P C ADV NEUR INF PRO; ZHANG WC, 2005, P 10 IEEE INT C COMP; ZHU J, 2005, MULTICLASS ADABOOST	45	30	33	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1423	1436		10.1109/TPAMI.2011.225	http://dx.doi.org/10.1109/TPAMI.2011.225			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22144519				2022-12-18	WOS:000304138300013
J	Li, CC; Kowdle, A; Saxena, A; Chen, TH				Li, Congcong; Kowdle, Adarsh; Saxena, Ashutosh; Chen, Tsuhan			Toward Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene understanding; classification; machine learning; robotics	ALGORITHM	Scene understanding includes many related subtasks, such as scene categorization, depth estimation, object detection, etc. Each of these subtasks is often notoriously hard, and state-of-the-art classifiers already exist for many of them. These classifiers operate on the same raw image and provide correlated outputs. It is desirable to have an algorithm that can capture such correlation without requiring any changes to the inner workings of any classifier. We propose Feedback Enabled Cascaded Classification Models (FE-CCM), that jointly optimizes all the subtasks while requiring only a "black box" interface to the original classifier for each subtask. We use a two-layer cascade of classifiers, which are repeated instantiations of the original ones, with the output of the first layer fed into the second layer as input. Our training method involves a feedback step that allows later classifiers to provide earlier classifiers information about which error modes to focus on. We show that our method significantly improves performance in all the subtasks in the domain of scene understanding, where we consider depth estimation, scene categorization, event categorization, object detection, geometric labeling, and saliency detection. Our method also improves performance in two robotic applications: an object-grasping robot and an object-finding robot.	[Li, Congcong; Kowdle, Adarsh; Chen, Tsuhan] Cornell Univ, Dept Elect & Comp Engn, Ithaca, NY 14853 USA; [Saxena, Ashutosh] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Cornell University; Cornell University	Li, CC (corresponding author), Cornell Univ, Dept Elect & Comp Engn, Ithaca, NY 14853 USA.	cl758@cornell.edu; apk64@cornell.edu; asaxena@cs.cornell.edu; tsuhan@ece.cornell.edu		Chen, Tsuhan/0000-0003-3951-7931				Achanta R., 2009, P IEEE C COMP VIS PA; AGARWAL A, 2005, P IEEE C COMP VIS PA; Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], [No title captured]; Bengio Y., 2007, LARGE SCALE KERNEL M; Blaschko M. B., 2009, P BRIT MACH VIS C; Brubaker SC, 2008, INT J COMPUT VISION, V77, P65, DOI 10.1007/s11263-007-0060-1; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Collobert R., 2008, MACH LEARN P 25 INT; Dalal N., 2005, P IEEE CS C COMP VIS; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Desai C., 2009, P 12 IEEE INT C COMP; Divvala S.K., 2009, P IEEE C COMP VIS PA; Everingham M., 2012, PASCAL VOC2006 RESUL; Everingham M., 2012, PASCAL VISUAL OBJECT; FEIFEI L, 2005, P IEEE CS C COMP VIS; Felzenszwalb P.F., 2012, DISCRIMINATIVELY TRA; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fink M., 2004, P ADV NEUR INF PROC; Freund Y., 1993, P IEEE INT C AC SPEE; Freund Y., 1995, P 2 EUR C COMP LEARN; GALLEGUILLOS C., 2010, P IEEE C COMP VIS PA; Gibbs MN, 2000, IEEE T NEURAL NETWOR, V11, P1458, DOI 10.1109/72.883477; Goodfellow I.J., 2009, P NEUR INF PROC SYST; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hedau V., 2009, P 12 IEEE INT C COMP; HEITZ G, 2008, P EUR C COMP VIS; Heitz G., 2008, P NEUR INF PROC SYST; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoiem D., 2008, P IEEE C COMP VIS PA; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Koppula H., 2011, P NEUR INF PROC SYST; Kowdle A., 2010, P EUR C COMP VIS WOR; KUMAR S, 2005, P 10 IEEE INT C COMP; LeCun Y., 1998, NEURAL NETWORKS TRIC; Li C, 2011, P ADV NEUR INF PROC; Li C., 2010, P ADV NEURAL INFORM; Li C., 2011, P IEEE INT C ROB AUT; Li L.J., 2007, P 11 IEEE INT C COMP; Li Li-Jia, 2009, P IEEE C COMP VIS PA, P1; Lim J.J., 2009, P 12 IEEE INT C COMP; Mairal J., 2008, P 10 EUR C COMP VIS; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; PARIKH D, 2008, P IEEE C COMP VIS PA; Park D., 2010, P 11 EUR C COMP VIS; Quattoni A., 2004, P NEUR INF PROC SYST; Rabinovich A., 2007, P 11 IEEE INT C COMP; SAXENA A, 2005, P NEUR INF PROC SYST; SAXENA A, 2007, P 20 INT JOINT C ART; Saxena A., 2006, P NEUR INF PROC SYST; Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y; Saxena A, 2008, INT J ROBOT RES, V27, P157, DOI 10.1177/0278364907087172; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; SUDDERTH E, 2006, P IEEE CS C COMP VIS; Sutton C., 2005, P 9 C COMP NAT LANG; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214; Torralba A., 2005, P ADV NEUR INF PROC; Torralba A., 2012, MIT OUTDOOR SCENE DA; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; Toshev A., 2010, P IEEE C COMP VIS PA; Tsochantaridis I., 2004, P 21 INT C MACH LEAR; Tu Z., 2008, P IEEE C COMP VIS PA; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Yao B., 2010, P IEEE C COMP VIS PA; Yu C., 2009, P 26 ANN INT C MACH; Zeiler M. D., 2010, P IEEE C COMP VIS PA	68	30	33	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1394	1408		10.1109/TPAMI.2011.232	http://dx.doi.org/10.1109/TPAMI.2011.232			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22144522				2022-12-18	WOS:000304138300011
J	De-Maeztu, L; Villanueva, A; Cabeza, R				De-Maeztu, Leonardo; Villanueva, Arantxa; Cabeza, Rafael			Near Real-Time Stereo Matching Using Geodesic Diffusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo; 3D/stereo scene analysis	COST AGGREGATION; VARIABLE WINDOW	Adaptive-weight algorithms currently represent the state of the art in local stereo matching. However, due to their computational requirements, these types of solutions are not suitable for real-time implementation. Here, we present a novel aggregation method inspired by the anisotropic diffusion technique used in image filtering. The proposed aggregation algorithm produces results similar to adaptive-weight solutions while reducing the computational requirements. Moreover, near real-time performance is demonstrated with a GPU implementation of the algorithm.	[De-Maeztu, Leonardo; Villanueva, Arantxa; Cabeza, Rafael] Univ Publ Navarra, Dept Elect & Elect Engn, Pamplona 31006, Spain	Universidad Publica de Navarra	De-Maeztu, L (corresponding author), Univ Publ Navarra, Dept Elect & Elect Engn, Arrosadia Campus, Pamplona 31006, Spain.	leonardo.demaeztu@unavarra.es; avilla@unavarra.es; rcabeza@unavarra.es	Cabeza, Rafael/D-8236-2012; Villanueva, Arantxa/M-1641-2014	Cabeza, Rafael/0000-0001-7999-1182; Villanueva, Arantxa/0000-0001-9822-2530	Spanish Ministry of Science and Innovation [AP2007-02468]	Spanish Ministry of Science and Innovation(Ministry of Science and Innovation, Spain (MICINN)Spanish Government)	The work described in this paper was supported by the Spanish Ministry of Science and Innovation with an FPU grant (reference AP2007-02468).	Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 1998, IEEE T PATTERN ANAL, V20, P1283, DOI 10.1109/34.735802; Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428; Gong ML, 2007, INT J COMPUT VISION, V75, P283, DOI 10.1007/s11263-006-0032-x; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hosni A., 2010, P INT S 3D DAT PROC, P1; Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; Kuk-Jin Yoon, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P25; Min D, 2008, IEEE T IMAGE PROCESS, V17, P1431, DOI 10.1109/TIP.2008.925372; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Richardt C, 2010, LECT NOTES COMPUT SC, V6313, P510; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D., 2011, MIDDLEBURY STEREO EV; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Tombari F., 2007, P 2 PAC RIM C ADV IM; Tombari F., 2008, P IEEE C COMP VIS PA; Veksler O, 2003, PROC CVPR IEEE, P556; Wang L, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P798; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70	21	30	33	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					410	416		10.1109/TPAMI.2011.192	http://dx.doi.org/10.1109/TPAMI.2011.192			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21968916	Green Submitted			2022-12-18	WOS:000298105500017
J	Zhu, L; Chen, YH; Lin, Y; Lin, CX; Yuille, A				Zhu, Long (Leo); Chen, Yuanhao; Lin, Yuan; Lin, Chenxi; Yuille, Alan			Recursive Segmentation and Recognition Templates for Image Parsing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hierarchy; parsing; segmentation; scene labeling	MODELS; RELAXATION; FRAMEWORK; SIGNAL	In this paper, we propose a Hierarchical Image Model (HIM) which parses images to perform segmentation and object recognition. The HIM represents the image recursively by segmentation and recognition templates at multiple levels of the hierarchy. This has advantages for representation, inference, and learning. First, the HIM has a coarse-to-fine representation which is capable of capturing long-range dependency and exploiting different levels of contextual information (similar to how natural language models represent sentence structure in terms of hierarchical representations such as verb and noun phrases). Second, the structure of the HIM allows us to design a rapid inference algorithm, based on dynamic programming, which yields the first polynomial time algorithm for image labeling. Third, we learn the HIM efficiently using machine learning methods from a labeled data set. We demonstrate that the HIM is comparable with the state-of-the-art methods by evaluation on the challenging public MSRC and PASCAL VOC 2007 image data sets.	[Zhu, Long (Leo); Chen, Yuanhao; Yuille, Alan] Univ Calif Los Angeles, Los Angeles, CA 90095 USA; [Lin, Yuan] Shanghai Jiao Tong Univ, Shanghai 200001, Peoples R China; [Lin, Chenxi] Alibaba Grp R&D, Beijing 100000, Peoples R China	University of California System; University of California Los Angeles; Shanghai Jiao Tong University; Alibaba Group	Zhu, L (corresponding author), Univ Calif Los Angeles, 8125 Math Sci Bldg, Los Angeles, CA 90095 USA.	lzhu@stat.ucla.edu; yhchen4@ustc.edu; loirey@sjtu.edu.cn; chenxi.lin@alibaba-inc.com; yuille@stat.ucla.edu		Yuille, Alan L./0000-0001-5207-9249	W.M. Keck Foundation; US National Science Foundation (NSF) [0413214, 613563]; Air Force [FA9550-08-1-0489]; National Research Foundation of Korea; Ministry of Education, Science, and Technology [R31-2008-000-10008-0]	W.M. Keck Foundation(W.M. Keck Foundation); US National Science Foundation (NSF)(National Science Foundation (NSF)); Air Force; National Research Foundation of Korea(National Research Foundation of Korea); Ministry of Education, Science, and Technology(Ministry of Education, Science & Technology (MEST), Republic of Korea)	This research was supported by the W.M. Keck Foundation, US National Science Foundation (NSF) grants 0413214 and 613563, and by the Air Force FA9550-08-1-0489. Part of this research was supported by the World Class University (WCU) program through the National Research Foundation of Korea funded by the Ministry of Education, Science, and Technology (R31-2008-000-10008-0).	Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Chen H., 2006, PROC IEEE COMPUT SCI, V1, P943; Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1; Collins M., 1999, THESIS U PENNSYLVANI; Cour T., 2005, P IEEE CS C COMP VIS; Cowans P.J., 2005, P 10 INT WORKSH ART; Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544; Csurka G., 2008, P BRIT MACH VIS C; E.M, 2011, PASCAL VISUAL OBJECT; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEIGER D, 1991, INT J COMPUT VISION, V6, P227, DOI 10.1007/BF00115697; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; He XM, 2004, PROC CVPR IEEE, P695; Jelinek F., 1991, Computational Linguistics, V17, P315; Jin Y., 2006, CVPR, V2, P2145; Kivinen J.J., 2007, P 11 IEEE INT C COMP; Koch C., 1986, P NATL ACAD SCI US; Kumar S, 2005, IEEE I CONF COMP VIS, P1284; Kumar S., 2003, P 9 IEEE INT C COMP; Ladicky L., 2009, P IEEE INT C COMP VI; Lafferty J, 2001, P 18 INT C MACH LEAR, P282, DOI DOI 10.1038/NPROT.2006.61; Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Levin A, 2006, LECT NOTES COMPUT SC, V3954, P581; Lim J.J., 2009, P 12 IEEE INT C COMP; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Roth S., 2005, P IEEE CS C COMP VIS; Sharon E, 2000, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2000.855801; Shilman M, 2005, IEEE I CONF COMP VIS, P962; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Spence C, 2006, IEEE T IMAGE PROCESS, V15, P319, DOI 10.1109/TIP.2005.860601; Sudderth EB, 2005, IEEE I CONF COMP VIS, P1331; Taskar B., 2004, P ANN M ASS COMP LIN; Tu Z., 2008, P IEEE CS C COMP VIS; Tu ZW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P18, DOI 10.1109/ICCV.2003.1238309; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Verbeek J., 2008, P ADV NEUR INF PROC, V20; Verbeek J., 2007, P IEEE CS C COMP VIS; Willsky AS, 2002, P IEEE, V90, P1396, DOI 10.1109/JPROC.2002.800717; Zhu L., 2008, P IEEE CS C COMP VIS; Zhu L., 2008, P ADV NEUR INF PROC; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018	49	30	30	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					359	371		10.1109/TPAMI.2011.160	http://dx.doi.org/10.1109/TPAMI.2011.160			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	22193662				2022-12-18	WOS:000298105500013
J	Yang, T; Priebe, CE				Yang, Ting; Priebe, Carey E.			The Effect of Model Misspecification on Semi-Supervised Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semi-supervised classification; finite mixture model; Bayes plug-in classifier	MAXIMUM-LIKELIHOOD; SAMPLES	Semi-supervised classification-training both on labeled and unlabeled observations-can yield improved performance compared to the classifier based on only the labeled observations. Unlabeled observations are always beneficial to classification if the model we assume is correct. However, they may degrade the classifier performance when the model is misspecified. In the classical classification problem setting, many factors affect the semi-supervised performance, including training data, model specification, estimation method, and the classifier itself. For concreteness, we consider maximum likelihood estimation in finite mixture models and the Bayes plug-in classifier, due to their ubiquitousness and tractability. In this specific setting, we examine the effect of model misspecification on semi-supervised classification performance and shed some light on when and why performance degradation occurs.	[Yang, Ting; Priebe, Carey E.] Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA	Johns Hopkins University	Yang, T (corresponding author), Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA.	ting.yang@jhu.edu; cep@jhu.edu	Priebe, Carey E./A-3305-2010					CASTELLI V, 1995, PATTERN RECOGN LETT, V16, P105, DOI 10.1016/0167-8655(94)00074-D; Castelli V, 1996, IEEE T INFORM THEORY, V42, P2102, DOI 10.1109/18.556600; Cohen I, 2004, IEEE T PATTERN ANAL, V26, P1553, DOI 10.1109/TPAMI.2004.127; COZMAN F, 2006, SEMISUPERVISED LEARN, V4, P57; Grunwald P. D., 2007, MINIMUM DESCRIPTION; James LF, 2001, ANN STAT, V29, P1281; R Core Team, 2017, R LANGUAGE ENVIRONME; RATSABY J, 1995, P 8 ANN C COMP LEARN, P417; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Titterington D.M., 1987, STAT ANAL FINITE MIX; WHITE H, 1982, ECONOMETRICA, V50, P1, DOI 10.2307/1912526; Zhang Tong, 2000, P 17 INT C MACHINE L, P1191	13	30	32	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2093	2103		10.1109/TPAMI.2011.45	http://dx.doi.org/10.1109/TPAMI.2011.45			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21383400				2022-12-18	WOS:000293969000015
J	Zaharescu, A; Boyer, E; Horaud, R				Zaharescu, Andrei; Boyer, Edmond; Horaud, Radu			Topology-Adaptive Mesh Deformation for Surface Evolution, Morphing, and Multiview Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mesh; surface; manifold mesh; triangulated mesh; mesh evolution; deformable objects; morphing; 3D reconstruction	LEVEL-SET APPROACH; BOOLEAN OPERATIONS; ALGORITHMS; EXTRACTION	Triangulated meshes have become ubiquitous discrete surface representations. In this paper, we address the problem of how to maintain the manifold properties of a surface while it undergoes strong deformations that may cause topological changes. We introduce a new self-intersection removal algorithm, TransforMesh, and propose a mesh evolution framework based on this algorithm. Numerous shape modeling applications use surface evolution in order to improve shape properties such as appearance or accuracy. Both explicit and implicit representations can be considered for that purpose. However, explicit mesh representations, while allowing for accurate surface modeling, suffer from the inherent difficulty of reliably dealing with self-intersections and topological changes such as merges and splits. As a consequence, a majority of methods rely on implicit representations of surfaces, e. g., level sets, that naturally overcome these issues. Nevertheless, these methods are based on volumetric discretizations, which introduce an unwanted precision-complexity trade-off. The method that we propose handles topological changes in a robust manner and removes self-intersections, thus overcoming the traditional limitations of mesh-based approaches. To illustrate the effectiveness of TransforMesh, we describe several challenging applications: surface morphing and 3D reconstruction.	[Zaharescu, Andrei; Boyer, Edmond; Horaud, Radu] INRIA Grenoble Rhone Alpes, F-38330 Montbonnot St Martin, France		Zaharescu, A (corresponding author), INRIA Grenoble Rhone Alpes, 655 Ave Europe, F-38330 Montbonnot St Martin, France.	andrei.zaharescu@inrialpes.fr; edmond.boyer@inrialpes.fr; radu.horaud@inrialpes.fr	Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X	EC	EC(European CommissionEuropean Commission Joint Research Centre)	The authors thank Jean-Philippe Pons and Renaud Keriven for providing the source code for the gradient computation needed by multiview 3D reconstruction. This research was supported by the EC's Marie-Curie program through the VISIONTRAIN project.	ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; AFTOSMIS MJ, 1997, 970196 AIAA; AGRAWAL A, 1994, COMPUT GRAPH FORUM, V13, pC33, DOI 10.1111/1467-8659.1330033; Amenta N, 2001, COMP GEOM-THEOR APPL, V19, P127, DOI 10.1016/S0925-7721(01)00017-7; Baumgart B.G., 1974, THESIS STANFORD U; Biermann H, 2001, COMP GRAPH, P185, DOI 10.1145/383259.383280; BOARD CE, 2006, CGAL 3 2 USER REFERE; BRAID IC, 1978, MATH METHODS COMPUTE; Breen DE, 2001, IEEE T VIS COMPUT GR, V7, P173, DOI 10.1109/2945.928169; Brochu T, 2009, SIAM J SCI COMPUT, V31, P2472, DOI 10.1137/080737617; CARVALHO P. C. P., 1995, GRAPHICS GEMS, P42; CELNIKER G, 1991, COMP GRAPH, V25, P257, DOI 10.1145/127719.122746; DELINGETTE H, 1992, IMAGE VISION COMPUT, V10, P132, DOI 10.1016/0262-8856(92)90065-B; DUAN Y, 2004, EUR C COMP VIS, V3, P238; EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639; Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566645, 10.1145/566570.566581]; Enright D, 2002, J COMPUT PHYS, V183, P83, DOI 10.1006/jcph.2002.7166; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Foley James D, 1996, COMPUTER GRAPHICS PR, V12110; Franco J.-S., 2003, BRIT MACH VIS C BMVC, V1, P329, DOI [DOI 10.5244/C.17.32, 10.5244/C.17.32]; Franco JS, 2009, IEEE T PATTERN ANAL, V31, P414, DOI 10.1109/TPAMI.2008.104; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; GOLDFEATHER J, 1986, P SIGGRAPH 86, P107; Gueziec A, 2001, IEEE T VIS COMPUT GR, V7, P136, DOI 10.1109/2945.928166; HERT S, 2006, CGAL 3 2 USER REFERE; Hjaltason GR, 1995, LECT NOTES COMPUT SC, V951, P83; Hoppe H., 1992, P ACM SIGGRAPH; HUBBARD PM, 1990, CS9007 BROWN U DEP C; Jones MW, 2006, IEEE T VIS COMPUT GR, V12, P581, DOI 10.1109/TVCG.2006.56; JU T, 2002, P ACM SIGGRAPH; JUNG W, 2004, COMPUT AIDED DESIGN, V1, P477; KETTNER L, 2006, CGAL 3 2 USER REFERE; Kobbelt LP, 2001, COMP GRAPH, P57, DOI 10.1145/383259.383265; Kobbelt LP, 2000, COMPUT GRAPH FORUM, V19, pC249, DOI 10.1111/1467-8659.00417; LACHAUD JO, 2003, P 4 INT C 3D DIG IM; LITKE ALN, 2000, TRIMMING SUBDIVISION; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Losasso F, 2006, COMPUT FLUIDS, V35, P995, DOI 10.1016/j.compfluid.2005.01.006; MANTYLA M, 1986, ACM T GRAPHIC, V5, P1, DOI 10.1145/7529.7530; McInerney T, 2000, MED IMAGE ANAL, V4, P73, DOI 10.1016/S1361-8415(00)00008-6; MEYER M, 2002, P WORKSH VIS MATH; Ohtake Y, 2003, VISUAL COMPUT, V19, P115, DOI 10.1007/s00371-002-0181-z; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osher S., 2003, GEOMETRIC LEVEL SET; Osher S, 2003, LEVEL SET METHODS DY; Park JY, 2001, COMPUT GRAPH-UK, V25, P421, DOI 10.1016/S0097-8493(01)00066-8; Pons J.P., 2007, P IEEE C COMP VIS PA; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; Rappoport A., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P269, DOI 10.1145/258734.258865; Rossignac JR, 1999, ENCY ELECT ELECT ENG; Seitz S., 2006, P CVPR 06 IE COMP SO, V1, P519, DOI DOI 10.1109/CVPR.2006.19; Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526; SHIN H, 2004, P GEOM MOD PROC; SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155; VARANASI K, 2008, P EUR C COMP VIS; VU H, 2009, P IEEE C COMP VIS PA; WOJTAN C, 2008, P ACM SIGGRAPH; WOJTAN C, 2009, P ACM SIGGRAPH; Wormser, 2009, CGAL USER REFERENCE; Zaharescu A, 2009, INT J COMPUT VISION, V81, P240, DOI 10.1007/s11263-008-0169-x; Zomorodian A, 2002, INT J COMPUT GEOM AP, V12, P143, DOI 10.1142/S0218195902000785	62	30	30	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					823	837		10.1109/TPAMI.2010.116	http://dx.doi.org/10.1109/TPAMI.2010.116			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	20530809	Green Submitted			2022-12-18	WOS:000287370400013
J	Ng, HS; Wu, TP; Tang, CK				Ng, Heung-Sun; Wu, Tai-Pang; Tang, Chi-Keung			Surface-from-Gradients without Discrete Integrability Enforcement: A Gaussian Kernel Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Surface from gradients; integrability; kernel methods; basis functions	INTERPOLATION; POINTS	Representative surface reconstruction algorithms taking a gradient field as input enforce the integrability constraint in a discrete manner. While enforcing integrability allows the subsequent integration to produce surface heights, existing algorithms have one or more of the following disadvantages: They can only handle dense per-pixel gradient fields, smooth out sharp features in a partially integrable field, or produce severe surface distortion in the results. In this paper, we present a method which does not enforce discrete integrability and reconstructs a 3D continuous surface from a gradient or a height field, or a combination of both, which can be dense or sparse. The key to our approach is the use of kernel basis functions, which transfer the continuous surface reconstruction problem into high-dimensional space, where a closed-form solution exists. By using the Gaussian kernel, we can derive a straightforward implementation which is able to produce results better than traditional techniques. In general, an important advantage of our kernel-based method is that the method does not suffer discretization and finite approximation, both of which lead to surface distortion, which is typical of Fourier or wavelet bases widely adopted by previous representative approaches. We perform comparisons with classical and recent methods on benchmark as well as challenging data sets to demonstrate that our method produces accurate surface reconstruction that preserves salient and sharp features. The source code and executable of the system are available for downloading.	[Ng, Heung-Sun; Wu, Tai-Pang; Tang, Chi-Keung] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China	Hong Kong University of Science & Technology	Ng, HS (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China.	egsun@cse.ust.hk; pang@cse.ust.hk; cktang@cse.ust.hk			Hong Kong Research Grant Council [6200087]	Hong Kong Research Grant Council(Hong Kong Research Grants Council)	The authors gratefully thank Kovesi [16] and Agrawal et al. [2] for their Matlab implementations of the tested methods available in their respective project Web sites. This research is supported by the Hong Kong Research Grant Council (grant number 6200087).	Agrawal A, 2005, IEEE I CONF COMP VIS, P174, DOI 10.1109/ICCV.2005.31; AGRAWAL A, 2006, P EUR C COMP VIS, P578; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7; Cucker F, 2002, B AM MATH SOC, V39, P1; Dinh HQ, 2002, IEEE T PATTERN ANAL, V24, P1358, DOI 10.1109/TPAMI.2002.1039207; FANG L, 1995, COMPUT AIDED DESIGN, V27, P48, DOI 10.1016/0010-4485(95)90752-2; Frankot R. T., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P118; Girosi Federico, 1993, PRIORS STABILIZERS B; Goldman DB, 2005, IEEE I CONF COMP VIS, P341; Gonzalez R.C., 2008, DIGITAL IMAGE PROCES; Karacali B, 2004, INT J COMPUT VISION, V60, P25, DOI 10.1023/B:VISI.0000027788.50090.b6; Karacali B, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P525; Koenderink JJ, 1998, PHILOS T R SOC A, V356, P1071, DOI 10.1098/rsta.1998.0211; Kovesi P, 2005, IEEE I CONF COMP VIS, P994; MERCER J, 1909, PHILOS T ROYAL SOC; MICCHELLI CA, 1986, CONSTR APPROX, V2, P11, DOI 10.1007/BF01893414; MORTENSEN EN, 1995, P 22 ANN C COMP GRAP, P191, DOI DOI 10.1145/218380.218442; NEHAB D, 2005, P ACM SIGGRAPH 05 AU, V24; NG HS, 2007, P IEEE INT C COMP VI; Ohtake Y, 2004, ACM T GRAPHIC, V23, P609, DOI 10.1145/1015706.1015768; Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293; OLeary P., 2008, P IEEE C COMP VIS PA, P1; PETROVIC N, 2001, P IEEE C COMP VIS PA, V1; PRASAD M, 2006, P CVPR, P1345; SAVCHENKO VV, 1995, COMPUT GRAPH FORUM, V14, P181, DOI 10.1111/1467-8659.1440181; Schoelkopf B., 2002, LEARNING KERNELS; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; SZELISKI R, 1990, IEEE T PATTERN ANAL, V12, P513, DOI 10.1109/34.56188; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Tikhonov A.N., 1977, SOLUTION ILL POSED P; Wahba G., 1990, SPLINE MODELS OBSERV; Wu TG, 2006, PROCEEDINGS OF THE 6TH INTERNATIONAL CYTOKINE CONFERENCE, P159; WU TP, 2006, P IEEE C COMP VIS PA, P1793; WU TP, 2007, P ACM SIGGRAPH 07 AU; Zhang L, 2001, PROC CVPR IEEE, P990	37	30	31	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					2085	2099		10.1109/TPAMI.2009.183	http://dx.doi.org/10.1109/TPAMI.2009.183			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20847395				2022-12-18	WOS:000281990900011
J	Song, Z; Chung, CKR				Song, Zhan; Chung, Chi-Kit Ronald			Determining Both Surface Position and Orientation in Structured-Light-Based Sensing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Structured light system; 3D reconstruction; surface orientation; feature detection	SHAPE; ACQUISITION; PATTERNS	Position and orientation profiles are two principal descriptions of shape in space. We describe how a structured light system, coupled with the illumination of a pseudorandom pattern and a suitable choice of feature points, can allow not only the position but also the orientation of individual surface elements to be determined independently. Unlike traditional designs which use the centroids of the illuminated pattern elements as the feature points, the proposed design uses the grid points between the pattern elements instead. The grid points have the essences that their positions in the image data are inert to the effect of perspective distortion, their individual extractions are not directly dependent on one another, and the grid points possess strong symmetry that can be exploited for their precise localization in the image data. Most importantly, the grid lines of the illuminated pattern that form the grid points can aid in determining surface normals. In this paper, we describe how each of the grid points can be labeled with a unique color code, what symmetry they possess and how the symmetry can be exploited for their precise localization at subpixel accuracy in the image data, and how 3D orientation in addition to 3D position can be determined at each of them. Both the position and orientation profiles can be determined with only a single pattern illumination and a single image capture.	[Song, Zhan] Chinese Acad Sci, Shenzhen Inst Adv Technol, CIE Lab, Shenzhen 518055, Guangdong, Peoples R China; [Chung, Chi-Kit Ronald] Chinese Univ Hong Kong, Dept Mech & Automat Engn, Shatin, Hong Kong, Peoples R China; [Chung, Chi-Kit Ronald] Chinese Univ Hong Kong, Comp Vis Lab, Shatin, Hong Kong, Peoples R China	Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Chinese University of Hong Kong; Chinese University of Hong Kong	Song, Z (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, CIE Lab, Rm 301,Res Bldg 1,1068 Xueyuan Ave, Shenzhen 518055, Guangdong, Peoples R China.	zhan.song@sub.siat.ac.cn; rchung@cuhk.edu.hk	Chung, Chi-Kit Ronald/C-7702-2011		Research Grants Council of the Hong Kong Special Administrative Region, China [CUHK4195/04E]	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council)	The work described in this paper was partially supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. CUHK4195/04E).	Adan A, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P168, DOI 10.1109/CRV.2005.1; Albitar C, 2007, IEEE I CONF COMP VIS, P1207; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; Chen CS, 1997, IMAGE VISION COMPUT, V15, P445, DOI 10.1016/S0262-8856(96)01148-1; Chen SY, 2008, IEEE T IMAGE PROCESS, V17, P167, DOI 10.1109/TIP.2007.914755; Cohen J., 1988, STAT POWER ANAL BEHA; Davies CJ, 1998, IEEE T SYST MAN CY B, V28, P90, DOI 10.1109/3477.658582; Desjardins D, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P216, DOI 10.1109/CRV.2007.22; FONG P, 2005, P IEEE RSJ INT C INT, P1606; GARDING J, 1993, IEEE T PATTERN ANAL, V15, P1202, DOI 10.1109/34.244682; Gray F., 1953, U.S. Patent no, Patent No. [2 632 058, 2632058, 2, 632, 058, 2,632,058]; GRIFFIN PM, 1992, PATTERN RECOGN, V25, P609, DOI 10.1016/0031-3203(92)90078-W; Guhring J, 2001, PROC SPIE, V4309, P220; Harris C. G., 1988, P 4 ALV VIS C, V15, P10, DOI [10.5244/C.2.23, DOI 10.5244/C.2.23]; HEALEY G, 1987, P IEEE INT C COMP VI, V1, P151; Hsieh YC, 2001, PATTERN RECOGN, V34, P343, DOI 10.1016/S0031-3203(99)00224-1; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Ishii I, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P931; KIYASU S, 1995, IEEE T INSTRUM MEAS, V44, P775, DOI 10.1109/19.387330; KRATTENTHALER W, 1994, P 17 M AUSTR ASS PAT, P103; MACWILLIAMS FJ, 1976, P IEEE, V64, P1715, DOI 10.1109/PROC.1976.10411; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Miyazaki D, 2002, J OPT SOC AM A, V19, P687, DOI 10.1364/JOSAA.19.000687; Morano RA, 1998, IEEE T PATTERN ANAL, V20, P322, DOI 10.1109/34.667888; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; Pages J, 2005, IMAGE VISION COMPUT, V23, P707, DOI 10.1016/j.imavis.2005.05.007; Sadlo F., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P89, DOI 10.1109/PBG.2005.194069; Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002; Salvi J, 1998, PATTERN RECOGN LETT, V19, P1055, DOI 10.1016/S0167-8655(98)00085-3; Scharstein D, 2003, PROC CVPR IEEE, P195; SHRIKHANDE N, 1989, IEEE T PATTERN ANAL, V11, P650, DOI 10.1109/34.24799; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Song Z., 2008, HKIE T, V15, P44; Song Z, 2008, IEEE T INSTRUM MEAS, V57, P2623, DOI 10.1109/TIM.2008.925016; Song Z, 2008, IEEE IMAGE PROC, P1956, DOI 10.1109/ICIP.2008.4712165; Valkenburg RJ, 1998, IMAGE VISION COMPUT, V16, P99, DOI 10.1016/S0262-8856(97)00053-X; VUYLSTEKE P, 1990, IEEE T PATTERN ANAL, V12, P148, DOI 10.1109/34.44402; Winkelbach S., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P240; Winkelbach S., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P377; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhang S, 2006, OPT ENG, V45, DOI 10.1117/1.2336196	43	30	34	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1770	1780		10.1109/TPAMI.2009.192	http://dx.doi.org/10.1109/TPAMI.2009.192			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20724755				2022-12-18	WOS:000281000700004
J	Kim, JH; Li, HD; Hartley, R				Kim, Jae-Hak; Li, Hongdong; Hartley, Richard			Motion Estimation for Nonoverlapping Multicamera Rigs: Linear Algebraic and L-infinity Geometric Solutions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multicamera rigs; generalized camera; motion estimation; epipolar equation; branch and bound; linear programming		We investigate the problem of estimating the ego-motion of a multicamera rig from two positions of the rig. We describe and compare two new algorithms for finding the 6 degrees of freedom (3 for rotation and 3 for translation) of the motion. One algorithm gives a linear solution and the other is a geometric algorithm that minimizes the maximum measurement error-the optimal L-infinity solution. They are described in the context of the General Camera Model (GCM), and we pay particular attention to multicamera systems in which the cameras have nonoverlapping or minimally overlapping field of view. Many nonlinear algorithms have been developed to solve the multicamera motion estimation problem. However, no linear solution or guaranteed optimal geometric solution has previously been proposed. We made two contributions: 1) a fast linear algebraic method using the GCM and 2) a guaranteed globally optimal algorithm based on the L-infinity geometric error using the branch-and-bound technique. In deriving the linear method using the GCM, we give a detailed analysis of degeneracy of camera configurations. In finding the globally optimal solution, we apply a rotation space search technique recently proposed by Hartley and Kahl. Our experiments conducted on both synthetic and real data have shown excellent results.	[Kim, Jae-Hak] Univ London, Dept Comp Sci, London E1 4NS, England; [Li, Hongdong; Hartley, Richard] Australian Natl Univ, Res Sch Informat Sci & Engn, Dept Informat Engn, Canberra, ACT 0200, Australia	University of London; Australian National University	Kim, JH (corresponding author), Univ London, Dept Comp Sci, Mile End Rd, London E1 4NS, England.	jaehak@dcs.qmul.ac.uk; Hongdong.Li@anu.edu.au; Richard.Hartley@anu.edu.au		Hartley, Richard/0000-0002-5005-0191	Australian Government; Australian Research Council	Australian Government(Australian GovernmentCGIAR); Australian Research Council(Australian Research Council)	This research was partly supported by NICTA, a research center funded by the Australian Government as represented by the Department of Broadband, Communications and Digital Economy, and the Australian Research Council through the ICT Centre of Excellence program. Jae-Hak Kim was a PhD student at the Australian National University when this manuscript was first submitted. During the period of the review process, he joined Queen Mary, University of London.	*2D3 LTD, 2005, 2D3 BOUJ; BYROD M, 2007, P IEEE INT C COMP VI; Clipp B, 2008, IEEE WORK APP COMP, P125; Feldman D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P988; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FRAHM JM, 2004, P DAGM; *GNU PROJ, 2009, GNU LIN PROGR KIT VE; Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; Hart D, 2009, BRIT J RADIOL, V82, P1, DOI 10.1259/bjr/12568539; Hartley R, 2004, PROC CVPR IEEE, P504; HARTLEY R, 1993, P SPIE C INT PHOT TE, P127; HARTLEY R, 2007, P IEEE INT C COMP VI; Hartley R., 2004, ROBOTICA; Hartley R. I., 1997, PROC DARPA IMAGE UND, P649; HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005; Jae Moung Kim, 2008, 3rd International Conference on Cognitive Radio Oriented Wireless Networks and Communications (CrownCom 2008), P1, DOI 10.1109/CROWNCOM.2008.4562484; Kahl F, 2005, IEEE I CONF COMP VIS, P1002; Kim JH, 2007, LECT NOTES COMPUT SC, V4844, P353; Lhuillier M, 2006, INT C PATT RECOG, P67; Li HD, 2006, INT C PATT RECOG, P630; Li HF, 2008, CURR MED RES OPIN, V24, P1, DOI [10.1185/030079908X253933, 10.1088/0256-307X/24/3/072]; MOURAGNON E, 2007, P BRIT MACH VIS C; *PGR INC, 2006, LADYBUG2 CAM; Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520; SCHWEIGHOFER G, 2006, P BRIT MACH VIS C; Sim Kristy, 2006, IEEE COMP SOC C COMP, P485; STEWENIUS H, 2005, P WORKSH OMN VIS OCT; Stolfi J., 1991, ORIENTED PROJECTIVE; Sturm P, 2005, PROC CVPR IEEE, P206; Yu L, 2007, IEEE INT C BIOINFORM, P9, DOI 10.1109/BIBM.2007.19; ZOMET A, 2002, NONPERSPECTIVE IMAGI; [No title captured]	33	30	30	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					1044	1059		10.1109/TPAMI.2009.82	http://dx.doi.org/10.1109/TPAMI.2009.82			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431130				2022-12-18	WOS:000276671900007
J	Cohen, AR; Bjornsson, CS; Temple, S; Banker, G; Roysam, B				Cohen, Andrew R.; Bjornsson, Christopher S.; Temple, Sally; Banker, Gary; Roysam, Badrinath			Automatic Summarization of Changes in Biological Image Sequences Using Algorithmic Information Theory	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image sequence analysis; algorithmic information theory; algorithmic statistics; information distance; gap statistic; clustering	TRACKING; MODEL; SIMILARITY; CLUSTERS; DISTANCE; NEURONS	An algorithmic information-theoretic method is presented for object-level summarization of meaningful changes in image sequences. Object extraction and tracking data are represented as an attributed tracking graph (ATG). Time courses of object states are compared using an adaptive information distance measure, aided by a closed-form multidimensional quantization. The notion of meaningful summarization is captured by using the gap statistic to estimate the randomness deficiency from algorithmic statistics. The summary is the clustering result and feature subset that maximize the gap statistic. This approach was validated on four bioimaging applications: 1) It was applied to a synthetic data set containing two populations of cells differing in the rate of growth, for which it correctly identified the two populations and the single feature out of 23 that separated them; 2) it was applied to 59 movies of three types of neuroprosthetic devices being inserted in the brain tissue at three speeds each, for which it correctly identified insertion speed as the primary factor affecting tissue strain; 3) when applied to movies of cultured neural progenitor cells, it correctly distinguished neurons from progenitors without requiring the use of a fixative stain; and 4) when analyzing intracellular molecular transport in cultured neurons undergoing axon specification, it automatically confirmed the role of kinesins in axon specification.	[Cohen, Andrew R.] Univ Wisconsin, Milwaukee, WI 53201 USA; [Bjornsson, Christopher S.; Roysam, Badrinath] Rensselaer Polytech Inst, Troy, NY 12180 USA; [Temple, Sally] New York Neural Stem Cell Inst, Rensselaer, NY 12144 USA; [Banker, Gary] Oregon Hlth & Sci Univ, Portland, OR 97239 USA	University of Wisconsin System; University of Wisconsin Milwaukee; Rensselaer Polytechnic Institute; Oregon Health & Science University	Cohen, AR (corresponding author), Univ Wisconsin, POB 784, Milwaukee, WI 53201 USA.	cohena@uwm.edu; bjornc@rpi.edu; sallytemple@nynsci.org; bankerg@ohsu.edu; roysam@ecse.rpi.edu		Cohen, Andrew/0000-0002-7707-5970	US National Science Foundation [EEC-9986821]; Rensselaer Polytechnic Institute	US National Science Foundation(National Science Foundation (NSF)); Rensselaer Polytechnic Institute	This work was performed while A. Cohen was with the Department of Electrical, Computer and Systems Engineering, at the Rensselaer Polytechnic Institute. A preliminary version of this work appeared as a part of a conference proceeding [65]. Various portions of this research were supported by the Center for Subsurface Sensing and Imaging Systems under the Engineering Research Centers Program of the US National Science Foundation (EEC-9986821) and by Rensselaer Polytechnic Institute. The authors would like to thank Dr. William Shain at the Wadsworth Center and Dr. S. J. Kim at Seoul National University for the neuroprosthetics data, Yousef Al-Kofahi and Omar Al-Kofahi for help with tracking data, Susan Goderie for her help with the imaging of neural progenitor cells and advice, Dr. Stefanie Kaech at Oregon Health and Sciences University for time-lapse neuronal data, Hussein Sharafeddin for suggestions on the display of ATG, and Professor Richard Radke for insightful comments on the role of quantization in algorithmic information theory and automatic feature selection.	ADRIAANS P, 2007, P IEEE INT S INF THE; Al-Kofahi KA, 2002, IEEE T INF TECHNOL B, V6, P171, DOI 10.1109/TITB.2002.1006304; Al-Kofahi O, 2006, CELL CYCLE, V5, P327, DOI 10.4161/cc.5.3.2426; Al-Kofahi O, 2006, IEEE T BIO-MED ENG, V53, P1109, DOI 10.1109/TBME.2006.873565; ANTON B, 2006, P IEEE INT S INF THE, P436; Au CE, 2006, INT C PATT RECOG, P888; Bain L., 1992, INTRO PROBABILITY MA, Vsecond; Bao ZR, 2006, P NATL ACAD SCI USA, V103, P2707, DOI 10.1073/pnas.0511111103; Bennett CH, 1998, IEEE T INFORM THEORY, V44, P1407, DOI 10.1109/18.681318; Bjornsson CS, 2006, J NEURAL ENG, V3, P196, DOI 10.1088/1741-2560/3/3/002; Cebrian M, 2007, IEEE T INFORM THEORY, V53, P1895, DOI 10.1109/TIT.2007.894669; Chaitin G.J., 1990, INFORM RANDOMNESS IN; Chen L, 2004, PROC INT CONF DATA, P838; CHEW V, 1966, J AM STAT ASSOC, V61, P605, DOI 10.2307/2282774; Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059; COHEN AR, 2008, P 5 IEEE INT S BIOM; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Debeir O, 2005, IEEE T MED IMAGING, V24, P697, DOI 10.1109/TMI.2005.846851; Gacs P, 2001, IEEE T INFORM THEORY, V47, P2443, DOI 10.1109/18.945257; Gao Q, 2000, ARTIF INTELL, V121, P1, DOI 10.1016/S0004-3702(00)00034-5; Gokcay E, 2002, IEEE T PATTERN ANAL, V24, P158, DOI 10.1109/34.982897; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Grunwald P.D., 2005, ADV MINIMUM DESCRIPT; Hamerly G., 2003, ADV NEURAL INFORM PR, V17; Heas P, 2005, IEEE T GEOSCI REMOTE, V43, P1635, DOI 10.1109/TGRS.2005.847791; Jacobson C, 2006, NEURON, V49, P797, DOI 10.1016/j.neuron.2006.02.005; KATZ B, 2003, P AAAI SPRING S NEW; KEOGH E, 2004, P ACM SIGKDD; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101; Li M., 1997, INTRO KOLMOGOROV COM, DOI 10.1016/b978-0-444-88071-0.50009-6; Lin FT, 2007, INT J INNOV COMPUT I, V3, P71; Lin J., 2003, P 8 ACM SIGMOD WORKS; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601; Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990; Megalooikonomou V, 2005, PROC INT CONF DATA, P668; Mitchell JG, 2006, FEMS MICROBIOL ECOL, V55, P3, DOI 10.1111/j.1574-6941.2005.00003.x; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Narasimha-Iyer H, 2007, IEEE T BIO-MED ENG, V54, P1436, DOI 10.1109/TBME.2007.900807; Ng AY, 2002, ADV NEURAL INFORM PR, V14; PITIE F, 2005, P IEEE IN T C IM PRO, V3, P109; Pradeep PP, 2003, PROC SPIE, V4877, P138, DOI 10.1117/12.463680; PUDIL P, 1994, INT C PATT RECOG, P279, DOI 10.1109/ICPR.1994.576920; Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698; RATANAMAHATANA C, 2005, P SIAM INT C DAT MIN; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; RONSE C, 2005, COMPUTATIONAL IMAGIN, V30; Roussel N, 2007, IEEE T BIO-MED ENG, V54, P1786, DOI 10.1109/TBME.2007.894981; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Tyrrell JA, 2007, IEEE T MED IMAGING, V26, P223, DOI 10.1109/TMI.2006.889722; Vereshchagin NK, 2004, IEEE T INFORM THEORY, V50, P3265, DOI 10.1109/TIT.2004.838346; Vitanyi PM, 2006, IEEE T INFORM THEORY, V52, P4617, DOI 10.1109/TIT.2006.881729; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Vlachos M, 2003, P 9 ACM SIGKDD INT C, P216, DOI DOI 10.1145/956750.956777; Wood D., 1987, THEORY COMPUTATION; YI M, 2007, IEEE T PATTERN ANAL, V29, P1547; YIANILOS PN, 1991, NORMALIZED FORMS 2 C; Zhou SK, 2006, IEEE T PATTERN ANAL, V28, P917, DOI 10.1109/TPAMI.2006.120; 1990, VECTOR QUANTIZATION	65	30	31	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1386	1403		10.1109/TPAMI.2008.162	http://dx.doi.org/10.1109/TPAMI.2008.162			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542574				2022-12-18	WOS:000267050600004
J	Dhanjal, C; Gunn, SR; Shawe-Taylor, J				Dhanjal, Charanpal; Gunn, Steve R.; Shawe-Taylor, John			Efficient Sparse Kernel Feature Extraction Based on Partial Least Squares	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; kernel methods; feature extraction; partial least squares (PLS)	STATISTICAL VARIABLES; REGRESSION; COMPLEX	The presence of irrelevant features in training data is a significant obstacle for many machine learning tasks. One approach to this problem is to extract appropriate features and, often, one selects a feature extraction method based on the inference algorithm. Here, we formalize a general framework for feature extraction, based on Partial Least Squares, in which one can select a user-defined criterion to compute projection directions. The framework draws together a number of existing results and provides additional insights into several popular feature extraction methods. Two new sparse kernel feature extraction methods are derived under the framework, called Sparse Maximal Alignment (SMA) and Sparse Maximal Covariance (SMC), respectively. Key advantages of these approaches include simple implementation and a training time which scales linearly in the number of examples. Furthermore, one can project a new test example using only k kernel evaluations, where k is the output dimensionality. Computational results on several real-world data sets show that SMA and SMC extract features which are as predictive as those found using other popular feature extraction methods. Additionally, on large text retrieval and face detection data sets, they produce features which match the performance of the original ones in conjunction with a Support Vector Machine.	[Dhanjal, Charanpal; Gunn, Steve R.] Univ Southampton, Sch Elect & Comp Sci, Informat Signals Images Syst Res Grp, Southampton SO17 1BJ, Hants, England; [Shawe-Taylor, John] UCL, Dept Comp Sci, Ctr Computat Stat & Machine Learning, London WC1E 6BT, England	University of Southampton; University of London; University College London	Dhanjal, C (corresponding author), Univ Southampton, Sch Elect & Comp Sci, Informat Signals Images Syst Res Grp, Bldg 1, Southampton SO17 1BJ, Hants, England.	cd04r@ecs.soton.ac.uk; srg@ecs.soton.ac.uk; jst@cs.ucl.ac.uk		Shawe-Taylor, John/0000-0002-2030-0073				ARENASGARCIA J, 2006, ADV NEURAL INFORM PR, V19, P33; Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Bi J., 2003, Journal of Machine Learning Research, V3, P1229, DOI 10.1162/153244303322753643; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; CRAMMER K, 2002, ADV NEURAL INFORM PR, V15, P537; CRISTIANINI N, 2001, ADV NEURAL INFORM PR, V14, P10; DASPREMONT A, 2004, UCBCSD041330 EL ENG; Dhanjal Charanpal, 2006, Proceedings of the 2006 IEEE Signal Processing Society Workshop, P27; Drucker H, 1997, ADV NEUR IN, V9, P155; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; Guvenir H.A., 2000, BILKENT U FUNCTION A; Heisele B., 2000, 1687 AI MIT CTR BIOL; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Joachims T., 1998, P EUROPEAN C MACHINE, P137, DOI [10.1007/bfb0026683, 10.1007/BFb0026683]; Joachims T., 2006, P 12 ACM SIGKDD INT, V06, P217, DOI DOI 10.1145/1150402.1150429; Ledoux M., 1991, PROBABILITY BANACH S, DOI [10.1007/978-3-642-20212-4, DOI 10.1007/978-3-642-20212-4]; MANNE R, 1987, CHEMOMETR INTELL LAB, V2, P187, DOI 10.1016/0169-7439(87)80096-5; MASSY WF, 1965, J AM STAT ASSOC, V60, P234, DOI 10.2307/2283149; *MIT CTR BIOL COMP, 1996, MIT CBCL FAC DAT 1; MOGHADDAM B, 2006, ADV NEURAL INFORM PR, V18, P915; Moghaddam B., 2006, P 23 INT C MACH LEAR, P641, DOI DOI 10.1145/1143844.1143925; Momma M, 2003, LECT NOTES ARTIF INT, V2777, P216, DOI 10.1007/978-3-540-45167-9_17; MOMMA M, 2005, FEATURE EXTRACTION F, P551; MOMMA M, 2005, P SIGKDD INT C KNOWL, P654; Newman C. B. D., 1998, UCI REPOSITORY MACHI; ROSE TG, 2002, P 3 INT C LANG RES E, P827; ROSIPAL R, 2001, J MACHINE LEARNING R, V2, P97; Rosipal R, 2003, P 20 INT C MACH LEAR, P640; Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shawe-Taylor J, 2005, IEEE T INFORM THEORY, V51, P2510, DOI 10.1109/TIT.2005.850052; SMOLA AJ, 1999, SPARSE KERNEL FEATUR; STONE M, 1990, J ROY STAT SOC B MET, V52, P237; Strang G., 2003, INTRO LINEAR ALGEBRA, DOI 10.4324/9780203788219; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik VN, 1998, STAT LEARNING THEORY, DOI DOI 10.1007/978-1-4419-1428-6_5864; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Weston J, 2001, ADV NEUR IN, V13, P668; Wold H., 1966, MULTIVARIATE ANAL, V1; Worsley KJ, 1997, NEUROIMAGE, V6, P305, DOI 10.1006/nimg.1997.0294; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	47	30	38	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1347	1361		10.1109/TPAMI.2008.171	http://dx.doi.org/10.1109/TPAMI.2008.171			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542571				2022-12-18	WOS:000267050600001
J	Shan, Y; Sawhney, HS; Kumar, R				Shan, Ying; Sawhney, Harpreet S.; Kumar, Rakesh (Teddy)			Unsupervised learning of discriminative edge measures for vehicle matching between nonoverlapping cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; unsupervised learning; Gibbs Sampling; Fisher's Linear Discriminants; edge feature; vehicle matching; object reacquisition; nonoverlapping cameras		This paper proposes a novel unsupervised algorithm learning discriminative features in the context of matching road vehicles between two nonoverlapping cameras. The matching problem is formulated as a same-different classification problem, which aims to compute the probability of vehicle images from two distinct cameras being from the same vehicle or different vehicle(s). We employ a novel measurement vector that consists of three independent edge-based measures and their associated robust measures computed from a pair of aligned vehicle edge maps. The weight of each measure is determined by an unsupervised learning algorithm that optimally separates the same-different classes in the combined measurement space. This is achieved with a weak classification algorithm that automatically collects representative samples from same-different classes, followed by a more discriminative classifier based on Fisher's Linear Discriminants and Gibbs Sampling. The robustness of the match measures and the use of unsupervised discriminant analysis in the classification ensures that the proposed method performs consistently in the presence of missing/false features, temporally and spatially changing illumination conditions and systematic misalignment caused by different camera configurations. Extensive experiments based on real data of more than 200 vehicles at different times of the day demonstrate promising results.	[Shan, Ying] Microsoft Corp, Redmond, WA 98052 USA; [Sawhney, Harpreet S.; Kumar, Rakesh (Teddy)] Sarnoff Corp, Princeton, NJ 08540 USA	Microsoft; Sarnoff Corporation	Shan, Y (corresponding author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.	ying.shan@microsoft.com; hsawhney@sarnoff.com; rkumar@sarnoff.com						ATHITSOS V, 2003, P IEEE C COMP VIS PA; Bennett KP, 1999, ADV NEUR IN, V11, P368; COLLINS R, 2003, P INT C COMP VIS; Dalal N., 2005, HISTOGRAMS ORIENTED; DEBIE T, 2003, P NEURAL INFORM PROC; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Grauman K, 2004, PROC CVPR IEEE, P220; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952; Javed O., 2005, P IEEE C COMP VIS PA; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; KETTAKER V, 1999, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100; Pasula H, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1160; STENGER B, 2004, P INT WORKSH HUM COM; Tieu K., 2005, P INT C COMP VIS; Wu Y, 2000, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2000.855823; WU ZL, 2003, P NIPS 2003 WORKSH F; Xu L., 2004, P ADV NEUR INF PROC	21	30	34	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					700	711		10.1109/TPAMI.2007.70728	http://dx.doi.org/10.1109/TPAMI.2007.70728			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276974				2022-12-18	WOS:000253135600012
J	Vidal, R; Hartley, R				Vidal, Rene; Hartley, Richard			Three-view multibody structure from motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multibody structure from motion; 3D motion segmentation; multibody trilinear constraint; multibody trifocal tensor; Generalized PCA ( GPCA)	SEGMENTATION	We propose a geometric approach to 3D motion segmentation from point correspondences in three perspective views. We demonstrate that after applying a polynomial embedding to the point correspondences, they become related by the so-called multibody trilinear constraint and its associated multibody trifocal tensor, which are natural generalizations of the trilinear constraint and the trifocal tensor to multiple motions. We derive a rank constraint on the embedded correspondences from which one can estimate the number of independent motions, as well as linearly solve for the multibody trifocal tensor. We then show how to compute the epipolar lines associated with each image point from the common root of a set of univariate polynomials and the epipoles by solving a pair of plane clustering problems using Generalized Principal Component Analysis ( GPCA). The individual trifocal tensors are then obtained from the second-order derivatives of the multibody trilinear constraint. Given epipolar lines and epipoles or trifocal tensors, one can immediately obtain an initial clustering of the correspondences. We use this clustering to initialize an iterative algorithm that alternates between the computation of the trifocal tensors and the segmentation of the correspondences. We test our algorithm on various synthetic and real scenes and compare it with other algebraic and iterative algorithms.	[Vidal, Rene] Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD 21218 USA; [Hartley, Richard] Australian Natl Univ, Dept Informat Engn, Canberra, ACT 0200, Australia	Johns Hopkins University; Australian National University	Vidal, R (corresponding author), Johns Hopkins Univ, Dept Biomed Engn, 308B Clark Hall,3400 N Charles St, Baltimore, MD 21218 USA.	rvidal@cis.jhu.edu; Richard.Hartley@anu.edu.au	Vidal, Rene/A-3367-2010	Hartley, Richard/0000-0002-5005-0191				Boult T. E., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P179, DOI 10.1109/WVM.1991.212809; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 2000, PATTERN CLASSIFICATI; Fan ZM, 2006, IEEE T PATTERN ANAL, V28, P91, DOI 10.1109/TPAMI.2006.16; Feng XL, 1998, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.1998.698613; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fitzgibbon AW, 2000, LECT NOTES COMPUT SC, V1842, P891; Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903; Gruber A, 2004, PROC CVPR IEEE, P707; Han M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P163, DOI 10.1109/ICCV.2001.937513; Han M, 2000, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2000.854908; Hartley R, 2004, PROC CVPR IEEE, P769; Hartley R., 2004, ROBOTICA; Kanatani K., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P7; Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679; KANATANI K, 2003, P AUSTR JAP ADV WORK, P335; KANATANI K, 2002, P 7 EUR C COMP VIS, P25; Ma Y, 2004, INT J COMPUT VISION, V59, P115, DOI 10.1023/B:VISI.0000022286.53224.3d; Ma Y., 2003, INVITATION 3D VISION; Shashua A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P592, DOI 10.1109/ICCV.2001.937680; SHASHUA A, 2000, P 6 EUR C COMP VIS, V1, P507; SHI F, 2005, P IEEE C COMP VIS PA, V1, P315; STURM P, 2002, P 7 EUR C COMP VIS, P867; Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; Vidal R, 2004, PROC CVPR IEEE, P310; Vidal R, 2004, PROC CVPR IEEE, P510; Vidal R, 2004, LECT NOTES COMPUT SC, V3021, P1; Vidal R, 2003, PROC CVPR IEEE, P621; Vidal R., 2005, IEEE T PATTERN ANAL, V27, P1; Vidal R, 2006, INT J COMPUT VISION, V68, P7, DOI 10.1007/s11263-005-4839-7; Wolf L, 2001, PROC CVPR IEEE, P263; Wolf L, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P238, DOI 10.1109/ICCV.2001.937630; Wu Y, 2001, PROC CVPR IEEE, P252; Zelnik-Manor L, 2003, PROC CVPR IEEE, P287	36	30	37	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2008	30	2					214	227		10.1109/TPAMI.2007.1179	http://dx.doi.org/10.1109/TPAMI.2007.1179			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	240IC	18084054				2022-12-18	WOS:000251580300002
J	Shan, Y; Sawhney, HS; Matei, B; Kumar, R				Shan, Y; Sawhney, HS; Matei, B; Kumar, R			Shapeme histogram projection and matching for partial object recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shapeme histogram; spin image; Gibbs sampling; feature saliency; object recognition; Bayesian analysis		Histograms of shape signature or prototypical shapes, called shapemes, have been used effectively in previous work for 2D/3D shape matching and recognition. We extend the idea of shapeme histogram to recognize partially observed query objects from a database of complete model objects. We propose representing each model object as a collection of shapeme histograms and match the query histogram to this representation in two steps: 1) compute a constrained projection of the query histogram onto the subspace spanned by all the shapeme histograms of the model and 2) compute a match measure between the query histogram and the projection. The first step is formulated as a constrained optimization problem that is solved by a sampling algorithm. The second step is formulated under a Bayesian framework, where an implicit feature selection process is conducted to improve the discrimination capability of shapeme histograms. Results of matching partially viewed range objects with a 243 model database demonstrate better performance than the original shapeme histogram matching algorithm and other approaches.	Sarnoff Corp, Vis Technol Lab, Princeton, NJ 08540 USA	Sarnoff Corporation	Shan, Y (corresponding author), Sarnoff Corp, Vis Technol Lab, 201 Washington Rd, Princeton, NJ 08540 USA.	yshan@sarnoff.com; hsawhney@sarnoff.com; bmatei@sarnoff.com; rkumar@sarnoff.com						Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; KAZHDAN M, 2002, P SIGGRAPH; Kuncheva LI, 1999, IEEE T NEURAL NETWOR, V10, P1142, DOI 10.1109/72.788653; LAZEBNIK S, 2003, P INT C COMP VIS; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; MATEI B, UNPUB IEEE T PATTERN; Mori G, 2001, PROC CVPR IEEE, P723; Ruiz-Correa S, 2001, PROC CVPR IEEE, P769; RUIZCORREA S, 2003, P INT C COMP VIS; SALTON G, 1991, SCIENCE, V253, P974, DOI 10.1126/science.253.5023.974; Shan Y, 2004, P IEEE C COMP VIS PA; SHAN Y, 2004, P EUR C COMP VIS; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785	19	30	33	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					568	577		10.1109/TPAMI.2006.83	http://dx.doi.org/10.1109/TPAMI.2006.83			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	011FK	16566506				2022-12-18	WOS:000235253300007
J	Rieger, B; Timmermans, FJ; van Vliet, LJ; Verbeek, PW				Rieger, B; Timmermans, FJ; van Vliet, LJ; Verbeek, PW			On curvature estimation of ISO surfaces in 3D gray-value images and the computation of shape descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						principal curvatures; surface area; local surface measures; gradient structure tensor; Knutsson mapping	ORIENTED PATTERNS; OPERATORS; ERROR; FLOW	In this paper, we present a novel method to estimate curvature of iso gray-level surfaces in gray-value images. Our method succeeds where standard isophote curvature estimation methods fail. There is neither a segmentation of the surface needed nor a parametric model assumed. Our estimator works on the orientation field of the surface. This orientation field and a description of local structure is obtained by the Gradient Structure Tensor. The estimated orientation field has discontinuities mod pi. It is mapped via the Knutsson mapping to a continuous representation. The principal curvatures of the surface, a coordinate invariant property, are computed in this mapped representation. From these curvatures, locally the bending energy is computed to describe the surface shape. An extensive evaluation shows that our curvature estimation is robust even in the presence of noise, independent of the scale of the object and furthermore the relative error stays small.	Delft Univ Technol, Dept Appl Phys, Pattern Recognit Grp, NL-2628 CJ Delft, Netherlands	Delft University of Technology	Rieger, B (corresponding author), Delft Univ Technol, Dept Appl Phys, Pattern Recognit Grp, Lorentzweg 1, NL-2628 CJ Delft, Netherlands.	bernd@ph.tn.tudelft.nl; lucas@ph.tn.tudelft.nl; piet@ph.tn.tudelft.nl	van Vliet, Lucas/E-1678-2012	van Vliet, Lucas/0000-0001-7018-726X				BARMAN H, 1990, P C COMP VIS, P563; BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668; Breton P, 1996, PROC CVPR IEEE, P782, DOI 10.1109/CVPR.1996.517161; DIZENO S, 1986, COMPUTER VISION GRAP, V33, P166; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; DUNCAN JS, 1991, IEEE T MED IMAGING, V10, P307, DOI 10.1109/42.97580; Frankel T., 1997, GEOMETRY PHYS; HILTON A, 1995, PATTERN RECOGN, V28, P1201, DOI 10.1016/0031-3203(95)00002-H; IVERSON LA, 1995, IEEE T PATTERN ANAL, V17, P982, DOI 10.1109/34.464562; Jahne B, 2005, DIGITAL IMAGE PROCES, V4; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; Knutsson H., 1989, Proceedings of 6th Scandinavian Conference on Image Analysis, P244; KNUTSSON H, 1985, P IEEE COMP SOC WORK, P175; KNUTSSON H, 1982, THESIS LINKOPING U; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; LUENGOHENDRIKS CL, 2001, P 4 INT WORKSH VIS F; Maintz JBA, 1996, IEEE T PATTERN ANAL, V18, P353, DOI 10.1109/34.491617; MONGA O, 1992, IMAGE VISION COMPUT, V10, P403, DOI 10.1016/0262-8856(92)90026-Y; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Rieger B, 2003, P 10 INT C COMP AN I; ROMENY BMT, 1994, IMAGE VISION COMPUT, V12, P317, DOI 10.1016/0262-8856(94)90056-6; Rutovitz D, 1968, PICTORIAL PATTERN RE, P105; Salden AH, 1998, J MATH IMAGING VIS, V9, P5, DOI 10.1023/A:1008253609285; Serra CRB, 1999, CLIN EXP RHEUMATOL, V17, P375; SERTA J, 1982, IMAGE ANAL MATH MORP; THIRION JP, 1995, COMPUT VIS IMAGE UND, V61, P190, DOI 10.1006/cviu.1995.1015; van de Weijer J, 2001, IEEE T PATTERN ANAL, V23, P1035, DOI 10.1109/34.955116; Van Vliet L. J., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P1403; VANDENBOOMGAARD R, 2002, P 2 INT WORKSH TEXT, P135; VERBEEK PW, 1994, IEEE T PATTERN ANAL, V16, P726, DOI 10.1109/34.297954; VERBEEK PW, 1990, PATTERN RECOGN LETT, V11, P681, DOI 10.1016/0167-8655(90)90102-8; VERBEEK PW, 1985, PATTERN RECOGN LETT, V3, P287, DOI 10.1016/0167-8655(85)90009-1; VERBEEK PW, 1993, BIOIMAGING, V1, P46; VERBEEK PW, 2003, P 10 INT C COMP AN I; Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190; *WOLFR RES, 1998, MATHEMATICA 4; YOUNG IT, 1974, INFORM CONTROL, V25, P357, DOI 10.1016/S0019-9958(74)91038-9	37	30	30	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					1088	1094		10.1109/TPAMI.2004.50	http://dx.doi.org/10.1109/TPAMI.2004.50			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641738	Green Submitted			2022-12-18	WOS:000221872400012
J	Jiang, G; Quan, L; Tsui, HT				Jiang, G; Quan, L; Tsui, HT			Circular motion geometry using minimal data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure from motion; minimal data; turntable; circular motion; vision geometry; single axis motion	FITTING CONIC SECTIONS; RECONSTRUCTION	Circular motion or single axis motion is widely used in computer vision and graphics for 3D model acquisition. This paper describes a new and simple method for recovering the geometry of uncalibrated circular motion from a minimal set of only two points in four images. This problem has been previously solved using nonminimal data either by computing the fundamental matrix and trifocal tensor in three images or by fitting conics to tracked points in five or more images. It is first established that two sets of tracked points in different images under circular motion for two distinct space points are related by a homography. Then, we compute a plane homography from a minimal two points in four images. After that, we show that the unique pair of complex conjugate eigenvectors of this homography are the image of the circular points of the parallel planes of the circular motion. Subsequently, all other motion and structure parameters are computed from this homography in a straighforward manner. The experiments on real image sequences demonstrate the simplicity, accuracy, and robustness of the new method.	Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China; Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	Chinese University of Hong Kong; Hong Kong University of Science & Technology	Jiang, G (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.	gjiang@ee.cuhk.edu.hk; quan@cs.ust.hk; httsui@ee.cuhk.edu.hk						ARMSTRONG M, 1996, P 4 EUR C COMP VIS C, P3; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; BOYER E, 1996, P EUR C COMP VIS, P109; CHIEN CH, 1986, COMPUT VISION GRAPH, V36, P256, DOI 10.1016/0734-189X(86)90078-2; Faugeras O., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P36, DOI 10.1007/BFb0055658; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FITZGIBBON AW, 1998, P EUR WORKSH 3D STRU, P155; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Jiang G, 2003, IEEE T PATTERN ANAL, V25, P1343, DOI 10.1109/TPAMI.2003.1233910; JIANG G, 2003, P IEEE INT C COMP VI; KUTULAKOS K, 1999, INT C COMP VIS ICCV, V1, P307; Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; Mendonca PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461; MENDONCA PRS, 2000, P 6 EUR C COMP VIS, V2, P864; NIEM W, 1994, WORKSH COMP SER; QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; SAWHNEY HS, 1993, IEEE T PATTERN ANAL, V15, P885, DOI 10.1109/34.232075; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; Sullivan S, 1998, IEEE T PATTERN ANAL, V20, P1091, DOI 10.1109/34.722621; Szeliski R., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P625, DOI 10.1109/CVPR.1991.139764; Van Gool L, 1998, IMAGE VISION COMPUT, V16, P21, DOI 10.1016/S0262-8856(97)00046-2; Vieville T, 1999, INT J COMPUT VISION, V31, P5, DOI 10.1023/A:1008082308694	25	30	31	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					721	731						11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EZ	18579933	Green Submitted			2022-12-18	WOS:000220756500006
J	Grossmann, R; Kiryati, N; Kimmel, R				Grossmann, R; Kiryati, N; Kimmel, R			Computational surface flattening: A voxel-based approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						surface flattening; geodesic distance estimation; multidimensional scaling; voxel representation; texture mapping	MINIMAL DISTANCES; MAPPINGS; PATHS	A voxel-based method for flattening a surface in 3D space into 2D while best preserving distances is presented. Triangulation or polyhedral approximation of the voxel data are not required. The problem is divided into two main parts: Voxel-based calculation of the minimal geodesic distances between points on the surface and finding a configuration of points in 2D that has Euclidean distances as close as possible to these distances. The method suggested combines an efficient voxel-based hybrid distance estimation method, that takes the continuity of the underlying surface into account, with classical multidimensional scaling (MDS) for finding the 2D point configuration. The proposed algorithm is efficient, simple, and can be applied to surfaces that are not functions. Experimental results are shown.	Comverse, Tel Aviv, Israel; Tel Aviv Univ, Dept Elect Engn Syst, IL-69978 Ramat Aviv, Israel; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Tel Aviv University; Technion Israel Institute of Technology	Grossmann, R (corresponding author), Comverse, HaBarzel 29, Tel Aviv, Israel.	ruth.grossmann@converse.com; nk@eng.tau.ac.il; ron@cs.technion.ac.il		Kiryati, Nahum/0000-0003-1436-2275				ANGENENT S, 1999, P 2 INT C MED IM COM, P269; BENNIS C, 1991, COMP GRAPH, V25, P237, DOI 10.1145/127719.122744; Borg I., 1997, MODERN MULTIDIMENSIO; CRITCHLEY F, 1988, LINEAR ALGEBRA APPL, V105, P91, DOI 10.1016/0024-3795(88)90006-7; Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Drury HA, 1996, J COGNITIVE NEUROSCI, V8, P1, DOI 10.1162/jocn.1996.8.1.1; DYN N, 1989, APPROXIMATION THEORY, V1, P211, DOI DOI 10.1007/BF01203417; Dyn N, 1987, TOPICS MULTIVARIATE, P47; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GOMES J, 1999, P HUM BRAIN MAPP C J; GONDRAN M, 1984, GRAPHS ALGORITHMS, pCH2; GROSSMANN R, 2001, P 4 INT WORKSH VIS F, P196; HAKER S, 2000, IEEE T VISUALIZATION, V6; HERMOSILLO G, 1999, P C SCAL SPAC 99, P58; Jonas A, 1997, PATTERN RECOGN, V30, P1803, DOI 10.1016/S0031-3203(97)00011-3; Jonas A, 1998, J MATH IMAGING VIS, V8, P215, DOI 10.1023/A:1008218517090; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; KIMMEL R, 1999, CURVE SURFACE DESIGN; KIRYATI N, 1995, PATTERN RECOGN, V28, P361, DOI 10.1016/0031-3203(94)00101-Q; KIRYATI N, 1993, PATTERN RECOGN, V26, P1623, DOI 10.1016/0031-3203(93)90018-R; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045; ONeill B., 1966, ELEMENTARY DIFFERENT; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506; SEDGEWICK R, 1988, ALGORITHMS, pCH11; Snyder JP, 1997, FLATTENING EARTH 200; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; WOLFSON E, 1989, IEEE T PATTERN ANAL, V11, P1001, DOI 10.1109/34.35505; ZIGELMAN G, IN PRESS IEEE T VISU; [No title captured]	32	30	32	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2002	24	4					433	441		10.1109/34.993552	http://dx.doi.org/10.1109/34.993552			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	534FM					2022-12-18	WOS:000174574100001
J	Jelinek, D; Taylor, CJ				Jelinek, D; Taylor, CJ			Reconstruction of linearly parameterized models from single images with a camera of unknown focal length	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; uncalibrated imagery; numerical optimization		This paper deals with the problem of recovering the dimensions of an object and its pose from a single image acquired with a camera of unknown focal length. It is assumed that the object in question can be modeled as a polyhedron where the coordinates of the vertices can be expressed as a linear function or a dimension vector, X. The reconstruction program takes as input, a set of correspondences between features in the model and features in the image. From this information, the program determines an appropriate projection model for the camera (scaled orthographic or perspective), the dimensions of the object, its pose relative to the camera and. in the case of perspective projection. the focal length of the camera. This paper describes how the reconstruction problem can be framed as an optimization over a compact set with low dimension-no more than four. This optimization problem can be solved efficiently by coupling standard nonlinear optimization techniques with a multistart method which generates multiple starting points for the optimizer by sampling the parameter space uniformly. The result is an efficient, reliable solution system that does not require initial estimates for any of the parameters being estimated.	Univ Penn, Grasp Lab, CIS Dept, Philadelphia, PA 19104 USA	University of Pennsylvania	Jelinek, D (corresponding author), Univ Penn, Grasp Lab, CIS Dept, 3401 Walnut St,Room 329C, Philadelphia, PA 19104 USA.	davidj2@seas.upenn.edu; cjtaylor@central.cis.upenn.edu						CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; Pollefeys M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P31, DOI 10.1007/BFb0015521; SHUFELT JA, 1996, THESIS CARNEGIE MELL; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684	8	30	32	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2001	23	7					767	773		10.1109/34.935850	http://dx.doi.org/10.1109/34.935850			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	449TV		Green Published, Green Submitted			2022-12-18	WOS:000169704000007
J	Adam, A; Rivlin, E; Shimshoni, I				Adam, A; Rivlin, E; Shimshoni, I			ROR: Rejection of outliers by rotations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						correspondence problem; feature matching; false matches; outliers; outlier rejection; robust estimation		We address the problem of rejecting false matches of points between two perspective views. The two views are taken from two arbitrary, unknown positions and orientations. Even the best algorithms for image matching make some mistakes and output some false matches. We present an algorithm for identification of the false matches between the views. The algorithm exploits the possibility of rotating one of the images to achieve some common behavior of the correct matches. Those matches that deviate from this common behavior turn out to be false matches. Our algorithm does not, in any way, use the image characteristics of the matched features. In particular, it avoids problems that cause the false matches in the first place. The algorithm works even in cases where the percentage of false matches is as high as 85 percent. The algorithm may be run as a postprocessing step on output from any point matching algorithm. Use of the algorithm may significantly improve the ratio of correct matches to incorrect matches. For robust estimation algorithms which are later employed, this is a very desirable quality since it reduces significantly their computational cost. We present the algorithm, identify the conditions under which it works, and present results of testing it on both synthetic and real images. The code for the algorithm is available through the World Wide Web.	Technion Israel Inst Technol, Dept Math, IL-32000 Haifa, Israel; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel; Technion Israel Inst Technol, Dept Ind Engn & Management, IL-32000 Haifa, Israel	Technion Israel Institute of Technology; Technion Israel Institute of Technology; Technion Israel Institute of Technology	Adam, A (corresponding author), Technion Israel Inst Technol, Dept Math, IL-32000 Haifa, Israel.	amita@cs.technion.ac.il; ehudr@cs.technion.ac.il; ilans@ie.technion.ac.il						ADAM A, 2000, THESIS TECHNION ISRA; ADAM A, 2000, ROR IMPLEMENTATION; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Comaniciu D, 1999, PATTERN ANAL APPL, V2, P22, DOI 10.1007/s100440050011; Craig J. J., 1989, INTRO ROBOTICS; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Haralick RM., 1992, COMPUTER ROBOT VISIO; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064; Lew M. S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P88, DOI 10.1109/CVPR.1999.786922; Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P727, DOI 10.1109/ICCV.1998.710798; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Wei GQ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1035, DOI 10.1109/ICCV.1998.710844; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	16	30	30	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2001	23	1					78	84		10.1109/34.899948	http://dx.doi.org/10.1109/34.899948			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	390VA					2022-12-18	WOS:000166316700007
J	Zelnik-Manor, L; Irani, M				Zelnik-Manor, L; Irani, M			Multi-frame estimation of planar motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion estimation; plane alignment; multi-frame analysis; gradient-based methods	OPTICAL-FLOW; RECOVERY; SHAPE	Traditional plane alignment techniques are typically performed between pairs of frames. In this paper, we present a method for extending existing two-frame planar motion estimation techniques into a simultaneous multi-frame estimation, by exploiting multiframe subspace constraints of planar surfaces. The paper has three main contributions: 1) we show that when the camera calibration does not change, the collection of all parametric image motions of a planar surface in the scene across multiple frames is embedded in a low dimensional linear subspace; 2) we show that the relative image motion of multiple planar surfaces across multiple frames is embedded in a yet lower dimensional linear subspace, even with varying camera calibration; and 3) we show how these multi-frame constraints can be incorporated into simultaneous multi-frame estimation of planar motion, without explicitly recovering any 3D information, or camera calibration. The resulting multi-frame estimation process is more constrained than the individual two-frame estimations, leading to more accurate alignment, even when applied to small image regions.	Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Weizmann Institute of Science	Zelnik-Manor, L (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.	lihi@wisdom.weizmann.ac.il; irani@wisdom.weizmann.ac.il						ADELSON EH, 1985, RCA ENG, V29, P33; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; BERGEN JR, 1992, P EUR C COMP VIS, P237; Black M. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P296, DOI 10.1109/CVPR.1991.139705; FAUGERAS O, 1996, 3 DIMENSIONAL COMPUT; FLEET DJ, 1995, IEEE T PATTERN ANAL, V17, P61, DOI 10.1109/34.368151; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Irani M, 1997, IEEE T PATTERN ANAL, V19, P268, DOI 10.1109/34.584105; IRANI M, 1992, LECT NOTES COMPUT SC, V588, P282; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Sawhney HS, 1997, PROC CVPR IEEE, P450, DOI 10.1109/CVPR.1997.609364; SHASHUA A, 1996, P EUR C COMP VIS; Szeliski R., 1998, 3D Structure from Multiple Images of Large-Scale Environments. European Workshop, SMILE'98. Proceedings, P171; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; Zelnik-Manor L., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P151, DOI 10.1109/CVPR.1999.786932; Zelnik-Manor L., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P710, DOI 10.1109/ICCV.1999.790291	23	30	32	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1105	1116		10.1109/34.879791	http://dx.doi.org/10.1109/34.879791			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ					2022-12-18	WOS:000165067100004
J	Antos, A; Devroye, L; Gyorfi, L				Antos, A; Devroye, L; Gyorfi, L			Lower bounds for Bayes error estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						discrimination; statistical pattern recognition; nonparametric estimation; Bayes error; lower bounds; rates of convergence	CONVERGENCE	We give a short proof of the following result. Let (X,Y) be any distribution on N x {0, 1}, and let (X-1,Y-1),...,(X-n,Y-n) be an i.i.d. sample drawn from this distribution. In discrimination. the Bayes error L* = inf(g)P{g(X) not equal Y} is crucial importance. Here we show that without further conditions on the distribution of (X,Y), no rate-of-convergence results can be obtained. Let phi(n)(X-1,Y-1,...,X-n,Y-n) be an estimate of the Bayes error, and let {phi(n)(.)} be a sequence of such estimates. For any sequence {a(n)} of positive numbers converging to zero, a distribution of (X,Y) may be found such that E{\L* - phi(n)(X-1,Y-1,...,X-n, Y-n)\} greater than or equal to a(n) infinitely often.	Hungarian Acad Sci, Comp & Automat Res Inst, H-1518 Budapest, Hungary; McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2K6, Canada; Tech Univ Budapest, Dept Comp Sci & Informat Theory, H-1521 Budapest, Hungary	Eotvos Lorand Research Network; Hungarian Academy of Sciences; Hungarian Institute for Computer Science & Control; McGill University; Budapest University of Technology & Economics	Antos, A (corresponding author), Hungarian Acad Sci, Comp & Automat Res Inst, Lagymanyosi U 11, H-1518 Budapest, Hungary.	gyorfi@inf.bme.hu						BIRGE L, 1986, PROBAB THEORY REL, V71, P271, DOI 10.1007/BF00332312; CHEN Z, 1973, P IEEE C SYST MAN CY; Cover T, 1968, P HAW INT C SYST SCI, V415, P413; DEVROYE L, 1983, Z WAHRSCHEINLICHKEIT, V62, P475, DOI 10.1007/BF00534199; DEVROYE L, 1995, STAT PROBABIL LETT, V23, P63, DOI 10.1016/0167-7152(94)00095-P; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154, DOI 10.1109/TPAMI.1982.4767222; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P1521, DOI 10.1109/T-C.1971.223165; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103, DOI 10.1109/TPAMI.1987.4767875; GARNETT JM, 1977, IEEE T COMPUT, V26, P46, DOI 10.1109/TC.1977.5009273; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST	11	30	31	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1999	21	7					643	645		10.1109/34.777375	http://dx.doi.org/10.1109/34.777375			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	216YT					2022-12-18	WOS:000081472600007
J	Guan, WG; Ma, SD				Guan, WG; Ma, SD			A list-processing approach to compute Voronoi diagrams and the Euclidean distance transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Voronoi transformation; Voronoi diagram; Euclidean distance; distance transformation; coherence	DIGITAL IMAGES	In this paper, we propose an efficient Voronoi transform algorithm for constructing Voronoi diagrams using segment lists of rows. A significant feature of the algorithm is that it takes segments rather than pixels as the basic units to represent and propagate the nearest neighbor information. The segment lists are dynamically updated as they are scanned. A distance map can then be easily computed from the segment list representation of the Voronoi diagram. Experimental results have demonstrated its high efficiency. Extension of the algorithm to higher dimensions is also discussed.	Victoria Univ Wellington, Dept Comp Sci, Wellington, New Zealand; Chinese Acad Sci, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China	Victoria University Wellington; Chinese Academy of Sciences	Guan, WG (corresponding author), Victoria Univ Wellington, Dept Comp Sci, Wellington, New Zealand.							BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; BREU H, 1995, IEEE T PATTERN ANAL, V17, P529, DOI 10.1109/34.391389; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; Guan Weiguang, 1995, Chinese Journal of Computers, V18, P626; HERMAN GT, 1992, IEEE COMPUTER GRAPHI; JI LA, 1992, IEEE T PATTERN ANAL, V14, P653, DOI 10.1109/34.141555; KOLOUNTZAKIS MN, 1992, INFORM PROCESS LETT, V43, P181, DOI 10.1016/0020-0190(92)90197-4; LEYMARIE F, 1992, CVGIP-IMAG UNDERSTAN, V55, P84, DOI 10.1016/1049-9660(92)90008-Q; MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486; ORBERT CL, 1993, THESIS UPPSALA U; Paglieroni D. W., 1992, Machine Vision and Applications, V5, P47, DOI 10.1007/BF01213529; PAGLIERONI DW, 1992, CVGIP-GRAPH MODEL IM, V54, P56, DOI 10.1016/1049-9652(92)90034-U; RAGNEMALM I, 1993, THESIS LINKOPING U L, P276; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1978, DIGITAL PICTURE PROC; Shih FYC, 1992, IEEE T IMAGE PROCESS, V1, P197, DOI 10.1109/83.136596; VERWER BJH, 1989, IEEE T PATTERN ANAL, V11, P425, DOI 10.1109/34.19041; VOSSEPOEL AM, 1988, COMPUT VISION GRAPH, V43, P88, DOI 10.1016/0734-189X(88)90045-X; YAMADA H, 1984, P 7 INT C PATT REC, P69	20	30	32	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1998	20	7					757	761		10.1109/34.689306	http://dx.doi.org/10.1109/34.689306			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZY930					2022-12-18	WOS:000074677200008
J	Bennett, J; Khotanzad, A				Bennett, J; Khotanzad, A			Multispectral random field models for synthesis and analysis of color images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color texture models; color texture synthesis; color texture analysis; multispectral random fields; multispectral simultaneous autoregressive models; multispectral Markov random field models; multispectral pseudo-Markov random field models; least squares estimation	SPATIAL-INTERACTION	In this paper, multispectral extensions to the traditional gray level simultaneous autoregressive (SAR) and Markov random field (MRF) models are considered. Furthermore, a new image model is proposed, the pseudo-Markov model, which retains the characteristics of the multispectral Markov model, yet admits to a simplified parameter estimation method. These models are well-suited to analysis and modeling of color images. For each model considered, procedures are developed for parameter estimation and image synthesis. Experimental results, based on known image models and natural texture samples, substantiate the validity of these results.	So Methodist Univ, Dept Elect Engn, Dallas, TX 75275 USA	Southern Methodist University	Bennett, J (corresponding author), So Methodist Univ, Dept Elect Engn, Dallas, TX 75275 USA.	kha@seas.smu.edu						BENNETT JW, 1997, THESIS SO METHODIST; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; CHELLAPPA R, 1985, IEEE T SYST MAN CYB, V15, P298, DOI 10.1109/TSMC.1985.6313361; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; GAGALOWICZ A, 1986, P INT C PATT REC PAR, P412; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KHOTANZAD A, 1987, IEEE T SYST MAN CYB, V17, P1087, DOI 10.1109/TSMC.1987.6499322; LARIMORE WE, 1977, P IEEE, V65, P961, DOI 10.1109/PROC.1977.10593; *MIT MED LAB VIS M, 1995, VIS TEXT VIST DAT; PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559; WHITTLE P, 1954, BIOMETRIKA, V41, P434	11	30	31	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					327	332		10.1109/34.667889	http://dx.doi.org/10.1109/34.667889			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156					2022-12-18	WOS:000073078400009
J	Cook, DJ; Gmytrasiewicz, P; Holder, LB				Cook, DJ; Gmytrasiewicz, P; Holder, LB			Decision-theoretic cooperative sensor planning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						sensor planning; decision theory; multiagent planning; Unmanned Ground Vehicle; active vision	PERCEPTION; COORDINATION	This paper describes a decision-theoretic approach to cooperative sensor planning between multiple autonomous vehicles executing a military mission. For this autonomous vehicle application, intelligent cooperative reasoning must be used to select optimal vehicle viewing locations and select optimal camera pan and tilt angles throughout the mission. Decisions are made in such a way as to maximize the Value of information gained by the sensors while maintaining vehicle stealth. Because the mission involves multiple vehicles, cooperation can be used to balance the work load and to increase information gain. This paper presents the theoretical foundations of our cooperative sensor planning research and describes the application of these techniques to ARPA's Unmanned Ground Vehicle program.			Cook, DJ (corresponding author), UNIV TEXAS,DEPT COMP SCI ENGN,ARLINGTON,TX 76019, USA.							Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571; ARKIN RC, 1994, IEEE T ROBOTIC AUTOM, V10, P276, DOI 10.1109/70.294203; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; BAJCSY R, 1992, CVGIP-IMAG UNDERSTAN, V56, P31, DOI 10.1016/1049-9660(92)90083-F; BALLARD DH, 1992, CVGIP-IMAG UNDERSTAN, V56, P3, DOI 10.1016/1049-9660(92)90081-D; Boff K. R, 1986, HDB PERCEPTION HUMAN, VI; BRIGS W, IN PRESS P INT JOINT; CAMUS T, 1993, P IM UND WORKSH, P593; COOK D, 1994, P ART INT PLANN SYST, P225; DURFEE EH, 1991, IEEE T SYST MAN CYB, V21, P1363, DOI 10.1109/21.135682; EPHRATI E, 1995, P INT JOINT C ART IN; Feldman J.A., 1977, COGNITIVE SCI, V1, P158, DOI 10.1207/s15516709cog0102_2; Goldberg DE, 1989, GENETIC ALGORITHMS S; HUBER MJ, 1994, PROBLEM MULTIPLE ROB; Keeney R.L., 1976, DECISIONS MULTIPLE O, P96; Krotkov EP, 1989, ACTIVE COMPUTER VISI; MOSES Y, 1991, CS9101 WEIZM I; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; RIMEY RD, 1994, INT J COMPUT VISION, V12, P173, DOI 10.1007/BF01421202; ROSENSCHEIN JS, 1994, AI MAG, V15, P29; Russell S., 2021, ARTIF INTELL, V19, P23; SHAW ML, 1977, J EXP PSYCHOL HUMAN, V3, P201, DOI 10.1037/0096-1523.3.2.201; SPIEGELHALTER DJ, 1993, STAT SCI, V8, P219, DOI 10.1214/ss/1177010888; VONMARTIAL F, 1992, COORDINATING PLANS A; Weiss S. M., 1990, COMPUTER SYSTEMS LEA	25	30	31	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1996	18	10					1013	1023		10.1109/34.541410	http://dx.doi.org/10.1109/34.541410			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VP691					2022-12-18	WOS:A1996VP69100005
J	DORI, D				DORI, D			VECTOR-BASED ARC SEGMENTATION IN THE MACHINE DRAWING UNDERSTANDING SYSTEM ENVIRONMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ARC SEGMENTATION; ENGINEERING DRAWING UNDERSTANDING; TECHNICAL DOCUMENTATION AUTOMATION; SPARSE-PIXEL RECOGNITION; DOCUMENT ANALYSIS AND RECOGNITION; VECTORIZATION; RASTER-TO-VECTOR; HOUGH TRANSFORM	HOUGH TRANSFORM; CIRCLES	Arcs are important primitives in engineering drawings. Along with bars, they play a major role in describing both the geometry and the annotation of the object represented in the drawing, Extracting these primitives during the lexical analysis phase is a prerequisite to syntactic and semantic understanding of engineering drawings within the Machine Drawing Understanding System, Bars are detected by the orthogonal zig-zag vectorization algorithm, Some of the detected bars are linear approximations of arcs, As such, they provide the basis for are segmentation, An are is detected by finding a chain of bars and a triplet of points along the chain. The are center is first approximated as the center of mass of the triangle formed by the intersection of the perpendicular bisectors of the chords these points define, The location of the center is refined by recursively finding more such triplets and converging to within no more than a few pixels from the actual are center after two or three iterations. The high performance of the algorithm, demonstrated on a set of real engineering drawings, is due to the fact that it avoids both raster-to-vector and massive pixel-level operations, as well as any space transformations.			DORI, D (corresponding author), TECHNION ISRAEL INST TECHNOL,FAC IND ENGN & MANAGEMENT,IL-32000 HAIFA,ISRAEL.							[Anonymous], 1986, INITIAL GRAPHICS EXC; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P1; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; CHAI I, 1992, VISUAL FORM, P127; CHAI I, 1992, SPIE, V1661, P38; CONKER RS, 1988, COMPUT VISION GRAPH, V43, P115, DOI 10.1016/0734-189X(88)90057-6; DORI D, 1988, COMPUT VISION GRAPH, V42, P1, DOI 10.1016/0734-189X(88)90139-9; DORI D, 1995, PATTERN RECOGN LETT, V16, P377, DOI 10.1016/0167-8655(94)00105-C; DORI D, 1992, COMMUN ACM, V35, P92, DOI 10.1145/135239.135245; Dori D., 1993, Machine Vision and Applications, V6, P69, DOI 10.1007/BF01211932; Dori D., 1995, Journal of Logic and Computation, V5, P227, DOI 10.1093/logcom/5.2.227; DORI D, 1989, COMPUTER VISION GRAP, V47, P1; Haralick RM., 1992, COMPUTER ROBOT VISIO; HUNT DJ, 1988, COMPUT VISION GRAPH, V43, P221, DOI 10.1016/0734-189X(88)90062-X; ILLINGWORTH J, 1987, IEEE T PATTERN ANAL, V9, P690, DOI 10.1109/TPAMI.1987.4767964; KASTURI R, 1990, IEEE T PATTERN ANAL, V12; KIMME C, 1975, COMMUN ACM, V18, P120, DOI 10.1145/360666.360677; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; OGORMAN L, 1988, JUN P CVPR ANN ARB; OGORMAN L, 1984, IEEE T PATTERN ANAL, P280; OGORMAN L, 1988, 9TH P ICPR ROM, P116; ROSIN PL, 1989, IMAGE VISION COMPUT, V7, P109, DOI 10.1016/0262-8856(89)90004-8	22	30	33	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1995	17	11					1057	1068		10.1109/34.473231	http://dx.doi.org/10.1109/34.473231			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TD854					2022-12-18	WOS:A1995TD85400004
J	VIDAL, E; MARZAL, A; AIBAR, P				VIDAL, E; MARZAL, A; AIBAR, P			FAST COMPUTATION OF NORMALIZED EDIT DISTANCES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						NORMALIZED EDIT DISTANCE; LEVENSHTEIN DISTANCE; PATTERN RECOGNITION; STRING CORRECTION; EDITING; SPELLING CORRECTION; OPTICAL CHARACTER RECOGNITION; SPEECH RECOGNITION; FRACTIONAL PROGRAMMING; FAST ALGORITHMS		The Normalized Edit Distance (NED) between two strings X and Y is defined as the minimum quotient between the sum of weights of the edit operations required to transform X into Y and the length of the editing path corresponding to these operations. An algorithm for computing the NED has recently been introduced by Marzal and Vidal that exhibits O(mn(2)) computing complexity, where m and n are the lengths of X and Y. We propose here an algorithm that is observed to require in practice the same O(mn) computing resources as the conventional unnormalized Edit Distance algorithm does. The performance of this algorithm is illustrated through computational experiments with synthetic data, as well as with real data consisting of OCR chain-coded strings.			VIDAL, E (corresponding author), UNIV POLITECN VALENCIA,DEPT SISTEMAS INFORMAT & COMP,E-46071 VALENCIA,SPAIN.							[Anonymous], [No title captured]; DINKELBACH W, 1967, SCIENCE, V18, P492; GOPALAKRISHNAN PS, 1991, IEEE T INFORM THEORY, V37, P107, DOI 10.1109/18.61108; KITAZUME Y, 1985, IEEE T ACOUST SPEECH, V33, P1, DOI 10.1109/TASSP.1985.1164510; Marzal A., 1993, IEEE T PATTERN ANAL, V15; PALLETT D, 1987, MAR P DARPA SPEECH R, P75; PRAT F, 1994, DSICII1594 U POL VAL; RABINER LR, 1981, IEEE T COMMUN, V29, P621, DOI 10.1109/TCOM.1981.1095031; RULOT H, 1987, PATTERN RECOGN, P451; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; SNIEDOVICH M, 1993, DYNAMIC PROGRAMMING; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811	12	30	31	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1995	17	9					899	902		10.1109/34.406656	http://dx.doi.org/10.1109/34.406656			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RR989					2022-12-18	WOS:A1995RR98900007
J	WEINSHALL, D; TOMASI, C				WEINSHALL, D; TOMASI, C			LINEAR AND INCREMENTAL ACQUISITION OF INVARIANT SHAPE MODELS FROM IMAGE SEQUENCES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						STRUCTURE FROM MOTION; LINEAR RECONSTRUCTION; FACTORIZATION METHOD; AFFINE SHAPE; EUCLIDEAN SHAPE; WEAK PERSPECTIVE; GRAMIAN; AFFINE COORDINATES	MOTION; ORIENTATION	We show how to automatically acquire Euclidian shape representations of objects from noisy image sequences under weak perspective. The proposed method is linear and incremental, requiring no more than pseudoinverse. A nonlinear, but numerically sound preprocessing stage is added to improve the accuracy of the results even further. Experiments show that attention to noise and computational techniques improves the shape results substantially with respect to previous methods proposed for ideal images.	STANFORD UNIV,DEPT COMP SCI,STANFORD,CA 94305	Stanford University	WEINSHALL, D (corresponding author), HEBREW UNIV JERUSALEM,INST COMP SCI,IL-91904 JERUSALEM,ISRAEL.							BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; GRIMSON WEL, 1992, COMPUTER VISION ECCV, P291; HEEGER DJ, 1989, MIT124 MED LAB TECHN; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; KUMAR R, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P365; LAWTON DT, 1983, COMPUT VISION GRAPH, V22, P116, DOI 10.1016/0734-189X(83)90098-1; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; SAWHNEY HS, 1909, 3RD P INT C COMP VIS, P494; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tomasi C., 1991, CMUCS91132 CARN MELL; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WEINSHALL D, 1993, INT J COMPUT VISION, V10, P27, DOI 10.1007/BF01440845; WEINSHALL D, 1992, RC1854981133 IBM TJ	16	30	30	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1995	17	5					512	517		10.1109/34.391392	http://dx.doi.org/10.1109/34.391392			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QW394					2022-12-18	WOS:A1995QW39400006
J	VERBEEK, PW; VANVLIET, LJ				VERBEEK, PW; VANVLIET, LJ			ON THE LOCATION ERROR OF CURVED EDGES IN LOW-PASS FILTERED 2-D AND 3-D IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EDGE DETECTION; EDGE LOCATION; LAPLACE; 2ND DERIVATIVE IN GRADIENT DIRECTION; EDGE BIAS; LOW-PASS FILTERS; CURVED EDGES; EDGE ACCURACY; SUBPIXEL RESOLUTION; DERIVATIVES OF GAUSSIAN	INTENSITY CHANGES; GAUSSIAN MASKS; DETECTORS; ACCURACY; VISION	In our research, we study the location error of curved edges in two- and three-dimensional images after analog and digital low-pass filtering. The zero crossing of a second derivative filter is a well-known edge localization criterion. The second derivative in gradient direction (SDGD) produces a predictable bias in edge location towards the centers of curvature while the linear Laplace filter produces a shift in the opposite direction. Their sum called PLUS (PLUS = Laplace + SDGD) leads to an edge detector that finds curved edges one order more accurately than its constituents. This argument holds irrespective of the dimension. The influence of commonly used low-pass filters (such as the PSF originating from diffraction limited optics using incoherent light (2-D), the Gaussian filter with variable cutoff point (D-D), and the isotropic uniform filter (D-D)) has been studied.			VERBEEK, PW (corresponding author), DELFT UNIV TECHNOL,FAC APPL PHYS,PATTERN RECOGNIT GRP,2628 CJ DELFT,NETHERLANDS.		van Vliet, Lucas/E-1678-2012	van Vliet, Lucas/0000-0001-7018-726X				BECKERS ALD, 1986, THESIS DELFT U TECHN; BERNSEN J, 1986, 8 INT C PATT REC, P1251; BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Canny J. F., 1983, THESIS MIT CAMBRIDGE; CHEN JS, 1987, IEEE T PATTERN ANAL, V9, P584, DOI 10.1109/TPAMI.1987.4767946; CLARK JJ, 1989, IEEE T PATTERN ANAL, V11, P43, DOI 10.1109/34.23112; DICKEY FM, 1977, APPL OPTICS, V16, P145, DOI 10.1364/AO.16.000145; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; LUNSCHER WHHJ, 1986, IEEE T PATTERN ANAL, V8, P164, DOI 10.1109/TPAMI.1986.4767770; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Press W. H., 1990, NUMERICAL RECIPES C; SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275; SARKAR S, 1991, CVGIP-IMAG UNDERSTAN, V54, P224, DOI 10.1016/1049-9660(91)90065-W; TAGARE HD, 1990, IEEE T PATTERN ANAL, V12, P1186, DOI [10.1109/34.62607, 10.1117/12.19530]; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; Van Vliet LJ, 1993, THESIS DELFT U; VANVLIET LJ, 1989, COMPUT VISION GRAPH, V45, P167, DOI 10.1016/0734-189X(89)90131-X; VANVLIET LJ, 1988, PATTERN RECOGN, V7, P63; VERBEEK PW, 1985, PATTERN RECOGN LETT, V3, P287, DOI 10.1016/0167-8655(85)90009-1; Xu Z., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P601	25	30	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1994	16	7					726	733		10.1109/34.297954	http://dx.doi.org/10.1109/34.297954			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NY134		Green Submitted			2022-12-18	WOS:A1994NY13400006
J	GRAY, AJ; KAY, JW; TITTERINGTON, DM				GRAY, AJ; KAY, JW; TITTERINGTON, DM			AN EMPIRICAL-STUDY OF THE SIMULATION OF VARIOUS MODELS USED FOR IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						MARKOV RANDOM FIELD; MARKOV MESH MODEL; IMAGE PRIOR; CLUSTERING; SIMULATION	STATISTICAL-ANALYSIS; MARKOV; TEXTURES; FIELDS	Markov random fields are typically used as priors in Bayesian image restoration methods to represent spatial information in the image. Commonly used Markov random fields are not in fact capable of representing the moderate-to-large scale clustering present in naturally occurring images and can also be time consuming to simulate, requiring iterative algorithms which can take hundreds of thousands of sweeps of the image to converge. Markov mesh models, a causal subclass of Markov random fields, are, however, readily simulated. We describe an empirical study of simulated realizations from various models used in the literature, and we introduce some new mesh-type models. We conclude, however, that while large-scale clustering may be represented by such models, strong directional effects are also present for all but very limited parameterizations. It is emphasized that the results do not detract from the use of Markov random fields as representers of local spatial properties, which is their main purpose in the implementation of Bayesian statistical approaches to image analysis. Brief allusion is made to the issue of parameter estimation.	SCOTTISH AGR STAT SERV,ENVIRONM MODELLING UNIT,MACAULAY LAND USE RES INST,ABERDEEN AB9 2QJ,SCOTLAND; UNIV GLASGOW,DEPT STAT,GLASGOW G12 8QW,SCOTLAND	James Hutton Institute; University of Aberdeen; University of Glasgow	GRAY, AJ (corresponding author), UNIV STRATHCLYDE,DEPT STAT & MODELLING SCI,GLASGOW G1 1XW,SCOTLAND.		Gray, Alison/GWQ-4596-2022; Gray, Alison/L-1063-2017	Gray, Alison/0000-0002-6273-0637				ABEND K, 1965, IEEE T INFORMATION T, V4, P538; AHUJA N, 1981, IEEE T PATTERN ANAL, V3, P1, DOI 10.1109/TPAMI.1981.4767045; AHUJA N, 1981, COMPUT SURV, V13, P374; AHUJA N, 1981, IEEE T PATTERN MACHI, V13, P374; BARTLETT MS, 1975, STATISTICAL ANAL SPI; BAXTER RJ, 1972, ANN PHYS-NEW YORK, V70, P193, DOI 10.1016/0003-4916(72)90335-1; BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1993, J ROY STAT SOC B MET, V55, P25; BESAG J, 1986, J R STAT SOC B, V48, P259; CHEN CC, 1980, THESIS MICHIGAN STAT; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; DEVIJVER PA, 1989, REAL TIME MODELLING; DEVIJVER PA, 1988, 4TH INT C PATT REC C, P131; Dubes R.C., 1989, J APPL STAT, V16, P131, DOI DOI 10.1080/02664768900000014; FLINN PA, 1974, J STAT PHYS, V10, P89, DOI 10.1007/BF01011718; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRAY AJ, 1994, IN PRESS STATIST COM; Green P., 1992, LECT NOTES STATIST, V74, P142; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; Ising E, 1925, Z PHYS, V31, P253, DOI 10.1007/BF02980577; KANAL LN, 1980, COMPUT VISION GRAPH, V12, P371, DOI 10.1016/0146-664X(80)90020-9; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; NEWELL GF, 1953, REV MOD PHYS, V25, P353, DOI 10.1103/RevModPhys.25.353; Onsager L, 1944, PHYS REV, V65, P117, DOI 10.1103/PhysRev.65.117; PICKARD DK, 1980, ADV APPL PROBAB, V12, P655, DOI 10.2307/1426425; PICKARD DK, 1977, J APPL PROBAB, V14, P717, DOI 10.2307/3213345; PICKARD DK, 1978, S ADV APPL PROB, V10, P58; PICKARD DK, 1982, J AM STAT ASSOC, V82, P90; PICKARD DK, 1977, THESIS AUSTR NAT U; POSSOLO A, 1989, 77 U WASH DEP STAT; POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106, DOI 10.1017/S0305004100027419; QIAN W, 1991, SIGNAL PROCESS, V22, P313, DOI 10.1016/0165-1684(91)90018-E; QIAN W, 1991, J ROY STAT SOC B MET, V53, P661; QIAN W, 1991, PHILOS T ROY SOC A, V337, P407, DOI 10.1098/rsta.1991.0132; RIPLEY BD, 1990, J COMPUT APPL MATH, V31, P165, DOI 10.1016/0377-0427(90)90347-3; SCHACHTER B, 1979, COMPUT VISION GRAPH, V10, P95, DOI 10.1016/0146-664X(79)90044-3; SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86; VERHAGEN AMW, 1977, J CHEM PHYS, V67, P5060, DOI 10.1063/1.434730; YANG CN, 1952, PHYS REV, V85, P808, DOI 10.1103/PhysRev.85.808	41	30	30	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					507	519		10.1109/34.291447	http://dx.doi.org/10.1109/34.291447			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141					2022-12-18	WOS:A1994NP14100006
J	PENTLAND, AP				PENTLAND, AP			INTERPOLATION USING WAVELET BASES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						REGULARIZATION; WAVELET TRANSFORMS; SURFACE INTERPOLATION; VOLUME INTERPOLATION	SURFACE INTERPOLATION	Efficient solutions to regularization problems can be obtained using orthogonal wavelet bases for preconditioning. Good approximate solutions can be obtained in only two or three iterations, with each iteration requiring only O(n) operations and O(n) storage locations. Two- and three-dimensional examples are shown using both synthetic and real range data.			PENTLAND, AP (corresponding author), MIT, MEDIA LAB, PERCEPTUAL COMP SECT, CAMBRIDGE, MA 02139 USA.							ALBERT B, 1990, DCS RR837 YAL U RES; Boult T. E., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P68; BOVE M, JUN P OPT SOC AM IM, P118; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; FAUGERAS OD, 1986, IEEE T ROBOTICS  APR; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Pentland A. P., 1992, Visual Computer, V8, P303, DOI 10.1007/BF01897117; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; PENTLAND AP, MUSTERERKENNUNG 1990, V254, P171; PENTLAND AP, IN PRESS NEURAL COMP; PENTLAND AP, 1991, INVEST OPHTH VIS SCI, V32, P1197; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; SCLAROFF S, C IMPLEMENTATION WAV; SIMONCELLI EP, 1990, P IEEE, V78, P652, DOI 10.1109/5.54805; Strang Gilbert, LINEAR ALGEBRA ITS A; SZELISKI R, 1990, IEEE T PATTERN ANAL, V12, P513, DOI 10.1109/34.56188; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; WILSON HR, 1984, J OPT SOC AM A, V1, P124, DOI 10.1364/JOSAA.1.000124	21	30	32	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1994	16	4					410	414		10.1109/34.277594	http://dx.doi.org/10.1109/34.277594			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NH607					2022-12-18	WOS:A1994NH60700007
J	YESHURUN, Y; SCHWARTZ, EL				YESHURUN, Y; SCHWARTZ, EL			SHAPE-DESCRIPTION WITH A SPACE-VARIANT SENSOR - ALGORITHMS FOR SCAN-PATH, FUSION, AND CONVERGENCE OVER MULTIPLE SCANS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									NYU MED CTR,DEPT PSYCHIAT,COMPUTAT NEUROSCI LABS,NEW YORK,NY 10016; NYU,COURANT INST MATH SCI,DEPT COMP SCI,NEW YORK,NY 10012	New York University; New York University								DOW BM, 1981, EXP BRAIN RES, V44, P213; Levine M., 1985, VISION MAN MACHINE; NOTON D, 1971, VISION RES, V11, P929, DOI 10.1016/0042-6989(71)90213-6; RAYNER K, 1978, PSYCHOL BULL, V85, P618, DOI 10.1037//0033-2909.85.3.618; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; SCHWARTZ EL, 1983, P NATL ACAD SCI-BIOL, V80, P5776, DOI 10.1073/pnas.80.18.5776; SCHWARTZ EL, 1985, SCIENCE, V227, P1066; SPARKS DL, 1983, J NEUROPHYSIOL, V49, P64, DOI 10.1152/jn.1983.49.1.64; SPERRY RW, 1950, J COMP PHYSIOL PSYCH, V43, P482, DOI 10.1037/h0055479; TOOTELL RBH, 1985, SCIENCE, V227, P1066, DOI 10.1126/science.227.4690.1066; VANESSEN DC, 1984, VISION RES, V24, P429, DOI 10.1016/0042-6989(84)90041-5; WOLFSON E, 1986, CNSTR1086 NYU MED CE; WOLFSON E, 1986, CNSTR2386 NYU MED CE	14	30	31	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1217	1222		10.1109/34.42860	http://dx.doi.org/10.1109/34.42860			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796					2022-12-18	WOS:A1989AW79600009
J	HAVELOCK, DI				HAVELOCK, DI			GEOMETRIC PRECISION IN NOISE-FREE DIGITAL IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											HAVELOCK, DI (corresponding author), NATL RES COUNCIL CANADA,DIV PHYS,OTTAWA K1A 0R6,ONTARIO,CANADA.							ANDERSON TA, 1985, COMPUT VISION GRAPH, V30, P279, DOI 10.1016/0734-189X(85)90161-6; BERENSTEIN CA, 1988, IEEE T PATTERN ANAL, V10, P880, DOI 10.1109/34.9109; BERENSTEIN CA, 1987, COMPUT VISION GRAPH, V40, P334, DOI 10.1016/S0734-189X(87)80146-9; BEYER HA, 1987, JUN P INT C FAST PRO, P68; BEYER HA, 1988, 16TH C ISPRS KYOT JA; BRUCKSTEIN AM, 1987, EEE T ACOUST SPEECH, V35, P553; CHEN LH, 1988, PATTERN RECOGN, V21, P45, DOI 10.1016/0031-3203(88)90070-2; CURRY S, 1986, PHOTOGRAMM ENG REM S, V52, P627; DAHLER J, 1987, JUN P INT C FAST PRO, P48; DIJAK JT, 1985, 1985 P IEEE NAT AER, P1382; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; DORST L, 1984, IEEE T PATTERN ANAL, V6, P632, DOI 10.1109/TPAMI.1984.4767577; DORST L, 1986, IEEE T PATTERN ANAL, V8, P276, DOI 10.1109/TPAMI.1986.4767781; DORST L, 1987, COMPUT VISION GRAPH, V40, P311, DOI 10.1016/S0734-189X(87)80145-7; DVORNYCHENKO VN, 1983, IEEE T PATTERN ANAL, V5, P206, DOI 10.1109/TPAMI.1983.4767373; ELHAKIM SF, 1986, PHOTOGRAMM ENG REM S, V52, P1757; FORSTNER W, 1985, 40TH PHOT WEEK; FORSTNERW, 1982, 3 P ISPRS COMM S HEL, P176; GONSALVES RA, 1976, APPL OPTICS, V5, P1270; HAVELOCK DI, THESIS CARLETON U; HO CS, 1983, IEEE T PATTERN ANAL, V5, P593, DOI 10.1109/TPAMI.1983.4767448; KLAASMAN H, 1975, COMPUT GRAPHICS IMAG, V4, P225; LANDAU UM, 1987, COMPUT VISION GRAPH, V38, P317, DOI 10.1016/0734-189X(87)90116-2; LENZ R, 1988, 16TH C ISPRS KYOT; LENZ RK, 1988, EEE T PATT AN MACH I, V10, P713; LUHMANN T, 1987, JUNP INT C FAST PROC, P35; LYVERSEP, 1988, EEET PATTERN ANAL MA, V10, P927; MIKHAIL EM, 1985, AM SOC PHOTOGRAMM, P717; NAKAMURA A, 1984, COMPUT VISION GRAPH, V26, P242, DOI 10.1016/0734-189X(84)90187-7; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; NIELSEN L, 1984, IEEE T ACOUST SPEECH, V32, P1247, DOI 10.1109/TASSP.1984.1164442; ROSENFELD A, 1986, 1986 IEEE NT C ROB A; SRIRAMAN R, 1989, IEEE T PATTERN ANAL, V11, P95, DOI 10.1109/34.23116; TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502; THURGOOD JD, 1982, INT ARCH PHOTOGRAMME, V24, P576; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9; TYAN TW, 1982, OPT ENG, V19, P312; UNRUH JE, 1982, PHOTOGRAMM ENG REM S, V48, P1343; VOSSELMAN G, 1988, 16TH P C ISPRS INT A, V27, P148; WIDROW B, 1965, IRE T CIRCUIT THEORY, V3, P266	40	30	35	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1989	11	10					1065	1075		10.1109/34.42837	http://dx.doi.org/10.1109/34.42837			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR689					2022-12-18	WOS:A1989AR68900004
J	HUNG, SHY				HUNG, SHY			ON THE STRAIGHTNESS OF DIGITAL ARCS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											HUNG, SHY (corresponding author), NRC CANADA,DIV ELECT ENGN,OTTAWA KIA 0R8,ONTARIO,CANADA.							Arcelli C., 1975, Computer Graphics and Image Processing, V4, P339, DOI 10.1016/0146-664X(75)90003-9; ARCELLI C, 1978, COMPUT VISION GRAPH, V7, P67, DOI 10.1016/S0146-664X(78)80014-8; ARCELLI C, 1976, COMPUT GRAPHICS IMAG, V5, P289; BELLMAN R, 1961, COMMUN ACM, V4, P284, DOI 10.1145/366573.366611; BRONS R, 1974, COMPUT GRAPHICS IMAG, V3, P48; DETTORI G, 1982, 6TH P INT C PATT REC, P739; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; GLUSS B, 1962, INFORM CONTROL, V5, P261, DOI 10.1016/S0019-9958(62)90599-5; HUNG SHY, 1983, PATTERN RECOGN, V16, P297, DOI 10.1016/0031-3203(83)90035-3; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; KIM CE, 1982, COMPUT VISION GRAPH, V18, P369, DOI 10.1016/0146-664X(82)90005-3; KIM CE, 1981, IEEE T PATTERN ANAL, V3, P617, DOI 10.1109/TPAMI.1981.4767162; LEE HC, 1982, COMPUT VISION GRAPH, V18, P359, DOI 10.1016/0146-664X(82)90004-1; Lipkin BS, 1970, PICTURE PROCESSING P, P241; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PAVLIDIS T, 1973, IEEE T COMPUT, VC 22, P689, DOI 10.1109/TC.1973.5009136; Pavlidis T., 1977, STRUCTURAL PATTERN R; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; ROSENFIELD A, 1977, IEEE T COMPUT, V22, P875; SANKAR PV, 1978, COMPUT VISION GRAPH, V7, P403, DOI 10.1016/S0146-664X(78)80006-9; SHLIEN S, 1983, COMPUT VISION GRAPH, V22, P277, DOI 10.1016/0734-189X(83)90070-1; SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P260, DOI 10.1109/TC.1972.5008948; SKLANSKY J, 1980, J PATTERN RECOGNITIO, V12, P327; WU LD, 1982, IEEE T PATTERN ANAL, V4, P347, DOI 10.1109/TPAMI.1982.4767258; WU LD, 1980, 5TH P INT C PATT REC, P32	27	30	30	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	2					203	215		10.1109/TPAMI.1985.4767644	http://dx.doi.org/10.1109/TPAMI.1985.4767644			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ACP84	21869257				2022-12-18	WOS:A1985ACP8400007
J	BURR, DJ				BURR, DJ			DESIGNING A HANDWRITING READER	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											BURR, DJ (corresponding author), BELL TEL LABS INC, HOLMDEL, NJ 07733 USA.							ALDEFELD B, 1980, AT&T TECH J, V59, P1343, DOI 10.1002/j.1538-7305.1980.tb03367.x; ALLEN J, 1973, IEEE T ACOUST SPEECH, VAU21, P259, DOI 10.1109/TAU.1973.1162463; BRIDLE JS, 1973, APR P BRIT AC SOC SP, P1; BROWN RM, 1964, IEEE TRANS ELECTRON, VEC13, P750, DOI 10.1109/PGEC.1964.263937; BURR DJ, 1981, COMPUT VISION GRAPH, V15, P102, DOI 10.1016/0146-664X(81)90072-1; BURR DJ, 1982, SEP INT S PHYS BIOL; BURR DJ, 1982, 6TH P INT C PATT REC; BURR DJ, 1979, AUG P PATT REC IM PR, P271; BURR DJ, 1981, MAR P INT C AC SPEEC, P471; BURR DJ, 1980, 5 INT C PATT REC, P715; DOSTER W, 1977, IEEE T COMPUT, V26, P1090, DOI 10.1109/TC.1977.1674755; EHRICH RW, 1975, IEEE T COMPUT, VC 24, P182, DOI 10.1109/T-C.1975.224184; Fujimoto Y., 1976, 3rd International Joint Conference on Pattern Recognition, P113; HARMON LD, 1972, P IEEE, V60, P1165, DOI 10.1109/PROC.1972.8878; HAYES KC, 1980, COMPUT VISION GRAPH, V14, P344, DOI 10.1016/0146-664X(80)90025-8; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; MOORE RK, 1979, IEEE T PATTERN ANAL, V1, P86, DOI 10.1109/TPAMI.1979.4766880; PAVLIDIS T, 1975, IEEE T SYST MAN CYB, V5, P610, DOI 10.1109/TSMC.1975.4309402; RABINER LR, 1978, IEEE T ACOUST SPEECH, V26; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; YASUHARA M, 1977, IEEE T SYST MAN CYB, V7, P212	21	30	32	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					554	559		10.1109/TPAMI.1983.4767435	http://dx.doi.org/10.1109/TPAMI.1983.4767435			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RM118	21869141				2022-12-18	WOS:A1983RM11800012
J	KALAYEH, HM; LANDGREBE, DA				KALAYEH, HM; LANDGREBE, DA			PREDICTING THE REQUIRED NUMBER OF TRAINING SAMPLES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									PURDUE UNIV,ENGN EXPT STN,W LAFAYETTE,IN 47906	Purdue University System; Purdue University; Purdue University West Lafayette Campus	KALAYEH, HM (corresponding author), OBJECT RECOGNIT SYST INC,PRINCETON,NJ 08540, USA.							Anderson T.W, 1958, INTRO MULTIVARIATE S; BICKEL J, 1977, MATH STATISTICS BASI; FUKUNAGA K, 1972, INTRO STATISTICAL PA; MUASHER MA, 1981, TREE8141 SCH EL ENG; MUASHER MA, 1981, LARS101381 PURD U TE; Swain P.H., 1978, REMOTE SENSING QUANT; SWAIN PH, 1973, LARS042673 PURD U TE	7	30	30	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					664	667		10.1109/TPAMI.1983.4767459	http://dx.doi.org/10.1109/TPAMI.1983.4767459			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869156	Green Submitted			2022-12-18	WOS:A1983RV48800016
J	AKL, SG; BARNARD, DT; DORAN, RJ				AKL, SG; BARNARD, DT; DORAN, RJ			DESIGN, ANALYSIS, AND IMPLEMENTATION OF A PARALLEL TREE-SEARCH ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											AKL, SG (corresponding author), QUEENS UNIV,DEPT COMP & INFORMAT SCI,KINGSTON K7L 3N6,ONTARIO,CANADA.							BAUDET GM, 1978, CMUCS78116 CARN MELL; BERLINER HJ, 1978, ARTIF INTELL, V10, P201, DOI 10.1016/S0004-3702(78)80012-5; CHARNESS N, 1977, CHESS SKILL MAN MACH; CORAOR LD, 1976, NOV P IEEE INT S MIN, P51; FISHBURN JP, 1979, 375 U WISC COMP SCI; FLYNN MJ, 1966, PR INST ELECTR ELECT, V54, P1901, DOI 10.1109/PROC.1966.5273; JACKSON PC, 1974, INTRO ARTIFICIAL INT; KNUTH DE, 1975, ARTIF INTELL, V6, P293, DOI 10.1016/0004-3702(75)90019-3; NEWBORN MM, 1977, ARTIF INTELL, V8, P137, DOI 10.1016/0004-3702(77)90017-0; Nilsson N.J., 1980, PRINCIPLES ARTIFICAL; PRITSKER AAB, 1974, GASP 4 SIMULATION LA; SLAGLE J, 1969, J ASS COMPUTING MACH, V16, P198; STOCKMAN GC, 1979, ARTIF INTELL, V12, P179, DOI 10.1016/0004-3702(79)90016-X	13	30	30	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					192	203		10.1109/TPAMI.1982.4767226	http://dx.doi.org/10.1109/TPAMI.1982.4767226			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	NE957	21869025				2022-12-18	WOS:A1982NE95700015
J	Liu, Y; Zhang, DW; Zhang, Q; Han, JG				Liu, Yi; Zhang, Dingwen; Zhang, Qiang; Han, Jungong			Part-Object Relational Visual Saliency	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; Routing; Feature extraction; Streaming media; Training; Task analysis; Saliency detection; Salient object detection; capsule network; part-object relationships	RECOGNITION; MODEL; IMAGE; ATTENTION; EXTRACTION	Recent years have witnessed a big leap in automatic visual saliency detection attributed to advances in deep learning, especially Convolutional Neural Networks (CNNs). However, inferring the saliency of each image part separately, as was adopted by most CNNs methods, inevitably leads to an incomplete segmentation of the salient object. In this paper, we describe how to use the property of part-object relations endowed by the Capsule Network (CapsNet) to solve the problems that fundamentally hinge on relational inference for visual saliency detection. Concretely, we put in place a two-stream strategy, termed Two-Stream Part-Object RelaTional Network (TSPORTNet), to implement CapsNet, aiming to reduce both the network complexity and the possible redundancy during capsule routing. Additionally, taking into account the correlations of capsule types from the preceding training images, a correlation-aware capsule routing algorithm is developed for more accurate capsule assignments at the training stage, which also speeds up the training dramatically. By exploring part-object relationships, TSPORTNet produces a capsule wholeness map, which in turn aids multi-level features in generating the final saliency map. Experimental results on five widely-used benchmarks show that our framework consistently achieves state-of-the-art performance. The code can be found on https://github.com/liuyi1989/TSPORTNet.	[Liu, Yi; Zhang, Dingwen; Zhang, Qiang] Xidian Univ, Sch Mechanoelect Engn, Xian 710126, Shaanxi, Peoples R China; [Han, Jungong] Aberystwyth Univ, Dept Comp Sci, Aberystwyth SY23 3FL, Dyfed, Wales	Xidian University; Aberystwyth University	Zhang, Q (corresponding author), Xidian Univ, Sch Mechanoelect Engn, Xian 710126, Shaanxi, Peoples R China.; Han, JG (corresponding author), Aberystwyth Univ, Dept Comp Sci, Aberystwyth SY23 3FL, Dyfed, Wales.	liuyi0089@gmail.com; zdw@xidian.edu.cn; qzhang@xidian.edu.cn; jungong.han@aber.ac.uk			National Natural Science Foundation of China [62001341, 61773301, 61876140]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China under Grants 62001341, 61773301, and 61876140.	Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]; Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Ba J., 2017, P 3 INT C LEARN REPR; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399; Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667; Cheng MM, 2017, J COMPUT SCI TECH-CH, V32, P110, DOI 10.1007/s11390-017-1681-7; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601; Cong RM, 2018, IEEE T IMAGE PROCESS, V27, P568, DOI 10.1109/TIP.2017.2763819; Duarte K, 2018, ADV NEUR IN, V31; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487; Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698; Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906; Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172; Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502; Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641; Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969; Guo JF, 2017, IEEE INT CON MULTI, P325, DOI 10.1109/ICME.2017.8019389; Han JG, 2013, NEUROCOMPUTING, V111, P70, DOI 10.1016/j.neucom.2012.12.015; Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028; Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6; Hinton Geoffrey E., 2018, INT C LEARN REPR; Hu P, 2017, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.2017.65; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jaklic A, 2000, SEGMENTATION RECOVER; Jaklic A., 1997, THESIS U LJUBLJANA L; Juttner M, 1996, BIOL CYBERN, V74, P521, DOI 10.1007/BF00209423; Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122; Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499; Krivic J, 2004, COMPUT VIS IMAGE UND, V95, P105, DOI 10.1016/j.cviu.2003.11.002; Lee G, 2018, IEEE T PATTERN ANAL, V40, P1599, DOI 10.1109/TPAMI.2017.2737631; Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184; Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158; Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404; Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Liu Y, 2020, IEEE T IMAGE PROCESS, V29, P360, DOI 10.1109/TIP.2019.2930906; Liu Y, 2019, IEEE T CIRC SYST VID, V29, P1023, DOI 10.1109/TCSVT.2018.2823769; Liu Y, 2018, IMAGE VISION COMPUT, V69, P155, DOI 10.1016/j.imavis.2017.10.002; Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198; Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698; Oh SJ, 2017, PROC CVPR IEEE, P5038, DOI 10.1109/CVPR.2017.535; Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766; Rutishauser U, 2004, PROC CVPR IEEE, P37; Sabour S, 2017, ADV NEUR IN, V30; Simonyan Karen, 2015, INT C LEARN REPR; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256; Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683; Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404; Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938; Wang P, 2015, IEEE I CONF COMP VIS, P1573, DOI 10.1109/ICCV.2015.184; Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403; Xia CQ, 2017, PROC CVPR IEEE, P4399, DOI 10.1109/CVPR.2017.468; Xu YY, 2019, IEEE I CONF COMP VIS, P3788, DOI 10.1109/ICCV.2019.00389; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yu F., 2016, INT C LEARN REPRESEN; Zeng Y, 2019, IEEE I CONF COMP VIS, P7233, DOI 10.1109/ICCV.2019.00733; Zhang LH, 2020, IEEE T IMAGE PROCESS, V29, P3534, DOI 10.1109/TIP.2019.2962688; Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187; Zhang PP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1149; Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31; Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zhao W., 2018, EMNLP; Zhao YF, 2021, IEEE T PATTERN ANAL, V43, P1636, DOI 10.1109/TPAMI.2019.2953854	79	29	29	15	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3688	3704		10.1109/TPAMI.2021.3053577	http://dx.doi.org/10.1109/TPAMI.2021.3053577			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33481705	Green Submitted			2022-12-18	WOS:000805820500026
J	Xia, SY; Peng, DW; Meng, DY; Zhang, CQ; Wang, GY; Giem, E; Wei, W; Chen, ZZ				Xia, Shuyin; Peng, Daowan; Meng, Deyu; Zhang, Changqing; Wang, Guoyin; Giem, Elisabeth; Wei, Wei; Chen, Zizhong			Ball k-Means: Fast Adaptive Clustering With No Bounds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Ball k-means; k-means; ball cluster; stable area; active area; neighbor cluster	EFFICIENT	This paper presents a novel accelerated exact k-means called as "Ball k-means" by using the ball to describe each cluster, which focus on reducing the point-centroid distance computation. The "Ball k-means" can exactly find its neighbor clusters for each cluster, resulting distance computations only between a point and its neighbor clusters' centroids instead of all centroids. What's more, each cluster can be divided into "stable area" and "active area", and the latter one is further divided into some exact "annular area". The assignment of the points in the "stable area" is not changed while the points in each "annular area" will be adjusted within a few neighbor clusters. There are no upper or lower bounds in the whole process. Moreover, ball k-means uses ball clusters and neighbor searching along with multiple novel stratagems for reducing centroid distance computations. In comparison with the current state-of-the art accelerated exact bounded methods, the Yinyang algorithm and the Exponion algorithm, as well as other top-of-the-line tree-based and bounded methods, the ball k-means attains both higher performance and performs fewer distance calculations, especially for large-k problems. The faster speed, no extra parameters and simpler design of "Ball k-means" make it an all-around replacement of the naive k-means.	[Xia, Shuyin; Peng, Daowan; Wang, Guoyin] Chongqing Univ Posts & Telecommun, Dept Chongqing Key Lab Computat Intelligence, Chongqing 400065, Peoples R China; [Meng, Deyu] Macau Univ Sci & Technol, Macau Inst Syst Engn, Taipa, Macau, Peoples R China; [Meng, Deyu] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China; [Zhang, Changqing] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China; [Giem, Elisabeth; Chen, Zizhong] Univ Calif Riverside, Dept Comp Sci & Engn, 900 Univ Ave, Riverside, CA 92521 USA; [Wei, Wei] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China	Chongqing University of Posts & Telecommunications; Macau University of Science & Technology; Xi'an Jiaotong University; Tianjin University; University of California System; University of California Riverside; Xi'an University of Technology	Xia, SY; Wang, GY (corresponding author), Chongqing Univ Posts & Telecommun, Dept Chongqing Key Lab Computat Intelligence, Chongqing 400065, Peoples R China.	xiasy@cqupt.edu.cn; daowan_peng@qq.com; dymeng@xjtu.edu.cn; zhangchangqing@tju.edu.cn; wanggy@cqupt.edu.cn; chen@cs.ucr.edu; weiwei@xaut.edu.cn; gieme01@ucr.edu			National Natural Science Foundation of China [61806030, 61936001, 11690011, 61721002, U1811461]; Natural Science Foundation of Chongqing [cstc2019jcyj-msxmX0485, cstc2019jcyj-cxttX0002]; National Key Research and Development Program of China [2019QY(Y)0301, 2016QY01W0200]; NICE: NRT for Integrated Computational Entomology, US National Natural Science [1631776]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Chongqing(Natural Science Foundation of Chongqing); National Key Research and Development Program of China; NICE: NRT for Integrated Computational Entomology, US National Natural Science	The authors greatly thank the handling associate editor and all anonymous reviewers for their valuable comments. This work was supported in part by the National Natural Science Foundation of China under Grant Nos. 61806030, 61936001, 11690011, 61721002, and U1811461, the Natural Science Foundation of Chongqing Nos. cstc2019jcyj-msxmX0485 and cstc2019jcyj-cxttX0002, the National Key Research and Development Program of China under Grant Nos. 2019QY(Y)0301 and 2016QY01W0200, and NICE: NRT for Integrated Computational Entomology, US National Natural Science award 1631776.	Aloise D, 2009, MACH LEARN, V75, P245, DOI 10.1007/s10994-009-5103-0; Andrew M, 2013, ARXIV13013877; Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027; Bachem O., 2016, ADV NEURAL INFORM PR, V29, P55; Bachem O, 2016, AAAI CONF ARTIF INTE, P1459; Bradley P. S., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P91; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Curtin R. R., 2017, P 2017 SIAM INT C DA, P300; Deng CH, 2018, PROC INT CONF DATA, P1220, DOI 10.1109/ICDE.2018.00115; Dheeru D., 2019, UCI MACHINE LEARNING; Ding YF, 2015, PR MACH LEARN RES, V37, P579; Elkan C., 2003, P 20 INT C MACHINE L, V20, P147, DOI DOI 10.1016/0026-2714(92)90278-S; Fahim A., 2006, J ZHEJIANG U SCI A, V7, P1626, DOI 10.1631/jzus.2006.A1626; Franti P, 2018, APPL INTELL, V48, P4743, DOI 10.1007/s10489-018-1238-7; Hamerly G, 2010, P 2010 SIAM INT C DA, V2010, P130, DOI DOI 10.1137/1.9781611972801.12; Hamerly G., 2015, PARTITIONAL CLUSTERI, P41, DOI [10.1007/978-3-319-09259-1_2, DOI 10.1007/978-3-319-09259-1_2]; Hu QH, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2099, DOI 10.1145/3132847.3133091; JANCEY RC, 1966, AUST J BOT, V14, P127, DOI 10.1071/BT9660127; Jonathan D, 2013, FASTER K MEANS CLUST; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; KHANDELWAL S, 2017, P EUR C INF RETR, P520; Kriegel H. P., 2008, P 14 ACM SIGKDD INT, P444, DOI [10.1145/1401890.1401946, DOI 10.1145/1401890.1401946]; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Martinez-Rebollar C, 2019, INTRO DATA SCI MACH; NEWLING J, 2017, PROC INT C NEURAL IN, P5195; Newling J, 2016, PR MACH LEARN RES, V48; Ng R. T., 1994, P VLDB, P144; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Pelleg D., 1999, PROC 5 ACM SIGKDD IN, P277, DOI [10.1145/312129.312248, DOI 10.1145/312129.312248]; Pereira JC, 2013, J NEUROSCI RURAL PRA, V4, P1, DOI 10.4103/0976-3147.105598; Ortega JP, 2018, INT J COMB OPTIM PRO, V9, P3; Pfender Florian, 2004, NOT AM MATH SOC, V51, P873; Philbin J, 2010, ANN ZOOL ECOL ANIM, V93, pE70; Rysavy P., 2016, P 2016 SIAM INT C DA, P324; Sculley D., 2010, P 19 INT C WORLD WID, P1177, DOI [10.1145/1772690.1772862, DOI 10.1145/1772690.1772862]; TSAI CK, 2007, P IEEE INT C SYST MA, P504; Verleysen M, 2005, LECT NOTES COMPUT SC, V3512, P758; Wang J, 2012, PROC CVPR IEEE, P3037, DOI 10.1109/CVPR.2012.6248034; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Xia SY, 2019, INFORM SCIENCES, V483, P136, DOI 10.1016/j.ins.2019.01.010	40	29	33	43	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					87	99		10.1109/TPAMI.2020.3008694	http://dx.doi.org/10.1109/TPAMI.2020.3008694			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750814				2022-12-18	WOS:000728561300008
J	Zhu, LC; Yang, Y				Zhu, Linchao; Yang, Yi			Label Independent Memory for Semi-Supervised Few-Shot Video Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Few-shot video classification; semi-supervised learning; memory-augmented neural networks; compound memory networks		In this paper, we propose to leverage freely available unlabeled video data to facilitate few-shot video classification. In this semi-supervised few-shot video classification task, millions of unlabeled data are available for each episode during training. These videos can be extremely imbalanced, while they have profound visual and motion dynamics. To tackle the semi-supervised few-shot video classification problem, we make the following contributions. First, we propose a label independent memory (LIM) to cache label related features, which enables a similarity search over a large set of videos. LIM produces a class prototype for few-shot training. This prototype is an aggregated embedding for each class, which is more robust to noisy video features. Second, we integrate a multi-modality compound memory network to capture both RGB and flow information. We propose to store the RGB and flow representation in two separate memory networks, but they are jointly optimized via a unified loss. In this way, mutual communications between the two modalities are leveraged to achieve better classification performance. Third, we conduct extensive experiments on the few-shot Kinetics-100, Something-Something-100 datasets, which validates the effectiveness of leveraging the accessible unlabeled data for few-shot classification.	[Zhu, Linchao; Yang, Yi] Univ Technol Sydney, Ultimo, NSW 2007, Australia	University of Technology Sydney	Yang, Y (corresponding author), Univ Technol Sydney, Ultimo, NSW 2007, Australia.	linchao.zhu@uts.edu.au; yi.yang@uts.edu.au	Yang, Yi/B-9273-2017; yang, yang/HGT-7999-2022	Yang, Yi/0000-0002-0512-880X; 	ARC [DP200100938]	ARC(Australian Research Council)	This work was partially supported by ARC DP200100938.	Abadi Martin, 2016, arXiv; Abu-El-Haija S, 2016, YOUTUBE 8M LARGE SCA; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Finn C, 2017, PR MACH LEARN RES, V70; Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459; Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337; Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hsu K., 2019, P INT C LEARN REPR; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Kaidi Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10615, DOI 10.1109/CVPR42600.2020.01063; Kay W., KINETICS HUMAN ACTIO; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Laine Samuli, 2017, P INT C LEARN REPR I, P3; Lake Brenden, 2011, C COGN SCI SOC, P6; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Li XZ, 2019, ADV NEUR IN, V32; Lin Z., 2017, ARXIV PREPRINT ARXIV; Miller EG, 2000, PROC CVPR IEEE, P464, DOI 10.1109/CVPR.2000.855856; Raffel C.A., 2019, ADV NEURAL INFORM PR, P5049; Ren M., 2018, ICLR; Roy, 2017, P INT C LEARN REPR; Santoro A, 2016, PR MACH LEARN RES, V48; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Simonyan K., 2014, 3 INT C LEARN REPR I; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Sivic, 2017, LEARNABLE POOLING CO, V1706; Snell J., 2017, ADV NEURAL INFORM PR, P4077; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tarvainen Antti, 2017, CORR, Vabs/1703; Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675; Vaswani A, 2017, ADV NEUR IN, V30; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Vinyals O., 2016, ADV NEURAL INFORM PR, P3637, DOI [10.48550/arXiv.1606.04080, DOI 10.5555/3157382.3157504]; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Weston Jason, 2015, P INT C LEARN REPR; Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19; Yang Y., 2018, P INT C LEARN REPR; Yeung S, 2018, INT J COMPUT VISION, V126, P375, DOI 10.1007/s11263-017-1013-y; Zhang H., 2018, 6 INT C LEARNING REP, DOI 10.48550/arXiv.1710.09412; Zhu LC, 2018, LECT NOTES COMPUT SC, V11211, P782, DOI 10.1007/978-3-030-01234-2_46; Zhu LC, 2017, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2017.147; Zhu Linchao, 2020, P IEEE CVF C COMP VI, P8746, DOI DOI 10.1109/CVPR42600.2020.00877	50	29	29	26	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					273	285		10.1109/TPAMI.2020.3007511	http://dx.doi.org/10.1109/TPAMI.2020.3007511			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750804				2022-12-18	WOS:000728561300020
J	Roffo, G; Melzi, S; Castellani, U; Vinciarelli, A; Cristani, M				Roffo, Giorgio; Melzi, Simone; Castellani, Umberto; Vinciarelli, Alessandro; Cristani, Marco			Infinite Feature Selection: A Graph-based Feature Filtering Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Mutual information; Redundancy; Markov processes; Computational complexity; Correlation; Laplace equations; Feature selection; filter methods; markov chains	MUTUAL INFORMATION; GENE SELECTION; MICROARRAY DATA; CANCER; CLASSIFICATION	We propose a filtering feature selection framework that considers subsets of features as paths in a graph, where a node is a feature and an edge indicates pairwise (customizable) relations among features, dealing with relevance and redundancy principles. By two different interpretations (exploiting properties of power series of matrices and relying on Markov chains fundamentals) we can evaluate the values of paths (i.e., feature subsets) of arbitrary lengths, eventually go to infinite, from which we dub our framework Infinite Feature Selection (Inf-FS). Going to infinite allows to constrain the computational complexity of the selection process, and to rank the features in an elegant way, that is, considering the value of any path (subset) containing a particular feature. We also propose a simple unsupervised strategy to cut the ranking, so providing the subset of features to keep. In the experiments, we analyze diverse settings with heterogeneous features, for a total of 11 benchmarks, comparing against 18 widely-known comparative approaches. The results show that Inf-FS behaves better in almost any situation, that is, when the number of features to keep are fixed a priori, or when the decision of the subset cardinality is part of the process.	[Roffo, Giorgio; Vinciarelli, Alessandro] Univ Glasgow, Sch Comp Sci, Glasgow G12 8QQ, Lanark, Scotland; [Melzi, Simone; Castellani, Umberto; Cristani, Marco] Univ Verona, Dept Comp Sci, I-37129 Verona, Italy; [Cristani, Marco] Inst Cognit Sci & Technol ISTC, I-00185 Rome, Italy	University of Glasgow; University of Verona; Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienze e Tecnologie della Cognizione (ISTC-CNR)	Roffo, G (corresponding author), Univ Glasgow, Sch Comp Sci, Glasgow G12 8QQ, Lanark, Scotland.	Giorgio.Roffo@glasgow.ac.uk; simone.melzi@univr.it; umberto.castellani@univr.it; Alessandro.Vinciarelli@glasgow.ac.uk; marco.cristani@univr.it	Melzi, Simone/AFI-2491-2022; Vinciarelli, Alessandro/C-1651-2012	Melzi, Simone/0000-0003-2790-9591; CRISTANI, Marco/0000-0002-0523-6042; Vinciarelli, Alessandro/0000-0002-9048-0524	Engineering and Physical Sciences Research Council (EPSRC) [EP/N035305/1]; Italian Ministry of Education, Universities and Research (MIUR) "Dipartimenti di Eccellenza 2018-2022"	Engineering and Physical Sciences Research Council (EPSRC)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Italian Ministry of Education, Universities and Research (MIUR) "Dipartimenti di Eccellenza 2018-2022"(Ministry of Education, Universities and Research (MIUR))	This work was supported in part by the Engineering and Physical Sciences Research Council (EPSRC) under grant EP/N035305/1, and the project of the Italian Ministry of Education, Universities and Research (MIUR) "Dipartimenti di Eccellenza 2018-2022".	Al-khafaji SL, 2018, IEEE T IMAGE PROCESS, V27, P837, DOI 10.1109/TIP.2017.2749145; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2007, GINA DIGIT RECOGNITI; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bergshoeff E, 1996, CLASSICAL QUANTUM GR, V13, P1; Bolon-Canedo V, 2014, INFORM SCIENCES, V282, P111, DOI 10.1016/j.ins.2014.05.042; Bradley P. S., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P82; Cai D., 2010, P ACM SIGKDD INT C K, P333, DOI 10.1145/1835804.1835848; Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024; Chen WQ, 2016, SIAM J SCI COMPUT, V38, pB570, DOI 10.1137/140988875; Comaniciu D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P438, DOI 10.1109/ICCV.2001.937550; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Denil Misha, 2013, NIPS, DOI DOI 10.5555/2999792.2999852; Dernoncourt D, 2014, COMPUT STAT DATA AN, V71, P681, DOI 10.1016/j.csda.2013.07.012; Du L, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P209, DOI 10.1145/2783258.2783345; Duan L, 2012, IEEE T IND INFORM, V8, P679, DOI 10.1109/TII.2012.2188804; Duda R.O., 2000, PATTERN CLASSIFICATI; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Estevez PA, 2009, IEEE T NEURAL NETWOR, V20, P189, DOI 10.1109/TNN.2008.2005601; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; Gu Q., 2010, 27 C UNC ART INT UAI; Guo J, 2018, AAAI CONF ARTIF INTE, P2232; Guo J, 2017, IEEE INT CON MULTI, P1213, DOI 10.1109/ICME.2017.8019357; Guyon, 2004, ADV NEURAL INF PROCE, V17, P545; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616; Guyon I., 2003, NIPS 2003 WORKSH FEA; Guyon I, 2007, PATTERN RECOGN LETT, V28, P1438, DOI 10.1016/j.patrec.2007.02.014; He X., 2005, P ADV NEUR INF PROC, P507; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Horn R.A., 2013, MATRIX ANAL, VSecond; Hubbard J. H., 2001, VECTOR CALCULUS LINE; Jakulin A, 2005, THESIS U LJUBLJANI L; Kemeny J. G., 1976, MARKOV CHAINS; LeCun Y., 2010, MNIST HANDWRITTEN DI; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lin DH, 2006, LECT NOTES COMPUT SC, V3951, P68; Liu H, 2008, CH CRC DATA MIN KNOW, P3; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Pal M, 2010, IEEE T GEOSCI REMOTE, V48, P2297, DOI 10.1109/TGRS.2009.2039484; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Powers J., 2015, MATH METHODS ENG; Roffo Giorgio, 2017, New Frontiers in Mining Complex Patterns. 5th International Workshop, NFMCP 2016, held in conjunction with ECML-PKDD 2016. Revised Selected Papers: LNAI 10312, P19, DOI 10.1007/978-3-319-61461-8_2; Roffo G, 2016, P NEW FRONT MIN COMP; Roffo G, 2017, IEEE I CONF COMP VIS, P1407, DOI 10.1109/ICCV.2017.156; Roffo G, 2015, IEEE I CONF COMP VIS, P4202, DOI 10.1109/ICCV.2015.478; Scibelli F, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6842; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Suzuki T, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-S1-S52; Tang YC, 2007, IEEE ACM T COMPUT BI, V4, P365, DOI 10.1109/TCBB.2007.1028; van de Geer SA, 2008, ANN STAT, V36, P614, DOI 10.1214/009053607000000929; van Rooyen B, 2015, ADV NEUR IN, V28; Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007; Wang J, 2017, IEEE T KNOWL DATA EN, V29, P828, DOI 10.1109/TKDE.2017.2650906; Weston J., 2003, Journal of Machine Learning Research, V3, P1439, DOI 10.1162/153244303322753751; Yang HH, 2000, ADV NEUR IN, V12, P687; Yang Y., 2011, P 22 INT JOINT C ART, P1589, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-267; Yousef M, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-144; Yu L, 2012, IEEE ACM T COMPUT BI, V9, P262, DOI 10.1109/TCBB.2011.47; Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958; Yuan XT, 2018, J MACH LEARN RES, V18; Yuan XT, 2014, PR MACH LEARN RES, V32, P127; Zaffalon M, 2002, P 18 INT C UNC ART I, P577; Zeng H, 2011, IEEE T PATTERN ANAL, V33, P1532, DOI 10.1109/TPAMI.2010.215; ZHOU SL, 2019, ARXIV190102763	74	29	30	15	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4396	4410		10.1109/TPAMI.2020.3002843	http://dx.doi.org/10.1109/TPAMI.2020.3002843			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	32750789	Green Accepted, Green Published, Green Submitted			2022-12-18	WOS:000714203900018
J	Kosti, R; Alvarez, JM; Recasens, A; Lapedriza, A				Kosti, Ronak; Alvarez, Jose M.; Recasens, Adria; Lapedriza, Agata			Context Based Emotion Recognition Using EMOTIC Dataset	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Emotion recognition; Databases; Face; Face recognition; Observers; Computer vision; Emotion recognition; affective computing; pattern recognition	FACIAL EXPRESSIONS; BODY; FACE	In our everyday lives and social interactions we often try to perceive the emotional states of people. There has been a lot of research in providing machines with a similar capacity of recognizing emotions. From a computer vision perspective, most of the previous efforts have been focusing in analyzing the facial expressions and, in some cases, also the body pose. Some of these methods work remarkably well in specific settings. However, their performance is limited in natural, unconstrained environments. Psychological studies show that the scene context, in addition to facial expression and body pose, provides important information to our perception of people's emotions. However, the processing of the context for automatic emotion recognition has not been explored in depth, partly due to the lack of proper data. In this paper we present EMOTIC, a dataset of images of people in a diverse set of natural situations, annotated with their apparent emotion. The EMOTIC dataset combines two different types of emotion representation: (1) a set of 26 discrete categories, and (2) the continuous dimensions Valence, Arousal, and Dominance. We also present a detailed statistical and algorithmic analysis of the dataset along with annotators' agreement analysis. Using the EMOTIC dataset we train different CNN models for emotion recognition, combining the information of the bounding box containing the person with the contextual information extracted from the scene. Our results show how scene context provides important information to automatically recognize emotional states and motivate further research in this direction.	[Kosti, Ronak; Lapedriza, Agata] Univ Oberta Catalunya, Barcelona 08018, Spain; [Recasens, Adria] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Alvarez, Jose M.] NVIDIA, Santa Clara, CA 95051 USA	UOC Universitat Oberta de Catalunya; Massachusetts Institute of Technology (MIT); Nvidia Corporation	Kosti, R (corresponding author), Univ Oberta Catalunya, Barcelona 08018, Spain.	rkosti@uoc.edu; jalvarez.research@gmail.com; recasens@mit.edu; alapedriza@uoc.edu		KOSTI, RONAK/0000-0003-2453-7876; Lapedriza, Agata/0000-0002-5248-0443	Ministerio de Economia, Industria y Competitividad (Spain) [TIN2015-66951-C2-2-R, RTI2018-095232-B-C22]; Innovation and Universities (FEDER funds)	Ministerio de Economia, Industria y Competitividad (Spain)(Spanish Government); Innovation and Universities (FEDER funds)	This work has been partially supported by the Ministerio de Economia, Industria y Competitividad (Spain), under the Grants Ref. TIN2015-66951-C2-2-R and RTI2018-095232-B-C22, and by Innovation and Universities (FEDER funds). The authors also thank NVIDIA for their generous hardware donations. Project Page: http://sunai.uoc.edu/emotic/	Alvarez J., 2016, CORR, P1; [Anonymous], 2017, CORR; Aviezer H, 2008, PSYCHOL SCI, V19, P724, DOI 10.1111/j.1467-9280.2008.02148.x; Banziger T., 2006, P LREC, P15; Barrett LF, 2011, CURR DIR PSYCHOL SCI, V20, P286, DOI 10.1177/0963721411422522; Barrett Lisa Feldman, 2017, EMOTIONS ARE MADE SE; Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600; Borth Damian, 2013, ACM MM; Caruana Rich, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P163, DOI 10.1007/978-3-642-35289-8_12; Chen T., 2014, ARXIV14108586; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dhall A., 2012, ASIAN C COMPUTER VIS, P613; Dhall A, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P427, DOI 10.1145/2993148.2997638; Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26; Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111; EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377; EKMAN P, 1976, ENVIRON PSYCH NONVER, V1, P56, DOI 10.1007/BF01115465; Fernandez-Abascal E. G., 2010, PSICOLOGIA EMOCION; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Groen Y, 2015, J AUTISM DEV DISORD, V45, P2848, DOI 10.1007/s10803-015-2448-z; Kleinsmith A, 2007, LECT NOTES COMPUT SC, V4738, P48, DOI 10.1007/978-3-540-74889-2_5; Kleinsmith A, 2011, IEEE T SYST MAN CY B, V41, P1027, DOI 10.1109/TSMCB.2010.2103557; Kosti R, 2017, IEEE COMPUT SOC CONF, P2309, DOI 10.1109/CVPRW.2017.285; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li ZS, 2009, IEEE SYS MAN CYBERN, P1353, DOI 10.1109/ICSMC.2009.5346254; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Masuda T, 2008, J PERS SOC PSYCHOL, V94, P365, DOI 10.1037/0022-3514.94.3.365; MEHRABIAN A, 1995, GENET SOC GEN PSYCH, V121, P339; Mou WX, 2015, IEEE INT CONF AUTOMA; Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9; Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2; Patterson G, 2016, LECT NOTES COMPUT SC, V9910, P85, DOI 10.1007/978-3-319-46466-4_6; Picard Rosalind W., 1997, AFFECTIVE COMPUTING; Righart R, 2008, SOC COGN AFFECT NEUR, V3, P270, DOI 10.1093/scan/nsn021; Schindler K, 2008, NEURAL NETWORKS, V21, P1238, DOI 10.1016/j.neunet.2008.05.003; Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tracy JL, 2009, EMOTION, V9, P554, DOI 10.1037/a0015766; Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009	40	29	31	8	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2755	2766		10.1109/TPAMI.2019.2916866	http://dx.doi.org/10.1109/TPAMI.2019.2916866			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	NX0AD	31095475	Green Submitted			2022-12-18	WOS:000575381000002
J	Martel, JNP; Muller, LK; Carey, SJ; Dudek, P; Wetzstein, G				Martel, Julien N. P.; Mueller, Lorenz K.; Carey, Stephen J.; Dudek, Piotr; Wetzstein, Gordon			Neural Sensors: Learning Pixel Exposures for HDR Imaging and Video Compressive Sensing With Programmable Sensors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optical sensors; Image sensors; Image coding; High-speed optical techniques; Optical imaging; High-dynamic range imaging; video compressive sensing; high-speed imaging; programmable sensors; vision chip; deep neural networks; end-to-end optimization	NETWORKS; CHIP	Camera sensors rely on global or rolling shutter functions to expose an image. This fixed function approach severely limits the sensors' ability to capture high-dynamic-range (HDR) scenes and resolve high-speed dynamics. Spatially varying pixel exposures have been introduced as a powerful computational photography approach to optically encode irradiance on a sensor and computationally recover additional information of a scene, but existing approaches rely on heuristic coding schemes and bulky spatial light modulators to optically implement these exposure functions. Here, we introduce neural sensors as a methodology to optimize per-pixel shutter functions jointly with a differentiable image processing method, such as a neural network, in an end-to-end fashion. Moreover, we demonstrate how to leverage emerging programmable and re-configurable sensor-processors to implement the optimized exposure functions directly on the sensor. Our system takes specific limitations of the sensor into account to optimize physically feasible optical codes and we evaluate its performance for snapshot HDR and high-speed compressive imaging both in simulation and experimentally with real scenes.	[Martel, Julien N. P.; Wetzstein, Gordon] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA; [Mueller, Lorenz K.] IBM Res Zurich, CH-8803 Ruschlikon, ZH, Switzerland; [Carey, Stephen J.; Dudek, Piotr] Univ Manchester, Sch Elect & Elect Engn, Manchester M13 9PL, Lancs, England	Stanford University; International Business Machines (IBM); University of Manchester	Martel, JNP (corresponding author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.	jnmartel@stanford.edu; lorenz.k.mueller@gmail.com; stephen.carey@manchester.ac.uk; p.dudek@manchester.ac.uk; gordon.wetzstein@stanford.edu	Martel, Julien/AAX-1449-2020	Wetzstein, Gordon/0000-0002-9243-6885	Swiss National Foundation (SNF) Fellowship [P2EZP2_181817]; NSF CAREER Award [IIS 1553333]; Sloan Fellowship; KAUST Office of Sponsored Research through the Visual Computing Center CCF grant; PECASE by the ARL; EPSRC [EP/M019284/1] Funding Source: UKRI	Swiss National Foundation (SNF) Fellowship(Swiss National Science Foundation (SNSF)); NSF CAREER Award(National Science Foundation (NSF)NSF - Office of the Director (OD)); Sloan Fellowship(Alfred P. Sloan Foundation); KAUST Office of Sponsored Research through the Visual Computing Center CCF grant; PECASE by the ARL; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors would like to thank Greg Zaal for the access to his repository of HDR images (http://hdrihaven.com), used in their experiments. The work of J.N.P.M. was supported by a Swiss National Foundation (SNF) Fellowship (P2EZP2_181817), thework of G.W. was supported by an NSF CAREER Award (IIS 1553333), a Sloan Fellowship, by the KAUST Office of Sponsored Research through the Visual Computing Center CCF grant, and a PECASE by the ARL.	AKAHANE N, 2006, 2006 IEEE INT SOL ST, P01161; Alghamdi MS, 2020, DEV NEUROREHABIL, V23, P166, DOI 10.1080/17518423.2019.1616844; Antipa N, 2019, IEEE INT CONF COMPUT; Baraniuk RG, 2017, IEEE SIGNAL PROC MAG, V34, P52, DOI 10.1109/MSP.2016.2602099; Bose L, 2017, IEEE I CONF COMP VIS, P4614, DOI 10.1109/ICCV.2017.493; Carey Stephen J., 2013, 2013 Symposium on VLSI Circuits, pC182; Chakrabarti Ayan, 2016, ADV NEURAL INFORM PR, P3081; Chang J, 2019, IEEE I CONF COMP VIS, P10192, DOI 10.1109/ICCV.2019.01029; Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y; Chen Jianing, 2017, IEEE RSJ INT C INT R; Dadkhah M, 2013, SENSORS-BASEL, V13, P4961, DOI 10.3390/s130404961; Dudek P, 2006, 2006 INTERNATIONAL WORKSHOP ON COMPUTER ARCHITECTURE FOR MACHINE PERCEPTION AND SENSING, P1; Eklund JE, 1996, IEEE T VLSI SYST, V4, P322, DOI 10.1109/92.532033; Fernandez-Berni J, 2014, ELECTRON LETT, V50, P1832, DOI 10.1049/el.2014.3136; Fernandez-Berni J., 2012, LOW POWER SMART IMAG, P67; Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI 10.1109/ICCV.2017.129; Gu J, 2010, PROCEEDINGS OF 2010 INTERNATIONAL SYMPOSIUM ON CONSTRUCTION ECONOMY AND MANAGEMENT (ISCEM2010), P16; Hajisharif S, 2015, EURASIP J IMAGE VIDE, P1, DOI 10.1186/s13640-015-0095-0; Hasinoff S. W., 2009, IEEE T PATTERN ANAL, V1, P1; Hasinoff SW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980254; Hitomi Y, 2011, IEEE I CONF COMP VIS, P287, DOI 10.1109/ICCV.2011.6126254; Holloway J., 2012, P IEEE INT C COMP PH, P1; Hubara I, 2016, ADV NEUR IN, V29; Iliadis M, 2020, DIGIT SIGNAL PROCESS, V96, DOI 10.1016/j.dsp.2019.102591; Iliadis M, 2018, DIGIT SIGNAL PROCESS, V72, P9, DOI 10.1016/j.dsp.2017.09.010; Ioualalen A, 2017, IEEE INT SYMP SOFTW, P1, DOI 10.1109/ISSREW.2017.40; Ishikawa M., 1999, 1999 IEEE International Solid-State Circuits Conference. Digest of Technical Papers. ISSCC. First Edition (Cat. No.99CH36278), P206, DOI 10.1109/ISSCC.1999.759195; Kingma D.P, P 3 INT C LEARNING R; Lenero-Bardallo J. A., 2015, 22 EUR C CIRC THEOR, P1; Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337; Loose M, 2001, IEEE J SOLID-ST CIRC, V36, P586, DOI 10.1109/4.913736; Lopich A., 2010, P IEEE INT S CIRC SY, P4257; Ma C, 2011, ELECTRON LETT, V47, P695, DOI 10.1049/el.2011.0808; Majidzadeh V, 2010, IEEE INT SYMP CIRC S, P2956, DOI 10.1109/ISCAS.2010.5538021; Malik J., 2008, P 24 ANN C COMPUTER, P31, DOI DOI 10.1145/1401132.1401174; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Martel JNP, 2016, IEEE INT SYMP CIRC S, P1430, DOI 10.1109/ISCAS.2016.7527519; Mase M, 2005, IEEE J SOLID-ST CIRC, V40, P2787, DOI 10.1109/JSSC.2005.858477; Metzler C. A., 2020, P C COMP VIS PATT RE; Miao W, 2008, IEEE J SOLID-ST CIRC, V43, P1470, DOI 10.1109/JSSC.2008.923621; Millet L, 2018, SYMP VLSI CIRCUITS, P245; Nayar SK, 2006, INT J COMPUT VISION, V70, P7, DOI 10.1007/s11263-005-3102-6; Nayar SK, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1168; Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857; Oike Y, 2013, IEEE J SOLID-ST CIRC, V48, P318, DOI 10.1109/JSSC.2012.2214851; Paillet F., 1999, Twelfth Annual IEEE International ASIC/SOC Conference (Cat. No.99TH8454), P304, DOI 10.1109/ASIC.1999.806524; Portz T, 2013, IEEE INT CONF COMPUT; Posch C, 2011, IEEE J SOLID-ST CIRC, V46, P259, DOI 10.1109/JSSC.2010.2085952; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Reddy D, 2011, PROC CVPR IEEE, P329, DOI 10.1109/CVPR.2011.5995542; Rodriguez-Vazquez A, 2010, CELLULAR NANOSCALE SENSORY WAVE COMPUTING, P129, DOI 10.1007/978-1-4419-1011-0_6; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sankaranarayanan A. C., 2012, P IEEE INT C COMP PH, P1, DOI DOI 10.1109/ICCPHOT.2012.6215212; Sankaranarayanan AC, 2010, LECT NOTES COMPUT SC, V6311, P129, DOI 10.1007/978-3-642-15549-9_10; Serrano A, 2016, COMPUT GRAPH FORUM, V35, P153, DOI 10.1111/cgf.12819; Serrano-Gotarredona T, 2013, IEEE J SOLID-ST CIRC, V48, P827, DOI 10.1109/JSSC.2012.2230553; Sitzmann V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201333; Teixeira EC, 2010, ELECTRON LETT, V46, P1658, DOI 10.1049/el.2010.2351; Tocci MD, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964936; Veeraraghavan A, 2011, IEEE T PATTERN ANAL, V33, P671, DOI 10.1109/TPAMI.2010.87; Wagner R., 2004, P IEEE INT WORKSH; Wei M, 2018, LECT NOTES COMPUT SC, V11207, P55, DOI 10.1007/978-3-030-01219-9_4; Wetzstein G, 2010, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2010.5540166; Wu YX, 2019, JOULE, V3, P1276, DOI 10.1016/j.joule.2019.02.008; Xhakoni A, 2014, IEEE T CIRCUITS-II, V61, P398, DOI 10.1109/TCSII.2014.2319972; Yamazaki T, 2017, ISSCC DIG TECH PAP I, P82, DOI 10.1109/ISSCC.2017.7870271; Yang D. X. D., 1999, 1999 IEEE International Solid-State Circuits Conference. Digest of Technical Papers. ISSCC. First Edition (Cat. No.99CH36278), P308, DOI 10.1109/ISSCC.1999.759263; Zarandy A, 2011, FOCAL-PLANE SENSOR-PROCESSOR CHIPS, P1; Zhang WC, 2011, IEEE J SOLID-ST CIRC, V46, P2132, DOI 10.1109/JSSC.2011.2158024	69	29	30	2	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1642	1653		10.1109/TPAMI.2020.2986944	http://dx.doi.org/10.1109/TPAMI.2020.2986944			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	32305899	Green Submitted			2022-12-18	WOS:000542967200010
J	Borghi, G; Fabbri, M; Vezzani, R; Calderara, S; Cucchiara, R				Borghi, Guido; Fabbri, Matteo; Vezzani, Roberto; Calderara, Simone; Cucchiara, Rita			Face-from-Depth for Head Pose Estimation on Depth Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Head pose estimation; shoulder pose estimation; automotive; deterministic conditional GAN; CNNs		Depth cameras allow to set up reliable solutions for people monitoring and behavior understanding, especially when unstable or poor illumination conditions make unusable common RGB sensors. Therefore, we propose a complete framework for the estimation of the head and shoulder pose based on depth images only. A head detection and localization module is also included, in order to develop a complete end-to-end system. The core element of the framework is a Convolutional Neural Network, called POSEidon(+), that receives as input three types of images and provides the 3D angles of the pose as output. Moreover, a Face-from-Depth component based on a Deterministic Conditional GAN model is able to hallucinate a face from the corresponding depth image. We empirically demonstrate that this positively impacts the system performances. We test the proposed framework on two public datasets, namely Biwi Kinect Head Pose and ICT-3DHP, and on Pandora, a new challenging dataset mainly inspired by the automotive setup. Experimental results show that our method overcomes several recent state-of-art works based on both intensity and depth input data, running in real-time at more than 30 frames per second.	[Borghi, Guido; Fabbri, Matteo; Vezzani, Roberto; Calderara, Simone; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, MO, Italy	Universita di Modena e Reggio Emilia	Borghi, G (corresponding author), Univ Modena & Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, MO, Italy.	guido.borghi@unimore.it; matteo.fabbri@unimore.it; roberto.vezzani@unimore.it; simone.calderara@unimore.it; rita.cucchiara@unimore.it	Vezzani, Roberto/K-9070-2015; calderara, simone/M-6932-2015	Vezzani, Roberto/0000-0002-1046-6870; calderara, simone/0000-0001-9056-1538	MIUR [CTN01-00034-393801]; University of Modena and Reggio Emilia	MIUR(Ministry of Education, Universities and Research (MIUR)); University of Modena and Reggio Emilia	This work has been carried out within the projects Citta educante (CTN01-00034-393801) of the National Technological Cluster on Smart Communities funded by MIUR and FAR2015 - Monitoring the car drivers attention with multisensory systems, computer vision and machine learning funded by the University of Modena and Reggio Emilia. We also acknowledge Ferrari SpA and CINECA for the availability of real car equipments and high performance computing resources, respectively.	Ahn B, 2015, LECT NOTES COMPUT SC, V9005, P82, DOI 10.1007/978-3-319-16811-1_6; Anh Tuan Nghiem, 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P164, DOI 10.1109/ISSPA.2012.6310538; [Anonymous], P ACM MULT INT WORKS; [Anonymous], 2008, 2008 8 IEEE INT C; [Anonymous], P IEEE C COMP VIS PA; [Anonymous], 2014, ICLR; Bar T, 2012, IEEE INT C INTELL TR, P1797, DOI 10.1109/ITSC.2012.6338678; Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980; Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598; Bingjie Wang, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P650, DOI 10.1109/ICIG.2013.133; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bleiweiss A., 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P116, DOI 10.1109/MMSP.2010.5662004; Borghi G, 2017, PROC CVPR IEEE, P5494, DOI 10.1109/CVPR.2017.583; Breitenstein MD, 2008, PROC CVPR IEEE, P3613; BUCKLAND ST, 1993, J APPL ECOL, V30, P478, DOI 10.2307/2404188; Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229; Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Chen JW, 2016, IEEE SW SYMP IMAG, P65, DOI 10.1109/SSIAI.2016.7459176; Chen SY, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P228, DOI 10.1109/AVSS.2016.7738060; Czuprynski B, 2014, LECT NOTES COMPUT SC, V8610, P407, DOI 10.1007/978-3-319-09912-5_34; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Doshi A, 2012, J VISION, V12, DOI [10.1167/12.2.9, 10.1167/12.6.9]; Drouard V, 2017, IEEE WINT CONF APPL, P1232, DOI 10.1109/WACV.2017.142; Drouard V, 2015, IEEE IMAGE PROC, P4624, DOI 10.1109/ICIP.2015.7351683; Eigen D, 2014, ADV NEUR IN, V27; Fabbri M, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11; Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0; Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458; Farneback G, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P171, DOI 10.1109/ICCV.2001.937514; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Ghiass Reza Shoja, 2015, P 2 WORKSH COMP MOD, P25; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gourier N., 2004, FG NET WORKSH VIS OB, V6; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Ito K, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON ANTENNA TECHNOLOGY : SMALL ANTENNAS AND NOVEL METAMATERIALS - CONFERENCE PROCEEDINGS, P1; Ji Q, 2004, IEEE T VEH TECHNOL, V53, P1052, DOI 10.1109/TVT.2004.830974; Kaymak Sertan, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P160, DOI 10.1007/978-3-642-37484-5_14; Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968; Khan K, 2017, IEEE INT CON MULTI, P175, DOI 10.1109/ICME.2017.8019521; Kondori F. A., 2011, 2011 INT C WIR COMM, P1; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lathuiliere S, 2017, PROC CVPR IEEE, P7149, DOI 10.1109/CVPR.2017.756; Li SN, 2016, IEEE T PATTERN ANAL, V38, P1922, DOI 10.1109/TPAMI.2015.2500221; Liu M. -Y., 2016, ADV NEURAL INFORM PR, P469; Liu XB, 2016, IEEE IMAGE PROC, P1289, DOI 10.1109/ICIP.2016.7532566; Low KLJCH., 2004, TR04004 U N CAR CHAP; Malassiotis S, 2005, PATTERN RECOGN, V38, P1153, DOI 10.1016/j.patcog.2004.11.020; Martin Manuel, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P641, DOI 10.1109/3DV.2014.54; Martin S, 2016, IEEE INT VEH SYM, P1010, DOI 10.1109/IVS.2016.7535512; Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7; Matsumoto Y., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P499, DOI 10.1109/AFGR.2000.840680; Meyer GP, 2015, IEEE I CONF COMP VIS, P3649, DOI 10.1109/ICCV.2015.416; Mirza M., 2014, ARXIV PREPRINT ARXIV; Mitra S, 2008, CH CRC COMP SCI DATA, P1; Mukherjee SS, 2015, IEEE T MULTIMEDIA, V17, P2094, DOI 10.1109/TMM.2015.2482819; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Nair V., 2010, ICML, P807; Nuevo J, 2010, PATTERN RECOGN LETT, V31, P2455, DOI 10.1016/j.patrec.2010.07.016; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; Padeleris P., 2012, 2012 IEEE COMP SOC C, P42, DOI DOI 10.1109/CVPRW.2012.6239236; Papadopoulos Georgios Th, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P473, DOI 10.1007/978-3-319-04114-8_40; Papazov C, 2015, PROC CVPR IEEE, P4722, DOI 10.1109/CVPR.2015.7299104; Park E, 2016, IEEE WINT CONF APPL; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Radford A., 2016, ICLR; Rekik Ahmed, 2013, Proceedings of the 8th International Conference on Computer Vision Theory and Applications. VISAPP 2013, P223; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Saeed A, 2015, IEEE IMAGE PROC, P1752, DOI 10.1109/ICIP.2015.7351101; Salimans T., 2016, ADV NEUR IN, P2234; Sarbolandi H, 2015, COMPUT VIS IMAGE UND, V139, P1, DOI 10.1016/j.cviu.2015.05.006; Seemann E, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P626, DOI 10.1109/AFGR.2004.1301603; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Sun Y, 2008, INT C PATT RECOG, P104; Tran C, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P446, DOI 10.1109/ISM.2009.89; Tran D., 2011, VISUAL ANAL HUMANS, P597; Trivedi M. M., 2016, INT C PATT RECOG, P2777; Trivedi MM, 2004, IEEE T VEH TECHNOL, V53, P1698, DOI 10.1109/TVT.2004.835526; Tulyakov S, 2014, INT C PATT RECOG, P2263, DOI 10.1109/ICPR.2014.393; Vatahska T, 2007, IEEE-RAS INT C HUMAN, P330, DOI 10.1109/ICHR.2007.4813889; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20; Xu X, 2017, IEEE INT CONF AUTOMA, P642, DOI 10.1109/FG.2017.81; Yang JL, 2012, INT C PATT RECOG, P2492; Yang RG, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P255, DOI 10.1109/AFGR.2002.1004163; Zeiler Matthew D., 2012, CORR; Zhang W, 2017, CORR; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23; Zhu YD, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P211	93	29	31	4	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					596	609		10.1109/TPAMI.2018.2885472	http://dx.doi.org/10.1109/TPAMI.2018.2885472			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30530311	Green Submitted			2022-12-18	WOS:000525365300006
J	Zhang, Q; Zhang, CP; Ling, JB; Wang, Q; Yu, JY				Zhang, Qi; Zhang, Chunping; Ling, Jinbo; Wang, Qing; Yu, Jingyi			A Generic Multi-Projection-Center Model and Calibration Method for Light Field Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-projection-center (MPC) model; light field cameras; two-parallel-plane (TPP) representation; calibration		Light field cameras can capture both spatial and angular information of light rays, enabling 3D reconstruction by a single exposure. The geometry of 3D reconstruction is affected by intrinsic parameters of a light field camera significantly. In the paper, we propose a multi-projection-center (MPC) model with 6 intrinsic parameters to characterize light field cameras based on traditional two-parallel-plane (TPP) representation. The MPC model can generally parameterize light field in different imaging formations, including conventional and focused light field cameras. By the constraints of 4D ray and 3D geometry, a 3D projective transformation is deduced to describe the relationship between geometric structure and the MPC coordinates. Based on the MPC model and projective transformation, we propose a calibration algorithm to verify our light field camera model. Our calibration method includes a close-form solution and a non-linear optimization by minimizing re-projection errors. Experimental results on both simulated and real scene data have verified the performance of our algorithm.	[Zhang, Qi; Zhang, Chunping; Ling, Jinbo; Wang, Qing] Northwestern Potytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China; [Yu, Jingyi] ShanghaiTech Univ, Sch Informat Sci & Technol, Virtual Real & Visual Comp Ctr, Shanghai 200031, Peoples R China	ShanghaiTech University	Wang, Q (corresponding author), Northwestern Potytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.	nwpugzhang@gmail.com; 724495506@qq.com; 312620756@qq.com; qwang@nwpu.edu.cn; jingyi.udel@gmail.com	Zhang, Qi/ABD-3983-2020	Zhang, Qi/0000-0001-9611-6697	NSFC [61531014]	NSFC(National Natural Science Foundation of China (NSFC))	The authors would like to thank Zhe Ji, Dr. Guoqing Zhou and Dr. Zhaolin Xiao for their helpful suggestions. We also thank anonymous reviewers for their valuable feedback. The work was supported by NSFC under Grant 61531014.	[Anonymous], 2006, DIGITAL LIGHT FIELD, P1; Birklbauer C, 2014, COMPUT GRAPH FORUM, V33, P43, DOI 10.1111/cgf.12289; Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168; Bok Y, 2017, IEEE T PATTERN ANAL, V39, P287, DOI 10.1109/TPAMI.2016.2541145; Bok Y, 2014, LECT NOTES COMPUT SC, V8694, P47, DOI 10.1007/978-3-319-10599-4_4; Cho D, 2013, IEEE I CONF COMP VIS, P3280, DOI 10.1109/ICCV.2013.407; Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Gortler S.J., 1996, ACM T GRAPHIC, V23, P43, DOI DOI 10.1145/237170.237200; Guo XQ, 2016, IEEE T VIS COMPUT GR, V22, P1852, DOI 10.1109/TVCG.2015.2476805; Hahne C., 2015, 3DTV C TRUE VIS CAPT, P1, DOI DOI 10.1109/3DTV.2015.7169363; Hahne C, 2014, OPT EXPRESS, V22, P26659, DOI 10.1364/OE.22.026659; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hartley RI, 1997, INT J COMPUT VISION, V22, P5, DOI 10.1023/A:1007957826135; Heinze C, 2015, IEEE IMTC P, P2038, DOI 10.1109/I2MTC.2015.7151596; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Johannsen Ole, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P302, DOI 10.1007/978-3-642-44964-2_15; Johannsen O, 2015, IEEE I CONF COMP VIS, P720, DOI 10.1109/ICCV.2015.89; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Lumsdaine A., 2009, 2009 IEEE INT C COMP, P1, DOI [10.1109/ICCPHOT.2009.5559008, DOI 10.1109/ICCPHOT.2009.5559008]; Madsen K., 2004, INFORM MATH MODELLIN; Ng R, 2005, ACM T GRAPHIC, V24, P735, DOI 10.1145/1073204.1073256; Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520; Thomason C.M., 2014, P 52 AER SCI M AM I, P1456; Vaish V, 2004, PROC CVPR IEEE, P2; Wanner Sven, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P90; Wanner S, 2013, PROC CVPR IEEE, P1011, DOI 10.1109/CVPR.2013.135; Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259; Zhang C., 2016, COMPUTATIONALVISUALM, V2, P57	29	29	34	2	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2539	2552		10.1109/TPAMI.2018.2864617	http://dx.doi.org/10.1109/TPAMI.2018.2864617			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30106674	Green Submitted			2022-12-18	WOS:000489838200001
J	Liu, H; Ji, RR; Wang, JD; Shen, CH				Liu, Hong; Ji, Rongrong; Wang, Jingdong; Shen, Chunhua			Ordinal Constraint Binary Coding for Approximate Nearest Neighbor Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Binary code learning; hashing; image retrieval; ordinal preserving; tensor graph; discrete optimization	QUANTIZATION; HASH; CODES	Binary code learning, a.k.a. hashing, has been successfully applied to the approximate nearest neighbor search in large-scale image collections. The key challenge lies in reducing the quantization error from the original real-valued feature space to a discrete Hamming space. Recent advances in unsupervised hashing advocate the preservation of ranking information, which is achieved by constraining the binary code learning to be correlated with pairwise similarity. However, few unsupervised methods consider the preservation of ordinal relations in the learning process, which serves as a more basic cue to learn optimal binary codes. In this paper, we propose a novel hashing scheme, termed Ordinal Constraint Hashing (OCH), which embeds the ordinal relation among data points to preserve ranking into binary codes. The core idea is to construct an ordinal graph via tensor product, and then train the hash function over this graph to preserve the permutation relations among data points in the Hamming space. Subsequently, an in-depth acceleration scheme, termed Ordinal Constraint Projection (OCP), is introduced, which approximates the n-pair ordinal graph by L-pair anchor-based ordinal graph, and reduce the corresponding complexity from O(n(4)) to O(L-3) (L << n). Finally, to make the optimization tractable, we further relax the discrete constrains and design a customized stochastic gradient decent algorithm on the Stiefel manifold. Experimental results on serval large-scale benchmarks demonstrate that the proposed OCH method can achieve superior performance over the state-of-the-art approaches.	[Liu, Hong; Ji, Rongrong] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen Shi 361005, Fujian Sheng, Peoples R China; [Wang, Jingdong] Microsoft Res Asia, Media Comp Grp, Beijing 100190, Peoples R China; [Shen, Chunhua] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	Xiamen University; Microsoft; Microsoft Research Asia; University of Adelaide	Ji, RR (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen Shi 361005, Fujian Sheng, Peoples R China.	lynnliu0207@163.com; rrji@xmu.edu.cn; jingdw@microsoft.com; chunhua.shen@adelaide.edu.au	Wang, Jingdong/E-9920-2017	Wang, Jingdong/0000-0002-4888-4445; Shen, Chunhua/0000-0002-8648-8718	National Key RD Program [2017YFC0113000, 2016YFB1001503]; Nature Science Foundation of China [U1705262, 61772443, 61572410]; Post Doctoral Innovative Talent Support Program [BX201600094]; China Post-Doctoral Science Foundation [2017M612134]; Scientific Research Project of National Language Committee of China [YB135-49]; Nature Science Foundation of Fujian Province, China [2017J01125]	National Key RD Program; Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Post Doctoral Innovative Talent Support Program; China Post-Doctoral Science Foundation(China Postdoctoral Science Foundation); Scientific Research Project of National Language Committee of China; Nature Science Foundation of Fujian Province, China(Natural Science Foundation of Fujian Province)	This work is supported by the National Key R&D Program (No. 2017YFC0113000, and No. 2016YFB1001503), Nature Science Foundation of China (No. U1705262, No. 61772443, and No. 61572410), Post Doctoral Innovative Talent Support Program under Grant BX201600094, China Post-Doctoral Science Foundation under Grant 2017M612134, Scientific Research Project of National Language Committee of China (Grant No. YB135-49), and Nature Science Foundation of Fujian Province, China (No. 2017J01125).	Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Arias-Castro E, 2017, BERNOULLI, V23, P1663, DOI 10.3150/15-BEJ792; Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124; Cai D., 2016, ARXIV161207545; Charikar M. S., 2002, P 34 ANN ACM S THEOR, P380, DOI DOI 10.1145/509907.509965; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Cunningham JP, 2015, J MACH LEARN RES, V16, P2859; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Ding C, 2004, P 21 INT C MACH LEAR, P29, DOI DOI 10.1145/1015330.1015408; Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378; Heo JP, 2015, IEEE T PATTERN ANAL, V37, P2304, DOI 10.1109/TPAMI.2015.2408363; Indyk P, 2001, J ALGORITHM, V38, P84, DOI 10.1006/jagm.2000.1131; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248; Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Li W.-J., 2012, P ADV NEUR INF PROC, P1646; Lin GS, 2015, IEEE T PATTERN ANAL, V37, P2317, DOI 10.1109/TPAMI.2015.2404776; Lin GS, 2014, LECT NOTES COMPUT SC, V8691, P613, DOI 10.1007/978-3-319-10578-9_40; Liu H, 2016, AAAI CONF ARTIF INTE, P1258; Liu H, 2017, AAAI CONF ARTIF INTE, P2238; Liu W., 2014, ADV NEURAL INFORM PR, V4, P3419; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu W, 2011, SER INF MANAGE SCI, V10, P1; Matsui Y, 2018, IEEE T MULTIMEDIA, V20, P1809, DOI 10.1109/TMM.2017.2774009; Mohammad Norouzi, 2012, ADV NEURAL INFORM PR, P1061; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Sivic J, 2008, PROC CVPR IEEE, P2182; Song DJ, 2015, IEEE I CONF COMP VIS, P1922, DOI 10.1109/ICCV.2015.223; Terada Y, 2014, PR MACH LEARN RES, V32, P847; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vidal R., 2016, GEN PRINCIPAL COMPON, P45; Wang Jianfeng, 2013, P 21 ACM INT C MULTI, P133; Wang J, 2017, IEEE INFOCOM SER, DOI 10.1007/s12083-017-0556-6; Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976; Wang J, 2013, IEEE I CONF COMP VIS, P3032, DOI 10.1109/ICCV.2013.377; Wang Z, 2016, AAAI CONF ARTIF INTE, P1102; Weiss Y, 2009, ADV NEURAL INFORM PR, P1753; Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1; Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424; Zhang QF, 2014, INT CONF MACH LEARN, P807, DOI 10.1109/ICMLC.2014.7009713	48	29	32	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					941	955		10.1109/TPAMI.2018.2819978	http://dx.doi.org/10.1109/TPAMI.2018.2819978			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29994286				2022-12-18	WOS:000460583500012
J	Yuan, GZ; Ghanem, B				Yuan, Ganzhao; Ghanem, Bernard			l(0)TV: A Sparse Optimization Method for Impulse Noise Image Restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Total variation; image restoration; MPEC; l(0) norm optimization; proximal ADMM; impulse noise	VARIATIONAL APPROACH; MINIMIZATION METHODS; VARIABLE SELECTION; REGULARIZATION; ALGORITHM; REPRESENTATION; REMOVAL	Total Variation (TV) is an effective and popular prior model in the field of regularization-based image processing. This paper focuses on total variation for removing impulse noise in image restoration. This type of noise frequently arises in data acquisition and transmission due to many reasons, e.g., a faulty sensor or analog-to-digital converter errors. Removing this noise is an important task in image restoration. State-of-the-art methods such as Adaptive Outlier Pursuit(AOP) [1], which is based on TV with l(02)-norm data fidelity, only give sub-optimal performance. In this paper, we propose a new sparse optimization method, called l(0)TV-PADMM, which solves the TV-based restoration problem with l(0)-norm data fidelity. To effectively deal with the resulting non-convex non-smooth optimization problem, we first reformulate it as an equivalent biconvex Mathematical Program with Equilibrium Constraints (MPEC), and then solve it using a proximal Alternating Direction Method of Multipliers (PADMM). Our l(0)TV-PADMM method finds a desirable solution to the original l(0)-norm optimization problem and is proven to be convergent under mild conditions. We apply l(0)TV-PADMM to the problems of image denoising and deblurring in the presence of impulse noise. Our extensive experiments demonstrate that l(0)TV-PADMM outperforms state-of-the-art image restoration methods.	[Yuan, Ganzhao] Sun Yat Sen Univ SYSU, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China; [Yuan, Ganzhao] Minist Educ, Key Lab Machine Intelligence & Adv Comp, Beijing 221143, Peoples R China; [Ghanem, Bernard] King Abdullah Univ Sci & Technol KAUST, Visual Comp Ctr, Thuwal 23955, Saudi Arabia	Sun Yat Sen University; King Abdullah University of Science & Technology	Yuan, GZ (corresponding author), Sun Yat Sen Univ SYSU, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China.	yuanganzhao@gmail.com; bernard.ghanem@kaust.edu.sa	Ghanem, Bernard/J-7605-2017	Ghanem, Bernard/0000-0002-5534-587X	King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research; NSF-China [61772570, 61402182]	King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research(King Abdullah University of Science & Technology); NSF-China(National Natural Science Foundation of China (NSFC))	We would like to thank Prof. Shaohua Pan for her helpful discussions on this paper. We also thank Prof. Ming Yan for sharing his code with us. This work was supported by the King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research and, in part, by the NSF-China (61772570, 61402182).	Afonso MV, 2015, IEEE T IMAGE PROCESS, V24, P2239, DOI 10.1109/TIP.2015.2417505; Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814; Aujol JF, 2009, J MATH IMAGING VIS, V34, P307, DOI 10.1007/s10851-009-0149-y; Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250; Bienstock D, 1996, MATH PROGRAM, V74, P121, DOI 10.1007/BF02592208; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Cai JF, 2012, J AM MATH SOC, V25, P1033, DOI 10.1090/S0894-0347-2012-00740-1; Cai JF, 2010, J MATH IMAGING VIS, V36, P46, DOI 10.1007/s10851-009-0169-7; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Chan A. B., 2007, PROC 24 INT C MACHIN, P145, DOI DOI 10.1145/1273496; Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196; Chan RH, 2004, IEEE SIGNAL PROC LET, V11, P921, DOI 10.1109/LSP.2004.838190; Chan TF, 1999, SIAM J SCI COMPUT, V20, P1964, DOI 10.1137/S1064827596299767; Chartrand R, 2008, IET IMAGE PROCESS, V2, P295, DOI 10.1049/iet-ipr:20080017; Chen CH, 2012, IMA J NUMER ANAL, V32, P227, DOI 10.1093/imanum/drq039; Chen DQ, 2012, J MATH IMAGING VIS, V43, P167, DOI 10.1007/s10851-011-0298-7; Clason C, 2012, INVERSE PROBL, V28, DOI 10.1088/0266-5611/28/10/104007; Clason C, 2010, SIAM J SCI COMPUT, V32, P1484, DOI 10.1137/090768217; d'Aspremont A, 2003, 42ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-6, PROCEEDINGS, P4985, DOI 10.1109/CDC.2003.1272418; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Feng M., 2013, 11 WORKSH ADV CONT O, P26; Ge DD, 2011, MATH PROGRAM, V129, P285, DOI 10.1007/s10107-011-0470-2; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Getreuer P., 2010, TVREG V2 VARIATIONAL; Goldfarb D, 2005, SIAM J SCI COMPUT, V27, P622, DOI 10.1137/040608982; Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891; He BS, 2012, SIAM J NUMER ANAL, V50, P700, DOI 10.1137/110836936; Hu J, 2012, J GLOBAL OPTIM, V53, P29, DOI 10.1007/s10898-010-9644-3; Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206; Le T, 2007, J MATH IMAGING VIS, V27, P257, DOI 10.1007/s10851-007-0652-y; Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P829, DOI 10.1109/TIP.2015.2511584; Lu ZS, 2014, MATH PROGRAM, V147, P277, DOI 10.1007/s10107-013-0722-4; Lu ZS, 2013, SIAM J OPTIMIZ, V23, P2448, DOI 10.1137/100808071; Luo Z.Q., 1996, MATH PROGRAMS EQUILI, DOI DOI 10.1017/CBO9780511983658; McDonald A. M., 2014, PROC 27 INT C NEURAL, P3644; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Nesterov Y. E, 2003, APPL OPTIMIZATION, V87; Ng MK, 2007, J MATH IMAGING VIS, V27, P265, DOI 10.1007/s10851-007-0650-0; Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Seabra J, 2008, IEEE ENG MED BIO, P435, DOI 10.1109/IEMBS.2008.4649183; Steidl G, 2010, J MATH IMAGING VIS, V36, P168, DOI 10.1007/s10851-009-0179-5; TIKHONOV VM, 1977, SOLUTION ILL POSED P; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Weiss P., 2006, SOME APPL L CONSTRAI, V6115, P1; Wen ZW, 2012, INVERSE PROBL, V28, DOI 10.1088/0266-5611/28/11/115010; Woo H, 2013, SIAM J SCI COMPUT, V35, pB336, DOI 10.1137/11083811X; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Xu ZB, 2012, IEEE T NEUR NET LEAR, V23, P1013, DOI 10.1109/TNNLS.2012.2197412; Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X; Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894; Yin PH, 2015, SIAM J SCI COMPUT, V37, pA536, DOI 10.1137/140952363; Yu J, 2011, IEEE I CONF COMP VIS, P399; Yuan G., 2016, ARXIV160804430; Yuan G., 2016, ARXIV160804425; Yuan GZ, 2017, AAAI CONF ARTIF INTE, P2867; Yuan GZ, 2016, AAAI CONF ARTIF INTE, P2300; Yuan GZ, 2015, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2015.7299175; Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729; Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379; Zuo WM, 2011, IEEE T IMAGE PROCESS, V20, P2748, DOI 10.1109/TIP.2011.2131665	68	29	29	6	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					352	364		10.1109/TPAMI.2017.2783936	http://dx.doi.org/10.1109/TPAMI.2017.2783936			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29990015	Green Published			2022-12-18	WOS:000456150600007
J	Pham, TH; Kyriazis, N; Argyros, AA; Kheddar, A				Tu-Hoa Pham; Kyriazis, Nikolaos; Argyros, Antonis A.; Kheddar, Abderrahmane			Hand-Object Contact Force Estimation from Markerless Visual Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Force sensing from vision; hand-object tracking; manipulation; pattern analysis; sensors; tracking	MANIPULATION; MODEL	We consider the problem of estimating realistic contact forces during manipulation, backed with ground-truth measurements, using vision alone. Interaction forces are usually measured by mounting force transducers onto the manipulated objects or the hands. Those are costly, cumbersome, and alter the objects' physical properties and their perception by the human sense of touch. Our work establishes that interaction forces can be estimated in a cost-effective, reliable, non-intrusive way using vision. This is a complex and challenging problem. Indeed, in multi-contact, a given motion can generally be caused by an infinity of possible force distributions. To alleviate the limitations of traditional models based on inverse optimization, we collect and release the first large-scale dataset on manipulation kinodynamics as 3.2 hours of synchronized force and motion measurements under 193 object-grasp configurations. We learn a mapping between high-level kinematic features based on the equations of motion and the underlying manipulation forces using recurrent neural networks (RNN). The RNN predictions are consistently refined using physics-based optimization through second-order cone programming (SOCP). We show that our method can successfully capture interaction forces compatible with both the observations and the way humans intuitively manipulate objects, using a single RGB-D camera.	[Tu-Hoa Pham; Kheddar, Abderrahmane] CNRS AIST Joint Robot Lab, UMI3218 RL Tsukuba Cent 1,1-1-1 Umezono, Tsukuba, Ibaraki 3058560, Japan; [Tu-Hoa Pham; Kheddar, Abderrahmane] Univ Montpellier, CNRS, UMR5506, LIRMM IDH, F-34090 Montpellier, France; [Kyriazis, Nikolaos; Argyros, Antonis A.] FORTH, Inst Comp Sci, GR-70013 Iraklion, Greece; [Argyros, Antonis A.] Univ Crete, Comp Sci Dept, Iraklion 74100, Rethimno, Greece	National Institute of Advanced Industrial Science & Technology (AIST); Centre National de la Recherche Scientifique (CNRS); Universite de Montpellier; Foundation for Research & Technology - Hellas (FORTH); University of Crete	Pham, TH (corresponding author), CNRS AIST Joint Robot Lab, UMI3218 RL Tsukuba Cent 1,1-1-1 Umezono, Tsukuba, Ibaraki 3058560, Japan.; Pham, TH (corresponding author), Univ Montpellier, CNRS, UMR5506, LIRMM IDH, F-34090 Montpellier, France.	pham.main@gmail.com; kyriazis@ics.forth.gr; argyros@ics.forth.gr; kheddar@gmail.com	Argyros, Antonis/AAD-9251-2019; Argyros, Antonis/GPK-4775-2022; Kheddar, Abderrahmane/N-5550-2015	Argyros, Antonis/0000-0001-8230-3192; Argyros, Antonis/0000-0001-8230-3192; Kheddar, Abderrahmane/0000-0001-9033-9742	FP7 EU Robo-How.Cog project; Japan Society for Promotion of Science (JSPS) Kakenhi B [16H02886]	FP7 EU Robo-How.Cog project; Japan Society for Promotion of Science (JSPS) Kakenhi B	This work was partially supported by the FP7 EU Robo-How.Cog project (www.robohow.eu), and the Japan Society for Promotion of Science (JSPS) Kakenhi B No. 16H02886.	Andersen M. S., 2013, CVXOPT PYTHON PACKAG; [Anonymous], SWARM INTELLIGENCE; Arbib M., 1985, HAND FUNCTION NEOCOR, V10, P111; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bhat KS, 2002, LECT NOTES COMPUT SC, V2350, P551; Boyd SP, 2007, IEEE T ROBOT, V23, P1117, DOI 10.1109/TRO.2007.910774; Brubaker MA, 2009, IEEE I CONF COMP VIS, P2389, DOI 10.1109/ICCV.2009.5459407; Cai MJ, 2015, IEEE INT CONF ROBOT, P1360, DOI 10.1109/ICRA.2015.7139367; Calli B, 2015, IEEE ROBOT AUTOM MAG, V22, P36, DOI 10.1109/MRA.2015.2448951; Ciocarlie M, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P219; Collobert R., 2011, P BIGLEARN NEUR INF; de La Gorce M, 2011, IEEE T PATTERN ANAL, V33, P1793, DOI 10.1109/TPAMI.2011.33; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Fermuller C, 2018, INT J COMPUT VISION, V126, P358, DOI 10.1007/s11263-017-0992-z; Flanagan JR, 2002, ENCY HUMAN BRAIN, V2, P399, DOI DOI 10.1016/B0-12-227210-2/00157-6; Gao F, 2005, EXP BRAIN RES, V165, P69, DOI 10.1007/s00221-005-2282-1; Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602; Ge L, 2016, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2016.391; Gorniak SL, 2010, EXP BRAIN RES, V202, P413, DOI 10.1007/s00221-009-2148-z; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang DA, 2015, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.2015.7298666; Issac J, 2016, IEEE INT CONF ROBOT, P608, DOI 10.1109/ICRA.2016.7487184; KERR J, 1986, INT J ROBOT RES, V4, P3, DOI 10.1177/027836498600400401; Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61; Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412; Koppula H. S., 2011, ADV NEURAL INFORM PR, P244; Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335; KRAFT D, 1994, ACM T MATH SOFTWARE, V20, P262, DOI 10.1145/192115.192124; Krejov Philip, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163141; Krull A, 2015, LECT NOTES COMPUT SC, V9006, P384, DOI 10.1007/978-3-319-16817-3_25; Kry PG, 2006, ACM T GRAPHIC, V25, P872, DOI 10.1145/1141911.1141969; Kyriazis N, 2014, PROC CVPR IEEE, P3430, DOI 10.1109/CVPR.2014.438; Kyriazis N, 2013, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2013.9; Lai K, 2014, IEEE INT CONF ROBOT, P3050, DOI 10.1109/ICRA.2014.6907298; Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607; Lobo MS, 1998, LINEAR ALGEBRA APPL, V284, P193, DOI 10.1016/S0024-3795(98)10032-0; Mascaro SA, 2001, IEEE T ROBOTIC AUTOM, V17, P698, DOI 10.1109/70.964669; Mason M., 1985, ROBOT HANDS MECH MAN; Mboup M, 2009, NUMER ALGORITHMS, V50, P439, DOI 10.1007/s11075-008-9236-1; Mohammadi M, 2016, IEEE HAPTICS SYM, P284, DOI 10.1109/HAPTICS.2016.7463191; Murray R. M., 1994, MATH INTRO ROBOTIC M, V1; Niu X, 2012, MOTOR CONTROL, V16, P195, DOI 10.1123/mcj.16.2.195; Oikonomidis I, 2012, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2012.6247885; Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101; Oikonomidis I, 2011, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2011.6126483; Park J, 2012, EXP BRAIN RES, V216, P591, DOI 10.1007/s00221-011-2963-x; Pham T.-H., 2015, P IEEE ICCV WORKSH O; Prilutsky BI, 2002, EXERC SPORT SCI REV, V30, P32, DOI 10.1097/00003677-200201000-00007; QIAN C, 2014, PROC CVPR IEEE, P1106, DOI DOI 10.1109/CVPR.2014.145; Rehg J. M., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P35, DOI 10.1007/BFb0028333; Rogez G, 2015, IEEE I CONF COMP VIS, P3889, DOI 10.1109/ICCV.2015.443; Saxena A, 2008, INT J ROBOT RES, V27, P157, DOI 10.1177/0278364907087172; Schedlinski C, 2001, MECH SYST SIGNAL PR, V15, P189, DOI 10.1006/mssp.2000.1345; Scholz JP, 2002, BIOL CYBERN, V86, P29, DOI 10.1007/s004220100279; Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179; Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494; Sinha A, 2016, PROC CVPR IEEE, P4150, DOI 10.1109/CVPR.2016.450; Slota GP, 2011, EXP BRAIN RES, V213, P125, DOI 10.1007/s00221-011-2784-y; Sridhar S, 2016, LECT NOTES COMPUT SC, V9906, P294, DOI 10.1007/978-3-319-46475-6_19; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stassi S, 2014, SENSORS-BASEL, V14, P5296, DOI 10.3390/s140305296; Sun Y, 2009, IEEE T ROBOT, V25, P1356, DOI 10.1109/TRO.2009.2032954; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Supancic JS, 2015, IEEE I CONF COMP VIS, P1868, DOI 10.1109/ICCV.2015.217; Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490; Taylor J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925965; Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500; Pham TH, 2018, IEEE T IND INFORM, V14, P2343, DOI 10.1109/TII.2017.2760912; Pham TH, 2015, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2015.7298898; Tzionas D, 2016, INT J COMPUT VISION, V118, P172, DOI 10.1007/s11263-016-0895-4; Urban S, 2013, IEEE INT C INT ROBOT, P4034, DOI 10.1109/IROS.2013.6696933; Wan CD, 2017, PROC CVPR IEEE, P1196, DOI 10.1109/CVPR.2017.132; Wang YG, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462000; Ye C., 2017, 2017 IEEE INT C ROB, P4604; YOSHIKAWA T, 1991, IEEE T ROBOTIC AUTOM, V7, P67, DOI 10.1109/70.68071; Zhao WP, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508412; Zheng Y, 2013, IEEE INT CONF ROBOT, P1580, DOI 10.1109/ICRA.2013.6630781; Zhu YX, 2015, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2015.7298903; ZHU YX, 2016, PROC CVPR IEEE, P3823, DOI DOI 10.1109/CVPR.2016.415	80	29	29	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					2883	2896		10.1109/TPAMI.2017.2759736	http://dx.doi.org/10.1109/TPAMI.2017.2759736			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29989962	Green Published, Bronze			2022-12-18	WOS:000449355500007
J	Hou, CP; Zhou, ZH				Hou, Chenping; Zhou, Zhi-Hua			One-Pass Learning with Incremental and Decremental Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						One-pass learning; incremental and decremental features; classification; robust learning	SENSORS	In many real tasks the features are evolving, with some features vanished and some other features being augmented. For example, in environment monitoring some sensors expired whereas some new ones were deployed; in mobile game recommendation some games dropped whereas some new ones were added. Learning with such incremental and decremental features is crucial but rarely studied, particularly when the data comes like a stream and thus it is infeasible to keep the whole data for optimization. In this paper, we study this challenging problem and present the OPID approach. Our approach attempts to compress important information of vanished features into functions of survived features, and then expand to include the augmented features. It is an one-pass learning approach, which only needs to scan each instance once and does not need to store the whole data, and thus satisfies the evolving streaming data nature. After tackling this problem in one-shot scenario, we then extend it to multi-shot case. Empirical study on a broad range of data sets shows that our approach can address this problem effectively.	[Hou, Chenping] Natl Univ Def Technol, Coll Sci, Changsha 410073, Hunan, Peoples R China; [Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China	National University of Defense Technology - China; Nanjing University	Zhou, ZH (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.	hcpnudt@hotmail.com; zhouzh@nju.edu.cn			NSF China [61751306, 61473302, 61503396]; Huawei Fund [YBN2017030027]; Collaborative Innovation Center of Novel Software Technology and Industrialization	NSF China(National Natural Science Foundation of China (NSFC)); Huawei Fund(Huawei Technologies); Collaborative Innovation Center of Novel Software Technology and Industrialization	The authors want to thank the associate editor and reviewers for helpful comments and suggestions. Thanks F. Nie and H.-J. Ye for discussion and B.-J. Hou for collecting the real data. This work was supported by NSF China (No. 61751306, 61473302, 61503396), Huawei Fund (YBN2017030027) and the Collaborative Innovation Center of Novel Software Technology and Industrialization. This research was conducted when C. Hou was visiting the LAMDA Group at Nanjing University.	[Anonymous], 2000, P AMS C MATH CHALL 2; Breiman L, 1996, MACH LEARN, V24, P49; Cauwenberghs G., 2000, NIPS, P409; Cesa-Bianchi Nicolo, 2006, PREDICTION LEARNING, DOI DOI 10.1017/CBO9780511546921; Dekel O., 2008, P INT C MACH LEARN, P216; Demsar J, 2006, J MACH LEARN RES, V7, P1; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Farquhar JDR, 2005, ADV NEURAL INFORM PR, P355, DOI 10.5555/2976248.2976293; Gao W., 2013, P 30 INT C MACHINE L, P906; Globerson Amir, 2006, P 23 INT C MACH LEAR, P353, DOI DOI 10.1145/1143844.1143889; Hazan E, 2015, PR MACH LEARN RES, V37, P257; Higham N. J., 2002, ACCURACY STABILITY N; Ho CK, 2005, SENSORS-BASEL, V5, P4, DOI 10.3390/s5010004; Li W, 2018, IEEE T PATTERN ANAL, V40, P2030, DOI 10.1109/TPAMI.2017.2734890; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Niu L, 2016, INT J COMPUT VISION, V118, P130, DOI 10.1007/s11263-015-0862-5; Pan S.J., 2014, DATA CLASSIFICATION, P537; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Scholkopf B., 1999, ADV KERNEL METHODS S; Shalev-Shwartz S, 2011, MATH PROGRAM, V127, P3, DOI 10.1007/s10107-010-0420-4; Sindhwani V., 2005, P WORKSH LEARN MULT; Skocir Pavle, 2012, Agent and Multi-Agent Systems. Technologies and Applications. Proceedings 6th KES International Conference, KES-AMSTA 2012, P104, DOI 10.1007/978-3-642-30947-2_14; Stetter JR, 2003, J ELECTROCHEM SOC, V150, pS11, DOI 10.1149/1.1539051; Teo C. H., 2007, P INT C NEUR INF PRO, P1489; Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042; Wang C., 2016, IEEE INFOCOM 2016 TH, P1; YIP EL, 1986, SIAM J SCI STAT COMP, V7, P507, DOI 10.1137/0907034; Zhang LJ, 2015, AAAI CONF ARTIF INTE, P3158; Zhou Z.-H, 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207; Zhou ZH, 2016, FRONT COMPUT SCI-CHI, V10, P589, DOI 10.1007/s11704-016-6906-3; Zhu Y., 2015, P ACML, P407; Zinkevich Martin, 2003, P INT C MACH LEARN, P928	35	29	32	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2776	2792		10.1109/TPAMI.2017.2769047	http://dx.doi.org/10.1109/TPAMI.2017.2769047			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29990079	hybrid, Green Submitted			2022-12-18	WOS:000446683700019
J	Park, S; Nie, BX; Zhu, SC				Park, Seyoung; Nie, Bruce Xiaohan; Zhu, Song-Chun			Attribute And-Or Grammar for Joint Parsing of Human Pose, Parts and Attributes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Attribute grammar; And-Or grammar; attribute prediction; pose estimation; part localization; joint parsing	PICTORIAL STRUCTURES; FLEXIBLE MIXTURES; RECOGNITION; REPRESENTATION	This paper presents an attribute and-or grammar (A-AOG) model for jointly inferring human body pose and human attributes in a parse graph with attributes augmented to nodes in the hierarchical representation. In contrast to other popular methods in the current literature that train separate classifiers for poses and individual attributes, our method explicitly represents the decomposition and articulation of body parts, and account for the correlations between poses and attributes. The A-AOG model is an amalgamation of three traditional grammar formulations: (i) Phrase structure grammar representing the hierarchical decomposition of the human body from whole to parts; (ii) Dependency grammar modeling the geometric articulation by a kinematic graph of the body pose; and (iii) Attribute grammar accounting for the compatibility relations between different parts in the hierarchy so that their appearances follow a consistent style. The parse graph outputs human detection, pose estimation, and attribute prediction simultaneously, which are intuitive and interpretable. We conduct experiments on two tasks on two datasets, and experimental results demonstrate the advantage of joint modeling in comparison with computing poses and attributes independently. Furthermore, our model obtains better performance over existing methods for both pose estimation and attribute prediction tasks.	[Park, Seyoung] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; [Nie, Bruce Xiaohan] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat & Comp Sci, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Nie, BX (corresponding author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.	seypark@cs.ucla.edu; xhnie@stat.ucla.edu; sczhu@stat.ucla.edu			DARPA SIMPLEX project [N66001-15-C-4035]; ONR MURI project [N00014-16-1-2007]; NSF [IIS 1423305]	DARPA SIMPLEX project; ONR MURI project; NSF(National Science Foundation (NSF))	This work was supported by a DARPA SIMPLEX project N66001-15-C-4035, ONR MURI project N00014-16-1-2007, and NSF IIS 1423305. The authors would like to thank Dr. Brandon Rothrock for discussions. Seyoung Park and Bruce Xiaohan Nie contributed equally.	Abney SP, 1997, COMPUT LINGUIST, V23, P597; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44; Chen X., 2014, P 27 ANN C NEURAL IN, P1736, DOI DOI 10.1109/CVPR.2018.00742; Cottrell GW, 1990, P ADV NEUR INF PROC, P564; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Damen D, 2012, INT J COMPUT VISION, V98, P83, DOI 10.1007/s11263-011-0497-0; Eichner M., 2009, BMVC, V2, P5; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906; Fidler S., 2006, PROC IEEE C COMPUT V, P182; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FU KS, 1982, SYNTACTIC PATTERN RE; Geman S, 2002, Q APPL MATH, V60, P707, DOI 10.1090/qam/1939008; Girshick R., 2011, ADV NEURAL INFORM PR, V24, P442; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gkioxari G, 2015, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2015.284; Golomb BA, 1991, ADV NEURAL INFORMATI, V1, P572; Han F, 2009, IEEE T PATTERN ANAL, V31, P59, DOI 10.1109/TPAMI.2008.55; Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318; Joo J, 2013, IEEE I CONF COMP VIS, P721, DOI 10.1109/ICCV.2013.95; KNUTH DE, 1990, LECT NOTES COMPUT SC, V461, P1; Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48; Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549; Lin L, 2009, PATTERN RECOGN LETT, V30, P180, DOI 10.1016/j.patrec.2008.02.023; Liu XL, 2014, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2014.275; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Park S, 2015, IEEE I CONF COMP VIS, P2372, DOI 10.1109/ICCV.2015.273; Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998; Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433; Ramanan D., 2006, NIPS, P1129; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rothrock B, 2013, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2013.413; Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471; Sapp B, 2010, PROC CVPR IEEE, P422, DOI 10.1109/CVPR.2010.5540182; Todorovic S, 2008, IEEE T PATTERN ANAL, V30, P2158, DOI 10.1109/TPAMI.2008.24; Tompson J.J., 2014, ADV NEURAL INFORM PR, V27, P1799; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Wang S, 2013, PROC CVPR IEEE, P3111, DOI 10.1109/CVPR.2013.400; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212; Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018	49	29	29	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1555	1569		10.1109/TPAMI.2017.2731842	http://dx.doi.org/10.1109/TPAMI.2017.2731842			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28749346	hybrid			2022-12-18	WOS:000434294800002
J	Lu, F; Chen, XW; Sato, I; Sato, Y				Lu, Feng; Chen, Xiaowu; Sato, Imari; Sato, Yoichi			SymPS: BRDF Symmetry Guided Photometric Stereo for Shape and Light Source Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; BRDF symmetry; uncalibrated light sources; isotropic reflectance	REFLECTANCE; SURFACES	We propose uncalibrated photometric stereo methods that address the problem due to unknown isotropic reflectance. At the core of our methods is the notion of "constrained half-vector symmetry" for general isotropic BRDFs. We show that such symmetry can be observed in various real-world materials, and it leads to new techniques for shape and light source estimation. Based on the 1D and 2D representations of the symmetry, we propose two methods for surface normal estimation; one focuses on accurate elevation angle recovery for surface normals when the light sources only cover the visible hemisphere, and the other for comprehensive surface normal optimization in the case that the light sources are also non-uniformly distributed. The proposed robust light source estimation method also plays an essential role to let our methods work in an uncalibrated manner with good accuracy. Quantitative evaluations are conducted with both synthetic and real-world scenes, which produce the state-of-the-art accuracy for all of the non-Lambertian materials in MERL database and the real-world datasets.	[Lu, Feng] Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China; [Lu, Feng] Beihang Univ, Int Res Inst Multidisciplinary Sci, Beijing 100191, Peoples R China; [Chen, Xiaowu] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Sch Comp Sci & Engn, Beijing 100191, Peoples R China; [Sato, Imari] Natl Inst Informat, Tokyo 1010003, Japan; [Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Tokyo 1538505, Japan	Beihang University; Beihang University; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan; University of Tokyo	Lu, F (corresponding author), Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.; Lu, F (corresponding author), Beihang Univ, Int Res Inst Multidisciplinary Sci, Beijing 100191, Peoples R China.	lufeng@buaa.edu.cn; chen@buaa.edu.cn; imarik@nii.ac.jp; ysato@iis.u-tokyo.ac.jp		Lu, Feng/0000-0001-9064-7964; Sato, Yoichi/0000-0003-0097-4537	National Natural Science Foundation of China [61602020]; Joint Funds of NSFC-CARFC [U1533129]; NSFC [61532003, 61421003, 61325011]; Fundamental Research Funds for the Central Universities	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Joint Funds of NSFC-CARFC; NSFC(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported in part by the National Natural Science Foundation of China (No. 61602020), the Joint Funds of NSFC-CARFC (No. U1533129), the NSFC (No. 61532003, 61421003 and 61325011), and the Fundamental Research Funds for the Central Universities. Feng Lu and Xiaowu Chen are the corresponding authors.	Agrawal A, 2006, LECT NOTES COMPUT SC, V3951, P578; Alldrin N., 2008, IEEE C COMP VIS PATT, P1; Alldrin NG, 2007, IEEE I CONF COMP VIS, P417; [Anonymous], 2007, CVPR; Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Chandraker M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2505, DOI 10.1109/CVPR.2011.5995603; Chandraker MK, 2005, PROC CVPR IEEE, P788; Chung H.-S., 2008, P IEEE C COMP VIS PA; Drbohlav O, 2005, IEEE I CONF COMP VIS, P1850; Drbohlav O., 2002, P EUR C COMP VIS ECC, P644; Favaro P, 2012, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2012.6247754; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; Goldman DB, 2005, IEEE I CONF COMP VIS, P341; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Higo T, 2010, PROC CVPR IEEE, P1157, DOI 10.1109/CVPR.2010.5540084; Holroyd M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409086; Ikehata S, 2012, PROC CVPR IEEE, P318, DOI 10.1109/CVPR.2012.6247691; Lombardi S., 2011, P IEEE INT C COMP VI, P238; Lu F, 2015, PROC CVPR IEEE, P168, DOI 10.1109/CVPR.2015.7298612; Lu F, 2015, IEEE T PATTERN ANAL, V37, P1999, DOI 10.1109/TPAMI.2015.2389841; Lu F, 2013, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2013.196; Marschner S. R., 1998, THESIS; Matusik W., 2003, P ACM SIGGRAPH, P27; Midorikawa K, 2016, PROC CVPR IEEE, P4350, DOI 10.1109/CVPR.2016.471; Miyazaki D, 2010, INT J COMPUT VISION, V86, P229, DOI 10.1007/s11263-009-0262-9; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Okabe T, 2009, IEEE I CONF COMP VIS, P1693, DOI 10.1109/ICCV.2009.5459381; Papadhimitri T, 2014, INT J COMPUT VISION, V107, P139, DOI 10.1007/s11263-013-0665-5; Papadhimitri T, 2013, PROC CVPR IEEE, P1474, DOI 10.1109/CVPR.2013.194; Ren P., 2011, P ACM SIGGRAPH; Rusinkiewicz S. M., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P11; Sato I, 2007, IEEE I CONF COMP VIS, P1493; Shi BX, 2016, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2016.403; Shi BX, 2012, LECT NOTES COMPUT SC, V7574, P455, DOI 10.1007/978-3-642-33712-3_33; Shi BX, 2010, PROC CVPR IEEE, P1118, DOI 10.1109/CVPR.2010.5540091; Tan P, 2011, IEEE T PATTERN ANAL, V33, P2506, DOI 10.1109/TPAMI.2011.35; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Winnemoller H, 2005, COMPUT GRAPH FORUM, V24, P433, DOI 10.1111/j.1467-8659.2005.00868.x; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Wu TP, 2006, IEEE T PATTERN ANAL, V28, P1830, DOI 10.1109/TPAMI.2006.224; Wu Z, 2013, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2013.197; Zhou ZL, 2010, LECT NOTES COMPUT SC, V6312, P265, DOI 10.1007/978-3-642-15552-9_20	45	29	29	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					221	234		10.1109/TPAMI.2017.2655525	http://dx.doi.org/10.1109/TPAMI.2017.2655525			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28113338				2022-12-18	WOS:000417806000017
J	Qi, N; Shi, YH; Sun, XY; Wang, JD; Yin, BC; Gao, JB				Qi, Na; Shi, Yunhui; Sun, Xiaoyan; Wang, Jingdong; Yin, Baocai; Gao, Junbin			Multi-Dimensional Sparse Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Synthesis sparse model; analysis sparse model; dictionary learning; MD signal restoration; multilinearity	DISCRIMINATIVE DICTIONARY; K-SVD; ALGORITHM; SIGNALS; REPRESENTATIONS; RECONSTRUCTION; DECOMPOSITION; SHRINKAGE; EQUATIONS; RECOVERY	Traditional synthesis/analysis sparse representation models signals in a one dimensional (1D) way, in which a multidimensional (MD) signal is converted into a 1D vector. 1D modeling cannot sufficiently handle MD signals of high dimensionality in limited computational resources and memory usage, as breaking the data structure and inherently ignores the diversity of MD signals (tensors). We utilize the multilinearity of tensors to establish the redundant basis of the space of multi linear maps with the sparsity constraint, and further propose MD synthesis/analysis sparse models to effectively and efficiently represent MD signals in their original form. The dimensional features of MD signals are captured by a series of dictionaries simultaneously and collaboratively. The corresponding dictionary learning algorithms and unified MD signal restoration formulations are proposed. The effectiveness of the proposed models and dictionary learning algorithms is demonstrated through experiments on MD signals denoising, image superresolution and texture classification. Experiments show that the proposed MD models outperform state-of-the-art 1D models in terms of signal representation quality, computational overhead, and memory storage. Moreover, our proposed MD sparse models generalize the 1D sparse models and are flexible and adaptive to both homogeneous and inhomogeneous properties of MD signals.	[Qi, Na; Shi, Yunhui; Yin, Baocai] Beijing Univ Technol, Beijing Adv Innovat Ctr Future Internet Technol, Beijing Key Lab Multimedia & Intelligent Software, BJUT Fac Informat Technol, Beijing 100124, Peoples R China; [Sun, Xiaoyan; Wang, Jingdong] Microsoft Res Asia, Beijing 100080, Peoples R China; [Gao, Junbin] Univ Sydney, Discipline Business Analyt, Business Sch, Sydney, NSW 2006, Australia	Beijing University of Technology; Microsoft; Microsoft Research Asia; University of Sydney	Qi, N (corresponding author), Beijing Univ Technol, Beijing Adv Innovat Ctr Future Internet Technol, Beijing Key Lab Multimedia & Intelligent Software, BJUT Fac Informat Technol, Beijing 100124, Peoples R China.	q1987n@emails.bjut.edu.cn; syhzm@bjut.edu.cn; xysun@microsoft.com; jingdw@microsoft.com; ybc@bjut.edu.cn; junbin.gao@sydney.edu.au	Gao, Junbin/C-6566-2008; Wang, Jingdong/E-9920-2017; Gao, Junbin/A-1766-2009	Wang, Jingdong/0000-0002-4888-4445; Gao, Junbin/0000-0001-9803-0256	NSFC [61390510, 61632006, 61672066, 61370118, 61672071, 61472018]; PHR (IHLB) [IDHT20150504]; ARC [DP130100364]	NSFC(National Natural Science Foundation of China (NSFC)); PHR (IHLB); ARC(Australian Research Council)	The authors would like to thank the editor and all the anonymous reviewers of this paper for their constructive suggestions and comments. This work was supported by the NSFC (No. 61390510, 61632006, 61672066, 61370118, 61672071, 61472018), the PHR (IHLB) (No. IDHT20150504) and the ARC Discovery Project Grant DP130100364.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Alex M, 2002, LECT NOTES COMPUT SC, V2350, P447; Bader BW, 2006, ACM T MATH SOFTWARE, V32, P635, DOI 10.1145/1186785.1186794; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704; Cai SJ, 2016, PROC CVPR IEEE, P2950, DOI 10.1109/CVPR.2016.322; Caiafa CF, 2013, NEURAL COMPUT, V25, P186, DOI 10.1162/NECO_a_00385; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Candes EJ, 2011, APPL COMPUT HARMON A, V31, P59, DOI 10.1016/j.acha.2010.10.002; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Cleju N, 2012, INT CONF ACOUST SPEE, P5401, DOI 10.1109/ICASSP.2012.6289142; Dabov Kostadin, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P145; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Dahl J, 2010, NUMER ALGORITHMS, V53, P67, DOI 10.1007/s11075-009-9310-3; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847; Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241; Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289; Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Eldar YC, 2009, IEEE T INFORM THEORY, V55, P5302, DOI 10.1109/TIT.2009.2030471; Fang Y, 2012, SCI CHINA INFORM SCI, V55, P889, DOI 10.1007/s11432-012-4551-5; Ghaffari A, 2009, INT CONF ACOUST SPEE, P3157, DOI 10.1109/ICASSP.2009.4960294; Hawe S, 2013, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2013.63; Hawe S, 2013, IEEE T IMAGE PROCESS, V22, P2138, DOI 10.1109/TIP.2013.2246175; Holmes M., 2007, P NEUR INF PROC SYST, P1; Jeevanjee N, 2011, INTRODUCTION TO TENSORS AND GROUP THEORY FOR PHYSICISTS, P1, DOI 10.1007/978-0-8176-4715-5; Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88; Katkovnik V, 2010, INT J COMPUT VISION, V86, P1, DOI 10.1007/s11263-009-0272-7; Kiechle M., 2014, INT J COMPUT VISION, V114, P1; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Lee H., 2007, ADV NEURAL INF PROCE, P801; Mairal J., 2008, P IEEE C COMP VIS PA, V2, P1, DOI DOI 10.1109/CVPR.2008.4587652; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Mairal J, 2010, J MACH LEARN RES, V11, P19; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Marwah K., 2013, ACM T GRAPHIC, V32, P1; Moretti V., 2016, MULTILINEAR ALGEBRA; Nam S, 2013, APPL COMPUT HARMON A, V34, P30, DOI 10.1016/j.acha.2012.03.006; PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Portilla J, 2009, IEEE IMAGE PROC, P3909, DOI 10.1109/ICIP.2009.5413975; Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065; Qi N., 2013, IEEE INT C MULTIMEDI, P1; Qi N, 2013, IEEE IMAGE PROC, P310, DOI 10.1109/ICIP.2013.6738064; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Rubinstein R, 2014, IEEE T SIGNAL PROCES, V62, P5962, DOI 10.1109/TSP.2014.2360157; Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445; Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551; Schneider P, 2008, PSYCHOANAL PSYCHOL, V25, P326, DOI 10.1037/0736-9735.25.2.326; Sivalingam R, 2011, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2011.6126346; Sivalingam R, 2010, LECT NOTES COMPUT SC, V6314, P722, DOI 10.1007/978-3-642-15561-1_52; Sun YB, 2014, IEEE T IMAGE PROCESS, V23, P3816, DOI 10.1109/TIP.2014.2331760; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811; Zeyde Roman, 2010, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47; Zhang YMZ, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.83; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278; Zubair S., 2013, P IEEE 18 INT C DIG, P1; Zubair S., 2012, P IMA INT C MATH SIG, P1	67	29	29	2	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					163	178		10.1109/TPAMI.2017.2663423	http://dx.doi.org/10.1109/TPAMI.2017.2663423			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28182553				2022-12-18	WOS:000417806000013
J	Kaltwang, S; Todorovic, S; Pantic, M				Kaltwang, Sebastian; Todorovic, Sinisa; Pantic, Maja			Doubly Sparse Relevance Vector Machine for Continuous Facial Behavior Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Regression; relevance vector machine; multiple kernel learning; facial expressions	LOCAL BINARY PATTERNS; EXPRESSION; PAIN; RECOGNITION; INTENSITY; PERCEPTION; DESCRIPTOR; SCALE	Certain inner feelings and physiological states like pain are subjective states that cannot be directly measured, but can be estimated from spontaneous facial expressions. Since they are typically characterized by subtle movements of facial parts, analysis of the facial details is required. To this end, we formulate a new regression method for continuous estimation of the intensity of facial behavior interpretation, called Doubly Sparse Relevance Vector Machine (DSRVM). DSRVM enforces double sparsity by jointly selecting the most relevant training examples (a.k.a. relevance vectors) and the most important kernels associated with facial parts relevant for interpretation of observed facial expressions. This advances prior work on multi-kernel learning, where sparsity of relevant kernels is typically ignored. Empirical evaluation on challenging Shoulder Pain videos, and the benchmark DISFA and SEMAINE datasets demonstrate that DSRVM outperforms competing approaches with a multi-fold reduction of running times in training and testing.	[Kaltwang, Sebastian; Pantic, Maja] Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2AZ, England; [Pantic, Maja] Univ Twente, EEMCS, POB 217, NL-7500 AE Enschede, Netherlands; [Todorovic, Sinisa] Oregon State Univ, Sch EECS, Kelley Engn Ctr 1148, Corvallis, OR 97331 USA	Imperial College London; University of Twente; Oregon State University	Kaltwang, S (corresponding author), Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.	sk2608@imperial.ac.uk; sinisa@eecs.oregonstate.edu; m.pantic@imperial.ac.uk			European Commission Horizon [645094]; National Science Foundation [IIS-1302700]	European Commission Horizon; National Science Foundation(National Science Foundation (NSF))	This work has been funded by the European Commission Horizon 2020 [H2020/2014-2020] under grant agreement no. 645094 (SEWA). S. Todorovic is supported in part by the National Science Foundation under grant IIS-1302700.	BASSILI JN, 1978, J EXP PSYCHOL HUMAN, V4, P373, DOI 10.1037/0096-1523.4.3.373; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Close R, 2011, INT GEOSCI REMOTE SE, P1103, DOI 10.1109/IGARSS.2011.6049389; Craig K. D., 2011, HDB PAIN ASSESSMENT, V3rd, P117; Craig K. D., 1992, APS J, V1, P153; Damoulas T, 2008, SEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P577, DOI 10.1109/ICMLA.2008.124; Dornaika F, 2007, J REAL-TIME IMAGE PR, V2, P35, DOI 10.1007/s11554-007-0032-2; Ekman P., 2002, FACIAL ACTION CODING; Gholami B, 2010, IEEE T BIO-MED ENG, V57, P1457, DOI 10.1109/TBME.2009.2039214; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016; Gunnery SD, 2013, J NONVERBAL BEHAV, V37, P29, DOI 10.1007/s10919-012-0139-4; Hammal Z, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P47, DOI 10.1145/2388676.2388688; HESS U, 1995, J PERS SOC PSYCHOL, V69, P280, DOI 10.1037/0022-3514.69.2.280; Hess U, 1997, J NONVERBAL BEHAV, V21, P241, DOI 10.1023/A:1024952730333; Jeni L.A., 2013, P 2013 10 IEEE INT C, P1; Jiang BH, 2014, IEEE T CYBERNETICS, V44, P161, DOI 10.1109/TCYB.2013.2249063; Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36; Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50; Littlewort GC, 2009, IMAGE VISION COMPUT, V27, P1797, DOI 10.1016/j.imavis.2008.12.010; Liu P, 2014, LECT NOTES COMPUT SC, V8692, P151, DOI 10.1007/978-3-319-10593-2_11; Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462; Lucey P, 2012, IMAGE VISION COMPUT, V30, P197, DOI 10.1016/j.imavis.2011.12.003; Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4; McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20; Nanni L, 2010, EXPERT SYST APPL, V37, P7888, DOI 10.1016/j.eswa.2010.04.048; Nicolaou MA, 2014, IEEE T PATTERN ANAL, V36, P1299, DOI 10.1109/TPAMI.2014.16; Nicolaou MA, 2012, IMAGE VISION COMPUT, V30, P186, DOI 10.1016/j.imavis.2011.12.005; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315; Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135; Paul E., 1997, WHAT FACE REVEALS BA, V2, P331; Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010; QIU S, 2005, MULTIPLE KERNEL LEAR; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Reicherts P, 2013, PAIN, V154, P793, DOI 10.1016/j.pain.2013.02.012; Romera-Paredes B., 2012, J MACHINE LEARNING, V22, P951; Rudovic O, 2015, IEEE T PATTERN ANAL, V37, P944, DOI 10.1109/TPAMI.2014.2356192; RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714; Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145; Sandbach G, 2012, IMAGE VISION COMPUT, V30, P762, DOI 10.1016/j.imavis.2012.01.006; Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008; Schuller B, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P449; SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Tipping M.E., 2003, AISTATS; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tzikas D, 2006, LECT NOTES COMPUT SC, V3955, P389; Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239; Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710; Williams ACD, 2002, BEHAV BRAIN SCI, V25, P439, DOI 10.1017/S0140525X02000080; Zafeiriou S, 2008, IEEE T MULTIMEDIA, V10, P1528, DOI 10.1109/TMM.2008.2007292; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao KL, 2015, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2015.7298833; Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974; Zhu JK, 2009, IEEE I CONF COMP VIS, P1265, DOI 10.1109/ICCV.2009.5459325	58	29	32	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1748	1761		10.1109/TPAMI.2015.2501824	http://dx.doi.org/10.1109/TPAMI.2015.2501824			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26595911	hybrid, Green Submitted			2022-12-18	WOS:000381432700003
J	O'Toole, M; Mather, J; Kutulakos, KN				O'Toole, Matthew; Mather, John; Kutulakos, Kiriakos N.			3D Shape and Indirect Appearance by Structured Light Transport	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		Light transport; coded exposure; coded illumination; epipolar constraints; dynamic 3D shape capture; structured light 3D scanning; inter-reflections; subsurface scattering; direct/global separation; multi-path interference; primal-dual coding	MICROSCOPY	We consider the problem of deliberately manipulating the direct and indirect light flowing through a time-varying, general scene in order to simplify its visual analysis. Our approach rests on a crucial link between stereo geometry and light transport: while direct light always obeys the epipolar geometry of a projector-camera pair, indirect light overwhelmingly does not. We show that it is possible to turn this observation into an imaging method that analyzes light transport in real time in the optical domain, prior to acquisition. This yields three key abilities that we demonstrate in an experimental camera prototype: (1) producing a live indirect-only video stream for any scene, regardless of geometric or photometric complexity; (2) capturing images that make existing structured-light shape recovery algorithms robust to indirect transport; and (3) turning them into one-shot methods for dynamic 3D shape capture.	[O'Toole, Matthew; Mather, John; Kutulakos, Kiriakos N.] Univ Toronto, Dept Comp Sci, Bahen Ctr, 40 St George St, Toronto, ON M5S 2E4, Canada	University of Toronto	O'Toole, M (corresponding author), Univ Toronto, Dept Comp Sci, Bahen Ctr, 40 St George St, Toronto, ON M5S 2E4, Canada.	motoole@cs.toronto.edu; jmather@cs.toronto.edu; kyros@cs.toronto.edu						Achar S., 2013, P INT C COMP VIS ICC, P1481; Chen T. H., 2008, P IEEE C COMP VIS PA, P1; Couture V, 2011, IEEE I CONF COMP VIS, P1895, DOI 10.1109/ICCV.2011.6126458; CURLESS B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P987, DOI 10.1109/ICCV.1995.466772; Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855; Fyffe G., 2011, P IEEE INT C COMP PH, P16, DOI [10.1109/ICCPHOT.2011.5753116, DOI 10.1109/ICCPH0T.2011.5753116]; Godin G., 2001, 5 C OPT 3D MEAS TECH; Guillemin V., 2010, DIFFERENTIAL TOPOLOG, V370; Gupta M, 2012, PATTERN DISCOVERY USING SEQUENCE DATA MINING: APPLICATIONS AND STUDIES, P1, DOI 10.4018/978-1-61350-056-9.ch001; Gupta M, 2011, PROC CVPR IEEE, P713, DOI 10.1109/CVPR.2011.5995321; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Heintzmann R, 2001, J MICROSC-OXFORD, V204, P119, DOI 10.1046/j.1365-2818.2001.00945.x; Hernandez C, 2007, IEEE I CONF COMP VIS, P873; Hitomi Y., P INT C COMP VIS, P287; Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319; Kajiya J.T., 1986, SIGGRAPH, P143, DOI [DOI 10.1145/15922.15902, 10.1145/15886.15902, DOI 10.1145/15886.15902]; Kawasaki H, 2008, P IEEE C COMP VIS PA, P1; Kelly MW, 2013, LASER FOCUS WORLD, V49, P90; Koenderink J., 1990, SOLID SHAPE; Lin zhen, 2002, ENVIRON TECHNOL, V3, P1; Mertz J, 2011, NAT METHODS, V8, P811, DOI 10.1038/nmeth.1709; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; NAYAR SK, 1991, INT J COMPUT VISION, V6, P173, DOI 10.1007/BF00115695; Ng R, 2003, ACM T GRAPHIC, V22, P376, DOI 10.1145/882262.882280; O'Toole M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185535; OToole M., 2014, SUPPLEMENTARY MAT; Reddy D, 2011, PROC CVPR IEEE, P329, DOI 10.1109/CVPR.2011.5995542; Rudin W., 1976, PRINCIPLES MATH ANAL, V3; Salvi J, 2010, PATTERN RECOGN, V43, P2666, DOI 10.1016/j.patcog.2010.03.004; Velten A, 2013, ACM T GRAPH, V32, P1; Wan G., 2012, IEEE J SOLID-ST CIRC, P1031; Wilson T, 1996, OPT LETT, V21, P1879, DOI 10.1364/OL.21.001879; Zhong J, 2012, ELECTRON J LINEAR AL, V23, P540	34	29	31	6	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1298	10.1109/TPAMI.2016.2545662	http://dx.doi.org/10.1109/TPAMI.2016.2545662			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	27295455	Green Submitted			2022-12-18	WOS:000377897100003
J	Shen, XY; Yan, Q; Xu, L; Ma, LZ; Jia, JY				Shen, Xiaoyong; Yan, Qiong; Xu, Li; Ma, Lizhuang; Jia, Jiaya			Multispectral Joint Image Restoration via Optimizing a Scale Map	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image restoration; image denoise; joint filtering; shadow detection; multispectral image; depth enhancement	PHOTOGRAPHY; FLASH	Color, infrared and flash images captured in different fields can be employed to effectively eliminate noise and other visual artifacts. We propose a two-image restoration framework considering input images from different fields, for example, one noisy color image and one dark-flashed near-infrared image. The major issue in such a framework is to handle all structure divergence and find commonly usable edges and smooth transitions for visually plausible image reconstruction. We introduce a novel scale map as a competent representation to explicitly model derivative-level confidence and propose new functions and a numerical solver to effectively infer it following our important structural observations. Multispectral shadow detection is also used to make our system more robust. Our method is general and shows a principled way to solve multispectral restoration problems.	[Shen, Xiaoyong; Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China; [Ma, Lizhuang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China; [Yan, Qiong; Xu, Li] Lenovo R&T, Jerusalem, Israel	Chinese University of Hong Kong; Shanghai Jiao Tong University	Shen, XY (corresponding author), Chinese Univ Hong Kong, Shatin, Hong Kong, Peoples R China.	xyshen@cse.cuhk.edu.hk; ma-lz@cs.sjtu.edu.cn; leojia@cse.cuhk.edu.hk	Jia, Jiaya/I-3251-2012		Research Grants Council of the Hong Kong Special Administrative Region [412911]	Research Grants Council of the Hong Kong Special Administrative Region(Hong Kong Research Grants Council)	The work described in this paper was supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region (Project No. 412911).	Agrawal A, 2005, ACM T GRAPHIC, V24, P828, DOI 10.1145/1073204.1073269; Akers D, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P349, DOI 10.1109/VISUAL.2003.1250392; Bhat P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731048; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778; Fattal R, 2002, ACM T GRAPHIC, V21, P249; Finlayson GD, 2002, LECT NOTES COMPUT SC, V2353, P823; Gastal ESL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185529; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; He KM, 2010, LECT NOTES COMPUT SC, V6311, P1; Hoiem D, 2011, CVPR 2011, P2033, DOI DOI 10.1109/CVPR.2011.5995725; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Krishnan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531402; Levin A, 2004, LECT NOTES COMPUT SC, V3021, P602; Levine MD, 2005, PATTERN RECOGN LETT, V26, P251, DOI 10.1016/j.patrec.2004.10.021; Paris S, 2006, LECT NOTES COMPUT SC, V3954, P568; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; Raskar R, 2004, P 3 INT S NONPH AN R, P85, DOI DOI 10.1145/987657.987671; Rufenacht D, 2014, IEEE T PATTERN ANAL, V36, P1672, DOI 10.1109/TPAMI.2013.229; Saxena A, 2007, IEEE I CONF COMP VIS, P1; Schaul L, 2009, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2009.5413700; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; Xu L, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P1049; Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158; Yan Q, 2013, IEEE I CONF COMP VIS, P1537, DOI 10.1109/ICCV.2013.194; Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452; Zhang X, 2008, PROC CVPR IEEE, P117; Zhuo SJ, 2010, IEEE IMAGE PROC, P2537, DOI 10.1109/ICIP.2010.5652900	32	29	29	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2518	2530		10.1109/TPAMI.2015.2417569	http://dx.doi.org/10.1109/TPAMI.2015.2417569			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539855				2022-12-18	WOS:000364831700013
J	Taneja, A; Ballan, L; Pollefeys, M				Taneja, Aparna; Ballan, Luca; Pollefeys, Marc			Geometric Change Detection in Urban Environments Using Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Change detection; image registration; Streetview image application	POSE ESTIMATION; 3D; RECOGNITION; ROBUST; SCALE	We propose a method to detect changes in the geometry of a city using panoramic images captured by a car driving around the city. The proposed method can be used to significantly optimize the process of updating the 3D model of an urban environment that is changing over time, by restricting this process to only those areas where changes are detected. With this application in mind, we designed our algorithm to specifically detect only structural changes in the environment, ignoring any changes in its appearance, and ignoring also all the changes which are not relevant for update purposes such as cars, people etc. The approach also accounts for the challenges involved in a large scale application of change detection, such as inaccuracies in the input geometry, errors in the geo-location data of the images as well as the limited amount of information due to sparse imagery. We evaluated our approach on a small scale setup using high resolution, densely captured images and a large scale setup covering an entire city using instead the more realistic scenario of low resolution, sparsely captured images. A quantitative evaluation was also conducted for the large scale setup consisting of 14; 000 images.	[Taneja, Aparna] Disney Res Zurich, CH-8006 Zurich, Switzerland; [Ballan, Luca; Pollefeys, Marc] ETH, Comp Vis & Geometry Grp, CH-8092 Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich	Taneja, A (corresponding author), Disney Res Zurich, CH-8006 Zurich, Switzerland.	aparna.taneja@disneyresearch.com; luca.ballan@inf.ethz.ch; marc.pollefeys@inf.ethz.ch	Pollefeys, Marc/I-7607-2013		ERC [210806]; SNSF; Google; Honda	ERC(European Research Council (ERC)European Commission); SNSF(Swiss National Science Foundation (SNSF)); Google(Google Incorporated); Honda	This work was supported by the ERC Grant #210806 4DVideo under FP7/2007-2013, SNSF, Google, and Honda. This work was done while Aparna Taneja was at ETH.	Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Baatz G, 2010, LECT NOTES COMPUT SC, V6316, P266, DOI 10.1007/978-3-642-15567-3_20; Bostrom G., 2006, P P ISPRS COMM S IM; Christy S, 1999, COMPUT VIS IMAGE UND, V73, P137, DOI 10.1006/cviu.1998.0717; Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692; Cornelis N, 2008, INT J COMPUT VISION, V78, P121, DOI 10.1007/s11263-007-0081-9; Eden I, 2008, LECT NOTES COMPUT SC, V5305, P172, DOI 10.1007/978-3-540-88693-8_13; Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27; Fruh C, 2004, INT J COMPUT VISION, V60, P5, DOI 10.1023/B:VISI.0000027787.82851.b6; Fruh C, 2003, IEEE COMPUT GRAPH, V23, P52, DOI 10.1109/MCG.2003.1242382; Gall J, 2006, LECT NOTES COMPUT SC, V4319, P84; Golparvar-Fard M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P249, DOI 10.1109/ICCVW.2011.6130250; Guangfan Zhang, 2007, 2007 IEEE Aerospace Conference, P1, DOI 10.1109/ICEMI.2007.4350559; Hartley R., 2004, ROBOTICA; Hassner T, 2014, MACH VISION APPL, V25, P971, DOI 10.1007/s00138-013-0571-4; Ivanov Y, 2000, INT J COMPUT VISION, V37, P199, DOI 10.1023/A:1008107805263; Kocaman S., 2006, P ISPRS; Kosecka J., 2012, P AS C COMP VIS, P590; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Levin A., 2006, IEEE C COMP VIS PATT; Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791; Liebelt J., 2008, P 2008 IEEE C COMPUT, P1; Liebelt J, 2010, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2010.5539836; Liu LY, 2005, PROC CVPR IEEE, P137; Lothe Pierre, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2882, DOI 10.1109/CVPRW.2009.5206662; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Oikonomidis I, 2012, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2012.6247885; Pollard T, 2007, PROC CVPR IEEE, P793; Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4; Prisacariu V., 2009, P BRIT MACH VIS C; Pylvanainen T., 2010, P 3D DAT PROC VIS TR; Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698; Ramalingam S, 2010, IEEE INT C INT ROBOT, P3816, DOI 10.1109/IROS.2010.5649105; Robertson D., 2004, P 15 BRIT MACH VIS C, P819; Sakurada K, 2013, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2013.25; Sandhu R, 2009, PROC CVPR IEEE, P786, DOI 10.1109/CVPRW.2009.5206842; Schindler G, 2010, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2010.5539803; Schindler Grant, 2007, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2007.383150; Takase Y., 2003, INT ARCH PHOTFRAMMET, P113; Taneja A, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P479, DOI 10.1109/3DIMPVT.2012.45; Taneja A, 2011, IEEE I CONF COMP VIS, P2336, DOI 10.1109/ICCV.2011.6126515; Taneja A, 2011, LECT NOTES COMPUT SC, V6494, P613, DOI 10.1007/978-3-642-19318-7_48; Wu CC, 2008, PROC CVPR IEEE, P1229; Zach C, 2007, IEEE I CONF COMP VIS, P1213; Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80; Zhao HJ, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P349, DOI 10.1109/IM.2001.924475; Zhao WY, 2005, IEEE T PATTERN ANAL, V27, P1305, DOI 10.1109/TPAMI.2005.152	47	29	30	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2193	2206		10.1109/TPAMI.2015.2404834	http://dx.doi.org/10.1109/TPAMI.2015.2404834			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440261	Green Submitted			2022-12-18	WOS:000362411000004
J	Jumutc, V; Suykens, JAK				Jumutc, Vilen; Suykens, Johan A. K.			Multi-Class Supervised Novelty Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Novelty detection; one-class SVM; classification; pattern recognition; labeling information	SUPPORT VECTOR MACHINES; FRAMEWORK	In this paper we study the problem of finding a support of unknown high-dimensional distributions in the presence of labeling information, called Supervised Novelty Detection (SND). The One-Class Support Vector Machine (SVM) is a widely used kernel-based technique to address this problem. However with the latter approach it is difficult to model a mixture of distributions from which the support might be constituted. We address this issue by presenting a new class of SVM-like algorithms which help to approach multi-class classification and novelty detection from a new perspective. We introduce a new coupling term between classes which leverages the problem of finding a good decision boundary while preserving the compactness of a support with the l(2)-norm penalty. First we present our optimization objective in the primal and then derive a dual QP formulation of the problem. Next we propose a Least-Squares formulation which results in a linear system which drastically reduces computational costs. Finally we derive a Pegasos-based formulation which can effectively cope with large data sets that cannot be handled by many existing QP solvers. We complete our paper with experiments that validate the usefulness and practical importance of the proposed methods both in classification and novelty detection settings.	[Jumutc, Vilen; Suykens, Johan A. K.] Katholieke Univ Leuven, Dept Elect Engn ESAT SCD SISTA, B-3001 Heverlee, Leuven, Belgium	KU Leuven	Jumutc, V (corresponding author), Katholieke Univ Leuven, Dept Elect Engn ESAT SCD SISTA, Kasteelpk Arenberg 10, B-3001 Heverlee, Leuven, Belgium.	Vilen.Jumutc@esat.kuleuven.be; Johan.Suykens@esat.kuleuven.be	Suykens, Johan A.K./C-9781-2014	Suykens, Johan A.K./0000-0002-8846-6352	Research Council KUL; ERC AdG A-DATADRIVE-B; CoE [EF/05/006]; FWO [G.0588.09, G.0377.12]; SBO POM; IUAP [P6/04 DYSCO];  [GOA/10/09MaNet]	Research Council KUL(KU Leuven); ERC AdG A-DATADRIVE-B; CoE(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)); FWO(FWO); SBO POM; IUAP; 	This work was supported by Research Council KUL, ERC AdG A-DATADRIVE-B, GOA/10/09MaNet, CoE EF/05/006, FWO G.0588.09, G.0377.12, SBO POM, IUAP P6/04 DYSCO. Johan Suykens is a professor at the KU Leuven, Belgium. The scientific responsibility is assumed by its authors. The authors wish to thank Gervasio Puertas for observations on the convexity of our dual objective in Eq. (18).	Belkin M, 2006, J MACH LEARN RES, V7, P2399; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Campbell C, 2001, ADV NEUR IN, V13, P395; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; David HA, 1997, AM STAT, V51, P9, DOI 10.2307/2684684; De Brabanter K, 2010, COMPUT STAT DATA AN, V54, P1484, DOI 10.1016/j.csda.2010.01.024; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Desforges MJ, 1998, P I MECH ENG C-J MEC, V212, P687, DOI 10.1243/0954406981521448; Frank A., 2010, UCI MACHINE LEARNING; Hytla PC, 2009, J APPL REMOTE SENS, V3, DOI 10.1117/1.3236689; Joachims T., 2006, P 12 ACM SIGKDD INT, V06, P217, DOI DOI 10.1145/1150402.1150429; Jumutc V, 2013, 2013 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING (CIDM), P143, DOI 10.1109/CIDM.2013.6597229; Mall Raghvendra, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference, PAKDD 2013. Proceedings, P161, DOI 10.1007/978-3-642-37453-1_14; Melacci S, 2011, J MACH LEARN RES, V12, P1149; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; Nesterov Y, 2009, MATH PROGRAM, V120, P221, DOI 10.1007/s10107-007-0149-x; Oppelt N, 2007, SENSORS-BASEL, V7, P1934, DOI 10.3390/s7091934; Platt J., 1998, ADV KERNEL METHODS S, P42; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; SHALEV- SHWARTZ S., 2007, P 24 INT C MACH LEAR, P807, DOI [DOI 10.1145/1273496.1273598, 10.1145/1273496.1273598]; Steinwart I, 2002, J MACH LEARN RES, V2, P67, DOI 10.1162/153244302760185252; Steinwart I, 2005, J MACH LEARN RES, V6, P211; Steinwart I, 2010, INT GEOSCI REMOTE SE, P3732, DOI 10.1109/IGARSS.2010.5651836; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Wachter A, 2006, MATH PROGRAM, V106, P25, DOI 10.1007/s10107-004-0559-y; Williams CKI, 2001, ADV NEUR IN, V13, P682; Xavier-de-Souza S, 2010, IEEE T SYST MAN CY B, V40, P320, DOI 10.1109/TSMCB.2009.2020435; Xu L., 2006, PROC 21 AAAI C ARTIF, P536	32	29	34	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2510	2523		10.1109/TPAMI.2014.2327984	http://dx.doi.org/10.1109/TPAMI.2014.2327984			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353154	Green Accepted			2022-12-18	WOS:000344988000013
J	Kontschieder, P; Bulo, SR; Pelillo, M; Bischof, H				Kontschieder, Peter; Bulo, Samuel Rota; Pelillo, Marcello; Bischof, Horst			Structured Labels in Random Forests for Semantic Labelling and Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Random forests; structured prediction; semantic image labelling; object detection	RELAXATION; RECOGNITION; CONTEXT; TREES; SHAPE	Ensembles of randomized decision trees, known as Random Forests, have become a valuable machine learning tool for addressing many computer vision problems. Despite their popularity, few works have tried to exploit contextual and structural information in random forests in order to improve their performance. In this paper, we propose a simple and effective way to integrate contextual information in random forests, which is typically reflected in the structured output space of complex problems like semantic image labelling. Our paper has several contributions: We show how random forests can be augmented with structured label information and be used to deliver structured low-level predictions. The learning task is carried out by employing a novel split function evaluation criterion that exploits the joint distribution observed in the structured label space. This allows the forest to learn typical label transitions between object classes and avoid locally implausible label configurations. We provide two approaches for integrating the structured output predictions obtained at a local level from the forest into a concise, global, semantic labelling. We integrate our new ideas also in the Hough-forest framework with the view of exploiting contextual information at the classification level to improve the performance on the task of object detection. Finally, we provide experimental evidence for the effectiveness of our approach on different tasks: Semantic image labelling on the challenging MSRCv2 and CamVid databases, reconstruction of occluded handwritten Chinese characters on the Kaist database and pedestrian detection on the TU Darmstadt databases.	[Kontschieder, Peter] Microsoft Res, Machine Learning & Percept Grp, Cambridge, England; [Bulo, Samuel Rota] Fdn Bruno Kessler, ICT TeV, Trento, Italy; [Pelillo, Marcello] Univ Ca Foscari Venezia, DAIS, I-30172 Venice, Italy; [Bischof, Horst] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Styria, Austria	Microsoft; Fondazione Bruno Kessler; Universita Ca Foscari Venezia; Graz University of Technology	Kontschieder, P (corresponding author), Microsoft Res, Machine Learning & Percept Grp, Cambridge, England.	pekontsc@microsoft.com; rotabulo@fbk.eu; pelillo@dsi.unive.it; bischof@icg.tugraz.at		Bischof, Horst/0000-0002-9096-6671				Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Avidan S, 2006, LECT NOTES COMPUT SC, V3954, P386; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Barinova O, 2010, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2010.5539905; BIEDERMA.I, 1972, SCIENCE, V177, P77, DOI 10.1126/science.177.4043.77; Bosch A, 2007, IEEE I CONF COMP VIS, P1863; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5; Bulo SR, 2012, PROC CVPR IEEE, P3530, DOI 10.1109/CVPR.2012.6248096; Carbonetto P, 2004, LECT NOTES COMPUT SC, V3021, P350; Caruana R., 2008, P 25 INT C MACH LEAR, DOI DOI 10.1145/1390156.1390169; Chow C. K., 1962, IRE T ELECTRON COM, VEC-11, P683; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; COHEN S, 1986, J PHILOS, V83, P574, DOI 10.2307/2026434; Criminisi A., 2013, DECISION FORESTS COM; Dollar P., 2013, P IEEE INT C COMP VI; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70; Gall J, 2009, PROC CVPR IEEE, P1022, DOI 10.1109/CVPRW.2009.5206740; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gonfaus JM, 2010, PROC CVPR IEEE, P3280, DOI 10.1109/CVPR.2010.5540048; Hanson A., 1978, COMPUTER VISION SYST, P303; He XM, 2004, PROC CVPR IEEE, P695; Hough, 1959, P INT C HIGH EN ACC, V590914, P554; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Jancsary J., 2013, INT C MACH LEARN ICM, V28, P915; Jancsary J, 2012, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2012.6247950; Kelm B. M., 2006, P IEEE C COMP VIS PA, P96; Kittler J., 1984, Image and Vision Computing, V2, P13, DOI 10.1016/0262-8856(84)90040-4; Kluckner S., 2009, P BRIT MACH VIS C, P25; Kontschieder P, 2013, PROC CVPR IEEE, P65, DOI 10.1109/CVPR.2013.16; Kontschieder P., 2012, P NEUR INF PROC SYST, V25, P440; Kontschieder P., 2011, P BRIT MACH VIS C, P1111; Kontschieder P, 2011, IEEE I CONF COMP VIS, P2190, DOI 10.1109/ICCV.2011.6126496; Ladicky L, 2010, LECT NOTES COMPUT SC, V6314, P424, DOI 10.1007/978-3-642-15561-1_31; Ladicky L, 2010, LECT NOTES COMPUT SC, V6315, P239, DOI 10.1007/978-3-642-15555-0_18; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Leistner C, 2010, LECT NOTES COMPUT SC, V6316, P29, DOI 10.1007/978-3-642-15567-3_3; Leistner C, 2009, IEEE I CONF COMP VIS, P506, DOI 10.1109/ICCV.2009.5459198; Lepetit V, 2005, PROC CVPR IEEE, P775; Li S., 1995, MARKOV RANDOM FIELD, P1; Montillo A, 2011, LECT NOTES COMPUT SC, V6801, P184, DOI 10.1007/978-3-642-22092-0_16; Moosmann F., 2006, NIPS, P985; Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033; Nowozin S, 2011, IEEE I CONF COMP VIS, P1668, DOI 10.1109/ICCV.2011.6126429; Pelillo M, 1997, J MATH IMAGING VIS, V7, P309, DOI 10.1023/A:1008255111261; PELILLO M, 1994, IEEE T PATTERN ANAL, V16, P933, DOI 10.1109/34.310691; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; Price A.W., 2008, CONTEXTUALITY PRACTI; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986; Riemenschneider H, 2012, LECT NOTES COMPUT SC, V7574, P258, DOI 10.1007/978-3-642-33712-3_19; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Russell B., 2007, ADV NEURAL INFORM PR, P1241; Sharp T, 2008, LECT NOTES COMPUT SC, V5305, P595, DOI 10.1007/978-3-540-88693-8_44; Shotton J, 2007, INT J COMPUT VISION, V81, P2, DOI DOI 10.1007/S11263-007-0109-1; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Singhal A, 2003, PROC CVPR IEEE, P235; Sturgess P., 2009, P BRIT MACH VIS C 20, P621; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Torralba Antonio, 2005, ADV NEURAL INFORM PR, P1401; TOUSSAINT GT, 1978, PATTERN RECOGN, V10, P189, DOI 10.1016/0031-3203(78)90027-4; Tu ZW, 2008, PROC CVPR IEEE, P735; Yakimovsky Y., 1973, P IJCAI, P580; Yang YQ, 2012, LECT NOTES COMPUT SC, V7578, P361, DOI 10.1007/978-3-642-33786-4_27; Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368; Zhu L., 2008, P NIPS	70	29	31	1	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					2104	2116		10.1109/TPAMI.2014.2315814	http://dx.doi.org/10.1109/TPAMI.2014.2315814			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352638				2022-12-18	WOS:000341981300015
J	Wang, XG; Qiu, S; Liu, K; Tang, XO				Wang, Xiaogang; Qiu, Shi; Liu, Ke; Tang, Xiaoou			Web Image Re-Ranking Using Query-Specific Semantic Signatures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image search; image re-ranking; semantic space; semantic signature; keyword expansion	RELEVANCE FEEDBACK; RETRIEVAL	Image re-ranking, as an effective way to improve the results of web-based image search, has been adopted by current commercial search engines such as Bing and Google. Given a query keyword, a pool of images are first retrieved based on textual information. By asking the user to select a query image from the pool, the remaining images are re-ranked based on their visual similarities with the query image. A major challenge is that the similarities of visual features do not well correlate with images' semantic meanings which interpret users' search intention. Recently people proposed to match images in a semantic space which used attributes or reference classes closely related to the semantic meanings of images as basis. However, learning a universal visual semantic space to characterize highly diverse images from the web is difficult and inefficient. In this paper, we propose a novel image re-ranking framework, which automatically offline learns different semantic spaces for different query keywords. The visual features of images are projected into their related semantic spaces to get semantic signatures. At the online stage, images are re-ranked by comparing their semantic signatures obtained from the semantic space specified by the query keyword. The proposed query-specific semantic signatures significantly improve both the accuracy and efficiency of image re-ranking. The original visual features of thousands of dimensions can be projected to the semantic signatures as short as 25 dimensions. Experimental results show that 25-40 percent relative improvement has been achieved on re-ranking precisions compared with the state-of-the-art methods.	[Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China; [Qiu, Shi; Liu, Ke] Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China; [Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China; [Tang, Xiaoou] Chinese Acad Sci, Inst Adv Technol, Key Lab Comp Vis & Pattern Recognit, Beijing, Peoples R China	Chinese University of Hong Kong; Chinese University of Hong Kong; Chinese University of Hong Kong; Chinese Academy of Sciences	Wang, XG (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.		Wang, Xiaogang/L-4369-2014	Wang, Xiaogang/0000-0002-9021-0954	Hong Kong SAR through RGC project [416510]; Guangdong Province through Introduced Innovative R&D Team of Guangdong Province [201001D0104648280]	Hong Kong SAR through RGC project; Guangdong Province through Introduced Innovative R&D Team of Guangdong Province	This work was partially supported by Hong Kong SAR through RGC project 416510 and by Guangdong Province through Introduced Innovative R&D Team of Guangdong Province 201001D0104648280.	Ah-Pine J, 2009, MULTIMED TOOLS APPL, V42, P31, DOI 10.1007/s11042-008-0246-8; Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494; Bart E., 2005, P BRIT MACH VIS C BM; Berg T., 2008, P IEEE C COMP VIS PA; Berg Tamara, 2010, P 11 EUR C COMP VIS; Branson S., 2010, P 11 EUR C COMP VIS; Cai J., 2012, P 20 ACM INT C MULT; CAO Y., 2010, P IEEE C COMP VIS PA; Cauwenberghs G., 2001, P ADV NEUR INF PROC; CHEN L, 2010, P IEEE C COMP VIS PA; Chum 0., 2007, P IEEE C COMP VIS PA; Chum O., 2011, P IEEE C COMP VIS PA; Cui J., 2008, P 16 ACM INT C MULT; Dalal N., 2005, HISTOGRAMS ORIENTED; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; Deselaers T., 2009, P ACM INT C IM VID R, P39; Douze M., 2011, P IEEE C COMP VIS PA; Farhadi A., 2009, P IEEE C COMP VIS PA; Farhadi Ali, 2010, P IEEE C COMP VIS PA; FERGUS R, 2004, P 8 EUR C COMP VIS E; Fergus R., 2005, P 10 IEEE INT C COMP; Ferrari V., 2007, P ADV NEUR INF PROC; Foo J.J., 2007, P INT WORKSH MULT IN; FRITZ M, 2008, P IEEE C COMP VIS PA; Geng B., 2010, P IEEE C COMP VIS PA; Gong B., 2011, P 19 ACM INT C MULT; Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791; Hsu W., 2007, P ACM 15 INT C MULT; Hsu WH, 2006, P 14 ANN ACM INT C M; Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463; Hwang S., 2011, P IEEE C COMP VIS PA; Jain V., 2011, P 20 INT C WORLD WID; Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121; Kovashka A., 2012, P IEEE C COMP VIS PA; Krapac J., 2010, P IEEE C COMP VIS PA; Kumar N., 2009, P 12 INT C COMP VIS; Kuo YH, 2012, IEEE T MULTIMEDIA, V14, P1079, DOI 10.1109/TMM.2012.2190386; Lampert C. H., 2009, P IEEE C COMP VIS PA; Liu W., 2011, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu J., 2012, P IEEE C COMP VIS PA; Lui J., 2011, P IEEE C COMP VIS PA; Mahajan D., 2011, P IEEE INT C COMP VI; Morioka N., 2011, P ACM INT C MULT; Nayar S., 2008, P 10 EUR C COMP VIS; Parikh D., 2011, P INT C COMP VIS ICC; Parkash A., 2012, P 12 EUR C COMP VIS; Philbin J., 2008, P IEEE C COMP VIS PA; Philbin J., 2010, P 11 EUR C COMP VIS; Qiao Y, 2009, IEEE T IMAGE PROCESS, V18, P2153, DOI 10.1109/TIP.2009.2026623; Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138; Rohrbach M, 2010, P IEEE C COMP VIS PA; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510; Sahami M., 2006, P 15 INT C WORLD WID; Scheirer Walter J, 2012, P IEEE C COMP VIS PA; Schroff F., 2007, P IEEE 11 INT C COMP; Sharmanska V., 2012, P 17 EUR C COMP VIS; Siddiquie Behjat, 2011, P IEEE C COMP VIS PA; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Tang XO, 2012, IEEE T PATTERN ANAL, V34, P1342, DOI 10.1109/TPAMI.2011.242; Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134; Tian XM, 2011, IEEE T MULTIMEDIA, V13, P639, DOI 10.1109/TMM.2011.2111363; Torralba A., 2003, P 9 IEEE INT C COMP; Torresani L., 2010, P EUR C COMP VIS ECC; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Wang G., 2009, P IEEE 12 INT C COMP; Wang Meng, 2009, TECHNICAL REPORT; Wang X., 2010, P IEEE C COMP VIS PA; Wang Y., 2010, P 11 EUR C COMP VIS; Yan R., 2003, PROF ACM INT C MULT; YAN R, 2003, P INT C IM VID RETR; YANG L, 2010, P ACM INT C MULT; Yin Q, 2011, P IEEE C COMP VIS PA; Yu Felix X., 2012, P IEEE C COMP VIS PA; Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3	75	29	30	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					810	823		10.1109/TPAMI.2013.214	http://dx.doi.org/10.1109/TPAMI.2013.214			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353202	Green Published			2022-12-18	WOS:000334109000014
J	Hadfield, S; Bowden, R				Hadfield, Simon; Bowden, Richard			Scene Particles: Unregularized Particle-Based Scene Flow Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene flow; scene particles; motion estimation; 3D; 3D motion; particle; particle filter; optical flow; hand tracking; sign language; tracking; occlusion estimation; probabilistic occlusion; occlusion; bilateral filter; 3D tracking; motion segmentation		In this paper, an algorithm is presented for estimating scene flow, which is a richer, 3D analog of optical flow. The approach operates orders of magnitude faster than alternative techniques and is well suited to further performance gains through parallelized implementation. The algorithm employs multiple hypotheses to deal with motion ambiguities, rather than the traditional smoothness constraints, removing oversmoothing errors and providing significant performance improvements on benchmark data, over the previous state of the art. The approach is flexible and capable of operating with any combination of appearance and/or depth sensors, in any setup, simultaneously estimating the structure and motion if necessary. Additionally, the algorithm propagates information over time to resolve ambiguities, rather than performing an isolated estimation at each frame, as in contemporary approaches. Approaches to smoothing the motion field without sacrificing the benefits of multiple hypotheses are explored, and a probabilistic approach to occlusion estimation is demonstrated, leading to 10 and 15 percent improved performance, respectively. Finally, a data-driven tracking approach is described, and used to estimate the 3D trajectories of hands during sign language, without the need to model complex appearance variations at each viewpoint.	[Hadfield, Simon; Bowden, Richard] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	University of Surrey	Hadfield, S (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	S.Hadfield@surrey.ac.uk; R.Bowden@surrey.ac.uk	Bowden, Richard/AAF-8283-2019	Bowden, Richard/0000-0003-3285-8020; Hadfield, Simon/0000-0001-8637-5054	European Community [231135]; EPSRC [EP/I011811/1]; Engineering and Physical Sciences Research Council [EP/I011811/1] Funding Source: researchfish	European Community(European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The work presented was supported by the European Community's Seventh Framework Programme (FP7/2007-2013) grant agreement no 231135 (Dicta-Sign), and by the EPSRC project "Learning to Recognise Dynamic Visual Content from Broadcast Footage" (EP/I011811/1).	Basha T., 2012, P IEEE C COMP VIS PA; Basha T, 2013, INT J COMPUT VISION, V101, P6, DOI 10.1007/s11263-012-0542-7; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Carceroni R.L., 2001, P 8 IEEE INT C COMP; Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577; Cipolla R., 1993, P 4 IEEE INT C COMP; Courchay J., 2009, P 9 AS C COMP VIS AC; Cutler R., 1998, P 3 IEEE INT C FAC G; Davison A.J, 2003, P 9 IEEE INT C COMP; Devernay F., 2006, P IEEE C COMP VIS PA; Douc R., 2005, P 4 INT S IM SIGN PR; Efthimiou E., 2012, P 5 WORKSH REPR PROC; Fransen B., 2009, P IEEE RSJ INT C INT; Furukawa Y., 2008, P IEEE C COMP VIS PA; Gong M., 2006, P 18 INT C PATT REC; Gordon N., 1993, P IEEE C RAD SIGN PR; Hadfield S., 2012, P 9 INT C IM AN REC; Hadfield S., 2011, P IEEE INT C COMP VI; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Huang H.-P., 2006, P IEEE C ROB BIOM RO; Huguet F., 2007, P 11 IEEE INT C COMP; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Isard M., 2006, P 7 AS C COMP VIS AC; Li R., 2005, P IEEE WORKSH MOT VI; Li R, 2008, COMPUT VIS IMAGE UND, V110, P75, DOI 10.1016/j.cviu.2007.04.002; Lukins T., 2005, P BRIT MACH VIS C BM; Moral PD., 2004, FEYNMAN KAC FORMULAE; Neumann J, 2002, INT J COMPUT VISION, V47, P181, DOI 10.1023/A:1014597925429; Pitsikalis V., 2011, P WORKSH GEST REC; Pons J., 2003, P 9 IEEE INT C COMP; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; Rabe C., 2010, P 11 EUR C COMP VIS; Ruttle J., 2009, P INT MACH VIS IM PR; Scharstein D., 2003, P IEEE C COMP VIS PA; Schuchert T., 2008, P 10 EUR C COMP VIS; Schuchert T, 2010, IEEE T PATTERN ANAL, V32, P1646, DOI 10.1109/TPAMI.2009.162; Sidenbladh H., 2001, THESIS STOCKHOLM ROY; Spies H, 2002, COMPUT VIS IMAGE UND, V85, P209, DOI 10.1006/cviu.2002.0970; Sun D., 2008, P 10 EUR C COMP VIS; Valgaerts L., 2010, P 11 EUR C COMP VIS; Vaudrey T., 2008, P 23 INT C IM VIS CO; Vedula S, 2005, IEEE T PATTERN ANAL, V27, P475, DOI 10.1109/TPAMI.2005.63; Vedula S., 1999, P IEEE INT C COMP VI; Vedula S., 2000, P IEEE C COMP VIS PA; Wedel A., 2008, P 10 EUR C COMP VIS; Wedel A, 2011, INT J COMPUT VISION, V95, P29, DOI 10.1007/s11263-010-0404-0; Yan H., 2003, P IEEE INT C SYST MA; Zhang Y, 2003, IEEE T SYST MAN CY B, V33, P592, DOI 10.1109/TSMCB.2003.814284; Zhang Y., 2001, P IEEE C COMP VIS PA; Zhang Y., 2000, P IEEE C COMP VIS PA	50	29	30	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					564	576		10.1109/TPAMI.2013.162	http://dx.doi.org/10.1109/TPAMI.2013.162			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457511	Green Submitted			2022-12-18	WOS:000331450100013
J	Yao, BZ; Nie, BX; Liu, ZC; Zhu, SC				Yao, Benjamin Z.; Nie, Bruce X.; Liu, Zicheng; Zhu, Song-Chun			Animated Pose Templates for Modeling and Detecting Human Actions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action detection; action recognition; structural SVM; animated pose templates	RECOGNITION	This paper presents animated pose templates (APTs) for detecting short-term, long-term, and contextual actions from cluttered scenes in videos. Each pose template consists of two components: 1) a shape template with deformable parts represented in an And-node whose appearances are represented by the Histogram of Oriented Gradient (HOG) features, and 2) a motion template specifying the motion of the parts by the Histogram of Optical-Flows (HOF) features. A shape template may have more than one motion template represented by an Or-node. Therefore, each action is defined as a mixture (Or-node) of pose templates in an And-Or tree structure. While this pose template is suitable for detecting short-term action snippets in two to five frames, we extend it in two ways: 1) For long-term actions, we animate the pose templates by adding temporal constraints in a Hidden Markov Model (HMM), and 2) for contextual actions, we treat contextual objects as additional parts of the pose templates and add constraints that encode spatial correlations between parts. To train the model, we manually annotate part locations on several keyframes of each video and cluster them into pose templates using EM. This leaves the unknown parameters for our learning algorithm in two groups: 1) latent variables for the unannotated frames including pose-IDs and part locations, 2) model parameters shared by all training samples such as weights for HOG and HOF features, canonical part locations of each pose, coefficients penalizing pose-transition and part-deformation. To learn these parameters, we introduce a semi-supervised structural SVM algorithm that iterates between two steps: 1) learning (updating) model parameters using labeled data by solving a structural SVM optimization, and 2) imputing missing variables (i.e., detecting actions on unlabeled frames) with parameters learned from the previous step and progressively accepting high-score frames as newly labeled examples. This algorithm belongs to a family of optimization methods known as the Concave-Convex Procedure (CCCP) that converge to a local optimal solution. The inference algorithm consists of two components: 1) Detecting top candidates for the pose templates, and 2) computing the sequence of pose templates. Both are done by dynamic programming or, more precisely, beam search. In experiments, we demonstrate that this method is capable of discovering salient poses of actions as well as interactions with contextual objects. We test our method on several public action data sets and a challenging outdoor contextual action data set collected by ourselves. The results show that our model achieves comparable or better performance compared to state-of-the-art methods.	[Yao, Benjamin Z.] Beijing Univ Posts & Telecommun, Beijing 100088, Peoples R China; [Nie, Bruce X.; Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Liu, Zicheng] Microsoft Res, Redmond, WA 98052 USA	Beijing University of Posts & Telecommunications; University of California System; University of California Los Angeles; Microsoft	Yao, BZ (corresponding author), Beijing Univ Posts & Telecommun, Beijing 100088, Peoples R China.	xhnie@stat.ucla.edu; zliu@microsoft.com; sczhu@stat.ucla.edu			US National Science Foundation (NSF) [IIS 1018751]; MURI [N00014-10-1-0933]; US Defense Advanced Research Projects Agency (DARPA) MSEE project [FA 8650-11-1-7149]	US National Science Foundation (NSF)(National Science Foundation (NSF)); MURI(MURI); US Defense Advanced Research Projects Agency (DARPA) MSEE project(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This work was supported by the following grants at UCLA: US National Science Foundation (NSF) IIS 1018751, MURI N00014-10-1-0933 and US Defense Advanced Research Projects Agency (DARPA) MSEE project FA 8650-11-1-7149.	[Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], 2008, P IEEE C COMP VIS PA; Azizpour H., 2012, P 12 EUR C COMP VIS; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Branson S, 2011, IEEE I CONF COMP VIS, P1832, DOI 10.1109/ICCV.2011.6126450; Cao L., 2010, P IEEE INT C MULT EX; Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875; Dollar P., 2005, P IEEE INT C COMP VI; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906; Ferrari V., 2009, PROC IEEE CONF COMPU; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Gong HF, 2012, INT J COMPUT VISION, V97, P255, DOI 10.1007/s11263-011-0486-3; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Gupta A, 2009, THESIS; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Iacoboni M, 2005, PLOS BIOL, V3, P529, DOI 10.1371/journal.pbio.0030079; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Johnson S., 2010, BMVC; Klaser A., 2010, P ECCV WORKSH SIGN G; Kovashka A., 2010, P IEEE C COMP VIS PA; Kumar MP, 2010, P ADV NEUR INF PROC; Lan T., 2010, P ADV NEUR INF PROC; Laptev I., 2007, P IEEE INT C COMP VI; Liu J., 2009, P IEEE C COMP VIS PA; Lucas Bruce, 1981, IJCAI; Marszalek M., 2009, P IEEE C COMP VIS PA; Muybridge Eadweard, 1902, ANIMALS MOTION, P20; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Pei M., 2011, P IEEE INT C COMP VI; Rothrock B., 2013, P IEEE INT C COMP VI; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Schuldt C., 2004, P IEEE INT C PATT RE; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Willems G., 2009, P BRIT MACH VIS C BM; Yang WL, 2010, PROC CVPR IEEE, P2030, DOI 10.1109/CVPR.2010.5539879; Yang Y., 2011, P IEEE C COMP VIS PA; Yao B., 2010, P IEEE INT C COMP VI, P1507; YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]	42	29	31	1	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					436	452		10.1109/TPAMI.2013.144	http://dx.doi.org/10.1109/TPAMI.2013.144			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457502				2022-12-18	WOS:000331450100004
J	Emonet, R; Varadarajan, J; Odobez, JM				Emonet, Remi; Varadarajan, Jagannadan; Odobez, Jean-Marc			Temporal Analysis of Motif Mixtures Using Dirichlet Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motif mining; mixed activity; unsupervised activity analysis; topic models; multicamera; camera network; nonparametric models; Bayesian modeling; multivariate time series		In this paper, we present a new model for unsupervised discovery of recurrent temporal patterns (or motifs) in time series (or documents). The model is designed to handle the difficult case of multivariate time series obtained from a mixture of activities, that is, our observations are caused by the superposition of multiple phenomena occurring concurrently and with no synchronization. The model uses nonparametric Bayesian methods to describe both the motifs and their occurrences in documents. We derive an inference scheme to automatically and simultaneously recover the recurrent motifs (both their characteristics and number) and their occurrence instants in each document. The model is widely applicable and is illustrated on datasets coming from multiple modalities, mainly videos from static cameras and audio localization data. The rich semantic interpretation that the model offers can be leveraged in tasks such as event counting or for scene analysis. The approach is also used as a mean of doing soft camera calibration in a camera network. A thorough study of the model parameters is provided and a cross-platform implementation of the inference algorithm will be made publicly available.	[Emonet, Remi; Odobez, Jean-Marc] Idiap Res Inst, CH-1920 Martigny, Switzerland; [Varadarajan, Jagannadan] Adv Digital Sci Ctr, Singapore 138632, Singapore		Emonet, R (corresponding author), Idiap Res Inst, Rue Marconi 19,POB 592, CH-1920 Martigny, Switzerland.	remi@heeere.com; vjagan@gmail.com; odobez@idiap.ch		Emonet, Remi/0000-0002-1870-1329	Swiss National Science Foundation [FNS-198, HAI]; seventh FP of the European Union project VANAHEIM [248907]	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission); seventh FP of the European Union project VANAHEIM	The authors acknowledge the Swiss National Science Foundation (Project: FNS-198, HAI) and from the seventh FP of the European Union project VANAHEIM (248907).	Blei D.M., 2006, P 23 INT C MACH LEAR, P113; Emonet R., 2011, P 8 IEEE INT C ADV V, P6; Emonet R., 2011, P IEEE C COMP VIS PA; Faruquie T.A., 2009, P BRIT MACH VIS C; Haines T.S.F., 2011, P IEEE INT C COMP VI; Hospedales T., 2009, P IEEE INT C COMP VI; J Li, 2009, P IEEE 12 INT C COMP; Javed O, 2008, INT SER VIDEO COMPUT, V10, P1, DOI 10.1007/978-0-387-78881-4_1; Jouneau E., 2011, P 18 IEEE INT C IM P; Kuettel D., 2010, P IEEE C COMP VIS PA; Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827; Marmaroli P., 2011, P 19 EUR SIGN PROC C; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Varadarajan J., 2009, P 12 IEEE INT C COMP; Varadarajan J., 2010, P BRIT MACH VIS C; Varadarajan J., 2012, P IEEE C COMP VIS PA; Wang C., 2009, P ADV NEURAL INFORM; WANG X, 2008, P IEEE C COMP VIS PA; Wang X., 2006, P C KNOWL DISC DAT M; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Wang XZ, 2009, STUD FUZZ SOFT COMP, V245, P1; Yang Y., 2009, P IEEE INT C COMP VI; Zhou B., 2011, P IEEE C COMP VIS PA	23	29	30	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					140	156		10.1109/TPAMI.2013.100	http://dx.doi.org/10.1109/TPAMI.2013.100			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231872	Green Submitted			2022-12-18	WOS:000327965100012
J	Ali, K; Fleuret, F; Hasler, D; Fua, P				Ali, Karim; Fleuret, Francois; Hasler, David; Fua, Pascal			A Real-Time Deformable Detector	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image processing and computer vision; machine learning; object detection	OBJECT DETECTION	We propose a new learning strategy for object detection. The proposed scheme forgoes the need to train a collection of detectors dedicated to homogeneous families of poses, and instead learns a single classifier that has the inherent ability to deform based on the signal of interest. We train a detector with a standard AdaBoost procedure by using combinations of pose-indexed features and pose estimators. This allows the learning process to select and combine various estimates of the pose with features able to compensate for variations in pose without the need to label data for training or explore the pose space in testing. We validate our framework on three types of data: hand video sequences, aerial images of cars, and face images. We compare our method to a standard boosting framework, with access to the same ground truth, and show a reduction in the false alarm rate of up to an order of magnitude. Where possible, we compare our method to the state of the art, which requires pose annotations of the training data, and demonstrate comparable performance.	[Ali, Karim; Fua, Pascal] EPFL IC CVLAB, Stn 14, CH-1015 Lausanne, Switzerland; [Fleuret, Francois] Idiap Res Inst, Ctr Parc, CH-1920 Martigny, Switzerland; [Hasler, David] CSEM SA, CH-2002 Neuchatel, Switzerland	Swiss Center for Electronics & Microtechnology (CSEM)	Ali, K (corresponding author), EPFL IC CVLAB, Stn 14, CH-1015 Lausanne, Switzerland.	karim.ali@epfl.ch; francois.fleuret@idiap.ch; David.hasler@csem.ch; pascal.fua@epfl.ch		Fua, Pascal/0000-0002-6702-9970				Amit Y., 1998, FACE RECOGNITION THE; Carbonetto P, 2008, INT J COMPUT VISION, V77, P219, DOI 10.1007/s11263-007-0067-7; Chum O., 2007, P IEEE C COMP VIS PA, P1; Dalal N., 2005, P IEEE CS C COMP VIS; Dorko G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P634; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; Fergus R, 2003, PROC CVPR IEEE, P264; Fleuret F, 2008, J MACH LEARN RES, V9, P2549; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Kolsch M, 2004, INT C PATT RECOG, P107, DOI 10.1109/ICPR.2004.1334480; Kushner A, 2007, ENCYCLOP MATH APPL, V101, P1; Leibe B., 2004, P ANN PATT REC S; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67; Liebelt J, 2008, PROC CVPR IEEE, P2118; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Opelt A, 2004, LECT NOTES COMPUT SC, V3022, P71; Ozuysal M., 2009, P IEEE C COMP VIS PA; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Rowley H.A., 1996, P IEEE CS C COMP VIS; Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585; Ruedi PF, 2003, IEEE J SOLID-ST CIRC, V38, P2325, DOI 10.1109/JSSC.2003.819169; SAVARESE S., 2007, P IEEE INT C COMP VI; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; SHAH M., 2007, P IEEE INT C COMP VI; Stenger B, 2007, IMAGE VISION COMPUT, V25, P1885, DOI 10.1016/j.imavis.2005.12.018; Stenger B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1063; Su H., 2009, ICCV; Thomas A., 2006, P IEEE CS C COMP VIS; Torralba A., 2004, P IEEE CS C COMP VIS; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P., 2003, FAST MULTIVIEW FACE; Zhang J., 2007, P IEEE C COMP VIS PA	35	29	31	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					225	239		10.1109/TPAMI.2011.117	http://dx.doi.org/10.1109/TPAMI.2011.117			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21670479	Green Submitted			2022-12-18	WOS:000298105500003
J	Chen, SS; Akselrod, P; Zhao, B; Carrasco, JAP; Linares-Barranco, B; Culurciello, E				Chen, Shoushun; Akselrod, Polina; Zhao, Bo; Perez Carrasco, Jose Antonio; Linares-Barranco, Bernabe; Culurciello, Eugenio			Efficient Feedforward Categorization of Objects and Human Postures with Address-Event Image Sensors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human posture categorization; bio-inspired categorization; event-based circuits; address-event image sensor	HAUSDORFF DISTANCE; RECOGNITION	This paper proposes an algorithm for feedforward categorization of objects and, in particular, human postures in real-time video sequences from address-event temporal-difference image sensors. The system employs an innovative combination of event-based hardware and bio-inspired software architecture. An event-based temporal difference image sensor is used to provide input video sequences, while a software module extracts size and position invariant line features inspired by models of the primate visual cortex. The detected line features are organized into vectorial segments. After feature extraction, a modified line segment Hausdorff-distance classifier combined with on-the-fly cluster-based size and position invariant categorization. The system can achieve about 90 percent average success rate in the categorization of human postures, while using only a small number of training samples. Compared to state-of-the-art bio-inspired categorization methods, the proposed algorithm requires less hardware resource, reduces the computation complexity by at least five times, and is an ideal candidate for hardware implementation with event-based circuits.	[Chen, Shoushun; Zhao, Bo] Nanyang Technol Univ, Sch Elect & Elect Engn EEE, Singapore, Singapore; [Akselrod, Polina; Culurciello, Eugenio] Yale Univ, Dept Elect Engn, New Haven, CT 06520 USA; [Perez Carrasco, Jose Antonio; Linares-Barranco, Bernabe] Inst Microelect Sevilla IMSE, Seville, Spain	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Yale University; Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Instituto de Microelectronica de Sevilla (IMS-CNM)	Chen, SS (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn EEE, Singapore, Singapore.	eechenss@ntu.edu.sg	linares-barranco, bernabe/H-6886-2012; Pérez-Carrasco, José Antonio/J-4990-2018; chen, shoushun/A-5132-2011	linares-barranco, bernabe/0000-0002-1813-4889; Pérez-Carrasco, José Antonio/0000-0002-9511-2499; chen, shoushun/0000-0002-5451-0028	US National Science Foundation (NSF) [0622133, M58040012]	US National Science Foundation (NSF)(National Science Foundation (NSF))	This project was funded in part by US National Science Foundation (NSF) award 0622133 and a Nanyang Assistant Professorship (M58040012). The authors also thank Berin Martini for his help on software development.	Aloysius LHW, 2004, I C CONT AUTOMAT ROB, P712; [Anonymous], 2011, JAVA AER OPEN SOURCE; Lenero-Bardallo JA, 2011, IEEE J SOLID-ST CIRC, V46, P1443, DOI 10.1109/JSSC.2011.2118490; Artyomov E, 2006, IEEE T CIRCUITS-I, V53, P2178, DOI 10.1109/TCSI.2006.883161; Barnsley M. F., 2012, FRACTALS EVERYWHERE; Boulay B., 2005, IEE International Symposium on Imaging for Crime Detection and Prevention (ICDP 2005), P135, DOI 10.1049/ic:20050085; Camunas-Mesa L, 2011, IEEE T CIRCUITS-I, V58, P777, DOI 10.1109/TCSI.2010.2078851; Chen JY, 2003, PATTERN RECOGN, V36, P943, DOI 10.1016/S0031-3203(02)00128-0; Chen LP, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P273; Chikkerur S, 2010, VISION RES, V50, P2233, DOI 10.1016/j.visres.2010.05.013; Choi J, 2007, IEEE J SOLID-ST CIRC, V42, P2978, DOI 10.1109/JSSC.2007.908716; Culurciello E., 2001, 2001 IEEE International Solid-State Circuits Conference. Digest of Technical Papers. ISSCC (Cat. No.01CH37177), P92, DOI 10.1109/ISSCC.2001.912560; Culurciello E, 2006, IEEE INT SYMP CIRC S, P955; Culurciello E, 2006, ANALOG INTEGR CIRC S, V49, P39, DOI 10.1007/s10470-006-8737-x; Delbruck T, 2007, IEEE INT SYMP CIRC S, P845, DOI 10.1109/ISCAS.2007.378038; Farabet C., 2010, P HIGH PERF EMB COMP; Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908; Fish A., 2006, INT J INFORM THEORY, V14, P103; Fu Z.M., 2008, P IEEE INT S CIRC SY; Fu ZM, 2008, IEEE T BIOMED CIRC S, V2, P88, DOI 10.1109/TBCAS.2008.924448; Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383; Gottardi M, 2009, IEEE J SOLID-ST CIRC, V44, P1582, DOI 10.1109/JSSC.2009.2017000; Herrero-Jaraba E, 2003, PATTERN RECOGN LETT, V24, P2079, DOI 10.1016/S0167-8655(03)00045-X; Huang F. J., 2009, NORB OBJECT DATABASE; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Isaacs J, 2004, SE SYM SYS THRY, P132; Jafari R, 2007, P INT WORKSH WEAR IM; Kim D, 2009, IEEE T ELECTRON DEV, V56, P2586, DOI 10.1109/TED.2009.2030591; Koch C., 2004, QUEST CONSCIOUSNESS, P260; LeCun Y., 2004, P IEEE CS C COMP VIS; Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337; Linares-Barrancoa A, 2007, NEUROCOMPUTING, V70, P2692, DOI 10.1016/j.neucom.2006.07.020; Litzenberger M, 2006, 2006 IEEE 12TH DIGITAL SIGNAL PROCESSING WORKSHOP & 4TH IEEE SIGNAL PROCESSING EDUCATION WORKSHOP, VOLS 1 AND 2, P173, DOI 10.1109/DSPWS.2006.265448; Masquelier T, 2007, PLOS COMPUT BIOL, V3, P247, DOI 10.1371/journal.pcbi.0030031; Mizuno S, 2003, IEEE J SOLID-ST CIRC, V38, P1072, DOI 10.1109/JSSC.2003.811988; Oster M, 2008, IEEE T CIRCUITS-I, V55, P3160, DOI 10.1109/TCSI.2008.923430; Peissig JJ, 2007, ANNU REV PSYCHOL, V58, P75, DOI 10.1146/annurev.psych.58.102904.190114; Pellegrini S, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/476151; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Serrano-Gotarredona R, 2006, IEEE T CIRCUITS-I, V53, P2548, DOI 10.1109/TCSI.2006.883843; Serrano-Gotarredona R, 2009, IEEE T NEURAL NETWOR, V20, P1417, DOI 10.1109/TNN.2009.2023653; Serre T., 2006, THESIS MIT; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sim DG, 1999, IEEE T IMAGE PROCESS, V8, P425, DOI 10.1109/83.748897; Spagnolo P, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P277, DOI 10.1109/AVSS.2003.1217932; Su H., 2005, P INT C MACH LEARN C, V7, P464; Takahashi K, 2004, IEEE SYS MAN CYBERN, P370; Takahashi K, 2001, JSME INT J C-MECH SY, V44, P618, DOI 10.1299/jsmec.44.618; Teixeira T., 2009, DISTR SMART CAM 2009, P1; Teixeira T, 2007, 2007 FIRST ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P32; Teixeira T, 2006, IEEE INT SYMP CIRC S, P4467, DOI 10.1109/ISCAS.2006.1693621; Teixeira T, 2006, IPSN 2006: THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P458; Teman A, 2008, IEEE INT SYMP CIRC S, P2138, DOI 10.1109/ISCAS.2008.4541873; Thorpe SJ, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL IV, P405, DOI 10.1109/ISCAS.2000.858774; Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568; Tsotsos JK, 2007, LECT NOTES COMPUT SC, V4729, P150; Van Rullen R, 2001, NEURAL COMPUT, V13, P1255, DOI 10.1162/08997660152002852; Virone G, 2008, IEEE T INF TECHNOL B, V12, P387, DOI 10.1109/TITB.2007.904157; Vogelstein R., 2004, P ADV NEURAL INFORM; Wu C, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, PROCEEDINGS, P321, DOI 10.1109/IPSN.2008.20; Yang CHT, 2007, PATTERN RECOGN, V40, P1173, DOI 10.1016/j.patcog.2006.09.014; Zhao B., 2011, P IEEE INT S CIRC SY	62	29	29	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					302	314		10.1109/TPAMI.2011.120	http://dx.doi.org/10.1109/TPAMI.2011.120			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21670481	Green Accepted			2022-12-18	WOS:000298105500009
J	Jiang, H; Yu, SX; Martin, DR				Jiang, Hao; Yu, Stella X.; Martin, David R.			Linear Scale and Rotation Invariant Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scale and rotation invariant matching; deformable matching; linear programming; action detection; shape matching; object matching	BELIEF-PROPAGATION; IMAGE; MODEL	Matching visual patterns that appear scaled, rotated, and deformed with respect to each other is a challenging problem. We propose a linear formulation that simultaneously matches feature points and estimates global geometrical transformation in a constrained linear space. The linear scheme enables search space reduction based on the lower convex hull property so that the problem size is largely decoupled from the original hard combinatorial problem. Our method therefore can be used to solve large scale problems that involve a very large number of candidate feature points. Without using prepruning in the search, this method is more robust in dealing with weak features and clutter. We apply the proposed method to action detection and image matching. Our results on a variety of images and videos demonstrate that our method is accurate, efficient, and robust.	[Jiang, Hao; Yu, Stella X.] Boston Coll, Dept Comp Sci, Chestnut Hill, MA 02467 USA; [Martin, David R.] Google Inc, Mountain View, CA 94043 USA	Boston College; Google Incorporated	Jiang, H (corresponding author), Boston Coll, Dept Comp Sci, 140 Commonwealth Ave, Chestnut Hill, MA 02467 USA.	hjiang@cs.bc.edu; syu@cs.bc.edu; david.r.martin@gmail.com			US National Science Foundation [0644204, 1018641]	US National Science Foundation(National Science Foundation (NSF))	This work is supported in part by US National Science Foundation Grants 0644204 and 1018641.	Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BERG AC, 2005, P IEEE CS C COMP VIS; BESAG J, 1986, J R STAT SOC B, V48, P259; Blank M., 2005, P IEEE INT C COMP VI; Boyd S., CONVEX OPTIMIZATION; Chekuri C, 2001, SIAM PROC S, P109; Chui H., 2000, P IEEE C COMP VIS PA; Chvatal V., 1983, LINEAR PROGRAMMING; Duchenne O., 2009, P IEEE C COMP VIS PA; DUCHI J, 2006, P C NEUR INF PROC SY; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GLOCKER B, 2008, MED IMAGE ANAL; Gonzalez-Linares JM, 2003, PATTERN RECOGN, V36, P2543, DOI 10.1016/S0031-3203(03)00168-7; GRIMSON WEL, 1988, 1019 AI; Jiang H., 2009, P IEEE C COMP VIS PA; JIANG H, 2008, P EUR C COMP VIS; Jiang H, 2007, IEEE T PATTERN ANAL, V29, P959, DOI 10.1109/TPAMI.2007.1048; Kenwright D. N., 1992, Proceedings. Visualization '92 (Cat. No.92CH3201-1), P62, DOI 10.1109/VISUAL.1992.235225; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; KOLMOGOROV V, 2001, P IEEE INT C COMP VI; Komodakis N, 2007, IEEE T PATTERN ANAL, V29, P1436, DOI 10.1109/TPAMI.2007.1061; Komodakis Nikos, 2008, P EUR C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151; Quattoni A, 2004, P C NEUR INF PROC SY; RAMANAN D, 2006, P IEEE CS C COMP VIS; ROY S, 1998, P INT C COMP VIS; Schellewald C, 2005, LECT NOTES COMPUT SC, V3757, P171, DOI 10.1007/11585978_12; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396; Shekhovtsov A, 2008, COMPUT VIS IMAGE UND, V112, P91, DOI 10.1016/j.cviu.2008.06.006; SUDDERTH E, 2004, P C NEUR INF PROC SY; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; TAYLOR CJ, 2008, P EUR C COMP VIS; Torr P.H., 2003, P INT WORKSH ART INT, P292; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Torresani L., 2008, P EUR C COMP VIS; Tu Z., 2004, P EUR C COMP VIS; Weiss Y, 2001, IEEE T INFORM THEORY, V47, P736, DOI 10.1109/18.910585	42	29	31	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1339	1355		10.1109/TPAMI.2010.212	http://dx.doi.org/10.1109/TPAMI.2010.212			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	21135437				2022-12-18	WOS:000290574000005
J	Ouzounis, GK; Wilkinson, MHF				Ouzounis, Georgios K.; Wilkinson, Michael H. F.			Hyperconnected Attribute Filters Based on k-Flat Zones	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image enhancement; object detection; hyperconnectivity; connectivity; Max-Tree; document processing; anisotropic diffusion; attribute filter	CONNECTED OPERATORS; IMAGE-ANALYSIS; ALGORITHMS; MORPHOLOGY; OPENINGS; TREE	In this paper, we present a new method for attribute filtering, combining contrast and structural information. Using hyperconnectivity based on k-flat zones, we improve the ability of attribute filters to retain internal details in detected objects. Simultaneously, we improve the suppression of small, unwanted detail in the background. We extend the theory of attribute filters to hyperconnectivity and provide a fast algorithm to implement the new method. The new version is only marginally slower than the standard Max-Tree algorithm for connected attribute filters, and linear in the number of pixels or voxels. It is two orders of magnitude faster than anisotropic diffusion. The method is implemented in the form of a filtering rule suitable for handling both increasing (size) and nonincreasing (shape) attributes. We test this new framework on nonincreasing shape filters on both 2D images from astronomy, document processing, and microscopy, and 3D CT scans, and show increased robustness to noise while maintaining the advantages of previous methods.	[Ouzounis, Georgios K.] European Commiss, Joint Res Ctr, Crisis Management Unit, I-21027 Ispra, VA, Italy; [Wilkinson, Michael H. F.] Univ Groningen, Johann Bernoulli Inst Math & Comp Sci, NL-9700 AK Groningen, Netherlands	European Commission Joint Research Centre; EC JRC ISPRA Site; University of Groningen	Ouzounis, GK (corresponding author), European Commiss, Joint Res Ctr, Crisis Management Unit, TP 268,Via E Fermi 2749, I-21027 Ispra, VA, Italy.	georgios.ouzounis@jrc.ec.europa.eu; h.f.wilkinson@rug.nl	Wilkinson, Michael/AAA-8471-2020; Ouzounis, Georgios/AAU-9186-2020; Wilkinson, Michael/Q-2847-2019; Wilkinson, Michael H.F./C-2386-2009	Ouzounis, Georgios/0000-0001-8914-3398; Wilkinson, Michael/0000-0001-6258-1128; Wilkinson, Michael H.F./0000-0001-6258-1128	Netherlands Organization for Scientific Research [612.065.202]	Netherlands Organization for Scientific Research(Netherlands Organization for Scientific Research (NWO))	The authors would like to thank Scott Trager of the Kapteyn Astronomical Institute, University of Groningen for his input on galaxy star separation. This work is funded by the Netherlands Organization for Scientific Research under project number 612.065.202.	Braga-Neto U, 2003, J MATH IMAGING VIS, V19, P5, DOI 10.1023/A:1024476403183; Braga-Neto U, 2004, IEEE T IMAGE PROCESS, V13, P1567, DOI 10.1109/TIP.2004.837514; Braga-Neto U, 2002, COMPUT VIS IMAGE UND, V85, P22, DOI 10.1006/cviu.2002.0961; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Caselles V, 2002, J MATH IMAGING VIS, V17, P249, DOI 10.1023/A:1020715626538; Cheng F, 1992, IEEE T IMAGE PROCESS, V1, P533, DOI 10.1109/83.199924; Crespo J, 1997, J MATH IMAGING VIS, V7, P85, DOI 10.1023/A:1008270125009; Crespo J, 1997, SIGNAL PROCESS, V62, P37, DOI 10.1016/S0165-1684(97)00114-X; Crespo J, 1995, SIGNAL PROCESS, V47, P201, DOI 10.1016/0165-1684(95)00108-5; Crespo J., 1999, COMPUTER VISION IMAG, V73, P99, DOI 10.1006/cviu.1998.0703; DIMICCOLI M, 2007, P INT S MATH MORPH, P227; Frei Z, 1996, ASTRON J, V111, P174, DOI 10.1086/117771; Frei Z, 1996, PUBL ASTRON SOC PAC, V108, P624, DOI 10.1086/133775; Gatica-Perez D, 2001, IEEE T IMAGE PROCESS, V10, P1332, DOI 10.1109/83.941857; Gimenez D, 2008, COMPUT VIS IMAGE UND, V110, P32, DOI 10.1016/j.cviu.2007.02.004; Heijmans H., 1995, P SUMM SCH MORPH IM; Jones R, 1999, COMPUT VIS IMAGE UND, V75, P215, DOI 10.1006/cviu.1999.0777; Kendall S, 2008, MON NOT R ASTRON SOC, V387, P1007, DOI 10.1111/j.1365-2966.2008.13327.x; MARAGOS P, 1990, IEEE T PATTERN ANAL, V12, P498, DOI 10.1109/34.55110; MATHERON G, 1988, MATH MORPHOLOGY, V2, P141; Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556; Meyer F, 1998, COMP IMAG VIS, V12, P199; Moore JA, 2006, PUBL ASTRON SOC AUST, V23, P135, DOI 10.1071/AS06010; Naegel B., 2007, P INT S MATH MORPH I, P239; NAGAO M, 1979, COMPUT VISION GRAPH, V10, P195, DOI 10.1016/0146-664X(79)90001-7; Najman L, 2006, IEEE T IMAGE PROCESS, V15, P3531, DOI 10.1109/TIP.2006.877518; Ouzounis GK, 2007, IEEE T PATTERN ANAL, V29, P990, DOI 10.1109/TPAMI.2007.1045; OUZOUNIS GK, 2005, P INT C IM PROC, P844; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; PURNAMA KE, 2007, P 2 INT C COMP VIS T, P328; Ronse C, 1998, J MATH IMAGING VIS, V8, P41, DOI 10.1023/A:1008210216583; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; Serra J, 2006, J MATH IMAGING VIS, V24, P83, DOI 10.1007/s10851-005-3616-0; Serra J, 1998, J MATH IMAGING VIS, V9, P231, DOI 10.1023/A:1008324520475; Serra J., 2000, Fundamenta Informaticae, V41, P147; Serra J, 1988, IMAGE ANAL MATH MORP; Soille P, 2008, IEEE T PATTERN ANAL, V30, P1132, DOI 10.1109/TPAMI.2007.70817; Tzafestas CS, 2002, J MATH IMAGING VIS, V17, P109, DOI 10.1023/A:1020629402912; Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28; Vincent L, 1992, P NATO SHAP PICT WOR, P197; Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823; Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131; Westenberg MA, 2007, IEEE T IMAGE PROCESS, V16, P2943, DOI 10.1109/TIP.2007.909317; WILKINSON M, 2001, P INT C MED IM COMP, P770; Wilkinson MHF, 2008, IEEE T PATTERN ANAL, V30, P1800, DOI 10.1109/TPAMI.2007.70836; Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279	49	29	29	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					224	239		10.1109/TPAMI.2010.74	http://dx.doi.org/10.1109/TPAMI.2010.74			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	21193806	Green Submitted			2022-12-18	WOS:000285313200002
J	Zhang, Z; Tan, TN; Huang, KQ				Zhang, Zhang; Tan, Tieniu; Huang, Kaiqi			An Extended Grammar System for Learning and Recognizing Complex Visual Events	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Rule induction; parsing; event recognition	RECOGNITION	For a grammar-based approach to the recognition of visual events, there are two major limitations that prevent it from real application. One is that the event rules are predefined by domain experts, which means huge manual cost. The other is that the commonly used grammar can only handle sequential relations between subevents, which is inadequate to recognize more complex events involving parallel subevents. To solve these problems, we propose an extended grammar approach to modeling and recognizing complex visual events. First, motion trajectories as original features are transformed into a set of basic motion patterns of a single moving object, namely, primitives (terminals) in the grammar system. Then, a Minimum Description Length (MDL) based rule induction algorithm is performed to discover the hidden temporal structures in primitive stream, where Stochastic Context-Free Grammar (SCFG) is extended by Allen's temporal logic to model the complex temporal relations between subevents. Finally, a Multithread Parsing (MTP) algorithm is adopted to recognize interesting complex events in a given primitive stream, where a Viterbilike error recovery strategy is also proposed to handle large-scale errors, e. g., insertion and deletion errors. Extensive experiments, including gymnastic exercises, traffic light events, and multi-agent interactions, have been executed to validate the effectiveness of the proposed approach.	[Zhang, Zhang; Tan, Tieniu; Huang, Kaiqi] Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Zhang, Z (corresponding author), Chinese Acad Sci, Inst Automat, NLPR, 95 Zhongguancun E Rd, Beijing 100190, Peoples R China.	zzhang@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn; kqhuang@nlpr.ia.ac.cn	Elhamod, Mohannad/A-1904-2012	Wang, Yunlong/0000-0002-3535-308X	National Basic Research Program of China [2004CB318110]	National Basic Research Program of China(National Basic Research Program of China)	The authors thank the anonymous reviewers for their insightful comments that significantly improved the quality of this paper. This work is partly funded by research grants from the National Basic Research Program of China (No. 2004CB318110). The authors also thank Dr. Xuelong Li at Birkbeck College, University of London, and Dr. Dacheng Tao at Nanyang Technological University for their valuable suggestions, and also thank Liangsheng Wang, Daoliang Tan, Shiquan Wang at the National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, and Lixin Duan at Nanyang Technological University for their help on trajectory extractions and experimental evaluations.	Allen J. E., 1994, Journal of Logic and Computation, V4, P531, DOI 10.1093/logcom/4.5.531; Amengual JC, 1998, IEEE T PATTERN ANAL, V20, P1109, DOI 10.1109/34.722628; Bilmes J., 1997, TR97021 INT COMP SCI; Chen Q, 2008, IEEE T INSTRUM MEAS, V57, P1562, DOI 10.1109/TIM.2008.922070; Dollar P., 2005, P IEEE INT WORKSH VI, P65, DOI [DOI 10.1109/VSPETS.2005.1570899, 10.1109/VSPETS.2005.1570899]; Dunn J. C., 1974, Journal of Cybernetics, V4, P95, DOI 10.1080/01969727408546059; FLEISCHMAN M, 2006, P ACM INT WORKSH MUL; FU KS, 1982, SYNTACTIC PATTERN RE; GALATA A, 2002, P 15 EUR C ART INT; Gong S., 2003, P IEEE INT C COMP VI; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Grunwald P., 1996, Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing, P203; Hakeem A, 2007, ARTIF INTELL, V171, P586, DOI 10.1016/j.artint.2007.04.002; HAMID R, 2005, P C UNC ART INT; HOPPNER F, 2001, P 4 INT S ADV INT DA, P123; Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; JOHNSTON M, 1998, P 17 INT C COMP LING, P624; JOO S, 2006, P IEEE INT C COMP VI; KITANI KM, 2005, P IEEE INT WORKSH VI; Kunz T, 2007, IEEE CONF WIREL MOB; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; LAXTON B, 2007, P IEEE INT C COMP VI; MAHMOOD TS, 2004, COMPUTER VISION IMAG, V96; Minnen D, 2003, PROC CVPR IEEE, P626; MOORE D, 2002, P AM ASS ART INT; Needham CJ, 2005, ARTIF INTELL, V167, P103, DOI 10.1016/j.artint.2005.04.006; NEVATIA R, 2003, P IEEE INT C COMP VI; Nguyen N.T., 2005, P IEEE INT C COMP VI; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; PORIKLI F, 2004, P IEEE INT C COMP VI; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; RYOO MS, 2006, P IEEE INT C COMP VI; Shannon C.E., 1949, MATH THEORY COMMUNIC; SHI Y, 2004, P IEEE INT C COMP VI; Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; STOLCKE A, 1995, COMPUT LINGUIST, V21, P165; TOSHEV A, 2006, P IEEE INT C COMP VI; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Wang X, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.208; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; YAMAMOTO M, 2006, P INT C AUT FAC GEST; YANG T, 2005, P IEEE INT C COMP VI; Yilmaz A, 2008, COMPUT VIS IMAGE UND, V109, P335, DOI 10.1016/j.cviu.2007.09.006; ZHANG Z, 2008, P EUR C COMP VIS; ZHANG Z, 2006, P AS C COMP VIS; 2009, CASIA ACTION DATABAS	50	29	33	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					240	255		10.1109/TPAMI.2010.60	http://dx.doi.org/10.1109/TPAMI.2010.60			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	21193807				2022-12-18	WOS:000285313200003
J	Quadrianto, N; Smola, AJ; Song, L; Tuytelaars, T				Quadrianto, Novi; Smola, Alex J.; Song, Le; Tuytelaars, Tinne			Kernelized Sorting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sorting; matching; kernels; object alignment; Hilbert-Schmidt Independence Criterion	DIMENSIONALITY REDUCTION; ALGORITHM	Object matching is a fundamental operation in data analysis. It typically requires the definition of a similarity measure between the classes of objects to be matched. Instead, we develop an approach which is able to perform matching by requiring a similarity measure only within each of the classes. This is achieved by maximizing the dependency between matched pairs of observations by means of the Hilbert-Schmidt Independence Criterion. This problem can be cast as one of maximizing a quadratic assignment problem with special structure and we present a simple algorithm for finding a locally optimal solution.	[Quadrianto, Novi] Australian Natl Univ, RSISE, Canberra, ACT 2601, Australia; [Quadrianto, Novi] NICTA, Canberra Res Lab, Stat Machine Learning Grp, Canberra, ACT 2601, Australia; [Smola, Alex J.] Yahoo Res, Santa Clara, CA 95054 USA; [Song, Le] Carnegie Mellon Univ, Lane Ctr Computat Biol, GHC7416, Sch Comp Sci, Pittsburgh, PA 15213 USA; [Tuytelaars, Tinne] KU Leuven ESAT PSI, B-3001 Louvain, Belgium	Australian National University; Australian National University; Carnegie Mellon University; KU Leuven	Quadrianto, N (corresponding author), Australian Natl Univ, RSISE, Tower A,7 London Circuit, Canberra, ACT 2601, Australia.	novi.quad@gmail.com; alex@smola.org; lesong@cs.cmu.edu; tinne.tuytelaars@esat.kuleuven.be	Tuytelaars, Tinne/B-4319-2015; Song, Le/C-1496-2012	Tuytelaars, Tinne/0000-0003-3307-9723; Quadrianto, Novi/0000-0001-8819-306X	Australian Government's Backing Australia's Ability initiative; ARC; Pascal Network; Fund for Scientific Research Flanders	Australian Government's Backing Australia's Ability initiative(Australian GovernmentDepartment of Industry, Innovation and Science); ARC(Australian Research Council); Pascal Network; Fund for Scientific Research Flanders(FWO)	The authors thank Marconi Barbosa, Tiberio Caetano and the anonymous reviewers for detailed comments. NICTA is funded through the Australian Government's Backing Australia's Ability initiative, in part through the ARC. This research was supported by the Pascal Network. Parts of this work were done while Alex J. Smola, Le Song, and Tinne Tuytelaars were working at NICTA. Tinne Tuytelaars is supported by a postdoctoral research grant of the Fund for Scientific Research Flanders. A short version of this paper appeared in [1].	Aronszajn N, 1943, P CAMB PHILOS SOC, V39, P133; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Caetano TS, 2007, IEEE I CONF COMP VIS, P86; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; CHUNGGRAHAM F, 1997, SPECTRAL GRAPH THEOR; COUR T, 2006, ADV NEURAL INFORM PR, V19, P313; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; DINH TP, 1988, SIAM J OPTIMIZ, V8, P476; FIEDLER M, 1973, CZECH MATH J, V23, P298; FINKE G, 1987, ANN DISCRETE MATH, V31, P61; GANDER W, 1989, LINEAR ALGEBRA APPL, V114, P815, DOI 10.1016/0024-3795(89)90494-1; Garey M.R., 1979, COMPUTERS INTRACTABI; Girosi F., 1997, 1606 MIT ART INT LAB; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; JEBARA T, 2004, P C COMP LEARN THEOR, P609; JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; McDiarmid C., 1989, SURVEYS COMBINATORIC, V141, P148, DOI DOI 10.1017/CBO9781107359949.008; Quadrianto N., 2009, ADV NEURAL INFORM PR, P1289; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SHERMAN S, 1951, P NATL ACAD SCI USA, V37, P826, DOI 10.1073/pnas.37.12.826; Smola A., 2007, ALGORITHMIC LEARNING; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Sriperumbudur B.K., 2008, P 21 ANN C LEARN THE, P111; STEINKE F, 2007, P 20 ANN C NEUR INF, P1313; Walder C, 2006, COMPUT GRAPH FORUM, V25, P635, DOI 10.1111/j.1467-8659.2006.00983.x; WEINBERGER KQ, 2006, P NAT C ART INT; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; [No title captured]	33	29	35	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1809	1821		10.1109/TPAMI.2009.184	http://dx.doi.org/10.1109/TPAMI.2009.184			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20724758				2022-12-18	WOS:000281000700007
J	Bhavsar, AV; Rajagopalan, AN				Bhavsar, Arnav V.; Rajagopalan, A. N.			Resolution Enhancement in Multi-Image Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Superresolution; high-resolution depth/disparity; Markov random fields; graph cuts; visibility	GRAPH CUTS; SUPERRESOLUTION	Under stereo settings, the twin problems of image superresolution (SR) and high-resolution (HR) depth estimation are intertwined. The subpixel registration information required for image superresolution is tightly coupled to the 3D structure. The effects of parallax and pixel averaging (inherent in the downsampling process) preclude a priori estimation of pixel motion for superresolution. These factors also compound the correspondence problem at low resolution (LR), which in turn affects the quality of the LR depth estimates. In this paper, we propose an integrated approach to estimate the HR depth and the SR image from multiple LR stereo observations. Our results demonstrate the efficacy of the proposed method in not only being able to bring out image details but also in enhancing the HR depth over its LR counterpart.	[Bhavsar, Arnav V.; Rajagopalan, A. N.] Indian Inst Technol, Dept Elect Engn, Madras 600036, Tamil Nadu, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Madras	Bhavsar, AV (corresponding author), Indian Inst Technol, Dept Elect Engn, Madras 600036, Tamil Nadu, India.	arnav_bhavsar@yahoo.co.in; raju@ee.iitm.ac.in	Bhavsar, Arnav/HDN-7002-2022	Ambasamudram, Rajagopalan/0000-0002-0006-6961; Bhavsar, Arnav/0000-0003-2849-4375				Baker S., 1999, CMURITR9936; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chung J, 2006, INVERSE PROBL, V22, P1261, DOI 10.1088/0266-5611/22/4/009; DROUIN MA, 2005, P CVPR 05, V1, P351; Farsiu S, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P291, DOI 10.1109/ICIP.2003.1246674; Fitzgibbon A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1176; Fransens R, 2007, COMPUT VIS IMAGE UND, V106, P106, DOI 10.1016/j.cviu.2005.09.011; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116; KANG SB, 2001, MSRTR200180; Knorr S, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P55; Knorr S, 2008, SIGNAL PROCESS-IMAGE, V23, P665, DOI 10.1016/j.image.2008.07.004; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; KOMODAKIS N, 2005, CSDTR200501 U CRET; Komodakis N, 2007, IEEE T PATTERN ANAL, V29, P1436, DOI 10.1109/TPAMI.2007.1061; Li S., 1995, MARKOV RANDOM FIELD, P1; Lin CC, 2004, MED ENG PHYS, V26, P1, DOI 10.1016/S1350-4533(03)00127-9; Martins A. L. D., 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P205; MUDENAGUDI U, 2007, P AS C COMP VIS, V2, P85; Nakamura Y, 1996, PROC CVPR IEEE, P371, DOI 10.1109/CVPR.1996.517099; RAVACHA A, 2001, P C COMP VIS PATT RE, V1, P645; Rother C., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383203; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Seitz S., 2006, P CVPR 06 IE COMP SO, V1, P519, DOI DOI 10.1109/CVPR.2006.19; Shen HF, 2007, IEEE T IMAGE PROCESS, V16, P479, DOI 10.1109/TIP.2006.888334; Strecha C, 2004, PROC CVPR IEEE, P552; STRECHA C, 2006, P IEEE C COMP VIS PA, V2, P2394; Sun J, 2005, PROC CVPR IEEE, P399; Suresh KV, 2007, J OPT SOC AM A, V24, P984, DOI 10.1364/JOSAA.24.000984; SURESH KV, 2006, P IET INT C VIS INF, P600; Wei YC, 2005, PROC CVPR IEEE, P902	33	29	30	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1721	1728		10.1109/TPAMI.2010.90	http://dx.doi.org/10.1109/TPAMI.2010.90			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	626MB	20421665				2022-12-18	WOS:000279969000013
J	Huckemann, S; Hotz, T; Munk, A				Huckemann, Stephan; Hotz, Thomas; Munk, Axel			Intrinsic MANOVA for Riemannian Manifolds with an Application to Kendall's Space of Planar Shapes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape analysis; nonlinear multivariate analysis of variance; Riemannian manifolds; orbifolds; orbit spaces; geodesics; Lie group actions; nonlinear multivariate statistics; covariance; inference; test; intrinsic mean; forest biometry	BOOTSTRAP METHODS; LARGE-SAMPLE; COVARIANCE; TESTS	We propose an intrinsic multifactorial model for data on Riemannian manifolds that typically occur in the statistical analysis of shape. Due to the lack of a linear structure, linear models cannot be defined in general; to date only one-way MANOVA is available. For a general multifactorial model, we assume that variation not explained by the model is concentrated near elements defining the effects. By determining the asymptotic distributions of respective sample covariances under parallel transport, we show that they can be compared by standard MANOVA. Often in applications manifolds are only implicitly given as quotients, where the bottom space parallel transport can be expressed through a differential equation. For Kendall's space of planar shapes, we provide an explicit solution. We illustrate our method by an intrinsic two-way MANOVA for a set of leaf shapes. While biologists can identify genotype effects by sight, we can detect height effects that are otherwise not identifiable.	[Huckemann, Stephan; Hotz, Thomas; Munk, Axel] Univ Gottingen, Inst Math Stochast, D-37077 Gottingen, Germany	University of Gottingen	Huckemann, S (corresponding author), Univ Gottingen, Inst Math Stochast, Goldschmidtstr 7, D-37077 Gottingen, Germany.	huckeman@math.uni-goettingen.de; hotz@math.uni-goettingen.de; munk@math.uni-goettingen.de			DFG [MU 1230/10-1]; German Federal Ministry of Education and Research [03MUPAH6, SFB 803]	DFG(German Research Foundation (DFG)); German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF))	The authors would like to thank their colleagues Branislav Sloboda and Michael Henke from the Institute for Forest Biometry and Informatics at the University of Gottingen who provided us with the data set and whose interest in leaf shapes prompted this research. Also many thanks go to Vic Patrangenaru and Alexander Lytchak for discussing differential geometric aspects. The authors appreciate the editor's and reviewers' comments which helped in further improving this paper. Stephan Huckemann gratefully acknowledges support by DFG grant MU 1230/10-1. Thomas Hotz gratefully acknowledges support by the German Federal Ministry of Education and Research, Grant 03MUPAH6 and SFB 803 and Axel Munk for FOR 916. Also, the authors would like to thank the three anonymous referees for their helpful comments and suggestions.	Amaral GJA, 2007, J AM STAT ASSOC, V102, P695, DOI 10.1198/016214506000001400; AMBARTZUMIAN RV, 1990, FACTORIZATION CALCUL; Anderson TW, 1984, INTRO MULTIVARIATE A; Bhattacharya R, 2005, ANN STAT, V33, P1225, DOI 10.1214/009053605000000093; BISSANTZ N, 2009, IEEE T INFORM THEORY; Bissantz N, 2007, J ROY STAT SOC B, V69, P483, DOI 10.1111/j.1467-9868.2007.599.x; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Cox T. F., 2005, INTRO MULTIVARIATE D; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Dryden IL, 2005, ANN STAT, V33, P1643, DOI 10.1214/009053605000000264; England JR, 2006, TREES-STRUCT FUNCT, V20, P79, DOI 10.1007/s00468-005-0015-5; EVANS K, 2009, SHAPE CURVES GEODESI; Fletcher PT, 2004, LECT NOTES COMPUT SC, V3117, P87; Fuchs M, 2008, INT J COMPUT VISION, V79, P119, DOI 10.1007/s11263-007-0103-7; GUPTA AK, 1984, BIOMETRIKA, V71, P555; Hallin M, 2009, J MULTIVARIATE ANAL, V100, P422, DOI 10.1016/j.jmva.2008.05.010; Hendriks H, 1998, J MULTIVARIATE ANAL, V67, P227, DOI 10.1006/jmva.1998.1776; Hotz T, 2010, J R STAT SOC C-APPL, V59, P127, DOI 10.1111/j.1467-9876.2009.00683.x; HUCKEMANN S, 2010, DYNAMIC SHAPE ANAL C; HUCKEMANN S, 2006, ADV APPL PROBAB, V38, P299, DOI DOI 10.1239/AAP/1151337073; Huckemann S, 2008, IEEE T PATTERN ANAL, V30, P1507, DOI 10.1109/TPAMI.2007.70826; Huckemann S, 2010, STAT SINICA, V20, P1; Huckemann S, 2009, J MULTIVARIATE ANAL, V100, P699, DOI 10.1016/j.jmva.2008.08.008; JUPP PE, 1987, J R STAT SOC C-APPL, V36, P34; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; Kendall D.G., 1999, SHAPE SHAPE THEORY; KIM PT, 2001, CONT MATH, V0287, P00155; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Kobayashi S., 1969, FDN DIFFERENTIAL GEO, V2; KOBAYASHI S, 1963, FDN DIFFERENTIAL GEO; Le H, 2000, J MICROSC-OXFORD, V200, P140, DOI 10.1046/j.1365-2818.2000.00744.x; LE H, 2007, BIOMETRIKA, V94, P513; Le HL, 2003, J LOND MATH SOC, V68, P511, DOI 10.1112/S0024610703004393; Le HL, 2001, ADV APPL PROBAB, V33, P324, DOI 10.1017/S0001867800010818; Lee John M, 2018, INTRO RIEMANNIAN MAN; Lehmann E. L., 1997, TESTING STAT HYPOTHE; Mardia K., 2001, FUNCTIONAL SPATIAL D, P39; Mardia KV, 2005, ANN STAT, V33, P1666, DOI 10.1214/009053605000000273; MARDIA KV, 1979, MULITVARIATE ANAL; ONEILL B, 1966, MICH MATH J, V13, P459; Patrangenaru V, 2001, COMMUN STAT-THEOR M, V30, P1675, DOI 10.1081/STA-100105692; Ziezold H, 1977, T 7 PRAG C INF THEOR, VA, P591	42	29	31	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					593	603		10.1109/TPAMI.2009.117	http://dx.doi.org/10.1109/TPAMI.2009.117			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224117	Green Submitted			2022-12-18	WOS:000274548800003
J	Ni, K; Kannan, A; Criminisi, A; Winn, J				Ni, Kai; Kannan, Anitha; Criminisi, Antonio; Winn, John			Epitomic Location Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Location class recognition; epitomic image analysis; panoramic stitching		This paper presents a novel method for location recognition, which exploits an epitomic representation to achieve both high efficiency and good generalization. A generative model based on epitomic image analysis captures the appearance and geometric structure of an environment while allowing for variations due to motion, occlusions, and non-Lambertian effects. The ability to model translation and scale invariance together with the fusion of diverse visual features yields enhanced generalization with economical training. Experiments on both existing and new labeled image databases result in recognition accuracy superior to state of the art with real-time computational performance.	[Ni, Kai] Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA; [Kannan, Anitha] Microsoft Res Search Labs, Mountain View, CA 94043 USA; [Criminisi, Antonio; Winn, John] Microsoft Res Cambridge, Cambridge CB3 0FB, England	University System of Georgia; Georgia Institute of Technology; Microsoft; Microsoft	Ni, K (corresponding author), Georgia Inst Technol, Coll Comp, 350426 Georgia Tech Stn, Atlanta, GA 30332 USA.	nikai@cc.gatech.edu; ankannan@microsoft.com; antcrim@microsoft.com; jwinn@microsoft.com			Frank Dellaert	Frank Dellaert	This work was partially done when Kai Ni was supported by funding from Frank Dellaert.	[Anonymous], P IEEE C COMP VIS PA; Breiman L., 1999, TR567 U CAL BERK; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Chen Y, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.82; CRIMINISI A, 2006, INT J COMPUTER VISIO; Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403; JOHANSSON B, 2002, P INT ASS SCI TECHN; Jojic N., 2003, P INT C COMP VIS; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Petrovic N., 2006, CVPR06, V1, P79; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Se S, 2001, IEEE INT CONF ROBOT, P2051, DOI 10.1109/ROBOT.2001.932909; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273; Viola Paul, 2001, PROC CVPR IEEE; Wang JQ, 2006, IEEE T SYST MAN CY B, V36, P413, DOI 10.1109/TSMCB.2005.859085; WILLIAMS B, 2007, P INT C COMP VIS	18	29	31	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2158	2167		10.1109/TPAMI.2009.165	http://dx.doi.org/10.1109/TPAMI.2009.165			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY	19834138				2022-12-18	WOS:000271140100005
J	Hamsici, OC; Martinez, AM				Hamsici, Onur C.; Martinez, Aleix M.			Rotation Invariant Kernels and Their Application to Shape Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape analysis; kernel functions; rotation invariance; spherical-homoscedastic distributions; face recognition; object recognition; handshape; LB1	CLASSIFICATION; BINGHAM; MODELS	Shape analysis requires invariance under translation, scale, and rotation. Translation and scale invariance can be realized by normalizing shape vectors with respect to their mean and norm. This maps the shape feature vectors onto the surface of a hypersphere. After normalization, the shape vectors can be made rotational invariant by modeling the resulting data using complex scalar-rotation invariant distributions defined on the complex hypersphere, e.g., using the complex Bingham distribution. However, the use of these distributions is hampered by the difficulty in estimating their parameters and the nonlinear nature of their formulation. In the present paper, we show how a set of kernel functions that we refer to as rotation invariant kernels can be used to convert the original nonlinear problem into a linear one. As their name implies, these kernels are defined to provide the much needed rotation invariance property allowing one to bypass the difficulty of working with complex spherical distributions. The resulting approach provides an easy, fast mechanism for 2D & 3D shape analysis. Extensive validation using a variety of shape modeling and classification problems demonstrates the accuracy of this proposed approach.	[Hamsici, Onur C.; Martinez, Aleix M.] Ohio State Univ, Dept Elect & Comp Engn, Dreese Lab 205, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Hamsici, OC (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, Dreese Lab 205, 2015 Neil Ave, Columbus, OH 43210 USA.	hamsicio@ece.osu.edu; aleix@ece.osu.edu	Martinez, Aleix M/A-2380-2008		US National Institutes of Health US National Institutes of Health [R01 DC 005241]; US National Science Foundation [IIS 0713055]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS [R01DC005241] Funding Source: NIH RePORTER	US National Institutes of Health US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); US National Science Foundation(National Science Foundation (NSF)); NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))	This research was partially supported by the US National Institutes of Health under grant R01 DC 005241 and by the US National Science Foundation under grant IIS 0713055.	Brown P, 2004, NATURE, V431, P1055, DOI 10.1038/nature02999; COPPERSMITH D, 1990, J SYMB COMPUT, V9, P251, DOI 10.1016/S0747-7171(08)80013-2; DING L, 2007, P IEEE C ADV VID SIG; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287; Friedman J.H., 1996, ANOTHER APPROACH POL; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Haasdonk B, 2007, MACH LEARN, V68, P35, DOI 10.1007/s10994-007-5009-7; HAMSICI OC, 2007, P INT C COMP VIS; Hamsici OC, 2007, J MACH LEARN RES, V8, P1583; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; KENT JT, 1994, J ROY STAT SOC B MET, V56, P285; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; KONDOR R, 2007, ARXIVCS0701127V3; Kume A, 2005, BIOMETRIKA, V92, P465, DOI 10.1093/biomet/92.2.465; LATORRE FD, 2007, P IEEE C COMP VIS PA; Leibe B., 2003, P IEEE C COMP VIS PA; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Mardia K.V., 2000, DIRECTIONAL STAT, P15, DOI [10.1002/9780470316979, DOI 10.1002/9780470316979]; Martinez AM, 2008, PATTERN RECOGN, V41, P3436, DOI 10.1016/j.patcog.2008.04.018; Martinez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250; MARTINEZ AM, 2002, P IEEE INT C MULT IN; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Nene A. S., 1996, CUCS00696; OBDRZALEK S, 2005, P BRIT MACH VIS C, V1, P1; Phillips P.J., 2005, P IEEE C COMP VIS PA; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; THEOBALD CM, 1975, P CAMBR PHIL SOC, V77, P256; Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246; WALDER C, 2007, P 21 ADV NEUR INF PR; Wei L, 2007, J R SOC INTERFACE, V4, P207, DOI 10.1098/rsif.2006.0168; Yang MH, 2000, LECT NOTES COMPUT SC, V1842, P439; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	35	29	30	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					1985	1999		10.1109/TPAMI.2008.234	http://dx.doi.org/10.1109/TPAMI.2008.234			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	493VV	19762926				2022-12-18	WOS:000269767600005
J	Nock, R; Nielsen, F				Nock, Richard; Nielsen, Frank			Bregman Divergences and Surrogates for Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Ensemble learning; boosting; Bregman divergences; linear separators; decision trees	BOUNDS	Bartlett et al. (2006) recently proved that a ground condition for surrogates, classification calibration, ties up their consistent minimization to that of the classification risk, and left as an important problem the algorithmic questions about their minimization. In this paper, we address this problem for a wide set which lies at the intersection of classification calibrated surrogates and those of Murata et al. (2004). This set coincides with those satisfying three common assumptions about surrogates. Equivalent expressions for the members-sometimes well known-follow for convex and concave surrogates, frequently used in the induction of linear separators and decision trees. Most notably, they share remarkable algorithmic features: for each of these two types of classifiers, we give a minimization algorithm provably converging to the minimum of any such surrogate. While seemingly different, we show that these algorithms are offshoots of the same "master" algorithm. This provides a new and broad unified account of different popular algorithms, including additive regression with the squared loss, the logistic loss, and the top-down induction performed in CART, C4.5. Moreover, we show that the induction enjoys the most popular boosting features, regardless of the surrogate. Experiments are provided on 40 readily available domains.	[Nock, Richard] Univ Antilles Guyane, CEREGMIA, UFR Droit & Sci Econ, Campus Schoelcher,BP 7209, F-97275 Schoelcher, Martinique, France; [Nielsen, Frank] Ecole Polytech, LIX, F-91128 Palaiseau, France	Institut Polytechnique de Paris	Nock, R (corresponding author), Univ Antilles Guyane, CEREGMIA, UFR Droit & Sci Econ, Campus Schoelcher,BP 7209, F-97275 Schoelcher, Martinique, France.	rnock@martinique.univ-ag.fr; nielsen@lix.polytechnique.fr		Nielsen, Frank/0000-0001-5728-0726	ANR Blanc [ANR-07-BLAN-0328-01]	ANR Blanc(French National Research Agency (ANR))	The authors would like to thank the reviewers for constructive comments that significantly helped to improve the manuscript. Both authors are supported by ANR Blanc project ANR-07-BLAN-0328-01 "Computational Information Geometry and Applications."	AZRAN A, 2004, P C COMP LEARN THEOR, P427; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Banerjee A, 2005, IEEE T INFORM THEORY, V51, P2664, DOI 10.1109/TIT.2005.850145; BARTLETT P, 2006, P NEUR INF PROC SYST; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Collins M., 2000, P 13 ANN C COMP LEAR, P158; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; GENTILE C, 1998, P 1998 C ADV NEUR IN, P225; Grunwald PD, 2004, ANN STAT, V32, P1367, DOI 10.1214/009053604000000553; Helmbold DP, 1999, IEEE T NEURAL NETWOR, V10, P1291, DOI 10.1109/72.809075; Henry C, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P842; Kearns M, 1999, J COMPUT SYST SCI, V58, P109, DOI 10.1006/jcss.1997.1543; Kivinen J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, P134, DOI 10.1145/307400.307424; MATSUSHITA K, 1956, ANN I STAT MATH, V8, P67; Murata N, 2004, NEURAL COMPUT, V16, P1437, DOI 10.1162/089976604323057452; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Nock R, 2004, THEOR COMPUT SCI, V321, P371, DOI 10.1016/j.tcs.2004.05.004; Nock R, 2007, ARTIF INTELL, V171, P25, DOI 10.1016/j.artint.2006.10.014; Olshen R., 1984, CLASSIFICATION REGRE; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Schapire RE, 1998, ANN STAT, V26, P1651; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Vapnik V.N, 1998, STAT LEARNING THEORY; Warmuth MK, 2006, P 23 INT C MACHINE L, P1001, DOI DOI 10.1145/1143844.1143970	24	29	30	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					2048	2059		10.1109/TPAMI.2008.225	http://dx.doi.org/10.1109/TPAMI.2008.225			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	493VV	19762930				2022-12-18	WOS:000269767600009
J	Barwick, DS				Barwick, D. Shane			Very Fast Best-Fit Circular and Elliptical Boundaries by Chord Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Circle fitting; ellipse fitting; conic fitting; image segmentation; least-squares fitting	CURVES	Many machine vision tasks require objects to be delineated during image segmentation that have shapes that are well approximated by circles or ellipses. Due to their computational efficiency least-squares, algebraic methods are a popular choice for fitting an elliptic primitive to noisy image data when real-time processing is required. These methods, however, suffer from biased estimates and sensitivity to outlier data. In this paper, a real-time, least-squares method is proposed that provides an indirect geometric fit based on the quadratic polynomial form of parallel chord lengths. The algorithm is shown to be more computationally efficient and more easily made robust to outlier data than algebraic methods. Experimental results also suggest that it provides estimates that suffer less from bias error.	Rocky Mound Engn, Macon, GA 31216 USA		Barwick, DS (corresponding author), Rocky Mound Engn, 116 White Pine Ct, Macon, GA 31216 USA.	dsbarwick@cox.net						BEKC JV, 1977, PARAMETER ESTIMATION; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Fitzgibbon A. W., 1995, BMVC '95 Proceedings of the 6th British Machine Vision Conference, P513; Halir R, 1998, WSCG '98, VOL 1, P125; HALIR R, 2000, P 8 INT C CENTR EUR, V1; KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P320, DOI 10.1109/34.276132; Maini ES, 2006, INT J PATTERN RECOGN, V20, P939, DOI 10.1142/S021800140600506X; NAKAGAWA Y, 1979, PATTERN RECOGN, V11, P133, DOI 10.1016/0031-3203(79)90059-1; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; Talukder A, 2005, APPL OPTICS, V44, P693, DOI 10.1364/AO.44.000693; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Theil H., 1950, NEDERLANDSCHE AKAD W, V53, P1397	15	29	29	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1147	1152		10.1109/TPAMI.2008.279	http://dx.doi.org/10.1109/TPAMI.2008.279			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372617				2022-12-18	WOS:000265100000015
J	Pujol, O; Masip, D				Pujol, Oriol; Masip, David			Geometry-Based Ensembles: Toward a Structural Characterization of the Classification Boundary	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Classification; ensemble of classifiers; Gabriel neighboring rule; visual object recognition	REGRESSION	This paper introduces a novel binary discriminative learning technique based on the approximation of the nonlinear decision boundary by a piecewise linear smooth additive model. The decision border is geometrically defined by means of the characterizing boundary points-points that belong to the optimal boundary under a certain notion of robustness. Based on these points, a set of locally robust linear classifiers is defined and assembled by means of a Tikhonov regularized optimization procedure in an additive model to create a final lambda-smooth decision rule. As a result, a very simple and robust classifier with a strong geometrical meaning and nonlinear behavior is obtained. The simplicity of the method allows its extension to cope with some of today's machine learning challenges, such as online learning, large-scale learning or parallelization, with linear computational complexity. We validate our approach on the UCI database, comparing with several state-of-the-art classification techniques. Finally, we apply our technique in online and large-scale scenarios and in six real-life computer vision and pattern recognition problems: gender recognition based on face images, intravascular ultrasound tissue classification, speed traffic sign detection, Chagas' disease myocardial damage severity detection, old musical scores clef classification, and action recognition using 3D accelerometer data from a wearable device. The results are promising and this paper opens a line of research that deserves further attention.	[Pujol, Oriol] Univ Barcelona, Dept Matemat Aplicada & Anal, E-08007 Barcelona, Spain; [Masip, David] Univ Oberta Catalunya, Dept Comp Sci Multimedia & Telecomunicat, Barcelona 08018, Spain	University of Barcelona; UOC Universitat Oberta de Catalunya	Pujol, O (corresponding author), Univ Barcelona, Dept Matemat Aplicada & Anal, Edifici Histor,Gran Via Corts Catalanes 585, E-08007 Barcelona, Spain.	oriol_pujol@ub.edu; dmasipr@uoc.edu	Pujol, Oriol/F-7146-2016; Masip, David/B-1709-2009	Pujol, Oriol/0000-0001-7573-009X; Masip Rodo, David/0000-0001-7898-1847				Benavente R, 1998, 24 COMP VIS CTR; Bennett K.P., 2000, ICML, P57; Bern M, 1991, INT J COMPUT GEOM AP, V1, P79, DOI 10.1142/S0218195991000074; Bhattacharya B, 2005, LECT NOTES COMPUT SC, V3776, P60; BHATTACHARYA BK, 1981, P INT S INF THEOR; Bi JB, 2003, NEUROCOMPUTING, V55, P79, DOI 10.1016/S0925-2312(03)00380-1; Bishop C.M., 2000, 16 C UNCERTAINTY ART, P46; Caballero KL, 2006, LECT NOTES COMPUT SC, V4225, P137; *DELFT U TECHN FAC, 2009, PRTOOLS TOOLB; Demsar J, 2006, J MACH LEARN RES, V7, P1; ESCALERA S, 2008, P IEEE INT C INT SYS, V2; Escalera S, 2007, LECT NOTES COMPUT SC, V4756, P142; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; GABRIEL KR, 1969, SYST ZOOL, V18, P259, DOI 10.2307/2412323; Hamsici OC, 2007, J MACH LEARN RES, V8, P1583; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Mukherjee K., 2004, THESIS SIMON FRASER; Murphy P., 1994, UCI REPOSITORY MACHI; OSU-SVM-TOOLBOX, OSU SVM TOOLB; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; ZHANG W, 2002, P INT C NEUR NETW, V1, P239	22	29	33	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1140	1146		10.1109/TPAMI.2009.31	http://dx.doi.org/10.1109/TPAMI.2009.31			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372616				2022-12-18	WOS:000265100000014
J	Demirci, MF; Shokoufandeh, A; Dickinson, SJ				Demirci, M. Fatih; Shokoufandeh, Ali; Dickinson, Sven J.			Skeletal Shape Abstraction from Examples	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape abstraction; medial axis graphs; prototype learning; many-to-many graph matching	RECOGNITION; MODELS	Learning a class prototype from a set of exemplars is an important challenge facing researchers in object categorization. Although the problem is receiving growing interest, most approaches assume a one-to-one correspondence among local features, restricting their ability to learn true abstractions of a shape. In this paper, we present a new technique for learning an abstract shape prototype from a set of exemplars whose features are in many-to-many correspondence. Focusing on the domain of 2D shape, we represent a silhouette as a medial axis graph whose nodes correspond to "parts" defined by medial branches and whose edges connect adjacent parts. Given a pair of medial axis graphs, we establish a many-to-many correspondence between their nodes to find correspondences among articulating parts. Based on these correspondences, we recover the abstracted medial axis graph along with the positional and radial attributes associated with its nodes. We evaluate the abstracted prototypes in the context of a recognition task.	[Demirci, M. Fatih] TOBB Univ Econ & Technol, Dept Comp Engn, TR-06560 Ankara, Turkey; [Shokoufandeh, Ali] Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA; [Dickinson, Sven J.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	TOBB Ekonomi ve Teknoloji University; Drexel University; University of Toronto	Demirci, MF (corresponding author), TOBB Univ Econ & Technol, Dept Comp Engn, Sogutozu Cad 43, TR-06560 Ankara, Turkey.	mfdemirci@etu.edu.tr; ashokouf@cs.drexel.edu; sven@cs.toronto.edu			TUBITAK [107E208]; US Office of Naval Research; US National Science Foundation (NSF); NSERC; PREA; NSF; CITO	TUBITAK(Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK)); US Office of Naval Research(Office of Naval Research); US National Science Foundation (NSF)(National Science Foundation (NSF)); NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); PREA; NSF(National Science Foundation (NSF)); CITO	F. Demirci gratefully acknowledges the support of TUBITAK grant no. 107E208, A. Shokoufandeh the support of the US Office of Naval Research and US National Science Foundation (NSF), and S. Dickinson the support of NSERC, PREA, NSF, and CITO.	Agarwala R, 1999, SIAM J COMPUT, V28, P1073, DOI 10.1137/S0097539795296334; August J, 1999, COMPUT VIS IMAGE UND, V76, P231, DOI 10.1006/cviu.1999.0802; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; BURTNYK N, 1976, COMMUN ACM, V19, P564, DOI 10.1145/360349.360357; CHENG LRL, 1989, TOP LANG DISORD, V9, P1; Demirci MF, 2006, INT J COMPUT VISION, V69, P203, DOI 10.1007/s11263-006-6993-y; DUTA N, 1999, P IEEE C COMP VIS PA, V2, P8; Ettinger G. J., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P32, DOI 10.1109/CVPR.1988.196212; Fei-Fei L., 2004, P IEEE C COMP VIS PA; Fergus R, 2003, PROC CVPR IEEE, P264; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Jiang XY, 2001, IEEE T PATTERN ANAL, V23, P1144; Keselman Y, 2005, IEEE T PATTERN ANAL, V27, P1141, DOI 10.1109/TPAMI.2005.139; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; Leibe B., 2003, P IEEE C COMP VIS PA; LEVINSHTEIN A, 2005, P INT WORKSH EN MIN, P251; Lozano MA, 2006, PATTERN RECOGN, V39, P539, DOI 10.1016/j.patcog.2005.10.008; Luo B, 2003, PATTERN RECOGN, V36, P2213, DOI 10.1016/S0031-3203(03)00084-0; Matousek J, 1999, ISRAEL J MATH, V114, P221, DOI 10.1007/BF02785579; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653; SIDDIQI MK, 2008, P IEEE C COMP VIS PA; Todorovic S, 2008, IEEE T PATTERN ANAL, V30, P2158, DOI 10.1109/TPAMI.2008.24; Torsello A, 2006, IEEE T PATTERN ANAL, V28, P954, DOI 10.1109/TPAMI.2006.125; UEDA N, 1993, IEEE T PATTERN ANAL, V15, P337, DOI 10.1109/34.206954; WEBER M, 2000, P ECCV, V1, P18; Whittaker ET., 1967, CALCULUS OBSERVATION; Winn J, 2005, IEEE I CONF COMP VIS, P756; Winston PH, 1975, PSYCHOL COMPUTER VIS, P157	37	29	30	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					944	952		10.1109/TPAMI.2008.267	http://dx.doi.org/10.1109/TPAMI.2008.267			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19299866	Green Submitted			2022-12-18	WOS:000264144500014
J	Goldberger, J; Greenspan, H; Dreyfuss, J				Goldberger, Jacob; Greenspan, Hayit; Dreyfuss, Jeremie			Simplifying mixture models using the Unscented Transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mixture of Gaussians; reduced model; Unscented Transform; weighted likelihood; clustering.		Mixture of Gaussians (MoG) model is a useful tool in statistical learning. In many learning processes that are based on mixture models, computational requirements are very demanding due to the large number of components involved in the model. We propose a novel algorithm for learning a simplified representation of a Gaussian mixture that is based on the Unscented Transform, which was introduced for filtering nonlinear dynamical systems. The superiority of the proposed method is validated on both simulation experiments and categorization of a real image database. The proposed categorization methodology is based on modeling each image using a Gaussian mixture model. A category model is obtained by learning a simplified mixture model from all the images in the category.	[Goldberger, Jacob] Bar Ilan Univ, Sch Engn, IL-52900 Ramat Gan, Israel; [Greenspan, Hayit; Dreyfuss, Jeremie] Tel Aviv Univ, Dept Biomed Engn, IL-69978 Tel Aviv, Israel	Bar Ilan University; Tel Aviv University	Goldberger, J (corresponding author), Bar Ilan Univ, Sch Engn, IL-52900 Ramat Gan, Israel.	goldbej@eng.biu.ac.il; hayit@eng.tau.ac.il; jeremied@lycos.com						Bar-Shalom Y, 1993, ESTIMATION TRACKING; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Davies K, 2006, CHEM WORLD-UK, V3, P20; Goldberger J, 2006, IEEE T PATTERN ANAL, V28, P463, DOI 10.1109/TPAMI.2006.47; GOLDBERGER J, 2007, P IEEE C COMP VIS PA; Goldberger J, 2003, P 9 IEEE INT C COMP; GOLDBERGER J, 2004, P 18 ANN C NEUR INF; Greenspan H, 2007, IEEE T INF TECHNOL B, V11, P190, DOI 10.1109/TITB.2006.874191; Han B., 2004, P IEEE C COMP VIS PA; HU F, 1997, CANADIAN J STAT, P45; Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141; Julier SJ, 2002, P AMER CONTR CONF, V1-6, P4555, DOI 10.1109/ACC.2002.1025369; Kurkoski B., 2007, P 30 S INF THEOR ITS, P877; Lehmann TM, 2004, METHOD INFORM MED, V43, P354; LEHMANN TM, 2005, COMPUTERIZED MED IMA, P143; Neal R. M., 1999, LEARNING GRAPHICAL M, P355, DOI DOI 10.1007/978-94-011-5014-9; PETROVIC N, 2006, P IEEE C COMP VIS PA; SUDDERTH EB, 2006, P 20 ANN C NEUR INF; VASCONCELOS N, 2001, P 8 INT C COMP VIS I; Wang XG, 2004, J STAT PLAN INFER, V119, P37, DOI 10.1016/S0378-3758(02)00410-X; ZHANG K, 2006, P 20 ANN C NEUR INF	22	29	30	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1496	1502		10.1109/TPAMI.2008.100	http://dx.doi.org/10.1109/TPAMI.2008.100			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566502				2022-12-18	WOS:000256679700015
J	LaViola, JJ; Zeleznik, R				LaViola, Joseph J., Jr.; Zeleznik, Robert			A practical approach for writer-dependent symbol recognition using a writer-independent symbol recognizer	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwriting recognition; AdaBoost; writer dependence; writer independence; pairwise classification; real-time systems	ONLINE; CLASSIFICATION; ART	We present a practical technique for using a writer-independent recognition engine to improve the accuracy and speed while reducing the training requirements of a writer-dependent symbol recognizer. Our writer-dependent recognizer uses a set of binary classifiers based on the AdaBoost learning algorithm, one for each possible pairwise symbol comparison. Each classifier consists of a set of weak learners, one of which is based on a writer-independent handwriting recognizer. During online recognition, we also use the n-best list of the writer-independent recognizer to prune the set of possible symbols and, thus, reduce the number of required binary classifications. In this paper, we describe the geometric and statistical features used in our recognizer and our all-pairs classification algorithm. We also present the results of experiments that quantify the effect incorporating a writer-independent recognition engine into a writer-dependent recognizer has on accuracy, speed, and user training time.	Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA; Brown Univ, Dept Comp Sci, Providence, RI 02912 USA	State University System of Florida; University of Central Florida; Brown University	LaViola, JJ (corresponding author), Univ Cent Florida, Sch Elect Engn & Comp Sci, Engn 3 Harris Ctr, Orlando, FL 32816 USA.	jjl@cs.ucf.edu; bcz@cs.brown.edu						Allwein EL, 2001, J MACH LEARN RES, V1, P113, DOI 10.1162/15324430152733133; Bahlmann C, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P49, DOI 10.1109/IWFHR.2002.1030883; BIEM A, 1984, IEEE T PATTERN ANAL, V6, P105; Brakensiek A., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P486, DOI 10.1109/ICDAR.2001.953837; Chancellor MB, 2000, NEUROMODULATION, V3, P15, DOI 10.1046/j.1525-1403.2000.00015.x; Connell SD, 2002, IEEE T PATTERN ANAL, V24, P329, DOI 10.1109/34.990135; Connell SD, 2001, PATTERN RECOGN, V34, P1, DOI 10.1016/S0031-3203(99)00197-1; DAY AM, 1972, MACHINE PERCEPTION P, P233; Deepu V, 2004, INT C PATT RECOG, P327, DOI 10.1109/ICPR.2004.1334196; DIMITRIADIS YA, 1995, PATTERN RECOGN, V28, P807, DOI 10.1016/0031-3203(94)00160-N; DONAHEY A, 1976, Patent No. 3996557; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FRIEDMAN J, 1996, APPROACH POLYCHOTOMO; GRONER GF, 1968, PATTERN RECOGN, P103; GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870; Hastie T, 1998, ANN STAT, V26, P451; JARRETT R, 2003, BUILDING TABLET PC A; KERRICK DD, 1988, PATTERN RECOGN, V21, P525, DOI 10.1016/0031-3203(88)90011-8; KOSCHINSKI M, 1995, INT CONF ACOUST SPEE, P2439, DOI 10.1109/ICASSP.1995.479986; Kosmala A, 1998, INT C PATT RECOG, P1306, DOI 10.1109/ICPR.1998.711941; LAVIOLA J, 2005, THESIS BROWN U; Li XL, 1997, PATTERN RECOGN, V30, P31, DOI 10.1016/S0031-3203(96)00052-0; Marzinkewitsch R., 1991, Proceedings of the 1991 International Symposium on Symbolic and Algebraic Computation. ISSAC '91, P411, DOI 10.1145/120694.120757; Mathis C, 2002, INT C PATT RECOG, P103, DOI 10.1109/ICPR.2002.1044623; MATSAKIS NE, 1999, THESIS MIT; Miller EG, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P784; NAKAYAMA Y, 1993, EDUCATIONAL MULTIMEDIA AND HYPERMEDIA ANNUAL, 1993, P400; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; POWERS VM, 1973, PATTERN RECOGN, V5, P291, DOI 10.1016/0031-3203(73)90022-8; Prevost L, 1998, INT C PATT RECOG, P381, DOI 10.1109/ICPR.1998.711160; RUBINE D, 1991, COMP GRAPH, V25, P329, DOI 10.1145/127719.122753; Sarkar P, 2005, IEEE T PATTERN ANAL, V27, P88, DOI 10.1109/TPAMI.2005.18; Schapire RE, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1401; SCHWENK H, 1997, LNCS, V1327, P967; SHILMAN M, 2002, P 9 INT WORKSH FRONT, P569; Smithies S, 1999, PROC GRAPH INTERF, P84; SUBRAHMONIA J, 1996, P ICASSP 96 ATL GEOR, V6, P3478; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; Weisstein E. W., 1998, CRC CONCISE ENCY MAT; Winkler H.J., 1994, P INT WORKSH MOD MOD	40	29	30	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					1917	1926		10.1109/TPAMI.2007.1109	http://dx.doi.org/10.1109/TPAMI.2007.1109			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848774				2022-12-18	WOS:000249343900004
J	Fan, ZM; Yang, M; Wu, Y				Fan, Zhimin; Yang, Ming; Wu, Ying			Multiple collaborative kernel tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						kernel-based tracking; multiple kernel; visual tracking	MEAN SHIFT	Those motion parameters that cannot be recovered from image measurements are unobservable in the visual dynamic system. This paper studies this important issue of singularity in the context of kernel-based tracking and presents a novel approach that is based on a motion field representation which employs redundant but sparsely correlated local motion parameters instead of compact but uncorrelated global ones. This approach makes it easy to design fully observable kernel-based motion estimators. This paper shows that these high-dimensional motion fields can be estimated efficiently by the collaboration among a set of simpler local kernel-based motion estimators, which makes the new approach very practical.	Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA	Northwestern University	Fan, ZM (corresponding author), Northwestern Univ, Dept Elect Engn & Comp Sci, 2145 Sheridan Rd, Evanston, IL 60208 USA.	zfa825@ece.northwestern.edu; mya671@ece.northwestern.edu; yingwu@ece.northwestern.edu	Yang, Ming-Hsuan/T-9533-2019; Wu, Ying/B-7283-2009	Yang, Ming-Hsuan/0000-0003-4848-2304; Yang, Ming/0000-0003-1691-6817				Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Collins RT, 2003, PROC CVPR IEEE, P234; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P438, DOI 10.1109/ICCV.2001.937550; Fan ZM, 2005, PROC CVPR IEEE, P502; Hager GD, 2004, PROC CVPR IEEE, P790; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Wand M.P., 1995, KERNEL SMOOTHING; WANG J, 2004, P EUR C COMP VIS; Wu Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1094, DOI 10.1109/ICCV.2003.1238471; Zivkovic Z, 2004, PROC CVPR IEEE, P798	14	29	32	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1268	1273		10.1109/TPAMI.2007.1034	http://dx.doi.org/10.1109/TPAMI.2007.1034			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496383	Green Submitted			2022-12-18	WOS:000246395300013
J	El Munim, HEA; Farag, AA				El Munim, Hossam E. Abd; Farag, Aly A.			Curve/surface representation and evolution using vector level sets with application to the shape-based segmentation problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape representation; level sets; deformable models; shape-based segmentation	IMAGE; REGISTRATION; INFORMATION; OBJECTS; SNAKES	In this paper, we revisit the implicit front representation and evolution using the vector level set function (VLSF) proposed in [1]. Unlike conventional scalar level sets, this function is designed to have a vector form. The distance from any point to the nearest point on the front has components (projections) in the coordinate directions included in the vector function. This kind of representation is used to evolve closed planar curves and 3D surfaces as well. Maintaining the VLSF property as the distance projections through evolution will be considered together with a detailed derivation of the vector partial differential equation (PDE) for such evolution. A shape-based segmentation framework will be demonstrated as an application of the given implicit representation. The proposed level set function system will be used to represent shapes to give a dissimilarity measure in a variational object registration process. This kind of formulation permits us to better control the process of shape registration, which is an important part in the shape-based segmentation framework. The method depends on a set of training shapes used to build a parametric shape model. The color is taken into consideration besides the shape prior information. The shape model is fitted to the image volume by registration through an energy minimization problem. The approach overcomes the conventional methods problems like point correspondences and weighing coefficients tuning of the evolution (PDEs). It is also suitable for multidimensional data and computationally efficient. Results in 2D and 3D of real and synthetic data will demonstrate the efficiency of the framework.	Univ Louisville, Comp Vis & Image Proc Lab, CVIP LAB Dept Elect & Comp Engn, Louisville, KY 40292 USA	University of Louisville	El Munim, HEA (corresponding author), Univ Louisville, Comp Vis & Image Proc Lab, CVIP LAB Dept Elect & Comp Engn, Lutz Hall,Room 412, Louisville, KY 40292 USA.	hossam@cvip.uofl.edu; aly.farag@louisville.edu		Abd El Munim, Hossam El Din/0000-0002-2223-2887				Abd El Munim HE, 2005, IEEE I CONF COMP VIS, P930; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985; Cohen I, 1998, PROC CVPR IEEE, P741, DOI 10.1109/CVPR.1998.698686; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; CREMERS D, 2003, P 2 IEEE WORKSH VAR, P169; EVANS LC, 1991, J DIFFER GEOM, V33, P635, DOI 10.4310/jdg/1214446559; FITZGIBBON A, 2001, P BRIT MACH VIS C BM, V2, P411; Goldenberg R, 2002, IEEE T MED IMAGING, V21, P1544, DOI 10.1109/TMI.2002.806594; Gomes J, 2003, INT J COMPUT VISION, V52, P161, DOI 10.1023/A:1022956108418; GOMES J, 1999, 3666 INRIA; GOMES J, 2000, 4011 INRIA; Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171; Huang XL, 2003, LECT NOTES COMPUT SC, V2879, P926; Huang XL, 2004, PROC CVPR IEEE, P496; Johnson AE, 1997, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.1997.609400; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kozinska D, 1997, GRAPH MODEL IM PROC, V59, P373, DOI 10.1006/gmip.1997.0447; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; Li CM, 2005, PROC CVPR IEEE, P430; Malladi R., 1994, P 3 EUR C COMP VIS; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osher S., 2003, GEOMETRIC LEVEL SET; Paragios N., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P300, DOI 10.1109/CVPR.1999.784648; PARAGIOS N, 2002, P 7 EUR C COMP VIS; RIKLINRAVIV T, 2004, P ECCV, P50; Rousson M, 2004, LECT NOTES COMPUT SC, V3216, P209; SAMSON C, 1999, 3662 INRIA; Sapiro G., 2001, GEOMETRIC PARTIAL DI; Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591; SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155; Tsai A, 2004, MED IMAGE ANAL, V8, P429, DOI 10.1016/j.media.2004.01.003; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Yang J, 2004, MED IMAGE ANAL, V8, P285, DOI 10.1016/j.media.2004.06.008; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	36	29	30	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2007	29	6					945	958		10.1109/TPAMI.2007.1100	http://dx.doi.org/10.1109/TPAMI.2007.1100			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	155TJ	17431295				2022-12-18	WOS:000245600800003
J	Prabhakar, S; Kittler, J; Maltoni, D; O'Gorman, L; Tan, T				Prabhakar, Salil; Kittler, Josef; Maltoni, Davide; O'Gorman, Lawrence; Tan, Tieniu			Introduction to the special issue on biometrics: Progress and directions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									Digital Persona Inc, Redwood City, CA 94063 USA; Univ Surrey, Sch Elect & Phys Sci, Guildford GU2 7XH, Surrey, England; Univ Bologna, I-40126 Bologna, Italy	University of Surrey; University of Bologna	Prabhakar, S (corresponding author), Digital Persona Inc, 720 Bay Rd,Suite 100, Redwood City, CA 94063 USA.	SalilP@digitalpersona.com; J.Kittler@surrey.ac.uk; maltoni@csr.unibo.it; logorman@avaya.com; tnt@nlpr.ia.ac.cn	Hyvarinen, Aapo/E-9006-2012	Wang, Yunlong/0000-0002-3535-308X					0	29	29	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					513	516		10.1109/TPAMI.2007.1025	http://dx.doi.org/10.1109/TPAMI.2007.1025			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ					2022-12-18	WOS:000244855600001
J	Zhang, W; Liu, WY; Zhang, K				Zhang, Wan; Liu, Wenyin; Zhang, Kun			Symbol recognition with kernel density matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						symbol recognition; graphics recognition; kernel density; independent component analysis	INDEPENDENT COMPONENT ANALYSIS	We propose a novel approach to similarity assessment for graphic symbols. Symbols are represented as 2D kernel densities and their similarity is measured by the Kullback-Leibler divergence. Symbol orientation is found by gradient-based angle searching or independent component analysis. Experimental results show the outstanding performance of this approach in various situations.	Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	University of Hong Kong; Chinese University of Hong Kong	Zhang, W (corresponding author), Univ Hong Kong, Dept Comp Sci, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.	wanzhang@cityu.edu.hk; csliuwy@cityu.edu.hk; kzhang@cse.cuhk.edu.hk						Ah-Soon C, 2001, PATTERN RECOGN LETT, V22, P231, DOI 10.1016/S0167-8655(00)00091-X; [Anonymous], 1992, STRUCTURED DOCUMENT, DOI DOI 10.1007/978-3-642-77281-8_16; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541; DOSCH P, 2003, P 5 INT WORKSH GRAPH, P154; HSE H, 2003, M0349 UCB ERL; Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LIBENZI D, 2006, RAS2VEC 1 2 FREEWARE; Liu Y, 2004, INT C PATT RECOG, P371, DOI 10.1109/ICPR.2004.1334129; Llados J, 2001, IEEE T PATTERN ANAL, V23, P1137, DOI 10.1109/34.954603; Scott DW, 2004, HANDBOOK OF COMPUTATIONAL STATISTICS: CONCEPTS AND METHODS, P517; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; SINGH M, 2004, P 2004 C COMP VIS PA, V11, P174; VALVENY E, 2004, P GRAPH REC REC ADV, P367; VENTURA AD, 1994, P 12 INT C PATT REC, V2, P533; XIAOGANG X, 2004, INT J DOC ANAL RECOG, V7, P44; Yang S, 2005, IEEE T PATTERN ANAL, V27, P278, DOI 10.1109/TPAMI.2005.38; YU B, 1995, ICDAR 95 P 3 INT C D, V2, P803; ZHANG J, 2005, P 6 IAPR INT WORKSH	22	29	30	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					2020	U1		10.1109/TPAMI.2006.254	http://dx.doi.org/10.1109/TPAMI.2006.254			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108374				2022-12-18	WOS:000241195700010
J	Mitiche, A; Sekkati, H				Mitiche, Amar; Sekkati, Hicham			Optical flow 3D segmentation and interpretation: A variational method with active curve evolution and level sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical flow; 3D segmentation; 3D interpretation; level sets; image sequence analysis	REGION COMPETITION; MOTION; SHAPE; SEQUENCES; DEPTH	This study investigates a variational, active curve evolution method for dense three-dimentional (3D) segmentation and interpretation of optical flow in an image sequence of a scene containing moving rigid objects viewed by a possibly moving camera. This method jointly performs 3D motion segmentation, 3D interpretation (recovery of 3D structure and motion), and optical flow estimation. The objective functional contains two data terms for each segmentation region, one based on the motion-only equation which relates the essential parameters of 3D rigid body motion to optical flow, and the other on the Horn and Schunck optical flow constraint. It also contains two regularization terms for each region, one for optical flow, the other for the region boundary. The necessary conditions for a minimum of the functional result in concurrent 3D-motion segmentation, by active curve evolution via level sets, and linear estimation of each region essential parameters and optical flow. Subsequently, the screw of 3D motion and regularized relative depth are recovered analytically for each region from the estimated essential parameters and optical flow. Examples are provided which verify the method and its implementation.	INRS, EMT, Montreal, PQ H5A 1K6, Canada	University of Quebec; Institut national de la recherche scientifique (INRS)	Mitiche, A (corresponding author), INRS, EMT, Pl Bonaventure,800 Gauchetiere Ouest Suite 6900, Montreal, PQ H5A 1K6, Canada.	mitiche@emt.inrs.ca; sekkati@emt.inrs.ca						ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; Aloimonos J., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P72; Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928; Aubert G, 1999, SIAM J APPL MATH, V60, P156, DOI 10.1137/S0036139998340170; Aubert G., 2002, MATH PROBLEMS IMAGE; Brodsky T, 2000, INT J COMPUT VISION, V37, P231, DOI 10.1023/A:1008132107950; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; Chan T, 1999, LECT NOTES COMPUT SC, V1682, P141; Debrunner C, 1998, IEEE T PATTERN ANAL, V20, P206, DOI 10.1109/34.659941; DEMICHELI E, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P962, DOI 10.1109/CVPR.1994.323934; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Feghali R, 2004, IEEE T IMAGE PROCESS, V13, P1473, DOI 10.1109/TIP.2004.836158; Fejes S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P979, DOI 10.1109/ICCV.1998.710835; Forsythe GE., 1977, COMPUTER METHODS MAT; GUPTA NC, 1995, ARTIF INTELL, V78, P45, DOI 10.1016/0004-3702(95)00031-3; Hartley R. I., 2000, MULTIPLE VIEW GEOMET; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; Hung YS, 1999, IEEE T PATTERN ANAL, V21, P570, DOI 10.1109/34.771330; LECLERC Y, 1996, INT J COMPUT VISION, P73; LIU H, 2002, P WORKSH MOT VID COM; LONGUETHIGGINS H, 1981, ROYAL SOC LONDON B, V208, P385; MACLEAN WJ, 1994, P 5 BRIT MACH VIS C, P13; Mansouri AR, 2006, COMPUT VIS IMAGE UND, V101, P137, DOI 10.1016/j.cviu.2005.07.008; Mitiche A, 2003, PATTERN ANAL APPL, V6, P78, DOI 10.1007/s10044-002-0182-6; MITICHE A, 1994, COMPUTATIONAL ANAL V; MOREL JM, 1994, VARIATIONAL METHODS; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; Osher S., 2003, GEOMETRIC LEVEL SET; Rousson M, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P56, DOI 10.1109/MOTION.2002.1182214; Sekkati H, 2006, IEEE T IMAGE PROCESS, V15, P641, DOI 10.1109/TIP.2005.863699; Sekkati H, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P424, DOI 10.1109/ICIAP.2003.1234087; Sethian J. A., 1999, LEVEL SET METHODS FA; SHAHRARAY B, 1988, P INT C COMP VIS, P641; Srinivasan S, 2000, INT J COMPUT VISION, V37, P203, DOI 10.1023/A:1008111923880; TAALEBINEZHAAD MA, 1992, IEEE T PATTERN ANAL, V14, P847, DOI 10.1109/34.149584; Vazquez C, 2004, IEEE IMAGE PROC, P3467; Weber J, 1997, IEEE T PATTERN ANAL, V19, P139, DOI 10.1109/34.574794; XIONG Y, 1998, P INT C COMP VIS IM, P222; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; ZHUANG X, 1984, P 1 INT C ART INT AP, P366	45	29	36	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1818	1829		10.1109/TPAMI.2006.232	http://dx.doi.org/10.1109/TPAMI.2006.232			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063686				2022-12-18	WOS:000240443400009
J	Begelfor, E; Werman, M				Begelfor, E; Werman, M			How to put probabilities on homographies	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						homography; lie groups; normal distribution; Bayesian statistics; geodesics		We present a family of "normal" distributions over a matrix group together with a simple method for estimating its parameters. In particular, the mean of a set of elements can be calculated. The approach is applied to planar projective homographies, showing that using priors defined in this way improves object recognition.	Hebrew Univ Jerusalem, Dept Comp Sci, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Begelfor, E (corresponding author), Hebrew Univ Jerusalem, Dept Comp Sci, IL-91904 Jerusalem, Israel.	aristo@cs.huji.ac.il; werman@cs.huji.ac.il						Berger M., 2003, PANORAMIC VIEW RIEMA; Buser P., 1981, ASTERISQUE, V81; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fletcher PT, 2003, PROC CVPR IEEE, P95; Fletcher PT, 2003, LECT NOTES COMPUT SC, V2732, P450; Govindu VM, 2004, PROC CVPR IEEE, P684; Grenander U., 1963, PROBABILITIES ALGEBR; Hays WL, 1970, STAT PROBABILITY INF; Helgason S., 1978, DIFFERENTIAL GEOMETR, V80; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MILLER E, 2003, P IEEE COMP VIS PATT, V2, P114; Pennec X, 1999, PROCEEDINGS OF THE IEEE-EURASIP WORKSHOP ON NONLINEAR SIGNAL AND IMAGE PROCESSING (NSIP'99), P194; Rao RPN, 1999, ADV NEUR IN, V11, P810; VARADARAJAN VS, 1974, LIE GROUPS LIE ALGEB; Wang H.-C., 1969, J DIFFER GEOM, V3, P481	15	29	29	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1666	1670		10.1109/TPAMI.2005.200	http://dx.doi.org/10.1109/TPAMI.2005.200			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	953OM	16238000	Green Submitted			2022-12-18	WOS:000231086700013
J	Yang, L				Yang, L			Distance-preserving projection of high-dimensional data for nonlinear dimensionality reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; statistical; feature evaluation and selection; pattern analysis	INTRINSIC DIMENSIONALITY; ALGORITHM	A distance-preserving method is presented to map high-dimensional data sequentially to low-dimensional space. It preserves exact distances of each data point to its nearest neighbor and to some other near neighbors. Intrinsic dimensionality of data is estimated by examining the preservation of interpoint distances. The method has no user-selectable parameter. It can successfully project data when the data points are spread among multiple clusters. Results of experiments show its usefulness in projecting high-dimensional data.	Western Michigan Univ, Dept Comp Sci, Kalamazoo, MI 49008 USA	Western Michigan University	Yang, L (corresponding author), Western Michigan Univ, Dept Comp Sci, Parkview Campus,1903 W Michigan Ave, Kalamazoo, MI 49008 USA.	li.yang@umich.edu						Balasubramanian M, 2002, SCIENCE, V295; BENNETT RS, 1969, IEEE T INFORM THEORY, V15, P517, DOI 10.1109/TIT.1969.1054365; BISWAS G, 1981, IEEE T PATTERN ANAL, V3, P701, DOI 10.1109/TPAMI.1981.4767175; BLAKE CL, 1998, UCI RESPOSITORY MACH; Bruske J, 1998, IEEE T PATTERN ANAL, V20, P572, DOI 10.1109/34.682189; Burges, 1998, MNIST DATABASE; Demartines P, 1997, IEEE T NEURAL NETWOR, V8, P148, DOI 10.1109/72.554199; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kohonen T., 1997, SELF ORG MAPS; KRUSKAL JB, 1971, IEEE T COMPUT, VC 20, P1614, DOI 10.1109/T-C.1971.223184; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Lee JH, 2000, 2000 IEEE/LEOS INTERNATIONAL CONFERENCE ON OPTICAL MEMS, P13, DOI 10.1109/OMEMS.2000.879604; LEE RCT, 1977, IEEE T COMPUT, V26, P288, DOI 10.1109/TC.1977.1674822; NIEMANN H, 1979, IEEE T COMPUT, V28, P142, DOI 10.1109/TC.1979.1675303; OLSEN DR, 1973, IEEE T COMPUT, VC 22, P915, DOI 10.1109/T-C.1973.223618; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25, DOI 10.1109/TPAMI.1979.4766873; PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TRUNK GV, 1976, IEEE T COMPUT, V25, P165, DOI 10.1109/TC.1976.5009231; VERVEER PJ, 1995, IEEE T PATTERN ANAL, V17, P81, DOI 10.1109/34.368147; Vlachos M., 2002, P 8 ACM SIGKDD INT C, P645, DOI DOI 10.1145/775047.775143	26	29	37	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1243	1246		10.1109/TPAMI.2004.66	http://dx.doi.org/10.1109/TPAMI.2004.66			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742900				2022-12-18	WOS:000222605100014
J	Borgefors, G; Ramella, G; di Baja, GS				Borgefors, G; Ramella, G; di Baja, GS			Hierarchical decomposition of multiscale skeletons	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						skeleton; decomposition; multiresolution; binary pyramid	SHAPE-DESCRIPTION; ALGORITHM; REPRESENTATION; EXTRACTION; FEATURES; GRAPHS	This paper presents a new procedure to hierarchically decompose a multiscale discrete skeleton. The skeleton is a linear pattern representation that is generally recognized as a good shape descriptor. For discrete images, the discrete skeleton is often preferable. Multiresolution representations are convenient for many image analysis tasks. Our resulting skeleton decomposition shows two different types of hierarchy. The first type of hierarchy is one of different scales, as the original pattern is converted into an AND-pyramid and the skeleton is computed for each resolution level. The second type of hierarchy is established at each level of the pyramid by identifying and ranking skeleton subsets according to their permanence, where permanence is a property intrinsically related to local pattern thickness. To achieve the decomposition, both bottom-up and top-down analysis in the sense of moving from higher to lower resolution and vice versa are used. The bottom-up analysis is used to ensure that a part of the skeleton that is connected at a higher resolution level is also connected (if at all present) in the next, lower resolution level. The top-down analysis is used to build the permanence hierarchy ranking the skeleton components. Our procedure is based on the use of (3 x 3) local operations in digital images, so it is fast and easy to implement. This skeleton decomposition procedure is most effective on patterns having different thickness in different regions. A number of examples of decompositions of multiscale skeletons (with and without loops) will be shown. The skeletons are, in most cases, nicely decomposed into meaningful parts. The procedure is general and not limited to any specific application.	Swedish Univ Agr Sci, Ctr Image Anal, SE-75237 Uppsala, Sweden; Italian Natl Res Council, Ist Cibernet, IT-80078 Naples, Italy	Swedish University of Agricultural Sciences; Consiglio Nazionale delle Ricerche (CNR); Istituto di Cibernetica "Eduardo Caianiello" (ICIB-CNR)	Borgefors, G (corresponding author), Swedish Univ Agr Sci, Ctr Image Anal, Lagerhyddvagen 17, SE-75237 Uppsala, Sweden.		Ramella, Giuliana/AAN-7025-2021	RAMELLA, Giuliana/0000-0001-6044-5237; Sanniti di Baja, Gabriella/0000-0003-2218-0412				ARCELLI C, 1993, IMAGE VISION COMPUT, V11, P163, DOI 10.1016/0262-8856(93)90055-L; ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P463, DOI 10.1109/TPAMI.1985.4767685; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Borgefors G, 1999, GRAPH MODEL IM PROC, V61, P44, DOI 10.1006/prmp.1999.0489; BORGEFORS G, 1997, LECT NOTES COMPUTER, V1310, P369; BORGEFORS G, 1996, P 13 INT C PATT REC, VD, P570; BORGEFORS G, 1997, ADV VISUAL FORM ANAL, P31; Bottoni P, 1998, PATTERN RECOGN, V31, P89, DOI 10.1016/S0031-3203(97)00021-6; CHETVERIKOV D, 1992, PATTERN RECOGN LETT, V13, P669, DOI 10.1016/0167-8655(92)90123-H; Concepcion V, 1996, PATTERN RECOGN, V29, P1543, DOI 10.1016/0031-3203(96)00013-1; CONNELLY S, 1990, COMPUT VISION GRAPH, V49, P332, DOI 10.1016/0734-189X(90)90107-7; diBaja GS, 1996, IMAGE VISION COMPUT, V14, P47, DOI 10.1016/0262-8856(95)01039-4; DIBAJA GS, 1994, PATTERN RECOGN, V27, P1039, DOI 10.1016/0031-3203(94)90143-0; DILL AR, 1987, IEEE T PATTERN ANAL, V9, P495, DOI 10.1109/TPAMI.1987.4767937; HONG TH, 1984, IEEE T PATTERN ANAL, V6, P222, DOI 10.1109/TPAMI.1984.4767505; Ip HHS, 1996, IMAGE VISION COMPUT, V14, P297, DOI 10.1016/0262-8856(95)01050-5; MONTANVERT A, 1991, IEEE T PATTERN ANAL, V13, P307, DOI 10.1109/34.88566; OGNIEWICZ RL, 1993, THESIS KONSTANZ GERM; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; Pizer SM, 1999, IEEE T MED IMAGING, V18, P851, DOI 10.1109/42.811263; PIZER SM, 1987, IEEE T PATTERN ANAL, V9, P505, DOI 10.1109/TPAMI.1987.4767938; ROM H, 1993, IEEE T PATTERN ANAL, V15, P973, DOI 10.1109/34.254054; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Yokoi S., 1975, COMPUT GRAPHICS IMAG, V4, P63, DOI DOI 10.1016/0146-664X(75)90022-2; Zhu SC, 1996, INT J COMPUT VISION, V20, P187; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1158, DOI 10.1109/34.809109	28	29	30	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2001	23	11					1296	1312		10.1109/34.969119	http://dx.doi.org/10.1109/34.969119			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	491KV					2022-12-18	WOS:000172108300007
J	Boshra, M; Bhanu, B				Boshra, M; Bhanu, B			Predicting performance of object recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						bounds on recognition performance; model-based real-world object recognition; modeling data distortion; performance validation; synthetic aperture radar images; theory of performance prediction	MODEL-BASED RECOGNITION; 3-D OBJECTS; VERIFICATION; UNCERTAINTY	We present a method for predicting fundamental performance of object recognition. We assume that both scene data and model objects are represented by 2D point features and a data/model match is evaluated using a vote-based criterion. The proposed method considers data distortion factors such as uncertainty, occlusion, and clutter, in addition to model similarity. This is unlike previous approaches, which consider only a subset of these factors. Performance is predicted in two stages. In the first stage, the similarity between every pair of model objects is captured by comparing their structures as a function of the relative transformation between them. In the second stage, the similarity information is used along with statistical models of the data-distortion factors to determine an upper bound on the probability of recognition error. This bound is directly used to determine a lower bound on the probability of correct recognition. The validity of the method is experimentally demonstrated using real synthetic aperture radar (SAR) data.	AuthenTec Inc, Melbourne, FL 32901 USA; Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA	Apple Inc; University of California System; University of California Riverside	Boshra, M (corresponding author), AuthenTec Inc, 709 S Harbor City Blvd, Melbourne, FL 32901 USA.	mboshra@authentec.com; bhanu@vislab.ucr.edu		Bhanu, Bir/0000-0001-8971-6416				Alter TD, 1997, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.1997.609347; Alter TD, 1998, INT J COMPUT VISION, V27, P127, DOI 10.1023/A:1007989016491; Amir A, 1998, IEEE T PATTERN ANAL, V20, P186, DOI 10.1109/34.659936; Bhanu B, 1999, P SOC PHOTO-OPT INS, V3721, P507, DOI 10.1117/12.357667; Boshra M, 1999, P SOC PHOTO-OPT INS, V3721, P716, DOI 10.1117/12.357687; Boykov Y., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P517, DOI 10.1109/CVPR.1999.784730; Breuel T. M., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P707, DOI 10.1109/CVPR.1993.341018; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P1201, DOI 10.1109/34.106994; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; Jones G, 1999, IEEE T PATTERN ANAL, V21, P603, DOI 10.1109/34.777371; Li S., 1995, MARKOV RANDOM FIELD, P1; Lindenbaum M, 1997, IEEE T PATTERN ANAL, V19, P1251, DOI 10.1109/34.632984; LINDENBAUM M, 1995, IEEE T PATTERN ANAL, V17, P666, DOI 10.1109/34.391409; MAO JC, 1995, COMPUT VIS IMAGE UND, V62, P309, DOI 10.1006/cviu.1995.1057; POPE AR, 1996, P INT WORKSH OBJ REP, P201; Ross T, 1998, P SOC PHOTO-OPT INS, V3370, P566, DOI 10.1117/12.321859; Sarachik KB, 1997, IEEE T PATTERN ANAL, V19, P289, DOI 10.1109/34.587990; STOCKMAN G, 1987, COMPUT VISION GRAPH, V40, P361, DOI 10.1016/S0734-189X(87)80147-0; Wells WM, 1997, INT J COMPUT VISION, V21, P63, DOI 10.1023/A:1007923522710	22	29	33	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2000	22	9					956	969		10.1109/34.877519	http://dx.doi.org/10.1109/34.877519			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	361TY					2022-12-18	WOS:000089741300004
J	Li, LY; Chen, WN				Li, LY; Chen, WN			Corner detection and interpretation on planar curves using fuzzy reasoning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						corner detection; dominant point detection; digital curves; curve description; feature extraction; shape analysis; fuzzy reasoning; fuzzy pattern recognition	DOMINANT POINTS; DIGITAL CURVES; ALGORITHM	The problem of corner detection on planar curves is examined based on human perception of local graphic features. First, a set of fuzzy patterns of contour points are established. Then, corner detection is characterized as a fuzzy classification problem that contains three stages: evaluation, classification, and location. Compared with existing methods, the proposed approach is superior in that it explains the curve, instead of simple labeling, and it performs based on human perception. Experimental results on shapes of various complexities are presented. The performance with respect to noise is also addressed.	Southeast Univ, Res Inst Automat, Nanjing 210018, Peoples R China	Southeast University - China	Li, LY (corresponding author), Southeast Univ, Res Inst Automat, Nanjing 210018, Peoples R China.							ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BEUS HL, 1987, PATTERN RECOGN, V20, P291, DOI 10.1016/0031-3203(87)90004-5; FISCHLER MA, 1994, IEEE T PATTERN ANAL, V16, P113, DOI 10.1109/34.273737; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; KANDEL A, 1982, FUZZY TECHNIQUES PAT; Law T, 1996, IEEE T PATTERN ANAL, V18, P481, DOI 10.1109/34.494638; LIU HC, 1990, PATTERN RECOGN, V23, P51, DOI 10.1016/0031-3203(90)90048-P; MEER P, 1988, PATTERN RECOGN, V21, P217, DOI 10.1016/0031-3203(88)90056-8; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; ROSIN PL, 1992, PATTERN RECOGN, V25, P1315, DOI 10.1016/0031-3203(92)90144-8; SAINTMARC P, 1988, P IM UND, V2, P1100; SANKAR PV, 1978, COMPUT VISION GRAPH, V7, P403, DOI 10.1016/S0146-664X(78)80006-9; SHAHRARAY B, 1989, IEEE T PATTERN ANAL, V11, P600, DOI 10.1109/34.24794; SIY P, 1974, IEEE T SYST MAN CYB, VSMC4, P570; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; WORRING M, 1993, CVGIP-IMAG UNDERSTAN, V58, P366, DOI 10.1006/ciun.1993.1048; Zadeh L.A., 1977, CLASSIFICATION CLUST, P251, DOI [10.1016/B978-0-12-714250-0.50014-0, DOI 10.1016/B978-0-12-714250-0.50014-0]; ZADEH LA, 1975, INFORMATION SCI, V8; ZHU PF, 1995, IEEE T PATTERN ANAL, V17, P737, DOI 10.1109/34.400564	23	29	40	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1204	1210		10.1109/34.809113	http://dx.doi.org/10.1109/34.809113			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100009
J	Cham, TJ; Cipolla, R				Cham, TJ; Cipolla, R			Automated B-spline curve representation incorporating MDL and error-minimizing control point insertion strategies	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						B-spline fitting; curve fitting; minimum description length; collapse mechanism; active contour		The main issues of developing an automatic and reliable scheme for spline-fitting are discussed and addressed in this paper, which are not fully covered in previous papers or algorithms. The proposed method incorporates B-spline active contours, the minimum description length (MDL) principle, and a novel control point insertion strategy based on maximizing the Potential for Energy-Reduction Maximization (PERM). A comparison of test results shows that it outperforms one of the better existing methods.	Compaq Comp Corp, Cambridge Res Lab, Cambridge, MA 02139 USA; Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	University of Cambridge	Cham, TJ (corresponding author), Compaq Comp Corp, Cambridge Res Lab, 1 Kendall Sq,Bldg 700, Cambridge, MA 02139 USA.		Arandjelović, Ognjen/V-5255-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Cham, Tat-Jen/0000-0001-5264-2572; Cipolla, Roberto/0000-0002-8999-2151				Bartels RH, 1987, INTRO SPLINES USE CO; CATALDI TRI, 1995, ANAL METHOD INSTRUM, V2, P27; CHAM TJ, 1996, THESIS U CAMBRIDGE; CHAM TJ, 1996, LECT NOTES COMPUTER, V1064, P385; Crandall S.H., 1978, INTRO MECH SOLIDS; Dierckx P., 1993, CURVE SURFACE FITTIN; DUDA RO, 1973, PATTERN CLSSIFICATIO; GUEZIEC A, 1994, INT J COMPUT VISION, V12, P79, DOI 10.1007/BF01420985; JUPP DLB, 1975, J APPROX THEORY, V14, P204, DOI 10.1016/0021-9045(75)90056-8; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LU F, 1994, SIGNAL PROCESS, V37, P129, DOI 10.1016/0165-1684(94)90171-6; POWELL MJD, 1970, NUMERICAL APPROXIMAT, P65; QAMAR I, 1993, COMMUN NUMER METH EN, V9, P483, DOI 10.1002/cnm.1640090605; Rissanen J., 1987, ENCY STATISTICAL SCI, V5, P523; SAINTMARC P, 1993, IEEE T PATTERN ANAL, V15, P1191, DOI 10.1109/34.244680; Sato J, 1998, INT J COMPUT VISION, V28, P117, DOI 10.1023/A:1008011016516	16	29	29	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					49	53		10.1109/34.745733	http://dx.doi.org/10.1109/34.745733			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ					2022-12-18	WOS:000078388900006
J	DeCarlo, D; Metaxas, D				DeCarlo, D; Metaxas, D			Shape evolution with structural and topological changes using blending	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape blending; shape estimation from range data; shape evolution; deformable models; shape representation	GLOBAL DEFORMATIONS; RANGE IMAGES; MODELS; SUPERQUADRICS; RECOGNITION; FORM; REPRESENTATION; SEGMENTATION; ORGANIZATION	This paper describes a framework for the estimation of shape from sparse or incomplete range data. It uses a shape representation called blending, which allows for the geometric combination of shapes into a unified model-selected regions of the component shapes are cut-out and glued together. Estimation of shape using this representation is realized using a physics-based framework, and also includes a process for deciding how to adapt the structure and topology of the model to improve the fit. The blending representation helps avoid abrupt changes in model geometry during fitting by allowing the smooth evolution of the shape, which improves the robustness of the technique. We demonstrate this framework with a series of experiments showing its ability to automatically extract structured representations from range data given both structurally and topologically complex objects.	Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA; Rutgers State Univ, Ctr Cognit Sci, Piscataway, NJ 08854 USA; Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA	Rutgers State University New Brunswick; Rutgers State University New Brunswick; University of Pennsylvania	DeCarlo, D (corresponding author), Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.	decarlo@cs.rutgers.edu; dnm@central.cis.upenn.edu						Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BINFORD TO, 1971, IEEE C SYST CONTR DE; BROUWER LEJ, 1976, COLLECTED WORKS, V0002; DeCarlo D, 1996, PROC GRAPH INTERF, P194; DeCarlo D, 1996, IEEE T PATTERN ANAL, V18, P443, DOI 10.1109/34.491626; DECARLO D, 1994, COMPUTER VISION PATT, P566; DECARLO D, 1995, IEEE P INT C COMP VI, P834; DELINGETTE H, 1994, CVPR94, P856; Farin G, 1990, CURVES SURFACES COMP; FERRIE FP, 1993, IEEE T PATTERN ANAL, V15, P771, DOI 10.1109/34.236252; GRIMM C, 1995, SIGGRAPH, P359; Guillemin V., 2010, DIFFERENTIAL TOPOLOG, V370; GUPTA A, 1993, CVGIP-IMAG UNDERSTAN, V58, P302, DOI 10.1006/ciun.1993.1044; HAN S, 1993, IEEE P 3 INT C COMP, P492; HANSON AJ, 1988, COMPUT VISION GRAPH, V44, P191, DOI 10.1016/S0734-189X(88)80005-7; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; HORIKOSHI T, 1993, COMPUTER VISION PATT, P168; Koenderink J., 1990, SOLID SHAPE; KUMAR S, 1995, IEEE WORKSH PHYS BAS, P17; LEE GC, 1991, CPS9108 MICH STAT U; LEJEUNE A, 1993, COMPUTER VISION PATT, P800; Leonardis A, 1997, IEEE T PATTERN ANAL, V19, P1289, DOI 10.1109/34.632988; LIAO C, 1994, COMPUTER VISION PATT, P617; LIAO C, 1995, IEEE WORKSH PHYS BAS, P2; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Marr D., 1982, VISION; Massey W. S., 1987, ALGEBRAIC TOPOLOGY I; MCINERNEY T, IN PRESS MED IMAGE A; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; METAXAS DN, 1996, PHYSICS BASED DEFORM; MURAKI S, 1991, COMP GRAPH, V25, P227, DOI 10.1145/127719.122743; ODONNELL T, 1994, CVPR, P174; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; RUTISHAUSER M, 1994, COMPUTER VISION PATT, P573; SATO Y, 1992, COMPUTER VISION PATT, P699; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; SZELISKI R, 1993, COMPUTER VISION PATT, P82; TAUBIN G, 1993, INT C COMP VIS, P658; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; VEMURI BC, 1993, COMPUTER VISION PATT, P307; WHITAKER R, 1995, ICCV95, P822	49	29	29	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1998	20	11					1186	1205		10.1109/34.730554	http://dx.doi.org/10.1109/34.730554			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	138TX		Green Submitted			2022-12-18	WOS:000076990100006
J	Sin, BK; Kim, JH				Sin, BK; Kim, JH			Ligature modeling for online cursive script recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						online character recognition; cursive script; Korean character; ligature; hidden Markov model; network searching	HIDDEN MARKOV-MODELS; SPEECH RECOGNITION	Online recognition of cursive words is a difficult task owing to variable shape and ambiguous letter boundaries. The approach proposed in this paper is based on hidden Markov modeling of letters and inter-letter patterns called ligatures occurring in cursive script. For each of the letters and the ligatures we create one HMM that models temporal and spatial variability of handwriting. By networking the two kinds of HMMs, we can design a network model for all words or composite characters. The network incorporates the knowledge sources of grammatical and structural constraints so that it can better capture the characteristics of handwriting. Given the network, the problem of recognition is formulated into that of finding the most likely path from the start node to the end node. A dynamic programming-based search for the optimal input-network alignment performs character recognition and letter segmentation simultaneously and efficiently. Experiments on Korean character showed correct recognition of up to 93.3 percent on unconstrained samples. It has also been compared with several other schemes of HMM-based recognition to characterize the proposed approach.	KOREA ADV INST SCI & TECHNOL,DEPT COMP SCI,YUSONG KU,TAEJON 305701,SOUTH KOREA	Korea Advanced Institute of Science & Technology (KAIST)	Sin, BK (corresponding author), KOREA TELECOM,RES CTR,INFORMAT RETRIEVAL TECHNOL TEAM,MULTIMEDIA RES LABS,SOCHO KU,17 UMYONDONG,SEOUL 137792,SOUTH KOREA.		Kim, Jin Hyung/C-1923-2011					BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BELLEGARDA JR, 1990, IEEE T ACOUST SPEECH, V38; BERCU S, 1993, 3RD P INT WORKSH FRO, P385; BROWN PF, 1987, THESIS CARNEGIE MELL; BUSH MA, 1987, IEEE T ACOUST SPEECH, V35, P1401, DOI 10.1109/TASSP.1987.1165057; CHEN F, 1993, P IEEE INT C AC SPEE, P1; CHERIET M, 1993, PATTERN RECOGN LETT, V14, P1009, DOI 10.1016/0167-8655(93)90009-3; Derouault A., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P360; FENG MW, 1992, P INT C SPOK LANG PR, P21; FUJISAKI T, 1991, P INT W FRONT HANDWR, P205; Giachin E. P., 1992, Computer Speech and Language, V6, P197, DOI 10.1016/0885-2308(92)90017-X; Giachin E. P., 1991, Computer Speech and Language, V5, P155, DOI 10.1016/0885-2308(91)90022-I; Hu Jianying, 1993, 3RD P INT WORKSH FRO, P455; KARLS I, 1993, P INT W FRONT HANDWR, P437; KOPEC GE, 1993, P INT C ACOUSTICS SP, P85; KUO SS, 1993, P IEEE ICASSP, P81; KWON OS, 1994, THESIS JUNGANG U; LEE HD, 1989, J KOREA INFOR SCI SC, V15, P29; LEE KF, 1990, IEEE T ACOUST SPEECH, V38, P599, DOI 10.1109/29.52701; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; LEE SH, 1994, P 2 WORKSH CHAR REC, P93; LEE SH, 1992, P 2 PAC RIM C AI SEO, P947; LEROUX M, 1991, 1ST P INT C DOC AN R, P774; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; ROSE RC, 1990, P IEEE ICASSP APR, P130; SCHWARTZ R, 1985, P IEEE ICASSP APR; SENI G, 1994, P INT W FRONT HANDWR, P472; SEONG TJ, 1991, P KOR INF SCI SOC C, P223; SESHADRI S, 1993, P INT W FRONT HANDWR, P443; Sin B. K., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P147, DOI 10.1109/ICDAR.1993.395762; SIN BK, 1995, THESIS KOREA ADV I S; TAPPERT CC, 1982, IBM J RES DEV, V26; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; WARD JR, 1988, IEEE T SYSTEMS MAN C, V18; WEISSMAN H, 1994, PATTERN RECOGN, V27, P405, DOI 10.1016/0031-3203(94)90117-1; WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088	36	29	30	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1997	19	6					623	633		10.1109/34.601250	http://dx.doi.org/10.1109/34.601250			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XG302					2022-12-18	WOS:A1997XG30200007
J	OGorman, L				OGorman, L			Subpixel precision of straight-edged shapes for registration and measurement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						registration; precision; fiducial marks; machine vision; image processing; metrology; subpixel precision	ACCURACY; CIRCLES	The precision by which a region is located or measured on the image plane is limited by the sampling density. In this paper, the worst-case precision errors are determined for calculating the average image location of an edge, line, and straight-edged region. For each case, it is shown how the worst-case error can be minimized as a function of the geometric parameters. These results can be used to determine the worst case error by which the location of a known shape is measured. Another application is to design shapes for use in registration, such as fiducial marks used in electronic assembly. The main conclusion of this paper is that, to achieve better precision, measurement of a straight-edged region should be made at an angle askew to the sampling axis (not 0, 45, or 90 degrees) and this should be at a certain length that is a function of this skew angle.			OGorman, L (corresponding author), AT&T BELL LABS,600 MT AVE,MURRAY HILL,NJ 07974, USA.							BERENSTEIN CA, 1987, COMPUT VISION GRAPH, V40, P334, DOI 10.1016/S0734-189X(87)80146-9; BOSE CB, 1990, IEEE T PATTERN ANAL, V12, P1196, DOI 10.1109/34.62609; BRUCKSTEIN AM, UNPUB DESIGN SHAPES; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; Efrat A, 1994, INT J COMPUT GEOM AP, V4, P403, DOI 10.1142/S0218195994000227; HAVELOCK DI, 1989, IEEE T PATTERN ANAL, V11, P1065, DOI 10.1109/34.42837; HAVELOCK DI, 1991, IEEE T PATTERN ANAL, V13, P380, DOI 10.1109/34.88574; Hill J.W., 1980, MACH INTELL, P75; KULPA Z, 1979, COMPUT VISION GRAPH, V10, P348, DOI 10.1016/S0146-664X(79)80043-X; NAKAMURA A, 1984, COMPUT VISION GRAPH, V26, P242, DOI 10.1016/0734-189X(84)90187-7; NISHIHARA HK, 1988, IEEE T PATTERN ANAL, V10, P17, DOI 10.1109/34.3864; NIVEN I, 1980, INTRO THEORY NUMBERS, pCH2; O'Gorman L., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P249, DOI 10.1109/ICPR.1990.119365; OGORMAN L, 1990, P IAPR WORKSH MACH V, P253; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9	15	29	30	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1996	18	7					746	751		10.1109/34.506796	http://dx.doi.org/10.1109/34.506796			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UZ457					2022-12-18	WOS:A1996UZ45700006
J	BICHSEL, M				BICHSEL, M			SEGMENTING SIMPLY CONNECTED MOVING-OBJECTS IN A STATIC SCENE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter							IMAGE SEQUENCES; SEGMENTATION	A new segmentation algorithm is derived, based on an object-background probability estimate exploiting the experimental fact that the statistics of local image derivatives show a Laplacian distribution. The objects' simply connectedness is included directly into the probability estimate and leads to an iterative optimization approach that can be implemented efficiently. This new approach avoids early thresholding, explicit edge detection, motion analysis, and grouping.			BICHSEL, M (corresponding author), UNIV ZURICH,DEPT COMP SCI,MULTIMEDIA LAB,WINTERTHURERSTR 190,CH-8057 ZURICH,SWITZERLAND.							BERGEN JR, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P27; Bichsel M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P459, DOI 10.1109/CVPR.1992.223150; BICHSEL M, 1993, 9320 U ZUR COMP SCI; BLOSTEIN SD, 1991, IEEE T SIGNAL PROCES, V39, P1611, DOI 10.1109/78.134399; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; BURT PJ, 1991, OCT IEEE WORKSH VIS, P187; DONOHOE GW, 1988, P INT C AC SPEECH SI, P1084; HSU YZ, 1984, COMPUT VISION GRAPH, V26, P73, DOI 10.1016/0734-189X(84)90131-2; JAIN RC, 1984, IEEE T PATTERN ANAL, V6, P624, DOI 10.1109/TPAMI.1984.4767575; LEUNG MK, 1987, PATTERN RECOGN, V20, P55, DOI 10.1016/0031-3203(87)90017-3; PAPOULIS A, 1987, PROBABILITY RANDOM V; Pratt W, 1991, DIGITAL IMAGE PROCES; SHIO A, 1991, IEEE WORKSH VIS MOT, P325	13	29	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1994	16	11					1138	1142		10.1109/34.334396	http://dx.doi.org/10.1109/34.334396			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PW081					2022-12-18	WOS:A1994PW08100010
J	YLAJAASKI, A; KIRYATI, N				YLAJAASKI, A; KIRYATI, N			ADAPTIVE TERMINATION OF VOTING IN THE PROBABILISTIC CIRCULAR HOUGH TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ADAPTIVE ALGORITHMS; PROBABILISTIC HOUGH TRANSFORM; STOPPING RULES	CURVE DETECTION	Reliable detection of objects using the Hough Transform is often possible even if just a small random poll of edge points is used for voting. This can lead to significant computational savings. To reduce the risk of errors, it is customary to preset the poll size to a value that is much larger than necessary in average conditions. Adaptive setting of the poll size in the probabilistic Hough Transform is suggested. It is experimentally demonstrated that by monitoring changes in the ranks of peaks in the parameter space, sensible decisions on voting termination can be made. Adaptive stopping leads to polls that are in average smaller than the fixed poll that leads to the same error rate. In many applications the number of objects to be detected is unknown. Finding the number of appearances of an object in a noisy image is difficult, especially with partial data. We present an adaptive stopping rule that terminates voting as soon as any number of objects seem to be reliably detected, even though the existence of others may not be ruled out yet.	SWISS FED INST TECHNOL,COMMUN TECHNOL LAB,IMAGE SCI GRP,CH-8093 ZURICH,SWITZERLAND	Swiss Federal Institutes of Technology Domain; ETH Zurich			Ylä-Jääski, Antti S/G-2484-2013	Ylä-Jääski, Antti S/0000-0002-2069-1721; Kiryati, Nahum/0000-0003-1436-2275				ADE F, 1993, 8TH P SCIA TROMS; GERIG G, 1987, 1 INT C COMP VIS LON, P112; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P1201, DOI 10.1109/34.106994; KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E; LEAVERS VF, 1993, CVGIP-IMAG UNDERSTAN, V58, P250, DOI 10.1006/ciun.1993.1041; Sheinvald J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P547, DOI 10.1109/CVPR.1992.223137; SKLANSKY J, 1978, IEEE T COMPUT, V27, P923, DOI 10.1109/TC.1978.1674971; XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z; YLAJAASKI A, 1993, ELECT ENG SER, V73	9	29	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					911	915		10.1109/34.310688	http://dx.doi.org/10.1109/34.310688			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802					2022-12-18	WOS:A1994PE80200008
J	BERMAN, M				BERMAN, M			AUTOMATED SMOOTHING OF IMAGE AND OTHER REGULARLY SPACED DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CROSS-VALIDATION; FOURIER TRANSFORM; HIGH-DIMENSIONAL IMAGERY; REGULARLY SPACED DATA; REMOTE SENSING; SMOOTHING; SPACE DOMAIN APPROXIMATION; THIN-PLATE SMOOTHING SPLINE	CROSS-VALIDATION; NOISY DATA; SPLINES; REGULARIZATION; RESTORATION; PARAMETER	This paper is primarily motivated by the problem of automatically removing unwanted noise from high-dimensional remote sensing imagery. The initial step involves the transformation of the data to a space of intrinsically lower dimensionality and the smoothing of images in the new space. Different images require different amounts of smoothing. The signal (assumed to be mostly smooth with relatively few discontinuities) is estimated from the data using the method of generalized cross-validation. It is shown how the generalized cross-validated thin-plate smoothing spline with observations on a regular grid (in d dimensions) is easily approximated and computed in the Fourier domain. Space domain approximations are also investigated. The technique is applied to some remote sensing data.			BERMAN, M (corresponding author), CSIRO,DEPT MATH & STAT,N RYDE,NSW 2113,AUSTRALIA.		Berman, Mark/D-3411-2009					ABRAMOWITZ M., 1965, HDB MATH FUNCTIONS; BERMAN M, 1991, P C DIG IMAGE COMPUT, P297; BERMAN M, 1990, NSW9011 CSIRO DIV MA; Bracewell R., 1986, FOURIER TRANSFORM IT; BUCKLEY M, 1994, IN PRESS BIOMETRIKA, V81; CRAVEN P, 1979, NUMER MATH, V31, P377, DOI 10.1007/BF01437407; de Hoog FR, 1987, NUMER MATH, V50, P311, DOI 10.1007/BF01390708; DUBRULE O, 1983, J INT ASS MATH GEOL, V15, P245, DOI 10.1007/BF01036069; Erdelyi A., 1954, TABLES INTEGRAL TRAN, VII; GIRARD DA, 1989, NUMER MATH, V56, P1, DOI 10.1007/BF01395775; Gradshteyn IS., 2001, TABLES INTEGRALS SER; GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001; HUTCHINSON MF, COMMUN STATIST SIMUL, V19, P433; LEE JB, 1990, IEEE T GEOSCI REMOTE, V28, P295, DOI 10.1109/36.54356; MATHERON G, 1980, SPLINES KRIGING THEI; O'Sullivan F, 1985, J R STAT SOC B, V47, P39; OSULLIVAN F, 1991, J AM STAT ASSOC, V86, P634, DOI 10.2307/2290392; REEVES SJ, 1990, OPT ENG, V29, P446, DOI 10.1117/12.55613; SIBSON R, 1991, SIAM J SCI STAT COMP, V12, P1304, DOI 10.1137/0912070; SILVERMAN BW, 1984, ANN STAT, V12, P898, DOI 10.1214/aos/1176346710; SINGLETO.RC, 1969, IEEE T ACOUST SPEECH, VAU17, P93, DOI 10.1109/TAU.1969.1162042; STEIN ML, 1991, ANN I STAT MATH, V43, P61, DOI 10.1007/BF00116469; Thompson A., 1989, J STATIST COMPUT SIM, V33, P199; THOMPSON AM, 1991, IEEE T PATTERN ANAL, V13, P326, DOI 10.1109/34.88568; WAHBA G, 1983, J ROY STAT SOC B MET, V45, P133; Wahba G., 1990, SPLINE MODELS OBSERV; WAHBA G, 1990, J ROY STATIST SOC B; WENDELBERGER J, 1981, 648 U WISC MADISON; ZHANG B, KERNEL APPROXIMATION	29	29	29	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					460	468		10.1109/34.291451	http://dx.doi.org/10.1109/34.291451			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141					2022-12-18	WOS:A1994NP14100002
J	SCHULTZ, H				SCHULTZ, H			RETRIEVING SHAPE INFORMATION FROM MULTIPLE IMAGES OF A SPECULAR SURFACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						OPTICAL REMOTE SENSING; STEREO VISION; NONDESTRUCTIVE MEASUREMENTS; SHAPE FROM SHADING; IMAGE UNDERSTANDING; SPECULAR SURFACE IMAGE ANALYSIS; SMALL-SCALE WAVE MEASUREMENTS		In many remote sensing and machine vision applications, the shape of a specular surface such as water, glass, or polished metal must be determined instantaneously and under natural lighting conditions. Most image analysis techniques, however, assume surface reflectance properties or lighting conditions that are incompatible with these situations. To retrieve the shape of smooth specular surfaces, a technique known as specular surface stereo was developed. The method analyzes multiple images of a surface and finds a surface shape that results in a set of synthetic images that match the observed ones. An image synthesis model is used to predict image irradiance values as a function of the shape and reflectance properties of the surface, camera geometry, and radiance distribution of the illumination. The specular surface stereo technique was tested by processing four numerical simulations-a water surface illuminated by a low- and high-contrast extended light source, and a mirrored surface illuminated by a low- and high-contrast extended light source. Under these controlled circumstances, the recovered surface shape showed good agreement with the known input.			SCHULTZ, H (corresponding author), UNIV MASSACHUSETTS,DEPT COMP SCI,AMHERST,MA 01003, USA.		Schultz, Howard J/G-1687-2011					Blake A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P394, DOI 10.1109/CCV.1988.590016; BLAKE A, 1985, 9TH P INT JOINT C AR, V2, P973; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; HARTT E, 1989, P IEEE COMPUTER VISI, P53; HEALEY G, 1987, P DARPA IM UND WORKS, P874; Horn B., 1986, ROBOT VISION, P1; Horn B.K.P., 1989, SHAPE SHADING; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MURASE H, 1992, IEEE T PATTERN ANAL, V14, P1045, DOI 10.1109/34.159906; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; NAYAR SK, 1989, P IMAGE UNDERSTANDIN; SANDERSON AC, 1988, IEEE T PATTERN ANAL, V10, P44, DOI 10.1109/34.3866; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; Tagare H. D., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P38, DOI 10.1109/CVPR.1989.37826; THOMAS J, 1991, PHOTOGRAMM ENG REM S, V57, P51; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; Woodham R.J., 1979, IMAGE UNDERSTANDING, V155, P136; ZISSERMAN A, 1989, IMAGE VISION COMPUT, V7, P38, DOI 10.1016/0262-8856(89)90018-8	19	29	32	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1994	16	2					195	201		10.1109/34.273732	http://dx.doi.org/10.1109/34.273732			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NA631					2022-12-18	WOS:A1994NA63100006
J	GAUCH, JM; PIZER, SM				GAUCH, JM; PIZER, SM			THE INTENSITY AXIS OF SYMMETRY AND ITS APPLICATION TO IMAGE SEGMENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							SHAPE	In this paper, we present a new method for describing the shape of structures in grey-scale images, which is known as the intensity axis of symmetry (IAS). We describe the spatial and intensity variations of the image simultaneously rather than by the usual two-step process of 1) using intensity properties of the image to segment an image into regions and 2) describing the spatial shape of these regions. The result is an image shape description that is useful for a number of computer vision applications. Our method for computing this image shape description relies on minimizing an active surface functional that provides coherence in both the spatial and intensity dimensions while deforming into an axis of symmetry. Shape-based image segmentation is possible by identifying image regions associated with individual components of the IAS. The resulting image regions have geometric coherence and correspond well to visually meaningful objects in medical images.	UNIV N CAROLINA,DEPT COMP SCI,CHAPEL HILL,NC 27514; UNIV N CAROLINA,DEPT RADIOL,CHAPEL HILL,NC 27514; UNIV N CAROLINA,DEPT RADIAT ONCOL,CHAPEL HILL,NC 27514	University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill; University of North Carolina; University of North Carolina Chapel Hill	GAUCH, JM (corresponding author), NORTHEASTERN UNIV,COLL COMP SCI,BOSTON,MA 02115, USA.							BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; Ballard D.H., 1982, COMPUTER VISION; BILCHER AP, 1985, THESIS STANFORD U; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BLUM H, 1974, MATH ANAL FUNDAMENTA, V231, P19; BRADY M, 1984, MIT AI757; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CANNY JF, 1983, MIT AI720; Castleman KR., 1979, DIGITAL IMAGE PROCES; COGGINS JM, 1988, DATA STRUCTURE IMAGE; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; CULLIP T, 1989, COMMUNICATION; DILL AR, 1987, IEE T PATT ANAL MACH, V9; GACUH JM, 1993, IEEE T PATTERN ANAL, V15, P635; GAUCH J, 1989, THESIS U N CAROLINA; GAUCH JM, 1987, 10TH P INFORM PROCES; GAUCH JM, 1988, 2ND P INT C COMPUT V; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LEYTON M, 1986, SMOOTH PROCESSES SHA; LIFSHITZ LM, 1987, THESIS U N CAROLINA; Morse M, 1934, ANN MATH, V35, P545, DOI 10.2307/1968750; PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X; PIZER SM, 1986, NATO ASI MATH COMPUT; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; THORPE JA, 1979, ELEMENTARY TOPICS DI	26	29	31	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1993	15	8					753	770		10.1109/34.236253	http://dx.doi.org/10.1109/34.236253			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR948					2022-12-18	WOS:A1993LR94800001
J	GREGOR, J; THOMASON, MG				GREGOR, J; THOMASON, MG			DYNAMIC-PROGRAMMING ALIGNMENT OF SEQUENCES REPRESENTING CYCLIC PATTERNS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CYCLIC PATTERNS; DNA AND PROTEIN SEQUENCES; DYNAMIC PROGRAMMING; GUIDED SEARCH; STRING MATCHING; STRUCTURAL PATTERN ANALYSIS	STRING CORRECTION PROBLEM; SATELLITE DNA	String alignment by dynamic programming is generalized to include cyclic shift and corresponding optimal alignment cost for strings representing cyclic patterns. A guided search algorithm uses bounds on actual alignment costs to find all optimal cyclic shifts. The bounds are derived from submatrices of an initial dynamic programming matrix. Algorithmic complexity is analyzed for major stages in the search. Applicability of the method is illustrated with satellite DNA sequences and circularly permuted protein sequences.			GREGOR, J (corresponding author), UNIV TENNESSEE,DEPT COMP SCI,KNOXVILLE,TN 37996, USA.							Bunke H., 1990, SYNTACTIC STRUCTURAL; CARLSON M, 1979, J MOL BIOL, V135, P483, DOI 10.1016/0022-2836(79)90448-0; CUNNINGHAM BA, 1979, P NATL ACAD SCI USA, V76, P3218, DOI 10.1073/pnas.76.7.3218; ERICKSON BW, 1983, TIME WARPS STRING ED, P55; FU KS, 1979, IEEE T SYST MAN CYB, V9, P55; HSIEH T, 1979, J MOL BIOL, V135, P465, DOI 10.1016/0022-2836(79)90447-9; Kruskal J.B., 1983, TIME WARPS STRING ED; MAES M, 1990, INFORM PROCESS LETT, V35, P73, DOI 10.1016/0020-0190(90)90109-B; Sellers P. H., 1974, Journal of Combinatorial Theory, Series A, V16, P253, DOI 10.1016/0097-3165(74)90050-8; TSAI WH, 1985, IEEE T PATTERN ANAL, V7, P453, DOI 10.1109/TPAMI.1985.4767684; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WANG YP, 1990, IEEE T PATTERN ANAL, V12, P1080, DOI 10.1109/34.61707	12	29	30	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					129	135		10.1109/34.192484	http://dx.doi.org/10.1109/34.192484			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KL910					2022-12-18	WOS:A1993KL91000003
J	CABRELLI, CA; MOLTER, UM				CABRELLI, CA; MOLTER, UM			AUTOMATIC REPRESENTATION OF BINARY IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV WATERLOO,DEPT APPL MATH,WATERLOO N2L 3G1,ONTARIO,CANADA	University of Waterloo				Molter, Ursula/0000-0002-2928-9480				Duda R.O., 1973, J ROYAL STAT SOC SER; HILDERBRANDT FB, 1987, INTRO NUMERICAL ANAL; Jain A. K., 1988, FUNDAMENTALS DIGITAL; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; Serra J, 1982, IMAGE ANAL MATH MORP	5	29	36	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1190	1196		10.1109/34.62608	http://dx.doi.org/10.1109/34.62608			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500					2022-12-18	WOS:A1990EN50000007
J	KASHYAP, RL; EOM, KB				KASHYAP, RL; EOM, KB			TEXTURE BOUNDARY DETECTION BASED ON THE LONG CORRELATION MODEL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SYRACUSE UNIV,DEPT ELECT & COMP ENGN,SYRACUSE,NY 13244	Syracuse University	KASHYAP, RL (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							BRADY M, 1982, COMPUT SURV, V14, P3, DOI 10.1145/356869.356871; Brillinger D.R., 1981, TIME SERIES DATA ANA; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; EOM KB, 1986, THESIS PURDUE U; FU KS, 1982, SYNTACTIC PATTERN RE; Gradshteyn I. S, 1980, TABLES INTEGRALS SUM; Granger C. W. J., 1980, Journal of Time Series Analysis, V1, P15, DOI 10.1111/j.1467-9892.1980.tb00297.x; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HOSKING JRM, 1981, BIOMETRIKA, V68, P165, DOI 10.1093/biomet/68.1.165; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; HURST HE, 1951, T AM SOC CIV ENG, V116, P770; KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811; KASHYAP RL, 1988, J TIME SER ANAL, V9, P35; KASHYAP RL, 1985, OCT P INT GEOSC REM; KASHYAP RL, 1984, IEEE T PATTERN ANAL, V6; Loeve M., 1977, PROBABILITY THEORY; MANDELBROT BB, 1968, SIAM REV, V10, P422, DOI 10.1137/1010093; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; RAO CR, 1967, LINEAR STATISTICAL I; ROSENFELD A, 1982, DIGITAL IMAGE PROCES, V1; Rosenfeld A., 1982, DIGITAL IMAGE PROCES, V2; [No title captured]	24	29	29	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1989	11	1					58	67		10.1109/34.23113	http://dx.doi.org/10.1109/34.23113			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R4474					2022-12-18	WOS:A1989R447400005
J	YASUMOTO, Y; MEDIONI, G				YASUMOTO, Y; MEDIONI, G			ROBUST ESTIMATION OF 3-DIMENSIONAL MOTION PARAMETERS FROM A SEQUENCE OF IMAGE FRAMES USING REGULARIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,DEPT ELECT ENGN,INTELLIGENT SYST GRP,LOS ANGELES,CA 90089	University of Southern California								ADIV G, 1984, OCT P DARPA IM UND W, P113; ARSENIN VY, 1968, USSR COMPUT MATH, V8; BOBICK A, 1983, P ACM INTERDISC WORK, P91; BRUSS AR, 1981, MIT AI662 MEM; CLOCKSIN WF, 1980, PERCEPTION; DRESCHLER L, 1981, 7TH P INT JOINT C AR; FANG JQ, 1984, IEEE T PATTERN ANAL, V6, P545, DOI 10.1109/TPAMI.1984.4767569; LAPPIN JS, 1980, SCIENCE, V209, P717, DOI 10.1126/science.7394534; LAWTON DT, 1980, 1ST P ANN NAT C ART; LEE DN, 1980, PHIL T ROY SOC LONDO; Longuet-Higgins H Christopher, 1981, NATURE; MEDIONI G, 1977, ENSTH77002 EC NAT SU; MEIRI AZ, 1980, IEEE T PATTERN ANAL, V2, P582, DOI 10.1109/TPAMI.1980.6447706; POGGIO T, 1984, OCT P IM UND WORKSH; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; Shariat H., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P181; SUGIE N, 1984, BIOL CYBERN, V50, P431, DOI 10.1007/BF00335200; TIKHONOV AN, 1963, DOKL AKAD NAUK SSSR+, V153, P49; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; ULLMAN S, 1984, PERCEPTION, V13, P255, DOI 10.1068/p130255; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WEBB JA, 1981, 7TH P INT JOINT C AR	22	29	30	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					464	471		10.1109/TPAMI.1986.4767810	http://dx.doi.org/10.1109/TPAMI.1986.4767810			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000005
J	JACKINS, CL; TANIMOTO, SL				JACKINS, CL; TANIMOTO, SL			QUAD-TREES, OCT-TREES, AND K-TREES - A GENERALIZED-APPROACH TO RECURSIVE DECOMPOSITION OF EUCLIDEAN-SPACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV WASHINGTON,DEPT COMP SCI,SEATTLE,WA 98195	University of Washington; University of Washington Seattle								BAUMGART BG, 1974, STANCS74463 STANF U; EASTMAN CM, 1978, COMMUN ASS COMPUT MA, V13, P242; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; JACKINS CL, 820202 U WASH TECH R; JACKINS CL, 1979, THESIS U WASHINGTON; KLINGER A, 1971, OPTIMIZING METHODS S; KNUTH DE, 1975, ART COMPUTER PROGRAM, V1, P401; SAMET H, 1981, IEEE T PATTERN ANAL, V3, P683, DOI 10.1109/TPAMI.1981.4767171; SAMET H, 1982, COMPUT VISION GRAPH, V18, P37, DOI 10.1016/0146-664X(82)90098-3; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; WARNOCK JE, 1969, TR415 U UT DEP COMP	12	29	30	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					533	539		10.1109/TPAMI.1983.4767433	http://dx.doi.org/10.1109/TPAMI.1983.4767433			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RM118	21869139				2022-12-18	WOS:A1983RM11800010
J	SATO, Y; KITAGAWA, H; FUJITA, H				SATO, Y; KITAGAWA, H; FUJITA, H			SHAPE MEASUREMENT OF CURVED OBJECTS USING MULTIPLE SLIT-RAY PROJECTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									KEIO UNIV,DEPT ELECT ENGN,KOHOKU KU,YOKOHAMA,KANAGAWA 223,JAPAN	Keio University	SATO, Y (corresponding author), TOKYO UNIV AGR & TECHNOL,DEPT ELECTR ENGN,KOGANEI,TOKYO 184,JAPAN.							AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626; BAKER H, 1977, 5TH P INT JOINT C AR, P649; Duda RO, 1973, PATTERN RECOGNITION; DUDA RO, 1978, 162 STANF RES I TECH; FORSEN GE, 1968, PICTORIAL PATTERN RE, P471; IDESAWA M, 1977, APPL OPTICS, V16, P2152, DOI 10.1364/AO.16.002152; NEVATIA R, 1976, COMPUT GRAPH IMAGE P, V5, P203; POTMESIL M, 1979, AUG P IEEE C PATT RE, P553; SATO Y, 1978, J I ELECTRON COMMU D, V61, P573; SATO Y, 1979, SYST COMPUT CONT, V10, P1; SHIRAI Y, 1972, PATTERN RECOGN, V4, P243, DOI 10.1016/0031-3203(72)90003-9; TSUYOSHI T, 1979, SYST COMPUT CONTR, V10, P22; WILL PM, 1972, PR INST ELECTR ELECT, V60, P669, DOI 10.1109/PROC.1972.8726	13	29	32	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					641	646		10.1109/TPAMI.1982.4767318	http://dx.doi.org/10.1109/TPAMI.1982.4767318			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499639				2022-12-18	WOS:A1982PS23700010
J	JAIN, AK; SMITH, SP; BACKER, E				JAIN, AK; SMITH, SP; BACKER, E			SEGMENTATION OF MUSCLE-CELL PICTURES - A PRELIMINARY-STUDY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									DELFT UNIV TECHNOL, INFORMAT THEORY LAB, DELFT, NETHERLANDS	Delft University of Technology	JAIN, AK (corresponding author), MICHIGAN STATE UNIV, DEPT COMP SCI, E LANSING, MI 48824 USA.							ARCELLI C, 1971, IEEE T COMPUT, VC 20, P1111, DOI 10.1109/T-C.1971.223414; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Dubes R., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P148; Duda R.O., 1973, J ROYAL STAT SOC SER; ECCLES MJ, 1977, PATTERN RECOGN, V9, P31, DOI 10.1016/0031-3203(77)90028-0; FREEMAN H, 1978, PATTERN RECOGN, V10, P159, DOI 10.1016/0031-3203(78)90024-9; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; GALLUS G, 1970, PHYS MED BIOL, V15, P435, DOI 10.1088/0031-9155/15/3/004; Hilditch C.J., 1969, MACH INTELL, P403; Ledley R. S., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P396; LEDLEY RS, 1972, IEEE T COMPUT, VC 21, P740, DOI 10.1109/T-C.1972.223577; MCKEE JW, 1975, PATTERN RECOGN, V7, P25, DOI 10.1016/0031-3203(75)90012-6; MUI JK, 1977, J HISTOCHEM CYTOCHEM, V25, P633, DOI 10.1177/25.7.894005; PAVLIDIS T, 1978, 4TH P INT C PATT REC, P70; PREWITT JMS, 1966, ANN NY ACAD SCI, V128, P1035; ROHLF FJ, 1970, SYST ZOOL, V19, P58, DOI 10.2307/2412027; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871; YAKIMOVSKY Y, 1974, 4TH INT J C ART INT, P695	19	29	29	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	3					232	242		10.1109/TPAMI.1980.4767010	http://dx.doi.org/10.1109/TPAMI.1980.4767010			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR843	21868896				2022-12-18	WOS:A1980JR84300004
J	WECHSLER, H; KIDODE, M				WECHSLER, H; KIDODE, M			RANDOM-WALK PROCEDURE FOR TEXTURE DISCRIMINATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV, SCH ELECT ENGN, W LAFAYETTE, IN 47907 USA; TOSHIBA RES & DEV CTR, SAIWAI KU, KAWASAKI CITY, KANAGAWA, JAPAN	Purdue University System; Purdue University; Purdue University West Lafayette Campus; Toshiba Corporation								Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CARLUCCI L, 1972, PATTERN RECOGN, V4, P53, DOI 10.1016/0031-3203(72)90019-2; CONNERS RW, 1976, IAL474 U MISS COLL E; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; Feller W., 1957, INTRO PROBABILITY TH, V1; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HOLMES WS, 1966, PR INST ELECTR ELECT, V54, P1679, DOI 10.1109/PROC.1966.5249; HUANG HK, 1976, PATTERN RECOGN, P340; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; Kemeny J. G., 1983, FINITE MARKOV CHAINS; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; Siegel S., 1956, NONPARAMETRIC STAT B; Tamura H., 1976, 3rd International Joint Conference on Pattern Recognition, P273; WECHSLER H, 1978, COMPUT VISION GRAPH, V7, P120, DOI 10.1016/S0146-664X(78)80017-3; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777	15	29	31	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					272	280		10.1109/TPAMI.1979.4766923	http://dx.doi.org/10.1109/TPAMI.1979.4766923			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868858				2022-12-18	WOS:A1979HC30100005
J	Phan, H; Chen, OY; Tran, MC; Koch, P; Mertins, A; De Vos, M				Phan, Huy; Chen, Oliver Y.; Tran, Minh C.; Koch, Philipp; Mertins, Alfred; De Vos, Maarten			XSleepNet: Multi-View Sequential Model for Automatic Sleep Staging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time-frequency analysis; Sleep apnea; Training data; Training; Databases; Task analysis; Robustness; Automatic sleep staging; deep neural network; multi-view learning; gradient blending; sequence-to-sequence; end-to-end	RESEARCH RESOURCE	Automating sleep staging is vital to scale up sleep assessment and diagnosis to serve millions experiencing sleep deprivation and disorders and enable longitudinal sleep monitoring in home environments. Learning from raw polysomnography signals and their derived time-frequency image representations has been prevalent. However, learning from multi-view inputs (e.g., both the raw signals and the time-frequency images) for sleep staging is difficult and not well understood. This work proposes a sequence-to-sequence sleep staging model, XSleepNet,(1) that is capable of learning a joint representation from both raw signals and time-frequency images. Since different views may generalize or overfit at different rates, the proposed network is trained such that the learning pace on each view is adapted based on their generalization/overfitting behavior. In simple terms, the learning on a particular view is speeded up when it is generalizing well and slowed down when it is overfitting. View-specific generalization/overfitting measures are computed on-the-fly during the training course and used to derive weights to blend the gradients from different views. As a result, the network is able to retain the representation power of different views in the joint features which represent the underlying distribution better than those learned by each individual view alone. Furthermore, the XSleepNet architecture is principally designed to gain robustness to the amount of training data and to increase the complementarity between the input views. Experimental results on five databases of different sizes show that XSleepNet consistently outperforms the single-view baselines and the multi-view baseline with a simple fusion strategy. Finally, XSleepNet also outperforms prior sleep staging methods and improves previous state-of-the-art results on the experimental databases.	[Phan, Huy] Queen Mary Univ London, Sch Elect Engn, London E1 4NS, England; [Chen, Oliver Y.] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England; [Tran, Minh C.] Univ Oxford, Nuffield Div Anaesthet, Oxford OX3 9DU, England; [Koch, Philipp; Mertins, Alfred] Univ Lubeck, Inst Signal Proc, D-23562 Lubeck, Germany; [De Vos, Maarten] Katholieke Univ Leuven, Dept Dev & Regenerat, Dept Engn, B-3001 Leuven, Belgium	University of London; Queen Mary University London; University of Oxford; University of Oxford; University of Lubeck; KU Leuven	Phan, H (corresponding author), Queen Mary Univ London, Sch Elect Engn, London E1 4NS, England.	h.phan@qmul.ac.uk; yibing.chen@seh.ox.ac.uk; minh.tran@chch.ox.ac.uk; ph.koch@uni-luebeck.de; alfred.mertins@uni-luebeck.de; maarten.devos@kuleuven.be		Tran, Minh Cong/0000-0003-2622-1365				Abadi M, 2015, P 12 USENIX S OPERAT; Amodei D, 2016, PR MACH LEARN RES, V48; Andreotti F, 2018, IEEE ENG MED BIO, P171, DOI 10.1109/EMBC.2018.8512214; Balaji Goparaju, 2017, Arxiv, DOI arXiv:1707.08262; Biswal S, 2018, J AM MED INFORM ASSN, V25, P1643, DOI 10.1093/jamia/ocy131; Chambon S, 2018, IEEE T NEUR SYS REH, V26, P758, DOI 10.1109/TNSRE.2018.2813138; Chattu VK, 2018, HEALTHCARE-BASEL, V7, DOI 10.3390/healthcare7010001; Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691; Cho K., 2014, P 2014 C EMP METH NA, P1724; Colten HR, 2006, SLEEP DISORDERS SLEE; Cooijmans T., 2016, ARXIV; Dong H, 2018, IEEE T NEUR SYS REH, V26, P324, DOI 10.1109/TNSRE.2017.2733220; Ghassemi MM, 2018, COMPUT CARDIOL CONF, V45, DOI [10.22489/cinc.2018.049, 10.22489/CinC.2018.049]; Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hobson J. A., 1969, ELECTROEN CLIN NEURO, V26, P644; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Phan H, 2020, PHYSIOL MEAS, V41, DOI 10.1088/1361-6579/ab921e; Phan H, 2019, IEEE ENG MED BIO, P1829, DOI 10.1109/EMBC.2019.8857348; Phan H, 2019, IEEE T NEUR SYS REH, V27, P400, DOI 10.1109/TNSRE.2019.2896659; Phan H, 2018, IEEE ENG MED BIO, P453, DOI 10.1109/EMBC.2018.8512286; Phan H, 2019, IEEE T BIO-MED ENG, V66, P1285, DOI 10.1109/TBME.2018.2872652; Iber C, 2007, AASM MANUAL SCORING, V1st; Imtiaz SA, 2015, IEEE ENG MED BIO, P6014, DOI 10.1109/EMBC.2015.7319762; Imtiaz SA, 2014, IEEE ENG MED BIO, P5044, DOI 10.1109/EMBC.2014.6944758; Kaare Mikkelsen, 2018, Arxiv, DOI arXiv:1801.02645; Kemp B, 2000, IEEE T BIO-MED ENG, V47, P1185, DOI 10.1109/10.867928; Kingma D.P., 2015, INT C LEARN REPR, P1; Krieger A. C, 2017, SOCIAL EC DIMENSIONS; Langkvist M., 2012, ADV ARTIF NEURAL SYS, V2012, P1; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Malhotra A, 2013, SLEEP, V36, P573, DOI 10.5665/sleep.2548; Maquet P, 2001, SCIENCE, V294, P1048, DOI 10.1126/science.1062856; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Mikkelsen KB, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53115-3; Mikkelsen KB, 2019, J SLEEP RES, V28, DOI 10.1111/jsr.12786; Mousavi S, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216456; O'Reilly C, 2014, J SLEEP RES, V23, P628, DOI 10.1111/jsr.12169; Olesen AN, 2019, IEEE ENG MED BIO, P556, DOI 10.1109/EMBC.2019.8856570; Orestis Tsinalis, 2016, Arxiv, DOI arXiv:1610.01683; Palaz D, 2015, INT CONF ACOUST SPEE, P4295, DOI 10.1109/ICASSP.2015.7178781; Perslev M, 2019, ADV NEUR IN, V32; Phan H, 2021, IEEE T BIO-MED ENG, V68, P1787, DOI 10.1109/TBME.2020.3020381; Phan Huy, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P1452, DOI 10.1109/EMBC.2018.8512480; Quan SF, 1997, SLEEP, V20, P1077; Schluter R, 2007, INT CONF ACOUST SPEE, P649; Seo H, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102037; Sors A, 2018, BIOMED SIGNAL PROCES, V42, P107, DOI 10.1016/j.bspc.2017.12.001; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stephansen JB, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07229-3; Sun H, 2017, SLEEP, V40, DOI 10.1093/sleep/zsx139; Supratak A, 2017, IEEE T NEUR SYS REH, V25, P1998, DOI 10.1109/TNSRE.2017.2721116; Tian Y., 2020, ECCV, P776, DOI [10.48550/arXiv.1906.05849, DOI 10.1007/978-3-030-58621-8_45]; Tsinalis O, 2016, ANN BIOMED ENG, V44, P1587, DOI 10.1007/s10439-015-1444-y; Tsymbal A., 2005, Information Fusion, V6, P83, DOI 10.1016/j.inffus.2004.04.003; Vilamala A, 2017, IEEE INT WORKS MACH; Wang Wenguan, 2020, CVPR; Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42, DOI 10.1145/312624.312647; Zhai B., 2020, PROC ACM INTERACTIVE; Zhang GQ, 2018, J AM MED INFORM ASSN, V25, P1351, DOI 10.1093/jamia/ocy064; Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007	61	28	28	7	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5903	5915		10.1109/TPAMI.2021.3070057	http://dx.doi.org/10.1109/TPAMI.2021.3070057			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33788679	Green Submitted, Green Accepted			2022-12-18	WOS:000836666600096
J	Liu, Y; Wu, YH; Wen, PS; Shi, YJ; Qiu, Y; Cheng, MM				Liu, Yun; Wu, Yu-Huan; Wen, Peisong; Shi, Yujun; Qiu, Yu; Cheng, Ming-Ming			Leveraging Instance-, Image- and Dataset-Level Information for Weakly Supervised Instance Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Proposals; Image segmentation; Training; Probability distribution; Feature extraction; Noise measurement; Weakly supervised learning; instance segmentation; semantic segmentation; multiple instance learning; multi-way cut		Weakly supervised semantic instance segmentation with only image-level supervision, instead of relying on expensive pixel-wise masks or bounding box annotations, is an important problem to alleviate the data-hungry nature of deep learning. In this article, we tackle this challenging problem by aggregating the image-level information of all training images into a large knowledge graph and exploiting semantic relationships from this graph. Specifically, our effort starts with some generic segment-based object proposals (SOP) without category priors. We propose a multiple instance learning (MIL) framework, which can be trained in an end-to-end manner using training images with image-level labels. For each proposal, this MIL framework can simultaneously compute probability distributions and category-aware semantic features, with which we can formulate a large undirected graph. The category of background is also included in this graph to remove the massive noisy object proposals. An optimal multi-way cut of this graph can thus assign a reliable category label to each proposal. The denoised SOP with assigned category labels can be viewed as pseudo instance segmentation of training images, which are used to train fully supervised models. The proposed approach achieves state-of-the-art performance for both weakly supervised instance segmentation and semantic segmentation. The code is available at https://github.com/yun-liu/LIID.	[Liu, Yun; Wu, Yu-Huan; Wen, Peisong; Shi, Yujun; Cheng, Ming-Ming] Nankai Univ, Coll Comp Sci, TKLNDST, Tianjin 300350, Peoples R China; [Qiu, Yu] Nankai Univ, Coll Artificial Intelligence, Tianjin 300350, Peoples R China	Nankai University; Nankai University	Cheng, MM (corresponding author), Nankai Univ, Coll Comp Sci, TKLNDST, Tianjin 300350, Peoples R China.	nk12csly@mail.nankai.edu.cn; wuyuhuan@mail.nankai.edu.cn; wps_@mail.nankai.edu.cn; 1511201@mail.nankai.edu.cn; yqiu@mail.nankai.edu.cn; cmm@nankai.edu.cn	Wu, Yu-Huan/ABG-4219-2020; Cheng, Ming-Ming/A-2527-2009	Wu, Yu-Huan/0000-0001-8666-3435; Cheng, Ming-Ming/0000-0001-5550-8758; Qiu, Yu/0000-0001-6722-3039; Reis, AlessanRSS/0000-0001-8486-7469; Liu, Yun/0000-0001-6143-0264	Major Project for New Generation of AI [2018AAA0100400]; NSFC [61922046]; Tianjin Natural Science Foundation [18ZXZNGX00110]; S&T innovation project from Chinese Ministry of Education	Major Project for New Generation of AI; NSFC(National Natural Science Foundation of China (NSFC)); Tianjin Natural Science Foundation(Natural Science Foundation of Tianjin); S&T innovation project from Chinese Ministry of Education	This research was supported by the Major Project for New Generation of AI under Grant No. 2018AAA0100400, NSFC (61922046), Tianjin Natural Science Foundation (18ZXZNGX00110), and S&T innovation project from Chinese Ministry of Education. Yun Liu and Yu-HuanWucontributed equally to this work.	Ahn J, 2019, PROC CVPR IEEE, P2204, DOI 10.1109/CVPR.2019.00231; Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arnab A, 2017, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.2017.100; Bai M, 2017, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2017.305; Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34; Bin Jin, 2017, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR.2017.185; Bliek C., 2014, P 26 RAMP S, P16; Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9; Calinescu G, 2000, J COMPUT SYST SCI, V60, P564, DOI 10.1006/jcss.1999.1687; Chaudhry Arslan, 2017, ARXIV170705821; Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Cheng MM, 2019, COMPUT VIS MEDIA, V5, P3, DOI 10.1007/s41095-018-0120-1; Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4; Cholakkal H, 2019, PROC CVPR IEEE, P12389, DOI 10.1109/CVPR.2019.01268; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; DAHLHAUS E, 1994, SIAM J COMPUT, V23, P864, DOI 10.1137/S0097539792225297; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Durand T, 2019, IEEE T PATTERN ANAL, V41, P337, DOI 10.1109/TPAMI.2017.2788435; Durand T, 2017, PROC CVPR IEEE, P5957, DOI 10.1109/CVPR.2017.631; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fan RC, 2018, LECT NOTES COMPUT SC, V11213, P371, DOI 10.1007/978-3-030-01240-3_23; Fan RC, 2020, COMPUT VIS MEDIA, V6, P191, DOI 10.1007/s41095-020-0173-9; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Garg N, 1996, SIAM J COMPUT, V25, P235, DOI 10.1137/S0097539793243016; Ge WF, 2019, IEEE I CONF COMP VIS, P3344, DOI 10.1109/ICCV.2019.00344; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hong S, 2017, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2017.239; Hou  Qibin, 2017, EMMCVPR; Hsu CC, 2019, ADV NEUR IN, V32; Hu R, 2018, PROC CVPR IEEE, P4233, DOI 10.1109/CVPR.2018.00445; Huang ZL, 2018, PROC CVPR IEEE, P7014, DOI 10.1109/CVPR.2018.00733; Jiang PT, 2019, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2019.00216; Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181; Kim D, 2017, IEEE I CONF COMP VIS, P3554, DOI 10.1109/ICCV.2017.382; Kirillov A, 2017, PROC CVPR IEEE, P7322, DOI 10.1109/CVPR.2017.774; Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Krahenbuhl P, 2015, PROC CVPR IEEE, P1574, DOI 10.1109/CVPR.2015.7298765; Lee J, 2019, IEEE I CONF COMP VIS, P6807, DOI 10.1109/ICCV.2019.00691; Lee J, 2019, PROC CVPR IEEE, P5262, DOI 10.1109/CVPR.2019.00541; Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960; Li QZ, 2018, LECT NOTES COMPUT SC, V11219, P106, DOI 10.1007/978-3-030-01267-0_7; Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472; Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Liu Y, 2020, ARXIV190312476; Liu YH, 2018, IEEE T NEUR NET LEAR, V29, P4983, DOI [10.1109/TSMC.2018.2867061, 10.1109/TNNLS.2017.2785278]; Liu Y, 2020, NEUROCOMPUTING, V406, P106, DOI 10.1016/j.neucom.2020.04.017; Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Oh SJ, 2017, PROC CVPR IEEE, P5038, DOI 10.1109/CVPR.2017.535; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320; Qi XJ, 2016, LECT NOTES COMPUT SC, V9912, P90, DOI 10.1007/978-3-319-46484-8_6; Qiu Y, 2020, NEUROCOMPUTING, V388, P124, DOI 10.1016/j.neucom.2019.12.123; Qiu Y, 2019, IEEE IMAGE PROC, P4010, DOI 10.1109/ICIP.2019.8803646; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Roy A, 2017, PROC CVPR IEEE, P7282, DOI 10.1109/CVPR.2017.770; Saleh F, 2016, LECT NOTES COMPUT SC, V9912, P413, DOI 10.1007/978-3-319-46484-8_25; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shen T, 2018, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2018.00148; Shen YH, 2018, PROC CVPR IEEE, P5764, DOI 10.1109/CVPR.2018.00604; Shen YH, 2019, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2019.00079; Shimoda W, 2019, IEEE I CONF COMP VIS, P5207, DOI 10.1109/ICCV.2019.00531; Shimoda W, 2016, LECT NOTES COMPUT SC, V9908, P218, DOI 10.1007/978-3-319-46493-0_14; Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381; Song CF, 2019, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2019.00325; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wan F, 2018, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2018.00141; Wang X, 2018, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2018.00147; Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687; Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759; Wei YC, 2017, IEEE T PATTERN ANAL, V39, P2314, DOI 10.1109/TPAMI.2016.2636150; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Xie SN, 2017, INT J COMPUT VISION, V125, P3, DOI 10.1007/s11263-017-1004-z; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhang XP, 2018, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR.2018.00448; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou YZ, 2018, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2018.00399; Zhu Y, 2017, IEEE I CONF COMP VIS, P1859, DOI 10.1109/ICCV.2017.204	93	28	29	37	76	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1415	1428		10.1109/TPAMI.2020.3023152	http://dx.doi.org/10.1109/TPAMI.2020.3023152			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32915726				2022-12-18	WOS:000752018000025
J	Bai, L; Cui, LX; Jiao, YH; Rossi, L; Hancock, ER				Bai, Lu; Cui, Lixin; Jiao, Yuhang; Rossi, Luca; Hancock, Edwin R.			Learning Backtrackless Aligned-Spatial Graph Convolutional Networks for Graph Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolution; Adaptation models; Transforms; Convolutional neural networks; Standards; Feature extraction; Kernel; Graph convolutional networks; transitive vertex alignment; backtrackless walk		In this paper, we develop a novel backtrackless aligned-spatial graph convolutional network (BASGCN) model to learn effective features for graph classification. Our idea is to transform arbitrary-sized graphs into fixed-sized backtrackless aligned grid structures and define a new spatial graph convolution operation associated with the grid structures. We show that the proposed BASGCN model not only reduces the problems of information loss and imprecise information representation arising in existing spatially-based graph convolutional network (GCN) models, but also bridges the theoretical gap between traditional convolutional neural network (CNN) models and spatially-based GCN models. Furthermore, the proposed BASGCN model can both adaptively discriminate the importance between specified vertices during the convolution process and reduce the notorious tottering problem of existing spatially-based GCNs related to the Weisfeiler-Lehman algorithm, explaining the effectiveness of the proposed model. Experiments on standard graph datasets demonstrate the effectiveness of the proposed model.	[Bai, Lu; Jiao, Yuhang] Cent Univ Finance & Econ, Beijing 100081, Peoples R China; [Cui, Lixin] Cent Univ Finance & Econ, Sch Informat, Beijing 100081, Peoples R China; [Rossi, Luca] Queen Mary Univ London, London E1 4NS, England; [Hancock, Edwin R.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England	Central University of Finance & Economics; Central University of Finance & Economics; University of London; Queen Mary University London; University of York - UK	Cui, LX (corresponding author), Cent Univ Finance & Econ, Sch Informat, Beijing 100081, Peoples R China.	bailucs@cufe.edu.cn; cuilixin@cufe.edu.cn; jiaoyuhang@email.cufe.edu.cn; luca.rossi@qmul.ac.uk; edwin.hancock@york.ac.uk	Hancock, Edwin R/C-6071-2008; Rossi, Luca/V-1459-2018	Hancock, Edwin R/0000-0003-4496-2028; Rossi, Luca/0000-0002-6116-9761	National Natural Science Foundation of China [61976235, 61602535]; program for innovation research in Central University of Finance and Economics; Youth Talent Development Support Program by Central University of Finance and Economics [QYP1908]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); program for innovation research in Central University of Finance and Economics; Youth Talent Development Support Program by Central University of Finance and Economics	This work was supported by the National Natural Science Foundation of China (Grants 61976235 and 61602535), the program for innovation research in Central University of Finance and Economics, and the Youth Talent Development Support Program by Central University of Finance and Economics, No. QYP1908. The third author Mr. Yuhang Jiao mainly participated partial coding and experiment works.	Atwood J., 2016, ADV NEURAL INFORM PR, P1993, DOI DOI 10.5555/3157096.3157320; Bai L, 2020, PATTERN RECOGN LETT, V134, P87, DOI 10.1016/j.patrec.2018.06.016; Bai L, 2020, IEEE T CYBERNETICS, V50, P1264, DOI 10.1109/TCYB.2019.2913038; Bai L, 2015, PR MACH LEARN RES, V37, P30; Bai L, 2016, PATTERN RECOGN, V54, P229, DOI 10.1016/j.patcog.2016.01.004; Bai L, 2014, PATTERN RECOGN, V47, P1172, DOI 10.1016/j.patcog.2013.09.010; Borgwardt KM, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P74, DOI 10.1109/ICDM.2005.132; Bruna J., 2014, C TRACK P; Chen YX, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107321; diaeresis>el Defferrard Micha<spacing, 2016, NEURIPS, DOI DOI 10.5555/3157382.3157527; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Gammerman A., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P148; Gibert J, 2012, PATTERN RECOGN, V45, P3072, DOI 10.1016/j.patcog.2012.01.009; Gomez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572; Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754; Hancock E. R., 2019, ARXIV190404238, P464; Harchaoui Z., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383049; Henaff M, 2015, ARXIV150605163; Kashima Hisashi, 2003, P 20 INT C MACH LEAR, P321; Kipf TN, 2016, P INT C LEARN REPR; Kondor R., 2008, P 25 INT C MACH LEAR, P496, DOI DOI 10.1145/1390156.1390219; Krause A., 2018, P 35 INT C MACH LEAR, V80, P2191; Kriege N.M., 2012, INT C MACHINE LEARNI, P291; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lee J, 2019, PR MACH LEARN RES, V97; Lu Bai, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8724, P99, DOI 10.1007/978-3-662-44848-9_7; Manessi F, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107000; Martino GD, 2018, IEEE T NEUR NET LEAR, V29, P3270, DOI 10.1109/TNNLS.2017.2705694; Morris C, 2019, AAAI CONF ARTIF INTE, P4602; Morris C, 2017, IEEE DATA MINING, P327, DOI 10.1109/ICDM.2017.42; Niepert M, 2016, PR MACH LEARN RES, V48; Nikolentzos G, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2595; Ou MD, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1105, DOI 10.1145/2939672.2939751; Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rippel Oren, 2015, ARXIV150603767; Shervashidze N., 2009, P 12 INT C ART INT S, P488; Shervashidze N., 2010, J MACH LEARN RES, V1, P1; Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11; Verma Saurabh, 2018, ABS180508090 CORR; Vialatte J., 2016, GEN CONVOLUTION OPER; Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753; Witten IH, 2011, MOR KAUF D, P1; Wu J, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P406, DOI 10.1145/3292500.3330950; Yanardag P, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1365, DOI 10.1145/2783258.2783417; Ying R, 2018, ADV NEUR IN, V31; You JX, 2019, PR MACH LEARN RES, V97; ZAMBON D, 2018, IEEE T NEUR NET LEAR, V29, P5592, DOI DOI 10.1109/TNNLS.2018.2804443; Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438; Zhang SX, 2015, INT CONF ACOUST SPEE, P4275, DOI 10.1109/ICASSP.2015.7178777; Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579; Zhang ZH, 2019, PATTERN RECOGN, V88, P38, DOI 10.1016/j.patcog.2018.11.002	52	28	28	38	63	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					783	798		10.1109/TPAMI.2020.3011866	http://dx.doi.org/10.1109/TPAMI.2020.3011866			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32750832	Green Accepted, Green Submitted, Green Published			2022-12-18	WOS:000740006100019
J	Damen, D; Doughty, H; Farinella, GM; Fidler, S; Furnari, A; Kazakos, E; Moltisanti, D; Munro, J; Perrett, T; Price, W; Wray, M				Damen, Dima; Doughty, Hazel; Farinella, Giovanni Maria; Fidler, Sanja; Furnari, Antonino; Kazakos, Evangelos; Moltisanti, Davide; Munro, Jonathan; Perrett, Toby; Price, Will; Wray, Michael			The EPIC-KITCHENS Dataset: Collection, Challenges and Baselines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Annotations; Cameras; Benchmark testing; Task analysis; Streaming media; YouTube; Indexes; Egocentric vision; first-person vision; large-scale dataset; open challenges; action recognition and anticipation		Since its introduction in 2018, EPIC-KITCHENS has attracted attention as the largest egocentric video benchmark, offering a unique viewpoint on people's interaction with objects, their attention, and even intention. In this paper, we detail how this large-scale dataset was captured by 32 participants in their native kitchen environments, and densely annotated with actions and object interactions. Our videos depict nonscripted daily activities, as recording is started every time a participant entered their kitchen. Recording took place in four countries by participants belonging to ten different nationalities, resulting in highly diverse kitchen habits and cooking styles. Our dataset features 55 hours of video consisting of 11.5M frames, which we densely labelled for a total of 39.6K action segments and 454.2K object bounding boxes. Our annotation is unique in that we had the participants narrate their own videos (after recording), thus reflecting true intention, and we crowd-sourced ground-truths based on these. We describe our object, action and anticipation challenges, and evaluate several baselines over two test splits, seen and unseen kitchens. We introduce new baselines that highlight the multimodal nature of the dataset and the importance of explicit temporal modelling to discriminate fine-grained actions (e.g., 'closing a tap' from 'opening' it up).	[Damen, Dima; Doughty, Hazel; Kazakos, Evangelos; Moltisanti, Davide; Munro, Jonathan; Perrett, Toby; Price, Will; Wray, Michael] Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England; [Fidler, Sanja] Univ Toronto, Vector Inst, Toronto, ON M5S, Canada; [Fidler, Sanja] Univ Toronto, NVIDIA, Toronto, ON M5S, Canada; [Farinella, Giovanni Maria] Univ Catania, Dept Math & Comp Sci, Comp Vis & Machine Learning, I-95124 Catania, CT, Italy; [Furnari, Antonino] Univ Catania, Dept Math & Comp Sci, I-95124 Catania, CT, Italy	University of Bristol; University of Toronto; University of Toronto; University of Catania; University of Catania	Damen, D (corresponding author), Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England.	Dima.Damen@bristol.ac.uk; Hazel.Doughty@bristol.ac.uk; Gfarinella@dmi.unict.it; Fidler@cs.toronto.edu; Furnari@dmi.unict.it; Evangelos.Kazakos@bristol.ac.uk; Davide.Moltisanti@bristol.ac.uk; Jonathan.Munro@bristol.ac.uk; Toby.Perrett@bristol.ac.uk; Will.Price@bristol.ac.uk; Michael.Wray@bristol.ac.uk	; FARINELLA, Giovanni Maria/L-8555-2015	Price, Will/0000-0003-2884-0290; FARINELLA, Giovanni Maria/0000-0002-6034-0432; Doughty, Hazel/0000-0002-3670-3897; FURNARI, Antonino/0000-0001-6911-0302; Moltisanti, Davide/0000-0003-4265-8882; Damen, Dima/0000-0001-8804-6238	Engineering & Physical Sciences Research Council (EPSRC) [EP/N013964/1, EP/N033779/1, EP/T004991/1]; Piano della Ricerca 2016-2018-linea di Intervento 2 of DMI	Engineering & Physical Sciences Research Council (EPSRC)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Piano della Ricerca 2016-2018-linea di Intervento 2 of DMI	The authorswould like to thank all 32 participants in the dataset collection. Research at the University of Bristol was supported by Engineering & Physical Sciences Research Council (EPSRC) Doctoral Training Programme, project GLANCE (EP/N013964/1), Project LOCATE (EP/N033779/1) and Fellowship UMPIRE (EP/T004991/1). Annotations have been sponsored by a charitable donation from Nokia Technologies and theUniversity of Bristol's Jean Golding Institute. Research at the University of Catania is sponsored by Piano della Ricerca 2016-2018-linea di Intervento 2 of DMI.	Abu-El-Haija S., 2016, ARXIV; Alayrac JB, 2017, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2017.234; Alletto S, 2015, PATTERN RECOGN, V48, P4082, DOI 10.1016/j.patcog.2015.06.006; [Anonymous], 2017, SLAC SPARSELY LABELE; [Anonymous], 2016, P ECCV; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Banerjee S., 2002, Computational Linguistics and Intelligent Text Processing. Third International Conference, CICLing 2002. Proceedings (Lecture Notes in Computer Science Vol.2276), P136; Baradel F, 2018, LECT NOTES COMPUT SC, V11217, P106, DOI 10.1007/978-3-030-01261-8_7; Carnegie Mellon University, CMU SPHINX; Carreira Joao, 2019, ARXIV190706987; Damen Dima, 2014, BMVA; De la Torre Fernando, 2008, GUIDE CARNEGIE MELLO; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Doughty H, 2019, PROC CVPR IEEE, P7854, DOI 10.1109/CVPR.2019.00805; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23; Fathi A, 2012, PROC CVPR IEEE, P1226, DOI 10.1109/CVPR.2012.6247805; Fouhey DF, 2018, PROC CVPR IEEE, P4991, DOI 10.1109/CVPR.2018.00524; Furnari Antonino, 2017, J VIS COMMUN IMAGE R, V49, P401, DOI DOI 10.1016/j.jvcir.2017.10.004; Gao Jiyang, 2017, BRIT MACH VIS C BMVC; Georgia Tech, 2018, EXT GTEA GAZ; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Google, GOOGL CLOUD SPEECH A; Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622; Gygli M, 2020, INT J COMPUT VISION, V128, P1061, DOI 10.1007/s11263-019-01255-4; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; IBM, IBM WATS SPEECH TEXT; Kalogeiton V, 2017, IEEE I CONF COMP VIS, P2001, DOI 10.1109/ICCV.2017.219; Kapidis G, 2019, 2019 IEEE SMARTWORLD, P922; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kazakos E, 2019, IEEE I CONF COMP VIS, P5491, DOI 10.1109/ICCV.2019.00559; Kilgarriff A., 2000, P 2 INT C LANG RES E; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105; Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820; Lesk M., 1986, ANN INT C SYSTEMS DO, P24, DOI DOI 10.1145/318723.318728; Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272; Mikolov T., 2013, WORKSHOP TRACK P; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Moltisanti D, 2019, PROC CVPR IEEE, P9907, DOI 10.1109/CVPR.2019.01015; Moltisanti D, 2017, IEEE I CONF COMP VIS, P2905, DOI 10.1109/ICCV.2017.314; Monfort M, 2020, IEEE T PATTERN ANAL, V42, P502, DOI 10.1109/TPAMI.2019.2901464; Munro J., 2020, P IEEE CVF C COMP VI; Nagarajan T, 2020, PROC CVPR IEEE, P160, DOI 10.1109/CVPR42600.2020.00024; Park HS, 2016, PROC CVPR IEEE, P4697, DOI 10.1109/CVPR.2016.508; Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rhinehart N, 2017, IEEE I CONF COMP VIS, P3716, DOI 10.1109/ICCV.2017.399; Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940; Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801; Ryoo MS, 2013, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2013.352; Sigurdsson G. A, 2018, CHARADESEGO LARGE SC; Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31; Simonyan K, 2014, ADV NEUR IN, V27; Stein S, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P729, DOI 10.1145/2493432.2493482; Suris D., 2019, LEARNING LEARN WORDS; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501; Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18; Wang XH, 2020, AAAI CONF ARTIF INTE, V34, P12249; Wray M, 2019, IEEE I CONF COMP VIS, P450, DOI 10.1109/ICCV.2019.00054; Wu HP, 2019, IEEE I CONF COMP VIS, P9216, DOI 10.1109/ICCV.2019.00931; Xiao Fanyi, 2020, ARXIV200108740; Xu YD, 2018, INT C PATT RECOG, P1833, DOI 10.1109/ICPR.2018.8545058; Yamaguchi K., BBOX ANNOTATOR; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhao H, 2019, IEEE I CONF COMP VIS, P8667, DOI 10.1109/ICCV.2019.00876; Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544; Zhou LW, 2018, AAAI CONF ARTIF INTE, P7590	72	28	29	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					4125	4141		10.1109/TPAMI.2020.2991965	http://dx.doi.org/10.1109/TPAMI.2020.2991965			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32365017	Green Submitted			2022-12-18	WOS:000702649700030
J	Gao, QX; Zhang, P; Xia, W; Xie, DY; Gao, XB; Tao, DC				Gao, Quanxue; Zhang, Pu; Xia, Wei; Xie, Deyan; Gao, Xinbo; Tao, Dacheng			Enhanced Tensor RPCA and its Application	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensor singular value decomposition; robust principal component analysis; multidimensional image denoising	ROBUST-PCA	Despite the promising results, tensor robust principal component analysis (TRPCA), which aims to recover underlying low-rank structure of clean tensor data corrupted with noise/outliers by shrinking all singular values equally, cannot well preserve the salient content of image. The major reason is that, in real applications, there is a salient difference information between all singular values of a tensor image, and the larger singular values are generally associated with some salient parts in the image. Thus, the singular values should be treated differently. Inspired by this observation, we investigate whether there is a better alternative solution when using tensor rank minimization. In this paper, we develop an enhanced TRPCA (ETRPCA) which explicitly considers the salient difference information between singular values of tensor data by the weighted tensor Schatten p-norm minimization, and then propose an efficient algorithm, which has a good convergence, to solve ETRPCA. Extensive experimental results reveal that the proposed method ETRPCA is superior to several state-of-the-art variant RPCA methods in terms of performance.	[Gao, Quanxue; Zhang, Pu; Xia, Wei; Xie, Deyan] Xidian Univ, Integrated Serv Networks, Xian 710071, Peoples R China; [Gao, Quanxue] Northwestern Polytech Univ, Unmanned Syst Res Inst, Xian 710069, Peoples R China; [Gao, Xinbo] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China; [Gao, Xinbo] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing 400065, Peoples R China; [Tao, Dacheng] Univ Sydney, Fac Engn & Informat Technol, UBTECH Sydney Artificial Intelligence Ctr, Darlington, NSW 2008, Australia; [Tao, Dacheng] Univ Sydney, Fac Engn & Informat Technol, Sch Informat Technol, Darlington, NSW 2008, Australia	Xidian University; Northwestern Polytechnical University; Xidian University; Chongqing University of Posts & Telecommunications; University of Sydney; University of Sydney	Gao, QX (corresponding author), Xidian Univ, Integrated Serv Networks, Xian 710071, Peoples R China.	qxgao@xidian.edu.cn; 845037828@qq.com; xiawei0122@gmail.com; 287784562@qq.com; xbgao@mail.xidian.edu.cn; dacheng.tao@sydney.edu.au			National Natural Science Foundation of China [61773302]; Natural Science Basic Research Plan in Shaanxi Province [2020JZ-19]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Basic Research Plan in Shaanxi Province	The authors would like to thank the anonymous reviewers and AE for their constructive comments and suggestions. This work was supported by the National Natural Science Foundation of China (Grant 61773302), Natural Science Basic Research Plan in Shaanxi Province (Grant 2020JZ-19).	Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bouwmans T, 2018, P IEEE, V106, P1427, DOI 10.1109/JPROC.2018.2853589; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chen K, 2013, BIOMETRIKA, V100, P901, DOI 10.1093/biomet/ast036; Gao QX, 2020, AAAI CONF ARTIF INTE, V34, P3930; Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5; Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271; Jiang B, 2013, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2013.448; Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020; KIMBER JE, 1965, AM MATH MON, V72, P1007, DOI 10.2307/2313347; Lin Z., 2015, MACH LEARN, V99, P287, DOI DOI 10.1007/s10994-014-5469-5; Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760; Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567; Maddalena L, 2015, LECT NOTES COMPUT SC, V9281, P469, DOI 10.1007/978-3-319-23222-5_57; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; MIRSKY L, 1975, MONATSH MATH, V79, P303, DOI 10.1007/BF01647331; Mu Y, 2020, PATTERN RECOGN LETT, V130, P4, DOI 10.1016/j.patrec.2018.12.012; Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956; Shahid N, 2015, IEEE I CONF COMP VIS, P2812, DOI 10.1109/ICCV.2015.322; Vaswani N, 2018, IEEE SIGNAL PROC MAG, V35, P32, DOI 10.1109/MSP.2018.2826566; Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290; Zhang LD, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040382	23	28	28	10	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2133	2140		10.1109/TPAMI.2020.3017672	http://dx.doi.org/10.1109/TPAMI.2020.3017672			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	32809937				2022-12-18	WOS:000649590200023
J	Nie, FP; Wang, Z; Wang, R; Wang, Z; Li, XL				Nie, Feiping; Wang, Zheng; Wang, Rong; Wang, Zhen; Li, Xuelong			Towards Robust Discriminative Projections Learning via Non-Greedy l(2,1)-Norm MinMax	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robust dimensionality reduction; l(2,1)-normminmax problem; non-greedy iterative re-weighted solver; optimal weighted mean; outlier	PRINCIPAL COMPONENT ANALYSIS; REPRESENTATION	Linear Discriminant Analysis (LDA) is one of the most successful supervised dimensionality reduction methods and has been widely used in many real-world applications. However, l(2)-norm is employed as the distance metric in the objective of LDA, which is sensitive to outliers. Many previous works improve the robustness of LDA by using l(1)-norm distance. However, the robustness against outliers is limited and the solver of l(1)-norm is mostly based on the greedy search strategy, which is time-consuming and easy to get stuck in a local optimum. In this paper, we propose a novel robust LDA measured by l(2,1)-norm to learn robust discriminative projections. The proposed model is challenging to solve since it needs to minimize and maximize (minmax) l(2,1)-norm terms simultaneously. As a result, we first systematically derive an efficient iterative optimization algorithm to solve a general ratio minimization problem, and then rigorously prove its convergence. More importantly, an alternately non-greedy iterative re-weighted optimization algorithm is developed based on the preceding approach for solving proposed l(2,1)-norm minmax problem. Besides, an optimal weighted mean mechanism is driven according to the designed objective and solver, which can be applied to other approaches for robustness improvement. Experimental results on several real-world datasets show the effectiveness of proposed method.	[Nie, Feiping; Wang, Zheng; Wang, Rong; Wang, Zhen; Li, Xuelong] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China; [Nie, Feiping; Wang, Zheng; Wang, Rong; Wang, Zhen; Li, Xuelong] Northwestern Polytech Univ, Ctr Opt IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China; [Wang, Rong; Wang, Zhen] Northwestern Polytech Univ, Sch Mech Engn, Xian 710072, Shaanxi, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University	Nie, FP (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Nie, FP (corresponding author), Northwestern Polytech Univ, Ctr Opt IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.	feipingnie@gmail.com; zhengwangml@gmail.com; wangrong07@tsinghua.org.cn; zhenwang0@gmail.com; li@nwpu.edu.cn			National Key Research and Development Program of China [2018AAA0101902]; National Natural Science Foundation of China [U1803263, 61936014, 61772427, 61751202]; Fundamental Research Funds for the Central Universities [G2019KY0501, 3102019PJ006]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0101902, in part by the National Natural Science Foundation of China under Grant U1803263, Grant 61936014, Grant 61772427, and Grant 61751202, and in part by the Fundamental Research Funds for the Central Universities under Grant G2019KY0501 and Grant 3102019PJ006.	[Anonymous], 2018, P INT C NEUR INF PRO; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Border K., 2001, SUPERGRADIENT CONCAV; Chen S, 2017, IEEE T IMAGE PROCESS, V26, P5519, DOI 10.1109/TIP.2017.2738560; Chen XB, 2014, INT C PATT RECOG, P1585, DOI 10.1109/ICPR.2014.281; Croux C, 2001, CAN J STAT, V29, P473, DOI 10.2307/3316042; Ding C., 2006, PROC INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880; Gao JB, 2008, NEURAL COMPUT, V20, P555, DOI 10.1162/neco.2007.11-06-397; He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220; Huang H., 2010, NIPS, P1813; Huang H., 2016, ARXIV160308293; Huang HCJ, 2008, LINGUISTICS, V46, P1, DOI 10.1515/LING.2008.001; Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760; Jolliffe I, 2011, INT ENCY STAT SCI, DOI 10.1007/978-3-642-04898-2_455; Journee M, 2010, J MACH LEARN RES, V11, P517; Khalid C., 2017, P INT SYST COMP VIS, P1; Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346; Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114; Kyperountas M, 2007, IEEE T NEURAL NETWOR, V18, P506, DOI 10.1109/TNN.2006.885038; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Liu Y, 2017, IEEE T IMAGE PROCESS, V26, P684, DOI 10.1109/TIP.2016.2621667; Markopoulos PP, 2017, IEEE T SIGNAL PROCES, V65, P4252, DOI 10.1109/TSP.2017.2708023; Meng DY, 2012, PATTERN RECOGN, V45, P487, DOI 10.1016/j.patcog.2011.07.009; Nie F., 2011, PROC INT JOINT C ART, P1433; Nie F., 2016, IJCAI, P1881; Nie FP, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-9021-9; Nie FP, 2014, PR MACH LEARN RES, V32, P1062; Nie FP, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P993; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Ren CX, 2012, PATTERN RECOGN, V45, P2708, DOI 10.1016/j.patcog.2012.01.003; Shi XS, 2018, NEUROCOMPUTING, V283, P205, DOI 10.1016/j.neucom.2017.12.034; Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang HX, 2014, IEEE T CYBERNETICS, V44, P828, DOI 10.1109/TCYB.2013.2273355; Wang H, 2014, PR MACH LEARN RES, V32, P1836; Wang H, 2011, LECT NOTES COMPUT SC, V6893, P115, DOI 10.1007/978-3-642-23626-6_15; Wang H, 2007, PROC CVPR IEEE, P108; Wang R, 2017, IEEE T IMAGE PROCESS, V26, P5019, DOI 10.1109/TIP.2017.2726188; Wang R, 2015, IEEE T CYBERNETICS, V45, P1108, DOI 10.1109/TCYB.2014.2341575; Wang XJ, 2010, INT CONF COMP SCI, P52, DOI 10.1109/ICCSIT.2010.5563960; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Xu J, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2555, DOI 10.1145/3219819.3220016; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097; Yang J, 2006, IEEE SYS MAN CYBERN, P4208, DOI 10.1109/ICSMC.2006.384795; Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170; Ye QL, 2018, NEURAL NETWORKS, V105, P393, DOI 10.1016/j.neunet.2018.05.020; Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989; Zhang R, 2017, INT CONF ACOUST SPEE, P6065, DOI 10.1109/ICASSP.2017.7953321; Zhang Yu., 2010, P ADV NEURAL INFORM, P2568; Zhao HF, 2019, IEEE T KNOWL DATA EN, V31, P629, DOI 10.1109/TKDE.2018.2842023; Zhao W, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P336, DOI 10.1109/AFGR.1998.670971; Zheng WM, 2014, IEEE T NEUR NET LEAR, V25, P793, DOI 10.1109/TNNLS.2013.2281428; Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476	58	28	29	6	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2086	2100		10.1109/TPAMI.2019.2961877	http://dx.doi.org/10.1109/TPAMI.2019.2961877			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	31880539				2022-12-18	WOS:000649590200019
J	Liu, RS; Cheng, SC; He, Y; Fan, X; Lin, ZC; Luo, ZX				Liu, Risheng; Cheng, Shichao; He, Yi; Fan, Xin; Lin, Zhouchen; Luo, Zhongxuan			On the Convergence of Learning-Based Iterative Methods for Nonconvex Inverse Problems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Inverse problems; Convergence; Iterative methods; Learning systems; Acceleration; Iterative algorithms; Learning systems; Statistical analysis; Nonconvex optimization; learning-based iteration; convergence guarantee; image deconvolution; rain streaks removal	THRESHOLDING ALGORITHM; BLIND DECONVOLUTION; IMAGE; MINIMIZATION; DESIGN	Numerous tasks at the core of statistics, learning and vision areas are specific cases of ill-posed inverse problems. Recently, learning-based (e.g., deep) iterative methods have been empirically shown to be useful for these problems. Nevertheless, integrating learnable structures into iterations is still a laborious process, which can only be guided by intuitions or empirical insights. Moreover, there is a lack of rigorous analysis about the convergence behaviors of these reimplemented iterations, and thus the significance of such methods is a little bit vague. This paper moves beyond these limits and proposes Flexible Iterative Modularization Algorithm (FIMA), a generic and provable paradigm for nonconvex inverse problems. Our theoretical analysis reveals that FIMA allows us to generate globally convergent trajectories for learning-based iterative methods. Meanwhile, the devised scheduling policies on flexible modules should also be beneficial for classical numerical methods in the nonconvex scenario. Extensive experiments on real applications verify the superiority of FIMA.	[Liu, Risheng; He, Yi; Fan, Xin] Dalian Univ Technol, DUT RU Int Sch Informat Sci & Engn, Dalian 116081, Peoples R China; [Liu, Risheng; Cheng, Shichao; He, Yi; Fan, Xin; Luo, Zhongxuan] Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116024, Peoples R China; [Cheng, Shichao] Dalian Univ Technol, Sch Math Sci, Dalian 116081, Peoples R China; [Lin, Zhouchen] Peking Univ, Sch Elect Engn & Comp Sci, Minist Educ, Key Lab Machine Percept, Beijing 100871, Peoples R China; [Luo, Zhongxuan] Dalian Univ Technol, Sch Math Sci, DUT RU Int Sch Informat Sci & Engn, Dalian 116081, Peoples R China; [Luo, Zhongxuan] Guilin Univ Elect Technol, Inst Artificial Intelligence, Guilin 541004, Peoples R China	Dalian University of Technology; Dalian University of Technology; Peking University; Dalian University of Technology; Guilin University of Electronic Technology	Liu, RS (corresponding author), Dalian Univ Technol, DUT RU Int Sch Informat Sci & Engn, Dalian 116081, Peoples R China.	rsliu@dlut.edu.cn; shichao.cheng@outlook.com; xin.fan@dlut.edu.cn; heyiking@outlook.com; zlin@pku.edu.cn; zxluo@dlut.edu.cn		Liu, Risheng/0000-0002-9554-0565	National Natural Science Foundation (NSF) of China [61672125, 61733002, 61572096, 61632019]; Fundamental Research Funds for the Central Universities; 973 Program of China [2015CB352502]; NSF of China [61625301, 61731018]; Qualcomm; Microsoft Research Asia	National Natural Science Foundation (NSF) of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); 973 Program of China(National Basic Research Program of China); NSF of China(National Natural Science Foundation of China (NSFC)); Qualcomm; Microsoft Research Asia(Microsoft)	R. Liu, S. Cheng, Y. He, X. Fan and Z. Luo are supported in part by the National Natural Science Foundation (NSF) of China (grant nos. 61672125, 61733002, 61572096 and 61632019), and the Fundamental Research Funds for the Central Universities. Z. Lin is supported by 973 Program of China (grant no. 2015CB352502), NSF of China (grant nos. 61625301 and 61731018), Qualcomm, and Microsoft Research Asia.	Andrychowicz M, 2016, ADV NEUR IN, V29; [Anonymous], 2016, ADV NEUR IN; [Anonymous], 2010, P INT C MACH LEARN; Attouch H, 2009, MATH PROGRAM, V116, P5, DOI 10.1007/s10107-007-0133-5; Attouch H, 2013, MATH PROGRAM, V137, P91, DOI 10.1007/s10107-011-0484-9; Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chan SH, 2017, IEEE T COMPUT IMAG, V3, P84, DOI 10.1109/TCI.2016.2629286; Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743; Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280; Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng LJ, 2018, APPL MATH MODEL, V59, P662, DOI 10.1016/j.apm.2018.03.001; Diamond S, 2017, ARXIV170508041; Duchi J., 2008, PROC 25 INT C MACH L, P272; Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186; Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802; Gu B, 2018, AAAI CONF ARTIF INTE, P3093; Gui LY, 2018, LECT NOTES COMPUT SC, V11212, P441, DOI 10.1007/978-3-030-01237-3_27; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057; Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li HY, 2015, INT CONF SOFTW ENG, P379, DOI 10.1109/ICSESS.2015.7339079; Li Ke, 2016, ARXIV160601885; Li QW, 2017, PR MACH LEARN RES, V70; Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299; Liu RS, 2016, IEEE T PATTERN ANAL, V38, P2457, DOI 10.1109/TPAMI.2016.2522415; Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388; Moreau Thomas, 2016, ARXIV160900285; NESTEROV IE, 1983, DOKL AKAD NAUK SSSR+, V269, P543; Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804; Perrone D, 2014, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2014.372; Schmidt M., 2011, ADV NEURAL INFORM PR, P1458; Schmidt U, 2016, IEEE T PATTERN ANAL, V38, P677, DOI 10.1109/TPAMI.2015.2441053; Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349; Sprechmann P., 2012, P 29 INT C MACH LEAR, P615; Sun LH, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL WORKSHOP ON COMPUTER SCIENCE IN SPORTS, P1; Thrun S., 2012, LEARNING LEARN; Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984; UNSER M, 1991, IEEE T PATTERN ANAL, V13, P272, DOI 10.1109/34.75514; Wang S., 2016, ADV NEURAL INFORM PR, V29, P865; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Yao QM, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3308; Zhang C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3061; Zhang HC, 2013, PROC CVPR IEEE, P1051, DOI 10.1109/CVPR.2013.140; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zhao Y, 2016, INT SYM COMPUT INTEL, P244, DOI [10.1109/ISCID.2016.170, 10.1109/ISCID.2016.2065]; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	54	28	29	2	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2020	42	12					3027	3039		10.1109/TPAMI.2019.2920591	http://dx.doi.org/10.1109/TPAMI.2019.2920591			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OP2KH	31170064	Green Submitted			2022-12-18	WOS:000587912800005
J	Busto, PP; Iqbal, A; Gall, J				Busto, Pau Panareda; Iqbal, Ahsan; Gall, Juergen			Open Set Domain Adaptation for Image and Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Videos; Feature extraction; Image recognition; Training; Task analysis; Face recognition; Protocols; Domain adaptation; open set recognition; action recognition		Since annotating and curating large datasets is very expensive, there is a need to transfer the knowledge from existing annotated datasets to unlabelled data. Data that is relevant for a specific application, however, usually differs from publicly available datasets since it is sampled from a different domain. While domain adaptation methods compensate for such a domain shift, they assume that all categories in the target domain are known and match the categories in the source domain. Since this assumption is violated under real-world conditions, we propose an approach for open set domain adaptation where the target domain contains instances of categories that are not present in the source domain. The proposed approach achieves state-of-the-art results on various datasets for image classification and action recognition. Since the approach can be used for open set and closed set domain adaptation, as well as unsupervised and semi-supervised domain adaptation, it is a versatile tool for many applications.	[Busto, Pau Panareda; Iqbal, Ahsan; Gall, Juergen] Univ Bonn, Comp Vis Grp, D-53113 Bonn, Germany	University of Bonn	Busto, PP (corresponding author), Univ Bonn, Comp Vis Grp, D-53113 Bonn, Germany.	s6papana@uni-bonn.de; iqbalm@iai.uni-bonn.de; gall@iai.uni-bonn.de		Panareda Busto, Pau/0000-0002-2556-2531	ERC Starting Grant ARCA [677650]; DFG [GA 1927/2-2, FOR 1505, GA 1927/4-1, FOR 2535]	ERC Starting Grant ARCA; DFG(German Research Foundation (DFG))	The work has been supported by the ERC Starting Grant ARCA (677650) and the DFG projects GA 1927/2-2 (DFG Research Unit FOR 1505 Mapping on Demand) and GA 1927/4-1 (DFG Research Unit FOR 2535 Anticipating Human Behavior).	Achterberg T, 2009, MATH PROGRAM COMPUT, V1, P1, DOI 10.1007/s12532-008-0001-1; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2012, ABS12120402 CORR; [Anonymous], ABS14123474 CORR; [Anonymous], P BRIT MACH VIS C; [Anonymous], 2017, ABS171006924 CORR; [Anonymous], P ICML WORKSH CHALL; [Anonymous], P BRIT MACH VIS C; Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504; Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100; Bartlett PL, 2008, J MACH LEARN RES, V9, P1823; Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173; Bengio Yoshua, 2013, INT C MACHINE LEARNI, P552; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Blitzer J., P 45 ANN M ASS COMP, P440, DOI DOI 10.1109/IRPS.2011.5784441; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Busto PP, 2017, IEEE I CONF COMP VIS, P754, DOI 10.1109/ICCV.2017.88; Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI [10.1145/1961189.1961199, DOI 10.1145/1961189.1961199]; Csurka G, 2016, LECT NOTES COMPUT SC, V9915, P458, DOI 10.1007/978-3-319-49409-8_37; Donahue J, 2014, PR MACH LEARN RES, V32; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Gavves E, 2015, IEEE I CONF COMP VIS, P2731, DOI 10.1109/ICCV.2015.313; Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36; Ghifary M, 2014, LECT NOTES ARTIF INT, V8862, P898, DOI 10.1007/978-3-319-13560-1_76; Gholami B, 2017, IEEE I CONF COMP VIS, P3601, DOI 10.1109/ICCV.2017.387; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gong Boqing, 2013, P ADV NEUR INF PROC, P1286; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gretton A., 2006, NIPS, P513; Herath S, 2017, PROC CVPR IEEE, P3956, DOI 10.1109/CVPR.2017.421; Hoffman J., 2013, P INT C LEARN REPR; Hoffman J, 2014, INT J COMPUT VISION, V109, P28, DOI 10.1007/s11263-014-0719-3; Hsu TMH, 2015, IEEE I CONF COMP VIS, P4121, DOI 10.1109/ICCV.2015.469; Jain LP, 2014, LECT NOTES COMPUT SC, V8691, P393, DOI 10.1007/978-3-319-10578-9_26; Johnson S.G., 2007, NLOPT NONLINEAR OPTI; KAUFMAN L, 1978, EUR J OPER RES, V2, P207, DOI 10.1016/0377-2217(78)90095-4; Koniusz P, 2017, PROC CVPR IEEE, P7139, DOI 10.1109/CVPR.2017.755; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686, DOI 10.1109/TPAMI.2005.224; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2016, ADV NEUR IN, V29; Lu H, 2017, IEEE I CONF COMP VIS, P599, DOI 10.1109/ICCV.2017.72; Motiian S, 2017, IEEE I CONF COMP VIS, P5716, DOI 10.1109/ICCV.2017.609; Ni J, 2013, PROC CVPR IEEE, P692, DOI 10.1109/CVPR.2013.95; Pan SJ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1187; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Sangineto E, 2014, LECT NOTES COMPUT SC, V8691, P456, DOI 10.1007/978-3-319-10578-9_30; Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Shekhar S, 2013, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2013.53; Sun B, 2014, P BRIT MACH VIS C; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Sun YP, 2015, ADV DIFFER EQU-NY, P1, DOI 10.1186/s13662-015-0433-7; Svanberg K, 2001, SIAM J OPTIMIZ, V12, P555; Tommasi T, 2017, ADV COMPUT VIS PATT, P37, DOI 10.1007/978-3-319-58347-1_2; Tommasi T, 2015, LECT NOTES COMPUT SC, V8927, P18, DOI 10.1007/978-3-319-16199-0_2; Tommasi T, 2013, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2013.116; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; Upchurch P, 2017, PROC CVPR IEEE, P6090, DOI 10.1109/CVPR.2017.645; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Xie CC, 2013, INT CONF COMPUTAT, P222, DOI 10.1109/ICCPS.2013.6893597; Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107; Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547; Zhang R., 2006, P BRIT MACH VIS C, P1209	72	28	29	7	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					413	429		10.1109/TPAMI.2018.2880750	http://dx.doi.org/10.1109/TPAMI.2018.2880750			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	30418898	Green Submitted			2022-12-18	WOS:000508386100013
J	Li, CL; Lin, L; Zuo, WM; Tang, J; Yang, MH				Li, Chenglong; Lin, Liang; Zuo, Wangmeng; Tang, Jin; Yang, Ming-Hsuan			Visual Tracking via Dynamic Graph Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; graph learning; object segmentation; ADMM optimization	OBJECT TRACKING; LOW-RANK; ROBUST	Existing visual tracking methods usually localize a target object with a bounding box, in which the performance of the foreground object trackers or detectors is often affected by the inclusion of background clutter. To handle this problem, we learn a patch-based graph representation for visual tracking. The tracked object is modeled by with a graph by taking a set of non-overlapping image patches as nodes, in which the weight of each node indicates how likely it belongs to the foreground and edges are weighted for indicating the appearance compatibility of two neighboring nodes. This graph is dynamically learned and applied in object tracking and model updating. During the tracking process, the proposed algorithm performs three main steps in each frame. First, the graph is initialized by assigning binary weights of some image patches to indicate the object and background patches according to the predicted bounding box. Second, the graph is optimized to refine the patch weights by using a novel alternating direction method of multipliers. Third, the object feature representation is updated by imposing the weights of patches on the extracted image features. The object location is predicted by maximizing the classification score in the structured support vector machine. Extensive experiments show that the proposed tracking algorithm performs well against the state-of-the-art methods on large-scale benchmark datasets.	[Li, Chenglong; Tang, Jin] Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Anhui, Peoples R China; [Li, Chenglong] Chinese Acad Sci CASIA, Inst Automat, NLPR, Ctr Res Intelligent Percept & Comp CRIPAC, Beijing 100190, Peoples R China; [Li, Chenglong] Anhui Univ, Inst Phys Sci & Informat Technol, Hefei 230601, Anhui, Peoples R China; [Lin, Liang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China; [Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95344 USA	Anhui University; Anhui University; Sun Yat Sen University; Harbin Institute of Technology; University of California System; University of California Merced	Lin, L (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.	lcli314@foxmail.com; linliang@ieee.org; cswmzuo@gmail.com; tangjin@ahu.edu.cn; mhyang@ucmerced.edu	Yang, Ming-Hsuan/AAE-7350-2019; Zuo, Wangmeng/B-3701-2008; Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Liang, Lin/0000-0003-2248-3755; Zuo, Wangmeng/0000-0002-3330-783X	State Key Development Program [2018YFC0830103]; National Natural Science Foundation of China [61702002, 61472002]; Natural Science Foundation of Anhui Province [1808085QF187]; China Postdoctoral Science Foundation; Guangdong Natural Science Foundation Project for Research Teams [2017A030312006]; Open fund for Discipline Construction, Institute of Physical Science and Information Technology, Anhui University	State Key Development Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Anhui Province(Natural Science Foundation of Anhui Province); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Guangdong Natural Science Foundation Project for Research Teams; Open fund for Discipline Construction, Institute of Physical Science and Information Technology, Anhui University	This work is jointly supported by State Key Development Program under Grant 2018YFC0830103, National Natural Science Foundation of China (61702002, 61472002), Natural Science Foundation of Anhui Province (1808085QF187), China Postdoctoral Science Foundation, the Guangdong Natural Science Foundation Project for Research Teams under Grant 2017A030312006, and Open fund for Discipline Construction, Institute of Physical Science and Information Technology, Anhui University.	Adam A., 2006, IEEE C COMP VIS PATT; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; BAO CL, 2012, PROC CVPR IEEE, P1830, DOI DOI 10.1109/CVPR.2012.6247881; Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Danelljan M, 2014, BRIT MACHINE VISION; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308; Elhamifar E, 2009, PROC CVPR IEEE, P2782; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Guo XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3547; Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hogan E, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS: BIG DATA, EMERGENT THREATS, AND DECISION-MAKING IN SECURITY INFORMATICS, P315, DOI 10.1109/ISI.2013.6578850; Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675; Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880; Kim HU, 2017, IEEE T IMAGE PROCESS, V26, P3817, DOI 10.1109/TIP.2017.2706064; Kim HU, 2015, IEEE I CONF COMP VIS, P3011, DOI 10.1109/ICCV.2015.345; Kristan M, 2016, LECT NOTES COMPUT SC, V9914, P777, DOI 10.1007/978-3-319-48881-3_54; Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Li AN, 2016, IEEE T PATTERN ANAL, V38, P335, DOI 10.1109/TPAMI.2015.2417577; Li CL, 2016, IEEE T IMAGE PROCESS, V25, P5743, DOI 10.1109/TIP.2016.2614135; Li CL, 2016, IEEE T IMAGE PROCESS, V25, P1947, DOI 10.1109/TIP.2016.2537211; Li Chenglong, 2017, P 31 AAAI C ART INT; Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632; Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Lin Z., 2009, J MAR BIOL ASSOC UK; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Lukezic A, 2018, IEEE T CYBERNETICS, V48, P1849, DOI 10.1109/TCYB.2017.2716101; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177; Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66; NAM H, 2016, PROC CVPR IEEE, P4293, DOI DOI 10.1109/CVPR.2016.465; Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Shi YR, 2013, ASIA PACIF MICROWAVE, P809, DOI 10.1109/APMC.2013.6694940; Sun C, 2018, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2018.00058; Timofte R, 2016, COMPUT VIS IMAGE UND, V153, P151, DOI 10.1016/j.cviu.2016.02.002; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Xu YY, 2013, SIAM J IMAGING SCI, V6, P1758, DOI 10.1137/120887795; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823; Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13; Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI 10.1109/CVPR.2017.512; Zhang TZ, 2014, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2014.164; Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882; Zhuang LS, 2012, PROC CVPR IEEE, P2328, DOI 10.1109/CVPR.2012.6247944	57	28	28	3	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2770	2782		10.1109/TPAMI.2018.2864965	http://dx.doi.org/10.1109/TPAMI.2018.2864965			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30106707	Green Submitted			2022-12-18	WOS:000489838200015
J	Asif, U; Bennamoun, M; Sohel, FA				Asif, Umar; Bennamoun, Mohammed; Sohel, Ferdous A.			A Multi-Modal, Discriminative and Spatially Invariant CNN for RGB-D Object Labeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RGB-D object recognition; 3D scene labeling; semantic segmentation	RECOGNITION; SCENE	While deep convolutional neural networks have shown a remarkable success in image classification, the problems of inter-class similarities, intra-class variances, the effective combination of multi-modal data, and the spatial variability in images of objects remain to be major challenges. To address these problems, this paper proposes a novel framework to learn a discriminative and spatially invariant classification model for object and indoor scene recognition using multi-modal RGB-D imagery. This is achieved through three postulates: 1) spatial invariance-this is achieved by combining a spatial transformer network with a deep convolutional neural network to learn features which are invariant to spatial translations, rotations, and scale changes, 2) high discriminative capability-this is achieved by introducing Fisher encoding within the CNN architecture to learn features which have small inter-class similarities and large intra-class compactness, and 3) multi-modal hierarchical fusion-this is achieved through the regularization of semantic segmentation to a multi-modal CNN architecture, where class probabilities are estimated at different hierarchical levels (i.e., image- and pixel-levels), and fused into a Conditional Random Field (CRF)-based inference hypothesis, the optimization of which produces consistent class labels in RGB-D images. Extensive experimental evaluations on RGB-D object and scene datasets, and live video streams (acquired from Kinect) show that our framework produces superior object and scene classification results compared to the state-of-the-art methods.	[Asif, Umar] IBM Res, Melbourne, Vic 3053, Australia; [Bennamoun, Mohammed] Univ Western Australia, Crawley, WA 6009, Australia; [Sohel, Ferdous A.] Murdoch Univ, Murdoch, WA 6150, Australia	University of Western Australia; Murdoch University	Asif, U (corresponding author), IBM Res, Melbourne, Vic 3053, Australia.	umarasif@au1.ibm.com; mohammed.bennamoun@uwa.edu.au; f.sohel@murdoch.edu.au	Bennamoun, Mohammed/C-2789-2013; Sohel, Ferdous/C-2428-2013	Bennamoun, Mohammed/0000-0002-6603-3257; Sohel, Ferdous/0000-0003-1557-4907; Asif, Umar/0000-0001-5209-7084	Australian Research Council [DP150100294, DE120102960]	Australian Research Council(Australian Research Council)	The authors are grateful to NVIDIA for providing a TitanX GPU to conduct this research. This work was supported by Australian Research Council grants (DP150100294, DE120102960).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Asif U, 2017, IEEE T ROBOT, V33, P547, DOI 10.1109/TRO.2016.2638453; Asif U, 2016, IEEE INT CONF ROBOT, P2255, DOI 10.1109/ICRA.2016.7487374; Asif U, 2016, AUTON ROBOT, V40, P805, DOI 10.1007/s10514-015-9495-3; Asif U, 2015, IEEE INT C INT ROBOT, P272, DOI 10.1109/IROS.2015.7353385; Asif U, 2015, IEEE INT CONF ROBOT, P1295, DOI 10.1109/ICRA.2015.7139358; Asif U, 2014, IEEE INT C INT ROBOT, P4914, DOI 10.1109/IROS.2014.6943261; Asif U, 2014, LECT NOTES COMPUT SC, V8693, P659, DOI 10.1007/978-3-319-10602-1_43; Badrinarayanan V., 2017, IEEE T PATTERN ANAL; Blum M, 2012, IEEE INT CONF ROBOT, P1298, DOI 10.1109/ICRA.2012.6225188; Bo L., 2013, EXPT ROBOTICS, P387, DOI DOI 10.1007/978-3-319-00065-7; Bo L., P ADV NEUR INF PROC, P2115; Bo LF, 2011, IEEE INT C INT ROBOT, P821, DOI 10.1109/IROS.2011.6048717; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chen LC., ARXIV 2015ABS1412706; Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461; Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446; Gupta S, 2015, INT J COMPUT VISION, V112, P133, DOI 10.1007/s11263-014-0777-6; Janoch A., 2013, CONSUMER DEPTH CAMER, P141, DOI DOI 10.1007/978-1-4471-4640-7_8; Kavukcuoglu K, 2015, ADV NEURAL INF PROCE, P2017; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lai K, 2014, IEEE INT CONF ROBOT, P3050, DOI 10.1109/ICRA.2014.6907298; Lai KV, 2012, IEEE INT CONF ROBOT, P1330, DOI 10.1109/ICRA.2012.6225316; Lai K, 2011, IEEE INT CONF ROBOT, P1817; Liao YY, 2016, IEEE INT CONF ROBOT, P2318, DOI 10.1109/ICRA.2016.7487381; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Nair V., 2010, ICML, P807; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280; Schwarz M, 2015, IEEE INT CONF ROBOT, P1329, DOI 10.1109/ICRA.2015.7139363; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Socher R., 2012, ADV NEURAL INF PROCE, P665, DOI DOI 10.1002/2014GB005021; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Vedaldi A., 2015, ACM INT C MULT; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Wang Y, 2014, LECT NOTES COMPUT SC, V8689, P489, DOI 10.1007/978-3-319-10590-1_32; Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458; Zhou B., 2017, IEEE T PATTERN ANAL; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhu HY, 2016, PROC CVPR IEEE, P2969, DOI 10.1109/CVPR.2016.324	45	28	30	2	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2051	2065		10.1109/TPAMI.2017.2747134	http://dx.doi.org/10.1109/TPAMI.2017.2747134			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28866483				2022-12-18	WOS:000440868400002
J	Gadde, R; Jampani, V; Marlet, R; Gehler, PV				Gadde, Raghudeep; Jampani, Varun; Marlet, Renaud; Gehler, Peter V.			Efficient 2D and 3D Facade Segmentation Using Auto-Context	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Auto-Context; facade segmentation; semantic segmentation; stacked generalization		This paper introduces a fast and efficient segmentation technique for 2D images and 3D point clouds of building facades. Facades of buildings are highly structured and consequently most methods that have been proposed for this problem aim to make use of this strong prior information. Contrary to most prior work, we are describing a system that is almost domain independent and consists of standard segmentation methods. We train a sequence of boosted decision trees using auto-context features. This is learned using stacked generalization. We find that this technique performs better, or comparable with all previous published methods and present empirical results on all available 2D and 3D facade benchmark datasets. The proposed method is simple to implement, easy to extend, and very efficient at test-time inference.	[Gadde, Raghudeep; Marlet, Renaud] UPE, Ecole Ponts, LIGM, UMR 8049, Champs Sur Marne, Gaspard Monge, France; [Jampani, Varun] MPI IS, Heisenbergstr, D-70569 Stuttgart, Germany; [Gehler, Peter V.] Univ Wurzburg, Univ Tubingen, MPI IS, BCCN, Geschwister Scholl Pl, D-72074 Tubingen, Germany	Universite Gustave-Eiffel; ESIEE Paris; Centre National de la Recherche Scientifique (CNRS); Ecole des Ponts ParisTech; Eberhard Karls University of Tubingen; University of Wurzburg	Gadde, R (corresponding author), UPE, Ecole Ponts, LIGM, UMR 8049, Champs Sur Marne, Gaspard Monge, France.	raghudeep.gadde@enpc.fr; varun.jampani@tuebingen.mpg.de; renaud.marlet@enpc.fr; peter.gehler@uni-wuerzburg.de	Jain, Varun/HHN-1250-2022		project Semapolis [ANR-13-CORD-0003]; ECP; Max Planck ETH Center for Learning Systems	project Semapolis; ECP; Max Planck ETH Center for Learning Systems	This work was partly carried out in IMAGINE, a joint ENPC-CSTB project, and partly supported by project Semapolis ANR-13-CORD-0003, ECP and Max Planck ETH Center for Learning Systems. R. Gadde and V. Jampani contributed equally to this work.	Cohen A, 2014, PROC CVPR IEEE, P3206, DOI 10.1109/CVPR.2014.410; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P., 2014, PIOTRS COMPUTER VISI; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Frohlich Bjorn, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3029, DOI 10.1109/ICPR.2010.742; Frohlich B., 2012, 11 AS C COMP VIS DAE, P218; Gadde R, 2016, INT J COMPUT VISION, V117, P290, DOI 10.1007/s11263-016-0887-4; Gatta C, 2014, IEEE T PATTERN ANAL, V36, P1694, DOI 10.1109/TPAMI.2013.2297706; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Gould S, 2012, J MACH LEARN RES, V13, P3533; Jampani V, 2015, IEEE WINT CONF APPL, P1038, DOI 10.1109/WACV.2015.143; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Korc F., 2009, TRIGGP200901; KOZINSKI M, 2014, IEEE WINTER C APPL C, P729; Kozinski M., 2014, P AS C COMP VIS, P79; Kozinski M, 2015, PROC CVPR IEEE, P2820, DOI 10.1109/CVPR.2015.7298899; Ladicky L, 2010, LECT NOTES COMPUT SC, V6314, P424, DOI 10.1007/978-3-642-15561-1_31; Martinovic A, 2015, PROC CVPR IEEE, P4456, DOI 10.1109/CVPR.2015.7299075; Martinovic A, 2013, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2013.33; Martinovic A, 2012, LECT NOTES COMPUT SC, V7578, P416, DOI 10.1007/978-3-642-33786-4_31; Mathias M, 2016, INT J COMPUT VISION, V118, P22, DOI 10.1007/s11263-015-0868-z; Nowozin S, 2014, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2014.77; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ok D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P128, DOI 10.1109/3DIMPVT.2012.25; Riemenschneider H, 2014, LECT NOTES COMPUT SC, V8693, P516, DOI 10.1007/978-3-319-10602-1_34; Riemenschneider H, 2012, PROC CVPR IEEE, P1640, DOI 10.1109/CVPR.2012.6247857; Ripperda N, 2006, LECT NOTES COMPUT SC, V4174, P750; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Teboul O., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2273, DOI 10.1109/CVPR.2011.5995319; Teboul O., 2010, ECOLE CENTRALE PARIS; Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26; Tu Z., 2008, IEEE C COMP VIS PATT, P1; Tylecek R, 2013, LECT NOTES COMPUT SC, V8142, P364, DOI 10.1007/978-3-642-40602-7_39; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yang MY, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130243	37	28	28	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1273	1280		10.1109/TPAMI.2017.2696526	http://dx.doi.org/10.1109/TPAMI.2017.2696526			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28436846	Green Submitted			2022-12-18	WOS:000428901200019
J	Merveille, O; Talbot, H; Najman, L; Passat, N				Merveille, Odyssee; Talbot, Hugues; Najman, Laurent; Passat, Nicolas			Curvilinear Structure Analysis by Ranking the Orientation Responses of Path Operators	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Thin structures; non-linear filtering; direction estimation; mathematical morphology; path opening; 3D grey-level imaging; curvilinear structure	VESSEL ENHANCEMENT; MATHEMATICAL MORPHOLOGY; COMPUTED-TOMOGRAPHY; SEGMENTATION; OPENINGS; FILTER; IMPLEMENTATION; CONNECTIVITY; DIFFUSION; IMAGE	The analysis of thin curvilinear objects in 3D images is a complex and challenging task. In this article, we introduce a new, non-linear operator, called RORPO (Ranking the Orientation Responses of Path Operators). Inspired by the multidirectional paradigm currently used in linear filtering for thin structure analysis, RORPO is built upon the notion of path operator from mathematical morphology. This operator, unlike most operators commonly used for 3D curvilinear structure analysis, is discrete, non-linear and non-local. From this new operator, two main curvilinear structure characteristics can be estimated: an intensity feature, that can be assimilated to a quantitative measure of curvilinearity; and a directional feature, providing a quantitative measure of the structure's orientation. We provide a full description of the structural and algorithmic details for computing these two features from RORPO, and we discuss computational issues. We experimentally assess RORPO by comparison with three of the most popular curvilinear structure analysis filters, namely Frangi Vesselness, Optimally Oriented Flux, and Hybrid Diffusion with Continuous Switch. In particular, we show that our method provides up to 8 percent more true positive and 50 percent less false positives than the next best method, on synthetic and real 3D images.	[Merveille, Odyssee; Talbot, Hugues; Najman, Laurent] Univ Paris Est, LIGM UMR 8049, CNRS, ENPC,ESIEE Paris,UPEM, F-93162 Noisy Le Grand, France; [Merveille, Odyssee; Passat, Nicolas] Univ Reims, CReSTIC, F-51100 Reims, France	Centre National de la Recherche Scientifique (CNRS); Ecole des Ponts ParisTech; Universite Gustave-Eiffel; ESIEE Paris; Universite de Reims Champagne-Ardenne	Merveille, O (corresponding author), Univ Paris Est, LIGM UMR 8049, CNRS, ENPC,ESIEE Paris,UPEM, F-93162 Noisy Le Grand, France.; Merveille, O (corresponding author), Univ Reims, CReSTIC, F-51100 Reims, France.	odyssee.merveille@esiee.fr; hugues.talbot@esiee.fr; laurent.najman@esiee.fr; nicolas.passat@univ-reims.fr	Najman, Laurent/AAB-4212-2020; Merveille, Odyssée/X-9031-2019	Najman, Laurent/0000-0002-6190-0235; Merveille, Odyssée/0000-0002-9918-3761	French Agence Nationale de la Recherche [ANR-12-MONU-0010]	French Agence Nationale de la Recherche(French National Research Agency (ANR))	This work was funded with French Agence Nationale de la Recherche grant agreement ANR-12-MONU-0010 (VIVA-BRAIN Project: http://vivabrain.fr). The CTA and ground-truth for our real-data experiments were provided by Heart-Flow (http://www.heartflow.com).	Bauer C, 2008, LECT NOTES COMPUT SC, V5096, P163, DOI 10.1007/978-3-540-69321-5_17; Bennink HE, 2007, LECT NOTES COMPUT SC, V4792, P436; Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433; Bismuth V, 2012, LECT NOTES COMPUT SC, V7511, P9, DOI 10.1007/978-3-642-33418-4_2; Bouraoui B, 2010, COMPUT MED IMAG GRAP, V34, P377, DOI 10.1016/j.compmedimag.2010.01.001; Buckley M, 2000, COMP IMAG VIS, V18, P109; Caldairou B, 2009, LECT NOTES COMPUT SC, V5720, P171, DOI 10.1007/978-3-642-03613-2_16; Chapman BE, 2005, MED IMAGE ANAL, V9, P191, DOI 10.1016/j.media.2004.08.001; Cohen Laurent D., 2007, Computer Methods in Biomechanics and Biomedical Engineering, V10, P289, DOI 10.1080/10255840701328239; Cokelaer F, 2012, IEEE J-STSP, V6, P830, DOI 10.1109/JSTSP.2012.2213578; Danielsson PE, 2001, J VIS COMMUN IMAGE R, V12, P255, DOI 10.1006/jvci.2000.0472; Derpanis K. G., 2005, P IEEE INT C IM PROC, V3, P553; Dokladal P, 2009, LECT NOTES COMPUT SC, V5720, P126, DOI 10.1007/978-3-642-03613-2_12; DU YPP, 1995, JMRI-J MAGN RESON IM, V5, P353, DOI 10.1002/jmri.1880050321; Dufour A, 2013, MED IMAGE ANAL, V17, P147, DOI 10.1016/j.media.2012.08.004; Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gonzalez G, 2009, LECT NOTES COMPUT SC, V5762, P625, DOI 10.1007/978-3-642-04271-3_76; Hamarneh G, 2010, COMPUT MED IMAG GRAP, V34, P605, DOI 10.1016/j.compmedimag.2010.06.002; Heijmans H, 2005, J MATH IMAGING VIS, V22, P107, DOI 10.1007/s10851-005-4885-3; Hendriks CLL, 2010, IEEE T IMAGE PROCESS, V19, P1587, DOI 10.1109/TIP.2010.2044959; KOLLER TM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P864, DOI 10.1109/ICCV.1995.466846; Krause M, 2010, J MATER SCI, V45, P888, DOI 10.1007/s10853-009-4016-4; Krissian K, 2000, COMPUT VIS IMAGE UND, V80, P130, DOI 10.1006/cviu.2000.0866; Law MWK, 2008, LECT NOTES COMPUT SC, V5305, P368, DOI 10.1007/978-3-540-88693-8_27; Lesage D, 2009, MED IMAGE ANAL, V13, P819, DOI 10.1016/j.media.2009.07.011; Lorenz C, 1997, LECT NOTES COMPUT SC, V1205, P233, DOI 10.1007/BFb0029242; Manniesing R, 2006, MED IMAGE ANAL, V10, P815, DOI 10.1016/j.media.2006.06.003; Mendrik AM, 2009, IEEE T MED IMAGING, V28, P1585, DOI 10.1109/TMI.2009.2022368; Merveille O., 2016, THESIS; Merveille O, 2016, IEEE IMAGE PROC, P4324, DOI 10.1109/ICIP.2016.7533176; Merveille O, 2015, LECT NOTES COMPUT SC, V9082, P633, DOI 10.1007/978-3-319-18720-4_53; Merveille O, 2014, LECT NOTES COMPUT SC, V8690, P203, DOI 10.1007/978-3-319-10605-2_14; Morard V, 2014, IEEE T IMAGE PROCESS, V23, P1543, DOI 10.1109/TIP.2014.2303647; Morard V, 2013, J MATH IMAGING VIS, V46, P128, DOI 10.1007/s10851-012-0374-7; Moreno R, 2015, MED IMAGE ANAL, V26, P19, DOI 10.1016/j.media.2015.07.001; Naegel B, 2007, PATTERN RECOGN, V40, P648, DOI 10.1016/j.patcog.2006.06.011; Najman L, 2010, MATH MORPHOLOGY THEO; Orkisz M., 2000, Machine Graphics & Vision, V9, P463; Ouzounis GK, 2007, IEEE T PATTERN ANAL, V29, P990, DOI 10.1109/TPAMI.2007.1045; Passat N, 2006, MED IMAGE ANAL, V10, P259, DOI 10.1016/j.media.2005.11.002; Perret B, 2015, IEEE T PATTERN ANAL, V37, P1162, DOI 10.1109/TPAMI.2014.2366145; Rouchdy Y, 2013, COMPUT VIS IMAGE UND, V117, P1453, DOI 10.1016/j.cviu.2013.06.001; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; Sato Y, 1997, LECT NOTES COMPUT SC, V1205, P213, DOI 10.1007/BFb0029240; Schaap M, 2009, MED IMAGE ANAL, V13, P701, DOI 10.1016/j.media.2009.06.003; Soille P, 2001, IEEE T PATTERN ANAL, V23, P1313, DOI 10.1109/34.969120; Soille P, 1996, IEEE T PATTERN ANAL, V18, P562, DOI 10.1109/34.494646; Stawiaski J, 2011, LECT NOTES COMPUT SC, V6671, P417, DOI 10.1007/978-3-642-21569-8_36; Talbot H., 2013, THESIS; Talbot H, 2007, IMAGE VISION COMPUT, V25, P416, DOI 10.1016/j.imavis.2006.07.021; Tankyevych O, 2009, LECT NOTES COMPUT SC, V5720, P137, DOI 10.1007/978-3-642-03613-2_13; Tankyevych O, 2008, I S BIOMED IMAGING, P1011, DOI 10.1109/ISBI.2008.4541170; Taylor CA, 2013, J AM COLL CARDIOL, V61, P2233, DOI 10.1016/j.jacc.2012.11.083; THACKRAY BD, 1993, IEEE T MED IMAGING, V12, P385, DOI 10.1109/42.241865; Vincent L, 1998, COMP IMAG VIS, V12, P331; Weickert J., 1998, TEUBNER STUTTGART, V1; Wilkinson M.H.F., 2001, P 4 INT C MED IM COM, V2208, P770, DOI DOI 10.1007/3-540-45468-3_92; Wilkinson MHF, 2009, LECT NOTES COMPUT SC, V5720, P47, DOI 10.1007/978-3-642-03613-2_5; Xiao CY, 2013, IEEE T IMAGE PROCESS, V22, P174, DOI 10.1109/TIP.2012.2216277; Xiao CY, 2011, MED IMAGE ANAL, V15, P112, DOI 10.1016/j.media.2010.08.003; Yongchao Xu, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P390, DOI 10.1007/978-3-642-38294-9_33; Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095	63	28	28	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					304	317		10.1109/TPAMI.2017.2672972	http://dx.doi.org/10.1109/TPAMI.2017.2672972			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28237921	Green Submitted			2022-12-18	WOS:000422706000004
J	Straub, J; Freifeld, O; Rosman, G; Leonard, JJ; Fisher, JW				Straub, Julian; Freifeld, Oren; Rosman, Guy; Leonard, John J.; Fisher, John W., III			The Manhattan Frame Model-Manhattan World Inference in the Space of Surface Normals	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manhattan world; Manhattan frame; mixture of Manhattan frames; world representation; surface normal distribution; bayesian models	VANISHING POINT DETECTION; BAYESIAN-ANALYSIS	Objects and structures within man-made environments typically exhibit a high degree of organization in the form of orthogonal and parallel planes. Traditional approaches utilize these regularities via the restrictive, and rather local, Manhattan World (MW) assumption which posits that every plane is perpendicular to one of the axes of a single coordinate system. The aforementioned regularities are especially evident in the surface normal distribution of a scene where they manifest as orthogonally-coupled clusters. This motivates the introduction of the Manhattan-Frame (MF) model which captures the notion of an MW in the surface normals space, the unit sphere, and two probabilistic MF models over this space. First, for a single MF we propose novel real-time MAP inference algorithms, evaluate their performance and their use in drift-free rotation estimation. Second, to capture the complexity of real-world scenes at a global scale, we extend the MF model to a probabilistic mixture of Manhattan Frames (MMF). For MMF inference we propose a simple MAP inference algorithm and an adaptive Markov-Chain Monte-Carlo sampling algorithm with Metropolis-Hastings split/merge moves that let us infer the unknown number of mixture components. We demonstrate the versatility of the MMF model and inference algorithm across several scales of man-made environments.	[Straub, Julian; Rosman, Guy; Fisher, John W., III] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA; [Freifeld, Oren] Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel; [Leonard, John J.] MIT, Dept Mech Engn, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Ben Gurion University; Massachusetts Institute of Technology (MIT)	Straub, J (corresponding author), MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.	jstraub@csail.mit.edu; orenfr@cs.bgu.ac.il; rosman@csail.mit.edu; jleonard@mit.edu; fisher@csail.mit.edu		Freifeld, Oren/0000-0001-9816-9709; /0000-0003-2339-1262	ONR MURI program [N00014-11-1-0688]; DARPA [FA8650-11-1-7154]; MIT-Technion Postdoctoral Fellowship	ONR MURI program(MURI); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); MIT-Technion Postdoctoral Fellowship	We thank J. Chang for his help with the split/merge proposals, R. Cabezas for his help with the Cambridge dataset, T. Whelan for giving access to Kintinuous and R. Finman for helping to scan indoor environments. J.S., O.F., J.L. and J.F. were partially supported by the ONR MURI program, award N00014-11-1-0688. J.S., O.F. and J.F. were also partially supported by the DARPA, award FA8650-11-1-7154. G.R. was partially funded by a MIT-Technion Postdoctoral Fellowship.	Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Altmann S. L., 2005, ROTATIONS QUATERNION; [Anonymous], 2009, DIRECTIONAL STAT; [Anonymous], [No title captured]; Antone ME, 2000, PROC CVPR IEEE, P282, DOI 10.1109/CVPR.2000.854809; Antunes M, 2013, PROC CVPR IEEE, P1336, DOI 10.1109/CVPR.2013.176; Bangert M., 2010, 2010 Ninth International Conference on Machine Learning and Applications (ICMLA 2010), P746, DOI 10.1109/ICMLA.2010.114; Barinova O, 2010, LECT NOTES COMPUT SC, V6312, P57, DOI 10.1007/978-3-642-15552-9_5; BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; Bazin JC, 2012, IEEE INT C INT ROBOT, P4282, DOI 10.1109/IROS.2012.6385802; BINGHAM C, 1974, ANN STAT, V2, P1201, DOI 10.1214/aos/1176342874; Bosse M, 2003, VISUAL COMPUT, V19, P417, DOI 10.1007/s00371-003-0205-3; Botsch Mario, 2010, POLYGON MESH PROCESS, P3; Boumal N, 2014, INF INFERENCE, V3, P1, DOI 10.1093/imaiai/iat006; Cabezas R, 2015, IEEE I CONF COMP VIS, P2156, DOI 10.1109/ICCV.2015.249; CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; Chang J., 2013, P NIPS, P620; Chirikjian G., 2011, STOCHASTIC MODELS IN; Cipolla R., 1999, P BRIT MACH VIS C; Collins R. T., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P400, DOI 10.1109/ICCV.1990.139560; Coughlan J.M., 1999, P ICCV, V2, P941, DOI DOI 10.1109/ICCV.1999.790349; Delage E, 2007, SPRINGER TRAC ADV RO, V28, P305; Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15; do Carmo M. P., 1992, RIEMANNIAN GEOMETRY; Eade E., 2008, THESIS; Fisher N.I., 1995, STAT ANAL CIRCULAR D, DOI DOI 10.1017/CBO9780511564345; Fleishman S, 2005, ACM T GRAPHIC, V24, P544, DOI 10.1145/1073204.1073227; Flint A, 2011, IEEE I CONF COMP VIS, P2228, DOI 10.1109/ICCV.2011.6126501; Furukawa Y, 2009, IEEE I CONF COMP VIS, P80, DOI 10.1109/ICCV.2009.5459145; Gallier J., 2001, TEXTS APPL MATH GEOM, V38, P367, DOI [10.1007/978-1-4613-0137-0_14, DOI 10.1007/978-1-4613-0137-0_14]; Gelman A., 2013, TEXTS STAT SCI SERIE, Vthird, DOI 10.1201/b16018; Ghanem B, 2015, PROC CVPR IEEE, P3772, DOI 10.1109/CVPR.2015.7299001; Gopal S, 2014, PR MACH LEARN RES, V32; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Hartley R., 2004, ROBOTICA; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411; Holz D., 2011, ROBOT SOCCER WORLD C, P306; Horn B. K., 2013, J OPT SOC AM A, V4, P629; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P121, DOI 10.1109/IM.1997.603857; Joo K, 2016, PROC CVPR IEEE, P1763, DOI 10.1109/CVPR.2016.195; Kazhdan Michael, 2005, P 3 EUR S GEOM PROC, P73; KENT JT, 1982, J ROY STAT SOC B MET, V44, P71; KHATRI CG, 1977, J ROY STAT SOC B MET, V39, P95; Kosecka J, 2002, LECT NOTES COMPUT SC, V2353, P476; Kroeger T, 2015, PROC CVPR IEEE, P2449, DOI 10.1109/CVPR.2015.7298859; Lee DC, 2009, PROC CVPR IEEE, P2136, DOI 10.1109/CVPRW.2009.5206872; Leonard J. J., 1991, Proceedings IROS '91. IEEE/RSJ International Workshop on Intelligent Robots and Systems '91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711; Lezama J, 2014, PROC CVPR IEEE, P509, DOI 10.1109/CVPR.2014.72; Liu CX, 2015, PROC CVPR IEEE, P3413, DOI 10.1109/CVPR.2015.7298963; LUTTON E, 1994, IEEE T PATTERN ANAL, V16, P430, DOI 10.1109/34.277598; Mitra NJ, 2004, INT J COMPUT GEOM AP, V14, P261, DOI 10.1142/S0218195904001470; Moghadam P, 2012, IEEE INT C INT ROBOT, P1553, DOI 10.1109/IROS.2012.6386089; MONSZPART A., 2015, ACM T GRAPHIC, V34, P103; Neverova N, 2013, LECT NOTES COMPUT SC, V7786, P281, DOI 10.1007/978-3-642-36700-7_22; Nunez- Antonio G, 2005, COMMUN STAT-SIMUL C, V34, P989, DOI 10.1080/03610910500308495; Peasley B, 2012, IEEE INT C INT ROBOT, P5283, DOI 10.1109/IROS.2012.6386157; Pennec X, 1999, PROCEEDINGS OF THE IEEE-EURASIP WORKSHOP ON NONLINEAR SIGNAL AND IMAGE PROCESSING (NSIP'99), P194; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; Rodrigues O, 1840, LOIS GEOMETRIQUES QU; Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9; Saurer O., 2012, P IEEE IROS WORKSH V; Schindler G, 2004, PROC CVPR IEEE, P203; SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Straub J, 2015, JMLR WORKSH CONF PRO, V38, P930; Straub J, 2015, IEEE INT C INT ROBOT, P1913, DOI 10.1109/IROS.2015.7353628; Straub J, 2015, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2015.7298630; Straub J, 2014, PROC CVPR IEEE, P3770, DOI 10.1109/CVPR.2014.488; Tardif JP, 2009, IEEE I CONF COMP VIS, P1250, DOI 10.1109/ICCV.2009.5459328; Triebel R., 2005, P IEEE INT C ROB AUT, P4437; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; Whelan T., 2015, P RSS WORKSH RGB D A, V35, P1697; Wildenauer H, 2012, PROC CVPR IEEE, P2831, DOI 10.1109/CVPR.2012.6248008; Xu YL, 2013, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR.2013.181	77	28	28	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					235	249		10.1109/TPAMI.2017.2662686	http://dx.doi.org/10.1109/TPAMI.2017.2662686			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28166490	Green Published			2022-12-18	WOS:000417806000018
J	Cevikalp, H				Cevikalp, Hakan			Best Fitting Hyperplanes for Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Best fitting hyperlane classifier; open set recognition; large margin classifier; kernel methods; support vector machines	SUPPORT VECTOR MACHINE	In this paper, we propose novel methods that are more suitable than classical large-margin classifiers for open set recognition and object detection tasks. The proposed methods use the best fitting hyperplanes approach, and the main idea is to find the best fitting hyperplanes such that each hyperplane is close to the samples of one of the classes and is as far as possible from the other class samples. To this end, we propose two different classifiers: The first classifier solves a convex quadratic optimization problem, but negative samples can lie on one side of the best fitting hyperplane. The second classifier, however, allows the negative samples to lie on both sides of the fitting hyperplane by using concave-convex procedure. Both methods are extended to the nonlinear case by using the kernel trick. In contrast to the existing hyperplane fitting classifiers in the literature, our proposed methods are suitable for large-scale problems, and they return sparse solutions. The experiments on several databases show that the proposed methods typically outperform other hyperplane fitting classifiers, and they work as good as the SVM classifier in classical recognition tasks. However, the proposed methods significantly outperform SVM in open set recognition and object detection tasks.	[Cevikalp, Hakan] Eskisehir Osmangazi Univ, Lab Machine Learning & Comp Vis, Dept Elect & Elect Engn, TR-26480 Eskisehir, Turkey	Eskisehir Osmangazi University	Cevikalp, H (corresponding author), Eskisehir Osmangazi Univ, Lab Machine Learning & Comp Vis, Dept Elect & Elect Engn, TR-26480 Eskisehir, Turkey.	hakan.cevikalp@gmail.com	Cevikalp, Hakan/R-1300-2016	Cevikalp, Hakan/0000-0002-1708-8817	Scientific and Technological Research Council of Turkey (TUBITAK) [EEEAG-109E279]	Scientific and Technological Research Council of Turkey (TUBITAK)(Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK))	This work was funded by the Scientific and Technological Research Council of Turkey (TUBITAK) under Grant number EEEAG-109E279.	[Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Cevikalp H, 2004, INT C PATT RECOG, P326, DOI 10.1109/ICPR.2004.1334118; Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9; Cevikalp H., 2013, 2013 10 IEEE INT C W, P1; Cevikalp H, 2007, IEEE T SYST MAN CY B, V37, P937, DOI 10.1109/TSMCB.2007.896011; Cevikalp H, 2006, IEEE T NEURAL NETWOR, V17, P1550, DOI 10.1109/TNN.2006.881485; Cevikalp H, 2013, PATTERN RECOGN, V46, P1523, DOI 10.1016/j.patcog.2012.11.004; Cevikalp H, 2012, PROC CVPR IEEE, P3138, DOI 10.1109/CVPR.2012.6248047; Cevikalp H, 2010, NEUROCOMPUTING, V73, P3160, DOI 10.1016/j.neucom.2010.06.018; Collobert R., 2006, P 23 INT C MACHINE L, P201, DOI DOI 10.1145/1143844.1143870.; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng Z, 2007, INT JOINT C NEUR NET, P2385; Ertekin S, 2011, IEEE T PATTERN ANAL, V33, P368, DOI 10.1109/TPAMI.2010.109; Fan RE, 2005, J MACH LEARN RES, V6, P1889; Fox J, 2002, ROBUST REGRESSION AP; Fung G., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P77, DOI 10.1145/502512.502527; Gao SB, 2011, NEUROCOMPUTING, V74, P3590, DOI 10.1016/j.neucom.2011.06.015; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Gulmezoglu MB, 2001, IEEE T SPEECH AUDI P, V9, P655, DOI 10.1109/89.943343; Jain V.., 2010, FDDB BENCHMARK FACE; Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068; Jia Y., P ACM MULT, P675; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Kalal Z., 2008, P BRIT MACH VIS C, P421; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar MA, 2008, PATTERN RECOGN LETT, V29, P1842, DOI 10.1016/j.patrec.2008.05.016; Kumar MA, 2009, EXPERT SYST APPL, V36, P7535, DOI 10.1016/j.eswa.2008.09.066; Lanckriet G. R. G., 2003, Journal of Machine Learning Research, V3, P555, DOI 10.1162/153244303321897726; Mangasarian OL, 2006, IEEE T PATTERN ANAL, V28, P69, DOI 10.1109/TPAMI.2006.17; Peng XJ, 2011, PATTERN RECOGN, V44, P2678, DOI 10.1016/j.patcog.2011.03.031; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Shao YH, 2011, IEEE T NEURAL NETWOR, V22, P962, DOI 10.1109/TNN.2011.2130540; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Yuille AL, 2002, ADV NEUR IN, V14, P1033	40	28	31	2	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1076	1088		10.1109/TPAMI.2016.2587647	http://dx.doi.org/10.1109/TPAMI.2016.2587647			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27392344				2022-12-18	WOS:000401091200003
J	Liu, RS; Zhong, GY; Cao, JJ; Lin, ZC; Shan, SG; Luo, ZX				Liu, Risheng; Zhong, Guangyu; Cao, Junjie; Lin, Zhouchen; Shan, Shiguang; Luo, Zhongxuan			Learning to Diffuse: A New Perspective to Design PDEs for Visual Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual diffusion; PDE governed combinatorial optimization; submodularity; saliency detection; object tracking	SALIENCY; TRACKING; MODEL	Partial differential equations (PDEs) have been used to formulate image processing for several decades. Generally, a PDE system consists of two components: the governing equation and the boundary condition. In most previous work, both of them are generally designed by people using mathematical skills. However, in real world visual analysis tasks, such predefined and fixed-form PDEs may not be able to describe the complex structure of the visual data. More importantly, it is hard to incorporate the labeling information and the discriminative distribution priors into these PDEs. To address above issues, we propose a new PDE framework, named learning to diffuse (LTD), to adaptively design the governing equation and the boundary condition of a diffusion PDE system for various vision tasks on different types of visual data. To our best knowledge, the problems considered in this paper (i.e., saliency detection and object tracking) have never been addressed by PDE models before. Experimental results on various challenging benchmark databases show the superiority of LTD against existing state-of-the-art methods for all the tested visual analysis tasks.	[Liu, Risheng; Luo, Zhongxuan] Dalian Univ Technol, Sch Software Technol, Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian, Peoples R China; [Zhong, Guangyu; Cao, Junjie] Dalian Univ Technol, Sch Math Sci, Dalian, Peoples R China; [Lin, Zhouchen] Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing, Peoples R China; [Lin, Zhouchen] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai, Peoples R China; [Shan, Shiguang] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing, Peoples R China	Dalian University of Technology; Dalian University of Technology; Peking University; Shanghai Jiao Tong University; Chinese Academy of Sciences; Institute of Computing Technology, CAS	Liu, RS (corresponding author), Dalian Univ Technol, Sch Software Technol, Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian, Peoples R China.	rsliu@dlut.edu.cn; guangyuzhonghikari@gmail.com; jjcao1231@gmail.com; zlin@pku.edu.cn; sgshan@ict.ac.cn; zxluo@dlut.edu.cn		Shan, Shiguang/0000-0002-8348-392X	National Natural Science Foundation of China (NSFC) [61300086, 61432003]; Fundamental Research Funds for the Central Universities [DUT15QY15]; Hong Kong Scholar Program [XJ2015008]; China Scholarship Council; NSFC [61363048, 61272341, 61231002, 61222211]; National Basic Research Program of China (973 Program) [2015CB352502]; Microsoft Research Asia Collaborative Research Program	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Hong Kong Scholar Program; China Scholarship Council(China Scholarship Council); NSFC(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China); Microsoft Research Asia Collaborative Research Program(Microsoft)	The authors thank all reviewers for their helpful comments. R. Liu is supported by National Natural Science Foundation of China (NSFC) (Nos. 61300086, 61432003), Fundamental Research Funds for the Central Universities (No. DUT15QY15) and the Hong Kong Scholar Program (No. XJ2015008). G. Zhong is supported by China Scholarship Council. J. Cao is supported by NSFC (No. 61363048). Z. Lin is supported by National Basic Research Program of China (973 Program) (No. 2015CB352502), NSFC (Nos. 61272341, 61231002), and Microsoft Research Asia Collaborative Research Program. S. Shan is supported by NSFC (No. 61222211). A preliminary version of this work was published in [1]. R. Liu is the corresponding author.	Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66; Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Adam A., 2006, IEEE C COMP VIS PATT; Aubert G., 2006, MATH PROBLEMS IMAGE; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; BAO CL, 2012, PROC CVPR IEEE, P1830, DOI DOI 10.1109/CVPR.2012.6247881; Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0; Brown E. S., 2010, 1043 UCLA CAM; Cai J.-F., 2013, ARXIV13016791; Calinescu G, 2011, SIAM J COMPUT, V40, P1740, DOI 10.1137/080733991; Cao Frederic, 2003, GEOMETRIC CURVE EVOL; Cao L., 2012, P 20 ACM INT C MULTI, P299; Chan TF, 2005, IMAGE PROCESSING AND ANALYSIS, P1, DOI 10.1137/1.9780898717877; Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Danelljan Martin, 2014, BRIT MACH VIS C NOTT; Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733; Fattal R, 2002, ACM T GRAPHIC, V21, P249; Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Grabner H., 2006, 2006 IEEE COMP SOC C, V1, P260; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Henriques J. F., 2012, EUR C COMP VIS, P702, DOI DOI 10.1007/978-3-642-33765-9_50; Hou X, 2007, 2007 IEEE C COMP VIS, V800, P1, DOI DOI 10.1109/CVPR.2007.383267; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880; Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110; Jiang ZL, 2013, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR.2013.266; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239; Kindermann S, 2005, MULTISCALE MODEL SIM, V4, P1091, DOI 10.1137/050622249; Krause A., 2008, P ICML TUTS; Krause A., 2012, TRACTABILITY PRACTIC, V3; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341; Lindeberg T., 1994, SCALE SPACE THEORY C; Liu RG, 2013, SCI CHINA TECHNOL SC, V56, P1395, DOI 10.1007/s11431-013-5221-6; Liu RS, 2014, PROC CVPR IEEE, P3866, DOI 10.1109/CVPR.2014.494; Liu RS, 2010, LECT NOTES COMPUT SC, V6311, P115; Liu Tie, 2011, PAMI, V33, P353, DOI DOI 10.1109/TPAMI.2010.70; Ma Y.-F, 2003, P 11 ACM INT C MULTI, P374; Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847; Movahedi Vida, 2010, P IEEE C COMP VIS PA, P49, DOI DOI 10.1109/CVPRW.2010.5543739; Nemhauser G. L., 1978, Mathematics of Operations Research, V3, P177, DOI 10.1287/moor.3.3.177; Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Romeny B.M., 1994, GEOMETRY DRIVEN DIFF; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sapiro G., 2006, GEOMETRIC PARTIAL DI; Scherzer O., 2008, VARIATIONAL METHODS, V167; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891; Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721; Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798; van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; Witkin A., 1984, P IEEE INT C AC SPEE, V9, P150, DOI DOI 10.1109/ICASSP.1984.1172729; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878; Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Zhai Y., 2006, PROC14TH ACM INT C M, DOI [10.1145/1180639.1180824, DOI 10.1145/1180639.1180824]; Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62; Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908	78	28	30	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2457	2471		10.1109/TPAMI.2016.2522415	http://dx.doi.org/10.1109/TPAMI.2016.2522415			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	26829775				2022-12-18	WOS:000387984700009
J	Hasnat, MA; Alata, O; Tremeau, A				Hasnat, Md. Abul; Alata, Olivier; Tremeau, Alain			Joint Color-Spatial-Directional Clustering and Region Merging (JCSD-RM) for Unsupervised RGB-D Image Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised; clustering; RGB-D image segmentation; directional distributions; Bregman divergence; mixture model; region adjacency graph; region merging	MIXTURE MODEL	Recent advances in depth imaging sensors provide easy access to the synchronized depth with color, called RGB-D image. In this paper, we propose an unsupervised method for indoor RGB-D image segmentation and analysis. We consider a statistical image generation model based on the color and geometry of the scene. Our method consists of a joint color-spatial-directional clustering method followed by a statistical planar region merging method. We evaluate our method on the NYU depth database and compare it with existing unsupervised RGB-D segmentation methods. Results show that, it is comparable with the state of the art methods and it needs less computation time. Moreover, it opens interesting perspectives to fuse color and geometry in an unsupervised manner.	[Hasnat, Md. Abul; Tremeau, Alain] Univ St Etienne, Lab Hubert Curien, St Etienne, France; [Alata, Olivier] Univ St Etienne, Lab Hubert Curien, UMR CNRS 5516, Dept Comp Sci, St Etienne, France	Universite Jean Monnet; Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS); Universite Jean Monnet	Hasnat, MA (corresponding author), Univ St Etienne, Lab Hubert Curien, St Etienne, France.	mdabul.hasnat@univ-st-etienne.fr; olivier.alata@univ-st-etienne.fr; alain.tremeau@univ-st-etienne.fr		Hasnat, Md Abul/0000-0003-2748-8221				Alata O, 2009, COMPUT VIS IMAGE UND, V113, P867, DOI 10.1016/j.cviu.2009.03.001; [Anonymous], 2009, DIRECTIONAL STAT; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Barron JT, 2013, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2013.10; Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189; Biernacki C, 2003, COMPUT STAT DATA AN, V41, P561, DOI 10.1016/S0167-9473(02)00163-9; Bishop CM, 2006, PATTERN RECOGNITION, V1; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Dal Mutto C, 2012, IEEE J-STSP, V6, P505, DOI 10.1109/JSTSP.2012.2194474; DalMutto C, 2012, SPRBRIEF ELECT, P1, DOI 10.1007/978-1-4614-3807-6; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Fraley C., 2007, J STAT SOFTW, V18, P1, DOI DOI 10.18637/JSS.V018.I06; Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27; Garcia V, 2010, SIGNAL PROCESS, V90, P3197, DOI 10.1016/j.sigpro.2010.05.024; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378; Hasnat A., 2014, BRIT MACH VIS C BMVC, P1; Hasnat M. A., 2013, P 1 WORKSH DIV DIV L; Hasnat MA, 2016, STAT COMPUT, V26, P861, DOI 10.1007/s11222-015-9576-3; Hasnat MA, 2014, INT C PATT RECOG, P214, DOI 10.1109/ICPR.2014.46; Holz Dirk, 2012, RoboCup 2011: Robot Soccer World Cup XV: LNCS 7416, P306, DOI 10.1007/978-3-642-32060-6_26; Koppula H. S., 2011, NIPS, V1, P4; Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4, DOI 10.1007/BFb0026666; Liu MZ, 2012, IEEE T PATTERN ANAL, V34, P2407, DOI 10.1109/TPAMI.2012.44; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; Martinez-Uso A, 2013, PATTERN ANAL APPL, V16, P581, DOI 10.1007/s10044-011-0259-1; McLachlan GJ, 2008, WILEY SER PROBAB ST, P365; Nielsen F., 2009, STAT EXPONENTIAL FAM; Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708; Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110; Peng B, 2011, IEEE T IMAGE PROCESS, V20, P3592, DOI 10.1109/TIP.2011.2157512; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Rusu RB, 2013, SEMANTIC 3D OBJECT M; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Strom J, 2010, IEEE INT C INT ROBOT, P2131, DOI 10.1109/IROS.2010.5650459; Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0; Taylor Camillo J., 2013, 2012 Robotics: Science and Systems, P401; Taylor C. J., 2011, P RSS WORKSH RGB D C; Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176; Tremeau A, 2000, IEEE T IMAGE PROCESS, V9, P735, DOI 10.1109/83.841950; Zhang H., 2004, AA, V1, P3; Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24	47	28	29	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2255	2268		10.1109/TPAMI.2015.2513407	http://dx.doi.org/10.1109/TPAMI.2015.2513407			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26731640	Green Submitted			2022-12-18	WOS:000385945000009
J	Djelouah, A; Franco, JS; Boyer, E; Le Clerc, F; Perez, P				Djelouah, Abdelaziz; Franco, Jean-Sebastien; Boyer, Edmond; Le Clerc, Francois; Perez, Patrick			Sparse Multi-View Consistency for Object Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Segmentation; scene analysis	OCCUPANCY	Multiple view segmentation consists in segmenting objects simultaneously in several views. A key issue in that respect and compared to monocular settings is to ensure propagation of segmentation information between views while minimizing complexity and computational cost. In this work, we first investigate the idea that examining measurements at the projections of a sparse set of 3D points is sufficient to achieve this goal. The proposed algorithm softly assigns each of these 3D samples to the scene background if it projects on the background region in at least one view, or to the foreground if it projects on foreground region in all views. Second, we show how other modalities such as depth may be seamlessly integrated in the model and benefit the segmentation. The paper exposes a detailed set of experiments used to validate the algorithm, showing results comparable with the state of art, with reduced computational complexity. We also discuss the use of different modalities for specific situations, such as dealing with a low number of viewpoints or a scene with color ambiguities between foreground and background.	[Djelouah, Abdelaziz; Le Clerc, Francois; Perez, Patrick] Technicolor, Cesson Sevigne, France; [Franco, Jean-Sebastien; Boyer, Edmond] LJK INRIA, Grenoble, France	Technicolor SA	Djelouah, A (corresponding author), Technicolor, Cesson Sevigne, France.	abdelaziz.djelouah@inria.fr; jean-sebastien.franco@inria.fr; francois.le-clerc@technicolor.com; Patrick.Perez@technicolor.com		Le Clerc, Francois/0000-0003-0519-8581				Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080; Bilmes J., 1997, TR97021 UC BERK I CO; Bishop CM, 2006, PATTERN RECOGNITION; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Bradski G., 2000, DOBBS J SOFTWARE TOO, V3; Campbell N. D. F., 2011, 2011 Conference for Visual Media Production, P126, DOI 10.1109/CVMP.2011.21; Campbell NDF, 2010, IMAGE VISION COMPUT, V28, P14, DOI 10.1016/j.imavis.2008.09.005; Crabb Ryan, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563170; Djelouah A, 2012, LECT NOTES COMPUT SC, V7576, P818, DOI 10.1007/978-3-642-33715-4_59; Feldmann T, 2009, LECT NOTES COMPUT SC, V5748, P522, DOI 10.1007/978-3-642-03798-6_53; Franco JS, 2005, IEEE I CONF COMP VIS, P1747; Gallego J, 2011, IEEE IMAGE PROC, P997, DOI 10.1109/ICIP.2011.6116731; Guan L., 2008, P 5 INT S 3D DAT PRO; Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261; JOULIN A, 2010, PROC CVPR IEEE, P1943, DOI DOI 10.1109/CVPR.2010.5539868; Kolev K, 2012, IEEE T PATTERN ANAL, V34, P493, DOI 10.1109/TPAMI.2011.150; Kolmogorov V, 2005, PROC CVPR IEEE, P407; Kowdle A, 2012, LECT NOTES COMPUT SC, V7576, P789, DOI 10.1007/978-3-642-33715-4_57; Kutulakos K. N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P307, DOI 10.1109/ICCV.1999.791235; Lee W, 2011, IEEE T PATTERN ANAL, V33, P1429, DOI 10.1109/TPAMI.2010.196; Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44; Reinbacher C, 2012, IMAGE VISION COMPUT, V30, P797, DOI 10.1016/j.imavis.2012.08.009; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Sarim M, 2010, PROCEEDINGS OF THE 2010 ACM WORKSHOP ON 3D VIDEO PROCESSING (3DVP'10), P13, DOI 10.1145/1877791.1877795; Snow D, 2000, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2000.855839; Sormann M, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P1085; Stauffer C., 1999, P IEEE COMP SOC C CO, V2; Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228; van Beusekom J., 2012, 3DTV C TRUE VIS CAPT, P1; Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530; Wang L, 2010, NANO RES, V3, P317, DOI DOI 10.1093/MP/SSQ042; Winn J, 2005, IEEE I CONF COMP VIS, P756; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Young Min Kim, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1542, DOI 10.1109/ICCVW.2009.5457430; Zeng G., 2004, P AS C COMP VIS, P628	36	28	28	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1890	1903		10.1109/TPAMI.2014.2385704	http://dx.doi.org/10.1109/TPAMI.2014.2385704			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353134	Green Submitted			2022-12-18	WOS:000359216600012
J	Li, K; Fu, Y				Li, Kang; Fu, Yun			Prediction of Human Activity by Discovering Temporal Sequence Patterns	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Activity prediction; causality; context-cue; predictability	ACTION RECOGNITION	Early prediction of ongoing human activity has become more valuable in a large variety of time-critical applications. To build an effective representation for prediction, human activities can be characterized by a complex temporal composition of constituent simple actions and interacting objects. Different from early detection on short-duration simple actions, we propose a novel framework for long-duration complex activity prediction by discovering three key aspects of activity: Causality, Context-cue, and Predictability. The major contributions of our work include: (1) a general framework is proposed to systematically address the problem of complex activity prediction by mining temporal sequence patterns; (2) probabilistic suffix tree (PST) is introduced to model causal relationships between constituent actions, where both large and small order Markov dependencies between action units are captured; (3) the context-cue, especially interactive objects information, is modeled through sequential pattern mining (SPM), where a series of action and object co-occurrence are encoded as a complex symbolic sequence; (4) we also present a predictive accumulative function (PAF) to depict the predictability of each kind of activity. The effectiveness of our approach is evaluated on two experimental scenarios with two data sets for each: action-only prediction and context-aware prediction. Our method achieves superior performance for predicting global activity classes and local action units.	[Li, Kang; Fu, Yun] Northeastern Univ, Dept Elect & Comp Engn, Coll Engn, Boston, MA 02115 USA; [Fu, Yun] Northeastern Univ, Coll Comp & Informat Sci, Dana Res Ctr 403, Boston, MA 02115 USA	Northeastern University; Northeastern University	Li, K (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Coll Engn, Boston, MA 02115 USA.	li.ka@husky.neu.edu; yunfu@ece.neu.edu			NSF CNS [1314484]; Office of Naval Research [N00014-12-1-1028]; Air Force Office of Scientic Research [FA9550-12-1-0201]; U.S. Army Research Office [W911NF-13-1-0160]; IC Postdoc Program [2011-11071400006]	NSF CNS(National Science Foundation (NSF)); Office of Naval Research(Office of Naval Research); Air Force Office of Scientic Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); U.S. Army Research Office; IC Postdoc Program	This research was supported in part by the NSF CNS award 1314484, Office of Naval Research award N00014-12-1-1028, Air Force Office of Scientic Research award FA9550-12-1-0201, U.S. Army Research Office grant W911NF-13-1-0160, and IC Postdoc Program Grant 2011-11071400006. The authors would thank Dr. Yu Cao and Dr. M. S. Ryoo for sharing the codes and giving suggestions to this work.	Abbeel P., 2004, P 21 INT C MACHINE L, P1; AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Agrawal R., 1994, P 20 INT C VER LARG, P487; Baker CL, 2009, COGNITION, V113, P329, DOI 10.1016/j.cognition.2009.07.005; Begleiter R, 2004, J ARTIF INTELL RES, V22, P385, DOI 10.1613/jair.1491; Brendel W, 2011, IEEE I CONF COMP VIS, P778, DOI 10.1109/ICCV.2011.6126316; Brown P. F., 1992, Computational Linguistics, V18, P467; Collins R., 2005, IEEE INT WORKSH PERF, V2; Davis JW, 2006, IMAGE VISION COMPUT, V24, P455, DOI 10.1016/j.imavis.2006.01.012; Desobry F, 2005, IEEE T SIGNAL PROCES, V53, P2961, DOI 10.1109/TSP.2005.851098; Dong G., 2009, SEQUENCE DATA MINING; Facca FM, 2005, DATA KNOWL ENG, V53, P225, DOI 10.1016/j.datak.2004.08.001; Fan QF, 2009, PROC CVPR IEEE, P943, DOI 10.1109/CVPRW.2009.5206644; Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Haider P, 2007, P 24 INT C MACH LEAR, P345; Hamid R, 2009, ARTIF INTELL, V173, P1221, DOI 10.1016/j.artint.2009.05.002; Han D, 2009, IEEE I CONF COMP VIS, P1933, DOI 10.1109/ICCV.2009.5459427; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; Jiang YG, 2011, IEEE T CIRC SYST VID, V21, P674, DOI 10.1109/TCSVT.2011.2129870; Kim KJ, 2003, NEUROCOMPUTING, V55, P307, DOI 10.1016/S0925-2312(03)00372-2; Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15; Kolahi SS, 2013, IEEE SYMP COMP COMMU; Kollar T, 2009, IEEE INT CONF ROBOT, P4116; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Levine S., 2011, P NEUR INF PROC SYST, V24, P1; Li K, 2012, LECT NOTES COMPUT SC, V7572, P286, DOI 10.1007/978-3-642-33718-5_21; Mabroukeh NR, 2010, ACM COMPUT SURV, V43, DOI 10.1145/1824795.1824798; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Hoai M, 2012, PROC CVPR IEEE, P2863, DOI 10.1109/CVPR.2012.6248012; Munoz D, 2012, LECT NOTES COMPUT SC, V7577, P668, DOI 10.1007/978-3-642-33783-3_48; Munoz D, 2010, LECT NOTES COMPUT SC, V6316, P57, DOI 10.1007/978-3-642-15567-3_5; Nasraoui O, 2008, IEEE T KNOWL DATA EN, V20, P202, DOI 10.1109/TKDE.2007.190667; Neill D. B., 2006, ADV NEURAL INFORM PR, V18, P1003; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279; Roggen D., 2010, 2010 Seventh International Conference on Networked Sensing Systems (INSS 2010), P233, DOI 10.1109/INSS.2010.5573462; Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801; Ron D, 1996, MACH LEARN, V25, P117, DOI 10.1007/BF00114008; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Ryoo MS, 2006, 2006 IEEE COMPUTER S, V2, P1709, DOI DOI 10.1109/CVPR.2006.242; Si ZZ, 2011, IEEE I CONF COMP VIS, P41, DOI 10.1109/ICCV.2011.6126223; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; Srivastava J., 2000, SIGKDD EXP, V1, P12, DOI DOI 10.1145/846183.846188; Suha Kwak, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3345, DOI 10.1109/CVPR.2011.5995435; Turaga P. K., 2007, P IEEE C COMP VIS PA, P1; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang K., 2004, P 13 ACM INT C INF K, P178; Wongun Choi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3273, DOI 10.1109/CVPR.2011.5995707; YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235; Zhao Q., 2003, SEQUENTIAL PATTERN M, P1; Ziebart B. D., 2008, AAAI, V8, P1433; Ziebart BD, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3931, DOI 10.1109/IROS.2009.5354147	57	28	28	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1644	1657		10.1109/TPAMI.2013.2297321	http://dx.doi.org/10.1109/TPAMI.2013.2297321			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN					2022-12-18	WOS:000340191900012
J	Shen, L; Yeo, C; Hua, BS				Shen, Li; Yeo, Chuohao; Hua, Binh-Son			Intrinsic Image Decomposition Using a Sparse Representation of Reflectance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Intrinsic image decomposition; sparse reconstruction; multiresolution analysis		Intrinsic image decomposition is an important problem that targets the recovery of shading and reflectance components from a single image. While this is an ill-posed problem on its own, we propose a novel approach for intrinsic image decomposition using reflectance sparsity priors that we have developed. Our sparse representation of reflectance is based on a simple observation: Neighboring pixels with similar chromaticities usually have the same reflectance. We formalize and apply this sparsity constraint on local reflectance to construct a data-driven second-generation wavelet representation. We show that the reflectance component of natural images is sparse in this representation. We further propose and formulate a global sparse constraint on reflectance colors using the assumption that each natural image uses a small set of material colors. Using this sparse reflectance representation and the global constraint on a sparse set of reflectance colors, we formulate a constrained l(1)-norm minimization problem for intrinsic image decomposition that can be solved efficiently. Our algorithm can successfully extract intrinsic images from a single image without using color models or any user interaction. Experimental results on a variety of images demonstrate the effectiveness of the proposed technique.	[Shen, Li] Inst Infocomm Res, Comp Graph & Interface Dept, Singapore 138632, Singapore; [Yeo, Chuohao] Inst Infocomm Res, Signal Proc Dept, Singapore 138632, Singapore; [Hua, Binh-Son] Natl Univ Singapore, Dept Comp Sci, Singapore 119077, Singapore	Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); National University of Singapore	Shen, L (corresponding author), Inst Infocomm Res, Comp Graph & Interface Dept, 1 Fusionopolis Way,21-01 Connexis North Tower, Singapore 138632, Singapore.	lshen@i2r.a-star.edu.sg; chyeo@i2r.a-star.edu.sg; huabinhs@comp.nus.edu.sg						Barrow H. G., 1978, COMPUTER VISION SYST; Bell M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P670, DOI 10.1109/ICCV.2001.937585; Bousseau A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618476; Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328; Finlayson G. D., 2002, P IS T SID 10 COL IM, P73; FUNT BV, 1992, LECT NOTES COMPUT SC, V588, P124; Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428; Horn B., 1986, ROBOT VISION, P1; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998; Land E., 1971, J OPT SOC AM A, V3, P1684; Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105; Matsushita Y, 2004, LECT NOTES COMPUT SC, V3022, P274; Omer I, 2004, PROC CVPR IEEE, P946; Shen L., 2008, P IEEE C COMPUTER VI, P1; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sunkavalli K, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239552, 10.1145/1276377.1276504]; Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051; Tappen M.F., 2006, 2006 IEEE COMPUTER S, V2, P1992; Tappen MF, 2005, IEEE T PATTERN ANAL, V27, P1459, DOI 10.1109/TPAMI.2005.185; Troccoli A, 2008, INT J COMPUT VISION, V78, P261, DOI 10.1007/s11263-007-0100-x; Uytterhoeven G., 1998, P IEEE BEN SIGN PROC, P191; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606	27	28	31	2	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2904	2915		10.1109/TPAMI.2013.136	http://dx.doi.org/10.1109/TPAMI.2013.136			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136429				2022-12-18	WOS:000326502200008
J	Ren, Z; Yuan, JS; Liu, WY				Ren, Zhou; Yuan, Junsong; Liu, Wenyu			Minimum Near-Convex Shape Decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape decomposition; shape representation; discrete optimization		Shape decomposition is a fundamental problem for part-based shape representation. We propose the minimum near-convex decomposition (MNCD) to decompose arbitrary shapes into minimum number of "near-convex" parts. The near-convex shape decomposition is formulated as a discrete optimization problem by minimizing the number of nonintersecting cuts. Two perception rules are imposed as constraints into our objective function to improve the visual naturalness of the decomposition. With the degree of near-convexity a user-specified parameter, our decomposition is robust to local distortions and shape deformation. The optimization can be efficiently solved via binary integer linear programming. Both theoretical analysis and experiment results show that our approach outperforms the state-of-the-art results without introducing redundant parts and thus leads to robust shape representation.	[Ren, Zhou; Yuan, Junsong] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Liu, Wenyu] Huazhong Univ Sci & Technol, Wuhan 430074, Hubei Province, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Huazhong University of Science & Technology	Ren, Z (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.		Yuan, Junsong/R-4352-2019; Liu, Wenyu/AAG-1426-2019; Yuan, Junsong/A-5171-2011	Liu, Wenyu/0000-0002-4582-7488; 	Nanyang Assistant Professorship [SUG M58040015]; National Natural Science Foundation of China [61173120]	Nanyang Assistant Professorship; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors thank Professor Yoshinobu Kawahara from Osaka University for helpful discussions. This work was supported in part by the Nanyang Assistant Professorship (SUG M58040015) to Dr. Junsong Yuan and the National Natural Science Foundation of China (grant No. 61173120) to Dr. Wenyu Liu. A preliminary version of this paper appeared in the Proceedings of the IEEE International Conference on Computer Vision [1].	Aurenhammer F, 2008, COMP GEOM-THEOR APPL, V40, P93, DOI 10.1016/j.comgeo.2007.08.002; Bai X., 2009, P IEEE WORKSH NORDIA; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Cass TA, 1998, IEEE T PATTERN ANAL, V20, P1265, DOI 10.1109/34.730560; Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3; Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369; Keil J.M., 2007, MINIMUM CONVEX DECOM; Keil M, 2002, INT J COMPUT GEOM AP, V12, P181, DOI 10.1142/S0218195902000803; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Lien J.-M., 2009, P ROB SCI SYST C; Lien J.-M., 2008, P ROB SCI SYST C; Lien J.-M., 2007, P 2007 ACM S SOLID P, P121; Lien JM, 2006, COMP GEOM-THEOR APPL, V35, P100, DOI 10.1016/j.comgeo.2005.10.005; Liu H., 2010, P IEEE C COMP VIS PA, P104; Lu GJ, 1999, MULTIMEDIA SYST, V7, P165, DOI 10.1007/s005300050119; Macrini D, 2012, INT C PATT RECOG, P2302; Macrini D, 2011, COMPUT VIS IMAGE UND, V115, P1044, DOI 10.1016/j.cviu.2010.12.011; Mi XF, 2007, IEEE I CONF COMP VIS, P1448; Ren Z., 2011, P 19 ACM INT C MULTI, P759, DOI DOI 10.1145/2072298.2072443; Ren Z, 2011, P 19 ACM INT C MULT, DOI DOI 10.1145/2072298.2071946; Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148; Ren Z, 2011, IEEE I CONF COMP VIS, P303, DOI 10.1109/ICCV.2011.6126256; Siddiqi K, 1996, PERCEPTION, V25, P399, DOI 10.1068/p250399; Singh M, 1999, PERCEPT PSYCHOPHYS, V61, P636, DOI 10.3758/BF03205536; Singh M, 1999, PERCEPT PSYCHOPHYS, V61, P943, DOI 10.3758/BF03206908; Singh M., 2001, ADV PSYCHOL, VVolume 130, P401, DOI DOI 10.1016/S0166-4115(01)80033-9; Tanase M., 2003, P 19 ANN S COMP GEOM, P58; Zuckerberger E, 2002, COMPUT GRAPH-UK, V26, P733, DOI 10.1016/S0097-8493(02)00128-0	28	28	29	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2546	2552		10.1109/TPAMI.2013.67	http://dx.doi.org/10.1109/TPAMI.2013.67			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969396				2022-12-18	WOS:000323175200018
J	Miraldo, P; Araujo, H				Miraldo, Pedro; Araujo, Helder			Calibration of Smooth Camera Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						General camera models; camera calibration; smooth vector-valued functions		Generic imaging models can be used to represent any camera. Current generic models are discrete and define a mapping between each pixel in the image and a straight line in 3D space. This paper presents a modification of the generic camera model that allows the simplification of the calibration procedure. The only requirement is that the coordinates of the 3D projecting lines are related by functions that vary smoothly across space. Such a model is obtained by modifying the general imaging model using radial basis functions (RBFs) to interpolate image coordinates and 3D lines, thereby allowing both an increase in resolution (due to their continuous nature) and a more compact representation. Using this variation of the general imaging model, we also develop a calibration procedure. This procedure only requires that a 3D point be matched to each pixel. In addition, not all the pixels need to be calibrated. As a result, the complexity of the procedure is significantly decreased. Normalization is applied to the coordinates of both image and 3D points, which increases the accuracy of the calibration. Results with both synthetic and real datasets show that the model and calibration procedure are easily applicable and provide accurate calibration results.	[Miraldo, Pedro; Araujo, Helder] Univ Coimbra, Inst Syst & Robot, Dept Elect & Comp Engn, P-3030290 Coimbra, Portugal	Universidade de Coimbra	Miraldo, P (corresponding author), Univ Coimbra, Inst Syst & Robot, Dept Elect & Comp Engn, P-3030290 Coimbra, Portugal.	miraldo@isr.uc.pt; helder@isr.uc.pt	Araujo, Helder/B-3554-2008; Miraldo, Pedro/C-2929-2016	Araujo, Helder/0000-0002-9544-424X; Miraldo, Pedro/0000-0002-8551-2448	Portuguese Foundation for Science and Technology (FCT) [PTDC/EIA-EIA/122454/2010, PTDC/EIA-CCO/109120/2008]; FCT [SFRH/BD/49054/2008]	Portuguese Foundation for Science and Technology (FCT)(Portuguese Foundation for Science and Technology); FCT(Portuguese Foundation for Science and TechnologyEuropean Commission)	This work was supported by the Portuguese Foundation for Science and Technology (FCT) with grants PTDC/EIA-EIA/122454/2010 and PTDC/EIA-CCO/109120/2008. P. Miraldo also wants to thanks to the FCT for his doctoral degree grant with reference SFRH/BD/49054/2008.	Agrawal A., 2010, P 11 EUR C COMP VIS; Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Bartoli A, 2005, COMPUT VIS IMAGE UND, V100, P416, DOI 10.1016/j.cviu.2005.06.001; Bouguet J-Y, 2010, CAMERA CALIBRATION T; Buhmann MD:, 2003, CAMBRIDGE MONOGRAPHS, V12)., DOI 10.1017/CBO9780511543241; Gasparini S., 2009, P 12 IEEE INT C COMP; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Goncalves N., 2008, THESIS U COIMBRA, p[1, 2, 6]; Grossberg M.D., 2001, P 8 IEEE INT C COMP; Grossberg MD, 2005, INT J COMPUT VISION, V61, P119, DOI 10.1023/B:VISI.0000043754.56350.10; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; Hartley R., 2005, P 10 IEEE INT C COMP; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hu S., 2009, P 2 INT C IM SIGN PR; Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153; Kutulakos KN, 2008, INT J COMPUT VISION, V76, P13, DOI 10.1007/s11263-007-0049-9; Menem M., 2004, P BRIT MACH VIS C; Micusik B., 2004, P IEEE C COMP VIS PA; Miraldo P., 2011, TECHNICAL REPORT; Miraldo P., 2011, P IEEE INT C COMP VI; Nister D., 2005, P 10 IEEE INT C COMP, P120; Northern Digital Incorporated, 2009, OPT CERT MOT CAPT SY; Ponce J., 2009, P IEEE C COMP VIS PA; Pottmann Helmut, 2001, MATH VISUAL, V2; QUAK E, 1993, SIAM J MATH ANAL, V24, P1043, DOI 10.1137/0524062; Ramalingam S., 2005, P IEEE C COMP VIS PA; Ramalingam S, 2010, COMPUT VIS IMAGE UND, V114, P210, DOI 10.1016/j.cviu.2009.07.007; SIVAKUMAR N, 1993, NUMER MATH, V65, P219, DOI 10.1007/BF01385749; Sturm P., 2004, P 8 EUR C COMP VIS; Sturm Peter, 2011, FDN TRENDS COMPUTER; Swaminathan R, 2006, INT J COMPUT VISION, V66, P211, DOI 10.1007/s11263-005-3220-1; Swaminathan R., 2003, P IEEE C COMP VIS PA; Thirthala SriRam, 2012, INT J COMPUTER VISIO, P2; Treibitz T., 2008, P IEEE C COMP VIS PA; Tsai R.Y., 1986, P COMPUTER VISION PA; Wendland H., 2005, SCATTERED DATA APPRO; Yu J., 2004, P EUR C COMP VIS; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zomet A, 2003, IEEE T PATTERN ANAL, V25, P741, DOI 10.1109/TPAMI.2003.1201823	40	28	30	3	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2091	2103		10.1109/TPAMI.2012.258	http://dx.doi.org/10.1109/TPAMI.2012.258			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868772				2022-12-18	WOS:000322029000004
J	Ma, AJ; Yuen, PC; Lai, JH				Ma, Andy Jinhua; Yuen, Pong C.; Lai, Jian-Huang			Linear Dependency Modeling for Classifier Fusion and Feature Combination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Linear dependency modeling; feature dependency; classifier level fusion; feature level fusion; multiple feature fusion		This paper addresses the independent assumption issue in fusion process. In the last decade, dependency modeling techniques were developed under a specific distribution of classifiers or by estimating the joint distribution of the posteriors. This paper proposes a new framework to model the dependency between features without any assumption on feature/classifier distribution, and overcomes the difficulty in estimating the high-dimensional joint density. In this paper, we prove that feature dependency can be modeled by a linear combination of the posterior probabilities under some mild assumptions. Based on the linear combination property, two methods, namely, Linear Classifier Dependency Modeling (LCDM) and Linear Feature Dependency Modeling (LFDM), are derived and developed for dependency modeling in classifier level and feature level, respectively. The optimal models for LCDM and LFDM are learned by maximizing the margin between the genuine and imposter posterior probabilities. Both synthetic data and real datasets are used for experiments. Experimental results show that LCDM and LFDM with dependency modeling outperform existing classifier level and feature level combination methods under nonnormal distributions and on four real databases, respectively. Comparing the classifier level and feature level fusion methods, LFDM gives the best performance.	[Ma, Andy Jinhua; Yuen, Pong C.] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; [Yuen, Pong C.] BNU HKBU United Int Coll, Zhuhai, Peoples R China; [Lai, Jian-Huang] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510257, Guangdong, Peoples R China; [Lai, Jian-Huang] Guangdong Prov Key Lab Informat Secur, Guangzhou 510006, Guangdong, Peoples R China	Hong Kong Baptist University; Beijing Normal University - Hong Kong Baptist University United International College; Sun Yat Sen University	Ma, AJ (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	jhma@comp.hkbu.edu.hk; pcyuen@comp.hkbu.edu.hk; stsljh@mail.sysu.edu.cn	Jinhua, Andy/Y-9408-2019		Hong Kong Baptist University; National Natural Science Foundation of China [61128009, 61172136]; NSFC [U0835005]	Hong Kong Baptist University; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); NSFC(National Natural Science Foundation of China (NSFC))	This project was partially supported by the Science Faculty Research Grant of Hong Kong Baptist University, National Natural Science Foundation of China Research Grants 61128009 and 61172136, and NSFC-GuangDong Research Grant U0835005. The authors would like to thank the reviewers for their helpful comments which improved the quality of this paper.	Alkoot FM, 1999, PATTERN RECOGN LETT, V20, P1361, DOI 10.1016/S0167-8655(99)00107-5; Bach F.R., 2004, P INT C MACH LEARN; Botev ZI, 2010, ANN STAT, V38, P2916, DOI 10.1214/10-AOS799; Bowman A., 1997, APPL SMOOTHING TECHN; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; Dollar P., 2005, P IEEE JOINT INT WOR; Duda R.O., 2000, PATTERN CLASSIFICATI; Feller W., 1968, INTRO PROBABILITY TH, V1; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Guigue V., 2005, PERCEPTION SYSTMES I; Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luenberger D.G., 2008, LINEAR NONLINEAR PRO; Ma A.J., 2011, P IEEE INT C COMP VI; Nandakumar K, 2008, IEEE T PATTERN ANAL, V30, P342, DOI 10.1109/TPAMI.2007.70796; Nilsback M.-E., 2008, P IEEE IND C COMP VI; Nilsback M.E., 2006, P 2006 IEEE COMP VIS; Orabona F, 2010, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2010.5540137; Prabhakar S, 2002, PATTERN RECOGN, V35, P861, DOI 10.1016/S0031-3203(01)00103-0; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Terrades OR, 2009, IEEE T PATTERN ANAL, V31, P1630, DOI 10.1109/TPAMI.2008.224; Ross A.A., 2006, HDB MULTIBIOMETRICS; Saffari A, 2010, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2010.5539937; Schuldt C., 2004, P IEEE INT C PATT RE; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Szekely GJ, 2007, ANN STAT, V35, P2769, DOI 10.1214/009053607000000505; van Breukelen M, 1998, KYBERNETIKA, V34, P381; Yang JJ, 2009, IEEE I CONF COMP VIS, P436, DOI 10.1109/ICCV.2009.5459172	37	28	30	1	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1135	1148		10.1109/TPAMI.2012.198	http://dx.doi.org/10.1109/TPAMI.2012.198			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520255				2022-12-18	WOS:000316126800009
J	McCloskey, S; Ding, YY; Yu, JY				McCloskey, Scott; Ding, Yuanyuan; Yu, Jingyi			Design and Estimation of Coded Exposure Point Spread Functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Coded exposure; motion deblurring; blur estimation; computational photography	IMAGES	We address the problem of motion deblurring using coded exposure. This approach allows for accurate estimation of a sharp latent image via well-posed deconvolution and avoids lost image content that cannot be recovered from images acquired with a traditional shutter. Previous work in this area has used either manual user input or alpha matting approaches to estimate the coded exposure Point Spread Function (PSF) from the captured image. In order to automate deblurring and to avoid the limitations of matting approaches, we propose a Fourier-domain statistical approach to coded exposure PSF estimation that allows us to estimate the latent image in cases of constant velocity, constant acceleration, and harmonic motion. We further demonstrate that previously used criteria to choose a coded exposure PSF do not produce one with optimal reconstruction error, and that an additional 30 percent reduction in Root Mean Squared Error (RMSE) of the latent image estimate can be achieved by incorporating natural image statistics.	[McCloskey, Scott] Honeywell ACS Labs, Golden Valley, MN 55422 USA; [Ding, Yuanyuan] Epson Res & Dev Inc, San Jose, CA 95112 USA; [Yu, Jingyi] Univ Delaware, Dept CIS, Newark, DE 19716 USA	Honeywell; University of Delaware	McCloskey, S (corresponding author), Honeywell ACS Labs, 1985 Douglas Dr N 112A, Golden Valley, MN 55422 USA.	scott.mccloskey@honeywell.com; yding@erd.epson.com; yu@eecis.udel.edu			US Army Biometrics Task Force [W91CRB-09-C-0013]; US National Science Foundation [IIS-CA-REER-0845268]; US Air Force Office of Scientific Research [FA9550-10-1-0175]	US Army Biometrics Task Force; US National Science Foundation(National Science Foundation (NSF)); US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR))	This material is based upon work supported by the US Army Biometrics Task Force under Contract No. W91CRB-09-C-0013. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the US Army. Flea2 is a trademark of Point Grey Research, Inc. All brand names and trademarks used herein are for descriptive purposes only and are the property of their respective owners. Drs. Ding and Yu were partially supported by US National Science Foundation grant IIS-CA-REER-0845268 and US Air Force Office of Scientific Research grant FA9550-10-1-0175.	Agrawal A., 2009, P IEEE C COMP VIS PA; Cho S., 2009, P ACM SIGGR AS; Dai S., 2008, P IEEE C COMP VIS PA; Moghaddam ME, 2007, PATTERN RECOGN, V40, P1946, DOI 10.1016/j.patcog.2006.11.022; Favaro P, 2005, IEEE T PATTERN ANAL, V27, P406, DOI 10.1109/TPAMI.2005.43; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Gupta A., 2010, P EUR C COMP VIS; Haykin S., 1994, BLIND DECONVOLUTION; Ji H., 2008, P IEEE C COMP VIS PA; JIA J, 2007, P IEEE C COMP VIS PA; JOSHI N, 2009, P IEEE C COMP VIS PA; KRISHNAN D., 2009, P NEUR INF PROC SYST; Levin A., 2006, ADV NEURAL INFORM PR, V19, P841; Levin A., 2007, P ACM SIGGRAPH; LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605; Martin D., 2001, P IEEE INT C COMP VI; McCloskey S., 2010, P 4 IEEE C BIOM THEO; Oliveira J.a.P., 2007, P IB C PATT REC IM A; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Shan Q., 2007, P 11 IEEE INT C COMP; Shan Q., 2008, P ACM SIGGRAPH; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Xu Li, 2010, P EUR C COMP VIS; Xu W., 2011, P WORKSH APPL COMP V; Zhou CY, 2011, IEEE T IMAGE PROCESS, V20, P3322, DOI 10.1109/TIP.2011.2171700	26	28	31	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					2071	2077		10.1109/TPAMI.2012.108	http://dx.doi.org/10.1109/TPAMI.2012.108			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22585096				2022-12-18	WOS:000307522700017
J	Pei, YR; Huang, FC; Shi, FH; Zha, HB				Pei, Yuru; Huang, Fengchun; Shi, Fuhao; Zha, Hongbin			Unsupervised Image Matching Based on Manifold Alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manifold alignment; unsupervised image set matching; nonrigid transformation; parameterized distance curve	DIMENSIONALITY REDUCTION	This paper challenges the issue of automatic matching between two image sets with similar intrinsic structures and different appearances, especially when there is no prior correspondence. An unsupervised manifold alignment framework is proposed to establish correspondence between data sets by a mapping function in the mutual embedding space. We introduce a local similarity metric based on parameterized distance curves to represent the connection of one point with the rest of the manifold. A small set of valid feature pairs can be found without manual interactions by matching the distance curve of one manifold with the curve cluster of the other manifold. To avoid potential confusions in image matching, we propose an extended affine transformation to solve the nonrigid alignment in the embedding space. The comparatively tight alignments and the structure preservation can be obtained simultaneously. The point pairs with the minimum distance after alignment are viewed as the matchings. We apply manifold alignment to image set matching problems. The correspondence between image sets of different poses, illuminations, and identities can be established effectively by our approach.	[Pei, Yuru; Huang, Fengchun; Shi, Fuhao; Zha, Hongbin] Peking Univ, Key Lab Machine Percept MOE, Dept Machine Intelligence, Beijing 100871, Peoples R China	Peking University	Pei, YR (corresponding author), Peking Univ, Key Lab Machine Percept MOE, Dept Machine Intelligence, Sci Bldg 2,5 Yiheyuan Rd, Beijing 100871, Peoples R China.	peiyuru@cis.pku.edu.cn; hfch@cis.pku.edu.cn; fhshi@cis.pku.edu.cn; zha@cis.pku.edu.cn			NSFC [60803067]; NHTRDP 863 [2009AA01Z312]; NBRPC [2011CB302202]	NSFC(National Natural Science Foundation of China (NSFC)); NHTRDP 863; NBRPC(National Basic Research Program of China)	Portions of the research in this paper use the oriental face database collected under the research of the Artificial Intelligence and Robotics (AIR). This work was supported in part by NSFC 60803067, NHTRDP 863 Grant No. 2009AA01Z312, and NBRPC Grant No. 2011CB302202.	Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626; [Anonymous], 2011, ORIENTAL FACE DATABA; Avriel M., 2003, NONLINEAR PROGRAMMIN; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Diaz F, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2727; Fodor I.K., 2002, LIB LOND, DOI DOI 10.2172/15002155; Grujic N., 2008, P INT C AUT FAC GEST; Ham J., 2006, P IEE COMP VIS PATT, V1, P817; Ham J., 2005, P ANN C UNC ART INT, P120; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1784, DOI 10.1109/TPAMI.2006.223; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Wang C, 2008, P 25 INT C MACH LEAR, P1120, DOI DOI 10.1145/1390156.1390297; Wang C, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1273; Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850; Xiong L, 2007, LECT NOTES ARTIF INT, V4701, P773; Yin L., 2008, P INT C AUT FAC GEST	24	28	28	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1658	1664		10.1109/TPAMI.2011.229	http://dx.doi.org/10.1109/TPAMI.2011.229			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22144524				2022-12-18	WOS:000305188500016
J	Si, ZZ; Zhu, SC				Si, Zhangzhang; Zhu, Song-Chun			Learning Hybrid Image Templates (HIT) by Information Projection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image representation; deformable templates; information projection; visual learning; statistical modeling	OBJECT RECOGNITION; APPEARANCE; MODEL; SHAPE	This paper presents a novel framework for learning a generative image representation-the hybrid image template (HIT) from a small number (i.e., 3 similar to 20) of image examples. Each learned template is composed of, typically, 50 similar to 500 image patches whose geometric attributes (location, scale, orientation) may adapt in a local neighborhood for deformation, and whose appearances are characterized, respectively, by four types of descriptors: local sketch (edge or bar), texture gradients with orientations, flatness regions, and colors. These heterogeneous patches are automatically ranked and selected from a large pool according to their information gains using an information projection framework. Intuitively, a patch has a higher information gain if 1) its feature statistics are consistent within the training examples and are distinctive from the statistics of negative examples (i.e., generic images or examples from other categories); and 2) its feature statistics have less intraclass variations. The learning process pursues the most informative (for either generative or discriminative purpose) patches one at a time and stops when the information gain is within statistical fluctuation. The template is associated with a well-normalized probability model that integrates the heterogeneous feature statistics. This automated feature selection procedure allows our algorithm to scale up to a wide range of image categories, from those with regular shapes to those with stochastic texture. The learned representation captures the intrinsic characteristics of the object or scene categories. We evaluate the hybrid image templates on several public benchmarks, and demonstrate classification performances on par with state-of-the-art methods like HoG+SVM, and when small training sample sizes are used, the proposed system shows a clear advantage.	[Si, Zhangzhang; Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Si, ZZ (corresponding author), Univ Calif Los Angeles, Dept Stat, 8125 Math Sci Bldg, Los Angeles, CA 90095 USA.	zzsi@stat.ucla.edu; sczhu@stat.ucla.edu			US National Science Foundation (NSF) [IIS1018751]; DMS [1007889]; ONR [N000141010933]	US National Science Foundation (NSF)(National Science Foundation (NSF)); DMS; ONR(Office of Naval Research)	The authors would like to thank Dr. Ying Nian Wu for his valuable suggestions in experiments and writing. They also thank the three anonymous reviewers for their insightful comments. The work is supported by US National Science Foundation (NSF) IIS1018751, DMS 1007889, and ONR N000141010933. Reproducibility page: http://www.stat.ucla.edu/similar to zzsi/hit.html.	AHUJA N, 2007, P IEEE INT C COMP VI; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bissacco A., 2007, ADV NEURAL INFORM PR; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, P IEEE CS C COMP VIS; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; Epstein RA, 2008, J NEUROPHYSIOL, V99, P2877, DOI 10.1152/jn.90376.2008; Everingham M., 2011, PASCAL VISUAL OBJECT; Fei-Fei L, 2004, P CVPR WORKSH GEN MO; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; Fidler S., 2007, CVPR; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; Gehler P.V., 2009, P IEEE INT C COMP VI; Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004; HEISELE B, 2001, P IEEE INT C COMP VI; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Liu C., 2010, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma X., 2008, P IEEE C COMP VIS PA; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Opelt A, 2008, INT J COMPUT VISION, V80, P16, DOI 10.1007/s11263-008-0139-3; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; Sudderth EB, 2008, INT J COMPUT VISION, V77, P291, DOI 10.1007/s11263-007-0069-5; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; VARMA M, 2007, P IEEE INT C COMP VI; Wu YN, 2008, Q APPL MATH, V66, P81; Wu YN, 2010, INT J COMPUT VISION, V90, P198, DOI 10.1007/s11263-009-0287-0; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; ZHANG H, 2006, P IEEE CS C COMP VIS; ZHU L., 2010, P IEEE C COMP VIS PA; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627	38	28	30	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1354	1367		10.1109/TPAMI.2011.227	http://dx.doi.org/10.1109/TPAMI.2011.227			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22144518	Green Submitted			2022-12-18	WOS:000304138300008
J	Brostow, GJ; Hernandez, C; Vogiatzis, G; Stenger, B; Cipolla, R				Brostow, Gabriel J.; Hernandez, Carlos; Vogiatzis, George; Stenger, Bjoern; Cipolla, Roberto			Video Normals from Colored Lights	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; multispectral; single view; video normals	PHOTOMETRIC-STEREO; MOTION CAPTURE; RECONSTRUCTION; SHAPE; INTEGRABILITY; CALIBRATION; ORIENTATION; EXAMPLE	We present an algorithm and the associated single-view capture methodology to acquire the detailed 3D shape, bends, and wrinkles of deforming surfaces. Moving 3D data has been difficult to obtain by methods that rely on known surface features, structured light, or silhouettes. Multispectral photometric stereo is an attractive alternative because it can recover a dense normal field from an untextured surface. We show how to capture such data, which in turn allows us to demonstrate the strengths and limitations of our simple frame-to-frame registration over time. Experiments were performed on monocular video sequences of untextured cloth and faces with and without white makeup. Subjects were filmed under spatially separated red, green, and blue lights. Our first finding is that the color photometric stereo setup is able to produce smoothly varying per-frame reconstructions with high detail. Second, when these 3D reconstructions are augmented with 2D tracking results, one can register both the surfaces and relax the homogenous-color restriction of the single-hue subject. Quantitative and qualitative experiments explore both the practicality and limitations of this simple multispectral capture system.	[Brostow, Gabriel J.] UCL, Dept Comp Sci, London WC1E 6BT, England; [Hernandez, Carlos] Google Inc, Seattle, WA 98103 USA; [Vogiatzis, George] Aston Univ, Sch Engn & Appl Sci, Dept Comp Sci, Birmingham B4 7ET, W Midlands, England; [Stenger, Bjoern] Toshiba Res Europe Ltd, Cambridge CB4 0GZ, England; [Cipolla, Roberto] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	University of London; University College London; Google Incorporated; Aston University; Toshiba Corporation; University of Cambridge	Brostow, GJ (corresponding author), UCL, Dept Comp Sci, Gower St, London WC1E 6BT, England.	G.Brostow@cs.ucl.ac.uk; carloshernandez@google.com; g.vogiatzis@aston.co.uk; bjorn.stenger@crl.toshiba.co.uk; cipolla@eng.cam.ac.uk	Arandjelović, Ognjen/V-5255-2019; Brostow, Gabriel/S-1464-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Brostow, Gabriel/0000-0001-8472-3828; Vogiatzis, George/0000-0002-3226-0603; Cipolla, Roberto/0000-0002-8999-2151				Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626; Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777; BHAT KS, 2003, P ACM SIGGRAPH EUR S, P37; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054; Bradley D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778778; Bradley D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360698; Chang W, 2008, COMPUT GRAPH FORUM, V27, P1459, DOI 10.1111/j.1467-8659.2008.01286.x; de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697; Drew MS, 1996, COMPUT VIS IMAGE UND, V64, P286, DOI 10.1006/cviu.1996.0059; DREW MS, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P985, DOI 10.1109/CVPR.1994.323939; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Furukawa Y, 2009, IEEE I CONF COMP VIS, P80, DOI 10.1109/ICCV.2009.5459145; GOLDMAN DB, 2005, ICCV 05, V1, P341; GU X, 2006, P ACM S SOL PHYS MOD, P129; Hartley R., 2004, ROBOTICA; Hernandez C., 2007, P 11 IEEE INT C COMP; HERNANDEZ C, 2010, P INT S 3DPVT; Hernandez C, 2008, LECT NOTES COMPUT SC, V5302, P290, DOI 10.1007/978-3-540-88682-2_23; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Hernandez C, 2007, IEEE T PATTERN ANAL, V29, P343, DOI 10.1109/TPAMI.2007.42; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Hertzmann A, 2003, PROC CVPR IEEE, P533; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Johnson MK, 2009, PROC CVPR IEEE, P1070, DOI 10.1109/CVPRW.2009.5206534; KONTSEVICH LL, 1994, J OPT SOC AM A, V11, P1047, DOI 10.1364/JOSAA.11.001047; Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849; Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862; Li H, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1618521, 10.1145/1618452.1618503]; Lim J, 2005, IEEE I CONF COMP VIS, P1635; Ma W., 2007, P EUR S REND; Ma WC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409074; Mac Aodha O., 2010, P IEEE C COMP VIS PA; Malzbender T, 2006, P EUR S REND; Mitra N. J., 2007, SGP, P173; ONN R, 1990, INT J COMPUT VISION, V5, P105, DOI 10.1007/BF00056773; Paterson JA, 2005, COMPUT GRAPH FORUM, V24, P383, DOI 10.1111/j.1467-8659.2005.00863.x; Pekelny Y, 2008, COMPUT GRAPH FORUM, V27, P399, DOI 10.1111/j.1467-8659.2008.01137.x; Petrov A., 1987, COGNITIVE PROCESS, P350; PILET J, 2005, P IEEE CS C COMP VIS; POPA T, 2010, P EUR S GEOM PROC; Pritchard D, 2003, COMPUT GRAPH FORUM, V22, P263, DOI 10.1111/1467-8659.00673; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; SALZMANN M, 2005, P BRIT MACH VIS C; Sand P, 2003, ACM T GRAPHIC, V22, P578, DOI 10.1145/882262.882310; Scholz V, 2005, COMPUT GRAPH FORUM, V24, P439, DOI 10.1111/j.1467-8659.2005.00869.x; Seitz S., 2006, P CVPR 06 IE COMP SO, V1, P519, DOI DOI 10.1109/CVPR.2006.19; Sharf A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409063; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; Sinha P., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P156, DOI 10.1109/ICCV.1993.378224; Sinha SN, 2004, PROC CVPR IEEE, P195; Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68; Sussmuth J, 2008, COMPUT GRAPH FORUM, V27, P1469, DOI 10.1111/j.1467-8659.2008.01287.x; Tagliasacchi A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531377; Vlasic D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618520; Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696; Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712; Wand M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1516522.1516526; WANG XC, 2002, SCA 02, P129; Weise T, 2007, P IEEE C COMP VIS PA; WHITE R, 2006, P 9 EUR C COMP VIS, P70; WHITE R, 2007, P ACM SIGGRAPH; Wilson CA, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731055; WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759; Zheng Q, 2010, COMPUT GRAPH FORUM, V29, P635, DOI 10.1111/j.1467-8659.2009.01633.x; 2011, CMU GRAPHICS LAB MOT	70	28	30	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					2104	2114		10.1109/TPAMI.2011.37	http://dx.doi.org/10.1109/TPAMI.2011.37			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21339525	Green Accepted, Green Submitted			2022-12-18	WOS:000293969000016
J	Pozo, JM; Villa-Uriol, MC; Frangi, AF				Mari Pozo, Jose; Villa-Uriol, Maria-Cruz; Frangi, Alejandro F.			Efficient 3D Geometric and Zernike Moments Computation from Unstructured Surface Meshes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image analysis; geometric moments; 3D Zernike moments; shape characterization; object characterization	INTEGRATION; FORMULAS; POLYNOMIALS; POLYHEDRA; ACCURACY	This paper introduces and evaluates a fast exact algorithm and a series of faster approximate algorithms for the computation of 3D geometric moments from an unstructured surface mesh of triangles. Being based on the object surface reduces the computational complexity of these algorithms with respect to volumetric grid-based algorithms. In contrast, it can only be applied for the computation of geometric moments of homogeneous objects. This advantage and restriction is shared with other proposed algorithms based on the object boundary. The proposed exact algorithm reduces the computational complexity for computing geometric moments up to order N with respect to previously proposed exact algorithms, from N-9 to N-6. The approximate series algorithm appears as a power series on the rate between triangle size and object size, which can be truncated at any desired degree. The higher the number and quality of the triangles, the better the approximation. This approximate algorithm reduces the computational complexity to N-3. In addition, the paper introduces a fast algorithm for the computation of 3D Zernike moments from the computed geometric moments, with a computational complexity N-4, while the previously proposed algorithm is of order N6. The error introduced by the proposed approximate algorithms is evaluated in different shapes and the cost-benefit ratio in terms of error, and computational time is analyzed for different moment orders.	[Mari Pozo, Jose; Villa-Uriol, Maria-Cruz; Frangi, Alejandro F.] Univ Pompeu Fabra, DTIC, Ctr Computat Imaging & Simulat Technol Biomed CIS, Barcelona 08018, Spain; [Mari Pozo, Jose; Villa-Uriol, Maria-Cruz; Frangi, Alejandro F.] CIBER BBN, Networking Ctr Biomed Research, E-08018 Barcelona, Spain; [Frangi, Alejandro F.] ICREA, E-08018 Barcelona, Spain	Pompeu Fabra University; CIBER - Centro de Investigacion Biomedica en Red; CIBERBBN; ICREA	Pozo, JM (corresponding author), Univ Pompeu Fabra, DTIC, Ctr Computat Imaging & Simulat Technol Biomed CIS, C Roc Boronat 138 Tanger Blg, Barcelona 08018, Spain.	jose.pozo@upf.edu; cruz.villa@upf.edu; alejandro.frangi@upf.edu	Pozo, Jose M/M-7604-2016; Pozo, Jose M M/F-5741-2016; Villa-Uriol, Maria-Cruz/AAZ-4851-2020; Villa-Uriol, Maria-Cruz/I-5581-2015; Frangi, Alejandro F/C-6500-2008	Pozo, Jose M/0000-0002-0759-3510; Pozo, Jose M M/0000-0002-0759-3510; Villa-Uriol, Maria-Cruz/0000-0002-3345-539X; Villa-Uriol, Maria-Cruz/0000-0002-3345-539X; Frangi, Alejandro F/0000-0002-2675-528X	Philips Healthcare (Best, The Netherlands); European Commission [IST-027703]; Spanish Ministry of Industry; Spanish Ministry of Science and Innovation (MICINN) [TIN2009-14536-C02-01]; European Regional Development Fund (ERDF); ICREA Funding Source: Custom	Philips Healthcare (Best, The Netherlands)(Netherlands Government); European Commission(European CommissionEuropean Commission Joint Research Centre); Spanish Ministry of Industry(Spanish Government); Spanish Ministry of Science and Innovation (MICINN)(Ministry of Science and Innovation, Spain (MICINN)Spanish Government); European Regional Development Fund (ERDF)(European Commission); ICREA(ICREA)	The authors would like to thank the valuable and constructive comments from the anonymous reviewers. This work was partially supported by Philips Healthcare (Best, The Netherlands), the @neurIST Integrated Project (cofinanced by the European Commission through contract no. IST-027703), the CDTI CENIT-CDTEAM grant funded by the Spanish Ministry of Industry, and the research project STIMATH (TIN2009-14536-C02-01) funded by the Spanish Ministry of Science and Innovation (MICINN) and the European Regional Development Fund (ERDF).	Attene M, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P271; BERNARDINI F, 1991, COMPUT AIDED DESIGN, V23, P51, DOI 10.1016/0010-4485(91)90081-7; BEST GC, 1964, MATH COMPUT, V18, P310, DOI 10.2307/2003308; Canterakis N., 1999, P SCANDINAVIAN C IMA, P85; CANTERAKIS N, 1997, 597 A LUDW U I INF; CATTANI C, 1990, COMPUT AIDED DESIGN, V22, P130, DOI 10.1016/0010-4485(90)90007-Y; DiCarlo A, 2006, COMPUT AIDED DESIGN, V38, P1145, DOI 10.1016/j.cad.2006.03.005; Flusser J, 2006, PROC WRLD ACAD SCI E, V11, P196; GELLERT M, 1991, COMMUN APPL NUMER M, V7, P487, DOI 10.1002/cnm.1630070609; Gonzalez-Ochoa C, 1998, ACM T GRAPHIC, V17, P143, DOI 10.1145/285857.285858; HAMMER PC, 1956, MATH TABLES AIDS COM, V10, P130, DOI DOI 10.2307/2002483; Hillion P., 1981, Calcolo, V18, P117, DOI 10.1007/BF02576492; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; LI BC, 1993, PATTERN RECOGN, V26, P1229, DOI 10.1016/0031-3203(93)90207-D; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809; LIEN SL, 1984, IEEE COMPUT GRAPH, V4, P35, DOI 10.1109/MCG.1984.6429334; LIGGETT JA, 1988, COMMUN APPL NUMER M, V4, P815, DOI 10.1002/cnm.1630040616; Millan RD, 2007, IEEE T MED IMAGING, V26, P1270, DOI 10.1109/TMI.2007.901008; Mirtich B., 1996, J GRAPHICS TOOLS, V1, P31, DOI DOI 10.1080/10867651.1996.10487458; Mukundan R., 1998, MOMENT FUNCTIONS IMA; Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005; Rathod HT, 2007, APPL MATH COMPUT, V191, P397, DOI 10.1016/j.amc.2007.02.104; RATHOD HT, 1995, COMPUT METHOD APPL M, V126, P373, DOI 10.1016/0045-7825(95)00828-O; Rodtook S, 2005, IMAGE VISION COMPUT, V23, P577, DOI 10.1016/j.imavis.2005.02.001; Sheynin SA, 2001, PATTERN RECOGN LETT, V22, P1103, DOI 10.1016/S0167-8655(01)00067-8; Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504; STROUD AH, 1964, MATH COMPUT, V18, P590, DOI 10.2307/2002945; TEH CH, 1986, COMPUT VISION GRAPH, V33, P318, DOI 10.1016/0734-189X(86)90180-5; TIMMER HG, 1980, COMPUT AIDED DESIGN, V12, P301, DOI 10.1016/0010-4485(80)90093-7; Tuzikov AV, 2003, PATTERN RECOGN, V36, P2521, DOI 10.1016/S0031-3203(03)00127-4; Wang Qiuting, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P73, DOI 10.1109/CSSE.2008.828; Yang L, 1997, GRAPH MODEL IM PROC, V59, P97, DOI 10.1006/gmip.1997.0418	33	28	29	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					471	484		10.1109/TPAMI.2010.139	http://dx.doi.org/10.1109/TPAMI.2010.139			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	20714011	Green Accepted			2022-12-18	WOS:000286204700004
J	Adato, Y; Vasilyev, Y; Zickler, T; Ben-Shahar, O				Adato, Yair; Vasilyev, Yuriy; Zickler, Todd; Ben-Shahar, Ohad			Shape from Specular Flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Specular objects; specular flow; shape reconstruction; environment motion field; Gaussian curvature; parabolic points; specular curvature	SURFACE; REFLECTION	An image of a specular (mirror-like) object is nothing but a distorted reflection of its environment. When the environment is unknown, reconstructing shape from such an image can be very difficult. This reconstruction task can be made tractable when, instead of a single image, one observes relative motion between the specular object and its environment, and therefore, a motion field-or specular flow-in the image plane. In this paper, we study the shape from specular flow problem and show that observable specular flow is directly related to surface shape through a nonlinear partial differential equation. This equation has the key property of depending only on the relative motion of the environment while being independent of its content. We take first steps toward understanding and exploiting this PDE, and we examine its qualitative properties in relation to shape geometry. We analyze several cases in which the surface shape can be recovered in closed form, and we show that, under certain conditions, specular shape can be reconstructed when both the relative motion and the content of the environment are unknown. We discuss numerical issues related to the proposed reconstruction algorithms, and we validate our findings using both real and synthetic data.	[Adato, Yair; Ben-Shahar, Ohad] Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel; [Vasilyev, Yuriy; Zickler, Todd] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA	Ben Gurion University; Harvard University	Adato, Y (corresponding author), Ben Gurion Univ Negev, Dept Comp Sci, POB 653, IL-84105 Beer Sheva, Israel.	adato@cs.bgu.ac.il; vasilyev@fas.harvard.edu; zickler@eecs.harvard.edu; ben-shahar@cs.bgu.ac.il	Ben-Shahar, Ohad/F-8918-2015	Ben-Shahar, Ohad/0000-0001-5346-152X	Israel Science Foundation [1245/08]; US National Science Foundation (NSF) [IIS-0712956]; NSF [IIS-0546408]	Israel Science Foundation(Israel Science Foundation); US National Science Foundation (NSF)(National Science Foundation (NSF)); NSF(National Science Foundation (NSF))	This research is supported by the Israel Science Foundation under grant no. 1245/08 and the US National Science Foundation (NSF) under grant no. IIS-0712956. Ohad Ben-Shahar and Yair Adato also thank the generous support of the Frankel Fund and the Paul Ivanier Robotics Center at Ben-Gurion University. Additional funding for Todd Zickler and Yriy Vasilyev was provided by the NSF under CAREER Award IIS-0546408.	Agarwal S, 2004, LECT NOTES COMPUT SC, V3022, P483; Baker S., 2007, P IEEE INT C COMP VI; Ben-Shahar O, 2003, IEEE T PATTERN ANAL, V25, P401, DOI 10.1109/TPAMI.2003.1190568; BLAKE A, 1991, PHILOS T R SOC B, V331, P237, DOI 10.1098/rstb.1991.0012; BLAKE A, 1990, NATURE, V343, P165, DOI 10.1038/343165a0; BLAKE A, 1988, P IEEE INT C COMP VI; BLAKE A, 1985, P INT JOINT C ART IN, P973; Bonfort T, 2006, LECT NOTES COMPUT SC, V3852, P872; DELPPOZO A, 2007, P IEEE C COMP VIS PA; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Drbohlav O, 2005, IEEE I CONF COMP VIS, P1850; DRBOHLAV O, 2000, P EUR C COMP VIS, P46; Fleming RW, 2004, J VISION, V4, P798, DOI 10.1167/4.9.10; Hartung B., 2002, JOURNAL, V2, P551, DOI DOI 10.1167/2.7.551; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Knauer MC, 2004, PROC SPIE, V5457, P366, DOI 10.1117/12.545704; KOENDERINK JJ, 1980, OPT ACTA, V27, P981, DOI 10.1080/713820338; Kutulakos KN, 2005, IEEE I CONF COMP VIS, P1448; Lellmann J, 2008, INT J COMPUT VISION, V80, P226, DOI 10.1007/s11263-007-0123-3; LONGUETHIGGINS MS, 1960, J OPT SOC AM, V50, P838, DOI 10.1364/JOSA.50.000838; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; NISTER D, 2005, P IEEE INT C COMP VI, V1; Oren M, 1997, INT J COMPUT VISION, V24, P105, DOI 10.1023/A:1007954719939; Osadchy M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1512; RAMAKRISHNAN V, 2005, P 11 INT C FRACT MAR, P20; Roth S., 2006, J VISION, V1, P1869, DOI [10.1167/3.9.413, DOI 10.1167/3.9.413]; ROTH S, 2006, P IEEE C COMP VIS PA, P1869; ROZENFELD S, 2007, P IEEE C COMP VIS PA; Savarese S, 2005, INT J COMPUT VISION, V64, P31, DOI 10.1007/s11263-005-1086-x; SAVARESE S, 2004, P S APPL PERC GRAPH; Solem JE, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P26, DOI 10.1109/TDPVT.2004.1335137; Tarini M, 2005, GRAPH MODELS, V67, P233, DOI 10.1016/j.gmod.2004.11.002; Waldon S., 1993, Proceedings of IEEE Workshop on Qualitative Vision (Cat. No.93TH0521-5), P61, DOI 10.1109/WQV.1993.262949; Weidenbacher U, 2006, ACM T APPL PERCEPT, V3, P262, DOI [10.1145/1166087.1166094, DOI 10.1145/1166087.1166094]; Zheng JY, 2000, IEEE T PATTERN ANAL, V22, P913, DOI 10.1109/34.868691; ZHENG JY, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P72, DOI 10.1109/ICCV.1995.466804; ZISSERMAN A, 1989, IMAGE VISION COMPUT, V7, P38, DOI 10.1016/0262-8856(89)90018-8; 2008, LIGHT PROBE GALLERY	40	28	30	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					2054	2070		10.1109/TPAMI.2010.126	http://dx.doi.org/10.1109/TPAMI.2010.126			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20847393	Green Submitted			2022-12-18	WOS:000281990900009
J	Zheng, B; Takamatsu, J; Ikeuchi, K				Zheng, Bo; Takamatsu, Jun; Ikeuchi, Katsushi			An Adaptive and Stable Method for Fitting Implicit Polynomial Curves and Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fitting algebraic curves and surfaces; implicit polynomial (IP); implicit shape representation	PARAMETRIC CURVES; ALGEBRAIC-CURVES; POSE ESTIMATION; 3D SURFACES; 2D CURVES; REPRESENTATION; RECOGNITION; OBJECTS	Representing 2D and 3D data sets with implicit polynomials (IPs) has been attractive because of its applicability to various computer vision issues. Therefore, many IP fitting methods have already been proposed. However, the existing fitting methods can be and need to be improved with respect to computational cost for deciding on the appropriate degree of the IP representation and to fitting accuracy, while still maintaining the stability of the fit. We propose a stable method for accurate fitting that automatically determines the moderate degree required. Our method increases the degree of IP until a satisfactory fitting result is obtained. The incrementability of QR decomposition with Gram-Schmidt orthogonalization gives our method computational efficiency. Furthermore, since the decomposition detects the instability element precisely, our method can selectively apply ridge regression-based constraints to that element only. As a result, our method achieves computational stability while maintaining fitting accuracy. Experimental results demonstrate the effectiveness of our method compared with prior methods.	[Zheng, Bo; Ikeuchi, Katsushi] Univ Tokyo, Ikeuchi Lab, Dept 3, Inst Ind Sci,Meguro Ku, Tokyo 1538505, Japan; [Takamatsu, Jun] Nara Inst Sci & Technol, Nara 6300192, Japan	University of Tokyo; Nara Institute of Science & Technology	Zheng, B (corresponding author), Univ Tokyo, Ikeuchi Lab, Dept 3, Inst Ind Sci,Meguro Ku, 4-6-1 Komaba, Tokyo 1538505, Japan.	zheng@cvl.iis.u-tokyo.ac.jp; j-taka@is.naist.jp; ki@cvl.iis.u-tokyo.ac.jp			Ministry of Education, Culture, Sports, Science and Technology Japan	Ministry of Education, Culture, Sports, Science and Technology Japan(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT))	This work is supported by the Ministry of Education, Culture, Sports, Science and Technology Japan under the Leading Project: Development of High-Fidelity Digitization Software for Large-Scale and Intangible Cultural Assets.	Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; Golub GH, 1999, SIAM J MATRIX ANAL A, V21, P185, DOI 10.1137/S0895479897326432; GOSHTASBY A, 1993, INT J COMPUT VISION, V10, P233, DOI 10.1007/BF01539537; Helzer A, 2004, IEEE T PATTERN ANAL, V26, P1283, DOI 10.1109/TPAMI.2004.91; Helzer A, 2000, 21ST IEEE CONVENTION OF THE ELECTRICAL AND ELECTRONIC ENGINEERS IN ISRAEL - IEEE PROCEEDINGS, P384, DOI 10.1109/EEEI.2000.924441; Horn R. A., 1986, MATRIX ANAL; Kang KB, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P198, DOI 10.1109/ICCV.2001.937518; Keren D, 2004, IEEE T PATTERN ANAL, V26, P118, DOI 10.1109/TPAMI.2004.1261095; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P1143, DOI 10.1109/34.334397; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; KHAN N, 2007, THESIS SAARLAND U; KNANATANI K, 1994, INFO COMM ENG IEICE, V35, P201; Lei ZB, 1998, IEEE T PATTERN ANAL, V20, P212, DOI 10.1109/34.659942; Lei ZB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P827, DOI 10.1109/ICCV.1998.710813; Lei ZB, 1996, PROC CVPR IEEE, P514, DOI 10.1109/CVPR.1996.517120; Marola G, 2005, IEEE T PATTERN ANAL, V27, P465, DOI 10.1109/TPAMI.2005.45; Oden C, 2003, PATTERN RECOGN LETT, V24, P2145, DOI 10.1016/S0167-8655(03)00087-4; PIEGL L, 1991, IEEE COMPUT GRAPH, V11, P55, DOI 10.1109/38.67702; Redding NJ, 2000, IEEE T PATTERN ANAL, V22, P191, DOI 10.1109/34.825757; Sahin T, 2005, IEEE I CONF COMP VIS, P1083; SEDERBERG TW, 1984, COMPUT VISION GRAPH, V28, P72, DOI 10.1016/0734-189X(84)90140-3; Subrahmonia J, 1996, IEEE T PATTERN ANAL, V18, P505, DOI 10.1109/34.494640; Tarel J.-P., 1998, P IEEE WORKSH MOD BA, P13; Tarel JP, 2000, IEEE T PATTERN ANAL, V22, P663, DOI 10.1109/34.865183; Tasdizen T, 2000, IEEE T IMAGE PROCESS, V9, P405, DOI 10.1109/83.826778; Tasdizen T, 2000, INT C PATT RECOG, P225, DOI 10.1109/ICPR.2000.905308; TAUBIN G, 1994, IEEE T PATTERN ANAL, V16, P287, DOI 10.1109/34.276128; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; TAUBIN G, 1992, SYMBOLIC NUMERICAL C, pCH6; TURK G, 1999, GITGVU9915 GEORG TU; Unel M, 2000, ADV APPL MATH, V24, P65, DOI 10.1006/aama.1999.0679; UNSALAN C, 1999, P INT C MECH MACH VI; Unsalan C, 2007, PATTERN RECOGN LETT, V28, P49, DOI 10.1016/j.patrec.2006.06.003; Wolovich WA, 1998, IEEE T PATTERN ANAL, V20, P1080, DOI 10.1109/34.722620; Yalcin H, 2003, INT J COMPUT VISION, V54, P105, DOI 10.1023/A:1023757417916; ZHENG B, 2008, P IEEE C COMP VIS PA; ZHENG B, 2008, IEICE T INFORM SYS D, V91	39	28	33	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2010	32	3					561	568		10.1109/TPAMI.2009.189	http://dx.doi.org/10.1109/TPAMI.2009.189			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	543WG	20075478				2022-12-18	WOS:000273609600012
J	Zhu, L; Chen, YH; Yuille, A				Zhu, Long (Leo); Chen, Yuanhao; Yuille, Alan			Unsupervised Learning of Probabilistic Grammar-Markov Models for Object Categories	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; structural models; grammars; Markov random fields; object recognition	SCALE	We introduce a Probabilistic Grammar-Markov Model (PGMM) which couples probabilistic context-free grammars and Markov Random Fields. These PGMMs are generative models defined over attributed features and are used to detect and classify objects in natural images. PGMMs are designed so that they can perform rapid inference, parameter learning, and the more difficult task of structure induction. PGMMs can deal with unknown 2D pose (position, orientation, and scale) in both inference and learning, different appearances, or aspects of the model. The PGMMs can be learned in an unsupervised manner, where the image can contain one of an unknown number of objects of different categories or even be pure background. We first study the weakly supervised case, where each image contains an example of the (single) object of interest, and then generalize to less supervised cases. The goal of this paper is theoretical, but, to provide proof of concept, we demonstrate results from this approach on a subset of the Caltech data set (learning on a training set and evaluating on a testing set). Our results are generally comparable with the current state of the art and our inference is performed in less than five seconds.	[Zhu, Long (Leo); Yuille, Alan] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Chen, Yuanhao] Univ Sci & Technol China, Dept Automat, Hefei 230026, Peoples R China	University of California System; University of California Los Angeles; Chinese Academy of Sciences; University of Science & Technology of China, CAS	Zhu, L (corresponding author), Univ Calif Los Angeles, Dept Stat, 8125 Math Sci Bldg, Los Angeles, CA 90095 USA.	lzhu@stat.ucla.edu; yhchen4@ustc.edu; yuille@stat.ucla.edu		Yuille, Alan L./0000-0001-5207-9249	W. M. Keck Foundation; US National Science Foundation [0413214]; US National Institutes of Health [RO1 EY015261]; NATIONAL EYE INSTITUTE [R01EY015261] Funding Source: NIH RePORTER	W. M. Keck Foundation(W.M. Keck Foundation); US National Science Foundation(National Science Foundation (NSF)); US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI))	The authors gratefully acknowledge the support from the W. M. Keck Foundation, the US National Science Foundation with NSF Grant 0413214, and the US National Institutes of Health Grant RO1 EY015261. They thank Ying-Nian Wu and Song-Chun Zhu for the stimulating discussions. They also thank SongFeng Zheng and Shuang Wu for the helpful feedback on the drafts of this paper.	Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; [Anonymous], P 20 C UNC ART INT U; Barlow HB, 1989, NEURAL COMPUT, V1, P295, DOI 10.1162/neco.1989.1.3.295; Chen B, 2006, PHOTOCH PHOTOBIO SCI, V5, P943, DOI 10.1039/b611915h; Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842; Crandall D, 2005, PROC CVPR IEEE, P10; Crandall DJ, 2006, LECT NOTES COMPUT SC, V3951, P16; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; DECHTER H, 2006, ARTIFICIAL INTELLIGE; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; Fei-Fei L., 2004, P IEEE INT C COMP VI; Fergus R, 2005, PROC CVPR IEEE, P380; Fergus R, 2003, PROC CVPR IEEE, P264; FRIEDMAN N, 1998, P 14 ANN C UNC ART I, P13; Jensen F. V., 1990, Computational Statistics Quarterly, V5, P269; Jin Y., 2006, CVPR, V2, P2145; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Klein Dan, 2002, ADV NEURAL INFORM PR; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; LAZEBNIK S, 2004, P BRIT MACH VIS C; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Manning CD, 1999, FDN STAT NATURAL LAN; McCallum A., 2003, P 19 C UNC ART INT, P403; Meila M, 2001, J MACH LEARN RES, V1, P1, DOI 10.1162/153244301753344605; Neal R., 1998, VIEW EM ALGORITHM JU; PONCE J, 2006, DATASET ISSUES OBJEC; Ripley BD., 1996; Shams L, 1999, NEUROCOMPUTING, V26-7, P855, DOI 10.1016/S0925-2312(98)00130-1; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Zettlemoyer Luke S., 2005, P 21 C UNC ART INT, P658, DOI DOI 10.3115/1690219.1690283; ZHU L, 2007, ADV NEURAL INFORM PR, V19; ZHU S, 1997, NEURAL COMPUTATION, V9	32	28	29	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					114	128		10.1109/TPAMI.2008.67	http://dx.doi.org/10.1109/TPAMI.2008.67			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029550	Green Submitted			2022-12-18	WOS:000260889700010
J	Yousef, WA; Wagner, RF; Loew, MH				Yousef, Waleed A.; Wagner, Robert F.; Loew, Murray H.			Assessing classifiers from two independent data sets using ROC analysis: A nonparametric approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; nonparametric statistics; ROC analysis	VALIDATION; VARIANCE; AREA	This paper considers binary classification. We assess a classifier in terms of the Area Under the ROC Curve (AUC). We estimate three important parameters, the conditional AUC (conditional on a particular training set) and the mean and variance of this AUC. We derive, as well, a closed form expression of the variance of the estimator of the AUC. This expression exhibits several components of variance that facilitate an understanding for the sources of uncertainty of that estimate. In addition, we estimate this variance, i.e., the variance of the conditional AUC estimator. Our approach is nonparametric and based on general methods from U-statistics; it addresses the case where the data distribution is neither known nor modeled and where there are only two available data sets, the training and testing sets. Finally, we illustrate some simulation results for these estimators.	US FDA, CDRH, Rockville, MD 20852 USA; George Washington Univ, Washington, DC 20052 USA	US Food & Drug Administration (FDA); George Washington University	Yousef, WA (corresponding author), US FDA, CDRH, 12720 Twinbrook Pkwy, Rockville, MD 20852 USA.	wyousef@aucegypt.edu; Robert.Wagner@fda.hhs.gov; loew@gwu.edu	Yousef, Waleed/A-9082-2009; Yousef, Waleed A./AAN-1775-2021	Yousef, Waleed A./0000-0001-9669-7241				BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2; Barrett HH, 2005, P SOC PHOTO-OPT INS, V5749, P21, DOI 10.1117/12.595685; Barrett HH., 2003, FDN IMAGE SCI; Beiden SV, 2003, IEEE T PATTERN ANAL, V25, P1561, DOI 10.1109/TPAMI.2003.1251149; CAMPBELL G, 1988, P COMP CARD WASH DC, P267; Casella G., 1998, THEORY POINT ESTIMAT; Casella G, 2002, DUXBURY; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Gallas BD, 2006, ACAD RADIOL, V13, P353, DOI 10.1016/j.acra.2005.11.030; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Lee A.J., 2019, U STAT THEORY PRACTI; Lehmann E., 2005, TESTING STAT HYPOTHE, V3rd; Noether GE., 1967, ELEMENTS NONPARAMETR; Randles R, 1979, INTRO THEORY NONPARA; Raudys S., 2001, STAT NEURAL CLASSIFI, P209, DOI [10.1007/978-1-4471-0359-2_6, DOI 10.1007/978-1-4471-0359-2_6]; Roe CA, 1997, ACAD RADIOL, V4, P298, DOI 10.1016/S1076-6332(97)80032-3; Roe CA, 1997, ACAD RADIOL, V4, P587, DOI 10.1016/S1076-6332(97)80210-3; STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x; Yousef W. A., 2004, Proceedings. 33rd Applied Imagery Pattern Recognition Workshop, P190; Yousef WA, 2005, PATTERN RECOGN LETT, V26, P2600, DOI 10.1016/j.patrec.2005.06.006; YOUSEF WA, UNPUB PATTERN RECOGN; YOUSEF WA, 2006, THESIS GEORGE WASHIN	25	28	30	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1809	1817		10.1109/TPAMI.2006.218	http://dx.doi.org/10.1109/TPAMI.2006.218			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063685				2022-12-18	WOS:000240443400008
J	Goldberger, J; Greenspan, H				Goldberger, J; Greenspan, H			Context-based segmentation of image sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image-sequence analysis; video segmentation; model adaptation; conjugate prior; MAP; context-based segmentation		We describe an algorithm for context-based segmentation of visual data. New frames in an image sequence ( video) are segmented based on the prior segmentation of earlier frames in the sequence. The segmentation is performed by adapting a probabilistic model learned on previous frames, according to the content of the new frame. We utilize the maximum a posteriori version of the EM algorithm to segment the new image. The Gaussian mixture distribution that is used to model the current frame is transformed into a conjugate-prior distribution for the parametric model describing the segmentation of the new frame. This semisupervised method improves the segmentation quality and consistency and enables a propagation of segments along the segmented images. The performance of the proposed approach is illustrated on both simulated and real image data.	Bar Ilan Univ, Sch Engn, IL-52900 Ramat Gan, Israel; Tel Aviv Univ, Fac Engn, Dept Biomed Engn, IL-69978 Tel Aviv, Israel	Bar Ilan University; Tel Aviv University	Goldberger, J (corresponding author), Bar Ilan Univ, Sch Engn, IL-52900 Ramat Gan, Israel.	goldbej@engbiu.ac.il; hayit@eng.tau.ac.il						AGARWAL S, 2002, SEGMENTATION EXAMPLE; BORENSTEIN E, 2002, P EUR C COMP VIS, P109; BREGLER C, 1997, P IEEE C COMP VIS PA; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507; Deng YN, 1998, IEEE T CIRC SYST VID, V8, P616, DOI 10.1109/76.718508; DUC B, 1995, P 6 INT C COMP AN IM, P238; Duygulu P., 2002, P EUR C COMP VIS; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Greenspan H, 2004, COMPUT VIS IMAGE UND, V93, P86, DOI 10.1016/j.cviu.2003.08.004; Greenspan H, 2001, COMPUT VIS IMAGE UND, V84, P384, DOI 10.1006/cviu.2001.0946; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KaewTraKulPong P., 2001, P EUR WORKSH ADV VID; Khan S, 2001, PROC CVPR IEEE, P746; McKenna SJ, 2004, INT C PATT RECOG, P138, DOI 10.1109/ICPR.2004.1333723; MCKENNA SJ, 1998, P ACCV 98, P615; MEGRET R, 2002, UMIACS200283; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; WANG JYA, 1994, P SOC PHOTO-OPT INS, V2182, P120, DOI 10.1117/12.174204; WEISS Y, 1999, P INT C COMP VIS; [No title captured]	23	28	28	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					463	468		10.1109/TPAMI.2006.47	http://dx.doi.org/10.1109/TPAMI.2006.47			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526431	Green Submitted			2022-12-18	WOS:000234517900011
J	Wang, J; Dana, KJ				Wang, J; Dana, KJ			Relief texture from specularities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture; relief texture; BTF; bidirectional texture function; 3D texture; shape from specularity; curved mirror; reflectance; roughness	MODEL; REFLECTANCE; RANGE; SHAPE	In vision and graphics, advanced object models require not only 3D shape, but also surface detail. While several scanning devices exist to capture the global shape of an object, few methods concentrate on capturing the fine-scale detail. Fine-scale surface geometry (relief texture), such as surface markings, roughness, and imprints, is essential in highly realistic rendering and accurate prediction. We present a novel approach for measuring the relief texture of specular or partially specular surfaces using a specialized imaging device with a concave parabolic mirror to view multiple angles in a single image. Laser scanning typically fails for specular surfaces because of light scattering, but our method is explicitly designed for specular surfaces. Also, the spatial resolution of the measured geometry is significantly higher than standard methods, so very small surface details are captured. Furthermore, spatially varying reflectance is measured simultaneously, i.e., both texture color and texture shape are retrieved.	Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA	Rutgers State University New Brunswick	Wang, J (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, 94 Brett Rd, Piscataway, NJ 08854 USA.	jingwang@caip.rutgers.edu; kdana@caip.rutgers.edu						BASRI R, 2001, P IEEE C COMP VIS PA; Bernardini F, 2002, IEEE COMPUT GRAPH, V22, P59, DOI 10.1109/38.974519; Bernardini F, 2001, IEEE T VIS COMPUT GR, V7, P318, DOI 10.1109/2945.965346; CHEN RL, 1988, J FRESHWATER ECOL, V4, P279, DOI 10.1080/02705060.1988.9665177; Cula OG, 2001, PROC CVPR IEEE, P1041; CULA OG, 2004, INT J COMPUTER VISIO, V59; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Dana KJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P460, DOI 10.1109/ICCV.2001.937661; DANAAND KJ, 2004, J OPTICAL SOC A  JAN, P1; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; DONG J, 2002, P TEXT 2002 2 INT WO, P41; Gardner A, 2003, ACM T GRAPHIC, V22, P749, DOI 10.1145/882262.882342; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; HALSTEAD MA, 1996, P ACM SIGGRAPH, P335; Hawkins T., 2001, P C VIRT REAL ARCH C, P333; Hertzmann A, 2003, PROC CVPR IEEE, P533; Koenderink JJ, 1996, J OPT SOC AM A, V13, P452, DOI 10.1364/JOSAA.13.000452; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P129, DOI 10.1023/A:1008061730969; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849; Liu XG, 2001, COMP GRAPH, P97; MATUSIK W, 2002, P ACM SIGGRAPH, P427; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P208, DOI 10.1109/70.54736; PONT SC, 2002, P EUR C COMP VIS, P808; Rushmeier H., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P81; RUSINKIEWICZ S, 2002, P SIGGRAPH, P438; Saito H, 2003, IMAGE VISION COMPUT, V21, P777, DOI 10.1016/S0262-8856(03)00091-X; Savarese S, 2001, PROC CVPR IEEE, P738; SAVARESE S, 2004, P 8 EUR C COMP VIS, P468; SAVARESE S, 2002, P EUR C COMP VIS, V2, P759; SEITZ SM, 1996, P SIGGRAPH 96, P21; Stamos I, 2000, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2000.855865; Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255; Wang J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1374, DOI 10.1109/ICCV.2003.1238650; WANG J, 2004, P IEEE C COMP VIS PA; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Yu YZ, 2001, IEEE T VIS COMPUT GR, V7, P351, DOI 10.1109/2945.965349; Zalesny A, 2001, PROC CVPR IEEE, P615; Zheng JY, 2000, IEEE T PATTERN ANAL, V22, P913, DOI 10.1109/34.868691	43	28	30	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					446	457		10.1109/TPAMI.2006.63	http://dx.doi.org/10.1109/TPAMI.2006.63			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526429				2022-12-18	WOS:000234517900009
J	Okatani, T; Deguchi, K				Okatani, T; Deguchi, K			Autocalibration of a projector-camera system	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						camera calibration; imaging geometry; projector-camera system; autocalibration; homography		This paper presents a method for calibrating a projector-camera system that consists of multiple projectors (or multiple poses of a single projector), a camera, and a planar screen. We consider the problem of estimating the homography between the screen and the image plane of the camera or the screen-camera homography, in the case where there is no prior knowledge regarding the screen surface that enables the direct computation of the homography. It is assumed that the pose of each projector is unknown while its internal geometry is known. Subsequently, it is shown that the screen-camera homography can be determined from only the images projected by the projectors and then obtained by the camera, up to a transformation with four degrees of freedom. This transformation corresponds to arbitrariness in choosing a two-dimensional coordinate system on the screen surface and when this coordinate system is chosen in some manner, the screen-camera homography as well as the unknown poses of the projectors can be uniquely determined. A noniterative algorithm is presented, which computes the homography from three or more images. Several experimental results on synthetic as well as real images are shown to demonstrate the effectiveness of the method.	Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, Sendai, Miyagi 9808579, Japan	Tohoku University	Okatani, T (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, 6-6-09 Aramaki Aza, Sendai, Miyagi 9808579, Japan.	okatani@fractal.is.tohoku.ac.jp; kodeg@fractal.is.tohoku.ac.jp	Okatani, Takayuki/AAE-3339-2019					Chen YQ, 2000, IEEE VISUAL, P125, DOI 10.1109/VISUAL.2000.885685; HARTLEY R, 2000, MULTIVIEW GEOMETRY C; HEYDEN A, 1998, P AS C COMP VIS, P169; HEYDEN A, 1999, P IEEE INT C COMP VI, P438; Kanatani K., 1993, GEOMETRIC COMPUTATIO; Raskar R, 2001, PROC CVPR IEEE, P504; Sukthankar R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P247, DOI 10.1109/ICCV.2001.937525	8	28	36	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1845	1855		10.1109/TPAMI.2005.235	http://dx.doi.org/10.1109/TPAMI.2005.235			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16355654				2022-12-18	WOS:000232532600001
J	Fish, RK; Ostendorf, M; Bernard, GD; Castanon, DA				Fish, RK; Ostendorf, M; Bernard, GD; Castanon, DA			Multilevel classification of milling tool wear with confidence estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tool wear; confidence; normalized cross entropy; HMM; sparsely-labeled training; machining; milling		An important problem during industrial machining operations is the detection and classification of tool wear. Past research in this area has demonstrated the effectiveness of various feature sets and binary classifiers. Here, the goal is to develop a classifier which makes use of the dynamic characteristics of tool wear in a metal milling application and which replaces the standard binary classification result with two outputs: a prediction of the wear level (quantized) and a gradient measure that is the posterior probability (or confidence) that the tool is worn given the observed feature sequence. The classifier tracks the dynamics of sensor data within a single cutting pass as well as the evolution of wear from sharp to dull. Different alternatives to parameter estimation with sparsely-labeled training data are proposed and evaluated. We achieve high accuracy across changing cutting conditions, even with a limited feature set drawn from a single sensor.	Eastern Nazarene Coll, Quincy, MA 02170 USA; Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA; Boeing Commercial Airplanes, Seattle, WA 98124 USA; Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA	University of Washington; University of Washington Seattle; Boeing; Boston University	Fish, RK (corresponding author), Eastern Nazarene Coll, 23 E Elm Ave, Quincy, MA 02170 USA.	fishr@enc.edu; mo@ee.washington.edu; gary.d.bernard@boeing.com; dac@bu.edu	BERNARD, GARY D/L-6655-2014	BERNARD, GARY D/0000-0001-7460-5123				ANDERSON DA, 1989, P SOC MAN ENG SME C; Atlas L, 2000, INT CONF ACOUST SPEE, P3887, DOI 10.1109/ICASSP.2000.860252; Chambers JM., 1992, STAT MODELS S; Chen YD, 1996, J DYN SYST-T ASME, V118, P635, DOI 10.1115/1.2801194; DAN L, 1990, INT J MACH TOOL MANU, V30, P579, DOI DOI 10.1016/0890-6955(90)90009-8; DU R, 1995, J ENG IND-T ASME, V117, P133, DOI 10.1115/1.2803287; EMEL E, 1988, ASME, V110, P137; FISH R, 2000, P ASME MANUFACTURING, V11, P111; Gunawardana A, 2001, COMPUT SPEECH LANG, V15, P15, DOI 10.1006/csla.2000.0151; HECK LP, 1991, INT CONF ACOUST SPEE, P1697, DOI 10.1109/ICASSP.1991.150631; Kim S, 1997, J MANUF SCI E-T ASME, V119, P118, DOI 10.1115/1.2836548; Leem CS, 1997, INT J PROD RES, V35, P1051, DOI 10.1080/002075497195533; Li S, 1996, J DYN SYST-T ASME, V118, P665, DOI 10.1115/1.2802341; Li XL, 1998, WEAR, V219, P145; Li XQ, 1998, J MANUF SCI E-T ASME, V120, P433, DOI 10.1115/1.2830144; Littlefair G, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P734, DOI 10.1109/ICNN.1995.487508; MCLAUGHLIN J, 1997, P SAE AER M; Niu YM, 1998, J MANUF SCI E-T ASME, V120, P807, DOI 10.1115/1.2830224; ODELL J, 1997, HTK BOOK; Owsley LMD, 1997, IEEE T SIGNAL PROCES, V45, P2787, DOI 10.1109/78.650105; Prickett PW, 1999, INT J MACH TOOL MANU, V39, P105, DOI 10.1016/S0890-6955(98)00020-0; Rabiner L., 1993, FUNDAMENTALS SPEECH; RANGWALA S, 1990, J ENG IND-T ASME, V112, P219, DOI 10.1115/1.2899578; *SANDV COR TECHN E, 1996, MOD MET CUTT A PRACT; Siu MH, 1999, COMPUT SPEECH LANG, V13, P299, DOI 10.1006/csla.1999.0126	25	28	29	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2003	25	1					75	85		10.1109/TPAMI.2003.1159947	http://dx.doi.org/10.1109/TPAMI.2003.1159947			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	628NL					2022-12-18	WOS:000180002300006
J	Tolle, CR; McJunkin, TR; Gorsich, DJ				Tolle, CR; McJunkin, TR; Gorsich, DJ			Suboptimal minimum cluster volume cover-based method for measuring fractal dimension	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fractal dimension; Fuzzy-C Means; suboptimal cover; box counting; clustering; texture analysis	IMPLEMENTATION; ALGORITHMS	A new method for calculating fractal dimension is developed in this paper. The method is based on the box dimension concept; however, it involves direct estimation of a suboptimal covering of the data set of interest. By finding a suboptimal cover, this method is better able to estimate the required number of covering elements for a given cover size than is the standard box counting algorithm. Moreover, any decrease in the error of the covering element count directly increases the accuracy of the fractal dimension estimation. In general, our method represents a mathematical dual to the standard box counting algorithm by not solving for the number of boxes used to cover a data set given the size of the box. Instead, the method chooses the number of covering elements and then proceeds to find the placement of smallest hyperellipsoids that fully covers the data set. This method involves a variant of the Fuzzy-C Means clustering algorithm, as well as the use of the Minimum Cluster Volume clustering algorithm. A variety of fractal dimension estimators using this suboptimal covering method are discussed. Finally, these methods are compared to the standard box counting algorithm and wavelet-decomposition methods for calculating fractal dimension by using one-dimensional cantor dust sets and a set of standard Brownian random fractal images.	Idaho Natl Engn & Environm Lab, Idaho Falls, ID 83415 USA; USA, Tank Automot Res Dev & Engn Ctr, Robot Lab, Warren, MI 48397 USA	United States Department of Energy (DOE); Idaho National Laboratory	Tolle, CR (corresponding author), Idaho Natl Engn & Environm Lab, POB 1625, Idaho Falls, ID 83415 USA.		McJunkin, Timothy/AAL-2822-2020; McJunkin, Timothy/G-8385-2011	McJunkin, Timothy/0000-0002-4987-9170				BASSINGTHWAIGHT.J, 1994, FRACTAL PHYSL; Blumofe RD, 1996, J PARALLEL DISTR COM, V37, P55, DOI 10.1006/jpdc.1996.0107; CANNON RL, 1986, IEEE T PATTERN ANAL, V8, P248, DOI 10.1109/TPAMI.1986.4767778; DUBUC B, 1989, PHYS REV A, V39, P1500, DOI 10.1103/PhysRevA.39.1500; Dubuc B, 1996, SIAM J NUMER ANAL, V33, P602, DOI 10.1137/0733032; EBERT DS, 1994, TEXTURING MODELING P, P256; Foroutan-pour K, 1999, APPL MATH COMPUT, V105, P195, DOI 10.1016/S0096-3003(98)10096-6; FRIGO M, 1998, P ACM SIGPLAN 98 C P; GORSICH D, 1996, P 7 ANN GROUND VEH S; GORSICH D, 1996, P SPIE S AUG; Hartman P., 1964, ORDINARY DIFFERENTIA; JARDINE LF, 1993, APPL FRACTALS CHAOS, P101; JENG X, 2001, PATTERN RECOGN, V34, P151; JIN XC, 1995, PATTERN RECOGN LETT, V16, P457, DOI 10.1016/0167-8655(94)00119-N; Kreithen D. E., 1993, Lincoln Laboratory Journal, V6, P25; Krishnapuram R, 2000, IEEE T FUZZY SYST, V8, P228, DOI 10.1109/91.842156; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Mandelbrot BB, 1983, FRACTAL GEOMETRY NAT; ONEIL PV, 1987, ADV ENG MATH, P57; Peitgen H. O., 2004, NEW FRONTIERS SCI, DOI [10.1007/b97624, DOI 10.1007/B97624]; Summers RM, 1999, PROC SPIE, V3660, P258, DOI 10.1117/12.349595; TOLLE CR, 1996, P ROCK MOUNT NASA SP; TOLLE CR, 2000, UNPUB PHYSICA D	23	28	33	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2003	25	1					32	41		10.1109/TPAMI.2003.1159944	http://dx.doi.org/10.1109/TPAMI.2003.1159944			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	628NL		hybrid, Green Submitted			2022-12-18	WOS:000180002300003
J	Bharadwaj, P; Carin, L				Bharadwaj, P; Carin, L			Infrared-image classification using hidden Markov trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hidden Markov model; infrared imagery; classification	MODELS	An image of a three-dimensional target is generally characterized by the visible target subcomponents, with these dictated by the target-sensor orientation (target pose) An image often changes quickly with variable pose. We define a class as a set of contiguous target-sensor orientations over which the associated target image is relatively stationary with aspect Each target is in general characterized by multiple classes A distinct set of Wiener filters are employed for each class of images, to identify the presence of target subcomponents A Karhunen-Loeve representation is used to minimize the number of filters (templates) associated with a given subcomponent. The statistical relationships between the different target subcomponents are modeled via a hidden Markov tree (HMT). The HMT classifier is discussed and example results are presented for forward-looking-infrared (FLIR) imagery of several vehicles.	A Siemens Co, Mt View, CA 94039 USA; Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Siemens AG; Duke University	Bharadwaj, P (corresponding author), A Siemens Co, 1220 Charleston Rd,POB 9373, Mt View, CA 94039 USA.			Carin, Lawrence/0000-0001-6277-7948				Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544; Dasgupta N, 2001, SIGNAL PROCESS, V81, P1303, DOI 10.1016/S0165-1684(00)00262-0; Geman S, 1987, P INT C MATH, V1, P1496; Jain A. K., 1989, FUNDAMENTALS DIGITAL; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Li J, 2000, IEEE T SIGNAL PROCES, V48, P517, DOI 10.1109/78.823977; MARINELLI AMP, 1999, P SPIE C ALG SAR IM, V6, P343; Nandy D, 1999, IEEE T IMAGE PROCESS, V8, P22, DOI 10.1109/83.736680; NILUBOL C, 1998, P IEEE INT C AC SPEE, V1, P1061; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626	11	28	32	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2002	24	10					1394	1398		10.1109/TPAMI.2002.1039210	http://dx.doi.org/10.1109/TPAMI.2002.1039210			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	596ZF		Green Submitted			2022-12-18	WOS:000178196300009
J	Talavera, L; Bejar, J				Talavera, L; Bejar, J			Generality-based conceptual clustering with probabilistic concepts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						conceptual clustering; hierarchical clustering; probabilistic concepts; user interaction		Statistical research in clustering has almost universally focused on data sets described by continuous features and its methods are difficult to apply to tasks involving symbolic features. In addition, these methods are seldom concerned with helping the user in interpreting the results obtained. Machine learning researchers have developed conceptual clustering methods aimed at solving these problems. Following a long term tradition in Al, early conceptual clustering implementations employed logic as the mechanism of concept representation. However, logical representations have been criticized for constraining the resulting cluster structures to be described by necessary and sufficient conditions. An alternative are probabilistic concepts which associate a probability or weight with each property of the concept definition. In this paper, we propose a symbolic hierarchical clustering model that makes use of probabilistic representations and extends the traditional ideas of specificity-generality typically found in machine learning. We propose a parameterized measure that allows users to specify both the number of levels and the degree of generality of each level. By providing some feedback to the user about the balance of the generality of the concepts created at each level and given the intuitive behavior of the user parameter, the system improves user interaction in the clustering process.	Univ Politecn Cataluna, Dept Llenguatges & Sistemes Informat, ES-08034 Barcelona, Spain	Universitat Politecnica de Catalunya	Talavera, L (corresponding author), Univ Politecn Cataluna, Dept Llenguatges & Sistemes Informat, Campus Nord,Jordi Girona 1-3, ES-08034 Barcelona, Spain.	talavera@lsi.upc.es; bejar@lsi.upc.es	Bejar, Javier/L-4414-2014; Talavera, Luis/B-2830-2012	Bejar, Javier/0000-0001-5281-3888; Talavera, Luis/0000-0002-7136-3349				Fisher D, 1996, J ARTIF INTELL RES, V4, P147, DOI 10.1613/jair.276; FISHER D, 1991, MOR KAUF M, P3; FISHER D, 1993, IEEE EXPERT, V8, P51, DOI 10.1109/64.248353; Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1007/BF00114265; Hanson S. J., 1989, Machine Learning, V3, P343, DOI 10.1007/BF00116838; IBA W, 1999, UNSUPERVISED LEARNIN; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Lebowitz M., 1987, Machine Learning, V2, P103, DOI 10.1023/A:1022800624210; Michalski R.S., 1983, MACHINE LEARNING ART, P331; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; MURPHY GL, 1982, J VERB LEARN VERB BE, V21, P1, DOI 10.1016/S0022-5371(82)90412-1; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Reich Y, 1999, ARTIF INTELL ENG, V13, P257, DOI 10.1016/S0954-1810(98)00021-1; REICH Y, 1991, MOR KAUF M, P323; Smith E. E., 1981, CATEGORIES CONCEPTS	15	28	29	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2001	23	2					196	206		10.1109/34.908969	http://dx.doi.org/10.1109/34.908969			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	401NJ					2022-12-18	WOS:000166933500008
J	Ricci, F; Avesani, P				Ricci, F; Avesani, P			Data compression and local metrics for nearest neighbor classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nearest neighbor; data compression; machine learning; local metric; multiple models; case-based reasoning	LEARNING ALGORITHMS	A local distance measure for the nearest neighbor classification rule is shown to achieve high compression rates and high accuracy on real data sets. In the approach proposed here, first, a set of prototypes is extracted during training and, then, a feedback learning algorithm is used to optimize the metric. Even if the prototypes are randomly selected, the proposed metric outperforms, both in compression rate and accuracy, common editing procedures like ICA, RNN, and PNN. Finally, when accuracy is the major concern, we show how compression can be traded for accuracy by exploiting voting techniques. That indicates how voting can be successfully integrated with instance-bases approaches, overcoming previous negative results.	Ist Ric Sci & Tecnol, ITC, I-38050 Trent, TN, Italy		Ricci, F (corresponding author), Ist Ric Sci & Tecnol, ITC, I-38050 Trent, TN, Italy.		Ricci, Francesco/H-3367-2012; Avesani, Paolo/AAY-9704-2021	Ricci, Francesco/0000-0001-5931-5566; Avesani, Paolo/0000-0001-8943-8911				AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; BAY SD, 1998, MACHINE LEARNING; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Breiman L., 1996, 460 U CAL; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; KAIN AK, 1988, ALGORITHMS CLUSTERIN; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; MEDIN DL, 1988, COGNITIVE PSYCHOL, V20, P158, DOI 10.1016/0010-0285(88)90018-7; Merz C., 1996, UCI REPOSITORY MACHI; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; RICCI F, 1996, 960201 IRST; RICCI F, 1998, P 10 EUR C MACH LEAR; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Skalak D. B, 1994, P 11 INT C MACH LEAR, P293, DOI DOI 10.1016/B978-1-55860-335-6.50043-X; Stanfill C., 1986, Communications of the ACM, V29, P1213, DOI 10.1145/7902.7906; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WILSON DR, 1997, J ARTIFICIAL INTELLI, V11, P1	21	28	29	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1999	21	4					380	384		10.1109/34.761268	http://dx.doi.org/10.1109/34.761268			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	187HL					2022-12-18	WOS:000079781200009
J	Aykroyd, RG				Aykroyd, RG			Bayesian estimation for homogeneous and inhomogeneous Gaussian random fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						adaptive smoothing; compound Gauss-Markov random fields; coupled random fields; doubly stochastic random fields; Markov random fields; Metropolis-Hastings algorithm	MARKOV RANDOM-FIELDS; SPATIAL STATISTICS; IMAGE ESTIMATION; MODELS; RESTORATION; RELAXATION; CHAINS	This paper investigates Bayesian estimation for Gaussian Markov random fields. In particular, a new class of compound model is proposed which describes the observed intensities using an inhomogeneous model and the degree of spatial variation described using a second random field. The coupled Markov random fields are used as prior distributions, and combined with Gaussian noise models to produce posterior distributions on which estimation is based. All model parameters are estimated, in a fully Bayesian setting, using the Metropolis-Hastings algorithm. The full posterior estimation procedures are illustrated and compared using various artificial examples. For these examples the inhomogeneous model performs very favorably when compared to the homogeneous model, allowing differential degrees of smoothing and varying local textures.	Univ Leeds, Dept Stat, Leeds LS2 9JT, W Yorkshire, England	University of Leeds	Aykroyd, RG (corresponding author), Univ Leeds, Dept Stat, Leeds LS2 9JT, W Yorkshire, England.	R.G.Aykroyd@leeds.ac.uk		Aykroyd, Robert/0000-0003-3700-0816				[Anonymous], 1994, 568 U MINN SCH STAT; Aykroyd RG, 1996, GRAPH MODEL IM PROC, V58, P452, DOI 10.1006/gmip.1996.0037; AYKROYD RG, 1991, PHILOS T ROY SOC A, V337, P323, DOI 10.1098/rsta.1991.0128; Berger J. O, 1985, STAT DECISION THEORY, P118; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1991, ANN I STAT MATH, V43, P1, DOI 10.1007/BF00116466; Besag J, 1995, BIOMETRIKA, V82, P733, DOI 10.2307/2337341; Besag J. E., 1989, J APPL STAT, V16, P395, DOI [10.1080/02664768900000049, DOI 10.1080/02664768900000049]; CHEN CC, 1993, PATTERN RECOGN LETT, V14, P907, DOI 10.1016/0167-8655(93)90155-7; COHEN FS, 1987, IEEE T PATTERN ANAL, V9, P195, DOI 10.1109/TPAMI.1987.4767895; Cowles MK, 1996, J AM STAT ASSOC, V91, P883, DOI 10.2307/2291683; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; GEMAN D, 1991, LECT NOTES MATH, V1427, P113; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Geman S, 1987, B INT STAT I, V4, P5; Green P., 1992, LECT NOTES STATIST, V74, P142; GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; JENG FC, 1991, IEEE T SIGNAL PROCES, V39, P683, DOI 10.1109/78.80887; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Propp JG, 1996, RANDOM STRUCT ALGOR, V9, P223, DOI 10.1002/(SICI)1098-2418(199608/09)9:1/2<223::AID-RSA14>3.0.CO;2-O; QIAN W, 1991, J ROY STAT SOC B MET, V53, P661; RAFTERY AE, 1991, ANN I STAT MATH, V43, P32; Sokal A. D., 1989, COURS TROIS CYCL PHY; WOODS JW, 1987, IEEE T PATTERN ANAL, V9, P245, DOI 10.1109/TPAMI.1987.4767898; [No title captured]	30	28	28	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					533	539		10.1109/34.682182	http://dx.doi.org/10.1109/34.682182			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZR253					2022-12-18	WOS:000073955600008
J	Hansen, MW; Higgins, WE				Hansen, MW; Higgins, WE			Relaxation methods for supervised image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image segmentation; watershed analysis; relaxation labeling; 3D image analysis; 3D medical imaging; 3D cardiac image analysis	3-D CT IMAGES; MEDICAL IMAGES; EXTRACTION; OPERATIONS; DISPLAY; CHAMBER; SYSTEM	We propose two methods for supervised image segmentation: supervised relaxation labeling and watershed-driven relaxation labeling. The methods are particularly well suited to problems in 3D medical image analysis, where the images are large, the regions are topologically complex, and the tolerance of errors is low. Each method uses predefined cues for supervision. The cues can be defined interactively or automatically, depending on the application. The cues provide statistical region information and region topological constraints. Supervised relaxation labeling exhibits strong noise resilience. Watershed-driven relaxation labeling combines the strengths of watershed analysis and supervised relaxation labeling to give a computationally efficient noise-resistant method. Extensive results for 2D and 3D images illustrate the effectiveness of the methods.	PENN STATE UNIV,UNIVERSITY PK,PA 16802	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Hansen, MW (corresponding author), DAVID SARNOFF RES CTR,CN 5300,PRINCETON,NJ 08543, USA.							AMERICUS P, 1996, ANN BIOMEDICAL EN S1, V24, pS65; BEARD D, 1994, P SOC PHOTO-OPT INS, V2167, P10, DOI 10.1117/12.175055; BOMANS M, 1990, IEEE T MED IMAGING, V9, P177, DOI 10.1109/42.56342; COATRIEUX JL, 1990, IEEE ENG MED BIOL, V9, P33, DOI 10.1109/51.105216; DHAWAN AP, 1991, IEEE ENG MED BIOL, V10, P30, DOI 10.1109/51.107166; DREYER KJ, 1989, SPIE INTELL ROBOTS C, V1192, P806; DUNCAN JS, 1992, IEEE T PATTERN ANAL, V14, P502, DOI 10.1109/34.134056; FABER TL, 1991, IEEE T MED IMAGING, V10, P21; FUNG PW, 1988, P IEEE C AC SPEECH S, P882; GARBAY C, 1986, IEEE T PATTERN ANAL, V8, P140, DOI 10.1109/TPAMI.1986.4767768; GAUCH JM, 1993, IEEE T PATTERN ANAL, V15, P635, DOI 10.1109/34.216734; HANSEN MW, 1993, THESIS PENNSYLVANIA; HANSEN MW, 1994, IEEE INT C IMG P, V3, P460; Higgins WE, 1996, IEEE T MED IMAGING, V15, P377, DOI 10.1109/42.500146; HIGGINS WE, 1993, COMPUT MED IMAG GRAP, V17, P387, DOI 10.1016/0895-6111(93)90033-J; HIGGINS WE, 1992, COMPUT MED IMAG GRAP, V16, P17, DOI 10.1016/0895-6111(92)90195-F; HIGGINS WE, 1990, IEEE T MED IMAGING, V9, P384, DOI 10.1109/42.61754; HIGGINS WE, 1994, SPIE MED IMAGING 199; HIGGINS WE, 1996, SPIE MED IMAGING 96, V2709, P359; HIGGINS WE, 1994, P SOC PHOTO-OPT INS, V2359, P59; HOHNE KH, 1992, J COMPUT ASSIST TOMO, V16, P285, DOI 10.1097/00004728-199203000-00019; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5; LI CH, 1995, GRAPH MODEL IM PROC, V57, P161, DOI 10.1006/gmip.1995.1016; MAES F, 1995, P COMP VIS VIRT REAL, P77; Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M; REINHARDT J, 1995, 1995 IEEE INT C IM P, P502; REINHARDT JM, UNPUB OPTICAL ENG; ROBB RA, 1989, IEEE T MED IMAGING, V8, P217, DOI 10.1109/42.34710; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Rosenfeld A., 1982, DIGITAL PICTURE PROC; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; STYTZ MR, 1991, ACM COMPUT SURV, V23, P421; SUNDARAMOORTHY G, 1995, COMPUT MED IMAG GRAP, V19, P131, DOI 10.1016/0895-6111(94)00042-5; Toriwaki J., 1986, Systems and Computers in Japan, V17, P73, DOI 10.1002/scj.4690170109; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; WECHSLER H, 1990, COMPUTATIONAL VISION; YOO TS, 1992, IEEE COMPUT GRAPH, V12, P63, DOI 10.1109/38.144828	38	28	34	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					949	962		10.1109/34.615445	http://dx.doi.org/10.1109/34.615445			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985					2022-12-18	WOS:A1997XX98500002
J	KUMAR, S; HAN, S; GOLDGOF, D; BOWYER, K				KUMAR, S; HAN, S; GOLDGOF, D; BOWYER, K			ON RECOVERING HYPERQUADRICS FROM RANGE DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						OBJECT MODELING; HYPERQUADRICS; SURFACE FITTING; OBJECT REPRESENTATION; VOLUMETRIC MODELS		This paper discusses the applications of hyperquadric models in computer vision and focuses on their recovery from range data. Hyperquadrics are volumetric shape models that include superquadrics as a special case. A hyperquadric model fan be composed of any number of terms and its geometric bound is an arbitrary convex polytope. Thus, hyperquadrics can model more complex shapes than superquadrics. Hyperquadrics also possess many other advantageous properties (compactness, semilocal control, and intuitive meaning). Recovering hyperquadric parameters is difficult not only due to the existence of many local minima in the error function but also due to the existence of an infinite number of global minima (with zero error) that do not correspond to any meaningful shape. Our proposed algorithm starts with a rough fit using only six terms in 3D (four in 2D) and adds additional terms as necessary to improve fitting. Suitable constraints are used to ensure proper convergence. Experimental results with real 2D and 3D data are presented.			KUMAR, S (corresponding author), UNIV S FLORIDA, DEPT COMP SCI & ENGN, TAMPA, FL 33620 USA.		Goldgof, Dmitry/ABF-1366-2020	Bowyer, Kevin/0000-0002-7562-4390				Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; BARR AH, 1984, COMPUTER GRAPHICS, V18; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BOULT TE, 1987, SPIE INTELLIGENT ROB, V848; CHEN CW, 1994, IEEE T PATTERN ANAL, V16, P342, DOI 10.1109/34.277589; FERRIE FP, 1993, IEEE T PATTERN ANAL, V15, P771, DOI 10.1109/34.236252; GUPTA A, 1991, THESIS U PENNSYLVANI; Han S., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P492, DOI 10.1109/ICCV.1993.378174; HANSON A, 1990, IMPLICIT FUNCTIONS M; HANSON AJ, 1988, COMPUT VISION GRAPH, V44, P191, DOI 10.1016/S0734-189X(88)80005-7; KUMAR S, E COMMUNICATION; KUMAR S, 1994, 12TH P ICPR JER, V1, P74; Luenberger D.G, 2016, LINEAR NONLINEAR PRO, DOI 10.1007/978-3-319-18842-3; PENTLAND A, 1987, 1ST INT C COMP VIS, P612; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; RAJA NS, 1992, IMAGE VISION COMPUT, V10, P179, DOI 10.1016/0262-8856(92)90069-F; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273	20	28	28	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1995	17	11					1079	1083		10.1109/34.473234	http://dx.doi.org/10.1109/34.473234			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TD854					2022-12-18	WOS:A1995TD85400006
J	DRAPER, BA; BRODLEY, CE; UTGOFF, PE				DRAPER, BA; BRODLEY, CE; UTGOFF, PE			GOAL-DIRECTED CLASSIFICATION USING LINEAR MACHINE DECISION TREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DECISION TREES; NONPARAMETRIC CLASSIFICATION; PATTERN RECOGNITION; OBJECT RECOGNITION; COMPUTER VISION; MACHINE LEARNING		Recent work in feature-based classification has focused on nonparametric techniques that can classify instances even when the underlying feature distributions are unknown. The inference algorithms for training these techniques, however, are designed to maximize the accuracy of the classifier, with all errors weighted equally. In many applications, certain errors are far more costly than others, and the need arises for nonparametric classification techniques that can be trained to optimize task-specific cost functions. This correspondence reviews the Linear Machine Decision Tree (LMDT) algorithm for inducing multivariate decision trees, and shows how LMDT can be altered to induce decision trees that minimize arbitrary misclassification cost functions (MCF's). Demonstrations of pixel classification in outdoor scenes show how MCF's can optimize the performance of embedded classifiers within the context of larger image understanding systems.			DRAPER, BA (corresponding author), UNIV MASSACHUSETTS,DEPT COMP SCI,AMHERST,MA 01003, USA.							BRODLEY CE, IN PRESS MACHINE LEA; DRAPER B, 1993, P SENSOR FUSION, V6, P175; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDA RO, 1966, IEEE TRANS ELECTRON, VEC15, P220, DOI 10.1109/PGEC.1966.264302; Frean MR, 1990, THESIS U EDINBURGH; Mingers J., 1989, Machine Learning, V4, P227, DOI 10.1023/A:1022604100933; Nilsson N., 1965, LEARNING MACHINES; Olshen R., 1984, CLASSIFICATION REGRE; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; UTGOFF PE, 1990, 7TH P INT C MACH LEA	11	28	28	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					888	893		10.1109/34.310684	http://dx.doi.org/10.1109/34.310684			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802					2022-12-18	WOS:A1994PE80200004
J	GREENSPAN, H; GOODMAN, R; CHELLAPPA, R; ANDERSON, CH				GREENSPAN, H; GOODMAN, R; CHELLAPPA, R; ANDERSON, CH			LEARNING TEXTURE-DISCRIMINATION RULES IN A MULTIRESOLUTION SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							FILTERS	We describe a texture analysis system in which informative discrimination rules are learned from a multiresolution representation of the textured input. The system incorporates unsupervised and supervised learning via statistical machine learning and rule-based neural networks, respectively. The textured input is represented in the frequency-orientation space via a log-Gabor pyramidal decomposition. In the unsupervised learning stage a statistical clustering scheme is used for the quantization of the feature-vector attributes. A supervised stage follows in which labeling of the textured map is achieved using a rule-based network. Simulation results for the texture classification task are given. An application of the system to real-world problems is demonstrated.	UNIV MARYLAND,INST ADV COMP STUDIES,DEPT ELECT ENGN,COLLEGE PK,MD 20742; UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742; JET PROP LAB,PASADENA,CA 91109	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; National Aeronautics & Space Administration (NASA); NASA Jet Propulsion Laboratory (JPL)	GREENSPAN, H (corresponding author), CALTECH,DEPT ELECT ENGN,PASADENA,CA 91125, USA.		Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAV-8690-2020					Anderson C. H., 1988, U. S. Patent No, Patent No. [4718104, 4,718,104]; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Brodatz P., 1966, TEXTURES; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; Duda R.O., 1973, J ROYAL STAT SOC SER; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; GOODMAN RM, 1992, NEURAL COMPUT, V4, P781, DOI 10.1162/neco.1992.4.6.781; Greenspan H., 1993, ADV NEURAL INFORMATI, V5, P425; GREENSPAN H, 1994, JUN P IEEE C COMP VI, P222; GREENSPAN H, 1994, THESIS CALTECH; GREENSPAN H, 1994, IN PRESS 12TH P INT; GREENSPAN HK, 1992, ADV NEUR IN, V4, P444; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; SMITH P, 1992, IEEE T KNOWL DATA EN, V4, P301; TUCERYAN M, 1992, HDB PATTERN RECOGNIT, pCH11; VILNROTTER FM, 1986, IEEE T PATTERN ANAL, V8, P76, DOI 10.1109/TPAMI.1986.4767754	18	28	32	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					894	901		10.1109/34.310685	http://dx.doi.org/10.1109/34.310685			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802		Green Accepted			2022-12-18	WOS:A1994PE80200005
J	WANG, JY; COHEN, FS				WANG, JY; COHEN, FS			3-D OBJECT RECOGNITION AND SHAPE ESTIMATION FROM IMAGE CONTOURS USING B-SPLINES, SHAPE INVARIANT MATCHING, AND NEURAL-NETWORK .2.	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						OBJECT RECOGNITION; OBJECT MARKINGS; SHAPE ESTIMATION; B-SPLINES; CONTROL POINTS; INVARIANT MATCHING; CONTOUR UNWARPING; SURFACE CONTOUR ESTIMATION; SURFACE CLASSIFICATION; NEURAL NETWORK; FOURIER DESCRIPTORS		This paper is the second part of a 3-D object recognition and shape estimation system that identifies particular objects by recognizing the special markings (text, symbols, drawings, etc.) on their surfaces. The shape of the object is identified from the image curves using B-spline curve modeling as described in Part I, as well as a binocular stereo imaging system, This is achieved by first estimating the 3-D control points from the corresponding curves in each image in the stereo imaging system. From the 3-D control points, the 3-D object curves are generated, and these are subsequently used for estimating the 3-D surface parameters. A Bayesian framework is used for classifying the image into one of c possible surfaces based on the extracted 3-D object curves. This is complemented by a neural network (NN) that recognizes the surface as a particular object (e.g., a Pepsi can versus a peanut butter jar), by reading the text/markings on the surface. To reduce the amount of training the NN has to undergo for recognition, the object curves are ''unwarped'' into planar curves before the matching process. This eliminates the need for templates that are surface shape dependent and results into a planar curve that might be a rotated, translated, and scaled version of the template. Hence, for the matching process we need to use measures that are invariant to these transformations. One such measure is the Fourier descriptors (FD) derived from the control points associated with the unwarped parent curves. The approach is tried on a variety of images of real objects and appears to hold great promise.	DREXEL UNIV,DEPT ELECT & COMP ENGN,PHILADELPHIA,PA 19104	Drexel University	WANG, JY (corresponding author), CHUNG CHENG INST TECHNOL,DEPT INFROMAT SCI,TAYUAN,TAIWAN.		Rohlf, F J/A-8710-2008					ALOIMONOS J, 1989, INTEGRATION VISUAL M; BAJCSY R, 1976, COMP GRAPHICS IMAGE, V5; BAKER HH, 1981, 7TH P INT JOINT C AR; BOLLE RM, 1984, IEEE T PATT ANAL MAC, V6; BRADY JM, 1981, ARTIF INTELL, V17, P1; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; BROOKS MJ, 1985, P INT JOINT C ARTIFI; CERNUSCHIFRIAS B, 1989, IEEE T PATTERN ANAL, V11, P1028, DOI 10.1109/34.42835; CERNUSHIFRIAS B, 1984, IEEE T PATT ANAL MAC, V6; COHEN FS, 1991, COMPUTER VISION GRAP; COHEN FS, IN PRESS THEORY APPL; COOPER DB, 1988, P INT C COMPUTER VIS, P74; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; Duda R.O., 1973, J ROYAL STAT SOC SER; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; GRIMSONWE, 1981, PHILOS T ROY SOC B, V292; Hecht-Nielsen R., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P593, DOI 10.1109/IJCNN.1989.118638; HERVE JY, 1990, 1ST P EUR C COMP VIS; HORN BKP, 1975, PSYCHOL COMPUTER VIS, pCH4; HORN BKP, 1979, APPL OPT, V18; IKEUCHI K, 1984, ARTIFICIAL INTELL, V22; JULESZ B, 1971, F CYCLOPEAN PERCEPTI; KEHTARNAVAZ N, 1988, COMPUTER VISION GRAP, P32; KENDER JR, 1979, P IMAGE UNDERSTANDIN; Lippmann R. P., 1988, Computer Architecture News, V16, P7, DOI [10.1109/MASSP.1987.1165576, 10.1145/44571.44572]; MARR D, 1977, P ROY SOC B, V197; Marr D., 1982, VISION; MARR D, 1979, P ROY SOC B, V204; Millman R.S., 1977, ELEMENTS DIFFERENTIA; MOERDLER ML, 1988, P IEEE INT C COMPUTE; NISHIHARA HK, 1978, THESIS MIT CAMBRIDGE; OHTA Y, 1980, P IJCAI; Pao Y.H., 1989, ADAPTIVE PATTERN REC; PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799; POGGIO T, 1988, P DARPA IMAGE UNDERS, P177; PRENTLAND AP, 1982, J OPT SOC AM, V72; RIMEY RD, 1988, IEEE T ROBOITCS AUTO, V4; Rogers D.F., 1990, MATH ELEMENTS COMPUT, Vsecond; SAMPSON PD, 1982, COMPUTER GRAPHICS IM, V18; STEVENS KA, 1981, ARTIFICIAL INTELL, V17; STRUTO LL, 1973, R635 DRAP LAB INT RE; WEISS I, 1988, COMPUTER VISION GRAP, P80; WITKIN AP, 1981, ARTIFICIAL INTELL, V17; YUEN SK, 1990, 1ST P EUR C COMP VIS; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	46	28	34	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1994	16	1					13	23						11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MV733					2022-12-18	WOS:A1994MV73300002
J	PROVAN, GM; CLARKE, JR				PROVAN, GM; CLARKE, JR			DYNAMIC NETWORK CONSTRUCTION AND UPDATING TECHNIQUES FOR THE DIAGNOSIS OF ACUTE ABDOMINAL-PAIN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note							DECISION; MODEL	Computing diagnoses in domains with continuously changing data is a difficult but essential aspect of solving many problems. To address this task, this paper describes a dynamic influence diagram (ID) construction and updating system (DYNASTY) and its application to constructing a decision-theoretic model to diagnose acute abdominal pain, which is a domain in which the findings evolve during the diagnostic process. For a system that evolves over time, DYNASTY constructs a parsimonious ID and then dynamically updates the ID, rather than constructing a new network from scratch for every time interval. In addition, DYNASTY contains algorithms that test the sensitivity of the constructed network's system parameters. The main contributions of this paper are 1) presenting an efficient temporal influence diagram technique based on parsimonious model construction and 2) formalizing the principles underlying a diagnostic tool for acute abdominal pain that explicitly models time-varying findings.	MED COLL PENN,DEPT SURG,PHILADELPHIA,PA 19129	Drexel University	PROVAN, GM (corresponding author), UNIV PENN,DEPT COMP & INFORMAT SCI,PHILADELPHIA,PA 19104, USA.			Provan, Gregory/0000-0003-3678-046X				BERZUINI C, 1989, P 5 WORKSH UNC ART I, P14; BREESE J, 1991, 30 ROCKW INT SCI CTR; CHANG KC, 1990, P 6 C UNC ART INT, P475; CLARKE JR, 1984, MED DECIS MAKING, V4, P331, DOI 10.1177/0272989X8400400309; CLARKE JR, 1991, ANN CHIR, V45, P279; CLARKE JR, 1992, SPR P AAAI S AI MED; DAGUM P, 1991, STANKSL9149 STANF U; Dean T., 1989, Computational Intelligence, V5, P142, DOI 10.1111/j.1467-8640.1989.tb00324.x; DEDOMBAL FT, 1972, BMJ-BRIT MED J, V2, P9, DOI 10.1136/bmj.2.5804.9; Derman C., 1970, FINITE STATE MARKOVI; GOLDMAN RP, 1993, IEEE T PATTERN ANAL, V15, P196, DOI 10.1109/34.204902; HECKERMANN D, 1990, P C UNC ART INT, P82; HERSKOVITS EH, 1990, P 6 C UNC ART INT CA, P54; HOWARD RA, 1981, PRINCIPLES APPL DECI, P720; KAHN MG, 1991, MED DECIS MAKING, V11, P249, DOI 10.1177/0272989X9101100403; KESHAVAN H, 1993, IEEE T PATT ANAL MAC, V15; MCALLESTER D, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1109; Mcleish M, 1990, ANN MATH ARTIFICIAL, V2, P261; Neutra R., 1977, COSTS RISKS BENEFITS, P277; PASS HI, 1988, HARDYS TXB SURG, P574; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PROVAN GM, 1991, P C UNCERTAINTY ARTI; PROVAN GM, 1992, MISCS9268 U PENNS DE; PROVAN GM, 1992, MISCS9269 U PENNS DE; PROVANGM, 1991, P C PRINCIPLES KNOWL, P461; SCHWARTZ SM, 1988, UNCERTAINTY ARTIFICI, P423; SHWE M, 1990, P C UNCERTAINTY ARTI, P498; SRINIVAS S, 1990, 6TH P C UNC ART INT, P212; Webber B. L., 1992, Artificial Intelligence in Medicine, V4, P145, DOI 10.1016/0933-3657(92)90051-P; WELLMAN M, 1992, KNOWLEDGE ENG REV, V7; Wellman M. P, 1990, FORMULATION TRADEOFF	31	28	28	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					299	307		10.1109/34.204913	http://dx.doi.org/10.1109/34.204913			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800012
J	SEGMAN, J; RUBINSTEIN, J; ZEEVI, YY				SEGMAN, J; RUBINSTEIN, J; ZEEVI, YY			THE CANONICAL COORDINATES METHOD FOR PATTERN DEFORMATION - THEORETICAL AND COMPUTATIONAL CONSIDERATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CANONICAL COORDINATES; DISTORTED PATTERNS; INVARIANCE KERNELS; LIE TRANSFORMATION GROUPS; MELLIN-FOURIER TRANSFORM; VISUAL SYSTEM	TRANSFORM; SIGNALS; VISION	A method for the analysis of deformed patterns is presented and analyzed. The image is transformed into a new set of coordinates in which the deformation has a particular simple form. A number of deformations are considered. The practical implementation of the method is discussed. We also consider similar aspects of biological vision.	HARVARD UNIV,DIV APPL SCI,CAMBRIDGE,MA 02138; TECHNION ISRAEL INST TECHNOL,DEPT MATH,HAIFA,ISRAEL	Harvard University; Technion Israel Institute of Technology	SEGMAN, J (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,HAIFA,ISRAEL.							BASTIAANS MJ, 1981, OPT ENG, V20, P594, DOI 10.1117/12.7972768; CAELLI T, 1978, J OPT SOC AM, V68, P402, DOI 10.1364/JOSA.68.000402; CAMPBELL JE, 1966, INTRO TREATISE LIES; CASSASENT D, 1976, OPT COMMUN, V17, P59; CASSASENT D, 1976, APPL OPTICS, V15, P1795; CASSASENT D, 1977, P IEEE, V65, P77; DAUGMAN JG, 1988, IEEE T ACOUSTICS SPE, V36; DUDA RO, 1974, PATTERN CLASSIFICATI; FERRARO M, 1988, J OPT SOC AM A, V5, P738, DOI 10.1364/JOSAA.5.000738; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; Guggenheimer H.W., 1963, DIFFERENTIAL GEOMETR; Higgins JR., 2004, COMPLETENESS BASIS P; Hoffman W. C., 1980, MATH MODELING, V1, P349, DOI [10.1016/0270-0255(80)90045-7, DOI 10.1016/0270-0255(80)90045-7]; HOFFMAN WC, 1966, J MATH PSYCHOL, V3, P65, DOI 10.1016/0022-2496(66)90005-8; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; HUBEL DH, 1982, NATURE, V299, P515, DOI 10.1038/299515a0; John F., 1991, PARTIAL DIFFERENTIAL; KRONAUER RE, 1985, IEEE T SYST MAN CYB, V15, P91, DOI 10.1109/TSMC.1985.6313397; MARR D, 1981, PROC R SOC SER B-BIO, V211, P151, DOI 10.1098/rspb.1981.0001; PAPATHOMAS TV, 1989, PIXELS FEATURES; PORAT M, 1988, IEEE T PATTERN ANAL, V10, P452, DOI 10.1109/34.3910; RUBINSTEIN J, 1990, 10TH P ICPR WASH, P159; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; SEGMAN J, 1989, EE PUBL TECHNION, V735; ZEEVI YY, 1992, VISUAL COMM IMAGE RE; ZWICKE PE, 1983, IEEE T PATTERN ANAL, V5, P191, DOI 10.1109/TPAMI.1983.4767371	26	28	28	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1992	14	12					1171	1183		10.1109/34.177382	http://dx.doi.org/10.1109/34.177382			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KC573					2022-12-18	WOS:A1992KC57300003
J	WILDES, RP				WILDES, RP			DIRECT RECOVERY OF 3-DIMENSIONAL SCENE GEOMETRY FROM BINOCULAR STEREO DISPARITY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BINOCULAR STEREO; DISPARITY INTERPRETATION; 3-DIMENSIONAL VISION	SURFACE RECONSTRUCTION; COMPUTATIONAL APPROACH; OPTICAL-FLOW; IMAGE FLOW; PERCEPTION; MOTION; MODEL	The problems under consideration center around the recovery of three-dimensional scene geometry from binocular stereo disparity. In order to accomplish this goal an analysis of disparity is presented. The analysis makes explicit the geometric relations between a stereo disparity field and a differentially projected scene. These results show how it is possible to recover three-dimensional surface geometry through first-order (i.e., distance and orientation of a surface relative to an observer) and binocular viewing parameters in a direct fashion from stereo disparity. As applications of the analysis, algorithms have been developed for recovering three-dimensional surface orientation and discontinuities from stereo disparity. The results of applying these algorithms to natural image binocular stereo disparity information are presented.	MIT,DEPT BRAIN & COGNIT SCI,CAMBRIDGE,MA 02139; MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)								ANANDAN P, 1987, P INT C COMPUTER VIS, P462; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; BOULT TE, 1987, REPRODUCING KERNELS; BRADY JM, 1985, MIT AI822 MEM; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CLOCKSIN WF, 1980, PERCEPTION, V9, P253, DOI 10.1068/p090253; Dahlquist G., 1974, NUMERICAL METHODS; EASTMAN RD, 1987, COMPUT VISION GRAPH, V39, P73, DOI 10.1016/S0734-189X(87)80203-7; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; GRIMSON WEL, 1981, IMAGES SURFACES; Harris J. G., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P277; Hoff W., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P284; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; KANATANI K, 1985, P INT JOINT C ART IN, P886; KOCH C, 1985, MIT AI751 MEM; KOENDERINK JJ, 1976, BIOL CYBERN, V21, P29, DOI 10.1007/BF00326670; KOENDERINK JJ, 1976, J OPT SOC AM, V66, P717, DOI 10.1364/JOSA.66.000717; Korn G.A., 2000, MATH HDB SCI ENG DEF; LEE D, 1987, 1ST P INT C COMP VIS, P572; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MARROQUIN JL, 1984, MIT AI792 MEM; MAYHEW JEW, 1982, NATURE, V297, P376, DOI 10.1038/297376a0; MEDIONI G, 1984, P DARPA IMAGE UNDERS, P219; MUTCH KM, 1985, IEEE T PATTERN ANAL, V7, P133, DOI 10.1109/TPAMI.1985.4767638; PRADZNY K, 1980, BIOL CYBERN, V36, P87; SCHUNK B, 1986, P INT JOINT C PATTER, P20; Siegel S., 1956, NONPARAMETRIC STAT B; SMITLEY T, 1984, P INT JOINT C PATT R, P405; STEVENS KA, 1987, P INT C COMPUTER VIS, P549; SUBBARAO M, 1988, INT J COMPUT VISION, V2, P77, DOI 10.1007/BF00836282; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1986, PIXELS PREDICATES; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; THOMPSON WB, 1982, P AM ASS ARTIFICIAL, P26; TRUESDELL C, 1960, HDB PHYSIK; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; WEINSHALL D, 1987, MIT AI1007 MEM; WILDES RP, 1989, MIT1112 AI LAB TECH; YESHURUN Y, 1989, IEEE T PATTERN ANAL, V11, P759, DOI 10.1109/34.192471; 1966, MANUAL PHOTOGRAMMETR	41	28	29	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					761	774		10.1109/34.85667	http://dx.doi.org/10.1109/34.85667			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642					2022-12-18	WOS:A1991GC64200002
J	RANGANATH, S				RANGANATH, S			IMAGE FILTERING USING MULTIRESOLUTION REPRESENTATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ADAPTIVE IMAGE RESTORATION; IMAGE ENHANCEMENT; LEAST-SQUARES FILTER APPROXIMATION; MULTIRESOLUTION IMAGE REPRESENTATIONS; PYRAMID CODING	COMPUTATION; TRANSFORM	This paper shows how multiresolution representations can be used for filter design and implementation. These representations provide a coarse frequency decomposition of the image, which forms the basis for two filtering techniques. The first method, based on image pyramids, is used for approximating the convolution of an image with a given mask. In this technique, a filter is designed using a least-squares (ls) procedure based on filters synthesized from the basic pyramid equivalent filters. This approximates the mask frequency characteristic. Next, implementation of the filter involves linearly combining scaled and filtered pyramid levels, using weights obtained from the ls procedure. By this method, filtering and pyramid image coding can be combined, efficiently integrating the filter into the reconstruction procedure for the coded image. The second method is an adaptive noise reduction algorithm. An optimally filtered image is synthesized from the multiresolution levels, which in this case, are maintained at the original sampling density. Individual pixels of the image representation are linearly combined under a minimum mean square error criterion. This uses a local signal to noise ratio estimate to provide the best compromise between noise removal and resolution loss.			RANGANATH, S (corresponding author), PHILIPS LABS,MED IMAGING GRP,345 SCARBOROUGH RD,BRIARCLIFF MANOR,NY 10510, USA.							ABRAMATIC JF, 1982, IEEE T ACOUST SPEECH, V30, P1, DOI 10.1109/TASSP.1982.1163840; Adelson E. H., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V845, P50, DOI 10.1117/12.976485; BURT PJ, 1983, COMPUT VISION GRAPH, V21, P368, DOI 10.1016/S0734-189X(83)80049-8; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; CHELLAPPA R, 1985, DIGITAL IMAGE PROCES, V1; CROCHIERE RE, 1976, AT&T TECH J, V55, P1069, DOI 10.1002/j.1538-7305.1976.tb02929.x; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P212, DOI 10.1109/TPAMI.1984.4767504; JOHNSTON JD, 1980, APR P IEEE INT C AC, P291; Mallat S. G. A., 1987, MSCIS8722 U PENNS; Marr D., 1982, VISION; MEER P, 1987, IEEE T PATTERN ANAL, V9, P512, DOI 10.1109/TPAMI.1987.4767939; OLEARY DP, 1988, COMPUT VISION GRAPH, V41, P333, DOI 10.1016/0734-189X(88)90107-7; PRATT WK, 1979, AUG P SPIE TECH S SA, V27; PRATT WK, 1982, Patent No. 4330833; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; SCHAFER RW, 1973, P IEEE, V61, P692, DOI 10.1109/PROC.1973.9150; VETTERLI M, 1984, SIGNAL PROCESS, V6, P97, DOI 10.1016/0165-1684(84)90012-4; WATSON AB, 1987, COMPUT VISION GRAPH, V39, P311, DOI 10.1016/S0734-189X(87)80184-6; WELLS WM, 1986, IEEE T PATTERN ANAL, V8, P234, DOI 10.1109/TPAMI.1986.4767776; WITKIN AP, 1983, 7TH P INT JOINT C AR, P1019; WOODS JW, 1986, IEEE T ACOUST SPEECH, V34, P1278, DOI 10.1109/TASSP.1986.1164962	22	28	44	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1991	13	5					426	440		10.1109/34.134042	http://dx.doi.org/10.1109/34.134042			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FQ207					2022-12-18	WOS:A1991FQ20700003
J	WEISS, SM				WEISS, SM			SMALL SAMPLE ERROR RATE ESTIMATION FOR K-NN CLASSIFIERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						BOOTSTRAP; CROSS-VALIDATION; ERROR RATE ESTIMATOR; LEAVING-ONE-OUT; NEAREST NEIGHBOR	BOOTSTRAP	Small sample error rate estimators for nearest neighbor classifiers are reexamined and contrasted with the same estimators for three-nearest neighbor classifiers. The performance of the bootstrap estimators, e0 and 0.632B, is considered relative to leaving-one-out and other cross-validation estimators. Monte Carlo simulations are used to measure the performance of the error rate estimators. The experimental results are compared to previously reported simulations for both nearest neighbor classifiers and alternative classifiers. It is shown that each of the estimators has strengths and weaknesses for varying apparent and true error rate situations. A combined estimator that corrects the leaving-one-out estimator (by combining bootstrap and cross-validation estimators) gave strong results over a broad range of situations and warrants further investigation for other classifiers.			WEISS, SM (corresponding author), RUTGERS STATE UNIV,DEPT COMP SCI,NEW BRUNSWICK,NJ 08903, USA.							CHERNICK MR, 1985, PATTERN RECOGN LETT, V3, P167, DOI 10.1016/0167-8655(85)90049-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAWFORD SL, 1989, INT J MAN MACH STUD, V31, P197, DOI 10.1016/0020-7373(89)90027-8; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634, DOI 10.1109/TPAMI.1987.4767958; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628, DOI 10.1109/TPAMI.1987.4767957; KANAL L, 1971, PATTERN RECOGN, V3, P225, DOI 10.1016/0031-3203(71)90013-6; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; McClelland J. L., 1988, EXPLORATIONS PARALLE; Olshen R., 1984, CLASSIFICATION REGRE; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Raudys S., 1988, P INT JOINT C PATTER, P1230; STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x	13	28	28	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1991	13	3					285	289		10.1109/34.75516	http://dx.doi.org/10.1109/34.75516			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FG360					2022-12-18	WOS:A1991FG36000008
J	PHILIP, J				PHILIP, J			ESTIMATION OF 3-DIMENSIONAL MOTION OF RIGID OBJECTS FROM NOISY OBSERVATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ACCURACY ESTIMATES; DISCARDING OF INACCURATE ESTIMATES; ESTIMATION OF MOTION; LEAST SQUARES; 3-DIMENSIONAL SYNTHETIC RIGID OBJECT; 2-DIMENSIONAL IMAGE; 2 FRAMES		We estimate the motion of a rigid body from two noisy 2-D perspective projections using the least squares method and the algebra of Tsai and Huang. The accuracy of the estimated motion parameters is influenced by the position of the features of the object used in the calculation. We derive four test variables that indicate how the accuracy is influenced and use them for discarding inaccurate estimates. Monte Carlo tests demonstrate the obtained accuracy.			PHILIP, J (corresponding author), ROYAL INST TECHNOL,DEPT MATH,S-10044 STOCKHOLM 70,SWEDEN.							ARUN KS, 1987, IEEE T PATERN ANAL M, V9; BROIDA T, 1986, IEEE T PATTERN ANAL, V8; FANG J, 1984, IEEE T PATTERN ANAL, V6; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; GOLUB GH, 1971, HDB AUTOMATIC COMPUT, V2; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; Lawson C. L., 1974, SOLVING LEAST SQUARE; LEE CH, 1988, 2ND IEEE INT C COMP; LONGUETHIGGINS HC, 1981, NATURE, V293; MEIRI AZ, 1980, IEEE T PATTERN ANAL, V2; Moffit F.H., 1980, PHOTOGRAMMETRY, V3rd Ed.; PHILIP J, 1987, INVERSE PROBL, V3, P309, DOI 10.1088/0266-5611/3/2/013; PHILIP J, TRITANAP8902 CVAP59; ROACH JW, 1980, IEEE T PATTERN ANAL, V2; SPETSAKIS M, 1987, 6TH P AAAI NAT C ART, P738; TSAI RY, 1984, IEEE T PATTERN ANAL, V6; WENG J, 1988, JUN P IEEE C COMP VI, P387; WENG J, 1987, IEEE T PATTERN ANAL, V9; YASUMOTO Y, 1986, IEEE T PATT AN MACH, V8	19	28	28	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1991	13	1					61	66		10.1109/34.67631	http://dx.doi.org/10.1109/34.67631			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EX773					2022-12-18	WOS:A1991EX77300006
J	NALWA, VS				NALWA, VS			LINE-DRAWING INTERPRETATION - BILATERAL SYMMETRY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									STANFORD UNIV,ROBOT LAB,STANFORD,CA 94305	Stanford University								BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BRADY M, 1983, AUG P IJCAI 83 KARLS, P969; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KOENDERINK JJ, 1982, PERCEPTION, V11, P129, DOI 10.1068/p110129; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; LOWE DG, 1985, IEEE T PATTERN ANAL, V7, P320, DOI 10.1109/TPAMI.1985.4767660; MALIK J, 1985, THESIS STANFORD U; MARR D, 1977, PROC R SOC SER B-BIO, V197, P441, DOI 10.1098/rspb.1977.0080; NALWA VS, 1988, INT J COMPUT VISION, V2, P103, DOI 10.1007/BF00133696; NALWA VS, 1988, IEEE T PATTERN ANAL, V10, P514, DOI 10.1109/34.3914; Turner K., 1974, THESIS U EDINBURGH	13	28	28	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1989	11	10					1117	1120		10.1109/34.42842	http://dx.doi.org/10.1109/34.42842			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR689					2022-12-18	WOS:A1989AR68900009
J	LENZ, RK; TSAI, RY				LENZ, RK; TSAI, RY			CALIBRATING A CARTESIAN ROBOT WITH EYE-ON-HAND CONFIGURATION INDEPENDENT OF EYE-TO-HAND RELATIONSHIP	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									IBM CORP,THOMAS J WATSON RES CTR,YORKTOWN HTS,NY 10598	International Business Machines (IBM)	LENZ, RK (corresponding author), TECH UNIV MUNICH,LEHRSTUHL NACHRICHTENTECH,D-8000 MUNICH 2,FED REP GER.							ANTONSSON EK, 1982, THESIS MIT; BOWMAN M, 1987, UNPUB; CHAO LM, 1986, 10 ROB C P CHIC; CHEN J, 1986, P IEEE INT C ROBOTIC; DAINIS A, 1985, P IEEE INT C ROBOTIC; FOULLOY LP, 1984, P IEEE INT C ROBOTIC; HAYATI SA, 1986, RECENT TRENDS ROBOTI; HAYATI SA, 1985, J ROBOT SYST, V2; HAYATI SA, 1983, 22ND P IEEE C DEC CO; HOLLERBACH JM, 1987, 4TH P INT S ROB RES; IZAGUIRRE A, IN PRESS INT J ROBOT; JUDD RP, 1987, P IEEE INT C ROBOTIC; LENZ R, 1987, IEEE PATTERN ANAL MA, V9; LENZ R, 1987, P IEEE INT C ROBOTIC; MOORING BW, 1984, ASME P INT COMPUTERS; PUSKORIUS G, 1988, P IEEE INT C ROBOTIC; PUSKORIUS G, 1987, P IEEE INT C ROBOTIC; ROGERS DF, 1976, MATH ELEMENTS COMPUT; TSAI R, 1988, APR P INT C ROB AUT; TSAI R, 1989, SUM IEEE ROB AUT; TSAI R, 1987, IEEE J ROBOTICS AUTO, V3; TSAI R, 1987, 2ND P TOP M MACH VIS; TSAI R, 1986, 1986 P IEEE INT C CO; TSAI RY, 1987, 4TH P INT S ROB RES; WHITNEY DE, 1986, J DYNAMIC SYST MEAS	25	28	34	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					916	928		10.1109/34.35495	http://dx.doi.org/10.1109/34.35495			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800002
J	SMITH, SP; JAIN, AK				SMITH, SP; JAIN, AK			A TEST TO DETERMINE THE MULTIVARIATE NORMALITY OF A DATA SET	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824	Michigan State University	SMITH, SP (corresponding author), NORTHROP RES & TECHNOL CTR,AUTOMAT SCI LAB,1 RES PK,PALOS VERDES PENINSULA,CA 90274, USA.							COX DR, 1978, BIOMETRIKA, V65, P263, DOI 10.2307/2335204; CROSS GR, 1982, 6TH P INT C PATT REC, P862; DUBES RC, 1980, ADV COMPUT, P113; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; FUKUNAGA K, 1986, IEEE T PATTERN ANAL, V8, P240, DOI 10.1109/TPAMI.1986.4767777; GNANDESIKAN R, 1977, METHODS STATISTICAL; KOZIOL JA, 1983, J ROY STAT SOC B MET, V45, P358; Lesaffre E, 1983, PATTERN RECOGN LETT, V1, P187, DOI 10.1016/0167-8655(83)90061-2; Mardia K.V., 1980, HDB STAT, VVolume 1, P279, DOI DOI 10.1016/S0169-7161(80)01011-5; PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x; SMITH S, 1982, THESIS MICHIGAN STAT; Smith S. P., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P423; SMITH SP, 1984, IEEE T PATTERN ANAL, V6, P73, DOI 10.1109/TPAMI.1984.4767477	13	28	28	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					757	761		10.1109/34.6789	http://dx.doi.org/10.1109/34.6789			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500020
J	RHODES, FM; DITURI, JJ; CHAPMAN, GH; EMERSON, BE; SOARES, AM; RAFFEL, JI				RHODES, FM; DITURI, JJ; CHAPMAN, GH; EMERSON, BE; SOARES, AM; RAFFEL, JI			A MONOLITHIC HOUGH TRANSFORM PROCESSOR BASED ON RESTRUCTURABLE VLSI	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											RHODES, FM (corresponding author), MIT,LINCOLN LAB,LEXINGTON,MA 02173, USA.		Soares, Andreimar M/K-5556-2014					ANDERSON AH, 1985, P WORKSHOP WAFER SCA; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; CHAPMAN GH, 1985, P WORKSHOP WAFER SCA; DAVIS LS, 1986, OPT ENG, V25, P409, DOI 10.1117/12.7973838; DITURI JJ, 1986, 1986 P IEEE WORKSH V; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FRANKEL B, 1986, LSH USERS MANUAL; GARVERICK SL, 1983, 1983 P IEEE CICC ROC; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Pratt W. K., 1978, DIGITAL IMAGE PROCES; RAFFEL JI, 1985, IEEE T ELECTRON DEV, V32, P479, DOI 10.1109/T-ED.1985.21966; RAFFEL JI, 1985, P WORKSHOP WAFER SCA; RHODES FM, 1985, P WORKSHOP WAFER SCA; WAXMAN A, UNPUB; 1976, IEEE T COMMUN, V24, P418	15	28	28	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1988	10	1					106	110		10.1109/34.3873	http://dx.doi.org/10.1109/34.3873			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	L4366					2022-12-18	WOS:A1988L436600010
J	WANG, QR; SUEN, CY				WANG, QR; SUEN, CY			LARGE TREE CLASSIFIER WITH HEURISTIC-SEARCH AND GLOBAL TRAINING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CONCORDIA UNIV,DEPT COMP SCI,MONTREAL H3G 1M8,QUEBEC,CANADA	Concordia University - Canada								Aho AV, 1974, DESIGN ANAL COMPUTER; ARGENTIERO P, 1982, IEEE T PATTERN ANAL, V4, P51, DOI 10.1109/TPAMI.1982.4767195; CHANG RLP, 1977, IEEE T SYST MAN CYB, V7, P28, DOI 10.1109/TSMC.1977.4309586; DATTATREYA GR, 1980, 5TH P INT C PATT REC, P1212; DEMORI R, 1983, COMPUTER METHODS SPE; Devijver PA, 1982, PATTERN RECOGNITION; FU KS, 1982, SYNTACTIC PATTERN RE; GU YX, 1983, IEEE T PATTERN ANAL, V5, P83, DOI 10.1109/TPAMI.1983.4767349; Kanal L. N., 1977, APPLICATIONS STATIST, P301; KANAL LN, 1979, IEEE T PATTERN ANAL, V1, P193, DOI 10.1109/TPAMI.1979.4766905; KULKARNI AV, 1978, 4TH P INT JOINT C PA, P238; Kurzynski MW, 1983, PATTERN RECOGN LETT, V1, P305, DOI 10.1016/0167-8655(83)90068-5; LANDEWEERD GH, 1983, PATTERN RECOGN, V16, P571, DOI 10.1016/0031-3203(83)90073-0; MUI JK, 1980, IEEE T PATTERN ANAL, V2, P429, DOI 10.1109/TPAMI.1980.6592364; SETHI IK, 1982, IEEE T PATTERN ANAL, V4, P441, DOI 10.1109/TPAMI.1982.4767278; SHI QY, 1981, AUG P IEEE C IM PROC, P21; SUEN CY, 1984, PATTERN RECOGN, V17, P211, DOI 10.1016/0031-3203(84)90060-8; SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142, DOI 10.1109/TGE.1977.6498972; WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406, DOI 10.1109/TPAMI.1984.4767546; WANG QR, 1983, OCT P INT C CHIN INF, V1, P133; WANG QR, 1982, SEP P INT C CHIN LAN, P344; YOU KC, 1976, 3RD P S MACH PROC RE; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zadeh LA, 1975, FUZZY SETS THEIR APP	24	28	31	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					91	102		10.1109/TPAMI.1987.4767874	http://dx.doi.org/10.1109/TPAMI.1987.4767874			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869379				2022-12-18	WOS:A1987F378500007
J	FINK, PK; LUSTH, JC; DURAN, JW				FINK, PK; LUSTH, JC; DURAN, JW			A GENERAL EXPERT SYSTEM-DESIGN FOR DIAGNOSTIC PROBLEM-SOLVING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											FINK, PK (corresponding author), SW RES INST,DIV ELECTR SYST,DEPT AUTOMAT & DATA SYST,SAN ANTONIO,TX 78284, USA.							BUCHANAN BG, 1976, J AM CHEM SOC, V96; Chandrasekaran B., 1982, P NATIONAL C ARTIFIC, P349; DEKLEER J, 1979, P IJCAI 79 TOKYO, P197; ERMAN LD, 1980, COMPUT SURV, V12, P213, DOI 10.1145/356810.356816; HAMSCHER W, 1983, P AAAI, P152; Hayes-Roth F., 1978, PATTERN DIRECTED INF; JOHNSON CK, 1983, BUILDING EXPERT SYST; MCDERMOTT J, 1981, P IJCAI 81, P824; MICHALSKI R, 1980, INTJ POLICY ANAL INF, V4; MICHIE D, 1981, AI MAGAZINE      WIN, V3, P21; Minsky M., 1975, PSYCHOL COMPUTER VIS, P211; NAU DS, 1983, COMPUTER         FEB, P63; RIEGER C, 1979, P INT JOINT C ARTIF, P250; Shortliffe E.H., 2012, COMPUTER BASED MED C; STALLMAN RM, 1977, ARTIF INTELL, V9, P135, DOI 10.1016/0004-3702(77)90029-7; WEISS SM, 1978, ARTIF INTELL, V11, P145, DOI 10.1016/0004-3702(78)90015-2; WEISS SM, 1979, P INT JOINT C ART IN, P942; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; [No title captured]	19	28	29	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	5					553	560		10.1109/TPAMI.1985.4767702	http://dx.doi.org/10.1109/TPAMI.1985.4767702			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	AQH94	21869292				2022-12-18	WOS:A1985AQH9400006
J	INIGO, RM; MCVEY, ES; BERGER, BJ; WIRTZ, MJ				INIGO, RM; MCVEY, ES; BERGER, BJ; WIRTZ, MJ			MACHINE VISION APPLIED TO VEHICLE GUIDANCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											INIGO, RM (corresponding author), UNIV VIRGINIA,SCH ENGN & APPL SCI,CHARLOTTESVILLE,VA 22901, USA.							COOK RA, 1983, 13TH P INT S IND ROB, V7, P13; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FENTON RE, 1976, IEEE T AUTOMAT CONTR, V21, P306, DOI 10.1109/TAC.1976.1101230; Hannah M., 1974, THESIS STANFORD U ST; IANNINO A, 1978, 1978 P INT C PATT RE, P32; INIGO RM, 1982, APPLICATION IMAGE PR; JULLIERE M, 1983, 13TH P INT S IND ROB, V7, P13; LEE JW, 1981, MAR P SE S SYST THEO, pIB4; MARSHALL SV, 1972, MAY P IEEE WORKSH AP; MCVEY ES, 1982, IEEE T PATTERN ANAL, V4, P646, DOI 10.1109/TPAMI.1982.4767319; Moravec H., 1980, THESIS STANFORD U ST; MORAVEC HP, 1983, P IEEE, V71, P872, DOI 10.1109/PROC.1983.12684; Newman WM, 1979, PRINCIPLES INTERACTI, P333; OLSON KW, 1977, IEEE T VEH TECHNOL, V26, P161, DOI 10.1109/T-VT.1977.23673; ROBERTS LG, 1965, OPTICAL ELECTROOPTIC, P59; THOMPSON MM, MANUAL PHOTOGRAMMETR; TSUGAWA S, 1979, 6TH INT JOINT C ART; YATABE T, 1978, 1978 P NECI IND APPL	19	28	28	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					820	826		10.1109/TPAMI.1984.4767606	http://dx.doi.org/10.1109/TPAMI.1984.4767606			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499663				2022-12-18	WOS:A1984TX36100016
J	JAIN, RC				JAIN, RC			SEGMENTATION OF FRAME SEQUENCES OBTAINED BY A MOVING OBSERVER	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV MICHIGAN,DEPT ELECT & COMP ENGN,ANN ARBOR,MI 48109	University of Michigan System; University of Michigan	JAIN, RC (corresponding author), GM CORP,RES LABS,DEPT COMP SCI,WARREN,MI 48090, USA.							BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BRUSS AR, 1981, MIT662 AI MEM; CLOCKSIN WF, 1980, PERCEPTION, V9, P253, DOI 10.1068/p090253; Gibson J., 1979, ECOLOGICAL APPROACH; HORN B, 1981, ARTIFICIAL INTELL; HUANG TS, 1981, IMAGE SEQUENCE ANAL; Jain R., 1984, Image and Vision Computing, V2, P99, DOI 10.1016/0262-8856(84)90004-0; JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907; JAIN R, 1983, IEEE T PATTERN ANAL, V5, P58, DOI 10.1109/TPAMI.1983.4767345; JAIN R, 1983, GMR4548 GEN RES LAB; JAIN R, 1983, GMR4247 GEN MOT RES; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077	12	28	29	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					624	629		10.1109/TPAMI.1984.4767575	http://dx.doi.org/10.1109/TPAMI.1984.4767575			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813	21869230				2022-12-18	WOS:A1984TM81300007
J	SHI, QY; FU, KS				SHI, QY; FU, KS			PARSING AND TRANSLATION OF (ATTRIBUTED) EXPANSIVE GRAPH LANGUAGES FOR SCENE ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	SHI, QY (corresponding author), BEIJING UNIV,DEPT MATH,BEIJING,PEOPLES R CHINA.							BRAYER JM, 1975, TREE751 PURD U; BRAYER JM, 1977, P IEEE WORKSHOP DATA; BUNKE HO, 1981, TREE8122 PURD U; Carre B., 1979, GRAPHS NETWORKS; DELLAVIGNA P, 1978, INFORM CONTROL, V37, P207, DOI 10.1016/S0019-9958(78)90528-4; FAN TI, 1981, AUG P PRIP C DALL, P184; FRANCK R, 1978, ACTA INFORM, V10, P175, DOI 10.1007/BF00289155; FU KS, 1973, IEEE T COMPUT, VC 22, P1087, DOI 10.1109/T-C.1973.223654; FU KS, 1974, SYNTACTIC METHOD PAT; FU KS, 1976, PATTERN RECOGNITION; FU KS, 1973, COMPUT GRAPHICS IMAG, V2; Nagl M., 1979, LECTURE NOTES COMPUT, V73, P70; PAVLIDIS T, 1972, J ACM, V19, P11, DOI 10.1145/321679.321682; PAVLIDIS T, 1972, GRAPHIC LANGUAGES; PFALTZ JL, 1969, 1ST P INT JOINT C AR, P609; Pratt T. W., 1971, Journal of Computer and System Sciences, V5, P560, DOI 10.1016/S0022-0000(71)80016-8; SHAW AC, 1969, INFORM CONTROL, V14, P9, DOI 10.1016/S0019-9958(69)90017-5; SHI QY, 1981, TREE8132 PURD U; TSAI WH, 1980, IEEE T SYST MAN CYB, V10, P873, DOI 10.1109/TSMC.1980.4308414; TSAI WH, 1979, IEEE T SYST MAN CYBE, V9; 1972, PATTERN RECOGNITIO 2, V4; 1971, PATTERN RECOGNITION, V3; [No title captured]	23	28	30	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					472	485		10.1109/TPAMI.1983.4767426	http://dx.doi.org/10.1109/TPAMI.1983.4767426			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RM118	21869132				2022-12-18	WOS:A1983RM11800003
J	MCVEY, ES; LEE, JW				MCVEY, ES; LEE, JW			SOME ACCURACY AND RESOLUTION ASPECTS OF COMPUTER VISION DISTANCE MEASUREMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MCVEY, ES (corresponding author), UNIV VIRGINIA,SCH ENGN & APPL SCI,CHARLOTTESVILLE,VA 22901, USA.							DUDA RO, 1973, PATTERN CLASSIFICATI, P400; HALL E, 1979, COMPUTER IMAGE P REC, P43; LEE JW, UNPUB P SO S SYST TH; SATO T, 1979, P INT JOINT C ARTIFI, P763; YAKIMOWSKY Y, 1978, COMPUTER GRAPHICS IM, P195; 1972, HUMAN ENG GUIDE EQUI, P47; 1980, ELECTRONICS     0911, P78	7	28	29	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					646	649		10.1109/TPAMI.1982.4767319	http://dx.doi.org/10.1109/TPAMI.1982.4767319			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499640				2022-12-18	WOS:A1982PS23700011
J	Zhang, J; Fan, DP; Dai, YC; Anwar, S; Saleh, F; Aliakbarian, S; Barnes, N				Zhang, Jing; Fan, Deng-Ping; Dai, Yuchao; Anwar, Saeed; Saleh, Fatemeh; Aliakbarian, Sadegh; Barnes, Nick			Uncertainty Inspired RGB-D Saliency Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Saliency detection; Predictive models; Uncertainty; Pipelines; Data models; Labeling; Training; Uncertainty; RGB-D saliency detection; conditional variational autoencoders; alternating back-propagation	OBJECT DETECTION; FUSION; SEGMENTATION; ATTENTION; MODEL	We propose the first stochastic framework to employ uncertainty for RGB-D saliency detection by learning from the data labeling process. Existing RGB-D saliency detection models treat this task as a point estimation problem by predicting a single saliency map following a deterministic learning pipeline. We argue that, however, the deterministic solution is relatively ill-posed. Inspired by the saliency data labeling process, we propose a generative architecture to achieve probabilistic RGB-D saliency detection which utilizes a latent variable to model the labeling variations. Our framework includes two main models: 1) a generator model, which maps the input image and latent variable to stochastic saliency prediction, and 2) an inference model, which gradually updates the latent variable by sampling it from the true or approximate posterior distribution. The generator model is an encoder-decoder saliency network. To infer the latent variable, we introduce two different solutions: i) a Conditional Variational Auto-encoder with an extra encoder to approximate the posterior distribution of the latent variable; and ii) an Alternating Back-Propagation technique, which directly samples the latent variable from the true posterior distribution. Qualitative and quantitative results on six challenging RGB-D benchmark datasets show our approach's superior performance in learning the distribution of saliency maps. The source code is publicly available via our project page: https://github.com/JingZhang617/UCNet.	[Zhang, Jing] Australian Natl Univ, Sch Comp, ACRV, DATA61 CSIRO, Canberra, ACT 0200, Australia; [Fan, Deng-Ping] Nankai Univ, CS, Tianjin 300071, Peoples R China; [Dai, Yuchao] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China; [Anwar, Saeed] Australian Natl Univ, DATA61 CSIRO, Canberra, ACT 0200, Australia; [Saleh, Fatemeh; Aliakbarian, Sadegh] Australian Natl Univ, Sch Comp, ACRV, Canberra, ACT 0200, Australia; [Barnes, Nick] Australian Natl Univ, Sch Comp, Canberra, ACT 0200, Australia	Australian National University; Commonwealth Scientific & Industrial Research Organisation (CSIRO); Nankai University; Northwestern Polytechnical University; Australian National University; Commonwealth Scientific & Industrial Research Organisation (CSIRO); Australian National University; Australian National University	Fan, DP (corresponding author), Nankai Univ, CS, Tianjin 300071, Peoples R China.	zjnwpu@gmail.com; dengpfan@gmail.com; daiyuchao@gmail.com; saeed.atzwanr@data61.csiro.au; fatemehzsadat.saleh@anu.edu.au; sadegh.aliakbarian@anu.edu.au; nick.barnes@anu.edu.au	Fan, Deng-Ping/ABD-4052-2020; Barnes, Nick/Y-2744-2018	Fan, Deng-Ping/0000-0002-5245-7518; Barnes, Nick/0000-0002-9343-9535	National Natural Science Foundation of China [61871325, 61671387, 61620106008, 61572264]; National Key Research and Development Program of China [2018AAA0102803]; Tianjin Natural Science Foundation [17JCJQJC43700]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China; Tianjin Natural Science Foundation(Natural Science Foundation of Tianjin)	This work was supported in part by the National Natural Science Foundation of China under Grants 61871325, 61671387, 61620106008, and 61572264, National Key Research and Development Program of China (2018AAA0102803), and Tianjin Natural Science Foundation (17JCJQJC43700). A preliminary version of thiswork appeared at CVPR2020 [1].	Abubakar Abid, 2019, Arxiv, DOI arXiv:1902.04601; Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Ajay Pratap Singh, 2019, Arxiv, DOI arXiv:1904.01215; Aliakbarian S, 2020, PROC CVPR IEEE, P5222, DOI 10.1109/CVPR42600.2020.00527; Baumgartner CF, 2019, LECT NOTES COMPUT SC, V11765, P119, DOI 10.1007/978-3-030-32245-8_14; BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322; Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104; Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007; Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15; Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4; Cheng X., 2020, PROC INT C NEURAL IN, V33; Cheng Y., 2014, P INT C INTERNET MUL, P23; Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347; Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17; Du DP, 2019, PROC CVPR IEEE, P11828, DOI 10.1109/CVPR.2019.01211; Esser P, 2018, PROC CVPR IEEE, P8857, DOI 10.1109/CVPR.2018.00923; Fan D.-P., 2021, SCI SINICA INFORM, V6, DOI [10.1360/SSI-2020-0370, DOI 10.1360/SSI-2020-0370]; Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487; Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406; Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12; Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875; Fatemeh Sadat Saleh, 2020, Arxiv, DOI arXiv:1912.08521; Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257; Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172; Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326; Fu KR, 2022, IEEE T PATTERN ANAL, V44, P5541, DOI 10.1109/TPAMI.2021.3073689; Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gulrajani I., 2016, P INT C LEARN REPR; Guo J., 2016, PAPER PRESENTED IEEE, P1; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775; Han T, 2017, AAAI CONF ARTIF INTE, P1976; He Junxian, 2019, ARXIV190105534; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Henderson JM, 2017, NAT HUM BEHAV, V1, P743, DOI 10.1038/s41562-017-0208-0; Higgins I., 2017, P INT C LEARN REP RE; Hung Wei-Chih, 2018, ARXIV180207934; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Jiang B, 2021, IEEE T MULTIMEDIA, V23, P1343, DOI 10.1109/TMM.2020.2997184; Jianqiang Ren, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P25, DOI 10.1109/CVPRW.2015.7301391; Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222; Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304; Kingma D.P., 2013, INT C LEARN REPR; Kohl SAA, 2018, ADV NEUR IN, V31; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9; Li B, 2019, AAAI CONF ARTIF INTE, P8569; Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184; Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359; Liang FF, 2018, NEUROCOMPUTING, V275, P2227, DOI 10.1016/j.neucom.2017.10.052; Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326; Liu Y, 2019, IEEE I CONF COMP VIS, P1232, DOI 10.1109/ICCV.2019.00132; Long J., 2015, P IEEE C COMPUTER VI, P3431, DOI DOI 10.1109/CVPR.2015.7298965; Luc P., 2016, NIPS WORKSHOP ADVERS; Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698; Mehdi Mirza, 2014, Arxiv, DOI arXiv:1411.1784; Neal RM, 2011, CH CRC HANDB MOD STA, P113; Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377; Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708; Pan Junting, 2017, ABS170101081 CORR; Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7; Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735; Qin X., 2021, ARXIV; Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Settles B., 2009, ACT LEARN LIT SURV; Sohn K, 2015, ADV NEUR IN, V28; Sonderby CK, 2016, ADV NEUR IN, V29; Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277; Song SY, 2020, AAAI CONF ARTIF INTE, V34, P12023; Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606; Tan QY, 2018, PROC CVPR IEEE, P5841, DOI 10.1109/CVPR.2018.00612; Tang YB, 2019, IEEE T MULTIMEDIA, V21, P2237, DOI 10.1109/TMM.2019.2900908; Walker J, 2016, LECT NOTES COMPUT SC, V9911, P835, DOI 10.1007/978-3-319-46478-7_51; Wang J., 2020, PROC INT C NEURAL IN, V33; Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404; Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107; Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330; Wang WG, 2019, PROC CVPR IEEE, P5961, DOI 10.1109/CVPR.2019.00612; Wang Y, 2018, PROC CVPR IEEE, P4884, DOI 10.1109/CVPR.2018.00513; Wei Ji, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P52, DOI 10.1007/978-3-030-58523-5_4; Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321; Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834; Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736; Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403; Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yan X., 2018, LECT NOTES COMPUT SC, P276, DOI DOI 10.1007/978-3-030-01228-1_17; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388; Yi L, 2019, PROC CVPR IEEE, P3942, DOI 10.1109/CVPR.2019.00407; Zhai YJ, 2021, Arxiv, DOI arXiv:2007.02713; Yohanandan S. A., 2018, P ECCV, P235; Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908; Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15; Yu H., 2018, PROC 9 INT C GRAPHIC; Zhang CX, 2018, PROTEINS, V86, P136, DOI 10.1002/prot.25414; Zhang J, 2020, P IEEE CVF C COMP VI, P8582; Zhang J, 2018, PROC CVPR IEEE, P9029, DOI 10.1109/CVPR.2018.00941; Zhang Jing, 2020, CVPR; Zhang M, 2020, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR42600.2020.00353; Zhang X., 2018, 2018 IEEE 4 INT C MU, P1; Zhang Yulun, 2018, P EUROPEAN C COMPUTE, P286; Zhang Z, 2021, IEEE T IMAGE PROCESS, V30, P1949, DOI 10.1109/TIP.2021.3049959; Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405; Zhong YR, 2019, PROC CVPR IEEE, P12087, DOI 10.1109/CVPR.2019.01237; Zhong YR, 2018, LECT NOTES COMPUT SC, V11213, P441, DOI 10.1007/978-3-030-01240-3_27; Zhong YR, 2018, LECT NOTES COMPUT SC, V11206, P104, DOI 10.1007/978-3-030-01216-8_7; Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z; Zhu CB, 2017, IEEE INT CONF COMP V, P1509, DOI 10.1109/ICCVW.2017.178; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360	118	27	27	11	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5761	5779		10.1109/TPAMI.2021.3073564	http://dx.doi.org/10.1109/TPAMI.2021.3073564			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33856982	Green Submitted			2022-12-18	WOS:000836666600088
J	Li, PK; Xu, YQ; Wei, YC; Yang, Y				Li, Peike; Xu, Yunqiu; Wei, Yunchao; Yang, Yi			Self-Correction for Human Parsing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Task analysis; Predictive models; Annotations; Semantics; Analytical models; Solid modeling; Human parsing; learning with label noise; fine-grained semantic segmentation; video human parsing		Labeling pixel-level masks for fine-grained semantic segmentation tasks, e.g., human parsing, remains a challenging task. The ambiguous boundary between different semantic parts and those categories with similar appearances are usually confusing for annotators, leading to incorrect labels in ground-truth masks. These label noises will inevitably harm the training process and decrease the performance of the learned models. To tackle this issue, we introduce a noise-tolerant method in this work, called Self-Correction for Human Parsing (SCHP), to progressively promote the reliability of the supervised labels as well as the learned models. In particular, starting from a model trained with inaccurate annotations as initialization, we design a cyclically learning scheduler to infer more reliable pseudo masks by iteratively aggregating the current learned model with the former sub-optimal one in an online manner. Besides, those correspondingly corrected labels can in turn to further boost the model performance. In this way, the models and the labels will reciprocally become more robust and accurate during the self-correction learning cycles. Our SCHP is model-agnostic and can be applied to any human parsing models for further enhancing their performance. Extensive experiments on four human parsing models, including Deeplab V3+, CE2P, OCR and CE2P+, well demonstrate the effectiveness of the proposed SCHP. We achieve the new state-of-the-art results on 6 benchmarks, including LIP, Pascal-Person-Part and ATR for single human parsing, CIHP and MHP for multi-person human parsing and VIP for video human parsing tasks. In addition, benefiting the superiority of SCHP, we achieved the 1st place on all the three human parsing tracks in the 3rd Look Into Person Challenge. The code is available at https://github.com/PeikeLi/Self-Correction-Human-Parsing.	[Li, Peike; Xu, Yunqiu; Wei, Yunchao; Yang, Yi] Univ Technol Sydney, Australian Artificial Intelligence Inst, ReLER Lab, Ultimo, NSW 2007, Australia	University of Technology Sydney	Yang, Y (corresponding author), Univ Technol Sydney, Australian Artificial Intelligence Inst, ReLER Lab, Ultimo, NSW 2007, Australia.	peike.li@student.uts.edu.au; yunxiu.xu-1@student.uts.edu.au; yunchao.wei@uts.edu.au; yi.yang@uts.edu.au	yang, yang/HGT-7999-2022; yang, yang/GWB-9426-2022; Yang, Yi/B-9273-2017; Li, Peike/ACJ-3130-2022; xu, yunqiu/HHC-5717-2022; yang, yang/GVT-5210-2022	Yang, Yi/0000-0002-0512-880X; Li, Pengwei/0000-0001-9441-2847	ARC [DP200100938]; ARC DECRA [DE190101315]	ARC(Australian Research Council); ARC DECRA(Australian Research Council)	This work was supported in part by the ARC DP200100938 and ARC DECRA DE190101315. Part of this work was done when Peike Li and Yunqiu Xu were research interns at Baidu Research.	Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Fang HS, 2018, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2018.00015; Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47; Gong K, 2019, PROC CVPR IEEE, P7442, DOI 10.1109/CVPR.2019.00763; Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715; He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/TPAMI.2018.2844175; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton G., 2015, ARXIV150302531; Izmailov P, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P876; Laine Samuli, 2016, ARXIV161002242; Lee D.-H., 2013, ICML WORKSHOP CHALLE, V3, P2; Li J, 2017, ARXIV 170507206; Li P., 2020, ADV NEUR IN, P10317; Li Q., 2017, PROC BRIT MACH VIS C; Li X., 2020, BMVC, P1; Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063; Liang XD, 2016, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2016.347; Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8; Liang XD, 2015, IEEE I CONF COMP VIS, P1386, DOI 10.1109/ICCV.2015.163; Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360; Liu XC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P338, DOI 10.1145/3343031.3350857; Loshchilov I., 2017, P INT C LEARNING REP; Luo XH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P654, DOI 10.1145/3240508.3240634; Luo YW, 2018, LECT NOTES COMPUT SC, V11213, P424, DOI 10.1007/978-3-030-01240-3_26; Muller R, 2019, ADV NEUR IN, V32; Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P519, DOI 10.1007/978-3-030-01228-1_31; Peike Li, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P64, DOI 10.1145/3394171.3413944; Reed Scott, 2014, ARXIV14126596; Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7; Ruan T, 2019, AAAI CONF ARTIF INTE, P4814; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58; Sun K., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1904.04514; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tarvainen A, 2017, ADV NEUR IN, V30; Wang WG, 2019, IEEE I CONF COMP VIS, P5702, DOI 10.1109/ICCV.2019.00580; Wojke N, 2017, IEEE IMAGE PROC, P3645; Xia F., 2016, ECCV, P648; Xia FT, 2017, PROC CVPR IEEE, P6080, DOI 10.1109/CVPR.2017.644; Yang L, 2019, PROC CVPR IEEE, P364, DOI 10.1109/CVPR.2019.00045; Yuan Y., 2018, ARXIV 180900916; Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao J, 2020, INT J COMPUT VISION, V128, P2185, DOI 10.1007/s11263-019-01181-5; Zhao J, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P792, DOI 10.1145/3240508.3240509; Zhou QX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1527, DOI 10.1145/3240508.3240660; Zhu BK, 2018, AAAI CONF ARTIF INTE, P7607; Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52; Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441	58	27	28	11	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3260	3271		10.1109/TPAMI.2020.3048039	http://dx.doi.org/10.1109/TPAMI.2020.3048039			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33373297	Green Submitted			2022-12-18	WOS:000803117500034
J	Giraldozuluaga, JH; Javed, S; Bouwmans, T				Giraldozuluaga, Jhony H.; Javed, Sajid; Bouwmans, Thierry			Graph Moving Object Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Videos; Task analysis; Signal processing algorithms; Object segmentation; Semisupervised learning; Deep learning; Complexity theory; Moving object segmentation; graph signal processing; semi-supervised learning; unseen videos; video object segmentation		Moving Object Segmentation (MOS) is a fundamental task in computer vision. Due to undesirable variations in the background scene, MOS becomes very challenging for static and moving camera sequences. Several deep learning methods have been proposed for MOS with impressive performance. However, these methods show performance degradation in the presence of unseen videos; and usually, deep learning models require large amounts of data to avoid overfitting. Recently, graph learning has attracted significant attention in many computer vision applications since they provide tools to exploit the geometrical structure of data. In this work, concepts of graph signal processing are introduced for MOS. First, we propose a new algorithm that is composed of segmentation, background initialization, graph construction, unseen sampling, and a semi-supervised learning method inspired by the theory of recovery of graph signals. Second, theoretical developments are introduced, showing one bound for the sample complexity in semi-supervised learning, and two bounds for the condition number of the Sobolev norm. Our algorithm has the advantage of requiring less labeled data than deep learning methods while having competitive results on both static and moving camera videos. Our algorithm is also adapted for Video Object Segmentation (VOS) tasks and is evaluated on six publicly available datasets outperforming several state-of-the-art methods in challenging conditions.	[Giraldozuluaga, Jhony H.; Bouwmans, Thierry] La Rochelle Univ, Lab MIA Math Image & Applicat, F-17000 La Rochelle, France; [Javed, Sajid] Khalifa Univ, Ctr Autonomous Robot Syst, Abu Dhabi 127788, U Arab Emirates	Khalifa University of Science & Technology	Giraldozuluaga, JH (corresponding author), La Rochelle Univ, Lab MIA Math Image & Applicat, F-17000 La Rochelle, France.	jgiral01@univ-lr.fr; sajid.javed@ku.ac.ae; tbouwman@univ-lr.fr	BOUWMANS, Thierry/H-7041-2017; Giraldo, Jhony H./O-7502-2019	BOUWMANS, Thierry/0000-0003-4018-8856; Giraldo, Jhony H./0000-0002-0039-1270	Khalifa University of Science and Technology [RC1-2018-KUCARS]	Khalifa University of Science and Technology	This work was supported by the Khalifa University of Science and Technology under award No. RC1-2018-KUCARS. Jhony H. Giraldo, Sajid Javed, and Thierry Bouwmans equally contributed to this work.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Ramirez-Quintana JA, 2015, PATTERN RECOGN, V48, P1137, DOI 10.1016/j.patcog.2014.09.009; Anis A, 2019, IEEE T INFORM THEORY, V65, P2322, DOI 10.1109/TIT.2018.2879897; Anis A, 2016, IEEE T SIGNAL PROCES, V64, P3775, DOI 10.1109/TSP.2016.2546233; Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Bianco S, 2017, IEEE T EVOLUT COMPUT, V21, P914, DOI 10.1109/TEVC.2017.2694160; Bouwmans T., 2008, RECENT PATENTS COMPU, V1, P219; Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024; Bouwmans T, 2017, COMPUT SCI REV, V23, P1, DOI 10.1016/j.cosrev.2016.11.001; Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001; Bouwmans T, 2014, COMPUT VIS IMAGE UND, V122, P22, DOI 10.1016/j.cviu.2013.11.009; Boyd S, 2004, CONVEX OPTIMIZATION; Braham M, 2017, IEEE IMAGE PROC, P4552; Braham M, 2016, INT CONF SYST SIGNAL, P113; Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565; Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Chatfield K, 2014, P BRIT MACH VIS C; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen SH, 2015, IEEE T SIGNAL PROCES, V63, P6510, DOI 10.1109/TSP.2015.2469645; Cheng JC, 2018, PROC CVPR IEEE, P7415, DOI 10.1109/CVPR.2018.00774; Cheung G, 2018, P IEEE, V106, P907, DOI 10.1109/JPROC.2018.2799702; Chung F.R.K., 1997, AM MATH SOC, DOI DOI 10.1090/CBMS/092; Cinar GT, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P489, DOI 10.1109/IJCNN.2011.6033261; Cioppa A, 2020, IEEE IMAGE PROC, P3214, DOI 10.1109/ICIP40778.2020.9190838; Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733; Dong Y, 2011, COMPUT VIS IMAGE UND, V115, P31, DOI 10.1016/j.cviu.2010.08.003; Pham DS, 2015, IEEE T IMAGE PROCESS, V24, P332, DOI 10.1109/TIP.2014.2378034; El Baf F, 2008, IEEE INT CONF FUZZY, P1731; Fengting Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13961, DOI 10.1109/CVPR42600.2020.01398; Gangapure VN, 2018, IEEE T CIRC SYST VID, V28, P1263, DOI 10.1109/TCSVT.2017.2662743; Garcia-Garcia B, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100204; Garcia-Gonzalez J, 2019, PATTERN RECOGN LETT, V125, P481, DOI 10.1016/j.patrec.2019.06.006; Giraldo JH, 2020, IEEE IMAGE PROC, P3224, DOI 10.1109/ICIP40778.2020.9190887; Guestrin C, 2004, IPSN '04: THIRD INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P1; Guskov I, 1999, COMP GRAPH, P325, DOI 10.1145/311535.311577; Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239; Hammack R.H., 2011, HAND BOOK PRODUCT GR, V2; Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005; He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Horn R. A., 1986, MATRIX ANAL; Hu YT, 2017, ADV NEUR IN, V30; Isik S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023002; Javed S, 2020, IEEE T IMAGE PROCESS, V29, P9204, DOI 10.1109/TIP.2020.3023795; Javed S, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101696; Javed S, 2020, IEEE T IMAGE PROCESS, V29, P4390, DOI 10.1109/TIP.2020.2972102; Javed S, 2019, IEEE T IMAGE PROCESS, V28, P1007, DOI 10.1109/TIP.2018.2874289; Javed S, 2018, IEEE T CIRC SYST VID, V28, P1315, DOI 10.1109/TCSVT.2016.2632302; Javed S, 2017, IEEE T IMAGE PROCESS, V26, P5840, DOI 10.1109/TIP.2017.2746268; Jiang SQ, 2018, IEEE T CIRC SYST VID, V28, P2105, DOI 10.1109/TCSVT.2017.2711659; Johnander J, 2019, PROC CVPR IEEE, P8945, DOI 10.1109/CVPR.2019.00916; Jung A, 2019, IEEE T SIGNAL PROCES, V67, P6256, DOI 10.1109/TSP.2019.2953593; Jung J, 2019, INT CONF BIG DATA, P277; Kang Z, 2015, IEEE DATA MINING, P211, DOI 10.1109/ICDM.2015.15; Komodakis N, 2015, IEEE SIGNAL PROC MAG, V32, P31, DOI 10.1109/MSP.2014.2377273; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102; Lee SH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050621; Li CL, 2019, IEEE T PATTERN ANAL, V41, P2770, DOI 10.1109/TPAMI.2018.2864965; Li L., 2003, P 11 ACM INT C MULT, P2, DOI DOI 10.1145/957013.957017; Li S, 2018, IEEE T IMAGE PROCESS, V27, P3918, DOI 10.1109/TIP.2018.2828329; Li XX, 2018, LECT NOTES COMPUT SC, V11207, P93, DOI 10.1007/978-3-030-01219-9_6; Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9; Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Luiten J, 2019, LECT NOTES COMPUT SC, V11364, P565, DOI 10.1007/978-3-030-20870-7_35; Ma C, 2019, IEEE T PATTERN ANAL, V41, P2709, DOI 10.1109/TPAMI.2018.2865311; Maddalena L, 2015, LECT NOTES COMPUT SC, V9281, P469, DOI 10.1007/978-3-319-23222-5_57; Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112; Mahmood F, 2018, IEEE SIGNAL PROC LET, V25, P700, DOI 10.1109/LSP.2018.2816582; Mandal M, 2019, IEEE SIGNAL PROC LET, V26, P1882, DOI 10.1109/LSP.2019.2952253; Maninis KK, 2019, IEEE T PATTERN ANAL, V41, P1515, DOI 10.1109/TPAMI.2018.2838670; Narang SK, 2010, IEEE IMAGE PROC, P333, DOI 10.1109/ICIP.2010.5651072; Oh SW, 2022, IEEE T PATTERN ANAL, V44, P442, DOI 10.1109/TPAMI.2020.3008917; Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oreifej O, 2013, IEEE T PATTERN ANAL, V35, P450, DOI 10.1109/TPAMI.2012.97; Parada-Mayorga A, 2019, IEEE T SIGNAL INF PR, V5, P554, DOI 10.1109/TSIPN.2019.2922852; Parikh N., 2014, FDN TRENDS OPTIM, V1, P127, DOI DOI 10.1561/2400000003; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372; Perraudin N., 2014, ARXIV14020779; Perraudin N., 2014, ARXIV E PRINTS; Pesenson I, 2008, T AM MATH SOC, V360, P5603, DOI 10.1090/S0002-9947-08-04511-X; Pesenson I, 2009, CONSTR APPROX, V29, P1, DOI 10.1007/s00365-007-9004-9; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Romero D, 2017, IEEE T SIGNAL PROCES, V65, P764, DOI 10.1109/TSP.2016.2620116; Sandryhaila A, 2013, IEEE T SIGNAL PROCES, V61, P1644, DOI 10.1109/TSP.2013.2238935; Shalev-Shwartz S., 2014, UNDERSTANDING MACHIN, DOI DOI 10.1017/CBO9781107298019; Shang FH, 2018, IEEE T PATTERN ANAL, V40, P2066, DOI 10.1109/TPAMI.2017.2748590; Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shu XB, 2014, PROC CVPR IEEE, P3874, DOI 10.1109/CVPR.2014.495; Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192; Sobral A., 2014, HDB BACKGROUND MODEL; Sobral A., 2015, ROBUST LOW RANK SPAR; St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137; St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Sultana M, 2019, MACH VISION APPL, V30, P375, DOI 10.1007/s00138-018-0993-0; Tezcan MO, 2020, IEEE WINT CONF APPL, P2763, DOI 10.1109/WACV45572.2020.9093464; Vargas-Munoz JE, 2019, IEEE T IMAGE PROCESS, V28, P3477, DOI 10.1109/TIP.2019.2897941; Vaswani N, 2018, IEEE SIGNAL PROC MAG, V35, P32, DOI 10.1109/MSP.2018.2826566; Ventura C, 2019, PROC CVPR IEEE, P5272, DOI 10.1109/CVPR.2019.00542; Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661; Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971; Voigtlaender Paul, 2017, ARXIV170609364; Wagner R, 2006, IEEE DECIS CONTR P, P375; Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68; Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014; Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126; Wang Z, 2015, SIAM J SCI COMPUT, V37, pA488, DOI 10.1137/130934271; Wu Y., 2019, DETECTRON2 FACEBOOK; Xu N, 2018, LECT NOTES COMPUT SC, V11209, P603, DOI 10.1007/978-3-030-01228-1_36; Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680; Zhang H., 2020, ARXIV 200408955; Zhou K, 2004, COMPUT AIDED DESIGN, V36, P363, DOI 10.1016/S0010-4485(03)00098-8; Zhou X., 2011, P 14 INT C ART INT S, P892; Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132; Zhu XF, 2012, INT CONF ACOUST SPEE, P3921, DOI 10.1109/ICASSP.2012.6288775	124	27	27	11	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2485	2503		10.1109/TPAMI.2020.3042093	http://dx.doi.org/10.1109/TPAMI.2020.3042093			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33296300				2022-12-18	WOS:000792921400021
J	Zhang, L; Shi, ZL; Cheng, MM; Liu, Y; Bian, JW; Zhou, JT; Zheng, GY; Zeng, Z				Zhang, Le; Shi, Zenglin; Cheng, Ming-Ming; Liu, Yun; Bian, Jia-Wang; Zhou, Joey Tianyi; Zheng, Guoyan; Zeng, Zeng			Nonlinear Regression via Deep Negative Correlation Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Estimation; Training; Correlation; Computational modeling; Deep learning; Computer vision; Deep learning; deep regression; negative correlation learning; convolutional neural network	HUMAN AGE ESTIMATION; IMAGE QUALITY ASSESSMENT; SUPERRESOLUTION; CLASSIFICATION; CLASSIFIERS; DIVERSITY; ENSEMBLES; NETWORKS; CASCADE; ERROR	Nonlinear regression has been extensively employed in many computer vision problems (e.g., crowd counting, age estimation, affective computing). Under the umbrella of deep learning, two common solutions exist i) transforming nonlinear regression to a robust loss function which is jointly optimizable with the deep convolutional network, and ii) utilizing ensemble of deep networks. Although some improved performance is achieved, the former may be lacking due to the intrinsic limitation of choosing a single hypothesis and the latter may suffer from much larger computational complexity. To cope with those issues, we propose to regress via an efficient "divide and conquer" manner. The core of our approach is the generalization of negative correlation learning that has been shown, both theoretically and empirically, to work well for non-deep regression problems. Without extra parameters, the proposed method controls the bias-variance-covariance trade-off systematically and usually yields a deep regression ensemble where each base model is both "accurate" and "diversified." Moreover, we show that each sub-problem in the proposed method has less Rademacher Complexity and thus is easier to optimize. Extensive experiments on several diverse and challenging tasks including crowd counting, personality analysis, age estimation, and image super-resolution demonstrate the superiority over challenging baselines as well as the versatility of the proposed method. The source code and trained models are available on our project page: https://mmcheng.net/dncl/.	[Zhang, Le; Zhou, Joey Tianyi; Zeng, Zeng] ASTAR, Singapore 138632, Singapore; [Shi, Zenglin] Univ Amsterdam, NL-1012 WX Amsterdam, Netherlands; [Cheng, Ming-Ming; Liu, Yun] Nankai Univ, Coll Comp Sci, TKLNDST, Nankai 300071, Peoples R China; [Bian, Jia-Wang] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Zheng, Guoyan] Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai 200240, Peoples R China	Agency for Science Technology & Research (A*STAR); University of Amsterdam; Nankai University; University of Adelaide; Shanghai Jiao Tong University	Cheng, MM (corresponding author), Nankai Univ, Coll Comp Sci, TKLNDST, Nankai 300071, Peoples R China.	lzhang027@ntu.edu.sg; iezlshi@gmail.com; cmm@nankai.edu.cn; nk12csly@mail.nankai.edu.cn; jiawang.bian@gmail.com; joey.tianyi.zhou@gmail.com; guoyan.zheng@ieee.org; zengz@i2r.a-star.edu.sg	Bian, Jia-Wang/AAH-4463-2019; Bian, Jia-Wang/AAP-2274-2020; 于, 于增臣/AAH-4657-2021; Cheng, Ming-Ming/A-2527-2009	Bian, Jia-Wang/0000-0003-2046-3363; Bian, Jia-Wang/0000-0003-2046-3363; Cheng, Ming-Ming/0000-0001-5550-8758	Major Project for New Generation of AI Grant [2018AAA0100400]; NSFC [61922046, 61620106008]; national youth talent support program; Tianjin Natural Science Foundation [18ZXZNGX00110, 17JCJQJC43700]	Major Project for New Generation of AI Grant; NSFC(National Natural Science Foundation of China (NSFC)); national youth talent support program; Tianjin Natural Science Foundation(Natural Science Foundation of Tianjin)	This researchwas supported by Major Project for New Generation of AI Grant No.2018AAA0100400 and NSFC (61922046, 61620106008), the national youth talent support program, and the Tianjin Natural Science Foundation (18ZXZNGX00110, 17JCJQJC43700).	Abadi Mojtaba Khomami, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163100; Agustsson E, 2017, IEEE I CONF COMP VIS, P1652, DOI 10.1109/ICCV.2017.182; Alhamdoosh M, 2014, INFORM SCIENCES, V264, P104, DOI 10.1016/j.ins.2013.12.016; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arteta C, 2016, LECT NOTES COMPUT SC, V9911, P483, DOI 10.1007/978-3-319-46478-7_30; Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Batrinca L.M., 2011, P 13 INT C MULT INT, P255, DOI [10.1145/2070481.2070528, DOI 10.1145/2070481.2070528]; Belagiannis V, 2015, IEEE I CONF COMP VIS, P2830, DOI 10.1109/ICCV.2015.324; Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135; Biel JI, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P53; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Brown G, 2005, J MACH LEARN RES, V6, P1621; Brown G., 2005, Information Fusion, V6, P5, DOI 10.1016/j.inffus.2004.04.004; Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437; Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319; Chen SX, 2017, PROC CVPR IEEE, P742, DOI 10.1109/CVPR.2017.86; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cortes C, 2014, PR MACH LEARN RES, V32, P1179; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Escalante H. J., 2019, EXPLAINING 1 IMPRESS; Fernandez-Delgado M, 2014, J MACH LEARN RES, V15, P3133; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gucluturk Y, 2016, LECT NOTES COMPUT SC, V9915, P349, DOI 10.1007/978-3-319-49409-8_28; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404; Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681; Gurpinar F, 2016, LECT NOTES COMPUT SC, V9915, P372, DOI 10.1007/978-3-319-49409-8_30; Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759; Han S, 2016, ADV NEURAL INF PROCE, V29, DOI 10.5555/3157096.3157109; Han W, 2018, PROC CVPR IEEE, P1654, DOI 10.1109/CVPR.2018.00178; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156; Huber P. J, 2011, P INT ENC STAT SCI, P1248; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Huo ZW, 2016, IEEE COMPUT SOC CONF, P722, DOI 10.1109/CVPRW.2016.95; Jacques JCS, 2022, IEEE T AFFECT COMPUT, V13, P75, DOI 10.1109/TAFFC.2019.2930058; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Koltchinskii V, 2002, ANN STAT, V30, P1; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuang-Yu Chang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3396, DOI 10.1109/ICPR.2010.829; Lee S., 2016, ADV NEURAL INFORM PR, V29, P2119; Lempitsky V., 2010, NIPS, V23, P1324; Lepri B, 2012, IEEE T AFFECT COMPUT, V3, P443, DOI 10.1109/T-AFFC.2012.17; Li K, 2018, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2018.00049; Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545; Liu WC, 2017, PROCEEDINGS OF 2017 IEEE FAR EAST FORUM ON NONDESTRUCTIVE EVALUATION/TESTING: NEW TECHNOLOGY & APPLICATION (IEEE FENDT 2017), P1, DOI 10.1109/FENDT.2017.8584561; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380, DOI 10.1109/4235.887237; LIU Y, 2019, NEURAL NETWORKS, V41, P1939; Luu Khoa, 2011, BIOM IJCB 2011 INT J, P1, DOI DOI 10.1109/IJCB.2011.6117601; Mao XJ, 2016, ADV NEUR IN, V29; Marsden M., 2017, P INT C COMP VIS THE; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; MINKU LL, 2010, LECT NOTES COMPUT SC, V22, P730; Montilla A, 2009, IEEE IMAGE PROC, P2465, DOI 10.1109/ICIP.2009.5414103; Niu ZX, 2016, PROC CVPR IEEE, P4920, DOI 10.1109/CVPR.2016.532; Noroozi M, 2017, IEEE I CONF COMP VIS, P5899, DOI 10.1109/ICCV.2017.628; Onoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38; Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053; Ponce-Lopez V, 2016, LECT NOTES COMPUT SC, V9915, P400, DOI 10.1007/978-3-319-49409-8_32; Qiu XH, 2017, INFORM SCIENCES, V420, P249, DOI 10.1016/j.ins.2017.08.060; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren Y, 2016, IEEE COMPUT INTELL M, V11, P41, DOI 10.1109/MCI.2015.2471235; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3; Rothe R, 2016, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2016.599; Sanchez-Cortes Dairazalia, 2013, P 12 INT C MOB UB MU, P22; Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003; Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389; Shen W, 2018, PROC CVPR IEEE, P2304, DOI 10.1109/CVPR.2018.00245; Shen W, 2017, ADV NEUR IN, V30; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; SHI Z, 2016, IEEE T PATTERN ANAL, V83, P21; Shi ZL, 2018, PROC CVPR IEEE, P5382, DOI 10.1109/CVPR.2018.00564; Shi ZL, 2018, IEEE T IND INFORM, V14, P4953, DOI 10.1109/TII.2018.2852481; Subramaniam A, 2016, LECT NOTES COMPUT SC, V9915, P337, DOI 10.1007/978-3-319-49409-8_27; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Tang EK, 2006, MACH LEARN, V65, P247, DOI 10.1007/s10994-006-9449-2; Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41; Wang C., 2015, P 23 ACM INT C MULT, P1299, DOI [DOI 10.1145/2733373.28063370-12345-67-8/90/01, 10.1145/2733373.2806337, DOI 10.1145/2733373.2806337]; WANG L, 2016, P EUR C COMP VIS; Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153; Wang X., 2014, ADV NEURAL INFORM PR; Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yi D, 2015, LECT NOTES COMPUT SC, V9005, P144, DOI 10.1007/978-3-319-16811-1_10; Yu F., 2016, P ICLR 2016; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zeng LK, 2017, IEEE IMAGE PROC, P465; Zeyde Roman, 2010, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47; Zhang CL, 2016, LECT NOTES COMPUT SC, V9915, P311, DOI 10.1007/978-3-319-49409-8_25; Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684; Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344; Zhang L, 2017, PROC CVPR IEEE, P5825, DOI 10.1109/CVPR.2017.617; Zhang L, 2017, IEEE COMPUT INTELL M, V12, P61, DOI 10.1109/MCI.2017.2742867; Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70; Zhang YB, 2019, IEEE T SYST MAN CY-S, V49, P845, DOI 10.1109/TSMC.2017.2705480; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975; Zhang Yulun, 2018, P EUROPEAN C COMPUTE, P286; Zhang Yulun, 2019, ARXIV190310082; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	124	27	28	8	68	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					982	998		10.1109/TPAMI.2019.2943860	http://dx.doi.org/10.1109/TPAMI.2019.2943860			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31562072				2022-12-18	WOS:000616309900016
J	Yang, TY; Chan, AB				Yang, Tianyu; Chan, Antoni B.			Visual Tracking via Dynamic Memory Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dynamic memory networks; spatial attention; gated residual template learning; distractor template canceling	OBJECT TRACKING; NEURAL-NETWORK	Template-matching methods for visual tracking have gained popularity recently due to their good performance and fast speed. However, they lack effective ways to adapt to changes in the target object's appearance, making their tracking accuracy still far from state-of-the-art. In this paper, we propose a dynamic memory network to adapt the template to the target's appearance variations during tracking. The reading and writing process of the external memory is controlled by an LSTM network with the search feature map as input. A spatial attention mechanism is applied to concentrate the LSTM input on the potential target as the location of the target is at first unknown. To prevent aggressive model adaptivity, we apply gated residual template learning to control the amount of retrieved memory that is used to combine with the initial template. In order to alleviate the drift problem, we also design a "negative" memory unit that stores templates for distractors, which are used to cancel out wrong responses from the object template. To further boost the tracking performance, an auxiliary classification loss is added after the feature extractor part. Unlike tracking-by-detection methods where the object's information is maintained by the weight parameters of neural networks, which requires expensive online fine-tuning to be adaptable, our tracker runs completely feed-forward and adapts to the target's appearance changes by updating the external memory. Moreover, the capacity of our model is not determined by the network size as with other trackers - the capacity can be easily enlarged as the memory requirements of a task increase, which is favorable for memorizing long-term object information. Extensive experiments on the OTB and VOT datasets demonstrate that our trackers perform favorably against state-of-the-art tracking methods while retaining real-time speed.	[Yang, Tianyu; Chan, Antoni B.] City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China	City University of Hong Kong	Yang, TY (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.	tianyyang8-c@my.cityu.edu.hk; abchan@cityu.edu.hk		Yang, Tianyu/0000-0002-9674-5220	Research Grants Council of the Hong Kong Special Administrative Region, China [CityU 11200314, CityU 11212518]; NVIDIA Corporation	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council); NVIDIA Corporation	This work was supported by grants from the Research Grants Council of the Hong Kong Special Administrative Region, China (CityU 11200314, and CityU 11212518). We are grateful for the support of NVIDIA Corporation with the donation of the Tesla K40 GPU used for this research.	Abadi M, 2015, P 12 USENIX S OPERAT; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chi ZZ, 2017, IEEE T IMAGE PROCESS, V26, P2005, DOI 10.1109/TIP.2017.2669880; Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513; Collobert R., 2008, P 25 ICML, V25, P160, DOI DOI 10.1145/1390156.1390177; Danelljan M, 2014, BRIT MACHINE VISIO, P1; Danelljan M., 2016, P IEEE INT C COMP VI; Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733; Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Deng L, 2013, IEEE INT NEW CIRC; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Graves A., 2014, ARXIV14105401; Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101; Gulinsa G, 2010, CHINESE J INORG CHEM, V26, P733; Gundogdu E, 2018, IEEE T IMAGE PROCESS, V27, P2526, DOI 10.1109/TIP.2018.2806280; Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196; Han B, 2017, PROC CVPR IEEE, P521, DOI 10.1109/CVPR.2017.63; He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hinton, 2016, ARXIV PREPRINT ARXIV; Hua Y, 2015, IEEE I CONF COMP VIS, P3092, DOI 10.1109/ICCV.2015.354; Huang C, 2017, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2017.21; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781; Kingma D.P, P 3 INT C LEARNING R; Kristan M., 2016, P EUR C COMPUT VIS, P607; Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230; Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935; Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007; Li SJ, 2015, INT J COMPUT VISION, V113, P19, DOI 10.1007/s11263-014-0767-8; Li Yi, 2017, P IEEE C COMP VIS PA; Liu B., 2017, ARXIV171109414; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Long Y, 2018, IEEE INT CONF COMMUN, P158, DOI 10.1109/ICCChinaW.2018.8674473; Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; NAM H, 2016, PROC CVPR IEEE, P4293, DOI DOI 10.1109/CVPR.2016.465; Nam H., 2016, ARXIV160807242; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Santoro A, 2016, PR MACH LEARN RES, V48; Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sukhbaatar S, 2015, ADV NEUR IN, V28; Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158; Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; WANG MM, 2017, PROC CVPR IEEE, P4800, DOI DOI 10.1109/CVPR.2017.510; Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510; Weston Jason, 2015, P INT C LEARN REPR; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Yang TY, 2017, IEEE INT CONF COMP V, P2010, DOI 10.1109/ICCVW.2017.235; Yao J, 2012, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2012.6247739; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI 10.1109/CVPR.2017.512; Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108	75	27	27	5	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					360	374		10.1109/TPAMI.2019.2929034	http://dx.doi.org/10.1109/TPAMI.2019.2929034			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31352331	Green Submitted			2022-12-18	WOS:000597206900024
J	Gao, HY; Yuan, H; Wang, ZY; Ji, SW				Gao, Hongyang; Yuan, Hao; Wang, Zhengyang; Ji, Shuiwang			Pixel Transposed Convolutional Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolution; Semantics; Image segmentation; Kernel; Task analysis; Image generation; Analytical models; Deep learning; pixel-wise prediction; up-sampling; transposed convolution; pixel transposed convolution		Transposed convolutional layers have been widely used in a variety of deep models for up-sampling, including encoder-decoder networks for semantic segmentation and deep generative models for unsupervised learning. One of the key limitations of transposed convolutional operations is that they result in the so-called checkerboard problem. This is caused by the fact that no direct relationship exists among adjacent pixels on the output feature map. To address this problem, we propose the pixel transposed convolutional layer (PixelTCL) to establish direct relationships among adjacent pixels on the up-sampled feature map. Our method is based on a fresh interpretation of the regular transposed convolutional operation. The resulting PixelTCL can be used to replace any transposed convolutional layer in a plug-and-play manner without compromising the fully trainable capabilities of original models. The proposed PixelTCL may result in slight decrease in efficiency, but this can be overcome by an implementation trick. Experimental results on semantic segmentation demonstrate that PixelTCL can consider spatial features such as edges and shapes and yields more accurate segmentation outputs than transposed convolutional layers. When used in image generation tasks, our PixelTCL can largely overcome the checkerboard problem suffered by regular transposed convolutional operations.	[Gao, Hongyang; Wang, Zhengyang; Ji, Shuiwang] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA; [Yuan, Hao] Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA	Texas A&M University System; Texas A&M University College Station; Washington State University	Ji, SW (corresponding author), Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.	hongyang.gao@tamu.edu; hao.yuan@wsu.edu; zhengyang.wang@tamu.edu; sji@tamu.edu	Wang, Zhengyang/T-4824-2019	Wang, Zhengyang/0000-0002-5146-2884; Ji, Shuiwang/0000-0002-4205-4563	National Science Foundation [DBI-1641223, IIS-1633359]; Defense Advanced Research Projects Agency [N66001-17-2-4031]	National Science Foundation(National Science Foundation (NSF)); Defense Advanced Research Projects Agency(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This work was supported in part by National Science Foundation grants DBI-1641223 and IIS-1633359 and Defense Advanced Research Projects Agency grant N66001-17-2-4031.	[Anonymous], P BMVC; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Francesco Visin, 2018, Arxiv, DOI arXiv:1603.07285; Germain M, 2015, PR MACH LEARN RES, V37, P881; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jansson A., 2017, P ISMIR, P23; Jegou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156; Kingma D.P., 2014, P 2 INT C LEARN REPR, DOI DOI 10.1093/BIOINFORMATICS/BTAA169; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Larochelle H., 2011, INT C ART INT STAT; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li Q, 2001, STRUCT MULTIDISCIP O, V22, P230, DOI 10.1007/s001580100140; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Luxburg U. V., 2016, ADV NEURAL INFORM PR, V29, P4790; Makhzani A., 2015, ADV NEURAL INFORM PR, P2791; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Reed S, 2017, PR MACH LEARN RES, V70; Reed S, 2016, PR MACH LEARN RES, V48; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Simonyan K, 2015, 3 INT C LEARN REPR I; van den Oord A, 2016, PR MACH LEARN RES, V48	32	27	28	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1218	1227		10.1109/TPAMI.2019.2893965	http://dx.doi.org/10.1109/TPAMI.2019.2893965			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30668465	hybrid			2022-12-18	WOS:000523685800015
J	Zhang, Q; Wu, J; Zhang, P; Long, GD; Zhang, CQ				Zhang, Qin; Wu, Jia; Zhang, Peng; Long, Guodong; Zhang, Chengqi			Salient Subsequence Learning for Time Series Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time series; shapelet; unsupervised feature learning; clustering	UNSUPERVISED FEATURE-SELECTION; CLASSIFICATION; FRAMEWORK; FEATURES	Time series has been a popular research topic over the past decade. Salient subsequences of time series that can benefit the learning task, e.g., classification or clustering, are called shapelets. Shapelet-based time series learning extracts these types of salient subsequences with highly informative features from a time series. Most existing methods for shapelet discovery must scan a large pool of candidate subsequences, which is a time-consuming process. A recent work, [1], uses regression learning to discover shapelets in a time series; however, it only considers learning shapelets from labeled time series data. This paper proposes an Unsupervised Salient Subsequence Learning (USSL) model that discovers shapelets without the effort of labeling. We developed this new learning function by integrating the strengths of shapelet learning, shapelet regularization, spectral analysis and pseudo-label to simultaneously and automatically learn shapelets to help clustering unlabeled time series better. The optimization model is iteratively solved via a coordinate descent algorithm. Experiments show that our USSL can learn meaningful shapelets, with promising results on real-world and synthetic data that surpass current state-of-the-art unsupervised time series learning methods.	[Zhang, Qin; Wu, Jia; Long, Guodong; Zhang, Chengqi] Univ Technol Sydney, Fac Engn & Informat Technol, Ctr Artificial Intelligence, Sydney, NSW 2007, Australia; [Zhang, Qin] Data Ctr Social Network Grp SNG, Guangzhou 518057, Guangdong, Peoples R China; [Wu, Jia] Macquarie Univ, Fac Sci & Engn, Dept Comp, Sydney, NSW 2109, Australia; [Zhang, Peng] Ant Financial Serv Grp, Hangzhou 310012, Zhejiang, Peoples R China	University of Technology Sydney; Macquarie University	Wu, J (corresponding author), Macquarie Univ, Fac Sci & Engn, Dept Comp, Sydney, NSW 2109, Australia.	amberqzhang@tencent.com; jia.wu@mq.edu.au; hanyi.zp@antfin.com; guodong.long@uts.edu.au; chengqi.zhang@uts.edu.au	zhang, chi/GRX-3610-2022; Long, Guodong/T-3441-2019	Long, Guodong/0000-0003-3740-9515; Wu, Jia/0000-0002-1371-5801; Zhang, Chengqi/0000-0001-5715-7154	Australia's ARC Discovery Project [DP140100545, DP140102206]; Australia's ARC Linkage project [LP150100671, LP160100630]; MQNS [9201701203]; Macquarie University; Data61 on dynamic graph mining	Australia's ARC Discovery Project(Australian Research Council); Australia's ARC Linkage project(Australian Research Council); MQNS; Macquarie University; Data61 on dynamic graph mining	This work was supported in part by Australia's ARC Discovery Project (DP140100545, DP140102206) and Australia's ARC Linkage project (LP150100671, LP160100630), in part by the MQNS under Grant 9201701203, in part by the Collaborative Research Project (CRP) between Macquarie University and Data61 on dynamic graph mining.	Aghabozorgi S, 2015, INFORM SYST, V53, P16, DOI 10.1016/j.is.2015.04.007; Bagnall A, 2015, IEEE T KNOWL DATA EN, V27, P2522, DOI 10.1109/TKDE.2015.2416723; Baydogan MG, 2013, IEEE T PATTERN ANAL, V35, P2796, DOI 10.1109/TPAMI.2013.72; Boyd S, 2004, CONVEX OPTIMIZATION; Cai D., 2010, P ACM SIGKDD INT C K, P333, DOI 10.1145/1835804.1835848; Cai Y., 2004, P ACM SIGMOD INT C M, P599, DOI DOI 10.1145/1007568.1007636; Cetin M. S., 2015, P 2015 SIAM INT C DA, P307; Chang KW, 2012, IEEE DATA MINING, P131, DOI 10.1109/ICDM.2012.132; Chen Y, 2015, UCR TIME SERIES CLAS; Dau H. A., 2016, P 25 ACM INT C INF K, P978; DONATH WE, 1973, IBM J RES DEV, V17, P420, DOI 10.1147/rd.175.0420; Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141; Esling P, 2012, ACM COMPUT SURV, V45, DOI 10.1145/2379776.2379788; Frank J, 2013, IEEE T PATTERN ANAL, V35, P740, DOI 10.1109/TPAMI.2012.121; Gong D, 2014, IEEE T PATTERN ANAL, V36, P1414, DOI 10.1109/TPAMI.2013.244; Goodfellow IJ, 2013, IEEE T PATTERN ANAL, V35, P1902, DOI 10.1109/TPAMI.2012.273; Grabocka J, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P392, DOI 10.1145/2623330.2623613; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Hao Y, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P874; He Q, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P215, DOI 10.1109/ICMLA.2012.44; He X., 2005, P ADV NEUR INF PROC, P507; Heas P, 2005, IEEE T GEOSCI REMOTE, V43, P1635, DOI 10.1109/TGRS.2005.847791; Hills J, 2014, DATA MIN KNOWL DISC, V28, P851, DOI 10.1007/s10618-013-0322-1; Hirano S, 2006, IEEE DATA MINING, P896; Kelley C. T., 1999, ITERATIVE METHODS OP; Keogh E, 2006, IEEE T INF TECHNOL B, V10, P429, DOI 10.1109/TITB.2005.863870; Li Y., 2016, VLDB J, V25, P1; Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560; Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461; Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65; Lines J., 2012, P 18 ACM SIGKDD INT, P289, DOI 10.1145/2339530.2339579; Liu LL, 2012, ASIA-PAC INT SYM ELE, P269, DOI 10.1109/APEMC.2012.6237809; Ma YB, 2011, MODELLING SIMULATION, P117; Madeira SC, 2010, IEEE ACM T COMPUT BI, V7, P153, DOI 10.1109/TCBB.2008.34; Mueen A., 2011, P 17 ACM SIGKDD INT, P1154, DOI [10.1145/2020408.2020587, DOI 10.1145/2020408.2020587]; Nie F., 2010, ADV NEURAL INFORM PR, V2, P1813; Paparrizos J, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1855, DOI 10.1145/2723372.2737793; Qian M., 2013, P INT JOINT C ARTIFI, P1621; Rakthanmanon T., 2013, P 2013 SIAM INT C DA, P668, DOI [10.1137/1.9781611972832.74, DOI 10.1137/1.9781611972832.74]; Rakthanmanon Thanawin, 2012, KDD, V2012, P262, DOI 10.1145/2339530.2339576; Rand W. M., 2003, J AM STAT ASSOC, V66, P846; Romero A, 2015, IEEE T PATTERN ANAL, V37, P1716, DOI 10.1109/TPAMI.2014.2366129; Ruiz E. J., 2012, P 5 ACM INT C WEB SE, P513, DOI DOI 10.1145/2124295.2124358; Shariat S, 2011, IEEE I CONF COMP VIS, P2572, DOI 10.1109/ICCV.2011.6126545; Shi L, 2014, IEEE DATA MINING, P977, DOI 10.1109/ICDM.2014.58; Tang J, 2014, IEEE T KNOWL DATA EN, V26, P2914, DOI 10.1109/TKDE.2014.2320728; Taylor SJ, 2007, MODELING FINANCIAL T; Ulanova L., 2015, P 2015 SIAM INT C DA, P900, DOI DOI 10.1137/1.9781611974010.101; Vemulapalli PK, 2013, IEEE T PATTERN ANAL, V35, P1464, DOI 10.1109/TPAMI.2012.216; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wistuba M, 2015, ULTRAFAST SHAPELETS; Wu XD, 2013, IEEE T PATTERN ANAL, V35, P1178, DOI 10.1109/TPAMI.2012.197; Yang Y., 2011, P 22 INT JOINT C ART, P1589, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-267; Ye LX, 2011, DATA MIN KNOWL DISC, V22, P149, DOI 10.1007/s10618-010-0179-5; Ye LX, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P947; Zakaria J, 2016, DATA MIN KNOWL DISC, V30, P243, DOI 10.1007/s10618-015-0411-4; Zakaria J, 2012, IEEE DATA MINING, P785, DOI 10.1109/ICDM.2012.26; Zhang H, 2006, INFORM-J COMPUT INFO, V30, P305; Zhang Q., 2016, IJCAI, P2322; Zhao Z, 2010, AAAI CONF ARTIF INTE, P673; Zheng Z., 2007, P 24 INT C MACH LEAR, P1151, DOI DOI 10.1145/1273496.1273641; Zhou F, 2016, IEEE T PATTERN ANAL, V38, P279, DOI 10.1109/TPAMI.2015.2414429	63	27	29	9	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2193	2207		10.1109/TPAMI.2018.2847699	http://dx.doi.org/10.1109/TPAMI.2018.2847699			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	29994654				2022-12-18	WOS:000480343900011
J	Costilla-Reyes, O; Vera-Rodriguez, R; Scully, P; Ozanyan, KB				Costilla-Reyes, Omar; Vera-Rodriguez, Ruben; Scully, Patricia; Ozanyan, Krikor B.			Analysis of Spatio-Temporal Representations for Robust Footstep Recognition with Deep Residual Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometric system; verification system; deep learning; footstep recognition; floor sensor system		Human footsteps can provide a unique behavioural pattern for robust biometric systems. We propose spatio-temporal footstep representations from floor-only sensor data in advanced computational models for automatic biometric verification. Our models deliver an artificial intelligence capable of effectively differentiating the fine-grained variability of footsteps between legitimate users (clients) and impostor users of the biometric system. The methodology is validated in the largest to date footstep database, containing nearly 20,000 footstep signals from more than 120 users. The database is organized by considering a large cohort of impostors and a small set of clients to verify the reliability of biometric systems. We provide experimental results in 3 critical data-driven security scenarios, according to the amount of footstep data made available for model training: at airports security checkpoints (smallest training set), workspace environments (medium training set) and home environments (largest training set). We report state-of-the-art footstep recognition rates with an optimal equal false acceptance and false rejection rate (equal error rate) of 0.7 percent an improvement ratio of 371 percent compared to previous state-of-the-art. We perform a feature analysis of deep residual neural networks showing effective clustering of client's footstep data and to provide insights of the feature learning process.	[Costilla-Reyes, Omar; Ozanyan, Krikor B.] Univ Manchester, Sch Elect & Elect Engn, Manchester M13 9PL, Lancs, England; [Vera-Rodriguez, Ruben] Univ Autonoma Madrid, Biometr & Data Pattern Analyt BiDA Lab ATVS, Avda Francisco Toms & Valiente 11, E-28049 Madrid, Spain; [Scully, Patricia] Univ Manchester, Fac Engn & Phys Sci, Sch Chem Engn & Analyt Sci, Manchester M13 9PL, Lancs, England	University of Manchester; Autonomous University of Madrid; University of Manchester	Costilla-Reyes, O (corresponding author), Univ Manchester, Sch Elect & Elect Engn, Manchester M13 9PL, Lancs, England.	omar.costilla.reyes@gmail.com; ruben.vera@uam.es; patricia.scully@manchester.ac.uk; k.ozanyan@manchester.ac.uk	Vera-Rodriguez, Ruben/D-1272-2014	Vera-Rodriguez, Ruben/0000-0002-6338-8511; Scully, Patricia/0000-0003-4785-2019	CONACyT (Mexico); MINECO/FEDER [TEC2015-70627-R]; EPSRC, UK, through an IAA grant	CONACyT (Mexico)(Consejo Nacional de Ciencia y Tecnologia (CONACyT)); MINECO/FEDER(Spanish Government); EPSRC, UK, through an IAA grant(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	We express our gratitude to David H. Foster, Hujun Yin and Bernardino Romera-Paredes for useful discussions. O. Costilla-Reyes would like to acknowledge CONACyT (Mexico) for a studentship. We acknowledge NVIDIA for the donation of the GPU used to perform some of the experiments of this research. This work has been partially supported by Cognimetrics TEC2015-70627-R MINECO/FEDER. Early stages of this work have been funded by EPSRC, UK, through an IAA grant.	Abadi M, 2015, P 12 USENIX S OPERAT; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Anjos A., 2012, 20 ACM C MULT SYST A; Antoniou A., 2006, DIGITAL SIGNAL PROCE; Berger J, 2014, PHILOS PSYCHOL, V27, P829, DOI 10.1080/09515089.2013.771241; Bergstra James S, 2011, ADV NEURAL INFORM PR, P2546, DOI [10.5555/2986459.2986743, DOI 10.5555/2986459.2986743]; Cattin P.C., 2002, THESIS; Costilla-Reyes O, 2016, IEEE SENSOR; Costilla-Reyes O, 2016, IEEE SENS J, V16, P8815, DOI 10.1109/JSEN.2016.2583260; Dauphin Y. N., 2015, ARXIV150204390, V28, P1504; Feichtenhofer Christoph, 2016, NIPS; Gafurov D., 2007, P ANN NORW COMP SCI, P19; Glorot X., 2011, P 14 INT C ART INT S, P315; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jain A. K., 2005, PATTERN RECOGN, V38, P4; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Martin A., 1997, P EUR 97; Mason JE, 2016, MACHINE LEARNING TEC; Middleton L, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P171, DOI 10.1109/AUTOID.2005.2; Mostayed A, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND ASSURANCE, P307, DOI 10.1109/ISA.2008.46; Moustakidis SP, 2008, IEEE T SYST MAN CY B, V38, P1476, DOI 10.1109/TSMCB.2008.927722; Oliphant TE, 2007, COMPUT SCI ENG, V9, P10, DOI 10.1109/MCSE.2007.58; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Qian G, 2010, IEEE SENS J, V10, P1447, DOI 10.1109/JSEN.2010.2045158; Rodriguez R.V., 2015, ENCY BIOMETRICS, P693; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Stevenson J. P., 2007, P SENS APPL S, V7, P1; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tsatsoulis P. D., 2012, CONTINUOUS AUTHENTIC; Vacca J. R., 2007, BIOMETRIC TECHNOLOGI; Veit A, 2016, ADV NEUR IN, V29; Vera-Rodriguez R, 2013, IEEE T PATTERN ANAL, V35, P823, DOI 10.1109/TPAMI.2012.164; Weber MA, 2006, NEUROLOGY, V66, P1899, DOI 10.1212/01.wnl.0000219767.49705.9c; Whittle MW, 1996, HUM MOVEMENT SCI, V15, P369, DOI 10.1016/0167-9457(96)00006-1; Wu JX, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P225, DOI 10.1007/978-1-4419-9326-7_8; Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669; Yun J, 2011, SENSORS-BASEL, V11, P2611, DOI 10.3390/s110302611	39	27	30	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					285	296		10.1109/TPAMI.2018.2799847	http://dx.doi.org/10.1109/TPAMI.2018.2799847			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29994418	Green Submitted, Green Published			2022-12-18	WOS:000456150600002
J	Tang, YX; Wang, J; Wang, XF; Gao, BY; Dellandrea, E; Gaizauskas, R; Chen, LM				Tang, Yuxing; Wang, Josiah; Wang, Xiaofang; Gao, Boyang; Dellandrea, Emmanuel; Gaizauskas, Robert; Chen, Liming			Visual and Semantic Knowledge Transfer for Large Scale Semi-Supervised Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; convolutional neural networks; semi-supervised learning; transfer learning; visual similarity; semantic similarity; weakly supervised object detection	CONVOLUTIONAL NETWORKS; LOCALIZATION; SIMILARITY; MODELS	Deep CNN-based object detection systems have achieved remarkable success on several large-scale object detection benchmarks. However, training such detectors requires a large number of labeled bounding boxes, which are more difficult to obtain than image-level annotations. Previous work addresses this issue by transforming image-level classifiers into object detectors. This is done by modeling the differences between the two on categories with both image-level and bounding box annotations, and transferring this information to convert classifiers to detectors for categories without bounding box annotations. We improve this previous work by incorporating knowledge about object similarities from visual and semantic domains during the transfer process. The intuition behind our proposed method is that visually and semantically similar categories should exhibit more common transferable properties than dissimilar categories, e.g. a better detector would result by transforming the differences between a dog classifier and a dog detector onto the cat class, than would by transforming from the violin class. Experimental results on the challenging ILSVRC2013 detection dataset demonstrate that each of our proposed object similarity based knowledge transfer methods outperforms the baseline methods. We found strong evidence that visual similarity and semantic relatedness are complementary for the task, and when combined notably improve detection, achieving state-of-the-art detection performance in a semi-supervised setting.	[Tang, Yuxing] NIH, Imaging Biomarkers & Comp Aided Diag Lab, Clin Ctr, 10 Ctr Dr, Bethesda, MD 20814 USA; [Wang, Josiah; Gaizauskas, Robert] Univ Sheffield, Dept Comp Sci, 211 Portobello St, Sheffield S1 4DP, S Yorkshire, England; [Wang, Xiaofang; Dellandrea, Emmanuel; Chen, Liming] Ecole Cent Lyon, LIRIS, CNRS UMR 5205, 36 Ave Guy Collongue, F-69134 Ecully, France; [Gao, Boyang] IIT, Dept Adv Robot ADVR, Via Morego, I-16163 Genoa, Italy	National Institutes of Health (NIH) - USA; NIH Clinical Center (CC); University of Sheffield; Ecole Centrale de Lyon; Institut National des Sciences Appliquees de Lyon - INSA Lyon; Istituto Italiano di Tecnologia - IIT	Tang, YX (corresponding author), NIH, Imaging Biomarkers & Comp Aided Diag Lab, Clin Ctr, 10 Ctr Dr, Bethesda, MD 20814 USA.	yuxing.tang@ec-lyon.fr; j.k.wang@sheffield.ac.uk; xiaofang.wang@ec-lyon.fr; boyang.gao@iit.it; emmanuel.dellandrea@ec-lyon.fr; r.gaizauskas@sheffield.ac.uk; liming.chen@ec-lyon.fr	Tang, Yuxing/I-8413-2019	Tang, Yuxing/0000-0002-6452-2751; Chen, Liming/0000-0002-3654-9498; Wang, Josiah/0000-0003-0048-3893; Gaizauskas, Robert/0000-0002-3356-5126	French Research Agency; Agence Nationale de Recherche (ANR) [2009 CORD 026 02, ANR-12-CHRI-0002-04]; UK EPSRC [EP/K019082/1]; Partner University Foundation through the 4D Vision project; EPSRC [EP/K019082/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/K019082/1] Funding Source: researchfish	French Research Agency(French National Research Agency (ANR)); Agence Nationale de Recherche (ANR)(French National Research Agency (ANR)); UK EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Partner University Foundation through the 4D Vision project; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was partly supported by the French Research Agency, Agence Nationale de Recherche (ANR), through the VideoSense Project under Grant 2009 CORD 026 02, and the Visen project under Grants ANR-12-CHRI-0002-04 and UK EPSRC EP/K019082/1 within the framework of the ERA-Net CHIST-ERA, and by the Partner University Foundation through the 4D Vision project. The authors thank NVIDIA for providing the Titan X GPU. This work was done when Yuxing Tang was a Ph.D. student in LIRIS, Ecole Centrale de Lyon, France.	Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Bilen H, 2014, P BRIT MACH VIS C, P112; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Chum O., 2007, P IEEE C COMP VIS PA, P1; Crandall DJ, 2006, LECT NOTES COMPUT SC, V3951, P16; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Deselaers T, 2011, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR.2011.5995474; Donahue J, 2013, PROC CVPR IEEE, P668, DOI 10.1109/CVPR.2013.92; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fellbaum C, 1998, LANG SPEECH & COMMUN, P1; Frome Andrea, 2013, NEURIPS; Galleguillos C, 2008, LECT NOTES COMPUT SC, V5302, P193, DOI 10.1007/978-3-540-88682-2_16; Gao B., 2012, P 10 IEEE INT WORKSH, P1, DOI DOI 10.1109/ICSICT.2012.6467645; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hoffman Judy, 2014, NIPS; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Leacock C, 1998, LANG SPEECH & COMMUN, P265; Lin D., 1998, P INT C MACH LEARN; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lu Y, 2018, PSYCHOL MED, V48, P1201, DOI 10.1017/S0033291717002665; Mikolov T., 2013, P 2013 C N AM CHAPTE, P746, DOI DOI 10.3109/10826089109058901; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Nguyen MH, 2009, IEEE I CONF COMP VIS, P1925, DOI 10.1109/ICCV.2009.5459426; Misra I, 2015, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2015.7298982; OQUAB M, 2015, PROC CVPR IEEE, P685, DOI DOI 10.1109/CVPR.2015.7298668; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Pandey M., 2011, P IEEE INT C COMP VI, P343; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Resnik P, 1995, INT JOINT CONF ARTIF, P448; Rochan M, 2015, PROC CVPR IEEE, P4315, DOI 10.1109/CVPR.2015.7299060; Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121; Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29; Rothe S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1793; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sermanet P., 2013, ARXIV PREPRINT ARXIV; Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900; Shi Z, 2013, IEEE I CONF COMP VIS, P2984, DOI 10.1109/ICCV.2013.371; Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216; Singh KK, 2016, PROC CVPR IEEE, P3548, DOI 10.1109/CVPR.2016.386; Siva P, 2012, LECT NOTES COMPUT SC, V7574, P594, DOI 10.1007/978-3-642-33712-3_43; Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Szegedy C, 2013, ADV NEURAL INFORM PR, P2553; Szegedy C., 2016, P IEEE C COMP VIS PA, P2818, DOI DOI 10.1109/CVPR.2016.308; Tang YX, 2017, IEEE T MULTIMEDIA, V19, P393, DOI 10.1109/TMM.2016.2614862; Tang YX, 2016, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2016.233; Tang YX, 2014, IEEE IMAGE PROC, P4072, DOI 10.1109/ICIP.2014.7025827; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang C, 2015, IEEE T IMAGE PROCESS, V24, P1371, DOI 10.1109/TIP.2015.2396361; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Yang Y, 2013, PROC CVPR IEEE, P1650, DOI 10.1109/CVPR.2013.216; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319; Zhou Bolei, 2015, OBJECT DETECTORS EME, P2; Zhu Y., 2011, P 25 AAAI C ART INT; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	67	27	27	2	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					3045	3058		10.1109/TPAMI.2017.2771779	http://dx.doi.org/10.1109/TPAMI.2017.2771779			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29990152	Green Submitted, Green Accepted			2022-12-18	WOS:000449355500019
J	Lou, ZY; Alnajar, F; Alvarez, JM; Hu, NH; Gevers, T				Lou, Zhongyu; Alnajar, Fares; Alvarez, Jose M.; Hu, Ninghang; Gevers, Theo			Expression-Invariant Age Estimation Using Structured Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Age estimation; expression estimation; structured learning	CLASSIFICATION; DATABASE	In this paper, we investigate and exploit the influence of facial expressions on automatic age estimation. Different from existing approaches, our method jointly learns the age and expression by introducing a new graphical model with a latent layer between the age/expression labels and the features. This layer aims to learn the relationship between the age and expression and captures the face changes which induce the aging and expression appearance, and thus obtaining expression-invariant age estimation. Conducted on three age-expression datasets (FACES [1], Lifespan [2] and NEMO [3]), our experiments illustrate the improvement in performance when the age is jointly learnt with expression in comparison to expression-independent age estimation. The age estimation error is reduced by 14.43, 37.75 and 9.30 percent for the FACES, Lifespan and NEMO datasets respectively. The results obtained by our graphical model, without prior-knowledge of the expressions of the tested faces, are better than the best reported ones for all datasets. The flexibility of the proposed model to include more cues is explored by incorporating gender together with age and expression. The results show performance improvements for all cues.	[Lou, Zhongyu; Alnajar, Fares; Hu, Ninghang; Gevers, Theo] Univ Amsterdam, Intelligent Syst Lab Amsterdam, Informat Inst, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands; [Alvarez, Jose M.] NICTA, Canberra, ACT 2601, Australia; [Gevers, Theo] Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain	University of Amsterdam; Australian National University; Autonomous University of Barcelona; Centre de Visio per Computador (CVC)	Lou, ZY (corresponding author), Univ Amsterdam, Intelligent Syst Lab Amsterdam, Informat Inst, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.	z.lou@uva.nl; f.alnajar@uva.nl; jose.alvarez@nicta.com.au; n.hu@uva.nl; th.gevers@uva.nl		Hu, Ninghang/0000-0001-6831-4653				Alnajar F., 2014, P BRIT MACH VIS C; Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437; Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; Dibeklioglu H, 2012, LECT NOTES COMPUT SC, V7574, P525, DOI 10.1007/978-3-642-33712-3_38; Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351; Ekman P., 2002, FACIAL ACTION CODING; Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36; Geng X., 2008, P 16 ACM INT C MULT, P721; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; Guo GD, 2014, IMAGE VISION COMPUT, V32, P761, DOI 10.1016/j.imavis.2014.04.011; Guo GD, 2013, IEEE T AFFECT COMPUT, V4, P291, DOI 10.1109/T-AFFC.2013.13; Guo GD, 2012, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2012.6247972; Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681; KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543; Mooij JM, 2010, J MACH LEARN RES, V11, P2169; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Yan S, 2008, PR IEEE COMP DESIGN, P142, DOI 10.1109/ICCD.2008.4751853; Yan SC, 2008, INT CONF ACOUST SPEE, P737; Yang Z., 2007, DEMOGRAPHIC CLASSIFI, P464; Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; ZHANG CJ, 2013, PROC IEEE 6 INT, V50, P1; Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975	30	27	29	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					365	375		10.1109/TPAMI.2017.2679739	http://dx.doi.org/10.1109/TPAMI.2017.2679739			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28287961				2022-12-18	WOS:000422706000008
J	Lin, ZC; Xu, C; Zha, HB				Lin, Zhouchen; Xu, Chen; Zha, Hongbin			Robust Matrix Factorization by Majorization Minimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Matrix factorization; majorization minimization; alternating direction method of multipliers (ADMM)	APPROXIMATIONS; COMPLETION; ALGORITHMS; SHAPE	L-1-norm based low rank matrix factorization in the presence of missing data and outliers remains a hot topic in computer vision. Due to non-convexity and non-smoothness, all the existing methods either lack scalability or robustness, or have no theoretical guarantee on convergence. In this paper, we apply the Majorization Minimization technique to solve this problem. At each iteration, we upper bound the original function with a strongly convex surrogate. By minimizing the surrogate and updating the iterates accordingly, the objective function has sufficient decrease, which is stronger than just being non-increasing that other methods could offer. As a consequence, without extra assumptions, we prove that any limit point of the iterates is a stationary point of the objective function. In comparison, other methods either do not have such a convergence guarantee or require extra critical assumptions. Extensive experiments on both synthetic and real data sets testify to the effectiveness of our algorithm. The speed of our method is also highly competitive.	[Lin, Zhouchen; Xu, Chen; Zha, Hongbin] Peking Univ, Key Lab Machine Percept MOE, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China; [Lin, Zhouchen; Xu, Chen; Zha, Hongbin] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China	Peking University; Shanghai Jiao Tong University	Lin, ZC (corresponding author), Peking Univ, Key Lab Machine Percept MOE, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China.; Lin, ZC (corresponding author), Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China.	zlin@pku.edu.cn; xuen@pku.edu.cn; zha@cis.pku.edu.cn			National Basic Research Program of China (973 Program) [2015CB352502]; National Natural Science Foundation (NSF) of China [61625301, 61231002]; Beijing Municipal Natural Science Foundation [4152006]; Qualcomm	National Basic Research Program of China (973 Program)(National Basic Research Program of China); National Natural Science Foundation (NSF) of China(National Natural Science Foundation of China (NSFC)); Beijing Municipal Natural Science Foundation(Beijing Natural Science Foundation); Qualcomm	The authors would like to thank Canyi Lu for fruitful discussions and the reviewers for their comments that help improve the manuscript. Z. Lin is supported by National Basic Research Program of China (973 Program) (grant no. 2015CB352502), National Natural Science Foundation (NSF) of China (grant nos. 61625301 and 61231002), and Qualcomm. H. Zha is supported by Beijing Municipal Natural Science Foundation (grant no. 4152006).	Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; Borwein J. M., CONVEX ANAL NONLINEA, V3; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Buchanan AM, 2005, PROC CVPR IEEE, P316; Cabral R, 2013, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2013.309; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; Daubechies I., COMMUN PURE APPL MAT, V57, P1413; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Del Bue A, 2012, IEEE T PATTERN ANAL, V34, P1496, DOI 10.1109/TPAMI.2011.238; Eriksson A, 2012, IEEE T PATTERN ANAL, V34, P1681, DOI 10.1109/TPAMI.2012.116; GANESH A, 2009, 2009 3 IEEE INT, P213; Gasso G, 2009, IEEE T SIGNAL PROCES, V57, P4686, DOI 10.1109/TSP.2009.2026004; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Horst R, 1999, J OPTIMIZ THEORY APP, V103, P1, DOI 10.1023/A:1021765131316; Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271; Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836; Ke QF, 2005, PROC CVPR IEEE, P739; Ke QF, 2001, PROC CVPR IEEE, P255; Kim E, 2015, IEEE T NEUR NET LEAR, V26, P237, DOI 10.1109/TNNLS.2014.2312535; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Lee DD, 2001, ADV NEUR IN, V13, P556; Lin Z., 2015, MACH LEARN, V99, P287, DOI DOI 10.1007/s10994-014-5469-5; Lin Z, 2009, UILUENG092215 UIUC; Mairal J., 2013, P 30 INT C INT C MAC, P783; Mairal J, 2010, J MACH LEARN RES, V11, P19; Meng D., 2013, P 27 AAAI C ART INT, P704; Mitra K., 2010, ADV NEURAL INFORM PR, P1651; Nesterov Y, 2013, MATH PROGRAM, V140, P125, DOI 10.1007/s10107-012-0629-5; Okatani T, 2007, INT J COMPUT VISION, V72, P329, DOI 10.1007/s11263-006-9785-5; Pietra S. D., 2001, CMUCS01109R DTIC; Razaviyayn M., SIAM J OPTIMIZATION, V23, P1126; Seeger MW, 2010, IEEE SIGNAL PROC MAG, V27, P81, DOI 10.1109/MSP.2010.938082; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Wen ZW, 2012, MATH PROGRAM COMPUT, V4, P333, DOI 10.1007/s12532-012-0044-1; Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892; Xiong F, 2012, LECT NOTES COMPUT SC, V7576, P580, DOI 10.1007/978-3-642-33715-4_42; Zheng YQ, 2012, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2012.6247828	46	27	29	4	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					208	220		10.1109/TPAMI.2017.2651816	http://dx.doi.org/10.1109/TPAMI.2017.2651816			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28092520				2022-12-18	WOS:000417806000016
J	Su, B; Ding, XQ; Wang, H; Wu, Y				Su, Bing; Ding, Xiaoqing; Wang, Hao; Wu, Ying			Discriminative Dimensionality Reduction for Multi-Dimensional Sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; sequence classification; discriminant analysis; metric learning; character recognition	RECOGNITION; SIMILARITY	Since the observables at particular time instants in a temporal sequence exhibit dependencies, they are not independent samples. Thus, it is not plausible to apply i.i.d. assumption-based dimensionality reduction methods to sequence data. This paper presents a novel supervised dimensionality reduction approach for sequence data, called Linear Sequence Discriminant Analysis (LSDA). It learns a linear discriminative projection of the feature vectors in sequences to a lower-dimensional subspace by maximizing the separability of the sequence classes such that the entire sequences are holistically discriminated. The sequence class separability is constructed based on the sequence statistics, and the use of different statistics produces different LSDA methods. This paper presents and compares two novel LSDA methods, namely M-LSDA and D-LSDA. M-LSDA extracts model-based statistics by exploiting the dynamical structure of the sequence classes, and D-LSDA extracts the distance-based statistics by computing the pairwise similarity of samples from the same sequence class. Extensive experiments on several different tasks have demonstrated the effectiveness and the general applicability of the proposed methods.	[Su, Bing] Chinese Acad Sci, Inst Software, Sci & Technol Integrated Informat Syst Lab, Beijing 100190, Peoples R China; [Ding, Xiaoqing] Tsinghua Univ, State Key Lab Intelligent Technol & Syst, Tsinghua Natl Lab Informat Sci & Technol, Dept Elect Engn, Beijing 100084, Peoples R China; [Wang, Hao] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China; [Wu, Ying] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA	Chinese Academy of Sciences; Institute of Software, CAS; Tsinghua University; Chinese Academy of Sciences; Institute of Software, CAS; Northwestern University	Su, B (corresponding author), Chinese Acad Sci, Inst Software, Sci & Technol Integrated Informat Syst Lab, Beijing 100190, Peoples R China.	subingats@gmail.com; dingxq@tsinghua.edu.cn; wanghao@iscas.ac.cn; yingwu@eecs.northwestern.edu	Su, Bing/ABC-4813-2020; Wu, Ying/B-7283-2009	Koochak, Atousa/0000-0001-6547-2728	National Natural Science Foundation of China [61603373, 61032008, 61471214]; National Basic Research Program of China (973 program) [2013CB329403]; National Science Foundation [IIS-1217302, IIS-1619078]; Army Research Office [ARO W911NF-16-1-0138]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 program)(National Basic Research Program of China); National Science Foundation(National Science Foundation (NSF)); Army Research Office	The authors would like to thank the anonymous reviewers for their valuable comments. This work was supported by the National Natural Science Foundation of China under Grant No. 61603373, No. 61032008, No. 61471214, and the National Basic Research Program of China (973 program) under Grant No. 2013CB329403. This work was supported in part by National Science Foundation grant IIS-1217302, IIS-1619078, and the Army Research Office ARO W911NF-16-1-0138.	Alkhoury I., 2012, GUIDE OCR ARABIC SCR, P255; Baydogan MG, 2013, IEEE T PATTERN ANAL, V35, P2796, DOI 10.1109/TPAMI.2013.72; Bian W, 2011, IEEE T PATTERN ANAL, V33, P1037, DOI 10.1109/TPAMI.2010.189; BJORCK A, 1973, MATH COMPUT, V27, P579, DOI 10.2307/2005662; Cao HG, 2011, PROC INT CONF DOC, P739, DOI 10.1109/ICDAR.2011.154; Chan KP, 1999, PROC INT CONF DATA, P126, DOI 10.1109/ICDE.1999.754915; Cuturi M., 2011, P 28 INT C MACH LEAR, P929; Dreuw P., 2012, GUIDE OCR ARABIC SCR, P215; Durbin J., 1960, ECONOMETRICA, P233, DOI 10.2307/1401322 0101.35604; Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595; Faloutsos C., 1994, SIGMOD Record, V23, P419, DOI 10.1145/191843.191925; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Frank J, 2013, IEEE T PATTERN ANAL, V35, P740, DOI 10.1109/TPAMI.2012.121; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Haeb-Umbach R., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P13, DOI 10.1109/ICASSP.1992.225984; Hamsici OC, 2008, IEEE T PATTERN ANAL, V30, P647, DOI 10.1109/TPAMI.2007.70717; Iosifidis A, 2013, IEEE T KNOWL DATA EN, V25, P2564, DOI 10.1109/TKDE.2012.223; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kadous M.W., 2002, THESIS; Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Lichman M, 2013, UCI MACHINE LEARNING; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Lotlikar R, 2000, IEEE T PATTERN ANAL, V22, P623, DOI 10.1109/34.862200; Margner V, 2011, PROC INT CONF DOC, P1444, DOI 10.1109/ICDAR.2011.287; Margner V., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P709, DOI 10.1109/ICFHR.2010.115; Mohamad RAH, 2009, IEEE T PATTERN ANAL, V31, P1165, DOI 10.1109/TPAMI.2008.136; Pechwitz M., 2002, PROC CIFED, V2, P127; Pfister T, 2014, LECT NOTES COMPUT SC, V8694, P814, DOI 10.1007/978-3-319-10599-4_52; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ratanamahatana CA, 2004, SIAM PROC S, P11; Rodriguez LJ, 2003, LECT NOTES COMPUT SC, V2652, P847; Rodriguez-Serrano JA, 2012, IEEE T PATTERN ANAL, V34, P2108, DOI 10.1109/TPAMI.2012.25; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Ryoo MS, 2015, PROC CVPR IEEE, P896, DOI 10.1109/CVPR.2015.7298691; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Shyr A, 2010, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2010.5539922; Slimane F., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P670, DOI 10.1109/ICFHR.2010.110; Slimane Fouad, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P946, DOI 10.1109/ICDAR.2009.155; Su B, 2015, PROC CVPR IEEE, P4539, DOI 10.1109/CVPR.2015.7299084; Su B, 2013, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2013.115; Su B, 2013, PROC INT CONF DOC, P1250, DOI 10.1109/ICDAR.2013.253; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Vlachos M, 2006, VLDB J, V15, P1, DOI 10.1007/s00778-004-0144-2; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P810, DOI 10.1109/34.400572; Wu JX, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P453; Xing Z., 2010, ACM SIGKDD EXPLOR NE, V12, P40, DOI [10.1145/1882471.1882478, DOI 10.1145/1882471.1882478]; Ye LX, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P947; YOUNG S, 2001, HTK BOOK; Zhou F., 2009, ADV NEURAL INFORM PR, V22, P2286; Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	56	27	28	0	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					77	91		10.1109/TPAMI.2017.2665545	http://dx.doi.org/10.1109/TPAMI.2017.2665545			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28186877	hybrid			2022-12-18	WOS:000417806000007
J	Habibian, A; Mensink, T; Snoek, CGM				Habibian, Amirhossein; Mensink, Thomas; Snoek, Cees G. M.			Video2vec Embeddings Recognize Events When Examples Are Scarce	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Event recognition; semantic video representation; representation learning	FUSION	This paper aims for event recognition when video examples are scarce or even completely absent. The key in such a challenging setting is a semantic video representation. Rather than building the representation from individual attribute detectors and their annotations, we propose to learn the entire representation from freely available web videos and their descriptions using an embedding between video features and term vectors. In our proposed embedding, which we call Video2vec, the correlations between the words are utilized to learn a more effective representation by optimizing a joint objective balancing descriptiveness and predictability. We show how learning the Video2vec embedding using a multimodal predictability loss, including appearance, motion and audio features, results in a better predictable representation. We also propose an event specific variant of Video2vec to learn a more accurate representation for the words, which are indicative of the event, by introducing a term sensitive descriptiveness loss. Our experiments on three challenging collections of web videos from the NIST TRECVID Multimedia Event Detection and Columbia Consumer Videos datasets demonstrate: i) the advantages of Video2vec over representations using attributes or alternative embeddings, ii) the benefit of fusing video modalities by an embedding over common strategies, iii) the complementarity of term sensitive descriptiveness and multimodal predictability for event recognition. By its ability to improve predictability of present day audiovisual video features, while at the same time maximizing their semantic descriptiveness, Video2vec leads to state-of-the-art accuracy for both few-and zero-example recognition of events in video.	[Habibian, Amirhossein] Univ Amsterdam, QUVA Lab, NL-1012 WX Amsterdam, Netherlands; [Habibian, Amirhossein] Qualcomm Res, NL-1098 XH Amsterdam, Netherlands; [Mensink, Thomas; Snoek, Cees G. M.] Univ Amsterdam, NL-1012 WX Amsterdam, Netherlands; [Snoek, Cees G. M.] Qualcomm Res, QUVA Lab, NL-1012 WX Amsterdam, Netherlands	University of Amsterdam; University of Amsterdam	Habibian, A (corresponding author), Univ Amsterdam, QUVA Lab, NL-1012 WX Amsterdam, Netherlands.; Habibian, A (corresponding author), Qualcomm Res, NL-1098 XH Amsterdam, Netherlands.	habibian.a.h@gmail.com; t.mensink@uva.nl; cgmsnoek@uva.nl						Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; [Anonymous], C N AM ASS COMP LING; Aytar Y., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587822; Berg TL, 2010, LECT NOTES COMPUT SC, V6311, P663, DOI 10.1007/978-3-642-15549-9_48; Bhattacharya S, 2014, PROC CVPR IEEE, P2243, DOI 10.1109/CVPR.2014.287; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16; Chang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P581, DOI 10.1145/2733373.2806218; Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234; Chen J., 2014, P INT C MULT RETR, P1; CMU, CMUSPHINKX OP SOURC; Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142; Cui Y., 2014, ARXIV14037591; Dalton J, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1857, DOI 10.1145/2505515.2507880; Das P., 2013, P 6 ACM INT C WEB SE, P485; Das P, 2013, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2013.340; Dehghan A, 2014, PROC CVPR IEEE, P2585, DOI 10.1109/CVPR.2014.331; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902; Ferrari Vittorio, 2007, NIPS; Habibian A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P17, DOI 10.1145/2647868.2654913; Habibian A, 2014, COMPUT VIS IMAGE UND, V124, P110, DOI 10.1016/j.cviu.2014.02.003; Han X., 2016, ARXIV151203384; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Izadinia H, 2012, LECT NOTES COMPUT SC, V7575, P430, DOI 10.1007/978-3-642-33765-9_31; Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang L, 2015, AAAI CONF ARTIF INTE, P2694; Jiang L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P49, DOI 10.1145/2733373.2806237; Jiang Y.G, 2011, PROC 1 ACM INT C MUL, P29; Jiang Y.G., 2010, P TRECVID WORKSH; Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Li WX, 2013, IEEE I CONF COMP VIS, P2728, DOI 10.1109/ICCV.2013.339; Liu J, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P297, DOI 10.1109/ROBIO.2014.7090346; Ma Z., 2013, THESIS; Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419; Ma ZG, 2013, PROC CVPR IEEE, P2627, DOI 10.1109/CVPR.2013.339; Mairal J., 2012, FDN TRENDS COMPUTER, V8, P85; Mazloom M, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P123, DOI 10.1145/2671188.2749402; Mazloom M, 2014, IEEE T MULTIMEDIA, V16, P2214, DOI 10.1109/TMM.2014.2359771; Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; Nagel M., 2015, P BRIT MACH VIS C, p178 1; Natarajan P., 2013, P TRECVID WORKSH; Natarajan P, 2012, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2012.6247814; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Oh S, 2014, MACH VISION APPL, V25, P49, DOI 10.1007/s00138-013-0525-x; Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228; Over P., 2013, P TRECVID WORKSH; Palatucci Mark, 2009, ADV NEURAL INFORM PR, P1410; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Simonyan K, 2015, 3 INT C LEARN REPR I; Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236; Strassel S, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2573; Sun C, 2014, PROC CVPR IEEE, P2569, DOI 10.1109/CVPR.2014.329; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114; Tang KV, 2013, IEEE I CONF COMP VIS, P2696, DOI 10.1109/ICCV.2013.335; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang Q, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P685; Weinberger K., 2009, ADV NEURAL INFORM PR, P1737; Weston Jason, 2011, 22 INT JOINT C ART I; Wu S, 2014, PROC CVPR IEEE, P2665, DOI 10.1109/CVPR.2014.341; Xu R, 2015, AAAI CONF ARTIF INTE, P2346; Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789; Yan Y, 2015, AAAI CONF ARTIF INTE, P3841; Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221; Yu S.-I., 2014, P TRECVID WORKSH	84	27	30	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					2089	2103		10.1109/TPAMI.2016.2627563	http://dx.doi.org/10.1109/TPAMI.2016.2627563			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	27849523	Green Submitted			2022-12-18	WOS:000408807600014
J	Cho, D; Kim, S; Tai, YW; Kweon, IS				Cho, Donghyeon; Kim, Sunyeong; Tai, Yu-Wing; Kweon, In So			Automatic Trimap Generation and Consistent Matting for Light-Field Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image matting; light-field image; trimap		In this paper, we introduce an automatic approach to generate trimaps and consistent alpha mattes of foreground objects in a light-field image. Our method first performs binary segmentation to roughly segment a light-field image into foreground and background based on depth and color. Next, we estimate accurate trimaps through analyzing color distribution along the boundary of the segmentation using guided image filter and KL-divergence. In order to estimate consistent alpha mattes across sub-images, we utilize the epipolar plane image (EPI) where colors and alphas along the same epipolar line must be consistent. Since EPI of foreground and background are mixed in the matting area, we propagate the EPI from definite foreground/background regions to unknown regions by assuming depth variations within unknown regions are spatially smooth. Using the EPI constraint, we derive two solutions to estimate alpha when color samples along epipolar line are known, and unknown. To further enhance consistency, we refine the estimated alpha mattes by using the multi-image matting Laplacian with an additional EPI smoothness constraint. In experimental evaluations, we have created a dataset where the ground truth alpha mattes of light-field images were obtained by using the blue screen technique. A variety of experiments show that our proposed algorithm produces both visually and quantitatively high-quality alpha mattes for light-field images.	[Cho, Donghyeon; Kweon, In So] Korea Adv Inst Sci & Technol, Daejeon 34141, South Korea; [Kim, Sunyeong] Perples Inc, Seoul 121835, South Korea; [Tai, Yu-Wing] SenseTime, Hong Kong, Hong Kong, Peoples R China	Korea Advanced Institute of Science & Technology (KAIST)	Cho, D (corresponding author), Korea Adv Inst Sci & Technol, Daejeon 34141, South Korea.	cdh12242@gmail.com; harharr@gmail.com; yuwing@gmail.com; iskweon@kaist.ac.kr	Kweon, In So/C-2023-2011; Cho, DongHyeon/AAL-9874-2020		National Research Foundation of Korea (NRF) grant - Korea government (MSIP) [2010-0028680]	National Research Foundation of Korea (NRF) grant - Korea government (MSIP)	This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2010-0028680). In So Kweon is the corresponding author.	Bishop Tom E., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1622, DOI 10.1109/ICCVW.2009.5457420; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; Chen QF, 2012, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2012.6247760; Cho D, 2013, IEEE I CONF COMP VIS, P3280, DOI 10.1109/ICCV.2013.407; Cho D, 2014, LECT NOTES COMPUT SC, V8692, P90, DOI 10.1007/978-3-319-10593-2_7; Choi I, 2012, LECT NOTES COMPUT SC, V7577, P540, DOI 10.1007/978-3-642-33783-3_39; Chuang YY, 2001, PROC CVPR IEEE, P264; Criminisi A, 2005, COMPUT VIS IMAGE UND, V97, P51, DOI 10.1016/j.cviu.2004.06.001; Dansereau D, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P549; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Fiss J, 2015, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2015.7298661; Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x; Goldluecke B, 2013, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2013.134; He B, 2014, J VIS COMMUN IMAGE R, V25, P1031, DOI 10.1016/j.jvcir.2014.03.002; He KM, 2010, LECT NOTES COMPUT SC, V6311, P1; He KM, 2010, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR.2010.5539896; Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762; Joshi N, 2006, ACM T GRAPHIC, V25, P779, DOI 10.1145/1141911.1141955; Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495; Kim SH, 2016, IEEE T IMAGE PROCESS, V25, P3639, DOI 10.1109/TIP.2016.2555698; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kweon I., 2016, P EUR C COMPUT VIS, P1; Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719; McGuire M, 2005, ACM T GRAPHIC, V24, P567, DOI 10.1145/1073204.1073231; Ng R., 2005, THESIS STANFORD U; Rhemann C, 2008, CVPR, P1; Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503; Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88; Shahrian E, 2012, PROC CVPR IEEE, P718, DOI 10.1109/CVPR.2012.6247741; Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263; Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721; Sun J, 2006, ACM T GRAPHIC, V25, P772, DOI 10.1145/1141911.1141954; Sungheum Kim, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2361, DOI 10.1109/ICIP.2011.6116115; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Wang Jue, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383006; Wang O, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P469, DOI 10.1109/PG.2007.52; Wanner S., 2013, GERM C PATT REC BERL; Wanner S, 2013, PROC CVPR IEEE, P1011, DOI 10.1109/CVPR.2013.135; Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656; Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326	44	27	30	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1504	1517		10.1109/TPAMI.2016.2606397	http://dx.doi.org/10.1109/TPAMI.2016.2606397			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	28113357				2022-12-18	WOS:000404606300002
J	Rematas, K; Nguyen, CH; Ritschel, T; Fritz, M; Tuytelaars, T				Rematas, Konstantinos; Nguyen, Chuong H.; Ritschel, Tobias; Fritz, Mario; Tuytelaars, Tinne			Novel Views of Objects from a Single Image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Novel view synthesis; 2D to 3D alignment; image based rendering	VISUAL SIMILARITY; MODEL	Taking an image of an object is at its core a lossy process. The rich information about the three-dimensional structure of the world is flattened to an image plane and decisions such as viewpoint and camera parameters are final and not easily revertible. As a consequence, possibilities of changing viewpoint are limited. Given a single image depicting an object, novel-view synthesis is the task of generating new images that render the object from a different viewpoint than the one given. The main difficulty is to synthesize the parts that are disoccluded; disocclusion occurs when parts of an object are hidden by the object itself under a specific viewpoint. In this work, we show how to improve novel-view synthesis by making use of the correlations observed in 3D models and applying them to new image instances. We propose a technique to use the structural information extracted from a 3D model that matches the image object in terms of viewpoint and shape. For the latter part, we propose an efficient 2D-to-3D alignment method that associates precisely the image appearance with the 3D model geometry with minimal user interaction. Our technique is able to simulate plausible viewpoint changes for a variety of object classes within seconds. Additionally, we show that our synthesized images can be used as additional training data that improves the performance of standard object detectors.	[Rematas, Konstantinos; Tuytelaars, Tinne] Katholieke Univ Leuven, Dept Elect Engn, B-3000 Flanders, Leuven, Belgium; [Nguyen, Chuong H.; Fritz, Mario] MPI Informat, D-66123 Saarbrucken, Germany; [Ritschel, Tobias] UCL, London WC1E 6BT, England	KU Leuven; Max Planck Society; University of London; University College London	Rematas, K (corresponding author), Katholieke Univ Leuven, Dept Elect Engn, B-3000 Flanders, Leuven, Belgium.	krematas@esat.kuleuven.be; nguyen@mpi-inf.mpg.de; ritschel@mpi-inf.mpg.de; mfritz@mpi-inf.mpg.de; tinne.tuytelaars@esat.kuleuven.be	Tuytelaars, Tinne/B-4319-2015	Tuytelaars, Tinne/0000-0003-3307-9723				Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487; Aubry M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591009; BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Chang Angel X., 2015, ARXIV151203012CSGR P; Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669; Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153; Chiu WC, 2015, IEEE I CONF COMP VIS, P468, DOI 10.1109/ICCV.2015.61; Choy CB, 2015, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2015.7298866; Criminisi A., 2003, PROC CVPR IEEE, V2, pII; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Deering M., 1988, Computer Graphics, V22, P21, DOI 10.1145/378456.378468; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dengsheng Zhang, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P652; Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597; Enzweiler M, 2008, PROC CVPR IEEE, P1944; Everingham M., 2012, PASCAL VISUAL OBJECT; Everingham M., 2007, PASCAL VISUAL OBJECT, DOI DOI 10.1007/S11263-014-0733-5; Georgoulis S., 2016, ARXIV160200328; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Hariharan B, 2012, LECT NOTES COMPUT SC, V7575, P459, DOI 10.1007/978-3-642-33765-9_33; He Y., 2016, ARXIV160402388CSCV; Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232; Hoiem Derek, 2012, ECCV, P340, DOI [10.1007/978-3-642-33712-3_25, DOI 10.1007/978-3-642-33712-3_25]; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; Horry Y., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P225, DOI 10.1145/258734.258854; Hu WZ, 2012, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2012.6247945; Huang QX, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766890; Jain A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366162; Kaneva B, 2011, IEEE I CONF COMP VIS, P2282, DOI 10.1109/ICCV.2011.6126508; KHOLGADE N., 2014, ACM T GRAPHIC, V33, P4; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Lai K., 2009, ROBOTICS SCI SYSTEMS; Li WB, 2012, LECT NOTES COMPUT SC, V7575, P345, DOI 10.1007/978-3-642-33765-9_25; Liebelt J, 2010, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2010.5539836; Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Ozuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633; Paul D., 1998, P SIGGRAPH 98, P189, DOI [10.1145/280814.280864, DOI 10.1145/280814.280864]; PAULY M, 2005, P EUR S GEOM PROC; Pellacini F, 2000, COMP GRAPH, P55, DOI 10.1145/344779.344812; Peng XC, 2015, IEEE I CONF COMP VIS, P1278, DOI 10.1109/ICCV.2015.151; Pepik B, 2012, PROC CVPR IEEE, P3362, DOI 10.1109/CVPR.2012.6248075; Pishchulin L, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.5; Pishchulin L, 2011, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2011.5995574; Rematas K., 2016, P IEEE C COMP VIS PA, P3898; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Sharma A., 2016, ARXIV160403755CSCV; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Shrivastava A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024188; Sloan P.-P. J., 2001, GRAPHICS INTERFACE, P143; Stark M., 2010, P BRIT MACH VIS C, P1, DOI [10.5244/C.24.106, DOI 10.5244/C.24.106]; Su H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601159; Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308; Targhi AT, 2008, INT C PATT RECOG, P717; van den Hengel A., 2007, P ACM SIGGRAPH; Wohlkinger Walter, 2010, 2010 IEEE 19th International Workshop on Robotics in Alpe-Adria-Danube Region (RAAD 2010), P247, DOI 10.1109/RAAD.2010.5524578; Wood DN, 2000, COMP GRAPH, P287, DOI 10.1145/344779.344925; Wu HZ, 2015, COMPUT GRAPH FORUM, V34, P289, DOI 10.1111/cgf.12600; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Xu K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964975; Zhukov S., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P45; Zia MZ, 2013, IEEE T PATTERN ANAL, V35, P2608, DOI 10.1109/TPAMI.2013.87; Zobel M, 2002, VISION MODELING, AND VISUALIZATION 2002, PROCEEDINGS, P371	71	27	27	2	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1576	1590		10.1109/TPAMI.2016.2601093	http://dx.doi.org/10.1109/TPAMI.2016.2601093			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	27541489	Green Submitted			2022-12-18	WOS:000404606300007
J	Lian, W; Zhang, L; Yang, MH				Lian, Wei; Zhang, Lei; Yang, Ming-Hsuan			An Efficient Globally Optimal Algorithm for Asymmetric Point Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Branch and bound; concave optimization; linear assignment; point correspondence; robust point matching	REGISTRATION; SETS	Although the robust point matching algorithm has been demonstrated to be effective for non-rigid registration, there are several issues with the adopted deterministic annealing optimization technique. First, it is not globally optimal and regularization on the spatial transformation is needed for good matching results. Second, it tends to align the mass centers of two point sets. To address these issues, we propose a globally optimal algorithm for the robust point matching problem in the case that each model point has a counterpart in scene set. By eliminating the transformation variables, we show that the original matching problem is reduced to a concave quadratic assignment problem where the objective function has a low rank Hessian matrix. This facilitates the use of large scale global optimization techniques. We propose a modified normal rectangular branch-and-bound algorithm to solve the resulting problem where multiple rectangles are simultaneously subdivided to increase the chance of shrinking the rectangle containing the global optimal solution. In addition, we present an efficient lower bounding scheme which has a linear assignment formulation and can be efficiently solved. Extensive experiments on synthetic and real datasets demonstrate the proposed algorithm performs favorably against the state-of-the-art methods in terms of robustness to outliers, matching accuracy, and run-time.	[Lian, Wei] Changzhi Univ, Dept Comp Sci, Changzhi 046011, Shanxi, Peoples R China; [Lian, Wei; Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China; [Yang, Ming-Hsuan] Univ Calif, Sch Engn, Merced, CA 95344 USA	Changzhi University; Hong Kong Polytechnic University; University of California System; University of California Merced	Lian, W (corresponding author), Changzhi Univ, Dept Comp Sci, Changzhi 046011, Shanxi, Peoples R China.	lianwei3@gmail.com; cslzhang@comp.polyu.edu.hk; mhyang@ucmerced.edu	Yang, Ming-Hsuan/AAE-7350-2019; Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Zhang, Lei/0000-0002-2078-4215	Hong Kong RGC GRF grant [PolyU 5313/13E]; USA National Science Foundation CAREER grant [1149783]	Hong Kong RGC GRF grant; USA National Science Foundation CAREER grant	This work was supported by Hong Kong RGC GRF grant (PolyU 5313/13E), and USA National Science Foundation CAREER grant (1149783).	[Anonymous], 2007, CNSTR2007001 CALTECH; Bazin JC, 2013, IEEE T PATTERN ANAL, V35, P1565, DOI 10.1109/TPAMI.2012.264; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Breitenreicher D, 2011, INT J COMPUT VISION, V92, P32, DOI 10.1007/s11263-010-0401-3; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Caetano TS, 2006, INT C PATT RECOG, P121; Cho MS, 2014, PROC CVPR IEEE, P2091, DOI 10.1109/CVPR.2014.268; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Deng Y, 2014, PROC CVPR IEEE, P3756, DOI 10.1109/CVPR.2014.486; Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Glaunes J, 2004, PROC CVPR IEEE, P712; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hao Jiang, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2474, DOI 10.1109/CVPRW.2009.5206776; Ho J, 2009, IEEE I CONF COMP VIS, P1335, DOI 10.1109/ICCV.2009.5459309; Jian B, 2005, IEEE I CONF COMP VIS, P1246; Jiang H, 2007, IEEE T PATTERN ANAL, V29, P959, DOI 10.1109/TPAMI.2007.1048; Jiang H, 2015, IEEE T PATTERN ANAL, V37, P2558, DOI 10.1109/TPAMI.2015.2409880; JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710; Lee JH, 2011, IEEE T PATTERN ANAL, V33, P427, DOI 10.1109/TPAMI.2010.179; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Li HD, 2009, IEEE I CONF COMP VIS, P1074, DOI 10.1109/ICCV.2009.5459398; Li HS, 2013, IEEE T PATTERN ANAL, V35, P411, DOI 10.1109/TPAMI.2012.99; Lian W, 2014, PROC CVPR IEEE, P352, DOI 10.1109/CVPR.2014.52; Lian W, 2012, LECT NOTES COMPUT SC, V7573, P259, DOI 10.1007/978-3-642-33709-3_19; Lian W, 2012, IEEE T IMAGE PROCESS, V21, P2786, DOI 10.1109/TIP.2012.2186309; Lian W, 2010, LECT NOTES COMPUT SC, V6315, P506, DOI 10.1007/978-3-642-15555-0_37; Ma JY, 2013, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2013.279; Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131; Pfeuffer F, 2012, ANN OPER RES, V196, P737, DOI 10.1007/s10479-010-0760-8; Ngoc QN, 2015, PROC CVPR IEEE, P5270, DOI 10.1109/CVPR.2015.7299164; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sofka M., P 2007 IEEE C COMP V, P1; Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558; Tuy H., 1996, GLOBAL OPTIMIZATION; Yang JL, 2013, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2013.184; YUILLE AL, 1994, NEURAL COMPUT, V6, P341, DOI 10.1162/neco.1994.6.3.341; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	45	27	28	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1281	1293		10.1109/TPAMI.2016.2603988	http://dx.doi.org/10.1109/TPAMI.2016.2603988			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	28113572	hybrid			2022-12-18	WOS:000402744400001
J	Yoon, JH; Yang, MH; Yoon, KJ				Yoon, Ju Hong; Yang, Ming-Hsuan; Yoon, Kuk-Jin			Interacting Multiview Tracker	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object tracking; multiview representations; transition probability matrix; tracker interaction; multiple features	VISUAL TRACKING; CUE INTEGRATION; OBJECT TRACKING	A robust algorithm is proposed for tracking a target object in dynamic conditions including motion blurs, illumination changes, pose variations, and occlusions. To cope with these challenging factors, multiple trackers based on different feature representations are integrated within a probabilistic framework. Each view of the proposed multiview (multi-channel) feature learning algorithm is concerned with one particular feature representation of a target object from which a tracker is developed with different levels of reliability. With the multiple trackers, the proposed algorithm exploits tracker interaction and selection for robust tracking performance. In the tracker interaction, a transition probability matrix is used to estimate dependencies between trackers. Multiple trackers communicate with each other by sharing information of sample distributions. The tracker selection process determines the most reliable tracker with the highest probability. To account for object appearance changes, the transition probability matrix and tracker probability are updated in a recursive Bayesian framework by reflecting the tracker reliability measured by a robust tracker likelihood function that learns to account for both transient and stable appearance changes. Experimental results on benchmark datasets demonstrate that the proposed interacting multiview algorithm performs robustly and favorably against state-of-the-art methods in terms of several quantitative metrics.	[Yoon, Ju Hong] Gwangju Inst Sci & Technol, Sch Informat & Commun, Songnam, Gyeonggido, South Korea; [Yoon, Ju Hong] Korea Elect & Technol Inst, Multimedia IP Ctr, Songnam, Gyeonggido, South Korea; [Yang, Ming-Hsuan] Univ Calif, Sch Engn, Merced, CA USA; [Yoon, Kuk-Jin] Gwangju Inst Sci & Technol, Sch Informat & Commun, Gwangju, South Korea	Gwangju Institute of Science & Technology (GIST); Korea Electronics Technology Institute (KETI); University of California System; University of California Merced; Gwangju Institute of Science & Technology (GIST)	Yoon, JH (corresponding author), Gwangju Inst Sci & Technol, Sch Informat & Commun, Songnam, Gyeonggido, South Korea.; Yoon, JH (corresponding author), Korea Elect & Technol Inst, Multimedia IP Ctr, Songnam, Gyeonggido, South Korea.; Yang, MH (corresponding author), Univ Calif, Sch Engn, Merced, CA USA.; Yoon, KJ (corresponding author), Gwangju Inst Sci & Technol, Sch Informat & Commun, Gwangju, South Korea.	jhyoon@keti.re.kr; mhyang@ucmerced.edu; kjyoon@gist.ac.kr	Yang, Ming-Hsuan/AAE-7350-2019; Yang, Ming-Hsuan/T-9533-2019; Yoon, Kuk-Jin/F-4329-2018	Yang, Ming-Hsuan/0000-0003-4848-2304; 	ICT R&D program of MSIP/IITP [B0101-15-0552]; NRF - MSIP [NRF-2015R1A2A1A01005455]; Giga KOREA Project [GK130100]; Global Frontier Project [CISS-2011-0031868]; US National Science Foundation CAREER [1149783]; US National Science Foundation IIS [1152576]	ICT R&D program of MSIP/IITP(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of Korea); NRF - MSIP(National Research Foundation of Korea); Giga KOREA Project(Giga Korea Co.); Global Frontier Project; US National Science Foundation CAREER(National Science Foundation (NSF)); US National Science Foundation IIS(National Science Foundation (NSF))	This work was supported by the ICT R&D program of MSIP/IITP [B0101-15-0552], an NRF grant funded by the MSIP (No. NRF-2015R1A2A1A01005455), the Giga KOREA Project [GK130100], and the Global Frontier Project (CISS-2011-0031868). M.-H. Yang was supported in part by US National Science Foundation CAREER Grant 1149783 and IIS Grant 1152576.	Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Badrinarayanan V., 2009, THESIS INRIA RENNES; Badrinarayanan V, 2007, IEEE I CONF COMP VIS, P1000; Bar-Shalom Y., 2002, ESTIMATION APPL TRAC; Brasnett P, 2005, PROC SPIE, V5685, P430, DOI 10.1117/12.585882; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733; Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038; Du W, 2008, LECT NOTES COMPUT SC, V5303, P225, DOI 10.1007/978-3-540-88688-4_17; Grabner H, 2006, IEEE C COMP VIS PATT, P260; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880; Jilkov VP, 2004, IEEE T SIGNAL PROCES, V52, P1620, DOI 10.1109/TSP.2004.827145; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Koh KM, 2007, J MACH LEARN RES, V8, P1519; Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Leichter I, 2006, INT J COMPUT VISION, V67, P343, DOI 10.1007/s11263-006-5568-2; Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730; Mei X, 2011, PROC CVPR IEEE, P1257; Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66; Moreno-Noguer F, 2008, IEEE T PATTERN ANAL, V30, P670, DOI 10.1109/TPAMI.2007.70727; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145; Spengler M, 2003, MACH VISION APPL, V14, P50, DOI 10.1007/s00138-002-0095-9; Wang HZ, 2006, INT C PATT RECOG, P892; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Xu C., 2013, CORR; Yang A. Y., 2010, CORR; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yoon JH, 2012, LECT NOTES COMPUT SC, V7575, P28, DOI 10.1007/978-3-642-33765-9_3; Zelniker E., 2009, P BRIT MACH VIS C LO, P1; Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882	37	27	29	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					903	917		10.1109/TPAMI.2015.2473862	http://dx.doi.org/10.1109/TPAMI.2015.2473862			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	26336117				2022-12-18	WOS:000374164700006
J	Zhang, SL; Yang, M; Wang, XY; Lin, YQ; Tian, Q				Zhang, Shiliang; Yang, Ming; Wang, Xiaoyu; Lin, Yuanqing; Tian, Qi			Semantic-Aware Co-Indexing for Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Large-scale Image Retrieval; Inverted Indexing; Vocabulary Trees; Semantic Attributes; Deep CNN		In content-based image retrieval, inverted indexes allow fast access to database images and summarize all knowledge about the database. Indexing multiple clues of image contents allows retrieval algorithms search for relevant images from different perspectives, which is appealing to deliver satisfactory user experiences. However, when incorporating diverse image features during online retrieval, it is challenging to ensure retrieval efficiency and scalability. In this paper, for large-scale image retrieval, we propose a semantic-aware co-indexing algorithm to jointly embed two strong cues into the inverted indexes: 1) local invariant features that are robust to delineate low-level image contents, and 2) semantic attributes from large-scale object recognition that may reveal image semantic meanings. Specifically, for an initial set of inverted indexes of local features, we utilize semantic attributes to filter out isolated images and insert semantically similar images to this initial set. Encoding these two distinct and complementary cues together effectively enhances the discriminative capability of inverted indexes. Such co-indexing operations are totally off-line and introduce small computation overhead to online retrieval, because only local features but no semantic attributes are employed for the query. Hence, this co-indexing is different from existing image retrieval methods fusing multiple features or retrieval results. Extensive experiments and comparisons with recent retrieval methods manifest the competitive performance of our method.	[Zhang, Shiliang] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China; [Lin, Yuanqing] NEC Labs Amer Inc, Cupertino, CA 95014 USA; [Yang, Ming] Facebook Inc, AI Res, Menlo Pk, CA 94025 USA; [Wang, Xiaoyu] Snapchat, London, England; [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX USA	Peking University; NEC Corporation; Facebook Inc; University of Texas System; University of Texas at San Antonio (UTSA)	Zhang, SL (corresponding author), NEC Labs Amer, Princeton, NJ 08540 USA.	slzhang.jdl@pku.edu.cn; m-yang4@u.northwestern.edu; fanghuaxue@gmail.com; ylin@nec-labs.com; qitian@cs.utsa.edu	Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming/0000-0003-1691-6817; Wang, Xiaoyu/0000-0002-6431-8822	ARO [W911NF1210057]; NEC Laboratories of America; National Science Foundation of China (NSFC) [61429201, 61572050]	ARO; NEC Laboratories of America; National Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work was finished in part in NEC Laboratories America and in part in University of Texas at San Antonio (UTSA). This work was supported in part to Dr. Qi Tian by ARO grant W911NF1210057 and Faculty Research Award by NEC Laboratories of America. This work was supported in part by National Science Foundation of China (NSFC) 61429201 and 61572050.	[Anonymous], P IEEE C COMP VIS PA; [Anonymous], 2010, LARGE SCALE VISUAL R; [Anonymous], 2012, LARGE SCALE VISUAL R; Arandjelovic R, 2014, IEEE T PATTERN ANAL, V36, P2396, DOI 10.1109/TPAMI.2014.2339821; Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Douze M, 2011, PROC CVPR IEEE, P745, DOI 10.1109/CVPR.2011.5995595; Fagin R., 2003, P 2003 ACM SIGMOD IN, P301, DOI DOI 10.1145/872757.872795; Farhadi A., 2009, P IEEE C COMP VIS PA; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Ferrari V., 2007, P ADV NEUR INF PROC, V21, P1778; Ge T., 2013, P IEEE C COMP VIS PA, P2329; Gehler P.V., 2009, P INT C COMP VIS; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong YC, 2011, PROC CVPR IEEE; Hauptmann AG, 2008, P IEEE, V96, P602, DOI 10.1109/JPROC.2008.916355; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285; Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516; Jia Y., 2013, CAFFE OPEN SOURCE CO; KE Y, 2004, P ACM MULT; Krizhevsky A., 2012, ADV NEURAL INFORM PR; Kumar N., 2009, P INT C COMP VIS; Lin Y., 2011, P IEEE C COMP VIS PA; Liu W., 2012, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mu Y., 2010, P EUR C COMPUT VIS; Nister D., 2006, P 2006 IEEE COMP SOC; Norouzi M., 2013, P IEEE C COMP VIS PA; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Philbin J, 2007, CVPR; Shen X., 2012, P IEEE C COMP VIS PA; Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163; Sivic J., 2003, P INT C COMP VIS; Tolias G., 2013, P INT C COMP VIS; Torralba A., 2008, PAMI, V30, P1985; Torralba A., 2008, P IEEE C COMP VIS PA; Torresani L., 2010, P EUR C COMPUT VIS; Turcot P., 2009, P ICCV WORKSH; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Wang X., 2011, P INT C COMP VIS; Weiss Y., 2008, P ADV NEUR INF PROC; WU Z., 2009, P IEEE C COMP VIS PA; Ye G., 2012, P IEEE C COMP VIS PA; Yu Felix X., 2012, P IEEE C COMP VIS PA; ZHANG DQ, 2004, P ACM MULT; Zhang S., 2009, P ACM MULT; Zhang S., 2010, P ACM MULT; Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47; Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650; Zhang Y., 2011, P IEEE C COMP VIS PA; Zhou W., 2010, P ACM MULT	54	27	27	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2573	2587		10.1109/TPAMI.2015.2417573	http://dx.doi.org/10.1109/TPAMI.2015.2417573			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539859	Green Submitted			2022-12-18	WOS:000364831700017
J	Asthana, A; Zafeiriou, S; Tzimiropoulos, G; Cheng, SY; Pantic, M				Asthana, Akshay; Zafeiriou, Stefanos; Tzimiropoulos, Georgios; Cheng, Shiyang; Pantic, Maja			From Pixels to Response Maps: Discriminative Image Filtering for Face Alignment in the Wild	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face alignment; facial landmark detection; active appearance models; constrained local models	MODELS	We propose a face alignment framework that relies on the texture model generated by the responses of discriminatively trained part-based filters. Unlike standard texture models built from pixel intensities or responses generated by generic filters (e.g. Gabor), our framework has two important advantages. First, by virtue of discriminative training, invariance to external variations (like identity, pose, illumination and expression) is achieved. Second, we show that the responses generated by discriminatively trained filters (or patch-experts) are sparse and can be modeled using a very small number of parameters. As a result, the optimization methods based on the proposed texture model can better cope with unseen variations. We illustrate this point by formulating both part-based and holistic approaches for generic face alignment and show that our framework outperforms the state-of-the-art on multiple "wild" databases. The code and dataset annotations are available for research purposes from http://ibug.doc.ic.ac.uk/resources.	[Asthana, Akshay; Zafeiriou, Stefanos; Tzimiropoulos, Georgios; Cheng, Shiyang; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England; [Tzimiropoulos, Georgios] Lincoln Univ, Sch Comp Sci, Lincoln LN6 7TS, England; [Pantic, Maja] Univ Twente, Dept Comp Sci, NL-7522 NB Enschede, Netherlands	Imperial College London; University of Lincoln; University of Twente	Asthana, A (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.	a.asthana@imperial.ac.uk; s.zafeiriou@imperial.ac.uk; gtzimiropoulos@lincoln.ac.uk; cheng11@imperial.ac.uk; m.pantic@imperial.ac.uk		Tzimiropoulos, Georgios/0000-0002-1803-5338	Marie Curie Fellowship under FP7-PEOPLE-IIF [302836]; EPSRC [EP/J017787/1, EP/L026813/1]; EC [288235]; Engineering and Physical Sciences Research Council [EP/J017787/1, EP/L026813/1, EP/H016988/1] Funding Source: researchfish; EPSRC [EP/H016988/1] Funding Source: UKRI	Marie Curie Fellowship under FP7-PEOPLE-IIF; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EC(European CommissionEuropean Commission Joint Research Centre); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	A. Asthana was funded by Marie Curie Fellowship under FP7-PEOPLE-2011-IIF Grant agreement no. 302836 (FER in the Wild). S. Cheng was funded by the EPSRC project EP/J017787/1 (4D-FAB). S. Zafeiriou received support from EPSRC project EP/L026813/1 (ADAManT). The work of G. Tzimiropoulos was funded by the EC 7th Framework Programme [FP7/2007-2013] under grant agreement no. 288235 (FROG).	Amberg B, 2009, PROC CVPR IEEE, P1714, DOI 10.1109/CVPRW.2009.5206788; Baker S., 2003, CMURITR0335; Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cootes TF, 2012, LECT NOTES COMPUT SC, V7578, P278, DOI 10.1007/978-3-642-33786-4_21; Cristinacce D., 2006, P BRIT MACH VIS C, V3, P929; de la Rosa FDB, 2007, IBEROROMANIA, P1; Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; Gross R., 2008, P IEEE INT C AUT FAC, P1; Ho CH, 2012, J MACH LEARN RES, V13, P3323; Ho HT, 2013, IEEE T IMAGE PROCESS, V22, P1571, DOI 10.1109/TIP.2012.2233489; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Liu XM, 2007, PROC CVPR IEEE, P2264; Lucey S, 2013, IEEE T PATTERN ANAL, V35, P1383, DOI 10.1109/TPAMI.2012.220; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Saragih J, 2007, IEEE I CONF COMP VIS, P2173; Saragih J, 2006, INT C PATT RECOG, P1192; Saragih J, 2009, PATTERN RECOGN, V42, P2628, DOI 10.1016/j.patcog.2009.04.014; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Sauer P, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.30; Wang Y, 2008, PROC CVPR IEEE, P3621; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	27	27	28	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1312	1320		10.1109/TPAMI.2014.2362142	http://dx.doi.org/10.1109/TPAMI.2014.2362142			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357352	Green Published, Green Submitted, Green Accepted			2022-12-18	WOS:000354377100016
J	Bryner, D; Klassen, E; Le, HL; Srivastava, A				Bryner, Darshan; Klassen, Eric; Le, Huiling; Srivastava, Anuj			2D Affine and Projective Shape Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Affine shape analysis; projective shape analysis; path-straightening method; geodesic computation; shape models	RECOGNITION; GEODESICS; CURVES; SPACES	Current techniques for shape analysis tend to seek invariance to similarity transformations (rotation, translation, and scale), but certain imaging situations require invariance to larger groups, such as affine or projective groups. Here we present a general Riemannian framework for shape analysis of planar objects where metrics and related quantities are invariant to affine and projective groups. Highlighting two possibilities for representing object boundaries-ordered points (or landmarks) and parameterized curves-we study different combinations of these representations (points and curves) and transformations (affine and projective). Specifically, we provide solutions to three out of four situations and develop algorithms for computing geodesics and intrinsic sample statistics, leading up to Gaussian-type statistical models, and classifying test shapes using such models learned from training data. In the case of parameterized curves, we also achieve the desired goal of invariance to re-parameterizations. The geodesics are constructed by particularizing the path-straightening algorithm to geometries of current manifolds and are used, in turn, to compute shape statistics and Gaussian-type shape models. We demonstrate these ideas using a number of examples from shape and activity recognition.	[Bryner, Darshan] Naval Surface Warfare Ctr, Panama City, FL 32407 USA; [Bryner, Darshan] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA; [Klassen, Eric; Srivastava, Anuj] Florida State Univ, Tallahassee, FL 32306 USA; [Le, Huiling] Univ Nottingham, Sch Math Sci, Nottingham NG7 2RD, England	State University System of Florida; Florida State University; State University System of Florida; Florida State University; University of Nottingham	Bryner, D (corresponding author), Naval Surface Warfare Ctr, Panama City, FL 32407 USA.	dbryner@stat.fsu.edu; klassen@math.fsu.edu; huiling.le@nottingham.ac.uk; anuj@stat.fsu.edu	Srivastava, Anuj/L-4705-2019	Srivastava, Anuj/0000-0001-7406-0338	NSF [IIS-1217515, DMS-1208959]; NSWC PCD ILIR program; Direct For Computer & Info Scie & Enginr [1217515, 1319658] Funding Source: National Science Foundation; Division Of Mathematical Sciences [1208959] Funding Source: National Science Foundation	NSF(National Science Foundation (NSF)); NSWC PCD ILIR program; Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE)); Division Of Mathematical Sciences(National Science Foundation (NSF)NSF - Directorate for Mathematical & Physical Sciences (MPS))	This work was supported in part by the grants NSF IIS-1217515 and NSF DMS-1208959 to A. Srivastava, and by NSWC PCD ILIR program to D. Bryner. The authors acknowledge the support of Dr. Kerry Commander and Dr. Quyen Huynh.	Begelfor E., 2006, 2006 IEEE COMPUTER S, V2, P2087, DOI DOI 10.1109/CVPR.2006.50; Berthilsson R, 1999, J MATH IMAGING VIS, V11, P119, DOI 10.1023/A:1008379110792; Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426; Bryner D, 2012, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2012.6247700; Carlsson S, 1996, INT J COMPUT VISION, V19, P211, DOI 10.1007/BF00055145; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Goodall CR, 1999, J COMPUT GRAPH STAT, V8, P143, DOI 10.2307/1390631; Hartley R., 2004, ROBOTICA; Huang XM, 2005, PATTERN RECOGN LETT, V26, P1244, DOI 10.1016/j.patrec.2004.11.006; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Kent JT, 2012, BIOMETRIKA, V99, P833, DOI 10.1093/biomet/ass055; Klassen E, 2006, LECT NOTES COMPUT SC, V3951, P95; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Mardia KV, 2005, ANN STAT, V33, P1666, DOI 10.1214/009053605000000273; Mei Y., 2009, P IEEE INT C IM PROC, P1065; ROTHWELL CA, 1995, INT J COMPUT VISION, V16, P57, DOI 10.1007/BF01428193; SPARR G, 1992, IMAGE VISION COMPUT, V10, P683, DOI 10.1016/0262-8856(92)90013-S; Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184; TYLER DE, 1987, ANN STAT, V15, P234, DOI 10.1214/aos/1176350263; Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P810, DOI 10.1109/34.400572; Younes L, 2008, REND LINCEI-MAT APPL, V19, P25; Zuliani M., 2004, P IEEE INT C IM PROC	23	27	30	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					998	1011		10.1109/TPAMI.2013.199	http://dx.doi.org/10.1109/TPAMI.2013.199			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353232				2022-12-18	WOS:000336054200013
J	Vogelstein, JT; Roncal, WG; Vogelstein, RJ; Priebe, CE				Vogelstein, Joshua T.; Roncal, William Gray; Vogelstein, R. Jacob; Priebe, Carey E.			Graph Classification Using Signal-Subgraphs: Applications in Statistical Connectomics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Statistical inference; graph theory; network theory; structural pattern recognition; connectome; classification		This manuscript considers the following "graph classification"question: Given a collection of graphs and associated classes, how can one predict the class of a newly observed graph? To address this question, we propose a statistical model for graph/class pairs. This model naturally leads to a set of estimators to identify the class-conditional signal, or "signal-subgraph,"defined as the collection of edges that are probabilistically different between the classes. The estimators admit classifiers which are asymptotically optimal and efficient, but which differ by their assumption about the "coherency"of the signal-subgraph (coherency is the extent to which the signal-edges "stick together"around a common subset of vertices). Via simulation, the best estimator is shown to be not just a function of the coherency of the model, but also the number of training samples. These estimators are employed to address a contemporary neuroscience question: Can we classify "connectomes"(brain-graphs) according to sex? The answer is yes, and significantly better than all benchmark algorithms considered. Synthetic data analysis demonstrates that even when the model is correct, given the relatively small number of training samples, the estimated signal-subgraph should be taken with a grain of salt. We conclude by discussing several possible extensions.	[Vogelstein, Joshua T.] Duke Univ, Dept Math & Stat, Durham, NC 27708 USA; [Roncal, William Gray; Vogelstein, R. Jacob] Johns Hopkins Univ, Appl Phys Lab, Laurel, MD 20723 USA; [Priebe, Carey E.] Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA	Duke University; Johns Hopkins University; Johns Hopkins University Applied Physics Laboratory; Johns Hopkins University	Vogelstein, JT (corresponding author), Duke Univ, Dept Math & Stat, POB 90251,Res Dr, Durham, NC 27708 USA.	jovo@stat.duke.edu; William.Gray@jhuapl.edu; jacob.vogelstein@jhuapl.edu; cep@jhu.edu	Vogelstein, Joshua/AAG-5489-2019; Vogelstein, R Jacob/H-3396-2013	Vogelstein, Joshua/0000-0003-2487-6237; 	Research Program in Applied Neuroscience	Research Program in Applied Neuroscience	This work was partially supported by the Research Program in Applied Neuroscience. The authors would like to thank Michael Trosset for a helpful suggestion.	Bassett DS, 2009, CURR OPIN NEUROL, V22, P340, DOI 10.1097/WCO.0b013e32832d93dd; BICKEL PJ, 2000, MATH STAT BASIC IDEA, V1; Bock DD, 2011, NATURE, V471, P177, DOI 10.1038/nature09802; Bunke H, 2012, PATTERN RECOGN LETT, V33, P811, DOI 10.1016/j.patrec.2011.04.017; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Chandrasekaran V, 2011, SIAM J OPTIMIZ, V21, P572, DOI 10.1137/090761793; Coppersmith G. A., 2012, TECHNOLOGY, P1; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550; Ding XH, 2011, IEEE T IMAGE PROCESS, V20, P3419, DOI 10.1109/TIP.2011.2156801; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Fishkind D. E., 2012, RAPID POST       MAY, P20; Good P. I., 2010, PERMUTATION PARAMETR; Gray WR, 2012, IEEE PULSE, V3, P42, DOI 10.1109/MPUL.2011.2181023; Hagmann P, 2010, J NEUROSCI METH, V194, P34, DOI 10.1016/j.jneumeth.2010.01.014; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.1111/j.1751-5823.2001.tb00465.x; Hoff PD, 2002, J AM STAT ASSOC, V97, P1090, DOI 10.1198/016214502388618906; Huber PJ., 2009, ROBUST STAT, DOI [10. 1002/9780470434697, DOI 10.1002/9780470434697, 10.1002/9780470434697]; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Ketkar NS, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P259, DOI 10.1109/CIDM.2009.4938658; Kudo T., SCIENCE; Lasserre J.A., 2006, IEEE COMP SOC C COMP, P87, DOI DOI 10.1109/CVPR.2006.227; Lee D.S., 2012, RAPID POST; Lichtman JW, 2008, NAT REV NEUROSCI, V9, P417, DOI 10.1038/nrn2391; Marchette D. J., 2011, VERTEX NOMINATION VI; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Nolte J, 2002, HUMAN BRAIN INTRO IT; North G, 2007, COLD SPRING HARB MON, V49, pIX; Pao H, 2011, J COMPUT GRAPH STAT, V20, P395, DOI 10.1198/jcgs.2010.09004; Priebe C. E., 2010, STAT COMPUT GRAPH NE, V21, P11; Rice J. A., 1995, MATH STAT DATA ANAL; Rukhin A, 2011, J STAT PLAN INFER, V141, P1041, DOI 10.1016/j.jspi.2010.09.013; Shepherd JD, 2007, ANNU REV CELL DEV BI, V23, P613, DOI 10.1146/annurev.cellbio.23.090506.123516; Sporns O., 2016, NETWORKS BRAIN; Stein C., 1956, P BERK S MATH STAT P, V1, P197, DOI DOI 10.1525/9780520313880-018; Sussman D. L., 2012, J AM STAT ASSOC, P17; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Vogelstein J. T., 2011, RAPID POST; Vogelstein J. T., 2011, NATURE SCI REPORTS, P11; Vogelstein J. T., 2011, ARXIV11125506V2QBIOQ; Vogelstein J. T., 2010, ORG HUMAN BRAIN MAPP	43	27	27	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1539	1551		10.1109/TPAMI.2012.235	http://dx.doi.org/10.1109/TPAMI.2012.235			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681985	Green Submitted			2022-12-18	WOS:000319060600001
J	Audhkhasi, K; Narayanan, S				Audhkhasi, Kartik; Narayanan, Shrikanth (Shri)			A Globally-Variant Locally-Constant Model for Fusion of Labels from Multiple Diverse Experts without Using Reference Labels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiple diverse experts; label fusion; label reliability; expectation-maximization algorithm; human annotation; emotion recognition		Researchers have shown that fusion of categorical labels from multiple experts-humans or machine classifiers-improves the accuracy and generalizability of the overall classification system. Simple plurality is a popular technique for performing this fusion, but it gives equal importance to labels from all experts, who may not be equally reliable or consistent across the dataset. Estimation of expert reliability without knowing the reference labels is, however, a challenging problem. Most previous works deal with these challenges by modeling expert reliability as constant over the entire data (feature) space. This paper presents a model based on the consideration that in dealing with real-world data, expert reliability is variable over the complete feature space but constant over local clusters of homogeneous instances. This model jointly learns a classifier and expert reliability parameters without assuming knowledge of the reference labels using the Expectation-Maximization (EM) algorithm. Classification experiments on simulated data, data from the UCI Machine Learning Repository, and two emotional speech classification datasets show the benefits of the proposed model. Using a metric based on the Jensen-Shannon divergence, we empirically show that the proposed model gives greater benefit for datasets where expert reliability is highly variable over the feature space.	[Audhkhasi, Kartik; Narayanan, Shrikanth (Shri)] Univ So Calif, Dept Elect Engn, SAIL, Los Angeles, CA 90089 USA	University of Southern California	Audhkhasi, K (corresponding author), Univ So Calif, Dept Elect Engn, SAIL, 3740 McClintock Ave, Los Angeles, CA 90089 USA.	audhkhas@usc.edu; shri@sipi.usc.edu	Narayanan, Shrikanth S/D-5676-2012		Div Of Information & Intelligent Systems [0911009] Funding Source: National Science Foundation	Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))		Alimoglu F., 1996, P 5 TURK ART INT ART; Audhkhasi K., 2010, P INT C; Bishop C.M, 2006, PATTERN RECOGN; Black D, 1986, THEORY COMMITTEES EL; Dawid A.P., 1979, APPL STAT, V28, P20, DOI [10.2307/2346806, DOI 10.2307/2346806]; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Duda R.O., 2001, PATTERN CLASSIFICATI, V2; Eyben F., 2010, PROC ACM INT C MULTI, P1459, DOI [10.1145/1873951.1874246, DOI 10.1145/1873951.1874246]; Frank A., 2010, UCI MACHINE LEARNING; Grimm M, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P381; Hall M., 2008, WEKA DATA MINING SOF, V11, P10, DOI [10.1145/1656274.1656278, DOI 10.1145/1656274.1656278]; Heck D., 1998, CORSIKA MONTE CARLO; Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203; Horton P, 1996, Proc Int Conf Intell Syst Mol Biol, V4, P109; Jin R., 2003, PROC NEURAL INF PROC, P921; Kehrein R., 2002, P SPEECH PROS C, P423; Lee Sungbok, 2005, P 9 EUR C SPEECH COM; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Marge M., 2010, P INT C AC SPEECH SI; McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20; Mower E., 2009, P 3 INT C AFF COMP I; Nash W.J., 1978, POPULATION BIOL ABAL; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Raykar VC, 2010, J MACH LEARN RES, V11, P1297; Schulze M., 2003, VOTING MATTERS, V17, P9; Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1), P261; Smyth P., 1995, Advances in Neural Information Processing Systems 7, P1085; Snow Rion, 2008, P 2008 C EMP METH NA, P254, DOI DOI 10.3115/1613715.1613751; Sorokin A, 2008, PROC CVPR IEEE, P23; Whitehill J., 2009, ADV NEURAL INFORM PR, P2035; Yan Y., 2010, P INT C ART INT STAT	32	27	27	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					769	783		10.1109/TPAMI.2012.139	http://dx.doi.org/10.1109/TPAMI.2012.139			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22732663				2022-12-18	WOS:000314931000001
J	Lin, HT; Tai, YW; Brown, MS				Lin, Hai Ting; Tai, Yu-Wing; Brown, Michael S.			Motion Regularization for Matting Motion Blurred Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Matting; regularization; motion direction estimation; motion blur		This paper addresses the problem of matting motion blurred objects from a single image. Existing single image matting methods are designed to extract static objects that have fractional pixel occupancy. This arises because the physical scene object has a finer resolution than the discrete image pixel and therefore only occupies a fraction of the pixel. For a motion blurred object, however, fractional pixel occupancy is attributed to the object's motion over the exposure period. While conventional matting techniques can be used to matte motion blurred objects, they are not formulated in a manner that considers the object's motion and tend to work only when the object is on a homogeneous background. We show how to obtain better alpha mattes by introducing a regularization term in the matting formulation to account for the object's motion. In addition, we outline a method for estimating local object motion based on local gradient statistics from the original image. For the sake of completeness, we also discuss how user markup can be used to denote the local direction in lieu of motion estimation. Improvements to alpha mattes computed with our regularization are demonstrated on a variety of examples.	[Lin, Hai Ting; Brown, Michael S.] Natl Univ Singapore, Sch Comp, Singapore 117590, Singapore; [Tai, Yu-Wing] Korea Adv Inst Sci & Technol, Taejon 305701, South Korea	National University of Singapore; Korea Advanced Institute of Science & Technology (KAIST)	Lin, HT (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 117590, Singapore.	linhait@comp.nus.edu.sg; yuwing@cs.kaist.ac.kr; brown@comp.nus.edu.sg	Tai, Yu Wing/C-2047-2011	Tai, Yu Wing/0000-0002-3148-0380	FRC [R-252-000-423-112]; Ministry of Culture, Sports, and Tourism (MCST); Korea Content Agency (KOCCA)	FRC; Ministry of Culture, Sports, and Tourism (MCST); Korea Content Agency (KOCCA)	This work was supported in part by FRC Grant R-252-000-423-112 and the Ministry of Culture, Sports, and Tourism (MCST) and Korea Content Agency (KOCCA) in the Culture Technology Research and Development Program 2010.	Agrawal A., 2009, P IEEE C COMP VIS PA; Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1; Caglioti V, 2010, INT J COMPUT VISION, V86, P243, DOI 10.1007/s11263-008-0165-1; CHUANG Y, 2001, P IEEE CS C COMP VIS; Cohen M. F., 2007, P IEEE C COMP VIS PA; Dai S., 2008, P IEEE C COMP VIS PA; JIA J, 2007, P IEEE C COMP VIS PA; JOSHI N, 2006, P ACM SIGGRAPH; LEVIN A, 2006, P IEEE CS C COMP VIS; Levin A., 2006, ADV NEURAL INFORM PR, V19, P841; LEVIN A, 2009, P IEEE C COMP VIS PA; Liu R., 2008, P IEEE C COMP VIS PA; MCGUIRE M, 2005, P ACM SIGGRAPH; Rhemann C, 2010, PROC CVPR IEEE, P2149, DOI 10.1109/CVPR.2010.5539894; Shan Q., 2007, P IEEE INT C COMP VI; SUN J, 2004, P ACM SIGGRAPH; SUN J, 2006, P ACM SIGGRAPH; Tai Y.-W., 2010, P IEEE C COMP VIS PA; Tai Y. - W., 2008, P IEEE C COMP VIS PA; Tai YW, 2010, IEEE T PATTERN ANAL, V32, P1012, DOI 10.1109/TPAMI.2009.97; TAI YW, RICHARDSONL IN PRESS; WANG J, 2007, P ACM SIGGRAPH; Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019	23	27	32	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2329	2336		10.1109/TPAMI.2011.93	http://dx.doi.org/10.1109/TPAMI.2011.93			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM	21576738				2022-12-18	WOS:000294910000017
J	Hoyle, DC				Hoyle, David C.			Accuracy of Pseudo-Inverse Covariance Learning-A Random Matrix Theory Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pseudo-inverse; linear discriminants; peaking phenomenon; random matrix theory; bagging; random subspace method	LARGEST EIGENVALUE; TRACE INEQUALITY; CLASSIFICATION; SELECTION; ERROR; SET	For many learning problems, estimates of the inverse population covariance are required and often obtained by inverting the sample covariance matrix. Increasingly for modern scientific data sets, the number of sample points is less than the number of features and so the sample covariance is not invertible. In such circumstances, the Moore-Penrose pseudo-inverse sample covariance matrix, constructed from the eigenvectors corresponding to nonzero sample covariance eigenvalues, is often used as an approximation to the inverse population covariance matrix. The reconstruction error of the pseudo-inverse sample covariance matrix in estimating the true inverse covariance can be quantified via the Frobenius norm of the difference between the two. The reconstruction error is dominated by the smallest nonzero sample covariance eigenvalues and diverges as the sample size becomes comparable to the number of features. For high-dimensional data, we use random matrix theory techniques and results to study the reconstruction error for a wide class of population covariance matrices. We also show how bagging and random subspace methods can result in a reduction in the reconstruction error and can be combined to improve the accuracy of classifiers that utilize the pseudo-inverse sample covariance matrix. We test our analysis on both simulated and benchmark data sets.	Univ Manchester, Fac Life Sci, Manchester M13 9PT, Lancs, England	University of Manchester	Hoyle, DC (corresponding author), Univ Manchester, Fac Life Sci, Michael Smith Bldg,Oxford Rd, Manchester M13 9PT, Lancs, England.	david.hoyle@manchester.ac.uk		Hoyle, David/0000-0003-3483-5885	Isaac Newton Institute for Mathematical Sciences	Isaac Newton Institute for Mathematical Sciences	The author would like to acknowledge the support of the Isaac Newton Institute for Mathematical Sciences, where part of this research was carried out.	Baik J, 2006, J MULTIVARIATE ANAL, V97, P1382, DOI 10.1016/j.jmva.2005.08.003; BARBER D, 1995, J PHYS A-MATH GEN, V28, P1325, DOI 10.1088/0305-4470/28/5/018; Bickel PJ, 2008, ANN STAT, V36, P199, DOI 10.1214/009053607000000758; Bishop, 1995, NEURAL NETWORKS PATT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2007, PATTERN RECOGN LETT, V28, P1438, DOI 10.1016/j.patrec.2007.02.014; HANSEN LK, 1993, NEURAL NETWORKS, V6, P393, DOI 10.1016/0893-6080(93)90006-I; Hardy G.H., 1988, INEQUALITIES CAMBRID; Horn R. A., 1986, MATRIX ANAL; HOYLE D, 2004, P C LEARN THEOR; Hoyle DC, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.016101; Hoyle DC, 2008, J MACH LEARN RES, V9, P2733; Hoyle DC, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026124; Hoyle DC, 2003, EUROPHYS LETT, V62, P117, DOI 10.1209/epl/i2003-00370-1; Hoyle DC, 2002, BIOINFORMATICS, V18, P576, DOI 10.1093/bioinformatics/18.4.576; Johnstone I. M., 2006, P INT C MATH; Johnstone IM, 2001, ANN STAT, V29, P295, DOI 10.1214/aos/1009210544; KRZANOWSKI WJ, 1995, J R STAT SOC C-APPL, V44, P101, DOI 10.2307/2986198; LASSERRE JB, 1995, IEEE T AUTOMAT CONTR, V40, P1500, DOI 10.1109/9.402252; LECUN Y, 1991, PHYS REV LETT, V66, P2396, DOI 10.1103/PhysRevLett.66.2396; Marenko V. A., 1967, MATH USSR SB, V1, P457, DOI [10.1070/SM1967v001n04ABEH001994, DOI 10.1070/SM1967V001N04ABEH001994]; Minka TP, 2001, ADV NEUR IN, V13, P598; MIRSKY L, 1975, MONATSH MATH, V79, P303, DOI 10.1007/BF01647331; Moore E. H., 1920, B AM MATH SOC, V26, P394, DOI [10.1090/S0002-9904-1920-03322-7, 10.1155/2011/831409, DOI 10.1090/S0002-9904-1920-03322-7]; Penrose R., 1955, P CAMBRIDGE PHILOS S, V51, P406, DOI [10.1017/S0305004100030401, DOI 10.1017/S0305004100030401]; Price AL, 2006, NAT GENET, V38, P904, DOI 10.1038/ng1847; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; Schafer J, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1175; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Sengupta AM, 1999, PHYS REV E, V60, P3389, DOI 10.1103/PhysRevE.60.3389; STEWART GW, 1980, SIAM J NUMER ANAL, V17, P403, DOI 10.1137/0717034; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Von Neumann J., 1937, TOMSK U REV, V1, P286; WACHTER KW, 1978, ANN PROBAB, V6, P1, DOI 10.1214/aop/1176995607; Young WH, 1912, P R SOC LOND A-CONTA, V87, P331, DOI 10.1098/rspa.1912.0086	40	27	28	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1470	1481		10.1109/TPAMI.2010.186	http://dx.doi.org/10.1109/TPAMI.2010.186			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	20921584				2022-12-18	WOS:000290574000014
J	Sahbi, H; Audibert, JY; Keriven, R				Sahbi, Hichem; Audibert, Jean-Yves; Keriven, Renaud			Context-Dependent Kernels for Object Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel design; statistical machine learning; support vector machines; context-free kernels; context-dependent kernels; object recognition		Kernels are functions designed in order to capture resemblance between data and they are used in a wide range of machine learning techniques, including support vector machines (SVMs). In their standard version, commonly used kernels such as the Gaussian one show reasonably good performance in many classification and recognition tasks in computer vision, bioinformatics, and text processing. In the particular task of object recognition, the main deficiency of standard kernels such as the convolution one resides in the lack in capturing the right geometric structure of objects while also being invariant. We focus in this paper on object recognition using a new type of kernel referred to as "context dependent." Objects, seen as constellations of interest points, are matched by minimizing an energy function mixing 1) a fidelity term which measures the quality of feature matching, 2) a neighborhood criterion which captures the object geometry, and 3) a regularization term. We will show that the fixed point of this energy is a context-dependent kernel which is also positive definite. Experiments conducted on object recognition show that when plugging our kernel into SVMs, we clearly outperform SVMs with context-free kernels.	[Sahbi, Hichem] Telecom ParisTech, LTCI Lab, CNRS, F-75013 Paris, France; [Audibert, Jean-Yves] Univ Paris Est, Ecole Ponts ParisTech LIGM, F-77455 Marne La Vallee, France; [Audibert, Jean-Yves] CNRS ENS INRIA UMR 8548, F-75214 Paris, France; [Keriven, Renaud] Certis Univ Paris Est, Ecole Ponts ParisTech LIGM, F-77455 Marne La Vallee, France	Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; UDICE-French Research Universities; Universite Paris Cite; Ecole des Ponts ParisTech; Universite Gustave-Eiffel; Ecole des Ponts ParisTech	Sahbi, H (corresponding author), Telecom ParisTech, LTCI Lab, CNRS, 46 Rue Barrault, F-75013 Paris, France.	hichem.sahbi@telecom-paristech.fr; audibert@imagine.enpc.fr; keriven@imagine.enpc.fr			Research Agency ANR (Agence Nationale de la Recherche)	Research Agency ANR (Agence Nationale de la Recherche)(French National Research Agency (ANR))	This work was supported in part by a grant from the Research Agency ANR (Agence Nationale de la Recherche) under the AVEIR and the MGA Projects.	Bahlmann C, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P49, DOI 10.1109/IWFHR.2002.1030883; BARLA A, 2002, P ECCV, P20; BELONGIE S, 2000, P NEUR INF PROC SYST; Berg AC, 2005, PROC CVPR IEEE, P26; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; BOUGHORBEL S, 2005, THESIS FACULTE ORSAY; Caputo B, 2004, INT C PATT RECOG, P132, DOI 10.1109/ICPR.2004.1334079; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Cristianini N., 2000, INTRO SUPPORT VECTOR, DOI [10.1017/CBO9780511801389, DOI 10.1017/CBO9780511801389]; CUTURI M, 2005, THESIS ENSMP; Gartner T., 2003, ACM SIGKDD EXPLORATI, V5, P49; Genton G. M., 2001, J MACHINE LEARNING R, V2, P299; Grauman K, 2007, J MACH LEARN RES, V8, P725; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Haussler D., 1999, CONVOLUTION KERNELS; Jaakkola T, 1999, Proc Int Conf Intell Syst Mol Biol, P149; KONDOR R, 2003, P 20 INT C MACH LEAR; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1784, DOI 10.1109/TPAMI.2006.223; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LYU S, 2005, P IEEE CS C COMP VIS; Miyao H, 2005, PROC INT CONF DOC, P494, DOI 10.1109/ICDAR.2005.170; MORENO P, 2003, P NEUR INF PROC SYST; NG J, 1999, P INT WORKSH REC AN; NIE JY, 1999, P 22 ANN INT ACM SIG; Peters J, 2017, ADAPT COMPUT MACH LE; Sahbi H., 2008, P IEEE C COMP VIS PA, P1; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Schu┬lkopf B., 2004, KERNEL METHODS COMPU; SHASHUA A, 2004, P NEUR INF PROC SYST; Shechtman E, 2007, P IEEE C COMP VIS PA; SIM K, 2007, P 32 INT C AC SPEECH; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tong S., 2001, PROC ACM INT C MULTI, V9, P107; Vapnik V.N, 1998, STAT LEARNING THEORY; Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257; WOLF L, 2003, J MACHINE LEARNING R, V4, P913	36	27	27	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					699	708		10.1109/TPAMI.2010.198	http://dx.doi.org/10.1109/TPAMI.2010.198			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	21079276	Green Submitted			2022-12-18	WOS:000287370400004
J	Yin, P; Criminisi, A; Winn, J; Essa, I				Yin, Pei; Criminisi, Antonio; Winn, John; Essa, Irfan			Bilayer Segmentation of Webcam Videos Using Tree-Based Classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; image understanding; machine learning; decision tree; random forests; boosting; motion analysis	EXTRACTION	This paper presents an automatic segmentation algorithm for video frames captured by a (monocular) webcam that closely approximates depth segmentation from a stereo camera. The frames are segmented into foreground and background layers that comprise a subject (participant) and other objects and individuals. The algorithm produces correct segmentations even in the presence of large background motion with a nearly stationary foreground. This research makes three key contributions: First, we introduce a novel motion representation, referred to as "motons," inspired by research in object recognition. Second, we propose estimating the segmentation likelihood from the spatial context of motion. The estimation is efficiently learned by random forests. Third, we introduce a general taxonomy of tree-based classifiers that facilitates both theoretical and experimental comparisons of several known classification algorithms and generates new ones. In our bilayer segmentation algorithm, diverse visual cues such as motion, motion context, color, contrast, and spatial priors are fused by means of a conditional random field (CRF) model. Segmentation is then achieved by binary min-cut. Experiments on many sequences of our videochat application demonstrate that our algorithm, which requires no initialization, is effective in a variety of scenes, and the segmentation results are comparable to those obtained by stereo systems.	[Yin, Pei] Microsoft Corp, Redmond, WA 98052 USA; [Criminisi, Antonio; Winn, John] Microsoft Res Cambridge, Cambridge CB3 0FB, England; [Essa, Irfan] Georgia Inst Technol, Sch Interact Comp, Coll Comp, Atlanta, GA 30332 USA	Microsoft; Microsoft; University System of Georgia; Georgia Institute of Technology	Yin, P (corresponding author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.	peiyin@microsoft.com; antcrim@microsoft.com; jwinn@microsoft.com; irfan@cc.gatech.edu						Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Baker S, 1998, PROC CVPR IEEE, P434, DOI 10.1109/CVPR.1998.698642; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; Bishop, 1995, NEURAL NETWORKS PATT; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Breiman L, 1998, ANN STAT, V26, P801; Breiman L., 1999, TR567 U CAL BERK; Criminisi A., 2006, IEEE C COMP VIS PATT, V1, P53, DOI DOI 10.1109/CVPR.2006.69; DESELAERS T, 2007, P IEEE CS C COMP VIS; Eun Bae Kong, 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P313; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Jojic N, 2001, PROC CVPR IEEE, P199; Kolmogorov V, 2005, PROC CVPR IEEE, P407; Kumar S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1150, DOI 10.1109/ICCV.2003.1238478; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Lepetit V., 2005, P IEEE CS C COMP VIS; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297; Ozuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23; OZUYSAL M, 2007, P IEEE CS C COMP VIS; PERRONNIN F, 2006, P IEEE EUR C COMP VI; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Rabiner L., 1993, FUNDAMENTALS SPEECH; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Scholkopf B., 2000, MSRTR200023; Shotton J., 2006, P IEEE EUR C COMP VI; Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628; Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882; Torralba A, 2004, PROC CVPR IEEE, P762; Vapnik V.N, 1998, STAT LEARNING THEORY; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Winn J, 2005, IEEE I CONF COMP VIS, P1800; YIN P, 2008, P IEEE INT C AC SPEE; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59; Zhang C, 2008, IEEE T MULTIMEDIA, V10, P1541, DOI 10.1109/TMM.2008.2007344	39	27	32	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					30	42		10.1109/TPAMI.2010.65	http://dx.doi.org/10.1109/TPAMI.2010.65			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	21088317				2022-12-18	WOS:000284277600003
J	Panagopoulos, M; Papaodysseus, C; Rousopoulos, P; Dafi, D; Tracy, S				Panagopoulos, Michail; Papaodysseus, Constantin; Rousopoulos, Panayiotis; Dafi, Dimitra; Tracy, Stephen			Automatic Writer Identification of Ancient Greek Inscriptions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Writer identification; handwriting classification; ancient Greek inscription classification; handwriting analysis; archaeology; feature modeling; pattern recognition	SEGMENTATION	This paper introduces a novel methodology for the classification of ancient Greek inscriptions according to the writer who carved them. Inscription writer identification is crucial for dating the written content, which in turn is of fundamental importance in the sciences of history and archaeology. To achieve this, we first compute an ideal or "platonic" prototype for the letters of each inscription separately. Next, statistical criteria are introduced to reject the hypothesis that two inscriptions are carved by the same writer. In this way, we can determine the number of distinct writers who carved a given ensemble of inscriptions. Next, maximum likelihood considerations are employed to attribute all inscriptions in the collection to the respective writers. The method has been applied to 24 Ancient Athenian inscriptions and attributed these inscriptions to six different identified hands in full accordance with expert epigraphists' opinions.	[Panagopoulos, Michail; Papaodysseus, Constantin; Rousopoulos, Panayiotis; Dafi, Dimitra] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece; [Tracy, Stephen] Sch Hist Studies, Inst Adv Study, Princeton, NJ 08540 USA	National Technical University of Athens; Institute for Advanced Study - USA	Panagopoulos, M (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, 9 Heroon Polytechneiou, GR-15773 Athens, Greece.	mpanagop@hotmail.com; panrous@mail.ntua.gr; simitra7@hol.gr; stracy@ias.edu	Papaodysseus, Constantin/AAI-6900-2020	Papaodysseus, Constantin/0000-0002-5238-5833; Panagopoulos, Michail/0000-0003-4585-8185				Bensefia A, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P196, DOI 10.1109/IWFHR.2004.49; Bensefia A, 2005, PATTERN RECOGN LETT, V26, P2080, DOI 10.1016/j.patrec.2005.03.024; Bulacu M, 2007, IEEE T PATTERN ANAL, V29, P701, DOI 10.1109/TPAMI.2007.1009; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; Cha S.-H., 2000, P 7 INT WORKSH FRONT, P333; He Z., 2005, P 8 INT C DOC AN REC; HOMMEL G, 1989, BIOMETRIKA, V76, P624, DOI 10.1093/biomet/76.3.624; Marti UV, 2001, PROC INT CONF DOC, P101, DOI 10.1109/ICDAR.2001.953763; PANAGOPOULOS T, 2004, WSEAS T ELECT, V1, P108; Papaodysseus C, 2002, IEEE T SIGNAL PROCES, V50, P1277, DOI 10.1109/TSP.2002.1003053; Pervouchine V., 2007, PATTERN RECOGNITION, V40; Roman-Roldan R, 2001, PATTERN RECOGN, V34, P969, DOI 10.1016/S0031-3203(00)00052-2; Said HES, 2000, PATTERN RECOGN, V33, P149, DOI 10.1016/S0031-3203(99)00006-0; Schlapbach A, 2007, PATTERN ANAL APPL, V10, P33, DOI 10.1007/s10044-006-0047-5; Schomaker L, 2004, IEEE T PATTERN ANAL, V26, P787, DOI 10.1109/TPAMI.2004.18; TRACY SV, 2003, ATTIC LETT CUTTERS 3; Zhang B., 2003, P 7 INT C DOC AN REC; Zois EN, 2000, PATTERN RECOGN, V33, P385, DOI 10.1016/S0031-3203(99)00063-1	18	27	27	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1404	1414		10.1109/TPAMI.2008.201	http://dx.doi.org/10.1109/TPAMI.2008.201			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Engineering	458UN	19542575				2022-12-18	WOS:000267050600005
J	Munsell, BC; Dalal, P; Wang, S				Munsell, Brent C.; Dalal, Pahal; Wang, Song			Evaluating shape correspondence for statistical shape analysis: A benchmark study	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical shape analysis; shape correspondence; point distribution model; benchmark study	ALGORITHM	This paper introduces a new benchmark study to evaluate the performance of landmark-based shape correspondence used for statistical shape analysis. Different from previous shape-correspondence evaluation methods, the proposed benchmark first generates a large set of synthetic shape instances by randomly sampling a given statistical shape model that defines a ground-truth shape space. We then run a test shape-correspondence algorithm on these synthetic shape instances to identify a set of corresponded landmarks. According to the identified corresponded landmarks, we construct a new statistical shape model which defines a new shape space. We finally compare this new shape space against the ground-truth shape space to determine the performance of the test shape-correspondence algorithm. In this paper, we introduce three new performance measures that are landmark independent to quantify the difference between the ground-truth and the newly derived shape spaces. By introducing a ground-truth shape space that is defined by a statistical shape model and three new landmark-independent performance measures, we believe the proposed benchmark allows for a more objective evaluation of shape correspondence than previous methods. In this paper, we focus on developing the proposed benchmark for 2D shape correspondence. However, it can easily be extended to 3D cases.	[Munsell, Brent C.; Dalal, Pahal; Wang, Song] Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA	University of South Carolina; University of South Carolina System; University of South Carolina Columbia	Munsell, BC (corresponding author), Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.	munsell@engr.sc.edu; dalalpk@engr.sc.edu; songwang@engr.sc.edu		Wang, Song/0000-0003-4152-5295	AFOSR FA9550-07-1-0250;  [NSF-EIA-0312861]	AFOSR FA9550-07-1-0250(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); 	This work was funded, in part, by NSF-EIA-0312861 and AFOSR FA9550-07-1-0250. The authors thank T. Thodberg for providing the package of T-MDL, A. Ericsson for providing the packages of E-MDL, E-MDL+CUR, and EUC, and T. Richardson for providing the package of SDI. They thank A. Goldberg and R. Kennedy for providing the bipartite-matching software package. They would like to thank Eva Czabarka and Jijun Tang for their invaluable suggestions. Some preliminary results of this paper were published in a conference proceeding [17].	Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bookstein F L, 1997, Med Image Anal, V1, P225; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Catmull Edwin, 1974, COMPUT AIDED GEOM D, P317, DOI 10.1016/B978-0-12-079050-0.50020-5; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; David S, 2002, J SUSTAIN AGR, V21, P5, DOI 10.1300/J064v21n02_03; Davies R., 2002, THESIS U MANCHESTER; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; Goldberg AV, 1995, MATH PROGRAM, V71, P153, DOI 10.1007/BF01585996; Gower J. C., 2004, PROCRUSTES PROBLEMS; LEVENTON ME, 2000, PROC CVPR IEEE, P316, DOI DOI 10.1109/CVPR.2000.855835; Wang S, 2004, PROC CVPR IEEE, P143; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	24	27	28	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					2023	2039		10.1109/TPAMI.2007.70841	http://dx.doi.org/10.1109/TPAMI.2007.70841			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787249	Green Published			2022-12-18	WOS:000259110000014
J	Cao, LL; Liu, JZ; Tang, XO				Cao, Liangliang; Liu, Jianzhuang; Tang, Xiaoou			What the back of the object looks like: 3D reconstruction from line drawings without hidden lines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; hidden topology; line drawings; visual perception	SHAPE; FACES; IDENTIFICATION; POLYHEDRA; SOLIDS	The human vision system can interpret a single 2D line drawing as a 3D object without much difficulty even if the hidden lines of the object are invisible. Many reconstruction methods have been proposed to emulate this ability, but they cannot recover the complete object if the hidden lines of the object are not shown. This paper proposes a novel approach to reconstructing a complete 3D object, including the shape of the back of the object, from a line drawing without hidden lines. First, we develop theoretical constraints and an algorithm for the inference of the topology of the invisible edges and vertices of an object. Then, we present a reconstruction method based on perceptual symmetry and planarity of the object. We show a number of examples to demonstrate the success of our approach.	[Cao, Liangliang] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA; [Liu, Jianzhuang; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China	University of Illinois System; University of Illinois Urbana-Champaign; Chinese University of Hong Kong	Cao, LL (corresponding author), Univ Illinois, Dept Elect & Comp Engn, 1406 W Green St, Urbana, IL 61801 USA.	cao4@uiuc.edu; jzliu@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012					Ablameyko S, 1999, COMPUT CONTROL ENG J, V10, P277, DOI 10.1049/cce:19990606; Bagali S., 1995, Proceedings. Third Symposium on Solid Modeling and Applications, P339, DOI 10.1145/218013.218083; BAIRD L, 1995, INT J MATH IMAGING V, V5, P111; BERGER M, 1977, GEOMETRIE; CAO L, 2005, THESIS CHINESE U HON; Cao LL, 2005, IEEE I CONF COMP VIS, P272; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; Cooper MC, 2001, INT J COMPUT VISION, V43, P75, DOI 10.1023/A:1011166601983; COOPER MC, 1993, IMAGE VISION COMPUT, V11, P82, DOI 10.1016/0262-8856(93)90074-Q; de Berg M., 2000, COMPUTATIONAL GEOMET, P307, DOI DOI 10.1007/978-3-662-04245-8; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Dori D, 1999, IEEE T SYST MAN CY A, V29, P411, DOI 10.1109/3468.769761; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; Koffka K., 1963, PRINCIPLES GESTALT P, V2nd; Kuo MH, 1998, COMPUT AIDED DESIGN, V30, P517, DOI 10.1016/S0010-4485(98)00006-2; LECLERC YG, 1992, INT J COMPUT VISION, V9, P113, DOI 10.1007/BF00129683; LEQUETTE R, 1988, COMPUT AIDED DESIGN, V20, P171, DOI 10.1016/0010-4485(88)90273-4; Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X; Liu JZ, 2005, IEEE T PATTERN ANAL, V27, P861, DOI 10.1109/TPAMI.2005.119; Liu JZ, 2002, IEEE T PATTERN ANAL, V24, P1579, DOI 10.1109/TPAMI.2002.1114850; Liu JZ, 2001, IEEE T PATTERN ANAL, V23, P1106; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; Marefat MM, 1997, IEEE T SYST MAN CY A, V27, P705, DOI 10.1109/3468.634635; MARILL T, 1991, INT J COMPUT VISION, V6, P147, DOI 10.1007/BF00128154; Ortiz S, 2004, COMPUTER, V37, P24, DOI 10.1109/MC.2004.72; Palmer S.E., 1999, VISION SCI PHOTONS P; Ros L, 2005, J MATH IMAGING VIS, V22, P5, DOI 10.1007/s10851-005-4779-4; Ros L, 2002, IEEE T PATTERN ANAL, V24, P456, DOI 10.1109/34.993554; Shapiro LG, 2001, COMPUTER VISION; Shesh A, 2004, COMPUT GRAPH FORUM, V23, P301, DOI 10.1111/j.1467-8659.2004.00761.x; Shimodaira H, 2006, IEEE T PATTERN ANAL, V28, P612, DOI 10.1109/TPAMI.2006.67; Shimshoni I, 1997, COMPUT VIS IMAGE UND, V65, P296, DOI 10.1006/cviu.1996.0569; Shoji K, 2001, PROC CVPR IEEE, P90; Shpitalni M, 1996, IEEE T PATTERN ANAL, V18, P1000, DOI 10.1109/34.541409; STURM P, 1999, P BRIT MACH VIS C, P265; SUGIHARA K, 1984, ARTIF INTELL, V23, P59, DOI 10.1016/0004-3702(84)90005-5; SUGIHARA K, 1984, IEEE T PATTERN ANAL, V6, P578, DOI 10.1109/TPAMI.1984.4767571; SUGIHARA K, 1982, IEEE T PATTERN ANAL, V4, P458, DOI 10.1109/TPAMI.1982.4767289; Syeda-Mahmood T, 1999, IEEE T PATTERN ANAL, V21, P737, DOI 10.1109/34.784287; Turner A, 2000, COMPUT GRAPH-UK, V24, P869, DOI 10.1016/S0097-8493(00)00089-3; VARLEY PAC, 2000, P 1 KOR UK JOINT WOR, P129; VARLEY PAC, 2002, P 7 ACM S SOL MOD AP, P180; West DB., 2002, INTRO GRAPH THEORY, V2; WHITELEY W, 1989, DISCRETE COMPUT GEOM, V4, P75, DOI 10.1007/BF02187716; WHITELEY W, 1991, DISCRETE APPL MATH, V32, P275, DOI 10.1016/0166-218X(91)90004-G; Yu M, 2003, PROC CVPR IEEE, P656; [No title captured]	48	27	31	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					507	517		10.1109/TPAMI.2007.1185	http://dx.doi.org/10.1109/TPAMI.2007.1185			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195443	Green Submitted			2022-12-18	WOS:000252286100011
J	Chainais, P				Chainais, Pierre			Infinitely divisible cascades to model the statistics of natural images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stochastic processes; picture/image generation; fractals; image processing and computer vision; statistical; image models	FULLY-DEVELOPED TURBULENCE; MULTIFRACTAL FORMALISM; INTERMITTENCY; MARTINGALES; FLOW	We propose to model the statistics of natural images, thanks to the large class of stochastic processes called Infinitely Divisible Cascades ( IDCs). IDCs were first introduced in one dimension to provide multifractal time series to model the so- called intermittency phenomenon in hydrodynamical turbulence. We have extended the definition of scalar IDCs from one to N dimensions and commented on the relevance of such a model in fully developed turbulence in [ 1]. In this paper, we focus on the particular 2D case. IDCs appear as good candidates to model the statistics of natural images. They share most of their usual properties and appear to be consistent with several independent theoretical and experimental approaches of the literature. We point out the interest of IDCs for applications to procedural texture synthesis.	Univ Blaise Pascal Clermont Ferrand II, CNRS, UMR, LIMOS, F-63173 Aubiere, France	Centre National de la Recherche Scientifique (CNRS); Universite Clermont Auvergne (UCA)	Chainais, P (corresponding author), Univ Blaise Pascal Clermont Ferrand II, CNRS, UMR, LIMOS, F-63173 Aubiere, France.	pchainai@isima.fr		Chainais, Pierre/0000-0003-4377-7584				ALVAREZ L, 1999, SIZE OBJECTS NATURAL, V111; Arneodo A, 1998, PHYS REV LETT, V80, P708, DOI 10.1103/PhysRevLett.80.708; Arneodo A, 1996, EUROPHYS LETT, V34, P411, DOI 10.1209/epl/i1996-00472-2; Arneodo A, 1998, J MATH PHYS, V39, P4142, DOI 10.1063/1.532489; Arneodo A, 1997, J PHYS II, V7, P363, DOI 10.1051/jp2:1997130; Arneodo A., 1995, ONDELETTES MULTIFRAC; Ayache A, 2002, POTENTIAL ANAL, V17, P31, DOI 10.1023/A:1015260803576; Bacry E, 2003, COMMUN MATH PHYS, V236, P449, DOI 10.1007/s00220-003-0827-3; Bacry E, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.026103; Barral J, 2002, PROBAB THEORY REL, V124, P409, DOI 10.1007/s004400200220; BIERME H, 2005, THESIS ORLENAS U; Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P1; Burd GA, 2000, P AM MATH SOC, V128, P2753, DOI 10.1090/S0002-9939-00-05279-5; Castaing B, 1996, J PHYS II, V6, P105, DOI 10.1051/jp2:1996172; CASTAING B, 1995, J PHYS II, V5, P895, DOI 10.1051/jp2:1995107; Chainais P, 2006, EUR PHYS J B, V51, P229, DOI 10.1140/epjb/e2006-00213-y; Chainais P, 1999, PHYS FLUIDS, V11, P3524, DOI 10.1063/1.870210; Chainais P, 2005, IEEE T INFORM THEORY, V51, P1063, DOI 10.1109/TIT.2004.842570; Chainais P., 2005, P IEEE INT C IM PROC; CHAINAIS P, 2005, P 20 C GROUP REC ET; CHAINAIS P, 2005, TRAITEMENT SIGNAL, V22; CHAINAIS P, 2001, THESIS ENS LYON; CHAINAIS P, 2003, P INT S PHYS SIGN IM; CHI Z, 1998, THESIS BROWN U, pCH7; DEGUY S, 2001, VISION MODELLING VIS; DERUIGIN N, 1956, TELECOMM, V1, P1; Fadili MM, 2005, IEEE T IMAGE PROCESS, V14, P231, DOI 10.1109/TIP.2004.840704; Feller V, 1984, INTRO PROBABILITY TH; Field D.J., 1993, WAVELETS FRACTALS FO; FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Frisch U, 1985, TURBULENCE PREDICTAB, P84; Frisch U., 1995, TURBULENCE LEGACY A; GALLAGHER C, 2005, P IEEE INT C IM PROC; GEUSEBROEK JN, 2005, P 5 INT C SCAL SPAC, P327; GEUSEBROEK JN, 2003, P 3 INT WORKSH TEXT, P37; Gonzalez R.C, 2002, DIGITAL IMAGE PROCES; GOUSSEAU Y, SIAM J MULTISCALE MO; Grenander U, 2001, IEEE T PATTERN ANAL, V23, P424, DOI 10.1109/34.917579; Heeger D. J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P229, DOI 10.1145/218380.218446; Huang J G, 1999, P 1999 IEEE COMP VIS, P541; Jaffard S, 1997, SIAM J MATH ANAL, V28, P944, DOI 10.1137/S0036141095282991; KAHANE JP, 1976, ADV MATH, V22, P131, DOI 10.1016/0001-8708(76)90151-1; KAHANE JP, 1987, CHINESE ANN MATH B, V8, P1; Lashermes B., 2004, INT J WAVELETS MULTI, V2, P497, DOI [10.1142/s0219691304000597, DOI 10.1142/S0219691304000597]; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; MANDELBROT B, 1974, CR ACAD SCI A MATH, V278, P355; MANDELBROT BB, 1974, J FLUID MECH, V62, P331, DOI 10.1017/S0022112074000711; MANDELBROT BB, 1968, SIAM REV, V10, P422, DOI 10.1137/1010093; Mandelbrot BB, 1983, FRACTAL GEOMETRY NAT; Mumford D, 2001, Q APPL MATH, V59, P85, DOI 10.1090/qam/1811096; MUZY JF, 1994, INT J BIFURCAT CHAOS, V4, P245, DOI 10.1142/S0218127494000204; Muzy JF, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.056121; Naert A, 1997, PHYS REV E, V56, P6719, DOI 10.1103/PhysRevE.56.6719; Novikov E. A., 1971, Prikladnaya Matematika i Mekhanika, V35, P266; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; RAJPUT BS, 1989, PROBAB THEORY REL, V82, P451, DOI 10.1007/BF00339998; Riedi RH, 2003, THEORY AND APPLICATIONS OF LONG-RANGE DEPENDENCE, P625; Roux SG, 2000, EUR PHYS J B, V15, P765, DOI 10.1007/s100510051180; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006; Ruderman DL, 1997, VISION RES, V37, P3385, DOI 10.1016/S0042-6989(97)00008-4; SCHERTZER D, 1987, J GEOPHYS RES-ATMOS, V92, P9693, DOI 10.1029/JD092iD08p09693; Schmitt F, 2001, EUR PHYS J B, V20, P3; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; Srivastava A, 2002, IEEE T PATTERN ANAL, V24, P1200, DOI 10.1109/TPAMI.2002.1033212; Turiel A, 1998, PHYS REV LETT, V80, P1098, DOI 10.1103/PhysRevLett.80.1098; Turiel A, 2000, NEURAL COMPUT, V12, P763, DOI 10.1162/089976600300015583; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303; VEITCH D, 2000, P IEEE INT C AC SPEE; Wainwright MJ, 2001, APPL COMPUT HARMON A, V11, P89, DOI 10.1006/acha.2000.0350; Wainwright MJ, 2000, ADV NEUR IN, V12, P855; Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009; [No title captured]	75	27	28	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2105	2119		10.1109/TPAMI.2007.1113	http://dx.doi.org/10.1109/TPAMI.2007.1113			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934221				2022-12-18	WOS:000250087900004
J	Rothganger, F; Lazebnik, S; Schmid, C; Ponce, J				Rothganger, Fred; Lazebnik, Svetlana; Schmid, Cordelia; Ponce, Jean			Segmenting, modeling, and matching video clips containing multiple moving objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						affine-covariant patches; structure from motion; motion segmentation; shot matching; video retrieval	SHAPE; MOTION	This paper presents a novel representation for dynamic scenes composed of multiple rigid objects that may undergo different motions and are observed by a moving camera. Multiview constraints associated with groups of affine-covariant scene patches and a normalized description of their appearance are used to segment a scene into its rigid components, construct three-dimensional models of these components, and match instances of models recovered from different image sequences. The proposed approach has been applied to the detection and matching of moving objects in video sequences and to shot matching, i.e., the identification of shots that depict the same scene in a video clip.	Sandia Natl Labs, Albuquerque, NM 87123 USA; Beckman Inst, Urbana, IL 61801 USA; INRIA Rhone Alpes, F-38330 Montbonnot St Martin, France; Ecole Normale Super, Dept Informat, F-75230 Paris 05, France; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	United States Department of Energy (DOE); Sandia National Laboratories; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); University of Illinois System; University of Illinois Urbana-Champaign	Rothganger, F (corresponding author), Sandia Natl Labs, 1515 Eubank SE, Albuquerque, NM 87123 USA.	fred@rothganger.org; slazebni@uiuc.edu; Cordelia.Schmid@inrialpes.fr; ponce@di.ens.fr						Aner A, 2002, LECT NOTES COMPUT SC, V2353, P388; Ardebilian M, 1996, P SOC PHOTO-OPT INS, V2916, P236, DOI 10.1117/12.257293; Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899; BEARDSLEY P, 1996, P EUR C COMP VIS; BENAYOUN S, 1998, P COMPRESSION RESENT; Birchfield S., 1998, KLT IMPLEMENTATION K; Boult T. E., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P179, DOI 10.1109/WVM.1991.212809; CARSON C, 1999, P 3 INT C VIS INF SY; Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507; COSTEIRA J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1071, DOI 10.1109/ICCV.1995.466815; DAVENPORT G, 1991, IEEE COMPUT GRAPH, V11, P67, DOI 10.1109/38.126883; FABLET R, 1999, P 10 DELOS WORKSH AU; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FITZGIBBON A, 2002, P EUR C COMP VIS; FITZGIBBON A, 1998, P EUR SIGN PROC C; Fitzgibbon AW, 2000, LECT NOTES COMPUT SC, V1842, P891; FLICKNER M, 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146; GARDING J, 1992, J MATH IMAGING VIS, V2, P329; Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; GUPTA UI, 1982, NETWORKS, V12, P459, DOI 10.1002/net.3230120410; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; LEE H, 2001, P INT WORKSH IM AN M; LIENHART R, 2001, INT J IMAGE GRAP AUG; Lindeberg T, 1994, P 3 EUR C COMP VIS, P389; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lowe DG, 2001, PROC CVPR IEEE, P682; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121; Mahamud S, 2001, PROC CVPR IEEE, P1018; Malik J, 1997, INT J COMPUT VISION, V23, P149, DOI 10.1023/A:1007958829620; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561; MIKOLAJCZYK K, 2002, P ECCV, V1, P128; Mikolajczyk K., 2005, INT J COMPUTER VISIO, V65; NGO CW, 2001, INT J IMAGE GRAPHICS, V3, P445; Nister D., 2001, THESIS ROYAL I TECHN; Pollefeys M., 2001, P C OPT 3 D MEAS TEC, P251; PONCE J, 2000, P 2 SMILE WORKSH, P18; Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802; Rothganger F, 2004, PROC CVPR IEEE, P914; Rothganger Fred, 2006, INT J COMPUTER VISIO, V66, P1; Schaffalitzky F., 2002, P CHALLENGE IMAGE VI; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Shi J., 1994, P C COMP VIS PATT RE; Sivic J., 2003, P INT C COMP VIS; Sivic Josef, 2004, P EUR C COMP VIS; TAN YP, 1999, P IEEE INT C IM PROC; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tomasi C, 1991, CMUCS91132; Torr P.H.S., 1995, THESIS U OXFORD; TORR PHS, 1993, P SOC PHOTO-OPT INS, V2059, P432, DOI 10.1117/12.150246; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; VIDAL R, 2003, P C COMP VIS PATT RE; WEINSHALL D, 1995, IEEE T PATTERN ANAL, V17, P512, DOI 10.1109/34.391392; Yeung MM, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA338; ZISSERMAN A, 1999, P IEEE INT C MULT SY	63	27	29	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2007	29	3					477	491		10.1109/TPAMI.2007.57	http://dx.doi.org/10.1109/TPAMI.2007.57			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	125CY	17224617	Green Submitted			2022-12-18	WOS:000243420500009
J	Ding, XQ; Chen, L; Wu, T				Ding, Xiaoqing; Chen, Li; Wu, Tao			Character independent font recognition on a single Chinese character	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						font recognition; character independent; single character; wavelet features; LDA; MQDF		A novel algorithm for font recognition on a single unknown Chinese character, independent of the identity of the character, is proposed in this paper. We employ a wavelet transform on the character image and extract wavelet features from the transformed image. After a Box-Cox transformation and LDA (Linear Discriminant Analysis) process, the discriminating features for font recognition are extracted and classified through a MQDF (Modified Quadric Distance Function) classifier with only one prototype for each font class. Our experiments show that our algorithm can achieve a recognition rate of 90.28 percent on a single unknown character and 99.01 percent if five characters are used for font recognition. Compared with existing methods, all of which are based on a text block, our method can provide a higher recognition rate and is more flexible and robust, since it is based on a single unknown character. Additionally, our method demonstrates that it is possible to extract subtle yet discriminative signals embedded in a much larger noisy background.	Tsing Hua Univ, Elect Engn Dept, Beijing, Peoples R China; Huawei Corp, Shanghai 201206, Peoples R China; Tsing Hua Univ, Elect Engn Dept, Beijing 100084, Peoples R China	Tsinghua University; Huawei Technologies; Tsinghua University	Ding, XQ (corresponding author), Tsing Hua Univ, Elect Engn Dept, Beijing, Peoples R China.	dingxq@tsinghua.edu.cn; chenli@tsinghua.org.cn; wutao@ocrserv.ee.tsinghua.edu.cn						Castleman K.R., 1996, DIGITAL IMAGE PROCES; CHEN L, 2004, P 17 INT C PATT REC, V1, P413; CHEN L, 2003, P IS T SPIE DOC REC; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; JUNG MC, 1999, P INT C DOC AN REC B, P353; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; RAHMAN AFR, 2002, P 5 INT WORKSH DOC A; SAKIA RM, 1992, J ROY STAT SOC D-STA, V41, P169, DOI 10.2307/2348250; Shi HW, 1997, PROC INT CONF DOC, P39, DOI 10.1109/ICDAR.1997.619810; Zhu Y, 2001, IEEE T PATTERN ANAL, V23, P1192, DOI 10.1109/34.954608; Zramdini A, 1998, IEEE T PATTERN ANAL, V20, P877, DOI 10.1109/34.709616	12	27	30	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					195	204		10.1109/TPAMI.2007.26	http://dx.doi.org/10.1109/TPAMI.2007.26			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV	17170474				2022-12-18	WOS:000242826900002
J	Chiu, YH; Wu, CH; Su, HY; Cheng, CJ				Chiu, Yu-Hsien; Wu, Chung-Hsien; Su, Hung-Yu; Cheng, Chih-Jen			Joint optimization of word alignment and epenthesis generation for Chinese to Taiwanese sign synthesis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Taiwanese sign language; language translation; sign language synthesis; video concatenation	RECOGNITION; MODEL	This work proposes a novel approach to translate Chinese to Taiwanese sign language and to synthesize sign videos. An aligned bilingual corpus of Chinese and Taiwanese Sign Language (TSL) with linguistic and signing information is also presented for sign language translation. A two-pass alignment in syntax level and phrase level is developed to obtain the optimal alignment between Chinese sentences and Taiwanese sign sequences. For sign video synthesis, a scoring function is presented to develop motion transition-balanced sign videos with rich combinations of intersign transitions. Finally, the maximum a posteriori ( MAP) algorithm is employed for sign video synthesis based on joint optimization of two-pass word alignment and intersign epenthesis generation. Several experiments are conducted in an educational environment to evaluate the performance on the comprehension of sign expression. The proposed approach outperforms the IBM Model 2 in sign language translation. Moreover, deaf students perceived sign videos generated by the proposed method to be satisfactory.	Ind Technol Res Inst, Home Network Technol Ctr, Tainan 709, Taiwan; Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan	Industrial Technology Research Institute - Taiwan; National Cheng Kung University	Chiu, YH (corresponding author), Ind Technol Res Inst, Home Network Technol Ctr, N200,ITRI Bldg R1,31,Gongye 2nd Rd,Annan Dist, Tainan 709, Taiwan.	chiuyh@itri.org.tw; chwu@csie.ncku.edu.tw; elfsu@csie.ncku.edu.tw; chengc@csie.ncku.edu.tw	Wu, Chung-Hsien/E-7970-2013					ALONSO F, 1995, IEEE MULTIMEDIA, V2, P55, DOI 10.1109/93.482296; ARIKAN O, 2002, P 29 ANN C COMP GRAP, P483; Bregler C., 2007, P ACM SIGGRAPH, P353; BROWN C, 1992, COMMUN ACM, V35, P36, DOI 10.1145/129875.129877; Brown P. F., 1993, Computational Linguistics, V19, P263; CAO Y, 2004, P ACM SIGGRAPH EUR S, P347; Chen YQ, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P236; Chou W, 2003, PATTERN RECOGNITION IN SPEECH AND LANGUAGE PROCESSING, P1; *CKIP, 1993, 9305 CKIP I INF SCI; Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594; GRIEVESMITH AB, 2001, P GEST WORKSH, P134; HOLDEN EJ, 2005, P 8 INT S SIGN PROC, V1, P54; *I LING NAT CHUNG, 2003, P INT S TAIW SIGN LA; IRVING A, 2005, P 7 INT ACM SIGACCES, P212; KENNAWAY R, 2001, P 4 INT WORKSH GEST; Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605; Krapez S., 1999, Elektrotehniski Vestnik, V66, P260; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Lee M, 2002, ENERG ECON, V24, P491, DOI 10.1016/S0140-9883(02)00011-7; Li Y, 2002, ACM T GRAPHIC, V21, P465; LIANG R, 1997, THESIS NATL TAIWAN U; LLOYD LL, 1997, AUGMETATIVE ALTERNAT; Manning CD, 1999, FDN STAT NATURAL LAN; *MIN ED, 2000, DIV SPEC ED CHANGY C, V1; Ney H, 2000, IEEE T SPEECH AUDI P, V8, P24, DOI 10.1109/89.817451; Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112; Proctor DM, 2004, J OCCUP ENVIRON HYG, V1, P752, DOI 10.1080/15459620490523294; Shott S., 1990, STAT HLTH PROFESSION; Speers d A.L., 2001, THESIS GEORGETOWN U; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; SU MC, 2001, IEEE T NEURAL SYSTEM, V9; Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895; Vogler C, 1999, LECT NOTES ARTIF INT, V1739, P211; WILCOX S, 1997, LEARNING SEE; Wu CH, 2004, IEEE T NEUR SYS REH, V12, P441, DOI 10.1109/TNSRE.2003.819930; Wu CH, 2004, IEEE T PATTERN ANAL, V26, P495, DOI 10.1109/TPAMI.2004.1265864	36	27	27	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					28	39		10.1109/TPAMI.2007.250597	http://dx.doi.org/10.1109/TPAMI.2007.250597			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108381				2022-12-18	WOS:000241988300003
J	Chen, H; Zhu, SC				Chen, H; Zhu, SC			A generative sketch model for human hair analysis and synthesis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hair modeling; hair analysis and synthesis; flow patterns; generative models; orientation field; texture; nonphotorealistic rendering	RESTORATION; FIELDS	In this paper, we present a generative sketch model for human hair analysis and synthesis. We treat hair images as 2D piecewise smooth vector (flow) fields and, thus, our representation is view-based in contrast to the physically-based 3D hair models in graphics. The generative model has three levels. The bottom level is the high-frequency band of the hair image. The middle level is a piecewise smooth vector field for the hair orientation, gradient strength, and growth directions. The top level is an attribute sketch graph for representing the discontinuities in the vector field. A sketch graph typically has a number of sketch curves which are divided into 11 types of directed primitives. Each primitive is a small window (say 5 x 7 pixels) where the orientations and growth directions are defined in parametric forms, for example, hair boundaries, occluding lines between hair strands, dividing lines on top of the hair, etc. In addition to the three level representation, we model the shading effects, i.e., the low-frequency band of the hair image, by a linear superposition of some Gaussian image bases and we encode the hair color by a color map. The inference algorithm is divided into two stages: 1) We compute the undirected orientation field and sketch graph from an input image and 2) we compute the hair growth direction for the sketch curves and the orientation field using a Swendsen-Wang cut algorithm. Both steps maximize a joint Bayesian posterior probability. The generative model provides a straightforward way for synthesizing realistic hair images and stylistic drawings (rendering) from a sketch graph and a few Gaussian bases. The latter can be either inferred from a real hair image or input (edited) manually using a simple sketching interface. We test our algorithm on a large data set of hair images with diverse hair styles. Analysis, synthesis, and rendering results are reported in the experiments.	Univ Calif Los Angeles, Dept Comp Sci & Stat, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles	Chen, H (corresponding author), Univ Calif Los Angeles, Dept Comp Sci & Stat, 8125 Math Sci Bldg,Box 951554, Los Angeles, CA 90095 USA.	hchen@stat.ucla.edu; sczhu@stat.ucla.edu			NATIONAL EYE INSTITUTE [R01EY013875] Funding Source: NIH RePORTER; NEI NIH HHS [5R01-EY013875] Funding Source: Medline	NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NEI NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI))		Barbu A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P320; BERGEN JR, 1991, SPATIAL VISION; Cabral B., 1993, P 20 ANN C COMP GRAP, P263, DOI DOI 10.1145/166117.166151>; Chan T, 2000, SIAM J APPL MATH, V61, P1338, DOI 10.1137/S003613999935799X; CHANG JT, 2002, P SIGGR EUR S COMP A; Chen H., 2004, P INT S NONPH AN REN, P95, DOI DOI 10.1145/987; DALDEGAN A, 1993, P EUR 93 JUL, P211; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GUO C, 2003, P INT C COMP VIS; HADAP S, 2000, P EUR WORKSH COMP AN; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; KIM TY, 2002, P SIGGRAPH; Lee DW, 2001, GRAPH MODELS, V63, P67, DOI 10.1006/gmod.2001.0547; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Nitzberg M., 1993, LECT NOTES COMPUTER, V662; PARIS S, 2004, P SIGGRAPH; Perez P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P524, DOI 10.1109/ICCV.2001.937670; Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195; RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908; TU ZW, 2002, P EUR C COMP VIS JUN; WEI Y, 2005, P SIGGRAPH; WU YN, 2004, 48 U CAL DEP STAT; XU ZJ, 2005, P C COMP VIS PATT RE; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627; ZUCKER SW, 1985, COMPUT VISION GRAPH, V32, P74, DOI 10.1016/0734-189X(85)90003-9	26	27	42	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2006	28	7					1025	1040		10.1109/TPAMI.2006.131	http://dx.doi.org/10.1109/TPAMI.2006.131			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	041AG	16792093	Green Submitted			2022-12-18	WOS:000237424400001
J	El Rube, I; Ahmed, M; Kamel, M				El Rube, I; Ahmed, M; Kamel, M			Wavelet approximation-based affine invariant shape representation functions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						wavelet transform; shape representation; affine transformation; invariants	OBJECT RECOGNITION; DESCRIPTORS; RETRIEVAL; TRANSFORM	In this paper, new wavelet-based affine invariant functions for shape representation are presented. Unlike the previous representation functions, only the approximation coefficients are used to obtain the proposed functions. One of the derived functions is computed by applying a single wavelet transform; the other function is calculated by applying two different wavelet transforms with two different wavelet families. One drawback of the previously derived detail-based invariant representation functions is that they are sensitive to noise at the finer scale levels, which limits the number of scale levels that can be used. The experimental results in this paper demonstrate that the proposed functions are more stable and less sensitive to noise than the detail-based functions.	Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada; Wilfrid Laurier Univ, Phys & Comp Sci Dept, Waterloo, ON N2L 3C5, Canada; Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada	University of Waterloo; Wilfrid Laurier University; University of Waterloo	El Rube, I (corresponding author), Univ Waterloo, Dept Syst Design Engn, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.	ibrahim@pami.uwaterloo.ca; mahmed@wlu.ca; mkamel@pami.uwaterloo.ca	El rube', Ibrahim/Q-3843-2017; Kamel, Mohamed S/D-9323-2011	El rube', Ibrahim/0000-0001-8471-1341; Kamel, Mohamed/0000-0001-6173-8082				Abbasi S, 2001, IEEE T IMAGE PROCESS, V10, P131, DOI 10.1109/83.892449; Alferez R, 1999, IEEE T PATTERN ANAL, V21, P505, DOI 10.1109/34.771318; [Anonymous], 2001, SHAPE ANAL CLASSIFIC; Bala E, 2004, IEEE T PATTERN ANAL, V26, P1095, DOI 10.1109/TPAMI.2004.39; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426; Brooks RR, 2001, J ELECTRON IMAGING, V10, P757, DOI 10.1117/1.1381560; Bui TD, 1997, P SOC PHOTO-OPT INS, V3078, P552, DOI 10.1117/12.271746; CHAUANG G, 1996, IEEE T IMAGE PROCESS, V5, P56; Chen YX, 2002, IEEE T PATTERN ANAL, V24, P1252, DOI 10.1109/TPAMI.2002.1033216; Chui C.K., 1992, INTRO WAVELETS, V1; Feng L, 2001, INT J PATTERN RECOGN, V15, P329, DOI 10.1142/S0218001401000873; Kashi RS, 1996, SIMULATION, V66, P164, DOI 10.1177/003754979606600303; Khalifa E, 2000, DEV ARID REG RES SER, V1, P421; Khalil MI, 2002, PATTERN RECOGN LETT, V23, P57, DOI 10.1016/S0167-8655(01)00102-7; Khalil MI, 2001, IEEE T PATTERN ANAL, V23, P1152, DOI 10.1109/34.954605; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Mallat S., 1999, WAVELET TOUR SIGNAL, DOI 10.1016/B978-012466606-1/50008-8; Mandal MK, 1998, J ELECTRON IMAGING, V7, P282, DOI 10.1117/1.482644; MARTINEZ J, 2003, ISOIECJTC1SC29WG11N5; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Mokhtarian F., 2003, CURVATURE SCALE SPAC; Petrakis EGM, 2002, IEEE T PATTERN ANAL, V24, P1501, DOI 10.1109/TPAMI.2002.1046166; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shen DG, 1999, PATTERN RECOGN, V32, P151, DOI 10.1016/S0031-3203(98)00137-X; Sonka M., 2014, IMAGE PROCESSING ANA; TANG Y, 2000, WAVELET THEORY ITS A, V36; TANG Y, 1997, SPIE SIGNAL PROCESSI, V3068, P102; TIENG Q, 1994, P IEEE INT C IM PROC, V1, P198; Tieng Q. M., 1994, Proceedings of the 1994 Second Australian and New Zealand Conference on Intelligent Information Systems (Cat. No.94TH8019), P307, DOI 10.1109/ANZIIS.1994.396971; Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P846, DOI 10.1109/34.608288; Tieng QM, 1995, PATTERN RECOGN LETT, V16, P1287, DOI 10.1016/0167-8655(95)00079-1; Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P910, DOI 10.1109/34.608294; Tsang KM, 2001, INT J PATTERN RECOGN, V15, P691, DOI 10.1142/S021800140100109X	35	27	27	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					323	327		10.1109/TPAMI.2006.43	http://dx.doi.org/10.1109/TPAMI.2006.43			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468627				2022-12-18	WOS:000233824500013
J	Nel, EM; du Preez, JA; Herbst, BM				Nel, EM; du Preez, JA; Herbst, BM			Estimating the pen trajectories of static signatures using hidden Markov models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; document and text processing; document analysis; handwriting analysis	ORDER; RECOGNITION; INFORMATION	Static signatures originate as handwritten images on documents and by definition do not contain any dynamic information. This lack of information makes static signature verification systems significantly less reliable than their dynamic counterparts. This study involves extracting dynamic information from static images, specifically the pen trajectory while the signature was created. We assume that a dynamic version of the static image is available (typically obtained during an earlier registration process). We then derive a hidden Markov model from the static image and match it to the dynamic version of the image. This match results in the estimated pen trajectory of the static image.	Univ Stellenbosch, Dept Elect & Elect Engn, ZA-7602 Matieland, South Africa; Univ Stellenbosch, Dept Appl Math, ZA-7602 Matieland, South Africa	Stellenbosch University; Stellenbosch University	Nel, EM (corresponding author), Univ Stellenbosch, Dept Elect & Elect Engn, Private Bag X1, ZA-7602 Matieland, South Africa.	emnel@dsp.sun.ac.za; dupreez@dsp.sun.ac.za; herbst@sun.ac.za		du Preez, Johan/0000-0001-6775-9220				Abou-Moustafa KT, 2004, PATTERN RECOGN LETT, V25, P923, DOI 10.1016/j.patrec.2004.02.005; Abuhaiba ISI, 1996, PATTERN RECOGN, V29, P1161, DOI 10.1016/0031-3203(95)00142-5; Al-Ohali Y, 2002, INT C PATT RECOG, P323, DOI 10.1109/ICPR.2002.1044705; ALOHALI Y, 2002, P 8 INT WORKSH FRONT; Bengio Y, 1995, J ARTIF INTELL RES, V3, P249, DOI 10.1613/jair.233; Bengio Y., 1999, Neural Computing Surveys, V2; BOCCIGNONE G, 1993, PATTERN RECOGN, V26, P409, DOI 10.1016/0031-3203(93)90168-V; Chang HH, 1999, IEEE T SYST MAN CY B, V29, P47, DOI 10.1109/3477.740165; De Berg Mark, 1997, COMPUTATIONAL GEOMET; DOLFING JGA, 1995, THESIS EINDHOVEN NET; du Preez JA, 1998, COMPUT SPEECH LANG, V12, P23, DOI 10.1006/csla.1997.0037; DUPREEZ JA, 1998, AUSTR J INTELLIGENT, V5, P261; DUPREEZ JA, 1997, THESIS STELLENBOSCH; Franti P, 2000, INT C PATT RECOG, P389, DOI 10.1109/ICPR.2000.902940; Gonzalez R.C., 2020, DIGITAL IMAGE PROCES; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; Govindaraju V, 1996, PATTERN RECOGN LETT, V17, P537, DOI 10.1016/0167-8655(95)00125-5; Guo JK, 2001, INT J PATTERN RECOGN, V15, P579, DOI 10.1142/S0218001401001088; HUANG T, 1995, P IEEE SYSTEMS MAN C, V3, P2789; Huang W., 1995, P INT C DOC AN REC, P861; Jager S, 1997, PROC INT CONF DOC, P528, DOI 10.1109/ICDAR.1997.620555; JAGER S, 1998, THESIS U FREIBURG; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Kapoor R, 2004, PATTERN RECOGN LETT, V25, P1215, DOI 10.1016/j.patrec.2004.03.020; Kato Y., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P261, DOI 10.1109/ICDAR.1999.791774; Kato Y, 2000, IEEE T PATTERN ANAL, V22, P938, DOI 10.1109/34.877517; Lallican PM, 1997, PROC INT CONF DOC, P519, DOI 10.1109/ICDAR.1997.620553; LALLICAN PM, 2000, P 7 INT WORKSH FRONT, P303; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; Lau KK, 2003, PROC INT CONF DOC, P1123; Lau KK, 2002, INT C PATT RECOG, P119, DOI 10.1109/ICPR.2002.1047809; LEE S, 1992, IEEE T SYST MAN CYB, V22, P755, DOI 10.1109/21.156588; Munich ME, 2003, IEEE T PATTERN ANAL, V25, P200, DOI 10.1109/TPAMI.2003.1177152; Peebles P.Z., 1993, PROBABILITY RANDOM V, V3rd ed; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Proakis J. G., 2000, DISCRETE TIME PROCES; Rocha J, 2003, IEEE T SYST MAN CY B, V33, P165, DOI 10.1109/TSMCB.2003.808189; Rosenthal AS, 1997, INT CONF ACOUST SPEE, P3077, DOI 10.1109/ICASSP.1997.595442; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; Seul M, 2000, PRACTICAL ALGORITHMS; Terrades OR, 2003, PROC INT CONF DOC, P195; Zou JJ, 2001, IEEE T SYST MAN CY B, V31, P401, DOI 10.1109/3477.931528	42	27	27	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1733	1746		10.1109/TPAMI.2005.221	http://dx.doi.org/10.1109/TPAMI.2005.221			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285373				2022-12-18	WOS:000231826300005
J	Veenman, CJ; Tax, DMJ				Veenman, CJ; Tax, DMJ			LESS: A model-based classifier for sparse subspaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; support vector machine; high-dimensional; feature subset selection; mathematical programming	GENE-EXPRESSION; FEATURE-SELECTION; CANCER; LASSO	In this paper, we specifically focus on high-dimensional data sets for which the number of dimensions is an order of magnitude higher than the number of objects. From a classifier design standpoint, such small sample size problems have some interesting challenges. The first challenge is to find, from all hyperplanes that separate the classes, a separating hyperplane which generalizes well for future data. A second important task is to determine which features are required to distinguish the classes. To attack these problems, we propose the LESS ( Lowest Error in a Sparse Subspace) classifier that efficiently finds linear discriminants in a sparse subspace. In contrast with most classifiers for high-dimensional data sets, the LESS classifier incorporates a (simple) data model. Further, by means of a regularization parameter, the classifier establishes a suitable trade-off between subspace sparseness and classification accuracy. In the experiments, we show how LESS performs on several high-dimensional data sets and compare its performance to related state-of-the-art classifiers like, among others, linear ridge regression with the LASSO and the Support Vector Machine. It turns out that LESS performs competitively while using fewer dimensions.	Delft Univ Technol, Fac Elect Engn, Dept Mediamat, NL-2600 GA Delft, Netherlands	Delft University of Technology	Veenman, CJ (corresponding author), Delft Univ Technol, Fac Elect Engn, Dept Mediamat, POB 5031, NL-2600 GA Delft, Netherlands.	C.J.Veenman@ewi.tudelft.nl; D.M.J.Tax@ewi.tudelft.nl						Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bhattacharyya C, 2003, SIGNAL PROCESS, V83, P729, DOI 10.1016/S0165-1684(02)00474-7; BRADLEY PS, 1998, P 15 INT C MACH LEAR, P82; Breiman L., 1993, BETTER SUBSET SELECT; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Debuse J. C. W., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V9, P57, DOI 10.1023/A:1008641220268; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; *FREE SOFTW FDN, 2005, GNLI LIN PROGR; FUNG G, 2000, P 6 ACM SIGKDD INT C, V2094, P64; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; Karzynski M, 2003, ARTIF INTELL REV, V20, P39, DOI 10.1023/A:1026032530166; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; Theodoridis S., 2008, PATTERN RECOGN; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V.N, 1998, STAT LEARNING THEORY; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	23	27	28	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1496	1500		10.1109/TPAMI.2005.182	http://dx.doi.org/10.1109/TPAMI.2005.182			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173192	Green Submitted			2022-12-18	WOS:000230463300012
J	Wang, YZ; Zhu, SC				Wang, YZ; Zhu, SC			Analysis and synthesis of textured motion: Particles and waves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						textured motion; generative model; texton; statistical learning; object tracking; stochastic gradient		Natural scenes contain a wide range of textured motion phenomena which are characterized by the movement of a large amount of particle and wave elements, such as falling snow, wavy water, and dancing grass. In this paper, we present a generative model for representing these motion patterns and study a Markov chain Monte Carlo algorithm for inferring the generative representation from observed video sequences. Our generative model consists of three components. The first is a photometric model which represents an image as a linear superposition of image bases selected from a generic and overcomplete dictionary. The dictionary contains Gabor and LoG bases for point/particle elements and Fourier bases for wave elements. These bases compete to explain the input images and transfer them to a token (base) representation with an O(10(2))- fold dimension reduction. The second component is a geometric model which groups spatially adjacent tokens (bases) and their motion trajectories into a number of moving elements - called "motons." A moton is a deformable template in time-space representing a moving element, such as a falling snowflake or a flying bird. The third component is a dynamic model which characterizes the motion of particles, waves, and their interactions. For example, the motion of particle objects floating in a river, such as leaves and balls, should be coupled with the motion of waves. The trajectories of these moving elements are represented by coupled Markov chains. The dynamic model also includes probabilistic representations for the birth/death (source/sink) of the motons. We adopt a stochastic gradient algorithm for learning and inference. Given an input video sequence, the algorithm iterates two steps: 1) computing the motons and their trajectories by a number of reversible Markov chain jumps, and 2) learning the parameters that govern the geometric deformations and motion dynamics. Novel video sequences are synthesized from the learned models and, by editing the model parameters, we demonstrate the controllability of the generative model.	Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Wang, YZ (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, 3532F Boelter Hall, Los Angeles, CA 90095 USA.	wangyz@cs.ucla.edu; sczhu@stat.ucla.edu						BARJOSEPH Z, 2001, IEEE T VISUALIZATION, V7; BREGLER C, 2000, P SIGGRAPH; CLIFF AD, 1975, T I BRIT GEOGR, P119, DOI 10.2307/621469; EBERT D, 1990, P SIGGRAPH; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559; Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584; FLEET DJ, 1993, IEEE T PATTERN ANAL, V15, P1253, DOI 10.1109/34.250844; Gu MG, 1998, P NATL ACAD SCI USA, V95, P7270, DOI 10.1073/pnas.95.13.7270; HEEGER D, 1995, P SIGGRAPH; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; ISARD M, 1996, P EUR C COMP VIS; JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0; KAILATH R, 1980, LINEAR SYSTEMS; LI Y, 2002, P SIGGRAPH; LOGAN BF, 1977, AT&T TECH J, V56, P487, DOI 10.1002/j.1538-7305.1977.tb00522.x; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Mann R, 2002, INT C PATT RECOG, P264, DOI 10.1109/ICPR.2002.1047447; Marr D., 1983, VISION; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; REEVES WT, 1985, P SIGGRAPH; Saisan P., 2001, P IEEE C COMP VIS PA; SCHODL A, 2002, P ACM S COMP AN; SCHODL A, 2000, P SIGGRAPH; SOATTO S, 2001, P INT C COMP VIS; Stoica P, 1997, SPECTRAL ANAL SIGNAL, V1st; Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871; Tricker RAR, 1965, BORES BREAKERS WAVES; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; WANG Y, 2002, P EUR C COMP VIS; Wei L.-Y., 2000, P SIGGRAPH; ZHU S, 2002, IN PRESS INT J COMPU; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627	33	27	27	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2004	26	10					1348	1363		10.1109/TPAMI.2004.76	http://dx.doi.org/10.1109/TPAMI.2004.76			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	844EM	15641721	Green Submitted			2022-12-18	WOS:000223140200009
J	Acharyya, M; De, RK; Kundu, MK				Acharyya, M; De, RK; Kundu, MK			Extraction of features using M-band wavelet packet frame and their neuro-fuzzy evaluation for multitexture segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture segmentation; M-band wavelet packet frames; feature selection; fuzzy feature evaluation index; neural networks	IMAGE TEXTURE SEGMENTATION; CLASSIFICATION; SELECTION; DESIGN; BASES	In this paper, we propose a scheme for segmentation of multitexture images. The methodology involves extraction of texture features using an overcomplete wavelet decomposition scheme called discrete M-band wavelet packet frame (DMbWPF). This is followed by the selection of important features using a neuro-fuzzy algorithm under unsupervised learning. A computationally efficient search procedure is developed for finding the optimal basis based on some maximum criterion of textural measures derived from the statistical parameters for each of the subbands. The superior discriminating capability of the extracted features for segmentation of various texture images over those obtained by several existing methods is established.	Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India	Indian Statistical Institute; Indian Statistical Institute Kolkata	Acharyya, M (corresponding author), Indian Stat Inst, Machine Intelligence Unit, 203 BT Rd, Kolkata 700108, India.	mau_ach@yahoo.co.in; rajat@isical.ac.in; malay@isical.ac.in						Acharyya M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P622, DOI 10.1109/ICIP.2001.958570; Acharyya M, 2001, SIGNAL PROCESS, V81, P1337, DOI 10.1016/S0165-1684(00)00278-4; ALKIN O, 1995, IEEE T SIGNAL PROCES, V43, P1579, DOI 10.1109/78.398719; Basak J, 1998, PATTERN RECOGN LETT, V19, P997, DOI 10.1016/S0167-8655(98)00083-X; BOVIK AC, 1991, IEEE T SIGNAL PROCES, V39, P2025, DOI 10.1109/78.134435; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; ETEMAD K, 1994, IEEE IMAGE PROC, P441, DOI 10.1109/ICIP.1994.413768; Etemad K, 1998, IEEE T IMAGE PROCESS, V7, P1453, DOI 10.1109/83.718485; LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679; Laine A, 1996, IEEE T IMAGE PROCESS, V5, P771, DOI 10.1109/83.499915; MALLAT S, 1989, IEEE T PATTERN ANAL, V11, P7; Pal SK, 2000, INT J REMOTE SENS, V21, P2269, DOI 10.1080/01431160050029567; PAL SK, 2000, SOFT COMPUTING IMAGE; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; RANDEN T, 1994, OPT ENG, V33, P2617, DOI 10.1117/12.177115; RUZON MA, 1999, P 30 LUN PLAN SCI C; SAITO N, 1994, P SOC PHOTO-OPT INS, V2303, P2, DOI 10.1117/12.188763; STEFFEN P, 1993, IEEE T SIGNAL PROCES, V41, P3497, DOI 10.1109/78.258088; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; VETTERLI M, 1992, IEEE T SIGNAL PROCES, V40, P2207, DOI 10.1109/78.157221	20	27	29	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1639	1644		10.1109/TPAMI.2003.1251158	http://dx.doi.org/10.1109/TPAMI.2003.1251158			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA					2022-12-18	WOS:000186765000015
J	Crouzil, A; Descombes, X; Durou, JD				Crouzil, A; Descombes, X; Durou, JD			A multiresolution approach for shape from shading coupling deterministic and stochastic optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	3rd International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition	SEP 03-05, 2001	SOPHIA ANTIPOLIS, FRANCE	INRIA, Int Assoc Pattern Recognit, Conseil Gen Alpes Maritimes		shape from shading; optimization; simulated annealing; multiresolution		Shape from shading is an ill-posed inverse problem for which there is no completely satisfactory solution in the existing literature. In this paper, we address shape from shading as an energy minimization problem. We first show that the deterministic approach provides efficient algorithms in terms of CPU time, but reaches its limits since the energy associated with shape from shading can contain multiple deep local minima. We derive an alternative stochastic approach using simulated annealing. The obtained results strongly outperform the results of the deterministic approach. The shortcoming is an extreme slowness of the optimization. Therefore, we propose a hybrid approach which combines the deterministic and stochastic approaches in a multiresolution framework.	Univ Toulouse 3, Inst Rech Informat Toulouse, F-31062 Toulouse, France; INRIA, CNRS, INRIA, UNSA,Joint Res Grp, F-06902 Sophia Antipolis, France	Universite de Toulouse; Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite Toulouse III - Paul Sabatier; Institut National Polytechnique de Toulouse; Universite Toulouse 1 Capitole; Universite de Toulouse - Jean Jaures; Centre National de la Recherche Scientifique (CNRS); Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; Universite Cote d'Azur	Crouzil, A (corresponding author), Univ Toulouse 3, Inst Rech Informat Toulouse, 118 Route Narbonne, F-31062 Toulouse, France.							BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BLAKE A, 1985, IMAGE VISION COMPUT, V3, P183, DOI 10.1016/0262-8856(85)90006-X; CROUZIL A, 2003, MULTIRESOLUTION APPR; Daniel P, 2000, P 4 AS C COMP VIS TA, P187; Dupuis P., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P453, DOI 10.1109/CVPR.1992.223151; Durou JD, 2000, J MATH IMAGING VIS, V12, P99, DOI 10.1023/A:1008361021281; Durou JD, 1996, INT J COMPUT VISION, V17, P273, DOI 10.1007/BF00128234; FALCONE M, 1997, P 9 IEEE ITN C IM AN, V1, P596; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Horn B.K.P., 1989, SHAPE SHADING; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P47, DOI 10.1006/cviu.1995.1040; LEE KM, 1993, IEEE T PATTERN ANAL, V15, P815, DOI 10.1109/34.236247; LIONS PL, 1993, NUMER MATH, V64, P323, DOI 10.1007/BF01388692; PELEG S, 1990, IEEE T PATTERN ANAL, V12, P1206, DOI 10.1109/34.62611; SZELISKI R, 1991, CVGIP-IMAG UNDERSTAN, V53, P129, DOI 10.1016/1049-9660(91)90023-I; TERZOPOULOS D, 1984, P 4 NAT C ART INT AU, P314; TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7; WINKLER G, 1995, IMAGE ANAL FIELDS DY; Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284	25	27	27	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1416	1421		10.1109/TPAMI.2003.1240116	http://dx.doi.org/10.1109/TPAMI.2003.1240116			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	733NG		Green Submitted			2022-12-18	WOS:000186006800007
J	Irani, M; Anandan, P; Cohen, M				Irani, M; Anandan, P; Cohen, M			Direct recovery of planar-parallax from multiple frames	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						plane plus parallax; direct (gradient-based) methods; multiframe analysis; correspondence estimation; structure from motion	MOTION	In this paper, we present an algorithm that estimates dense planar-parallax motion from multiple uncalibrated views of a 3D scene. This generalizes the "plane+parallax" recovery methods to more than two frames. The parallax motion of pixels across multiple frames (relative to a planar surface) is related to the 3D scene structure and the camera epipoles. The parallax field, the epipoles, and the 3D scene structure are estimated directly from image brightness variations across multiple frames, without precomputing correspondences.	Weizmann Inst Sci, Dept Appl Math & Comp Sci, IL-76100 Rehovot, Israel; Microsoft Corp, Redmond, WA 98052 USA	Weizmann Institute of Science; Microsoft	Irani, M (corresponding author), Weizmann Inst Sci, Dept Appl Math & Comp Sci, IL-76100 Rehovot, Israel.	irani@wisdom.weizmann.ac.il; anandan@microscoft.com						BERGEN JR, 1992, P EUR C COMP VIS, P237; BRODSKY T, 1999, P IEEE C COMP VIS PA, VB, P146; CRIMINISI C, 1998, P EUR C COMP VIS, V2; Hanna K. J., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P156, DOI 10.1109/WVM.1991.212812; HANNA KJ, 1993, P INT C COMP VIS, P357, DOI DOI 10.1109/ICCV.1993.378192; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Irani M, 1997, IEEE T PATTERN ANAL, V19, P268, DOI 10.1109/34.584105; Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770; IRANI M, 1998, P EUR C COMP VIS, V2, P829; IRANI M, 1999, P WORKSH VIS ALG SEP; IRANI M, 1996, P EUR C COMP VIS, P17; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; SAWHNEY HS, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P929, DOI 10.1109/CVPR.1994.323927; SHASHUA A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P483, DOI 10.1109/CVPR.1994.323870; Stein GP, 1997, PROC CVPR IEEE, P400, DOI 10.1109/CVPR.1997.609356; SZELISKI R, 1995, P WORKSH REPR VIS SC; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	24	27	33	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1528	1534		10.1109/TPAMI.2002.1046174	http://dx.doi.org/10.1109/TPAMI.2002.1046174			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY		Green Submitted			2022-12-18	WOS:000178846400010
J	Shah-Hosseini, H; Safabakhsh, R				Shah-Hosseini, H; Safabakhsh, R			Automatic multilevel thresholding for image segmentation by the growing time adaptive self-organizing map	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						self-organizing map; image segmentation; automatic multilevel thresholding; histogram; time-adaptive; TASOM	COLOR; SELECTION	In this paper, a Growing TASOM (Time Adaptive Self-Organizing Map) network called "GTASOM" along with a peak finding process is proposed for automatic multilevel thresholding The proposed GTASOM is tested for image segmentation Experimental results demonstrate that the GTASOM is a reliable and accurate tool for image segmentation and its results outperform other thresholding methods.	Amirkabir Univ Technol, Comp Engn Dept, Tehran 15914, Iran	Amirkabir University of Technology	Shah-Hosseini, H (corresponding author), Amirkabir Univ Technol, Comp Engn Dept, Tehran 15914, Iran.	haamed@ce.aut.ac.ir; safa@ce.aut.ac.ir	Safabakhsh, Reza/K-9687-2018	Safabakhsh, Reza/0000-0002-4937-8026; Shah-Hosseini, Hamed/0000-0002-3969-4973				ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0; ALTMACA H, 1996, IEEE INT C IM PROC, P951; BOUKHAROUBA S, 1985, COMPUT VISION GRAPH, V29, P47, DOI 10.1016/S0734-189X(85)90150-1; CHANG CC, 1992, P INT C PATT REC, V11, P522; Chang JS, 1997, IMAGE VISION COMPUT, V15, P23, DOI 10.1016/S0262-8856(96)01087-6; DEKKER AH, 1994, NETWORK-COMP NEURAL, V5, P351, DOI 10.1088/0954-898X/5/3/003; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KHOTANZAD A, 1990, PATTERN RECOGN, V23, P961, DOI 10.1016/0031-3203(90)90105-T; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; Otsu N., 1979, IEEE T SYST MAN CYB, V9, P377; Papamarkos N, 2000, COMPUT VIS IMAGE UND, V78, P336, DOI 10.1006/cviu.2000.0838; Papamarkos N, 1999, INT J IMAG SYST TECH, V10, P404, DOI 10.1002/(SICI)1098-1098(1999)10:5<404::AID-IMA5>3.0.CO;2-F; PAPAMARKOS N, 1994, CVGIP-GRAPH MODEL IM, V56, P357, DOI 10.1006/cgip.1994.1033; Papamarkos N, 2000, IMAGE VISION COMPUT, V18, P213, DOI 10.1016/S0262-8856(99)00015-3; REDDI SS, 1984, IEEE T SYST MAN CYB, V14, P661, DOI 10.1109/TSMC.1984.6313341; RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039; SEZAN MI, 1990, COMPUT VISION GRAPH, V49, P36, DOI 10.1016/0734-189X(90)90161-N; Shah-Hosseini H, 2001, IEEE IMAGE PROC, P509, DOI 10.1109/ICIP.2001.959065; Shah-Hosseini H., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P422, DOI 10.1109/ITCC.2000.844265; Shah-Hosseini H, 2000, ICECS 2000: 7TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS & SYSTEMS, VOLS I AND II, P495, DOI 10.1109/ICECS.2000.911587; Shah-Hosseini H, 2000, P AI SIM PLANN HIGH, P123; Shah-Hosseini H., 2001, SCI IRAN, V8, P277; SHAHHOSSEINI H, 2002, INT J ENG, V15, P23; WANG S, 1984, COMPUT VISION GRAPH, V25, P46, DOI 10.1016/0734-189X(84)90048-3; WHATMOUGH RJ, 1991, CVGIP-GRAPH MODEL IM, V53, P592, DOI 10.1016/1049-9652(91)90009-9; Zhang XP, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P224, DOI 10.1109/ICIP.1997.647744	26	27	27	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2002	24	10					1388	1393		10.1109/TPAMI.2002.1039209	http://dx.doi.org/10.1109/TPAMI.2002.1039209			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	596ZF					2022-12-18	WOS:000178196300008
J	Ros, L; Thomas, F				Ros, L; Thomas, F			Overcoming superstrictness in line drawing interpretation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						line drawing interpretation; superstrictness; scene understanding; correction algorithms	COMPLEXITY; PROJECTIONS	This paper presents a new algorithm for correcting incorrect line drawings-incorrect projections of a polyhedral scene. Such incorrect drawings arise, e.g., when an image of a polyhedral world is taken, the edges and vertices are extracted, and a drawing is synthesized. Along the way, the true positions of the vertices in the 2D projection are perturbed due to digitization errors and the preprocessing. As most available algorithms for interpreting line drawings are "superstrict," they judge these noisy inputs as incorrect and fail to reconstruct a three-dimensional scene from them. The presented method overcomes this problem by moving the positions of all vertices until a very close correct drawing is found. The closeness criterion is to minimize the sum of squared distances from each vertex in the input drawing to its corrected position. With this tool, any superstrict method for line drawing interpretation is now practical, as it can be applied to the corrected version of the input drawing.	UPC, CSIC, Inst Robot & Informat Ind, Barcelona 08028, Catalonia, Spain	Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII); Universitat Politecnica de Catalunya	Ros, L (corresponding author), UPC, CSIC, Inst Robot & Informat Ind, Llorens Artigas 4-6,2 Planta, Barcelona 08028, Catalonia, Spain.	llros@iri.upc.es; fthomas@iri.upc.es	Ros, Lluís/L-7914-2014; Thomas, Federico/L-5143-2014	Ros, Lluís/0000-0002-8338-6062; Thomas, Federico/0000-0001-9341-5528				Bombin C, 2000, ADVANCES IN ROBOT KINEMATICS, P53; CRAPO H, 1993, STRUCTURAL TOPOLOGY, V20, P55; DRAPER SW, 1978, PERCEPTION, V7, P283, DOI 10.1068/p070283; ERNST B, 1987, ADVENTURES IMPOSSIBL; HANCOCK ER, 1990, IEEE T PATTERN ANAL, V12, P165, DOI 10.1109/34.44403; HANSEN E, 1992, GLOBAL OPTIMIZATION; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; HUFFMAN DA, 1977, MACHINE INTELLIGENCE, V8; KIROUSIS LM, 1988, J COMPUT SYST SCI, V37, P14, DOI 10.1016/0022-0000(88)90043-8; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; Maxwell JC, 1864, PHILOS MAG, V4, P250, DOI DOI 10.1080/14786446408643663; Myers R, 2000, PATTERN RECOGN, V33, P685, DOI 10.1016/S0031-3203(99)00080-1; Parodi P, 1998, ARTIF INTELL, V105, P47, DOI 10.1016/S0004-3702(98)00077-0; PARODI P, 1994, ARTIF INTELL, V70, P239, DOI 10.1016/0004-3702(94)90107-4; PENROSE LS, 1958, BRIT J PSYCHOL, V49, P31, DOI 10.1111/j.2044-8295.1958.tb00634.x; PONCE J, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P1786, DOI 10.1109/ROBOT.1992.220121; ROS I, 2001, P IEEE INT C ROBOTIC, V2, P2126; Ros L, 1998, IEEE INT CONF ROBOT, P3559, DOI 10.1109/ROBOT.1998.681020; ROS L, 2000, THESIS POLYTECHNIC U; SCHLICK T, 1992, ACM T MATH SOFTWARE, V18, P46, DOI 10.1145/128745.150973; SHIMSHONI I, 1995, THESIS U ILLINOIS UR; Sugihara K, 1999, DISCRETE COMPUT GEOM, V21, P243, DOI 10.1007/PL00009419; SUGIHARA K, 1984, IEEE T PATTERN ANAL, V6, P578, DOI 10.1109/TPAMI.1984.4767571; SUGIHARA K, 1982, IEEE T PATTERN ANAL, V4, P458, DOI 10.1109/TPAMI.1982.4767289; Sugihara K., 1986, MACHINE INTERPRETATI; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; WHITELEY W, 1989, DISCRETE COMPUT GEOM, V4, P75, DOI 10.1007/BF02187716; WHITELEY W, 1987, J MATH PSYCHOL, V31, P441, DOI 10.1016/0022-2496(87)90026-5; WHITELEY W, 1991, DISCRETE APPL MATH, V32, P275, DOI 10.1016/0166-218X(91)90004-G; WHITELEY W, 1994, J INTELL ROBOT SYST, V11, P135, DOI 10.1007/BF01258299	30	27	29	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2002	24	4					456	466		10.1109/34.993554	http://dx.doi.org/10.1109/34.993554			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	534FM		Green Submitted			2022-12-18	WOS:000174574100003
J	Vasconcelos, N; Lippman, A				Vasconcelos, N; Lippman, A			Empirical Bayesian motion segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion segmentation; layered representations; empirical Bayesian procedures; estimation of hyperparameters; statistical learning; expectation-maximization		We introduce an empirical Bayesian procedure for the simultaneous segmentation of an observed motion field and estimation of the hyperparameters of a Markov random field prior. The new approach exhibits the Bayesian appeal of incorporating prior beliefs, but requires only a qualitative description of the prior, avoiding the requirement for a quantitative specification of its parameters. This eliminates the need for trial-and-error strategies for the determination of these parameters and leads to better segmentations.	Compaq Comp Corp, Cambridge Res Lab, Cambridge, MA 02142 USA; MIT, Media Lab, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT)	Vasconcelos, N (corresponding author), Compaq Comp Corp, Cambridge Res Lab, 1 Cambridge Ctr, Cambridge, MA 02142 USA.			Vasconcelos, Nuno/0000-0002-9024-4302				BESAG J, 1986, J R STAT SOC B, V48, P259; Carlin B., 1996, BAYES EMPIRICAL BAYE; DEMPSTER AP, 1977, J ROYAL STAT SOC B, V39; JEPSON A, 1996, AKR96PUB54 U TOR; Jepson A., 1996, PERCEPTION BAYESIAN; MURRAY D, 1987, IEEE T PATTERN ANAL, V9; PAPPAS T, 1992, IEEE T SIGNAL PROCES, V40; VASCONCELOS N, 1997, P IEEE COMP VIS PATT; WANG J, 1994, IEEE T IMAGE PROCESS, V3; WEISS Y, 1996, P C COMP VIS PATT RE; ZHANG J, 1994, IEEE T IMAGE PROCESS, V3	11	27	30	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2001	23	2					217	221		10.1109/34.908972	http://dx.doi.org/10.1109/34.908972			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	401NJ					2022-12-18	WOS:000166933500011
J	Jiang, XY				Jiang, XY			An adaptive contour closure algorithm and its experimental evaluation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						contour closure; adaptive grouping; directional morphology; image segmentation; performance evaluation	RANGE IMAGE SEGMENTATION; COMPUTER VISION; EDGE-DETECTION; PERFORMANCE; REGRESSION; FRAMEWORK	The potential of edge-based complete image segmentation into regions has not gained the due attention in the literature thus far. The present paper attempts to explore this potential by proposing an adaptive grouping algorithm to solve the contour closure problem that is the key to a successful edge-based complete image segmentation. The effectiveness of the proposed algorithm will be extensively tested in the range image domain and compared to several region-based segmentation methods within a rigorous comparison framework. On three range image databases of varying quality acquired by different range scanners, it will be shown that the proposed approach is able to achieve very appealing performance with respect to both segmentation quality and computation time.	Univ Bern, Dept Comp Sci, CH-3012 Bern, Switzerland	University of Bern	Jiang, XY (corresponding author), Univ Bern, Dept Comp Sci, CH-3012 Bern, Switzerland.	jiang@iam.unibe.ch	Jiang, Xiaoyi/AAA-3532-2022	Jiang, Xiaoyi/0000-0001-7678-9528				ADE F, 1995, MODELLING PLANNING S, P445; ALHUJAZI E, 1990, IEEE T SYST MAN CYB, V20, P1313, DOI 10.1109/21.61203; ARMAN F, 1993, COMPUT SURV, V25, P5, DOI 10.1145/151254.151255; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BOLLES RC, 1993, P DARPA IM UND WORKS, P263; Borra S, 1997, IEEE T PATTERN ANAL, V19, P1306, DOI 10.1109/34.632991; Bowyer K., 1998, EMPIRICAL EVALUATION; CHENG JC, 1992, ADV MACHINE VISION S, P171; Christensen HI, 1997, MACH VISION APPL, V9, P215, DOI 10.1007/s001380050042; Cinque L, 2000, INT C PATT RECOG, P474, DOI 10.1109/ICPR.2000.905379; COX IJ, 1993, INT J COMPUT VISION, V11, P5, DOI 10.1007/BF01420590; FLYNN PJ, 2000, COMPUTER VISION IMAG; FLYNN PJ, 1994, HDB PATTERN RECOGNIT, P497; Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; JAIN RC, 1991, CVGIP-IMAG UNDERSTAN, V53, P112, DOI 10.1016/1049-9660(91)90009-E; Jiang X., 1997, Image Analysis and Processing. 9th International Conference, ICIAP '97 Proceedings, P182; JIANG X, 2000, P INT WORKSH MACH VI; JIANG X, 1998, P AS C COMP VIS HONG, P299; JIANG X, 1999, P 2 INT C 3D DIG IM, P252; Jiang XY, 1999, COMPUT VIS IMAGE UND, V73, P183, DOI 10.1006/cviu.1998.0715; Jiang XY, 1998, INT C PATT RECOG, P16, DOI 10.1109/ICPR.1998.711068; Kaveti S, 1996, PATTERN RECOGN, V29, P937, DOI 10.1016/0031-3203(95)00137-9; KEHTARNAVAZ N, 1989, COMPUT VISION GRAPH, V45, P88, DOI 10.1016/0734-189X(89)90072-8; KLETTE R, 2000, PERFORMANCE EVALUATI; KOCHER M, 1986, SIGNAL PROCESS, V11, P47, DOI 10.1016/0165-1684(86)90094-0; Krishnapuram R., 1992, Journal of Mathematical Imaging and Vision, V2, P351, DOI 10.1007/BF00121878; Leedan Y, 2000, INT J COMPUT VISION, V37, P127, DOI 10.1023/A:1008185619375; LIN YJ, 1992, PATTERN RECOGN, V25, P507, DOI 10.1016/0031-3203(92)90049-O; LIOU SP, 1991, IEEE T PATTERN ANAL, V13, P317, DOI 10.1109/34.88567; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Min J, 2000, INT C PATT RECOG, P644, DOI 10.1109/ICPR.2000.905420; MULGAONKAR PG, 1992, IEEE T PATTERN ANAL, V14, P303, DOI 10.1109/34.121798; Nair D, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB631; NALWA VS, 1987, COMPUT VISION GRAPH, V40, P79, DOI 10.1016/0734-189X(87)90057-0; NEWMAN TS, 1995, PATTERN RECOGN, V28, P1555, DOI 10.1016/0031-3203(95)00028-X; NEWMAN TS, 1993, CVGIP-IMAG UNDERSTAN, V58, P235, DOI 10.1006/ciun.1993.1040; Parvin B, 1996, INT J COMPUT VISION, V20, P81, DOI 10.1007/BF00144118; Powell MW, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P286, DOI 10.1109/ICCV.1998.710732; Sabata B, 1996, COMPUT VIS IMAGE UND, V63, P232, DOI 10.1006/cviu.1996.0017; SONG B, 1995, P 2 AS C COMP VIS, P528; Weisberg S., 1985, APPL LINEAR REGRESSI; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhu QM, 1996, IMAGE VISION COMPUT, V14, P59, DOI 10.1016/0262-8856(95)01040-8	45	27	33	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2000	22	11					1252	1265		10.1109/34.888710	http://dx.doi.org/10.1109/34.888710			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	374QE					2022-12-18	WOS:000165355200004
J	Pittman, J; Murthy, CA				Pittman, J; Murthy, CA			Fitting optimal piecewise linear functions using genetic algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						genetic algorithms; optimization; statistical data analysis; splines	LEAST-SQUARES APPROXIMATION; PATTERN-CLASSIFICATION; FREE KNOTS; SPLINES; REGRESSION	Constructing a model for data in R-2 is a common problem in many scientific fields, including pattern recognition, computer vision, and applied mathematics. Often little is known about the process which generated the data or its statistical properties. For example, in fitting a piecewise linear model, the number of pieces, as well as the knot locations, may be unknown. Hence, the method used to build the statistical model should have few assumptions, yet, still provide a model that is optimal in some sense. Such methods can be designed through the use of genetic algorithms. In this paper, we examine the use of genetic algorithms to fit piecewise linear functions to data in R-2. The number of pieces, the location of the knots, and the underlying distribution of the data are assumed to be unknown. We discuss existing methods which attempt to solve this problem and introduce a new method which employs genetic algorithms to optimize the number and location of the pieces. Experimental results are presented which demonstrate the performance of our method and compare it to the performance of several existing methods. We conclude that our method represents a valuable tool for fitting both robust and nonrobust piecewise linear functions.	Natl Inst Stat Sci, Res Triangle Pk, NC 27709 USA; Indian Stat Inst, Inst Machine Intelligence, Calcutta 700035, W Bengal, India	Indian Statistical Institute; Indian Statistical Institute Kolkata	Pittman, J (corresponding author), Natl Inst Stat Sci, POB 14006, Res Triangle Pk, NC 27709 USA.			Clarke, Jennifer/0000-0002-2723-7249				Ash R.B., 1972, REAL ANAL PROBABILIT; BACK T, 1993, P 5 INT C GEN ALG; BAINES MJ, 1994, MATH COMPUT, V62, P645, DOI 10.2307/2153528; Bandyopadhyay S, 1998, PATTERN RECOGN LETT, V19, P1171, DOI 10.1016/S0167-8655(98)00097-X; BANDYOPADHYAY S, 1995, PATTERN RECOGN LETT, V16, P801, DOI 10.1016/0167-8655(95)00052-I; BARROWS CH, 1978, AGE, V1, P131; Becker R.A., 1988, PACKAGE MAPS; Bhandari D, 1996, INT J PATTERN RECOGN, V10, P731, DOI 10.1142/S0218001496000438; BREIMAN L, 1994, STAT SCI, V9, P38; Chatterjee S, 1996, COMPUT STAT DATA AN, V22, P633, DOI 10.1016/0167-9473(96)00011-4; CHEN DS, 1994, IEEE T NEURAL NETWOR, V5, P467, DOI 10.1109/72.286917; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; CHUI CK, 1977, MATH COMPUT, V31, P17, DOI 10.2307/2005776; CRAVEN P, 1979, NUMER MATH, V31, P377, DOI 10.1007/BF01437407; Davis L, 1991, HDB GENETIC ALGORITH, DOI DOI 10.1.1.87.3586; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; De Boor C, 1968, 21 CSD PURD U; De Jong K. A., 1975, THESIS U MICHIGAN AN; Denison DGT, 1998, J ROY STAT SOC B, V60, P333, DOI 10.1111/1467-9868.00128; Dierckx P., 1993, CURVE SURFACE FITTIN; Eubank R.L., 1988, SPLINE SMOOTHING NON; EUBANK RL, 1990, BIOMETRIKA, V77, P1; Huber P., 1981, ROBUST STAT; KARR CL, 1991, 9339 BUR MIN US DEP; KARR CL, 1995, FLUID PRACTICE SEPAR, V8, P117; Kokkonis PA, 1996, COMP MATER SCI, V6, P103, DOI 10.1016/0927-0256(96)00005-5; LOACH PD, 1991, IMA J NUMER ANAL, V11, P393, DOI 10.1093/imanum/11.3.393; MURTHY CA, 1997, 9902 PENNS STAT U DE; PITTMAN J, IN PRESS J COMPUTATI; Ripley BD., 1996; SCHWETLICK H, 1995, BIT, V35, P361, DOI 10.1007/BF01732610; Tourigny Y, 1997, MATH COMPUT, V66, P623, DOI 10.1090/S0025-5718-97-00823-5; VANKEERBERGHEN P, 1995, CHEMOMETR INTELL LAB, V28, P73, DOI 10.1016/0169-7439(95)00010-T; *VIS NUM INC, 1997, IMSL FORTR NUM LIB V; WARWICK K, 1996, P IEEE C DEC CONTR, V1, P464; Weisberg S., 1985, APPL LINEAR REGRESSI	36	27	30	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2000	22	7					701	718		10.1109/34.865188	http://dx.doi.org/10.1109/34.865188			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347LV					2022-12-18	WOS:000088931800005
J	Beauchemin, SS; Barron, JL				Beauchemin, SS; Barron, JL			The frequency structure of one-dimensional occluding image signals	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						occlusion; Fourier transforms; optical flow; non-Fourier motion	OPTICAL-FLOW; MOTION	We present a theoretical investigation of the frequency structure of 1D occluding image signals. We show that image signal occlusion contains relevant information which is most easily extractable from its representation in the frequency domain. For instance, the occluding and occluded signal velocities may be identified as such and translucency phenomena may be understood in the terms of this theoretical investigation. in addition, it is found that the structure of occluding 1D signals is invariant under constant and linear models of signal velocity. This theoretical framework can be used to describe the exact frequency structure of non-Fourier motion and bridges the gap between such visual phenomena and their understanding in the frequency domain.	Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA; Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada	University of Pennsylvania; Western University (University of Western Ontario)	Beauchemin, SS (corresponding author), Univ Penn, GRASP Lab, 3401 Walnut St,Suite 300C, Philadelphia, PA 19104 USA.							AISBETT J, 1989, IEEE T PATTERN ANAL, V11, P512, DOI 10.1109/34.24783; CHUBB C, 1988, J OPT SOC AM A, V5, P1986, DOI 10.1364/JOSAA.5.001986; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; FLEET DJ, 1994, VISION RES, V34, P3057, DOI 10.1016/0042-6989(94)90278-X; Fleet DJ, 1992, MEASUREMENT IMAGE VE; Gaskill J.D., 1978, LINEAR SYSTEMS FOURI; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NAGEL HH, 1983, P INT JOINT C ART IN, P945; VICTOR JD, 1992, PERCEPT PSYCHOPHYS, V52, P403, DOI 10.3758/BF03206700; ZANKER JM, 1993, VISION RES, V33, P553, DOI 10.1016/0042-6989(93)90258-X	12	27	27	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2000	22	2					200	206		10.1109/34.825758	http://dx.doi.org/10.1109/34.825758			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	292JU					2022-12-18	WOS:000085791400007
J	Madhvanath, S; Kleinberg, E; Govindaraju, V				Madhvanath, S; Kleinberg, E; Govindaraju, V			Holistic verification of handwritten phrases	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						word verification; holistic approaches; word shape matching; handwritten word recognition; address interpretation	RECOGNITION	In this paper, we describe a system for rapid verification of unconstrained off-line handwritten phrases using perceptual holistic features of the handwritten phrase image. The system is used to verify handwritten street names automatically extracted from live U.S. mail against recognition results of analytical classifiers. Presented with a binary image of a street name and an ASCII street name, holistic features (reference lines, large gaps and local contour extrema) of the street name hypothesis are "predicted" from the expected features of the constituent characters using heuristic rules. A dynamic programming algorithm is used to match the predicted features with the extracted image features. Classes of holistic features are matched sequentially in increasing order of cost, allowing an ACCEPT/REJECT decision to be arrived at in a time-efficient manner. The system rejects errors with 98 percent accuracy at the 30 percent accept level, while consuming approximately 20/msec per image on the average on a 150 MHz SPARC 10.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA; SUNY Buffalo, Dept Comp Sci, Ctr Document Anal & Recognit, Buffalo, NY 14228 USA	International Business Machines (IBM); State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Madhvanath, S (corresponding author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.	srig@almaden.ibm.com; evie@cedar.buffalo.edu; govind@cedar.buffalo.edu						BERTILLE J, 1993, P 3 INT WORKSH FRONT, P417; CAMILLERAP J, 1992, PIXELS FEATURES FRON, P273; Dodel J.-P., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P15, DOI 10.1109/ICDAR.1995.598934; DOWNTON AC, 1992, PIXELS FEATURES 3 FR, P129; FAVATA JT, 1992, P SPIE S EL IM SCI T; HABER LR, 1983, READ RES QUART, V18, P165, DOI 10.2307/747516; HENDRAWAN, 1993, FUNDAMENTALS HANDWRI, P313; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; Kim GG, 1998, PATTERN RECOGN, V31, P41, DOI 10.1016/S0031-3203(97)00023-X; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482; Leroux M., 1991, P 1 INT C DOC AN REC, P774; Madhvanath S., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P911, DOI 10.1109/ICDAR.1995.602049; MADHVANATH S, 1997, P 4 INT C DOC AN REC; MADHVANATH S, 1993, P 3 INT WORKSH FRONT, P71; MADHVANATH S, 1997, THESIS STATE U NEW Y; MADHVANATH S, 1997, INT J PATTERN RECOGN, V11; Madhvanath S., 1999, IEEE T PATTERN ANAL, V21; MOREAU J, 1991, P INT WORKSH FRONT H, P121; PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9; SOLTYSIAK SJ, 1994, VISUAL INFORMATION W	20	27	29	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1999	21	12					1344	1356		10.1109/34.817412	http://dx.doi.org/10.1109/34.817412			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	275PG		Green Submitted			2022-12-18	WOS:000084828100007
J	Ferraro, M; Boccignone, G; Caelli, T				Ferraro, M; Boccignone, G; Caelli, T			On the representation of image structures via scale space entropy conditions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scale space; entropy production; features encoding	CELLS; MODEL	This gager deals with a novel way for representing and computing image features encapsulated within different regions of scale-space. Employing a thermodynamical model for scale-space generation, the method derives features as those corresponding to "entropy rich" image regions where, within a given range of spatial scales, the entropy gradient remains constant. Different types of image features, defining regions of different information content, are accordingly encoded by such regions within different bands of spatial scale.	Univ Turin, Dipartimento Fis Sperimentale, I-10125 Turin, Italy; Univ Turin, INFM, I-10125 Turin, Italy; Univ Salerno, Dipartimento Ingn Informaz & Ingn Elettrica, I-84084 Fisciano, SA, Italy; Univ Salerno, INFM, I-84084 Fisciano, SA, Italy; Univ Alberta, Dept Psychol, Edmonton, AB T6G 2E9, Canada	University of Turin; Consiglio Nazionale delle Ricerche (CNR); Istituto Nazionale per la Fisica della Materia (INFM-CNR); University of Turin; University of Salerno; Consiglio Nazionale delle Ricerche (CNR); Istituto Nazionale per la Fisica della Materia (INFM-CNR); University of Salerno; University of Alberta	Ferraro, M (corresponding author), Univ Turin, Dipartimento Fis Sperimentale, Via Giuria 1, I-10125 Turin, Italy.		Boccignone, Giuseppe/G-7542-2012; Boccignone, Giuseppe/AAH-4459-2020	Boccignone, Giuseppe/0000-0002-5572-0924; Boccignone, Giuseppe/0000-0002-5572-0924; Caelli, Terry/0000-0001-9281-2556				BRILLOUIN L, 1962, SCI INFORMATION THEO; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; de Groot S.R., 1984, NONEQUILIBRIUM THERM; Lindeberg T., 1994, SCALE SPACE THEORY C; MACKEY MC, 1989, REV MOD PHYS, V61, P981, DOI 10.1103/RevModPhys.61.981; MANJUNATH BS, 1993, IEEE T NEURAL NETWOR, V4, P96, DOI 10.1109/72.182699; MCCANE B, 1997, P 1 INT C KNOWL BAS, P72; Petkov N, 1997, BIOL CYBERN, V76, P83, DOI 10.1007/s004220050323; RAN XN, 1995, IEEE T IMAGE PROCESS, V4, P401, DOI 10.1109/83.370671; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Shah S, 1996, IEEE T SYST MAN CY B, V26, P259, DOI 10.1109/3477.485837; VONDERHEYDT R, 1992, J NEUROSCI, V12, P1416; VONDERHEYDT R, 1991, CHANNELS IN THE VISUAL NERVOUS SYSTEM : NEUROPHYSIOLOGY, PSYCHOPHYSICS AND MODELS, P53; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	15	27	29	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1199	1203		10.1109/34.809112	http://dx.doi.org/10.1109/34.809112			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100008
J	Chalmond, B; Girard, SC				Chalmond, B; Girard, SC			Nonlinear modeling of scattered multivariate data and its application to shape change	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data analysis; example-based analysis and synthesis; visual learning; face representation; principal components analysis; nonlinear PCA models; dimensionality reduction; multidimensional scaling; projection pursuit; eigenfeatures	PROJECTION PURSUIT; PRINCIPAL CURVES; IDENTIFICATION; REGRESSION; IMAGE	We are given a set of points in a space of high dimension. For instance, this set may represent many visual appearances of an object, a face, or a hand. We address the problem of approximating this set by a manifold in order to have a compact representation of the object appearance. When the scattering of this set is approximately an ellipsoid, then the problem has a well-known solution given by Principal Components Analysis (PCA). However, in some situations like object displacement learning or face learning, this linear technique may be ill-adapted and nonlinear approximation has to be introduced. The method we propose can be seen as a Non Linear PCA (NLPCA), the main difficulty being that the data are not ordered. We propose an index which favors the choice of axes preserving the closest point neighborhoods. These axes determine an order for visiting all the points when smoothing. Finally, a new criterion, called "generalization error," is introduced to determine the smoothing rate, that is, the knot number for the spline fitting. Experimental results conclude this paper: The method is tested on artificial data and on two data bases used in visual learning.	Ecole Normale Super, CMLA, F-94235 Cachan, France; Univ Montpellier, Dept Math, F-34095 Montpellier 5, France	UDICE-French Research Universities; Universite Paris Saclay; Universite de Montpellier	Chalmond, B (corresponding author), Ecole Normale Super, CMLA, 61 Av President Wilson, F-94235 Cachan, France.	Bernard.Chalmond@cmla.ens-cachan.fr; girard@stat.math.univ-montp2.fr		Girard, Stephane/0000-0003-0098-2369				BANFIELD JD, 1992, J AM STAT ASSOC, V87, P7, DOI 10.2307/2290446; Bibby J, MULTIVARIATE ANAL; Bookstein FL, 1978, MEASUREMENT BIOL SHA; CARROLL JD, 1980, ANNU REV PSYCHOL, V31, P607, DOI 10.1146/annurev.ps.31.020180.003135; CHABAB N, 1997, COMPUTER VISION IMAG, V65, P179; CHALMOND B, 1999, MODELIZATION IMAGE A; DIACONIS P, 1984, SIAM J SCI STAT COMP, V5, P175, DOI 10.1137/0905013; DUCHAMP T, 1995, ROBUST STAT DATA ANA; DUFLO M, 1996, STOCHASTIC ALGORITHM; EUBANK RL, 1990, SPLINE SMOOTHING NON; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; GEMAN S, 1991, NEURAL COMPUT, P1; Gifi A., 1990, NONLINEAR MULTIVARIA; Girard S, 1996, IEE P-VIS IMAGE SIGN, V143, P257, DOI 10.1049/ip-vis:19960689; GIRARD SC, 1996, THESIS U CERGY PONTO; GIRARD SC, 1998, CR HEBD ACAD SCI, P763; GIRARD SC, 1997, CURVES SURFACES APPL, P135; HALLINAN PW, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P995, DOI 10.1109/CVPR.1994.323941; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; KARHUNEN J, 1995, NEURAL NETWORKS, V8, P549, DOI 10.1016/0893-6080(94)00098-7; KERVRANN C, 1995, P INT WORKSH AUT FAC; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Kruskal JosephB., 1978, MULTIDIMENSIONAL SCA, DOI [10.4135/9781412985130, DOI 10.4135/9781412985130]; LANTINIS A, 1997, IEEE T PATTERN ANAL, V19, P696; MCKENNA S, 1996, P BRIT MACH VIS C ED; Milnor J. W., 1965, TOPOLOGY DIFFERENTIA; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; NIELSON GM, 1991, IEEE COMPUT GRAPH, V11, P47, DOI 10.1109/38.79453; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; Press WH., 1980, NUMERICAL RECIPES FO; Ramsay J.O., 1997, FUNCTIONAL DATA ANAL, DOI 10.1007/978-1-4757-7107-7; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SAUND E, 1989, IEEE T PATTERN ANAL, V11, P304, DOI 10.1109/34.21799; Shepard R. M., 1965, P INT S MULT AN, P561; SILVERMAN BW, 1990, DENSITY ESTIMATION; SOZOU PD, 1995, IMAGE VISION COMPUT, V13, P451, DOI 10.1016/0262-8856(95)99732-G; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Uenohara M, 1997, IEEE T PATTERN ANAL, V19, P891, DOI 10.1109/34.608291; Vapnik V., 1982, ESTIMATION DEPENDENC; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230; WHABA G, 1979, P 24 C DES EXP, P167	47	27	27	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1999	21	5					422	432		10.1109/34.765654	http://dx.doi.org/10.1109/34.765654			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	194LK		Green Submitted			2022-12-18	WOS:000080194900004
J	Wu, MF; Sheu, HT				Wu, MF; Sheu, HT			Representation of 3D surfaces by two variable Fourier descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						two-variable 3D Fourier descriptor; surface reconstruction; shape representation; striped lighting	COMPUTER VISION; INVARIANTS	A method for generating two-variable 3D FDs directly from a striped lighting system is developed. An iterative algorithm is proposed to compute the two-variable 3D FDs for both axisymmetric and nonaxisymmetric objects and a formula for convergence test is derived. Experiments conducted for a set of 3D objects show that the iterative algorithm converges very quickly and the two-variable 3D FD representations are attained accurately.	Kung Shan Inst Technol, Dept Elect Engn, Tainan, Taiwan; Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan	National Taiwan University of Science & Technology	Wu, MF (corresponding author), Kung Shan Inst Technol, Dept Elect Engn, 949 Da Wan Rd, Tainan, Taiwan.		Rohlf, F J/A-8710-2008					Cosgriff R. L., 1960, 82011 ASTIA OH STAT; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X; LIN CS, 1990, PATTERN RECOGN, V23, P833, DOI 10.1016/0031-3203(90)90130-D; LIN CS, 1987, PATTERN RECOGN, V20, P535, DOI 10.1016/0031-3203(87)90080-X; LU LE, 1986, COMMUN ACM, V29, P239; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; SATO Y, 1982, IEEE T PATTERN ANAL, V4, P641, DOI 10.1109/TPAMI.1982.4767318; SHEU HT, 1995, IEE P VIS IM SIGN PR, V142, P83; TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1; WALLACE TP, 1980, IEEE T PATTERN ANAL, V2, P583, DOI 10.1109/TPAMI.1980.6447707; WALLACE TP, 1980, COMPUTER GRAPHICS IM, V13, P126; WANG LL, 1991, IEEE T PATTERN ANAL, V13, P370, DOI 10.1109/34.88572; Wu MF, 1996, PATTERN RECOGN, V29, P267, DOI 10.1016/0031-3203(95)00088-7; WU MF, 1995, IPPR C COMP VIS GRAP, P63; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949; ZAID I, 1991, CAD CAM THEORY PRACT, P259; ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023	19	27	29	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1998	20	8					858	863		10.1109/34.709610	http://dx.doi.org/10.1109/34.709610			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	110GT					2022-12-18	WOS:000075372700009
J	Ben-Arie, J; Nandy, D				Ben-Arie, J; Nandy, D			A volumetric/iconic frequency domain representation for objects with application for pose invariant face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						volumetric frequency representation (VFR); object representation; projection-slice theorem; 4D Fourier space; face pose estimation; pose invariant face recognition	TEMPLATES	A novel method for representing 3D objects that unifies viewer and model centered object representations is presented. A unified 3D frequency-domain representation (called Volumetric Frequency Representation-VFR) encapsulates both the spatial structure of the object and a continuum of its views in the same data structure. The frequency-domain image of an object viewed from any direction can be directly extracted employing an extension of the Projection Slice Theorem, where each Fourier-transformed view is a planar slice of the volumetric frequency representation. The VFR is employed for pose-invariant recognition of complex objects, such as faces. The recognition and pose estimation is based on an efficient matching algorithm in a four-dimensional Fourier space. Experimental examples of pose estimation and recognition of faces in Various poses are also presented.	Univ Illinois, Dept Elect Engn & Comp Sci, Chicago, IL 60607 USA	University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	Ben-Arie, J (corresponding author), Univ Illinois, Dept Elect Engn & Comp Sci, 851 S Morgan St, Chicago, IL 60607 USA.	benarie@eecs.uic.edu	Rohlf, F J/A-8710-2008					Ballard D., 1982, COMPUTER VISION; Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; BENARIE J, 1996, P 1996 IEEE INT C SP, V6, P3470; BENARIE J, 1996, P ARPA IM UND WORKSH, P1277; BENARIE J, 1997, P 1997 IEEE CS C COM; BENARIE J, 1996, P IAPR IEEE INT C PA, V1, P672; Beymer DJ, 1993, 1461 MIT ART INT LAB; BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; CRAW I, 1992, P 2 EUR C COMP VIS, P92; DeMers D., 1993, ADV NEURAL INFORM PR, P580; HARALICK R, 1993, COMPUTER ROBOT VISIO, V2, pCH18; HU MK, 1977, COMPUTER METHODS IMA; Huang T.S., 1993, P 4 INT C COMP VIS B, P121; Jain A. K., 1989, FUNDAMENTALS DIGITAL, P431; JAIN R, 1995, MACHINE VISION, pCH15; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Lawrence A., 1997, IEEE T NEURAL NETWOR, V8, P98; NASTAR C, 1995, P 1995 IEEE INT S CO; *OL OR RES LAB, 1994, ORL DAT FAC; Pentland A., 1994, P 1994 IEEE C COMP V; PENTLAND AP, 1986, ARTIF INTELL, V28, P29; REISFELD D, 1992, P INT C PATT REC HAG, V1, P117; Rosenfeld A., 1982, DIGITAL IMAGE PROCES; Samaria F., 1994, P 2 IEEE WORKSH APPL; Terzopoulos D., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P727, DOI 10.1109/ICCV.1990.139628; WANG Z, 1997, P 1997 IEEE INT C IM, V3, P162; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	30	27	27	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					449	457		10.1109/34.682175	http://dx.doi.org/10.1109/34.682175			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZR253					2022-12-18	WOS:000073955600001
J	Deseilligny, MP; Stamon, G; Suen, CY				Deseilligny, MP; Stamon, G; Suen, CY			Veinerization: A new shape description for flexible skeletonization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						digital skeleton; veinerization; skeletonization; context adaptation; digital topology; graphs; fractal sets	THINNING ALGORITHMS; GENERATION; PATTERNS	Despite the intuitive interpretation of the skeleton as the "center line of the shape" it is surprisingly hard to get skeletonization algorithms that simultaneously produce all the "good" properties we expect (e.g., well-centered, well-connected, rotation-invariant, efficient, robust, accurately reflecting the shape). In this paper, we introduce the new concept of "veinerization," which produces a graph that contains all the "topological" information needed to derive a wide variety of skeletons. Theoretically, the main contribution is to provide a homogeneous framework for integration of the major concepts described in other related works on digital skeletonization. In practice, the new aspect of this approach is to provide the user with different criteria for selecting the most suitable skeleton for a given application; e.g., the user can select a suitable threshold for obtaining the desirable balance between "having a skeleton without noisy prunes" and "having a skeleton that reflects the initial shape". This algorithm has been tested on numerous kinds of patterns, including pathological ones like fractal sets well-known for the complexity of their shapes.	Inst Geog Natl, Lab MATIS, F-94160 St Mande, France; Univ Paris 05, Lab SIP, F-75005 Paris, France; Concordia Univ, Montreal, PQ H3G 1M8, Canada	Universite Gustave-Eiffel; UDICE-French Research Universities; Universite Paris Cite; Concordia University - Canada	Deseilligny, MP (corresponding author), Inst Geog Natl, Lab MATIS, 2 Av Pasteur, F-94160 St Mande, France.	pierrot@valandre.ign.fr; stamon@math-info.univ-paris5.fr; suen@cenparmi.concordia.ca						ARCELLI C, 1979, SIGNAL PROCESS, V1, P283, DOI 10.1016/0165-1684(79)90031-8; ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P463, DOI 10.1109/TPAMI.1985.4767685; Blum Harry, 1967, TRANSFORMATION EXTRA, V43, P2; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Chassery J. M., 1991, GEOMETRIE DISCRETE A; CHU YK, 1986, SIGNAL PROCESS, V11, P207, DOI 10.1016/0165-1684(86)90001-0; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DESEILLIGNY MP, 1994, THESIS U PARIS 5 REN, V2, P25; DEUTSCH ES, 1972, COMMUN ACM, V15, P827, DOI 10.1145/361573.361583; diBaja GS, 1996, IMAGE VISION COMPUT, V14, P47, DOI 10.1016/0262-8856(95)01039-4; Ge YR, 1996, IEEE T PATTERN ANAL, V18, P1055, DOI 10.1109/34.544075; Hilditch C.J., 1969, MACH INTELL, P403; JANG BK, 1994, THINNING METHODOLOGI, P181; KWOK PCK, 1988, COMMUN ACM, V31, P1314, DOI 10.1145/50087.50092; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; LEE SW, 1994, THINNING METHODOLOGI, P239; MA H, 1983, COMP STUDY THINNING; MANDELBROT BB, 1980, ANN NY ACAD SCI, V357, P249; Matheron G., 1988, IMAGE ANAL MATH MORP, V2, P217; MEYER F, 1979, THESIS ECOLES MINES; MEYER F, 1988, IMAGE ANAL MATH MORP, V2, P257; NIBLACK CW, 1992, CVGIP-GRAPH MODEL IM, V54, P420, DOI 10.1016/1049-9652(92)90026-T; OGNIEWICZ R, 1993, THESIS HARTUNG GORE; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; PAGLERIONI DW, CVGIP GRAPHICAL MODE, V54, P56; Plamondon R., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P262, DOI 10.1109/ICDAR.1993.395735; Plamondon R., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P1247, DOI 10.1142/S0218001493000613; ROSENFELD A, 1979, PICTURES LANGUAGES, P7; RUTOVITZ D, 1966, J R STAT SOC SER A-G, V129, P504, DOI 10.2307/2982255; STEFANELLI R, 1971, J ACM, V18, P255, DOI 10.1145/321637.321646; SUEN CY, 1991, ALGORITHM THINNING H; SUZUKI S, 1994, THINNING METHODOLOGI, P45; SUZUKI Y, 1987, J INHERIT METAB DIS, V10, P297, DOI 10.1007/BF01800086; TALBOT H, 1992, SPIE, V1818, P862; Tamura H., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P715; TSURUOKA S, 1983, P IECE JAPAN, P525; VINCENT L, 1990, THESIS ECOLE NATL SU, P85; ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023	38	27	29	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					505	521		10.1109/34.682180	http://dx.doi.org/10.1109/34.682180			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZR253					2022-12-18	WOS:000073955600006
J	Jun, BH; Kim, CS; Song, HY; Kim, J				Jun, BH; Kim, CS; Song, HY; Kim, J			A new criterion in selection and discretization of attributes for the generation of decision trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						decision-tree generators; attribute selection; discretization; grouping; gain; gain ratio; normalized gain; entropy		It is important to use a better criterion in selection and discretization of attributes for the generation of decision trees to construct a better classifier in the area of pattern recognition in order to intelligently access huge amount of data efficiently. Two well-known criteria are gain and gain ratio, both based on the entropy of partitions. We propose in this paper a new criterion based also on entropy, and use both theoretical analysis and computer simulation to demonstrate that it works better than gain or gain ratio in a wide variety of situations. We use the usual entropy calculation where the base of the logarithm is not two but the number of successors to the node. Our theoretical analysis leads some specific situations in which the new criterion works always better than gain or gain ratio, and the simulation result may implicitly cover all the other situations not covered by the analysis.	YONSEI UNIV,DEPT ELECT ENGN,SEOUL 120749,SOUTH KOREA	Yonsei University	Jun, BH (corresponding author), KONGJU NATL UNIV,DEPT COMP SCI,182 SHINKWAN DONG,KONG JU 314701,CHUNGNAM,SOUTH KOREA.							ASH R, 1965, INFORMATION THEORY; CHENG J, 1988, 5TH P INT C MACH LEA, P100; Fayyad U. M., 1990, AAAI-90 Proceedings. Eighth National Conference on Artificial Intelligence, P749; FAYYAD UM, 1994, AAAI 94 P 12 NAT C A, P601; FAYYAD UM, 1991, THESIS U MICHIGAN; Lim JS, 1990, 2 DIMENSIONAL SIGNAL; Mingers J., 1989, Machine Learning, V3, P319, DOI 10.1007/BF00116837; Olshen R., 1984, CLASSIFICATION REGRE; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; QUINLAN JR, 1988, MACH INTELL, V11, P305; Quinlan R., 1987, APPL EXPERT SYSTEMS, P157	12	27	34	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1997	19	12					1371	1375		10.1109/34.643896	http://dx.doi.org/10.1109/34.643896			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YK781					2022-12-18	WOS:A1997YK78100006
J	Mardia, KV; Qian, W; Shah, D; deSouza, KMA				Mardia, KV; Qian, W; Shah, D; deSouza, KMA			Deformable template recognition of multiple occluded objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian methods; deformable templates; iterative conditional increase; iterative conditional mode; Markov random field; object ordering; object process; occlusion; response function		Based on deformable templates, the paper formulates an integrated and flexible Bayesian recognition system of multiple occluded objects. Various local dependence properties of the model are obtained to reduce the computational cost with the increase in the number of objects. Numerical results for a synthetic image and for a real image of mushrooms are discussed.			Mardia, KV (corresponding author), UNIV LEEDS, DEPT STAT, LEEDS LS2 9JT, W YORKSHIRE, ENGLAND.							BADDELEY AJ, 1993, STAT IMAGES, V1, P231; BADDELEY AJ, 1993, P 11 IAPR C PATT REC, VB, P136; BESAG J, 1986, J R STAT SOC B, V48, P259; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; FRIEDLAND NS, 1992, IEEE T PATTERN ANAL, V14, P770, DOI 10.1109/34.142912; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Grenander U., 1993, GEN PATTERN THEORY; Harrell R. C., 1989, Machine Vision and Applications, V2, P69, DOI 10.1007/BF01212369; JI LA, 1989, PATTERN RECOGN, V22, P519, DOI 10.1016/0031-3203(89)90021-6; MARCHANT J A, 1990, Computers and Electronics in Agriculture, V4, P235, DOI 10.1016/0168-1699(90)90022-H; MARDIA KV, 1994, STAT IMAGE, V2; MARDIA KV, 1995, IMA C P COMPL STOCH, P155; MARDIA KV, 1991, P 23 S INT, P520; MARDIA KV, 1993, STAT IMAGE, V1; NITZBERG M, 1991, FILTERING SEGMENTATI; QIAN W, 1995, 9501 U LEEDS DEP STA; RIGOTSOS I, 1993, P IEEE CVPR 93 LOS A; TILLETT R D, 1991, Computers and Electronics in Agriculture, V6, P191, DOI 10.1016/0168-1699(91)90001-P; VANLIESHOUT MNM, 1994, THESIS U AMSTERDAM	19	27	28	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					1035	1042		10.1109/34.615452	http://dx.doi.org/10.1109/34.615452			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985					2022-12-18	WOS:A1997XX98500009
J	Gruber, M; Hsu, KY				Gruber, M; Hsu, KY			Moment-based image normalization with high noise-tolerance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						moments; image normalization; image centroid; pattern recognition; noise suppression		In this paper the effects of noise with nonzero mean on existing moment-based image normalization methods are studied. Several modifications to reduce noise sensitivity are presented and tested. They involve nonlinear mapping and fractional- and negative-order moments.	NATL CHIAO TUNG UNIV,HSINCHU,TAIWAN	National Yang Ming Chiao Tung University			Hsu, Ken/C-8645-2012					ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087; SHENG Y, 1987, J OPT SOC AM A, V4, P1176, DOI 10.1364/JOSAA.4.001176; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913	6	27	28	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					136	139		10.1109/34.574793	http://dx.doi.org/10.1109/34.574793			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728		Green Published			2022-12-18	WOS:A1997WK72800005
J	Olstad, B; Torp, AH				Olstad, B; Torp, AH			Encoding of a priori information in active contour models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active contours; grammatical encoding; string matching; dynamic programming	CURVATURE	The theory of active contours models the problem of contour recovery as an energy minimization process. The computational solutions based on dynamic programming require that the energy associated with a contour candidate can be decomposed into an integral of local energy contributions. In this paper we propose a grammatical framework that can model different local energy models and a set of allowable transitions between these models. The grammatical encodings are utilized to represent a priori knowledge about the shape of the object and the associated signatures in the underlying images. The variability encountered in numerical experiments is addressed with the energy minimization procedure which is embedded in the grammatical framework. We propose an algorithmic solution that combines a nondeterministic version of the Knuth-Morris-Pratt algorithm for string matching with a time-delayed discrete dynamic programming algorithm for energy minimization. The numerical experiments address practical problems encountered in contour recovery such as noise robustness and occlusion.			Olstad, B (corresponding author), NORWEGIAN UNIV SCI & TECHNOL,DEPT COMP SYST & TELEMAT,N-7034 TRONDHEIM,NORWAY.							Aho A.V., 1986, COMPILERS PRINCIPLES; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; FRIEDLAND N, 1989, IEEE T MED IMAGING, V8, P344, DOI 10.1109/42.41487; GILL A, 1976, APPL ALGEBRA COMPUTE; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; GRENANDER U, 1989, J APPLIED STATISTICS, V16, P207; HE Y, 1991, IEEE T PATTERN ANAL, V13, P1172, DOI 10.1109/34.103276; Hopcroft John E., 1979, INTRO AUTOMATA THEOR; Kass M., 1988, INT J COMPUT VISION, V1, P321; LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733; OLSTAD B, 1993, P 8 SCAND C IM AN SC, V1, P257; OLSTAD B, 1991, P PROGR IMAGE ANAL P, V2, P430; Rabiner L. R., 1986, IEEE ASSP MAGAZI JAN, P4; Sedgewick R., 1983, ALGORITHMS; STORVIK G, 1992, THESIS NORWEGIAN COM; TAN HL, 1991, IEEE T PATTERN ANAL, V14, P3; WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L; WUESCHER DM, 1991, IEEE T PATTERN ANAL, V13, P41, DOI 10.1109/34.67629; YAMADA H, 1988, IEEE T PATTERN ANAL, V10, P731, DOI 10.1109/34.6784	21	27	29	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1996	18	9					863	872		10.1109/34.537341	http://dx.doi.org/10.1109/34.537341			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VK799					2022-12-18	WOS:A1996VK79900001
J	GONG, LG; KULIKOWSKI, CA				GONG, LG; KULIKOWSKI, CA			COMPOSITION OF IMAGE-ANALYSIS PROCESSES THROUGH OBJECT-CENTERED HIERARCHICAL PLANNING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE ANALYSIS; ARTIFICIAL INTELLIGENCE; KNOWLEDGE-BASED SYSTEMS; HIERARCHICAL PLANNING; COMPOSITION OF IMAGE ANALYSIS PROCESSES		This paper presents a new approach to the knowledge-based composition of processes for image interpretation and analysis, Its computer implementation in the VISIPLAN (VISIon PLANner) system provides a way of modeling the composition of image analysis processes within a unified, object-centered hierarchical planning framework, The approach has been tested and shown to be flexible in handling a reasonably broad class of multi-modality biomedical image analysis and interpretation problems, It provides a relatively general design or planning framework, within which problem-specific image analysis and recognition processes can be generated more efficiently and effectively, In this way, generality is gained at the design and planning stages, even though the final implementation stage of interpretation processes is almost invariably problem- and domain-specific.			GONG, LG (corresponding author), RUTGERS STATE UNIV,DEPT COMP SCI,NEW BRUNSWICK,NJ 08903, USA.							ALOIMONOS J, 1989, INTEGRATION VISUAL M; BROOKS RA, 1979, P INT JOINT C ART IN, P105; Chandrasekaran B., 1986, IEEE Expert, V1, P23, DOI 10.1109/MEX.1986.4306977; CLEMENT V, 1993, CVGIP-IMAG UNDERSTAN, V57, P166, DOI 10.1006/ciun.1993.1011; GARVEY D, 1976, SRI117 AI CTR TECHN; GONG L, 1991, 15TH P SCAMC, P465; GONG L, 1992, LCSRTR180 RUTG U TEC; GONG L, 1992, P MEDINFO 92, P628; GONG L, 1992, P SPIE IS T S ELECTR, V1, P416; HWANG SY, 1992, OPT ENG, V31, P1264, DOI 10.1117/12.56186; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; KAPOULEAS I, 1988, MED IMAGING, V2, P429; KOHL C, 1988, P IMAGE UNDERSTANDIN, P538; LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6; Marr D., 1982, VISION; MATSUYAMA T, 1989, COMPUT VISION GRAPH, V48, P22, DOI 10.1016/0734-189X(89)90103-5; MATSUYAMA T, 1985, 9TH P INT JOINT C AR, P908; Minsky M., 2019, FRAMEWORK REPRESENTI; RAYA S, 1989, SPIE VISUAL COMM IMA, V4, P913; Rosenfeld A., 1982, DIGITAL PICTURE PROC; ROSENTHAL DA, 1984, IEEE T PATTERN ANAL, V6, P319, DOI 10.1109/TPAMI.1984.4767524; SACERDOTI ED, 1974, ARTIF INTELL, V5, P115, DOI 10.1016/0004-3702(74)90026-5; SELFRIDGE P, 1981, THESIS U ROCHESTER; STEFIK M, 1980, 80784 STANF U COMP S; WEISS SM, 1991, COMPUTER SYSTEMS THA	25	27	27	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1995	17	10					997	1009		10.1109/34.464563	http://dx.doi.org/10.1109/34.464563			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RX289					2022-12-18	WOS:A1995RX28900006
J	NACKEN, PFM				NACKEN, PFM			A METRIC FOR LINE SEGMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CLUSTERING; FUNCTION SPACES; IMAGE ANALYSIS; LINEAR STRUCTURE; LINE SEGMENTS; METRIC; TOKEN	STRAIGHT-LINES; EXTRACTION	This correspondence presents a metric for describing line segments. This metric measures how well two line segments can be replaced by a single longer one. This depends for example on collinearity and nearness of the line segments. The metric is constructed using a new technique using so-called neighborhood functions. The behavior of the metric depends on the neighborhood function chosen. In this correspondence, an appropriate choice for the case of line segments is presented. The quality of the metric is verified by using it in a simple clustering algorithm that groups line segments found by an edge detection algorithm in an image. The fact that the clustering algorithm can detect long linear structures in an image shows that the metric is a good measure for the groupability of line segments.			NACKEN, PFM (corresponding author), CTR MATH & COMP SCI,AMSTERDAM,NETHERLANDS.							BOLDT M, 1989, IEEE T SYST MAN CYB, V19, P1581, DOI 10.1109/21.44073; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; DIEUDONNE J, 1960, F MODERN ANAL; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; NACKEN PFM, THESIS; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; PRINCEN J, 1990, COMPUT VISION GRAPH, V52, P57, DOI 10.1016/0734-189X(90)90123-D; SAUND E, 1990, IEEE T PATTERN ANAL, V12, P817, DOI 10.1109/34.57672; SCHER A, 1982, PATTERN RECOGN, V15, P85, DOI 10.1016/0031-3203(82)90003-6	10	27	31	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1312	1318		10.1109/34.250848	http://dx.doi.org/10.1109/34.250848			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176					2022-12-18	WOS:A1993MP17600008
J	NISHIDA, H; MORI, S				NISHIDA, H; MORI, S			AN ALGEBRAIC APPROACH TO AUTOMATIC CONSTRUCTION OF STRUCTURAL MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CHARACTER RECOGNITION; INDUCTIVE LEARNING; QUALITATIVE VISION; SHAPE ANALYSIS; STRUCTURAL PATTERN RECOGNITION; STRUCTURAL MODEL		We present an algebraic approach to the inductive learning of structural models and automatic construction of shape prototypes for character recognition on the basis of the algebraic description of curve structure proposed by Nishida and Mori. A class in the structural models is a set of shapes that can be transformed continuously to each other. We consider an algebraic representation of continuous transformation of components of the shape, and give specific properties satisfied by each component in the class. The generalization rules in the inductive learning are specified from the viewpoints of continuous transformation of components and relational structure among the components. The learning procedure generalizes a pair of classes into one class incrementally and hierarchically in terms of the generalization rules. We show experimental results on handwritten numerals.	FUKUSHIMA PREFECTURE GOVT, UNIV PREPARAT OFF, FUKUSHIMA 960, JAPAN		NISHIDA, H (corresponding author), RICOH RES & DEV CTR, ARTIFICIAL INTELLIGENCE RES DEPT, 16-1 SHINEI CHO, KOHOKU KU, YOKOHAMA, KANAGAWA 223, JAPAN.							BAIRD H, 1991, 1ST P INT C DOC AN R, P332; BAIRD HS, 1988, COMPUT VISION GRAPH, V42, P318, DOI 10.1016/S0734-189X(88)80042-2; Bunke H, 2012, STRUCTURED DOCUMENT; DIETTERICH TG, 1981, ARTIF INTELL, V16, P257, DOI 10.1016/0004-3702(81)90002-3; DIETTERICH TG, 1983, MACHINE LEARNING ART, V1, P41, DOI DOI 10.1007/978-3-662-12405-53; Duda R.O., 1973, J ROYAL STAT SOC SER; HARALICK RM, 1980, ARTIF INTELL, V14, P263, DOI 10.1016/0004-3702(80)90051-X; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; KASTURI R, 1992, MACHINE VISION APPLI, V5; LIU CL, 1977, ELEMENTS DISCRETE MA; MICHALSKI RS, 1983, MACHINE LEARNING ART, V1, P41; Nash C., 1983, TOPOLOGY GEOMETRY PH; NISHIDA H, 1992, IEEE T PATTERN ANAL, V14, P516, DOI 10.1109/34.134057; NISHIDA H, 1992, STRUCTURED DOCUMENT, P139; NISHIDA H, 1992, PIXELS FEATURES, V3, P29; NISHIDA H, 1991, 1ST P INT C DOC AN R, P231; NISHIDA H, 1992, THESIS U TOKYO TOKYO; OGORMAN L, 1992, COMPUTER, V25, P5; PAVLIDIS T, 1992, P IEEE, V80, P1027; PAVLIDIS T, 1990, COMMUNICATION; Pavlidis T., 1977, STRUCTURAL PATTERN R; Quinlan J.R., 1986, MACH LEARN ARTIF INT, V2, P149; SCHROEDER S, 1990, STRUCTURAL PATTERN A, P255; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; SUZUKI T, 1993, INT J PATTERN RECOGN, V7; WINSTON PH, 1975, PSYCHOL COMPUTER VIS, pCH5; YAMAMOTO K, 1980, PATTERN RECOGN, V12, P229, DOI 10.1016/0031-3203(80)90062-X	27	27	27	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1298	1311		10.1109/34.250847	http://dx.doi.org/10.1109/34.250847			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176					2022-12-18	WOS:A1993MP17600007
J	SINHA, RMK; PRASADA, B; HOULE, GF; SABOURIN, M				SINHA, RMK; PRASADA, B; HOULE, GF; SABOURIN, M			HYBRID CONTEXTUAL TEXT RECOGNITION WITH STRING-MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CONTEXT; MODIFIED VITERBI ALGORITHM; OPTICAL CHARACTER RECOGNITION; POST PROCESSING; STRING MATCHING; TEXT RECOGNITION	ALGORITHM; ERRORS	The hybrid contextual algorithm presented in this paper is designed to read real-life documents printed in varying fonts of any size. The text is typically composed of valid English words, proper nouns, acronyms, abbreviations, and numerals. In addition, word spelling may be corrupted by character misclassifications (due to fragmented, mutilated, or touching characters) or by errors in computing the word boundaries (due to word segmentation errors or word delimiter misclassifications). In this paper, text is recognized progressively in three passes. The first pass is used to generate character hypothesis, the second to generate word hypothesis, and the third to verify the word hypothesis. During the first pass, isolated characters are recognized using a dynamic contour warping classifier. Transient statistical information is collected to accelerate the recognition process and to verify hypotheses in later processing. A transient dictionary consisting of high confidence nondictionary words is constructed in this pass. During the second pass, word-level hypotheses are generated using hybrid contextual text processing. Nondictionary words are recognized using 1) a modified Viterbi algorithm (MVA), 2) a string matching algorithm (SMA) utilizing n grams, 3) special handlers for touching characters, and 4) pragmatic handlers for numerals, punctuation, hyphens, apostrophes, and a prefix/suffix handler. This processing usually generates several word hypothesis. During the third pass, word-level verification occurs. The word hypothesis generated during the second pass are verified using a cost criterion based on statistics (data driven or bottom up) and language heuristics (language driven or top down). The word with minimum cost is adopted. If no word hypothesis is generated in the second pass, the word is corrected using positional n-gram information. The hybrid contextual algorithm was tested on a set of 22 multifont documents of varying quality scanned at 200 dots/in using a facsimile scanner. A character recognition rate of 98% was observed.	BELL NO RES LTD, MONTREAL, PQ, CANADA; UNIV QUEBEC, INRS TELECOMMUNICAT, MONTREAL H3C 3P8, QUEBEC, CANADA; ARTHUR D LITTLE INC, WASHINGTON, DC USA	University of Quebec; Institut national de la recherche scientifique (INRS); University of Quebec Montreal	SINHA, RMK (corresponding author), INDIAN INST TECHNOL, DEPT COMP SCI & ENGN, KANPUR 208016, UTTAR PRADESH, INDIA.							BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; DOSTER W, 1980, 5TH P INT C PATT REC, P853; DUFFIE PK, 1985, THESIS MCGILL U; DUFFIE PK, 1985, BNR TR850105; GOSHTASBY A, 1988, PATTERN RECOGN, V21, P455, DOI 10.1016/0031-3203(88)90005-2; HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830; HARMALKAR S, 1990, 10TH P INT C PATT RE, P758; HULL JJ, 1982, IEEE T PATTERN ANAL, V4, P520, DOI 10.1109/TPAMI.1982.4767297; HULL JJ, 1983, IEEE T PATTERN ANAL, V5, P384, DOI 10.1109/TPAMI.1983.4767408; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; Knuth D, 1973, SORTING SEARCHING AR, V2nd; LANDAU GM, 1988, J COMPUT SYST SCI, V37, P63, DOI 10.1016/0022-0000(88)90045-1; OWALABI O, 1988, FAST APPROX STRING M, V18, P387; PETERSON JL, 1986, COMMUN ACM, V29, P633, DOI 10.1145/6138.6146; PETERSON JL, 1980, COMMUN ACM, V23, P676, DOI 10.1145/359038.359041; SHINGHAL R, 1979, INT J MAN MACH STUD, V11, P201, DOI 10.1016/S0020-7373(79)80017-6; SHINGHAL R, 1982, IEEE T SYST MAN CYB, V12, P573; SHINGHAL R, 1983, PATTERN RECOGN, V16, P261, DOI 10.1016/0031-3203(83)90030-4; SINHA RMK, 1990, PATTERN RECOGN, V23, P497, DOI 10.1016/0031-3203(90)90070-2; SINHA RMK, 1988, PATTERN RECOGN, V21, P463, DOI 10.1016/0031-3203(88)90006-4; TAPPERT CC, 1982, IBM J RES DEV, V26, P765, DOI 10.1147/rd.266.0765; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811	22	27	33	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					915	925		10.1109/34.232077	http://dx.doi.org/10.1109/34.232077			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600005
J	LI, LX; DUNCAN, JH				LI, LX; DUNCAN, JH			3-D TRANSLATIONAL MOTION AND STRUCTURE FROM BINOCULAR IMAGE FLOWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BINOCULAR FLOWS; CORRESPONDENCELESS APPROACH; MOTION ESTIMATION; STEREO MATCHING; STEREO-MOTION FUSION; 3-D VISION		In this paper, image flow fields from parallel stereo cameras are analyzed to determine the relative 3-D translational motion of the camera platform with respect to objects in view and to establish stereo correspondence of features in the left and right images. A two-step procedure is suggested. In the first step, translational motion parameters are determined from linear equations whose coefficients consist of the sums of measured quantities in the two images. Separate equations are developed for cases when measurements of either the full optical flow or the normal flow are available. This computation does not require feature-to-feature correspondence. In addition, no assumption is made about the surfaces being viewed. In the second step of the calculation, with the knowledge of the estimated translational motion parameters, the binocular flow information is used to find features in one image that correspond to given features in the other image. Experimental results with synthetic and laboratory images indicate that the method gives accurate results even in the presence of noise.	UNIV MARYLAND,CTR AUTOMAT RES,COLL PK,MD 20742; UNIV MARYLAND,DEPT MECH ENGN,COLL PK,MD 20742	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park			Duncan, James H/FVY-7148-2022	Duncan, James H/0000-0003-3740-9881				ALOIMONOS J, 1986, P IEEE C COMPUT VISI; BALASUBRAMANYAM P, 1988, P DARPA IMAGE UNDERS; BALLARD DH, 1983, CVGIP, V22; BARRON JL, 1987, 1ST P INT JOINT C CO; BASU A, 1987, CARTR279 U MAR COMP; BUXTON BF, 1984, 6TH P EUR C ART INT; CARLSSON S, 1987, P WORKSHOP COMPUT VI; DUNCAN JH, 1989, CARTR452 U MAR COMP; GEIGER D, 1987, INT JOINT C COMP VIS; HORN BKP, 1987, 1ST P INT C COMP VIS; Huang L., 1984, LINEAR ALGEBRA SYSTE; HUANG TS, 1985, P IEEE CVPR; KIM YC, 1987, IEEE J ROBOTICS AUTO, V3; MUTCH KM, 1986, IEEE T PATT ANAL MAC, V8; SCHUNCK BG, 1989, IEEE T PATT ANAL MAC, V11; VARMA V, 1990, CARTR508 U MAR COMP; WAXMAN AM, 1986, IEEE T PATT ANAL MAC, V8; WAXMAN AM, 1984, CARTR24 U MAR COMP V; WAXMAN AM, 1984, 58 U MAR CTR AUT RES	19	27	28	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1993	15	7					657	667		10.1109/34.221167	http://dx.doi.org/10.1109/34.221167			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LM185					2022-12-18	WOS:A1993LM18500001
J	COWELL, RG; DAWID, AP; SPIEGELHALTER, DJ				COWELL, RG; DAWID, AP; SPIEGELHALTER, DJ			SEQUENTIAL MODEL CRITICISM IN PROBABILISTIC EXPERT SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							GRAPHICAL STRUCTURES; LIKELIHOOD	Probabilistic expert systems based on Bayesian networks require initial specification of both qualitative graphical structure and quantitative conditional probability assessments. As (possibly incomplete) data accumulate on real cases, the parameters of the system may adapt, but it is also essential that the initial specifications are monitored with respect to their predictive performance. We present a range of monitors based on standardized scoring rules that are designed to detect both qualitative and quantitative departures from the specified model. A simulation study demonstrates the efficacy these monitors at uncovering such departures.	MRC,BIOSTAT UNIT,CAMBRIDGE,ENGLAND; CITY UNIV LONDON,LONDON EC1V 0HB,ENGLAND	MRC Biostatistics Unit; City University London	COWELL, RG (corresponding author), UNIV LONDON UNIV COLL,DEPT STAT SCI,LONDON WC1E 6BT,ENGLAND.							ANDERSEN SK, 1989, 11TH P INT JOINT C A, P1080; COOPER G, IN PRESS MACHINE LEA; Cowell R., 1992, BAYESIAN STATISTICS, V4, P595; Cowell R. G., 1992, Statistics and Computing, V2, P37, DOI 10.1007/BF01890547; COWELL RG, 1992, CALCULATING MOMENTS; Dawid A. P., 1992, Statistics and Computing, V2, P25, DOI 10.1007/BF01890546; DAWID AP, 1984, J ROY STAT SOC A STA, V147, P278, DOI 10.2307/2981683; DAWID AP, 1991, J ROY STAT SOC B MET, V53, P79; Dawid AP., 1986, ENCY STAT SCI, P210, DOI DOI 10.1002/0471667196.ESS2064.PUB2; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; EDWARDS D, 1987, J AM STAT ASSOC, V82, P205, DOI 10.2307/2289155; Glymour C., 1987, DISCOVERING CAUSAL S; Jensen F. V., 1990, Computational Statistics Quarterly, V5, P269; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LAURITZEN SL, 1991, R9105 AALB U I EL SY; MURPHY AH, 1984, J AM STAT ASSOC, V79, P489, DOI 10.2307/2288395; PEARL J, 1991, 2ND P INT C PRINC KN, P441; Pearl J, 1988, PROBABILISTIC INFERE; SEILLIERMOISEIW.F, IN PRESS J AM STAT A; SEILLIERMOISEIWITSCH F, 1992, SCAND J STAT, V19, P45; Spiegelhalter D. J., 1992, BAYESIAN STAT, V4, P447; SPIEGELHALTER DJ, 1991, MRC914 BIOST UN TECH; SPIEGELHALTER DJ, IN PRESS STAT SCI; THIESSON B, 1991, THESIS AALBORG U DEN	26	27	31	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					209	219		10.1109/34.204903	http://dx.doi.org/10.1109/34.204903			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800003
J	EGGERT, D; BOWYER, K				EGGERT, D; BOWYER, K			COMPUTING THE PERSPECTIVE PROJECTION ASPECT GRAPH OF SOLIDS OF REVOLUTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ASPECT GRAPH; CHARACTERISTIC VIEWS; GENERALIZED CYLINDERS; IMAGE STRUCTURE GRAPH; SOLIDS OF REVOLUTION; VIEWPOINT SPACE PARTITION	CURVED OBJECTS	A number of researchers have recently described algorithms for computing different versions of the aspect graph for various classes of objects. This paper presents the first (only) implemented algorithm to compute the aspect graph for a class of curved-surface objects based on an exact parcellation of 3-D viewpoint space. The object class considered is solids of revolution. A detailed analysis of the visual events for this object class is given, as well as an algorithm to construct the aspect graph. Numerical search techniques, based on a geometric interpretation of the visual events, have been devised to determine those visual event surfaces that cannot be calculated directly. The worst-case complexity of the number of cells in the parcellation of 3-D viewpoint space, and, hence, the number of nodes in the aspect graph, is O(N4), where N is the degree of a polynomial that defines the object shape. A summary of the results for 20 different object descriptions is presented, along with a detailed example for a flower vase. The implementation (in C, using X-windows) is available to interested research groups.			EGGERT, D (corresponding author), UNIV S FLORIDA,DEPT COMP SCI & ENGN,TAMPA,FL 33620, USA.		MA, Lei/I-4597-2014	Bowyer, Kevin/0000-0002-7562-4390				BOWYER K, 1989, MAY P IM UND WORKSH, P831; Bowyer K. W., 1990, International Journal of Imaging Systems and Technology, V2, P315, DOI 10.1002/ima.1850020407; Callahan J., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P240; CHAKRAVARTY I, 1982, P SOC PHOTO-OPT INST, V336, P37, DOI 10.1117/12.933609; CHEN S, 1990, 10TH P INT C PATT RE, P77; EGGERT D, 1991, THESIS U S FLORIDA; EGGERT D, 1989, NOV P IEEE WORKSH IN, P102; KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KRIEGMAN DJ, 1990, INT J COMPUT VISION, V5, P119, DOI 10.1007/BF00054918; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; NALWA VS, 1988, IEEE T PATTERN ANAL, V10, P514, DOI 10.1109/34.3914; PONCE J, 1987, INT J COMPUT VISION, V1, P195, DOI 10.1007/BF00127820; PONCE J, 1990, 8TH P NAT C ART INT, P1074; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; RIEGER JH, 1987, IMAGE VISION COMPUT, V5, P91, DOI 10.1016/0262-8856(87)90033-3; RIEGER JH, 1992, INT J COMPUT VISION, V7, P171, DOI 10.1007/BF00126392; RIEGER JH, 1990, ARTIF INTELL, V44, P1, DOI 10.1016/0004-3702(90)90097-J; SALLAM M, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P636; Shafer S. A., 1985, SHADOWS SILHOUETTES; SRIPRADISVARAKU.T, 1989, NOV P IEEE WORKSH IN, P109	22	27	28	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					109	128		10.1109/34.192483	http://dx.doi.org/10.1109/34.192483			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KL910					2022-12-18	WOS:A1993KL91000002
J	YAMAMOTO, M; BOULANGER, P; BERALDIN, JA; RIOUX, M				YAMAMOTO, M; BOULANGER, P; BERALDIN, JA; RIOUX, M			DIRECT ESTIMATION OF RANGE FLOW ON DEFORMABLE SHAPE FROM A VIDEO RATE RANGE CAMERA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DYNAMIC SCENE ANALYSIS; DIRECT METHOD; NONRIGID MOTION; RANGE CAMERA; RANGE FLOW; RANGE IMAGE SEQUENCE; VIDEO RATE	RIGID BODY MOTION; PARAMETERS; IMAGES; DEPTH	This correspondence describes a method capable of estimating range flow (space displacement vector field) on nonrigid as well as rigid objects from a sequence of range images. This method can directly estimate the deformable motion parameters by solving a system of linear equations that are obtained from substituting a linear transformation of nonrigid objects expressed by the Jacobian matrix into motion constraints based on an extension of the conventional scheme used in intensity image sequence. The range flow is directly computed by substituting these estimated motion parameters in the linear transformation. The algorithm is supported by experimental estimations of range flow on a sheet of paper, a piece of cloth, human skin, and a rubber balloon being inflated, using real range image sequences acquired by a video rate range camera.	NATL RES COUNCIL,INST INFORMAT TECHNOL,AUTONOMOUS SYST LAB,OTTAWA K1A 0R6,ON,CANADA	National Research Council Canada	YAMAMOTO, M (corresponding author), NIIGATA UNIV,DEPT INFORMAT ENGN,NIIGATA 95021,JAPAN.							ASADA M, 1985, 9TH P IJCAI, P895; BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; Barr A. H., 1984, Computers & Graphics, V18, P21; BENSON KB, 1986, TELEVISION ENG HDB; BERALDIN JA, 1990, NOV P VIS 90 DETR; BERALDIN JA, IN PRESS APPLIED OPT; CAFFORIO C, 1976, IEEE T INFORM THEORY, V22, P573, DOI 10.1109/TIT.1976.1055602; CHEN SS, 1986, COMPUT VISION GRAPH, V36, P175, DOI 10.1016/0734-189X(86)90075-7; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; HORN BKP, 1991, CVGIP-IMAG UNDERSTAN, V53, P1, DOI 10.1016/1049-9660(91)90001-6; JASINSCHI R, 1989, J OPT SOC AM A, V6, P1085; KEHTARNAVAZ N, 1989, COMPUT VISION GRAPH, V45, P88, DOI 10.1016/0734-189X(89)90072-8; KOENDERINK JJ, 1986, J OPT SOC AM A, V3, P242, DOI 10.1364/JOSAA.3.000242; Paul R. P., 1981, ROBOT MANIPULATORS M; RIOUX M, 1984, APPL OPTICS, V23, P3837, DOI 10.1364/AO.23.003837; SUBBARAO M, 1989, IEEE T PATTERN ANAL, V11, P266, DOI 10.1109/34.21796; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; ULLMAN S, 1984, PERCEPTION, V13, P255, DOI 10.1068/p130255; YAMAMOTO M, 1989, IEEE T PATTERN ANAL, V11, P528, DOI 10.1109/34.24785; Yamamoto M., 1985, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ68D, P562; YAMAMOTO M, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P460	22	27	27	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1993	15	1					82	89		10.1109/34.184776	http://dx.doi.org/10.1109/34.184776			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KH085					2022-12-18	WOS:A1993KH08500006
J	FRIEDLAND, NS; ROSENFELD, A				FRIEDLAND, NS; ROSENFELD, A			COMPACT OBJECT RECOGNITION USING ENERGY-FUNCTION-BASED OPTIMIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						MARKOV RANDOM FIELD; OBJECT DETECTION; OBJECT RECOGNITION; SIMULATED ANNEALING	IMAGES	This paper describes a method of recognizing objects whose contours can be represented in smoothly varying polar coordinate form. Both low- and high-level information about the object (contour smoothness and edge sharpness at the low level and contour shape at the high level) are incorporated into a single energy function that defines a 1-D, cyclic, Markov random field (1DCMRF). This 1DCMRF is based on a polar coordinate object representation whose center can be initialized at any location within the object. The recognition process is based on energy function minimization, which is implemented by simulated annealing.			FRIEDLAND, NS (corresponding author), UNIV MARYLAND, CTR AUTOMAT RES, COLLEGE PK, MD 20742 USA.							BAUM EB, IN PRESS DISCRETE MA; FRIEDLAND N, 1989, IEEE T MED IMAGING, V8, P344, DOI 10.1109/42.41487; FUA P, 1989, P DARPA IMAGE UNDERS, P676; FUA P, 1989, P DARPA IMAGE UNDERS, P443; GALLAGHER RG, 1972, INFORMATION THEORY R, P80; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Ising E, 1925, Z PHYS, V31, P253, DOI 10.1007/BF02980577; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KIRKPATRICK S, 1982, IBM RC9355 RES REP; Kornfeld G. H., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V781, P63, DOI 10.1117/12.940534; MARGALIT A, 1988, CSTR2050 U MARYL CEN; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; ROSENFELD A, 1982, KIGITAL PICTURE PROC, V2, P270; THOMPSON CJ, 1972, MATH STATISTICAL MEC	14	27	29	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1992	14	7					770	777		10.1109/34.142912	http://dx.doi.org/10.1109/34.142912			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JB675					2022-12-18	WOS:A1992JB67500005
J	NISHIDA, H; MORI, S				NISHIDA, H; MORI, S			ALGEBRAIC DESCRIPTION OF CURVE STRUCTURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CHARACTER RECOGNITION; CURVE DESCRIPTION; FEATURE EXTRACTION; SHAPE ANALYSIS; SHAPE DESCRIPTION; STRUCTURAL DESCRIPTION	HANDPRINTED CHARACTERS; PATTERN-RECOGNITION; SHAPE; REPRESENTATION; FEATURES	We propose a compact and concise description method of curves in terms of the quasi-topological features and the structure of each singular point. By quasi-topological features, we mean the convexity, loop, and connectivity. The quasi-topological structure is analyzed in a hierarchical way, and algebraic structure is presented explicitly on each representation level. The lower level representations are integrated into the higher level one in the systematic way. When a curve has singular points (branch points), the curve is decomposed into components, where each is a simple arc or a simple closed curve by decomposing each singular point. The description scheme is applied to character recognition.			NISHIDA, H (corresponding author), RICOH RES & DEV CTR, YOKOHAMA, JAPAN.							BAIRD HS, 1988, COMPUT VISION GRAPH, V42, P318, DOI 10.1016/S0734-189X(88)80042-2; COX CH, 1982, PATTERN RECOGN, V15, P11, DOI 10.1016/0031-3203(82)90056-5; FU KS, 1983, IEEE T PATTERN ANAL, V5, P200; FU KS, 1986, IEEE T PATTERN ANAL, V8, P343, DOI 10.1109/TPAMI.1986.4767796; FU KS, 1982, SYNTACTIC PATTERN RE; HARALICK RM, 1980, ARTIF INTELL, V14, P263, DOI 10.1016/0004-3702(80)90051-X; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HULL JJ, 1990, FRONTIERS HANDWRITIN, P117; JAKUBOWSKI R, 1986, INFORM SCIENCES, V39, P129, DOI 10.1016/0020-0255(86)90030-7; JAKUBOWSKI R, 1985, IEEE T SYST MAN CYB, V15, P642, DOI 10.1109/TSMC.1985.6313442; KOBAYASHI K, 1981, IECE PRL8133 TECH RE; KOVALEVSKY VA, 1969, P IFIP C 68, P1603; LEDLEY RS, 1965, OPTICAL ELECTROOPTIC; LEGAULT R, 1990, FRONTIERS HANDWRITIN, P181; LIAO CW, 1990, PATTERN RECOGN, V23, P475, DOI 10.1016/0031-3203(90)90068-V; Mangasarian L., 1969, NONLINEAR PROGRAMMIN; MEDIONI G, 1987, COMPUT VISION GRAPH, V39, P267, DOI 10.1016/S0734-189X(87)80181-0; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; MORI S, 1982, COMPUT VISION GRAPH, V19, P349, DOI 10.1016/0146-664X(82)90021-1; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; MORI S, 1986, FUNDAMENTALS IMAGE R, V1; MORI S, 1979, RES ELECTROTECHN LAB, V798; MORI S, 1981, T IECE JAPAN     AUG, P705; NISHIDA H, 1991, 1ST P INT C DOC AN R, P231; NISHIDA H, 1990, JUN P IAPR WORKSH SY, P310; NISHIDA H, 1992, STRUCTURED DOCUMENT; NISHIDA H, 1991, 2ND P INT WORKSH FRO, P57; PAVLIDIS T, 1986, COMPUT VISION GRAPH, V35, P111, DOI 10.1016/0734-189X(86)90128-3; PAVLIDIS T, 1972, FRONTIERS PATTERNS R; PAVLIDIS T, 1980, IEEE T PATT ANAL MAC, V2; Pavlidis T., 1977, STRUCTURAL PATTERN R; SAKAUCHI M, 1985, ANN REP CFE I IND SC, P146; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SHAW AC, 1969, INFORM CONTROL, V14, P9, DOI 10.1016/S0019-9958(69)90017-5; SIMON JC, 1992, STRUCTURED DOCUMENT; Suen C Y, 1990, FRONTIERS HANDWRITIN, P131; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; SUZUKI T, 1990, JUN TECH REP IEICE J; SUZUKI T, 1990, FRONTIERS HANDWRITIN, P39; TSAI WH, 1985, IEEE T PATTERN ANAL, V7, P453, DOI 10.1109/TPAMI.1985.4767684; YAMAMOTO K, 1980, PATTERN RECOGN, V12, P229, DOI 10.1016/0031-3203(80)90062-X	41	27	29	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1992	14	5					516	533		10.1109/34.134057	http://dx.doi.org/10.1109/34.134057			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HR650					2022-12-18	WOS:A1992HR65000002
J	KIRYATI, N; BRUCKSTEIN, AM				KIRYATI, N; BRUCKSTEIN, AM			WHATS IN A SET OF POINTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						HOUGH TRANSFORM; LEAST SQUARES; LINE FITTING; LINEAR REGRESSION; M-ESTIMATORS; ROBUST REGRESSION	HOUGH TRANSFORM	The problem of fitting a straight line to a planar set of points is reconsidered. A parameter space computational approach capable of fitting one or more lines to a set of points is presented. The suggested algorithm handles errors in both coordinates of the data points, even when the error variances vary between coordinates and among points and can be readily made robust to outliers. The algorithm is quite general and allows line fitting according to several useful optimality criteria to be performed within a single computational framework. It is observed that certain extensions of the Hough transform can be tuned to be equivalent to well-known M estimators, thus allowing computationally efficient approximate M estimation.	TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,HAIFA,ISRAEL	Technion Israel Institute of Technology	KIRYATI, N (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,HAIFA,ISRAEL.			Kiryati, Nahum/0000-0003-1436-2275				BARNETT V, 1984, OUTLIERS STATISTICAL; BROWN ML, 1982, J AM STAT ASSOC, V77, P71, DOI 10.2307/2287771; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Goodall C., 1983, UNDERSTANDING ROBUST; HAMPEL FR, 1986, ROBUST STATISTICS AP; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; KAMGARPARSI B, 1987, CARTR315 U MAR CENT; KIM DY, 1989, 1989 P IM UND WORKSH; KIRYATI N, 1991, IEEE T PATTERN ANAL, V13, P602, DOI 10.1109/34.87346; KIRYATI N, 1991, 6TH P IAPR SCAND C I, V53, P213; Li G., 1985, EXPLORING DATA TABLE, V281, pU340; MADANSKY A, 1959, J AM STAT ASSOC, V54, P173, DOI 10.2307/2282145; MOSTELLER F, 1985, EXPLORING DATA TABLE; NIBLACK W, 1988, JUN P IEEE COMP SOC, P574; READ BC, 1989, AM J PHYS, V57, P642; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; THRIFT PR, 1983, COMPUT VISION GRAPH, V21, P383, DOI 10.1016/S0734-189X(83)80050-4; WEISS I, 1989, IEEE T PATTERN ANAL, V11, P325, DOI 10.1109/34.21801; YORK D, 1966, CAN J PHYS, V44, P1079, DOI 10.1139/p66-090	20	27	28	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1992	14	4					496	500		10.1109/34.126810	http://dx.doi.org/10.1109/34.126810			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HL193					2022-12-18	WOS:A1992HL19300008
J	CHEN, MH; LEE, D; PAVLIDIS, T				CHEN, MH; LEE, D; PAVLIDIS, T			RESIDUAL ANALYSIS FOR FEATURE DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CORRELATION; IMAGE FEATURE DETECTION; RESIDUAL IMAGE ANALYSIS; ZERO CROSSING	EDGE-DETECTION	Images are considered as consisting of three parts: features, noise, and smooth components. After a smoothing operation, the difference between the result and the original image has the characteristics of noise in areas away from features. Systematic trends in the difference indicate features such as edges, corners, or textured areas. We show that the autocorrelation function of the residuals takes specific forms when computed along various paths, and in particular along a circle or a disk centered at a zero crossing of residuals. Then feature detection is reduced to classifying the autocorrelation profile.	SUNY STONY BROOK, DEPT COMP SCI, IMAGE ANAL LAB, STONY BROOK, NY 11794 USA; AT&T BELL LABS, COMP SCI RES CTR, MURRAY HILL, NJ 07974 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; AT&T; Nokia Corporation; Nokia Bell Labs	CHEN, MH (corresponding author), SUNY STONY BROOK, DEPT ELECT ENGN, STONY BROOK, NY 11794 USA.							BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHEN MH, 1989, RESIDUAL ANAL FEATUR; CHOW Y, 1988, HANDS PATTERN THEORE; DUBES RC, 1989, APPL STATIST, V16, P131; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; Healy G., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P460, DOI 10.1109/CCV.1988.590024; Horn B., 1986, ROBOT VISION, P1; KANDU A, 1989, JUN P IEEE COMP VIS, P11; Lee D., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P215, DOI 10.1109/CVPR.1988.196239; LEE D, 1987, 1ST P INT C COMP VIS, P572; LU Y, 1989, IEEE T PATTERN ANAL, V11, P337, DOI 10.1109/34.19032; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARR D, 1981, VISION COMPUTATIONAL; MUMFORD D, 1985, JUN P IEEE COMP VIS, P22; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; Papoulis A., 2002, PROBABILITY RANDOM V; PAVLIDIS T, 1979, P IEEE, V67, P737, DOI 10.1109/PROC.1979.11323; Pavlidis T., 1989, From Pixels to Features. Proceedings of a Workshop, P219; Pavlidis T., 1977, STRUCTURAL PATTERN R; POWELL MJD, 1970, NUMERICAL APPROXIMAT, P65; Rangarajan K., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P90, DOI 10.1109/CCV.1988.589975; Serra J., 1982, IMAGE ANAL MATH MORP; Simon J.-C., 1989, From Pixels to Features. Proceedings of a Workshop, P229; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807	27	27	32	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1991	13	1					30	40		10.1109/34.67628	http://dx.doi.org/10.1109/34.67628			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EX773					2022-12-18	WOS:A1991EX77300003
J	KRISHNAPURAM, R; CASASENT, D				KRISHNAPURAM, R; CASASENT, D			DETERMINATION OF 3-DIMENSIONAL OBJECT LOCATION AND ORIENTATION FROM RANGE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CARNEGIE MELLON UNIV,CTR EXCELLENCE OPT DATA PROC,DEPT ELECT & COMP ENGN,PITTSBURGH,PA 15213	Carnegie Mellon University	KRISHNAPURAM, R (corresponding author), UNIV MISSOURI,DEPT ELECT & COMP ENGN,COLUMBIA,MO 65211, USA.							AUGUSTEIJN MF, 1986, COMPUT VISION GRAPH, V36, P76, DOI 10.1016/S0734-189X(86)80030-5; BALLARD DH, 1983, IEEE T PATTERN ANAL, V5, P653, DOI 10.1109/TPAMI.1983.4767456; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; BOLLE RM, 1986, IEEE T PATTERN ANAL, V8, P619, DOI 10.1109/TPAMI.1986.4767836; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CASASENT D, 1987, PATTERN RECOGN, V20, P181, DOI 10.1016/0031-3203(87)90052-5; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; GASSON PC, 1983, GEOMETRY SPATIAL FOR; GRIMSON WEL, 1983, INT J ROBOT RES, V3, P3; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; IKEUCHI K, 1981, 7TH P INT JOINT C AR, P595; KRISHNAPURAM R, 1987, APPL OPTICS, V26, P3641, DOI 10.1364/AO.26.003641; KRISHNAPURAM R, 1987, COMPUT VISION GRAPH, V38, P299, DOI 10.1016/0734-189X(87)90115-0; KRISHNAPURAM R, 1988, APPL OPTICS, V27, P3451, DOI 10.1364/AO.27.003451; KRISHNAPURAM R, 1987, THESIS CARNEGIE MELL; LARROWE V, 1986, 3 D SENSORS; MILENKOVIC V, 1986, TECHNIQUES 3D MACHIN, P231; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; OSHIMA M, 1983, IEEE T PATTERN ANAL, V5, P353, DOI 10.1109/TPAMI.1983.4767405; Paul R. P., 1981, ROBOT MANIPULATORS M; PENTLAND A, 1986, SRI406 INT TECH REP; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; SHIRAI Y, 1983, COMPUT GRAPH, V7, P269, DOI 10.1016/0097-8493(83)90021-3; SILBERBERG TM, 1986, COMPUT VISION GRAPH, V35, P47, DOI 10.1016/0734-189X(86)90125-8; SILBERBERG TM, 1984, PATTERN RECOGN, V17, P621, DOI 10.1016/0031-3203(84)90015-3	27	27	30	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1158	1167		10.1109/34.42854	http://dx.doi.org/10.1109/34.42854			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796					2022-12-18	WOS:A1989AW79600003
J	SHRIKHANDE, N; STOCKMAN, G				SHRIKHANDE, N; STOCKMAN, G			SURFACE ORIENTATION FROM A PROJECTED GRID	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824	Michigan State University	SHRIKHANDE, N (corresponding author), CENT MICHIGAN UNIV,CTR COMP VIS & ROBOT RES,DEPT COMP SCI,MOUNT PLEASANT,MI 48858, USA.							ASADA M, 1988, IEEE T PATTERN ANAL, V10, P749, DOI 10.1109/34.6787; Bajcsy R., 1976, COMPUT GRAPHICS IMAG, V5, P52, DOI DOI 10.1016/S0146-664X(76)80005-6; Ballard D.H., 1982, COMPUTER VISION; Caponetti L., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P407; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; HALL EL, 1982, COMPUTER, V15, P42; Horn B., 1986, ROBOT VISION, P1; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; HU G, 1986, P CVPR 86, P602; IKEUCHI K, 1984, ARTIF INTELL, V22, P49, DOI 10.1016/0004-3702(84)90025-0; KENDER J, 1975, NOV P DARPA IM UND W, P14; NAGEL HH, 1981, P IEEE C PATTERN REC, P103; RAY R, 1983, IEEE T PATTERN ANAL, V5, P631, DOI 10.1109/TPAMI.1983.4767454; SHRIKHANDE N, 1988, MSUENGR88009 TECH RE; WANG YF, 1987, IEEE T PATTERN ANAL, V9, P129, DOI 10.1109/TPAMI.1987.4767878; WILL PM, 1971, ARTIF INTELL, V2, P319, DOI 10.1016/0004-3702(71)90015-4	16	27	30	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1989	11	6					650	655		10.1109/34.24799	http://dx.doi.org/10.1109/34.24799			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U6749					2022-12-18	WOS:A1989U674900010
J	LITTLE, JJ; BLELLOCH, GE; CASS, TA				LITTLE, JJ; BLELLOCH, GE; CASS, TA			ALGORITHMIC TECHNIQUES FOR COMPUTER VISION ON A FINE-GRAINED PARALLEL MACHINE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)	LITTLE, JJ (corresponding author), UNIV BRITISH COLUMBIA,DEPT COMP SCI,VANCOUVER V6T 1W5,BC,CANADA.							AGGARWAL A, 1985, P 25 ANN S FDN COMP, P468; Atallah M. J., 1985, Proceedings of the 1985 International Conference on Parallel Processing (Cat. No.85CH2140-2), P411; ATALLAH MJ, 1987, P IEEE S F COMPUTER, P151; ATHAS WC, 1988, IEEE COMPUTER    AUG, P9; Blelloch G. E., 1988, Proceedings of the 1988 International Conference on Parallel Processing, P218; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CASS TA, 1988, THESIS MIT CAMBRIDGE; CLEMENS DT, 1986, THESIS MIT CAMBRIDGE; CORPORATION TM, 1987, LISP REFERENCE MANUA; CYPHER R, 1987, 1987 COMP SOC WORKSH, P122; CYPHER R, 1987, 1987 P WORKSH COMP A, P5; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; GILLETT W, UNPUB LEARNING STERE; GOTTLIEB A, 1983, ACM T PROGRAM LANGUA, V5; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; Hillis W., 1985, CONNECTION MACHINE; HILLIS WD, 1986, COMMUN ACM, V29, P1170, DOI 10.1145/7902.7903; Hummel R., 1986, Intermediate-level image processing, P101; JEONG C, 1987, 8702FC01 NW U TECH R; KRUSKAL CP, 1985, 1985 P INT C PAR PRO, P180; LEE DT, 1980, J ACM, V27, P604, DOI 10.1145/322217.322219; LEE DT, 1980, SIAM J COMPUT, V9, P200, DOI 10.1137/0209017; Lim W., 1986, NA862 THINK MACH COR; Little J. J., 1982, Proceedings of the Workshop on Computer Vision: Representation and Control, P178; LITTLE JJ, 1986, MIT AI928 ART INT LA; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MILLER R, 1985, IEEE T PATTERN ANAL, V7, P216, DOI 10.1109/TPAMI.1985.4767645; MILLER R, 1987, SIAM J COMPUT, V16, P38, DOI 10.1137/0216004; NASSIMI D, 1980, SIAM J COMPUT, V9, P744, DOI 10.1137/0209058; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; SHILOACH Y, 1982, J ALGORITHM, V3, P57, DOI 10.1016/0196-6774(82)90008-6; STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4; VOORHEES, 1987, JUN P INT C COMP VIS; VOORHEES, IEEE WASHINGTON, P250; Wyllie J., 1978, P 10 ANN ACM S THEOR, P114, DOI [10.1145/800133.804339, DOI 10.1145/800133.804339]; WYLLIE JC, 1979, 79387 CORN U DEP COM	39	27	27	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					244	257		10.1109/34.21793	http://dx.doi.org/10.1109/34.21793			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840					2022-12-18	WOS:A1989T384000004
J	STEPHANOU, HE; LU, SY				STEPHANOU, HE; LU, SY			MEASURING CONSENSUS EFFECTIVENESS BY A GENERALIZED ENTROPY CRITERION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									EXXON PROD RES CO,DIV LONG RANGE RES,HOUSTON,TX 77001	Exxon Mobil Corporation	STEPHANOU, HE (corresponding author), GEORGE MASON UNIV,SCH INFORMAT TECHNOL & ENGN,DEPT ELECT & COMP ENGN,FAIRFAX,VA 22030, USA.							BARNETT JA, 1981, 7TH P INT JOINT C AR, P868; DEMPSTER AP, 1968, J ROY STAT SOC B, V30, P205; DUDA RO, 1976, AM FEDERATION INFORM, V45, P1075; ERKMEN AM, 1987, OCT P IEEE INT C SYS; GARVEY TD, 1981, 7TH P INT JOINT C AR, P319; ISHIZUKA M, 1981, TREE8133 PURD U TECH; LOWRANCE JD, 1983, 307 SRI INT TECH NOT; LU SY, 1984, AUG P NAT C ART INT; PRADE H, 1985, IEEE T PATTERN ANAL, V7, P260, DOI 10.1109/TPAMI.1985.4767656; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; Shortliffe E.H., 2012, COMPUTER BASED MED C; WALTZ EL, 1986, IEEE T SYST MAN CYB, V16, P865, DOI 10.1109/TSMC.1986.4309005; YAGER RR, 1983, INT J GEN SYST, V9, P249, DOI 10.1080/03081078308960825	13	27	28	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1988	10	4					544	554		10.1109/34.3916	http://dx.doi.org/10.1109/34.3916			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	P1493					2022-12-18	WOS:A1988P149300009
J	COHEN, Y; LANDY, MS; PAVEL, M				COHEN, Y; LANDY, MS; PAVEL, M			HIERARCHICAL CODING OF BINARY IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									STANFORD UNIV,DEPT PSYCHOL,STANFORD,CA 94305; NYU,DEPT PSYCHOL,HUMAN INFORMAT PROC LAB,NEW YORK,NY 10003	Stanford University; New York University	COHEN, Y (corresponding author), NATL INST TESTING & EVALUAT,JERUSALEM,ISRAEL.			Landy, Michael/0000-0002-2079-4552				BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; DYER CR, 1982, COMPUT VISION GRAPH, V19, P335, DOI 10.1016/0146-664X(82)90020-X; DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838; GARGANTINI I, 1984, PATTERN RECOGN, V17, P285, DOI 10.1016/0031-3203(84)90078-5; GARGANTINI I, 1982, COMPUT VISION GRAPH, V20, P365, DOI 10.1016/0146-664X(82)90058-2; GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741; GROSKY WI, 1983, IEEE T PATTERN ANAL, V5, P77, DOI 10.1109/TPAMI.1983.4767348; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; HUNTER GM, 1979, COMPUT VISION GRAPH, V10, P289, DOI 10.1016/0146-664X(79)90008-X; HUNTER GM, 1978, THESIS PRINCETON U P; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; Jones L., 1981, PRIP81, P57; KAWAGUCHI E, 1980, IEEE T PATTERN ANAL, V2, P27, DOI 10.1109/TPAMI.1980.4766967; KLINGER A, 1979, IEEE T PATTERN ANAL, V1, P50, DOI 10.1109/TPAMI.1979.4766875; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; KNOWLTON K, 1980, P IEEE, V68, P885, DOI 10.1109/PROC.1980.11754; LANDY MS, 1984, COMPUT VISION GRAPH, V25, P331, DOI 10.1016/0734-189X(84)90199-3; LANDY MS, 1984, BEHAV RES METH INS C, V16, P199, DOI 10.3758/BF03202390; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; ROSENFELD A, 1982, IEEE T SYST MAN CYB, V12, P401; SAMET H, 1981, IEEE T PATTERN ANAL, V3, P93, DOI 10.1109/TPAMI.1981.4767054; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836; SAMET H, 1980, 5TH P INT C PATT REC, P815; SHAPIRO LG, 1979, COMPUT VISION GRAPH, V11, P162, DOI 10.1016/0146-664X(79)90065-0; SLOAN KR, 1979, IEEE T COMPUT, V28, P871, DOI 10.1109/TC.1979.1675269; SPERLING G, 1980, SCIENCE, V210, P797, DOI 10.1126/science.7433998; SPERLING G, 1981, IEEE T COMMUN, V29, P1993, DOI 10.1109/TCOM.1981.1094953; SPERLING G, 1982, PHYSICAL BIOL PROCES; TAMMINEN M, 1983, CVGIP, V21, P160; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; TANIMOTO SL, 1975, THESIS PRINCETON U P; WARNOCK JE, 1969, 415 U UT DEP COMP SC	37	27	28	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	3					284	298		10.1109/TPAMI.1985.4767657	http://dx.doi.org/10.1109/TPAMI.1985.4767657			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AFM44	21869263				2022-12-18	WOS:A1985AFM4400003
J	MOHAMMED, JL; HUMMEL, RA; ZUCKER, SW				MOHAMMED, JL; HUMMEL, RA; ZUCKER, SW			A GRADIENT PROJECTION ALGORITHM FOR RELAXATION METHODS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									MCGILL UNIV,DEPT ELECT ENGN,COMP VIS & ROBOT LAB,MONTREAL H3A 2A7,QUEBEC,CANADA; NYU,COURANT INST MATH SCI,NEW YORK,NY 10012	McGill University; New York University	MOHAMMED, JL (corresponding author), FAIRCHILD CENT RES & DEV,ARTIFICIAL INTELLIGENCE LAB,PALO ALTO,CA 94304, USA.							BERTHOD M, 1980, P IFIP; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Luenberger D. G., 1973, INTRO LINEAR NONLINE; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ZOUTENDIJK G, 1976, MATH PROGRAMMING MET; Zoutendijk G., 1960, METHODS FEASIBLE DIR; ZUCKER SW, 1977, PATTERN RECOGNITION; ZUCKER SW, 1978, MAY P PATT REC IM PR; ZUCKER SW, 1976, 3RD P INT JOINT C PA	10	27	28	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	3					330	332		10.1109/TPAMI.1983.4767394	http://dx.doi.org/10.1109/TPAMI.1983.4767394			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QS785	21869115				2022-12-18	WOS:A1983QS78500007
J	SAYEGH, SI; SALEH, BEA				SAYEGH, SI; SALEH, BEA			IMAGE DESIGN - GENERATION OF A PRESCRIBED IMAGE AT THE OUTPUT OF A BAND-LIMITED SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV WISCONSIN,DEPT ELECT & COMP ENGN,MADISON,WI 53706	University of Wisconsin System; University of Wisconsin Madison								Born M., 1964, PRINCIPLE OPTICS; Frieden BR., 1975, PICTURE PROCESSING D; PAPOULIS A, 1967, PR INST ELECTR ELECT, V55, P1677, DOI 10.1109/PROC.1967.5960; Papoulis A., 1962, FOURIER INTEGRAL ITS; SALEH BEA, 1981, OPT ENG, V20, P781, DOI 10.1117/12.7972810	5	27	27	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	4					441	445		10.1109/TPAMI.1983.4767414	http://dx.doi.org/10.1109/TPAMI.1983.4767414			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RA578	21869129				2022-12-18	WOS:A1983RA57800010
J	TOMITA, F; SHIRAI, Y; TSUJI, S				TOMITA, F; SHIRAI, Y; TSUJI, S			DESCRIPTION OF TEXTURES BY A STRUCTURAL-ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									OSAKA UNIV, DEPT CONTROL ENGN, OSAKA, JAPAN	Osaka University	TOMITA, F (corresponding author), ELECTROTECH LAB, DIV INFORMAT SCI, IBARAKI, JAPAN.							BAJCSY R, 1973, 3RD P INT JOINT C AR, P572; BRODATS P, 1966, TEXTURES; DAVIS LS, 1979, COMPUT VISION GRAPH, V11, P111, DOI 10.1016/0146-664X(79)90061-3; DEGUCHI K, 1978, IEEE T COMPUT, V27, P739, DOI 10.1109/TC.1978.1675181; EHRICH RW, 1978, COMPUT VISION GRAPH, V8, P174, DOI 10.1016/0146-664X(78)90048-5; Galloway MM., 1975, COMPUT GRAPHICS IMAG, V4, DOI DOI 10.1016/S0146-664X(75)80008-6; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; JULESZ B, 1975, SCI AM, V232, P34, DOI 10.1038/scientificamerican0475-34; KAIZER H, 1955, AD69484; Lipkin BS, 1970, PICTURE PROCESSING P; LU SY, 1978, COMPUT VISION GRAPH, V7, P303, DOI 10.1016/S0146-664X(78)80001-X; LU SY, 1979, COMPUT VISION GRAPH, V9, P234, DOI 10.1016/0146-664X(79)90039-X; MALESON JT, 1977, OCT P DARPA IM UND W, P19; MARR D, 1975, AI340 MASS I TECHN M; MITCHELL OR, 1977, IEEE T COMPUT, V26, P408, DOI 10.1109/TC.1977.1674850; Nagao M., 1976, 3rd International Joint Conference on Pattern Recognition, P669; NEVATIA R, 1979, 6TH P INT JOINT C AR, P642; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PICKETT RM, 1970, PICTURE PROCESSING P, P289; Rao C.R, 1964, SANKHYA, V22, P317; READ JS, 1972, IEEE T COMPUT, VC 21, P803, DOI 10.1109/T-C.1972.223585; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; TOMITA F, 1973, 3RD P INT JOINT C AR, P564; TSUJI S, 1973, COMPUTER GRAPHICS IM, V2, P216; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; WESZKA JS, 1976, PATTERN RECOGN, V8, P195, DOI 10.1016/0031-3203(76)90039-X	27	27	27	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					183	191		10.1109/TPAMI.1982.4767225	http://dx.doi.org/10.1109/TPAMI.1982.4767225			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869024				2022-12-18	WOS:A1982NE95700014
J	JAIN, R				JAIN, R			EXTRACTION OF MOTION INFORMATION FROM PERIPHERAL PROCESSES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											JAIN, R (corresponding author), WAYNE STATE UNIV,DEPT COMP SCI,DETROIT,MI 48202, USA.							AGGARWAL JK, 1975, IEEE T COMPUT      C, V24, P1066; BADLER N, 1975, 80 U TOR DEP COMP TE; BARNARD ST, 1978, JUN P IEEE C PATT RE, P402; CHIEN RT, 1975, 1975 IJCAI TBIL GEOR; FENNEMA CL, 1978, VELOCITY DETERMINATI; Gibson J., 1979, ECOLOGICAL APPROACH; HOGG DC, 1977, 77 P IJCAI, P627; JAIN R, 1979, COMPUT VISION GRAPH, V11, P13, DOI 10.1016/0146-664X(79)90074-1; JAIN R, 1978, 48 U HAMB TECH REP; JAIN R, 1979, ADV FUZZY SET THEORY; JAIN R, 1979, NOV P MICOM WORKSH I; JAIN R, 1979, IEEE T PATTERN  PAMI, V1; JAIN R, 1977, 77 P IJCAI, P614; MARTIN WN, 1979, PATTERN RECOGN, V11, P169, DOI 10.1016/0031-3203(79)90004-9; MARTIN WN, 1978, COMPUT VISION GRAPH, V7, P356, DOI 10.1016/S0146-664X(78)80003-3; NAGEL HH, 1978, 1978 IJCPR KY JAP; NAGEL HH, 1979, APR IEEE WORKSH TIM; ONOE M, 1973, COMPUTER GRAPHICS IM, V2, P377; POTTER JL, 1977, COMPUT VISION GRAPH, V6, P558, DOI 10.1016/S0146-664X(77)80016-6; PRAGER JM, 1979, COIN797 U MASS TECH; ROACH J, 1979, IEEE T PATTERN ANAL, V1; SEKULAR R, 1975, HDB PERCEPTION SEEIN, V5; STEVENS KA, 1977, MIT AI AIM3102 MEM; TSOTSOS JK, 1976, 103 U TOR DEP COMP T; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; UNO T, 1976, PATTERN RECOG, V8, P261; VONFIENDT K, 1977, PERCEPTUAL WORLD; WARD MR, 1979, GMR21014 GEN MOT RES; YACHIDA M, 1978, 1978 IJCPR KY JAP; 1979, APR WORKSH COMP AN T	30	27	29	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	5					489	503		10.1109/TPAMI.1981.4767143	http://dx.doi.org/10.1109/TPAMI.1981.4767143			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ358	21868970				2022-12-18	WOS:A1981MQ35800001
J	RAGHAVAN, VV; YU, CT				RAGHAVAN, VV; YU, CT			A COMPARISON OF THE STABILITY CHARACTERISTICS OF SOME GRAPH THEORETIC CLUSTERING METHODS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV ILLINOIS,DEPT INFORMAT ENGN,CHICAGO,IL 60638	University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	RAGHAVAN, VV (corresponding author), UNIV REGINA,DEPT COMP SCI,REGINA S4S 0A2,SASKATCHEWAN,CANADA.							Ball G. H., 1965, P NOV 30 DEC 1 196 1, P533; BONNER RE, 1964, IBM J RES DEV, V8, P22, DOI 10.1147/rd.81.0022; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; CORNEIL DG, 1978, INFOR, V16, P74; DAY WHE, 1977, MATH BIOSCI, V36, P299, DOI 10.1016/0025-5564(77)90053-0; DEO N, 1974, GRAPH THEORY APPLICA, P22; GOTLIEB CC, 1968, J ACM, V15, P493; Harary F., 1994, GRAPH THEORY; HUBERT LJ, 1974, PSYCHOMETRIKA, V39, P283, DOI 10.1007/BF02291704; JACKSON DM, 1969, SOFTWARE ENG COINS, V2, P71; JACKSON DM, 1969, NUMERICAL TAXONOMY, P91; JARDINE N, 1968, Mathematical Biosciences, V2, P465, DOI 10.1016/0025-5564(68)90030-8; JARDINE N, 1968, COMPUT J, V11, P177, DOI 10.1093/comjnl/11.2.177; Jardine N., 1971, MATH TAXONOMY; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; LANCE GN, 1967, COMPUT J, V9, P373, DOI 10.1093/comjnl/9.4.373; LANCE GN, 1967, COMPUT J, V10, P271, DOI 10.1093/comjnl/10.3.271; LING RF, 1972, COMPUT J, V15, P326, DOI 10.1093/comjnl/15.4.326; MATULA DW, 1977, ADV SEMINAR CLASSIFI, P95; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; SOKAL ROBERT R., 1962, TAXON, V11, P33, DOI 10.2307/1217208; VASWANI PKT, 1968, INFORMATION PROCESSI, V68, P1300; WATANABE S, 1972, INFORMATION PROCESSI, P149; YU CT, 1976, J AM SOC INFORM SCI, V27, P248, DOI 10.1002/asi.4630270410; YU CT, 1974, J AM SOC INFORM SCI, V25, P218, DOI 10.1002/asi.4630250403; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	26	27	27	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					393	402		10.1109/TPAMI.1981.4767125	http://dx.doi.org/10.1109/TPAMI.1981.4767125			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	MQ357	21868960				2022-12-18	WOS:A1981MQ35700004
J	RAO, K; BALCK, K				RAO, K; BALCK, K			TYPE CLASSIFICATION OF FINGERPRINTS - A SYNTACTIC APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											RAO, K (corresponding author), LINKOPING UNIV,DEPT ELECT ENGN,S-58183 LINKOPING,SWEDEN.							BALCK K, 1976, LIHISYI102 LINK U DE; CRONSTROM S, 1976, LIHISYI0057 LINK U D; Fu K.S., 1974, MATH SCI ENG; GRASSELLI A, 1969, METHODOLOGIES PATTER, P253; HANKLEY WJ, 1968, PICTORIAL PATTERN RE, P411; KRUSE B, 1973, IEEE T COMPUT, VC 22, P1075, DOI 10.1109/T-C.1973.223653; MOAYER B, 1976, IEEE T COMPUT, V25, P262, DOI 10.1109/TC.1976.5009253; MOAYER B, 1976, PATTERN RECOGN, V8, P173, DOI 10.1016/0031-3203(76)90018-2; MOAYER B, 1975, PATTERN RECOGN, V7, P1, DOI 10.1016/0031-3203(75)90011-4; RAO CVK, 1978, IEEE T COMPUT, V27, P77; WEGSTEIN JH, 1968, NBS466 TECH NOT	11	27	30	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	3					223	231		10.1109/TPAMI.1980.4767009	http://dx.doi.org/10.1109/TPAMI.1980.4767009			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR843	21868895				2022-12-18	WOS:A1980JR84300003
J	Gao, Y; Zhang, ZZ; Lin, HJ; Zhao, XB; Du, SY; Zou, CQ				Gao, Yue; Zhang, Zizhao; Lin, Haojie; Zhao, Xibin; Du, Shaoyi; Zou, Changqing			Hypergraph Learning: Methods and Practices	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Learning systems; Correlation; Data models; Laplace equations; Three-dimensional displays; Brain modeling; Task analysis; Hypergraph learning; hypergraph generation; hypergraph learning tool; tensor-based dynamic hypergraph learning; classification and clustering	RECOGNITION; NETWORKS	Hypergraph learning is a technique for conducting learning on a hypergraph structure. In recent years, hypergraph learning has attracted increasing attention due to its flexibility and capability in modeling complex data correlation. In this paper, we first systematically review existing literature regarding hypergraph generation, including distance-based, representation-based, attribute-based, and network-based approaches. Then, we introduce the existing learning methods on a hypergraph, including transductive hypergraph learning, inductive hypergraph learning, hypergraph structure updating, and multi-modal hypergraph learning. After that, we present a tensor-based dynamic hypergraph representation and learning framework that can effectively describe high-order correlation in a hypergraph. To study the effectiveness and efficiency of hypergraph generation and learning methods, we conduct comprehensive evaluations on several typical applications, including object and action recognition, Microblog sentiment prediction, and clustering. In addition, we contribute a hypergraph learning development toolkit called THU-HyperG.	[Gao, Yue; Zhang, Zizhao; Lin, Haojie; Zhao, Xibin] Tsinghua Univ, BNRist, KLISS, Sch Software, Beijing 100084, Peoples R China; [Gao, Yue; Zhang, Zizhao] Tsinghua Univ, THUIBCS, Beijing 100084, Peoples R China; [Du, Shaoyi] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Coll Artificial Intelligence, Xian 710049, Shaanxi, Peoples R China; [Zou, Changqing] Sun Yat Sen Univ, Guangzhou 510275, Peoples R China	Tsinghua University; Tsinghua University; Xi'an Jiaotong University; Sun Yat Sen University	Zou, CQ (corresponding author), Sun Yat Sen Univ, Guangzhou 510275, Peoples R China.	kevin.gaoy@gmail.com; zhangziz18@mails.tsinghua.edu.cn; linhj18@mails.tsinghua.edu.cn; zxb@tsinghua.edu.cn; dushaoyi@gmail.com; aaronzou1125@gmail.com			National Key R&D Program of China [2017YFC0113000]	National Key R&D Program of China	This work was supported by the National Key R&D Program of China (Grant No. 2017YFC0113000).	Aksoy S, 2019, P HICSS S CYB BIG DA; Amato F, 2019, INFORMATION, V10, DOI 10.3390/info10060183; Birgin EG, 2000, SIAM J OPTIMIZ, V10, P1196, DOI 10.1137/S1052623497330963; Cao XC, 2015, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2015.7298657; Chen F, 2015, 2015 IEEE 6TH INTERNATIONAL SYMPOSIUM ON MICROWAVE, ANTENNA, PROPAGATION, AND EMC TECHNOLOGIES (MAPE), P1, DOI 10.1109/MAPE.2015.7510253; Diamond S, 2016, J MACH LEARN RES, V17; Du DW, 2017, IEEE T CYBERNETICS, V47, P4182, DOI 10.1109/TCYB.2016.2626275; Fang Q, 2014, IEEE T MULTIMEDIA, V16, P796, DOI 10.1109/TMM.2014.2298216; Fang YC, 2017, IEEE IMAGE PROC, P3440; Feng Y., 2018, P AAAI C ART INT; Feng YF, 2019, AAAI CONF ARTIF INTE, P3558; Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035; Franzese N, 2019, PLOS COMPUT BIOL, V15, DOI [10.1371/journal.pcbi.1007384, 10.1371/journal.pcbi.1007384.r001, 10.1371/journal.pcbi.1007384.r002, 10.1371/journal.pcbi.1007384.r003, 10.1371/journal.pcbi.1007384.r004]; Gao Y, 2015, LECT NOTES COMPUT SC, V9350, P78, DOI 10.1007/978-3-319-24571-3_10; Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502; Grover A, 2019, PR MACH LEARN RES, V97; Huang S, 2015, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2015.7298638; Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012; Huang YC, 2009, PROC CVPR IEEE, P1738, DOI 10.1109/CVPRW.2009.5206795; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Ji RR, 2019, IEEE T MULTIMEDIA, V21, P1062, DOI 10.1109/TMM.2018.2867718; Ji RR, 2014, IEEE T GEOSCI REMOTE, V52, P1811, DOI 10.1109/TGRS.2013.2255297; Ji SY, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2020, DOI 10.1145/3394486.3403253; Jiang JW, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2635; Jiang JW, 2019, AAAI CONF ARTIF INTE, P8513; Jin TS, 2019, INFORM SCIENCES, V501, P708, DOI 10.1016/j.ins.2019.03.012; Kipf Thomas N., 2016, ARXIV161107308, V2, P1; Kipf Thomas N., 2017, P ICLR; Klamt S, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000385; Kurakin A, 2012, EUR SIGNAL PR CONF, P1975; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li D, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P41; Liu QS, 2017, IEEE T IMAGE PROCESS, V26, P452, DOI 10.1109/TIP.2016.2621671; Lun ZL, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130841; Luo FL, 2019, IEEE T CYBERNETICS, V49, P2406, DOI 10.1109/TCYB.2018.2810806; Martinet LE, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16285-7; Oliphant TE., 2006, A GUIDE TO NUMPY; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16; Ramadan E, 2010, P 1 ACM INT C BIOINF, P556; Rozemberczki B., 2019, MULTISCALE ATTRIBUTE; Shao W, 2020, COMPUT MED IMAG GRAP, V80, DOI 10.1016/j.compmedimag.2019.101663; Sporns O, 2011, ANN NY ACAD SCI, V1224, P109, DOI 10.1111/j.1749-6632.2010.05888.x; Su LF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2779; Tian Z, 2009, BIOINFORMATICS, V25, P2831, DOI 10.1093/bioinformatics/btp467; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62; Wang M, 2015, IEEE T KNOWL DATA EN, V27, P2564, DOI 10.1109/TKDE.2015.2415497; Weichselbraun A, 2014, KNOWL-BASED SYST, V69, P78, DOI 10.1016/j.knosys.2014.04.039; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Xiao L, 2020, IEEE T MED IMAGING, V39, P1746, DOI 10.1109/TMI.2019.2957097; Xie JY, 2016, PR MACH LEARN RES, V48; Xu GL, 2018, IEEE INT VEH SYM, P734; Yang DQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2147, DOI 10.1145/3308558.3313635; You JX, 2018, PR MACH LEARN RES, V80; Zhang ZZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3162; Zhang ZZ, 2018, IEEE T IMAGE PROCESS, V27, P5957, DOI 10.1109/TIP.2018.2862625; Zhao W, 2018, IEEE T NEUR NET LEAR, V29, P5834, DOI 10.1109/TNNLS.2018.2812888; Zheng X, 2019, GENE, V706, P188, DOI 10.1016/j.gene.2019.04.060; Zhou D., 2007, P INT C NEUR INF PRO; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389; Zu C, 2016, LECT NOTES COMPUT SC, V10019, P1, DOI 10.1007/978-3-319-47157-0_1	66	26	26	44	69	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2548	2566		10.1109/TPAMI.2020.3039374	http://dx.doi.org/10.1109/TPAMI.2020.3039374			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33211654				2022-12-18	WOS:000792921400025
J	Deng, X; Dragotti, PL				Deng, Xin; Dragotti, Pier Luigi			Deep Convolutional Neural Network for Multi-Modal Image Restoration and Fusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image fusion; Task analysis; Image restoration; Convolutional codes; Image reconstruction; Convolutional neural networks; Image coding; Multi-modal image restoration; image fusion; multi-modal convolutional sparse coding		In this paper, we propose a novel deep convolutional neural network to solve the general multi-modal image restoration (MIR) and multi-modal image fusion (MIF) problems. Different from other methods based on deep learning, our network architecture is designed by drawing inspirations from a new proposed multi-modal convolutional sparse coding (MCSC) model. The key feature of the proposed network is that it can automatically split the common information shared among different modalities, from the unique information that belongs to each single modality, and is therefore denoted with CU-Net, i.e., common and unique information splitting network. Specifically, the CU-Net is composed of three modules, i.e., the unique feature extraction module (UFEM), common feature preservation module (CFPM), and image reconstruction module (IRM). The architecture of each module is derived from the corresponding part in the MCSC model, which consists of several learned convolutional sparse coding (LCSC) blocks. Extensive numerical results verify the effectiveness of our method on a variety of MIR and MIF tasks, including RGB guided depth image super-resolution, flash guided non-flash image denoising, multi-focus and multi-exposure image fusion.	[Deng, Xin; Dragotti, Pier Luigi] Imperial Coll London, Dept Elect & Elect Engn, London SW7 2BU, England	Imperial College London	Deng, X (corresponding author), Imperial Coll London, Dept Elect & Elect Engn, London SW7 2BU, England.	x.deng16@imperial.ac.uk; p.dragotti@imperial.ac.uk		Dragotti, Pier Luigi/0000-0002-6073-2807	CSA-Imperial Scholarship	CSA-Imperial Scholarship	CSA-Imperial Scholarship for funding.	Aksoy Y., 2018, P EUR C COMP VIS, P634; Blau Y., 2018, PROC CVPR IEEE, P6228, DOI DOI 10.1109/CVPR.2018.00652; Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281; Butler D. J., 2012, LECT NOTES COMPUT SC, P611; Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218; Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534; Dabov K, 2008, PROC SPIE, V6812, DOI 10.1117/12.766355; Daniel E, 2018, IEEE SENS J, V18, P6804, DOI 10.1109/JSEN.2018.2822712; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Deng X, 2020, IEEE T CIRC SYST VID, V30, P2447, DOI 10.1109/TCSVT.2019.2923901; Deng X, 2020, IEEE T IMAGE PROCESS, V29, P1683, DOI 10.1109/TIP.2019.2944270; Dong C., 2016, LECT NOTES COMPUT SC, P391, DOI DOI 10.1007/978-3-319-46475-6_25; Ferstl D., 2015, IEEE I CONF COMP VIS, P513, DOI DOI 10.1109/ICCV.2015.66; Gatys L. A., 2016, PROC CVPR IEEE, P2414, DOI DOI 10.1109/CVPR.2016.265; Gu S., 2017, PROC CVPR IEEE, P3769, DOI DOI 10.1109/CVPR.2017.83; Gu S., 2017, IEEE I CONF COMP VIS, P1708, DOI DOI 10.1109/ICCV.2017.189; Gu S., 2015, IEEE I CONF COMP VIS, P1823, DOI DOI 10.1109/ICCV.2015.212; Gu SH, 2020, IEEE T PATTERN ANAL, V42, P2437, DOI 10.1109/TPAMI.2019.2961672; Guo CL, 2019, IEEE T IMAGE PROCESS, V28, P2545, DOI 10.1109/TIP.2018.2887029; Guo XJ, 2020, IEEE T PATTERN ANAL, V42, P694, DOI 10.1109/TPAMI.2018.2883553; Ham B, 2018, IEEE T PATTERN ANAL, V40, P192, DOI 10.1109/TPAMI.2017.2669034; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2010, LECT NOTES COMPUT SC, V6311, P1; Hirschmuller H., 2007, 2007 IEEE C COMP VIS, P1; Hu JW, 2012, INFORM FUSION, V13, P196, DOI 10.1016/j.inffus.2011.01.002; Jang JH, 2012, IEEE T IMAGE PROCESS, V21, P3479, DOI 10.1109/TIP.2012.2197014; Jevnisek R. J., 2017, PROC CVPR IEEE, P3184, DOI DOI 10.1109/CVPR.2017.406; Johnson J., 2016, LECT NOTES COMPUT SC, P694, DOI DOI 10.1007/978-3-319-46475-6_43; Kim B., 2019, ARXIV191008373; Kim J., 2016, PROC CVPR IEEE, P1646, DOI DOI 10.1109/CVPR.2016.182; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183; Kwon H., 2015, PROC CVPR IEEE, P159; Lahoud F., 2018, P EUR C COMP VIS, P35; Lai W.-S., 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618; Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342; Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004; Li YJ, 2019, IEEE T PATTERN ANAL, V41, P1909, DOI 10.1109/TPAMI.2018.2890623; Li YJ, 2016, LECT NOTES COMPUT SC, V9908, P154, DOI 10.1007/978-3-319-46493-0_10; Li Z., 2019, PROC CVPR IEEE, P3867, DOI DOI 10.1109/CVPR.2019.00399; Lim B., 2017, IEEE COMPUT SOC CONF, P136, DOI DOI 10.1109/CVPRW.2017.151; Liu D, 2016, IEEE T IMAGE PROCESS, V25, P3194, DOI 10.1109/TIP.2016.2564643; Liu W, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2612826; Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001; Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776; Lohit S., 2019, INT CONF ACOUST SPEE, P7725; Lu J., 2015, PROC CVPR IEEE, P2245; Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004; Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138; Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921; Ma Z., 2013, IEEE I CONF COMP VIS, P49, DOI DOI 10.1109/ICCV.2013.13; Marivani I., 2019, IEEE IMAGE PROC, P2891; Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004; Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010; Pan J., 2019, PROC CVPR IEEE, P1702, DOI DOI 10.1109/CVPR.2019.00180; Papyan V, 2017, J MACH LEARN RES, V18, P1; Park J., 2011, IEEE I CONF COMP VIS, P1623; Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231; Prabhakar K. R., 2017, IEEE I CONF COMP VIS, P4724, DOI DOI 10.1109/ICCV.2017.505; Riegler G., 2016, PROC BRIT MACH VIS C; Shen X., 2015, IEEE I CONF COMP VIS, P3406, DOI DOI 10.1109/ICCV.2015.389; Shen XY, 2015, IEEE T PATTERN ANAL, V37, P2518, DOI 10.1109/TPAMI.2015.2417569; Shi Z., 2018, P EUR C COMP VIS; Song PF, 2020, IEEE T COMPUT IMAG, V6, P57, DOI 10.1109/TCI.2019.2916502; Song X., 2016, LECT NOTES COMPUT SC, P360, DOI DOI 10.1007/978-3-319-54190-7_22; Song XB, 2019, IEEE T CIRC SYST VID, V29, P2323, DOI 10.1109/TCSVT.2018.2866399; Sreter H., 2018, 2018 IEEE INT C AC, P2191; Summers D, 2003, J NEUROL NEUROSUR PS, V74, P288, DOI 10.1136/jnnp.74.3.288; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wei Q, 2015, IEEE T GEOSCI REMOTE, V53, P3658, DOI 10.1109/TGRS.2014.2381272; Wen Y, 2019, IEEE T IMAGE PROCESS, V28, P994, DOI 10.1109/TIP.2018.2874285; Wohlberg B, 2016, IEEE T IMAGE PROCESS, V25, P301, DOI 10.1109/TIP.2015.2495260; Xie J, 2016, IEEE T IMAGE PROCESS, V25, P428, DOI 10.1109/TIP.2015.2501749; Yan Q., 2013, IEEE I CONF COMP VIS, P1537, DOI DOI 10.1109/ICCV.2013.194; Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001; Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811; Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778; Zhang J., 2018, PROC CVPR IEEE, P1838, DOI DOI 10.1109/CVPR.2018.00197; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53; Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012	81	26	26	16	78	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3333	3348		10.1109/TPAMI.2020.2984244	http://dx.doi.org/10.1109/TPAMI.2020.2984244			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32248098	Green Submitted			2022-12-18	WOS:000692232400009
J	Lu, ZC; Sreekumar, G; Goodman, E; Banzhaf, W; Deb, K; Boddeti, VN				Lu, Zhichao; Sreekumar, Gautam; Goodman, Erik; Banzhaf, Wolfgang; Deb, Kalyanmoy; Boddeti, Vishnu Naresh			Neural Architecture Transfer	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional neural networks; neural architecture search; AutoML; transfer learning; evolutionary algorithms		Neural architecture search (NAS) has emerged as a promising avenue for automatically designing task-specific neural networks. Existing NAS approaches require one complete search for each deployment specification of hardware or objective. This is a computationally impractical endeavor given the potentially large number of application scenarios. In this paper, we propose Neural Architecture Transfer (NAT) to overcome this limitation. NAT is designed to efficiently generate task-specific custom models that are competitive under multiple conflicting objectives. To realize this goal we learn task-specific supernets from which specialized subnets can be sampled without any additional training. The key to our approach is an integrated online transfer learning and many-objective evolutionary search procedure. A pre-trained supernet is iteratively adapted while simultaneously searching for task-specific subnets. We demonstrate the efficacy of NATon 11 benchmark image classification tasks ranging from large-scale multi-class to small-scale fine-grained datasets. In all cases, including ImageNet, NATNets improve upon the state-of-the-art under mobile settings (<= 600M Multiply-Adds). Surprisingly, small-scale fine-grained datasets benefit the most from NAT. At the same time, the architecture search and transfer is orders ofmagnitude more efficient than existing NASmethods. Overall, experimental evaluation indicates that, across diverse image classification tasks and computational objectives, NAT is an appreciably more effective alternative to conventional transfer learning of fine-tuning weights of an existing network architecture learned on standard datasets. Code is available at https://github.com/human-analysis/neural-architecture-transfer	[Lu, Zhichao] Southern Univ Sci & Technol, Shenzhen 518055, Guangdong, Peoples R China; [Sreekumar, Gautam; Goodman, Erik; Banzhaf, Wolfgang; Deb, Kalyanmoy; Boddeti, Vishnu Naresh] Michigan State Univ, E Lansing, MI 48824 USA	Southern University of Science & Technology; Michigan State University	Boddeti, VN (corresponding author), Michigan State Univ, E Lansing, MI 48824 USA.	luzc@sustech.edu.cn; sreekum1@msu.edu; goodman@msu.edu; banzhafw@msu.edu; kdeb@msu.edu; vishnu@msu.edu	Lu, Zhichao/AAX-8657-2021; Sreekumar, Gautam/AAW-5152-2021; Deb, Kalyanmoy/B-1563-2009	Sreekumar, Gautam/0000-0003-4677-8240; Deb, Kalyanmoy/0000-0001-7402-9939; Goodman, Erik/0000-0002-2419-0692	National Science Foundation [DBI-0939454]	National Science Foundation(National Science Foundation (NSF))	This work was supported by the National Science Foundation under Cooperative Agreement No. DBI-0939454. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.	Baker B., 2017, ARXIV170510823; Bender G, 2018, PR MACH LEARN RES, V80; Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925; Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29; BRACKEN J, 1973, OPER RES, V21, P37, DOI 10.1287/opre.21.1.37; Brock A., 2018, ICLR, P1; Cai H., 2020, ICLR, P1; Cai Han, 2019, INT C LEARN REPR; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chu Xiangxiang, 2021, ARXIV190701845, P12239; Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461; Coates Adam, 2011, AISTATS, V6, DOI DOI 10.1177/1753193410390845; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359; Darlow L. N., 2018, CINIC 10 IS NOT IMAG; Das I, 1998, SIAM J OPTIMIZ, V8, P631, DOI 10.1137/S1052623496307510; Deb K., 1995, Complex Systems, V9, P115; Deb K, 2014, IEEE T EVOLUT COMPUT, V18, P577, DOI 10.1109/TEVC.2013.2281535; Elsken Thomas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12362, DOI 10.1109/CVPR42600.2020.01238; Elsken Thomas, 2019, INT C LEARN REPR; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fang J., ARXIV190105884; Gesmundo A., 2019, ARXIV190205781; Goyal P., 2017, LARGE MINIBATCH SGD; Guan Melody, 2018, ICML, P4095; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Howard A.G, 2017, ARXIV170404861; Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39; Jiahui Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P702, DOI 10.1007/978-3-030-58571-6_41; Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Krizhevsky Alex., 2009, LEARNING MULTIPLE LA, P6; Le Q. V., 2019, P BMVC, P74; Li Liam, 2019, ABS190207638 CORR; Li Yingwei, 2020, CVPR; Lian Dongze, 2020, INT C LEARN REPR; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2; Liu Hanxiao, 2018, ICLR; Liu Hanxiao, 2019, INTERNATIONAL CONFER; Lu ZC, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P419, DOI 10.1145/3321707.3321729; Maji S., 2013, TECH REP; Mei Jieru, 2020, ICLR; Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Real E, 2017, PR MACH LEARN RES, V70; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Sun YN, 2020, IEEE T EVOLUT COMPUT, V24, P350, DOI 10.1109/TEVC.2019.2924461; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan M., 2020, P IEEE ICVF C COMOP, P10781; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2019.00293; Tan MX, 2019, PR MACH LEARN RES, V97; Wan Alvin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12962, DOI 10.1109/CVPR42600.2020.01298; Wang Xiao, 2019, ARXIV191109265; Wistuba M., 2019, ARXIV190708307; Wong Catherine, 2018, ADV NEURAL INFORM PR, V31, P8366; Xie SN, 2019, IEEE I CONF COMP VIS, P1284, DOI 10.1109/ICCV.2019.00137; Yao X, 1999, P IEEE, V87, P1423, DOI 10.1109/5.784219; Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20; Yu Kaicheng, 2020, ICLR; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhichao Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12041, DOI 10.1109/CVPR42600.2020.01206; Zitzler E, 1998, LECT NOTES COMPUT SC, V1498, P292, DOI 10.1007/BFb0056872; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	87	26	26	4	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					2971	2989		10.1109/TPAMI.2021.3052758	http://dx.doi.org/10.1109/TPAMI.2021.3052758			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	33465025	Green Submitted			2022-12-18	WOS:000681124300011
J	Jabi, M; Pedersoli, M; Mitiche, A; Ben Ayed, I				Jabi, Mohammed; Pedersoli, Marco; Mitiche, Amar; Ayed, Ismail Ben			Deep Clustering: On the Link Between Discriminative Models and K-Means	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep clustering; convolutional neural networks; alternating direction methods; k-means; mutual information; Kullback-Leibler (KL) divergence; regularization; multilogit regression	NEURAL-NETWORKS; CUTS	In the context of recent deep clustering studies, discriminative models dominate the literature and report the most competitive performances. These models learn a deep discriminative neural network classifier in which the labels are latent. Typically, they use multinomial logistic regression posteriors and parameter regularization, as is very common in supervised learning. It is generally acknowledged that discriminative objective functions (e.g., those based on the mutual information or the KL divergence) are more flexible than generative approaches (e.g., K-means) in the sense that they make fewer assumptions about the data distributions and, typically, yield much better unsupervised deep learning results. On the surface, several recent discriminative models may seem unrelated to K-means. This study shows that these models are, in fact, equivalent to K-means under mild conditions and common posterior models and parameter regularization. We prove that, for the commonly used logistic regression posteriors, maximizing the L-2 regularized mutual information via an approximate alternating direction method (ADM) is equivalent to minimizing a soft and regularized K-means loss. Our theoretical analysis not only connects directly several recent state-of-the-art discriminative models to K-means, but also leads to a new soft and regularized deep K-means algorithm, which yields competitive performance on several image clustering benchmarks.	[Jabi, Mohammed] Ultra Elect TCS, Montreal, PQ H4T 1V7, Canada; [Pedersoli, Marco; Ayed, Ismail Ben] ETS Montreal, Montreal, PQ H3C 1K3, Canada; [Mitiche, Amar] INRS, Montreal, PQ, Canada	University of Quebec; Ecole de Technologie Superieure - Canada; University of Quebec; Institut national de la recherche scientifique (INRS)	Ben Ayed, I (corresponding author), ETS Montreal, Montreal, PQ H3C 1K3, Canada.	mohammed.jabi.mj@gmail.com; marco.pedersoli@etsmtl.ca; amar.mitiche@emt.inrs.ca; ismail.benayed@etsmtl.ca			NSERC (Natural Sciences and Engineering Research Council of Canada); FRQNT (Fonds de recherche du Quebec Nature et technologies)	NSERC (Natural Sciences and Engineering Research Council of Canada)(Natural Sciences and Engineering Research Council of Canada (NSERC)); FRQNT (Fonds de recherche du Quebec Nature et technologies)	This study was supported by the NSERC (Natural Sciences and Engineering Research Council of Canada) and the FRQNT (Fonds de recherche du Quebec Nature et technologies).	Aljalbout E., 2018, ARXIV180107648; BenAyed I, 2018, P 32 INT C NEUR INF, P10062; BERTSEKAS DP, 1976, SIAM J CONTROL, V14, P216, DOI 10.1137/0314017; Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Boyd S, 2018, EE364B LECT NOTES AL; Boykov Y, 2015, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2015.206; BRIDLE JS, 1992, ADV NEUR IN, V4, P1096; Caron M., 2018, P EUR C COMP VIS, P1692; Csisz I, 2011, INFORM THEORY CODING; Dizaji KG, 2017, IEEE I CONF COMP VIS, P5747, DOI 10.1109/ICCV.2017.612; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Grandvalet Yves, 2004, NIPS, P529; Hu WH, 2017, PR MACH LEARN RES, V70; Jiang ZX, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1965; Kingma D.P, P 3 INT C LEARNING R; Krause Andreas, 2010, ADV NEURAL INFORM PR, V23, P5; Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; Marin D, 2019, IEEE T PATTERN ANAL, V41, P136, DOI 10.1109/TPAMI.2017.2780166; Nair V., 2010, ICML, P807; Narasimhan M., 2005, UAI, P404; Shaham Uri, 2018, ICLR; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Springenberg J. T, 2016, P INT C LEARN REPR, P1965; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Tang M, 2019, INT J COMPUT VISION, V127, P477, DOI 10.1007/s11263-018-1115-1; Taylor G, 2016, PR MACH LEARN RES, V48; Trigeorgis G, 2014, PR MACH LEARN RES, V32, P1692; Valpola H., 2015, ARXIV14117783; Wang JX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P111, DOI 10.1145/3292500.3330936; Xie JY, 2016, PR MACH LEARN RES, V48; Xu W., 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485; Yang B, 2017, PR MACH LEARN RES, V70; Yang JW, 2016, PROC CVPR IEEE, P5147, DOI 10.1109/CVPR.2016.556; Yuan J, 2017, LECT NOTES COMPUT SC, V10302, P524, DOI 10.1007/978-3-319-58771-4_42; Yuille AL, 2002, ADV NEUR IN, V14, P1033; Zhang ZH, 2007, MACH LEARN, V69, P1, DOI 10.1007/s10994-007-5022-x	40	26	26	3	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					1887	1896		10.1109/TPAMI.2019.2962683	http://dx.doi.org/10.1109/TPAMI.2019.2962683			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	31899413	Green Submitted			2022-12-18	WOS:000649590200006
J	Ramesh, B; Yang, H; Orchard, G; Thi, NAT; Zhang, SH; Xiang, C				Ramesh, Bharath; Yang, Hong; Orchard, Garrick; Le Thi, Ngoc Anh; Zhang, Shihao; Xiang, Cheng			DART: Distribution Aware Retinal Transform for Event-Based Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Feature extraction; Object tracking; Object recognition; Shape; Retina; Event-based vision; log-polar grids; bag-of-words model; object recognition; object tracking; feature matching	FEATURES; TRACKING; BAG; CATEGORIZATION	We introduce a generic visual descriptor, termed as distribution aware retinal transform (DART), that encodes the structural context using log-polar grids for event cameras. The DART descriptor is applied to four different problems, namely object classification, tracking, detection and feature matching: (1) The DART features are directly employed as local descriptors in a bag-of-words classification framework and testing is carried out on four standard event-based object datasets (N-MNIST, MNIST-DVS, CIFAR10-DVS, NCaltech-101); (2) Extending the classification system, tracking is demonstrated using two key novelties: (i) Statistical bootstrapping is leveraged with online learning for overcoming the low-sample problem during the one-shot learning of the tracker, (ii) Cyclical shifts are induced in the log-polar domain of the DART descriptor to achieve robustness to object scale and rotation variations; (3) To solve the long-term object tracking problem, an object detector is designed using the principle of cluster majority voting. The detection scheme is then combined with the tracker to result in a high intersection-over-union score with augmented ground truth annotations on the publicly available event camera dataset; (4) Finally, the event context encoded by DART greatly simplifies the feature correspondence problem, especially for spatio-temporal slices far apart in time, which has not been explicitly tackled in the event-based vision domain.	[Ramesh, Bharath] Natl Univ Singapore, Inst Hlth 1, Singapore 119077, Singapore; [Yang, Hong; Orchard, Garrick] Natl Univ Singapore, Temasek Labs, Singapore 119077, Singapore; [Le Thi, Ngoc Anh; Zhang, Shihao; Xiang, Cheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore	National University of Singapore; National University of Singapore; National University of Singapore	Ramesh, B (corresponding author), Natl Univ Singapore, Inst Hlth 1, Singapore 119077, Singapore.	bharath.ramesh03@u.nus.edu; yang.hong@u.nus.edu; garrickorchard@nus.edu.sg; ngocanhlt@u.nus.edu; a0129916@u.nus.edu; elexc@nus.edu.sg						Afshar S, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00212; Alzugaray I, 2018, IEEE ROBOT AUTOM LET, V3, P3177, DOI 10.1109/LRA.2018.2849882; Anandh N, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES FOR SMART NATION (SMARTTECHCON), P1; Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005; [Anonymous], 2005, STUDIES FUZZINESS SO, DOI [DOI 10.1007/B95439, 10.1007/b95439]; Basu A, 2018, IEEE J EM SEL TOP C, V8, P6, DOI 10.1109/JETCAS.2018.2816339; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bone P, 2006, OPT ENG, V45, DOI 10.1117/1.2227362; BRACCINI C, 1982, BIOL CYBERN, V44, P47, DOI 10.1007/BF00353955; Brandli C, 2014, IEEE J SOLID-ST CIRC, V49, P2333, DOI 10.1109/JSSC.2014.2342715; Cohen GK, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00184; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004; Grosso E, 2000, LECT NOTES COMPUT SC, V1842, P299; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hongmin Li, 2016, Advances in Brain-Inspired Cognitive Systems. 8th International Conference, BICS 2016. Proceedings: LNAI 10023, P138, DOI 10.1007/978-3-319-49685-6_13; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kokkinos I., 2008, 2008 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2008.4587798; Lagorce X, 2017, IEEE T PATTERN ANAL, V39, P1346, DOI 10.1109/TPAMI.2016.2574707; Lagorce X, 2015, IEEE T NEUR NET LEAR, V26, P1710, DOI 10.1109/TNNLS.2014.2352401; Lagorce X, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00046; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lee JH, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00508; Lenz G., 2018, CORR; Lin L, 2015, LECT NOTES COMPUT SC, V9008, P473, DOI 10.1007/978-3-319-16628-5_34; Liu HJ, 2016, IEEE INT SYMP CIRC S, P2511, DOI 10.1109/ISCAS.2016.7539103; LIVINGSTONE MS, 1987, J NEUROSCI, V7, P3416; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; MESSNER RA, 1985, COMPUT VISION GRAPH, V31, P50, DOI 10.1016/S0734-189X(85)80075-X; Mueggler E., 2017, P 28 BRIT MACH VIS C; Mueggler E, 2017, INT J ROBOT RES, V36, P142, DOI 10.1177/0278364917691115; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; Nowozin S, 2014, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2014.77; Orchard G, 2015, FRONT NEUROSCI-SWITZ, V9, DOI [10.3389/fhins.2015.00437, 10.3389/fnins.2015.00437]; Orchard G, 2015, IEEE T PATTERN ANAL, V37, P2028, DOI 10.1109/TPAMI.2015.2392947; Peng X, 2017, IEEE T NEUR NET LEAR, V28, P791, DOI 10.1109/TNNLS.2016.2536741; Posch C, 2008, IEEE INT SYMP CIRC S, P2130, DOI 10.1109/ISCAS.2008.4541871; Ramesh B, 2017, PATTERN RECOGN, V67, P380, DOI 10.1016/j.patcog.2017.02.024; Ramesh B, 2017, NEUROCOMPUTING, V230, P88, DOI 10.1016/j.neucom.2016.12.003; Ramesh B., 2019, CORR; Ramesh B, 2015, PATTERN RECOGN, V48, P894, DOI 10.1016/j.patcog.2014.09.019; Rebecq H, 2017, IEEE ROBOT AUTOM LET, V2, P593, DOI 10.1109/LRA.2016.2645143; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Roberts L., 1960, P IRE INT, V48, P66; SANDINI G, 1980, COMPUT VISION GRAPH, V14, P365, DOI 10.1016/0146-664X(80)90026-X; SCHWARTZ EL, 1977, BIOL CYBERN, V25, P181, DOI 10.1007/BF01885636; Serrano-Gotarredona T, 2013, IEEE J SOLID-ST CIRC, V48, P827, DOI 10.1109/JSSC.2012.2230553; Shechtman E, 2007, PROC CVPR IEEE, P1744; Sironi A, 2018, PROC CVPR IEEE, P1731, DOI 10.1109/CVPR.2018.00186; TISTARELLI M, 1995, IMAGE VISION COMPUT, V13, P215, DOI 10.1016/0262-8856(95)90841-U; Valeiras DR, 2015, IEEE T NEUR NET LEAR, V26, P3045, DOI 10.1109/TNNLS.2015.2401834; Vedaldi A, 2010, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2010.5539949; WEIMAN CFR, 1979, COMPUT VISION GRAPH, V11, P197, DOI 10.1016/0146-664X(79)90089-3; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Zhao B, 2015, IEEE T NEUR NET LEAR, V26, P1963, DOI 10.1109/TNNLS.2014.2362542; Zou D., 2017, P BRIT MACH VIS C	57	26	26	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2767	2780		10.1109/TPAMI.2019.2919301	http://dx.doi.org/10.1109/TPAMI.2019.2919301			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NX0AD	31144625	Green Submitted			2022-12-18	WOS:000575381000003
J	Li, LM; Zhang, ZY				Li, Limin; Zhang, Zhenyue			Semi-Supervised Domain Adaptation by Covariance Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Covariance matching; transfer learning; domain adaptation	CLASSIFICATION; KERNEL	Transferring knowledge from a source domain to a target domain by domain adaptation has been an interesting and challenging problem in many machine learning applications. The key problem is how to match the data distributions of the two heterogeneous domains in a proper way such that they can be treated indifferently for learning. We propose a covariance matching approach DACoM for semi-supervised domain adaptation. The DACoM embeds the original samples into a common latent space linearly such that the covariance mismatch of the two mapped distributions is minimized, and the local geometric structure and discriminative information are preserved simultaneously. The KKT conditions of DACoM model are given as a nonlinear eigenvalue equation. We show that the KKT conditions could at least ensure local optimality. An efficient eigen-updating algorithm is then given for solving the nonlinear eigenvalue problem, whose convergence is guaranteed conditionally. To deal with the case when homogeneous information could only be matched nonlinearly, a kernel version of DACoM is further considered. We also analyze the generalization bound for our domain adaptation approaches. Numerical experiments on simulation datasets and real-world applications are given to comprehensively demonstrate the effectiveness and efficiency of the proposed approach. The experiments show that our method outperforms other existing methods for both homogeneous and heterogeneous domain adaptation.	[Li, Limin] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China; [Zhang, Zhenyue] Zhejiang Univ, Sch Math Sci, Hangzhou 310027, Zhejiang, Peoples R China; [Zhang, Zhenyue] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China	Xi'an Jiaotong University; Zhejiang University; Zhejiang University	Zhang, ZY (corresponding author), Zhejiang Univ, Sch Math Sci, Hangzhou 310027, Zhejiang, Peoples R China.; Zhang, ZY (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.	liminli@mail.xjtu.edu.cn; zyzhang@zju.edu.cn			NSFC [11471256, 11571312, 91730303]; National Basic Research Program of China (973 Program) [2015CB352503]	NSFC(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China)	We would like to thank Prof. Karsten Borgwardt from ETH Zurich for valuable discussion, and Ms Hongsha Guo for kindly collecting part of the real datasets. The work was supported by NSFC projects 11471256, 11571312, and 91730303, and National Basic Research Program of China (973 Program) 2015CB352503.	Amini M.R., 2009, ADV NEURAL INFORM PR, P28, DOI DOI 10.5555/2984093.2984097; Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Blitzer J., 2007, ADV NEURAL INFORM PR, V20, P129; Blitzer J., P 45 ANN M ASS COMP, P440, DOI DOI 10.1109/IRPS.2011.5784441; Blitzer J., 2011, PROC INT C ARTIF INT, P173; Bollegala D, 2016, IEEE T KNOWL DATA EN, V28, P398, DOI 10.1109/TKDE.2015.2475761; Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Bullinger L, 2004, NEW ENGL J MED, V350, P1605, DOI 10.1056/NEJMoa031046; Cao XD, 2013, IEEE I CONF COMP VIS, P3208, DOI 10.1109/ICCV.2013.398; Chen M., 2011, ADV NEURAL INF PROCE, P2456; Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921; Dai W, 2008, PROCEEDINGS OF THE 38TH INTERNATIONAL CONFERENCE ON COMPUTERS AND INDUSTRIAL ENGINEERING, VOLS 1-3, P1535; Duan L., 2012, P INT C MACH LEARN, V1, P711; Glorot Xavier, 2011, P 28 INT C MACH LEAR, P513, DOI DOI 10.1177/1753193411430810; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Kumar A., 2010, ADV NEURAL INFORM PR, V23, P478; Long M., 2014, IEEE T KNOWL DATA EN, V26, P1; Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111; Pan S.J., 2008, AAAI; Pan Sinno, 2007, ADAPTIVE LOCALIZATIO, V2, P1108; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Prettenhofer P, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1118; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Shi X, 2010, IEEE IMAGE PROC, P2849, DOI 10.1109/ICIP.2010.5652059; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126; Sugiyama M., 2008, NIPS, P1433; Valk P. J., 2000, NEW ENGL J MED, V350, P1617; Wang C., 2011, P IJCAI, V22, P1541; Wang Hua-Yan, 2011, P AAAI, P513; Warnat P, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-265; Xiao M., 2012, AAAI, P1183; Zheng V. W., 2008, PROC AAAI C ARTIF IN, P1427; Zhu Y., 2011, P 25 AAAI C ART INT	38	26	26	4	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2724	2739		10.1109/TPAMI.2018.2866846	http://dx.doi.org/10.1109/TPAMI.2018.2866846			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30136933				2022-12-18	WOS:000489838200012
J	Duan, YQ; Lu, JW; Wang, ZW; Feng, JJ; Zhou, J				Duan, Yueqi; Lu, Jiwen; Wang, Ziwei; Feng, Jianjiang; Zhou, Jie			Learning Deep Binary Descriptor with Multi-Quantization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Binary descriptor; unsupervised learning; deep learning; competitive learning; multi-quantization; K-Autoencoders	IMAGE DESCRIPTORS; SCALE; CLASSIFICATION; PATTERNS	In this paper, we propose an unsupervised feature learning method called deep binary descriptor with multi-quantization (DBD-MQ) for visual analysis. Existing learning-based binary descriptors such as compact binary face descriptor (CBFD) and DeepBit utilize the rigid sign function for binarization despite of data distributions, which usually suffer from severe quantization loss. In order to address the limitation, we propose a deep multi-quantization network to learn a data-dependent binarization in an unsupervised manner. More specifically, we design a K-Autoencoders (KAEs) network to jointly learn the parameters of feature extractor and the binarization functions under a deep learning framework, so that discriminative binary descriptors can be obtained with a fine-grained multi-quantization. As DBD-MQ simply allocates the same number of quantizers to each real-valued feature dimension ignoring the elementwise diversity of informativeness, we further propose a deep competitive binary descriptor with multi-quantization (DCBD-MQ) method to learn optimal allocation of bits with the fixed binary length in a competitive manner, where informative dimensions gain more bits for complete representation. Moreover, we present a similarity-aware binary encoding strategy based on the earth mover's distance of Autoencoders, so that elements that are quantized into similar Autoencoders will have smaller Hamming distances. Extensive experimental results on six widely-used datasets show that our DBD-MQ and DCBD-MQ outperform most state-of-the-art unsupervised binary descriptors.	[Duan, Yueqi; Lu, Jiwen; Wang, Ziwei; Feng, Jianjiang; Zhou, Jie] Tsinghua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Duan, Yueqi; Lu, Jiwen; Wang, Ziwei; Feng, Jianjiang; Zhou, Jie] Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing 100084, Peoples R China	Tsinghua University	Lu, JW (corresponding author), Tsinghua Univ, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.; Lu, JW (corresponding author), Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing 100084, Peoples R China.	duanyq14@mails.tsinghua.edu.cn; lujiwen@tsinghua.edu.cn; zw-wa14@mails.tsinghua.edu.cn; jfeng@tsinghua.edu.cn; jzhou@tsinghua.edu.cn	Wang, Ziwei/ABD-9344-2020; Lu, Jiwen/C-5291-2009	Duan, Yueqi/0000-0002-1190-6663; Lu, Jiwen/0000-0002-6121-5529	National Key Research and Development Program of China [2017YFA0700802]; National Natural Science Foundation of China [U1713214, 61672306, 61572271, 61527808]; National 1000 Young Talents Plan Program; Shenzhen Fundamental Research Fund (Subject Arrangement) [JCYJ20170412170602564]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National 1000 Young Talents Plan Program; Shenzhen Fundamental Research Fund (Subject Arrangement)	This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFA0700802, in part by the National Natural Science Foundation of China under Grant U1713214, Grant 61672306, Grant 61572271, and Grant 61527808, in part by the National 1000 Young Talents Plan Program, and in part by the Shenzhen Fundamental Research Fund (Subject Arrangement) under Grant JCYJ20170412170602564.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2005, THESIS MIT CAMBRIDGE; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38; Balntas V, 2020, IEEE T PATTERN ANAL, V42, P2825, DOI 10.1109/TPAMI.2019.2915233; Balntas V, 2018, IEEE T PATTERN ANAL, V40, P555, DOI 10.1109/TPAMI.2017.2679193; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Chatfield K., 2015, P BRIT MACH VIS C, P1, DOI DOI 10.1109/CITS.2015.7297761; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183; Duan YQ, 2017, PROC CVPR IEEE, P4857, DOI 10.1109/CVPR.2017.516; Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661; Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981; Fergus R, 2003, PROC CVPR IEEE, P264; Fischer P, 2014, ARXIV14055769; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378; He K, 2018, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2018.00069; Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024; Howard A.G., 2017, MOBILENETS EFFICIENT; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Iandola F.N., 2016, ARXIV; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Jain H, 2017, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2017.96; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227; Liu H, 2017, CHIN CONTR CONF, P390, DOI 10.23919/ChiCC.2017.8027373; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2018, IEEE T PATTERN ANAL, V40, P1979, DOI 10.1109/TPAMI.2017.2737538; Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Parkhi Omkar M., 2015, BRIT MACH VIS C; Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19; Philbin J, 2008, PROC CVPR IEEE, P2285; Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826; Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Shen Y., 2017, ICCV, P4097; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14; Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649; Trzcinski T, 2015, IEEE T PATTERN ANAL, V37, P597, DOI 10.1109/TPAMI.2014.2343961; Trzcinski T, 2013, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2013.370; Trzcinski T, 2012, LECT NOTES COMPUT SC, V7572, P228, DOI 10.1007/978-3-642-33718-5_17; Wang J, 2017, IEEE INFOCOM SER, DOI 10.1007/s12083-017-0556-6; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Weiss Y, 2009, ADV NEURAL INFORM PR, P1753; Xia R, 2014, 2014 INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY (POWERCON), P1521, DOI 10.1109/POWERCON.2014.6993796; Zhang SL, 2014, IEEE T IMAGE PROCESS, V23, P3671, DOI 10.1109/TIP.2014.2330794; Zhang ZM, 2016, PROC CVPR IEEE, P1487, DOI 10.1109/CVPR.2016.165	76	26	28	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1924	1938		10.1109/TPAMI.2018.2858760	http://dx.doi.org/10.1109/TPAMI.2018.2858760			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30040626				2022-12-18	WOS:000473598800010
J	La Manna, M; Kine, F; Breitbach, E; Jackson, J; Sultan, T; Velten, A				La Manna, Marco; Kine, Fiona; Breitbach, Eric; Jackson, Jonathan; Sultan, Talha; Velten, Andreas			Error Backprojection Algorithms for Non-Line-of-Sight Imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Non-line-of-sight (NLOS) imaging; time-of-flight; seeing-around-corners; algebraic reconstruction technique (ART); kaczmarz method	RECONSTRUCTION; ART; LOOKING	Recent advances in computer vision and inverse light transport theory have resulted in several non-line-of-sight imaging techniques. These techniques use photon time-of-flight information encoded in light after multiple, diffuse reflections to reconstruct a three-dimensional scene. In this paper, we propose and describe two iterative backprojection algorithms, the additive error backprojection (AEB) and multiplicative error backprojection (MEB), whose goal is to improve the reconstruction of the scene under investigation over non-iterative backprojection algorithms. We evaluate the proposed algorithms' performance applied to simulated and real data (gathered from an experimental setup where the system needs to reconstruct an unknown scene). Results show that the proposed iterative algorithms are able to provide better reconstruction than the unfiltered, non-iterative backprojection algorithm for both simulated and physical scenes, but are more sensitive to errors in the light transport model.	[La Manna, Marco; Kine, Fiona; Breitbach, Eric; Sultan, Talha; Velten, Andreas] Univ Wisconsin, Dept Biostat & Med Informat, Madison, WI 53706 USA; [Jackson, Jonathan] Univ Calif Berkeley, Dept Phys, Berkeley, CA 94720 USA	University of Wisconsin System; University of Wisconsin Madison; University of California System; University of California Berkeley	La Manna, M (corresponding author), Univ Wisconsin, Dept Biostat & Med Informat, Madison, WI 53706 USA.	lamanna2@wisc.edu; fkine@wisc.edu; ebreitbach2@wisc.edu; jonathanj@berkeley.edu; tsultan@wisc.edu; velten@wisc.edu	La Manna, Marco/Y-1513-2019	La Manna, Marco/0000-0002-4813-7351; Jackson, Jonathan/0000-0001-5051-1499	DARPA REVEAL Program [DARPA-BAA-15-44 MSN189781]; NASA NIAC Program [NNH15ZOA001N-15NIAC A2]; ONR [Open BAA 15-001]; Morgridge Institute for Research; AFRSO [AFOSR-2014-0003-cidYIP-2015]	DARPA REVEAL Program; NASA NIAC Program; ONR(Office of Naval Research); Morgridge Institute for Research; AFRSO	The authors thank Atul Ingle for valuable discussions and suggestions. This work was supported by DARPA REVEAL Program (Grant no. DARPA-BAA-15-44 MSN189781), NASA NIAC Program (Grant no. NNH15ZOA001N-15NIAC A2) AFRSO (Grant no. AFOSR-2014-0003-cidYIP-2015), ONR (Grant no. Open BAA 15-001), and Morgridge Institute for Research.	ANDERSEN AH, 1984, ULTRASONIC IMAGING, V6, P81, DOI 10.1016/0161-7346(84)90008-7; Arellano Victor, 2017, OPTICS EXP, V25, P10; Buttafava M, 2015, OPT EXPRESS, V23, P20997, DOI 10.1364/OE.23.020997; Buttafava M, 2014, REV SCI INSTRUM, V85, DOI 10.1063/1.4893385; Cimmino G., 1938, RIC SCI, V1, P326; Dai L, 2015, IEEE SIGNAL PROC LET, V22, P1571, DOI 10.1109/LSP.2015.2412253; Gariepy G, 2016, NAT PHOTONICS, V10, P23, DOI [10.1038/nphoton.2015.234, 10.1038/NPHOTON.2015.234]; GILBERT P, 1972, J THEOR BIOL, V36, P105, DOI 10.1016/0022-5193(72)90180-4; GORDON R, 1974, IEEE T NUCL SCI, VNS21, P78, DOI 10.1109/TNS.1974.6499238; GORDON R, 1970, J THEOR BIOL, V29, P471, DOI 10.1016/0022-5193(70)90109-8; Guan HQ, 1996, PHYS MED BIOL, V41, P1727, DOI 10.1088/0031-9155/41/9/012; Gupta O, 2012, OPT EXPRESS, V20, P19096, DOI 10.1364/OE.20.019096; Hansen PC, 2012, J COMPUT APPL MATH, V236, P2167, DOI 10.1016/j.cam.2011.09.039; HEIDE F, 2013, ACM T GRAPHIC, V32; Heide F, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766953; Heide F, 2014, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2014.418; Hernandez Quercus, 2017, ARXIV170302635; Jarabo A, 2017, VIS INFORM, V1, P65, DOI 10.1016/j.visinf.2017.01.008; KACZMARZ S, 1993, INT J CONTROL, V57, P1269, DOI 10.1080/00207179308934446; Kadambi A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2836164; Kajiya J.T., 1986, SIGGRAPH, P143, DOI [DOI 10.1145/15922.15902, 10.1145/15886.15902, DOI 10.1145/15886.15902]; Kak A.C., 1998, PRINCIPLES COMPUTERI; Katsevich A, 2004, ADV APPL MATH, V32, P681, DOI 10.1016/S0196-8858(03)00099-X; Kirmani A, 2011, INT J COMPUT VISION, V95, P13, DOI 10.1007/s11263-011-0470-y; Klein J, 2016, SCI REP-UK, V6, DOI 10.1038/srep32491; NAYAR SK, 1991, INT J COMPUT VISION, V6, P173, DOI 10.1007/BF00115695; Pediredla AK, 2017, IEEE INT CONF COMPUT, P1; Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Seitz SM, 2005, IEEE I CONF COMP VIS, P1440; Steinvall O., 2011, P SPIE SEC DEF; Tsai CY, 2017, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2017.251; Velten A, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1747	33	26	26	2	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1615	1626		10.1109/TPAMI.2018.2843363	http://dx.doi.org/10.1109/TPAMI.2018.2843363			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29993536	Green Submitted			2022-12-18	WOS:000470972300007
J	Booth, J; Roussos, A; Ververas, E; Antonakos, E; Ploumpis, S; Panagakis, Y; Zafeiriou, S				Booth, James; Roussos, Anastasios; Ververas, Evangelos; Antonakos, Epameinondas; Ploumpis, Stylianos; Panagakis, Yannis; Zafeiriou, Stefanos			3D Reconstruction of "In-the-Wild" Faces in Images and Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3DMM; morphable model; RPCA; 3D reconstruction	RECOGNITION; SHAPE; ILLUMINATION; CONSTRAINTS; MODELS	3D Morphable Models (3DMMs) are powerful statistical models of 3D facial shape and texture, and are among the state-of-the-art methods for reconstructing facial shape from single images. With the advent of new 3D sensors, many 3D facial datasets have been collected containing both neutral as well as expressive faces. However, all datasets are captured under controlled conditions. Thus, even though powerful 3D facial shape models can be learnt from such data, it is difficult to build statistical texture models that are sufficient to reconstruct faces captured in unconstrained conditions ("in-the-wild"). In this paper, we propose the first "in-the-wild" 3DMM by combining a statistical model of facial identity and expression shape with an "in-the-wild" texture model. We show that such an approach allows for the development of a greatly simplified fitting procedure for images and videos, as there is no need to optimise with regards to the illumination parameters. We have collected three new benchmarks that combine "in-the-wild" images and video with ground truth 3D facial geometry, the first of their kind, and report extensive quantitative evaluations using them that demonstrate our method is state-of-the-art.	[Booth, James; Roussos, Anastasios; Ververas, Evangelos; Antonakos, Epameinondas; Ploumpis, Stylianos; Panagakis, Yannis; Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, South Kensington Campus, London SW7 2AZ, England; [Roussos, Anastasios] Univ Exeter, Coll Engn Math & Phys Sci, Exeter EX4 4QD, Devon, England; [Panagakis, Yannis] Middlesex Univ London, Dept Comp Sci, London NW4 4BT, England	Imperial College London; University of Exeter; Middlesex University	Booth, J (corresponding author), Imperial Coll London, Dept Comp, South Kensington Campus, London SW7 2AZ, England.	james.booth08@imperial.ac.uk; troussos@imperial.ac.uk; e.ververas16@imperial.ac.uk; e.antonakos@imperial.ac.uk; s.ploumpis@imperial.ac.uk; i.panagakis@imperial.ac.uk; s.zafeiriou@imperial.ac.uk	Panagakis, Yannis/AAZ-8090-2020	Roussos, Anastasios/0000-0001-6015-3357; Panagakis, Ioannis/0000-0003-0153-5210; Ververas, Evangelos/0000-0003-4345-1744	EPSRC DTA award; EPSRC [EP/N007743/1]	EPSRC DTA award(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	J. Booth was supported by an EPSRC DTA award. The work of A. Roussos, S. Ploumpis and S. Zafeiriou has been partially funded by the EPSRC Project EP/N007743/1 (FACER2VM). We would like to thank George Trigeorgis for his invaluable help in the preparation of this article, and the authors of [71] for kindly providing us with results of their method.	Alabort-i Medina J., 2016, INT J COMPUT VISION, P1; Alabort-i-Medina J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P679, DOI 10.1145/2647868.2654890; Aldrian O, 2013, IEEE T PATTERN ANAL, V35, P1080, DOI 10.1109/TPAMI.2012.206; Amberg B, 2011, EDITING FACES VIDEOS; [Anonymous], 2016, AS C COMP VIS WORKSH, P377; Antonakos E, 2015, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2015.7299182; Antonakos E, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431445; Antonakos E, 2014, IEEE IMAGE PROC, P224, DOI 10.1109/ICIP.2014.7025044; Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23; Bertsekas D. P., 2014, CONSTRAINED OPTIMIZA; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Booth J., 2017, P IEEE C COMP VIS PA, P4010; Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7; Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Cheng SY, 2017, IMAGE VISION COMPUT, V58, P3, DOI 10.1016/j.imavis.2016.10.007; Chrysos GG, 2018, INT J COMPUT VISION, V126, P198, DOI 10.1007/s11263-017-0999-5; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J., 2018, P C AUT FAC GEST REC; Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168; Garg R, 2013, INT J COMPUT VISION, V104, P286, DOI 10.1007/s11263-012-0607-7; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Hernandez M, 2017, COMPUT GRAPH-UK, V66, P14, DOI 10.1016/j.cag.2017.05.008; Huber P., 2016, P INT C COMP VIS THE; Huber P, 2017, IEEE SIGNAL PROC LET, V24, P437, DOI 10.1109/LSP.2016.2643284; Izadi Shahram, 2011, UIST, DOI [10.1145/2047196.2047270, DOI 10.1145/2047196.2047270]; Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117; Jain V.., 2010, FDDB BENCHMARK FACE; Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454; Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241; Kemelmacher-Shlizerman I, 2013, IEEE I CONF COMP VIS, P3256, DOI 10.1109/ICCV.2013.404; Kuipers J. B., 1999, QUATERNIONS ROTATION, V66; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Marschner SR, 1999, SPRING EUROGRAP, P131; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Papandreou George, 2008, COMP VIS PATT REC 20, P1; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448; Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204; Romdhani S, 2005, PROC CVPR IEEE, P986; Romdhani S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P59; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Shang F., 2014, P 23 ACM INT C C INF, P1149, DOI DOI 10.1145/2661829.2662083; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Smith WAP, 2008, INT J COMPUT VISION, V76, P71, DOI 10.1007/s11263-007-0074-8; Smith WAP, 2006, IEEE T PATTERN ANAL, V28, P1914, DOI 10.1109/TPAMI.2006.251; Snape P, 2015, PROC CVPR IEEE, P91, DOI 10.1109/CVPR.2015.7298604; Snape P, 2014, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2014.139; Tewari A, 2017, IEEE INT CONF COMP V, P1274, DOI 10.1109/ICCVW.2017.153; THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262; Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239; Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79; WHEELER MD, 1995, CMUCS95215; Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Zafeiriou S., 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P132, DOI 10.1109/CVPRW.2011.5981840; Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23; Zollhofer M., 2014, ACM T GRAPHIC, V33, p[2, 8]	75	26	27	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2638	2652		10.1109/TPAMI.2018.2832138	http://dx.doi.org/10.1109/TPAMI.2018.2832138			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29993707	Green Accepted, Green Submitted			2022-12-18	WOS:000446683700009
J	Kim, TH; Nah, S; Lee, KM				Kim, Tae Hyun; Nah, Seungjun; Lee, Kyoung Mu			Dynamic Video Deblurring Using a Locally Adaptive Blur Model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video deblurring; non-uniform blur; motion blur; defocus blur; optical flow; Gaussian blur map; non-uniform blur dataset	CAMERA SHAKE; OPTICAL-FLOW; SINGLE	State-of-the-art video deblurring methods cannot handle blurry videos recorded in dynamic scenes since they are built under a strong assumption that the captured scenes are static. Contrary to the existing methods, we propose a new video deblurring algorithm that can deal with general blurs inherent in dynamic scenes. To handle general and locally varying blurs caused by various sources, such as moving objects, camera shake, depth variation, and defocus, we estimate pixel-wise varying non-uniform blur kernels. We infer bidirectional optical flows to handle motion blurs, and also estimate Gaussian blur maps to remove optical blur from defocus. Therefore, we propose a single energy model that jointly estimates optical flows, defocus blur maps and latent frames. We also provide a framework and efficient solvers to minimize the proposed energy model. By optimizing the energy model, we achieve significant improvements in removing general blurs, estimating optical flows, and extending depth-of-field in blurry frames. Moreover, in this work, to evaluate the performance of non-uniform deblurring methods objectively, we have constructed a new realistic dataset with ground truths. In addition, extensive experimental results on publicly available challenging videos demonstrate that the proposed method produces qualitatively superior performance than the state-of-the-art methods which often fail in either deblurring or optical flow estimation.	[Kim, Tae Hyun; Nah, Seungjun; Lee, Kyoung Mu] Seoul Natl Univ, Dept Elect Engn & Comp Sci, Automat & Syst Res Inst, 1 Ganak Ro, Seoul 151744, South Korea	Seoul National University (SNU)	Lee, KM (corresponding author), Seoul Natl Univ, Dept Elect Engn & Comp Sci, Automat & Syst Res Inst, 1 Ganak Ro, Seoul 151744, South Korea.	lliger9@gmail.com; seungjun.nah@gmail.com; kyoungmu@snu.ac.kr	Nah, Seungjun/J-2891-2019; Lee, Kyoung Mu/AAC-4063-2020; Kim, Tae Hyun/GNP-3195-2022	Nah, Seungjun/0000-0003-3971-9402; Lee, Kyoung Mu/0000-0001-7210-1036; Kim, Tae Hyun/0000-0002-7995-3984	MKE (The Ministry of Knowledge Economy), Korea; National Research Foundation of Korea (NRF) - Ministry of Science, ICT & Future Planning (MSIP) [2009-0083495]; Microsoft Research, under IT/SW Creative research program [NIPA-2013-H0503-13-1041]	MKE (The Ministry of Knowledge Economy), Korea(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea); National Research Foundation of Korea (NRF) - Ministry of Science, ICT & Future Planning (MSIP)(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea); Microsoft Research, under IT/SW Creative research program(Microsoft)	This research was supported in part by the MKE (The Ministry of Knowledge Economy), Korea and Microsoft Research, under IT/SW Creative research program supervised by the NIPA (National IT Industry Promotion Agency) (NIPA-2013-H0503-13-1041), and in part by the National Research Foundation of Korea (NRF) grant funded by the Ministry of Science, ICT & Future Planning (MSIP) (No. 2009-0083495)	Agrawal Amit, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2560, DOI 10.1109/CVPRW.2009.5206546; Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x; Bar L, 2007, IEEE I CONF COMP VIS, P1410; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Cai JF, 2009, J COMPUT PHYS, V228, P5057, DOI 10.1016/j.jcp.2009.04.022; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Cho S, 2007, IEEE I CONF COMP VIS, P596; Cho S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185560; Cho S, 2012, COMPUT GRAPH FORUM, V31, P2183, DOI 10.1111/j.1467-8659.2012.03211.x; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Dai S., 2008, P IEEE C COMP VIS PA, P1; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276; Hu Z, 2014, PROC CVPR IEEE, P2893, DOI 10.1109/CVPR.2014.370; Kee E., 2011, 2011 IEEE INT C COMP, P1; Kim TH, 2015, PROC CVPR IEEE, P5426, DOI 10.1109/CVPR.2015.7299181; Kim TH, 2013, IEEE I CONF COMP VIS, P3160, DOI 10.1109/ICCV.2013.392; Kim TH, 2014, PROC CVPR IEEE, P2766, DOI 10.1109/CVPR.2014.348; Kim TH, 2013, IEEE I CONF COMP VIS, P3344, DOI 10.1109/ICCV.2013.415; Kohler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3; Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521; Krishnan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531402; Lee HS, 2013, PROC CVPR IEEE, P273, DOI 10.1109/CVPR.2013.42; Levin A, 2007, IEEE T PATTERN ANAL, V29, P1647, DOI 10.1109/TPAMI.2007.1106; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li YP, 2010, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2010.5539938; Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141; Pan JS, 2017, IEEE T PATTERN ANAL, V39, P342, DOI 10.1109/TPAMI.2016.2551244; Paramanand C, 2013, PROC CVPR IEEE, P1115, DOI 10.1109/CVPR.2013.148; Portz T, 2012, PROC CVPR IEEE, P1752, DOI 10.1109/CVPR.2012.6247871; Ranftl R, 2014, LECT NOTES COMPUT SC, V8689, P439, DOI 10.1007/978-3-319-10590-1_29; Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372; Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222; Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2; Werlberger M, 2010, PROC CVPR IEEE, P2464, DOI 10.1109/CVPR.2010.5539945; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Wulff J, 2014, LECT NOTES COMPUT SC, V8694, P236, DOI 10.1007/978-3-319-10599-4_16; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhu X, 2013, IEEE T IMAGE PROCESS, V22, P4879, DOI 10.1109/TIP.2013.2279316; Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009	47	26	26	2	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2374	2387		10.1109/TPAMI.2017.2761348	http://dx.doi.org/10.1109/TPAMI.2017.2761348			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	29028187				2022-12-18	WOS:000443875500007
J	Xie, D; Shu, TM; Todorovic, S; Zhu, SC				Xie, Dan; Shu, Tianmin; Todorovic, Sinisa; Zhu, Song-Chun			Learning and Inferring "Dark Matter" and Predicting Human Intents and Trajectories in Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene understanding; video analysis; functional objects; intents modeling; trajectory projection	OBJECT RECOGNITION; MODEL; BEHAVIORS	This paper presents a method for localizing functional objects and predicting human intents and trajectories in surveillance videos of public spaces, under no supervision in training. People in public spaces are expected to intentionally take shortest paths (subject to obstacles) toward certain objects (e.g., vending machine, picnic table, dumpster etc.) where they can satisfy certain needs (e.g., quench thirst). Since these objects are typically very small or heavily occluded, they cannot be inferred by their visual appearance but indirectly by their influence on people's trajectories. Therefore, we call them "dark matter", by analogy to cosmology, since their presence can only be observed as attractive or repulsive "fields" in the public space. A person in the scene is modeled as an intelligent agent engaged in one of the "fields" selected depending his/her intent. An agent's trajectory is derived from an Agent-based Lagrangian Mechanics. The agents can change their intents in the middle of motion and thus alter the trajectory. For evaluation, we compiled and annotated a new dataset. The results demonstrate our effectiveness in predicting human intent behaviors and trajectories, and localizing and discovering distinct types of "dark matter" in wide public spaces.	[Xie, Dan; Shu, Tianmin; Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Todorovic, Sinisa] Oregon State Univ, Sch EECS, Corvallis, OR 97331 USA	University of California System; University of California Los Angeles; Oregon State University	Xie, D (corresponding author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.	xiedan@ucla.edu; tianmin.shu@ucla.edu; sinisa@oregonstate.edu; sczhu@stat.ucla.edu	Shu, Tianmin/AAT-6085-2021		NSF [IIS 1423305]; ONR MURI [N00014-16-1-2007]; DARPA SIMPLEX project [N66001-15-C-4035]	NSF(National Science Foundation (NSF)); ONR MURI(MURIOffice of Naval Research); DARPA SIMPLEX project	This work is supported by grants NSF IIS 1423305, ONR MURI N00014-16-1-2007, and a DARPA SIMPLEX project N66001-15-C-4035.	Abrams A., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P297, DOI 10.1109/WACV.2012.6163032; Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110; Ali S., 2007, P IEEE C COMP VIS PA, DOI [10.1109/CVPR.2007.382977, DOI 10.1109/CVPR.2007.382977]; Amer MR, 2012, LECT NOTES COMPUT SC, V7575, P187, DOI 10.1007/978-3-642-33765-9_14; [Anonymous], 2005, P 2005 SAE S DIG HUM; Baker CL, 2009, COGNITION, V113, P329, DOI 10.1016/j.cognition.2009.07.005; BAKER CL, 2007, P 29 ANN C COGN SCI, P779; BARRAQUAND J, 1992, IEEE T SYST MAN CYB, V22, P224, DOI 10.1109/21.148426; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bolei Zhou, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3441, DOI 10.1109/CVPR.2011.5995459; Brizard AJ, 2015, INTRO LAGRANGIAN MEC, V2nd; Delaitre V, 2012, LECT NOTES COMPUT SC, V7577, P284, DOI 10.1007/978-3-642-33783-3_21; Gall J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1969, DOI 10.1109/CVPR.2011.5995582; Gong HF, 2011, IEEE I CONF COMP VIS, P619, DOI 10.1109/ICCV.2011.6126296; Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; Huang D. - A., 2014, P EUR C COMPUT VIS; Kim K, 2010, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2010.5540128; Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15; Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39; KOPPULA HS, 2013, P IEEE RSJ INT C INT, P2071; Kwon J, 2013, IEEE T PATTERN ANAL, V35, P1011, DOI 10.1109/TPAMI.2012.161; Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45; Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109; Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x; Mehran R., 2009, P INT WORKSH HUM BEH, P134; Hoai M, 2012, PROC CVPR IEEE, P2863, DOI 10.1109/CVPR.2012.6248012; Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109; Oh SM, 2010, LECT NOTES COMPUT SC, V6311, P549; Park HS, 2016, PROC CVPR IEEE, P4697, DOI 10.1109/CVPR.2016.508; Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Pellegrini S, 2012, LECT NOTES COMPUT SC, V7585, P162, DOI 10.1007/978-3-642-33885-4_17; Pieropan A, 2013, IEEE INT CONF ROBOT, P1282, DOI 10.1109/ICRA.2013.6630736; Qin B, 2014, IEEE INT CONF ROBOT, P6062, DOI 10.1109/ICRA.2014.6907752; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Shu TM, 2015, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR.2015.7299088; Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Turek MW, 2010, LECT NOTES COMPUT SC, V6312, P664, DOI 10.1007/978-3-642-15552-9_48; Vondrick C, 2013, INT J COMPUT VISION, V101, P184, DOI 10.1007/s11263-012-0564-1; Wei P, 2013, IEEE I CONF COMP VIS, P3272, DOI 10.1109/ICCV.2013.406; Xie D, 2013, IEEE I CONF COMP VIS, P2224, DOI 10.1109/ICCV.2013.277; Zhao Y., 2011, ADV NEURAL INFORM PR, V24, P73; Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013; Ziebart BD, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3931, DOI 10.1109/IROS.2009.5354147	50	26	27	2	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1639	1652		10.1109/TPAMI.2017.2728788	http://dx.doi.org/10.1109/TPAMI.2017.2728788			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28727549	hybrid			2022-12-18	WOS:000434294800008
J	Roth, J; Tong, YY; Liu, XM				Roth, Joseph; Tong, Yiying; Liu, Xiaoming			Adaptive 3D Face Reconstruction from Unconstrained Photo Collections	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face reconstruction; photometric stereo; unconstrained	PHOTOMETRIC STEREO; MODEL; SHAPE	Given a photo collection of "unconstrained" face images of one individual captured under a variety of unknown pose, expression, and illumination conditions, this paper presents a method for reconstructing a 3D face surface model of the individual along with albedo information. Unlike prior work on face reconstruction that requires large photo collections, we formulate an approach to adapt to photo collections with a high diversity in both the number of images and the image quality. To achieve this, we incorporate prior knowledge about face shape by fitting a 3D morphable model to form a personalized template, following by using a novel photometric stereo formulation to complete the fine details, under a coarse-to-fine scheme. Our scheme incorporates a structural similarity-based local selection step to help identify a common expression for reconstruction while discarding occluded portions of faces. The evaluation of reconstruction performance is through a novel quality measure, in the absence of ground truth 3D scans. Superior large-scale experimental results are reported on synthetic, Internet, and personal photo collections.	[Roth, Joseph; Tong, Yiying; Liu, Xiaoming] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Roth, J (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	roth.joseph.e@gmail.com; ytong@msu.edu; liuxm@cse.msu.edu	Tong, Yiying/D-9202-2012	Tong, Yiying/0000-0002-7929-4333				Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293; Anjos A., 2012, P 20 ACM INT C MULT, P1449; [Anonymous], 1999, SIDLWP19990120 STANF; [Anonymous], 2006, KONICA MINOLTA VIVID; [Anonymous], 2013, IIID SCANNER PRIMESE; Attene M, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P271; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777; Beeler T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964970; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Boxin Shi, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P361, DOI 10.1109/3DV.2014.9; Bruckstein AM, 1999, INT J COMPUT VISION, V35, P223, DOI 10.1023/A:1008156210387; Cao C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766943; Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Chu B., 2014, P IEEE C COMP VIS PA, P1899; Cu L, 2008, LECT NOTES COMPUT SC, V5302, P413, DOI 10.1007/978-3-540-88682-2_32; Deng JK, 2016, IMAGE VISION COMPUT, V47, P19, DOI 10.1016/j.imavis.2015.11.005; Dou MS, 2015, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2015.7298647; Frolova D, 2004, LECT NOTES COMPUT SC, V3021, P574; Fyffe G, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2638549; Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493; Garrido P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508380; Ghosh A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024163; Govan A. Y., 2006, P MAM; Hansen MF, 2010, COMPUT VIS IMAGE UND, V114, P942, DOI 10.1016/j.cviu.2010.03.001; Haoqiang Fan, 2016, Image and Vision Computing, V47, P27, DOI 10.1016/j.imavis.2015.11.004; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974; Jacobson A., 2015, GPTOOLBOX GEOMETRY P; Jeni L., 2015, FG; Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454; Jourabloo A, 2015, INT CONF BIOMETR, P278, DOI 10.1109/ICB.2015.7139096; Kemelmacher-Shlizerman I, 2013, IEEE I CONF COMP VIS, P3256, DOI 10.1109/ICCV.2013.404; Kemelmacher-Shlizerman I, 2011, IEEE I CONF COMP VIS, P1746, DOI 10.1109/ICCV.2011.6126439; Lee K., 2001, CVPR, P129; Liu XM, 2005, PROC CVPR IEEE, P502; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Peng WL, 2016, NEUROCOMPUTING, V179, P228, DOI 10.1016/j.neucom.2015.11.090; Pinkall U., 1993, EXPT MATH, V2, P15, DOI DOI 10.1080/10586458.1993.10504266; PIOTRASCHKE M, 2016, PROC CVPR IEEE, P3418, DOI DOI 10.1109/CVPR.2016.372; Qu C., 2015, P BRIT MACH VIS C, P87; Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455; Roth J, 2015, PROC CVPR IEEE, P2606, DOI 10.1109/CVPR.2015.7298876; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Shi FH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661290; Snape P, 2015, PROC CVPR IEEE, P91, DOI 10.1109/CVPR.2015.7298604; Sorkine Olga., 2004, P EUR ACM SIGGRAPH S, P175; Spaulding K. E., 2007, Constructing extended color gamut images from limited color gamut digital images, U. S. Patent, Patent No. [7 308 135, 7]; Suwajanakorn S, 2014, LECT NOTES COMPUT SC, V8692, P796, DOI 10.1007/978-3-319-10593-2_52; THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262; WANG J, 2006, P IEEE INT C COMP VI, V2, P1399; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Weise T., 2009, P 2009 ACM SIGGRAPH, P7, DOI [DOI 10.1145/1599470.1599472, 10.1145/1599470.1599472]; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126; Yang C, 2014, IEEE COMPUT SOC CONF, P9, DOI 10.1109/CVPRW.2014.7; Yin L., 2008, AUTOMATIC FACE GESTU, V08, P1, DOI DOI 10.1109/AFGR.2008.4813324; Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774; Yuille AL, 1999, INT J COMPUT VISION, V35, P203, DOI 10.1023/A:1008180726317; Zeng D., 2016, J IMAGE VIS COMPUT; Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679	71	26	28	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2127	2141		10.1109/TPAMI.2016.2636829	http://dx.doi.org/10.1109/TPAMI.2016.2636829			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	28114006				2022-12-18	WOS:000412028600002
J	Hui, Z; Sankaranarayanan, AC				Hui, Zhuo; Sankaranarayanan, Aswin C.			Shape and Spatially-Varying Reflectance Estimation from Virtual Exemplars	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; BRDF estimation; dictionaries; spatially varying BRDF	PHOTOMETRIC STEREO; RECONSTRUCTION	This paper addresses the problem of estimating the shape of objects that exhibit spatially-varying reflectance. We assume that multiple images of the object are obtained under a fixed view-point and varying illumination, i.e., the setting of photometric stereo. At the core of our techniques is the assumption that the BRDF at each pixel lies in the non-negative span of a known BRDF dictionary. This assumption enables a per-pixel surface normal and BRDF estimation framework that is computationally tractable and requires no initialization in spite of the underlying problem being non-convex. Our estimation framework first solves for the surface normal at each pixel using a variant of example-based photometric stereo. We design an efficient multi-scale search strategy for estimating the surface normal and subsequently, refine this estimate using a gradient descent procedure. Given the surface normal estimate, we solve for the spatially-varying BRDF by constraining the BRDF at each pixel to be in the span of the BRDF dictionary; here, we use additional priors to further regularize the solution. A hallmark of our approach is that it does not require iterative optimization techniques nor the need for careful initialization, both of which are endemic to most state-of-the-art techniques. We showcase the performance of our technique on a wide range of simulated and real scenes where we outperform competing methods.	[Hui, Zhuo; Sankaranarayanan, Aswin C.] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Hui, Z (corresponding author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.	zhui@andrew.cmu.edu; saswin@andrew.cmu.edu	Hui, Zhuo/AAA-6568-2020	hui, zhuo/0000-0001-9564-0155	US National Science Foundation [CCF-1117939]	US National Science Foundation(National Science Foundation (NSF))	The authors were supported in part by the US National Science Foundation grant CCF-1117939.	Ackermann Jens, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P259, DOI 10.1109/3DV.2014.63; Ackermann J., 2010, PROC EUR C TRENDS TO, P197; Alldrin N., 2008, IEEE C COMP VIS PATT, P1; Alldrin NG, 2007, IEEE I CONF COMP VIS, P417; [Anonymous], 2008, P ACM SIGGRAPH 2008; Ashikhmin M., 2000, Journal of Graphics Tools, V5, P25, DOI 10.1080/10867651.2000.10487522; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; BLINN JF, 1976, COMMUN ACM, V19, P542, DOI [10.1145/360349.360353, 10.1145/965143.563322]; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chandraker M, 2013, IEEE T PATTERN ANAL, V35, P2941, DOI 10.1109/TPAMI.2012.217; Chandraker M, 2011, IEEE I CONF COMP VIS, P1076, DOI 10.1109/ICCV.2011.6126354; Cook R., 1982, ACM T GRAPHIC, V1, P7, DOI DOI 10.1145/357290.357293; Einarsson P., 2006, P EUR C REND TECHN; Fazel M, 2001, P AMER CONTR CONF, P4734, DOI 10.1109/ACC.2001.945730; Goldman DB, 2005, IEEE I CONF COMP VIS, P341; Grant M., 2014, CVX MATLAB SOFTWARE; Harman R, 2010, J MULTIVARIATE ANAL, V101, P2297, DOI 10.1016/j.jmva.2010.06.002; HE XD, 1991, ACM SIGGRAPH COMPUTE, V25, P175, DOI DOI 10.1145/127719; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Higo T, 2010, PROC CVPR IEEE, P1157, DOI 10.1109/CVPR.2010.5540084; Horn B. K., 1989, OBTAINING SHAPE SHAD; Hui Z., 2015, P IEEE INT C COMP PH, P1; Ikehata S, 2014, PROC CVPR IEEE, P2187, DOI 10.1109/CVPR.2014.280; Ikehata S, 2012, PROC CVPR IEEE, P318, DOI 10.1109/CVPR.2012.6247691; Lafortune E. P. F., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P117, DOI 10.1145/258734.258801; Lawrence J, 2006, ACM T GRAPHIC, V25, P735, DOI 10.1145/1141911.1141949; Lu F, 2015, PROC CVPR IEEE, P168, DOI 10.1109/CVPR.2015.7298612; Lu F, 2015, IEEE T PATTERN ANAL, V37, P1999, DOI 10.1109/TPAMI.2015.2389841; Lu F, 2013, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2013.196; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; Ngan A, 2005, EUR S REND, V2, P117, DOI DOI 10.2312/EGWR/EGSR05/117-126; OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684; Oxholm G, 2016, IEEE T PATTERN ANAL, V38, P376, DOI 10.1109/TPAMI.2015.2450734; Oxholm G, 2014, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2014.277; Oxholm G, 2012, LECT NOTES COMPUT SC, V7572, P528, DOI 10.1007/978-3-642-33718-5_38; Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003; Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Romeiro F, 2008, LECT NOTES COMPUT SC, V5305, P859, DOI 10.1007/978-3-540-88693-8_63; Romeiro F, 2010, LECT NOTES COMPUT SC, V6311, P45, DOI 10.1007/978-3-642-15549-9_4; Rusinkiewicz S. M., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P11; Shi BX, 2016, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2016.403; Shi BX, 2012, LECT NOTES COMPUT SC, V7574, P455, DOI 10.1007/978-3-642-33712-3_33; Shi BX, 2014, IEEE T PATTERN ANAL, V36, P1078, DOI 10.1109/TPAMI.2013.196; Tan P, 2011, IEEE T PATTERN ANAL, V33, P2506, DOI 10.1109/TPAMI.2011.35; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Yu C, 2010, LECT NOTES COMPUT SC, V6314, P115; Zhou ZL, 2013, PROC CVPR IEEE, P1482, DOI 10.1109/CVPR.2013.195	51	26	28	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2017	39	10					2060	2073		10.1109/TPAMI.2016.2623613	http://dx.doi.org/10.1109/TPAMI.2016.2623613			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FF3NI	27831859	Green Submitted, hybrid			2022-12-18	WOS:000408807600012
J	Kim, S; Min, D; Ham, B; Do, MN; Sohn, K				Kim, Seungryong; Min, Dongbo; Ham, Bumsub; Do, Minh N.; Sohn, Kwanghoon			DASC: Robust Dense Descriptor for Multi-Modal and Multi-Spectral Correspondence Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dense correspondence; descriptor; multi-spectral; multi-modal; edge-aware filtering	REGISTRATION; IMAGES; SIFT	Establishing dense correspondences between multiple images is a fundamental task in many applications. However, finding a reliable correspondence between multi-modal or multi-spectral images still remains unsolved due to their challenging photometric and geometric variations. In this paper, we propose a novel dense descriptor, called dense adaptive self-correlation (DASC), to estimate dense multi-modal and multi-spectral correspondences. Based on an observation that self-similarity existing within images is robust to imaging modality variations, we define the descriptor with a series of an adaptive self-correlation similarity measure between patches sampled by a randomized receptive field pooling, in which a sampling pattern is obtained using a discriminative learning. The computational redundancy of dense descriptors is dramatically reduced by applying fast edge-aware filtering. Furthermore, in order to address geometric variations including scale and rotation, we propose a geometry-invariant DASC (GI-DASC) descriptor that effectively leverages the DASC through a superpixel-based representation. For a quantitative evaluation of the GI-DASC, we build a novel multi-modal benchmark as varying photometric and geometric conditions. Experimental results demonstrate the outstanding performance of the DASC and GI-DASC in many cases of dense multi-modal and multi-spectral correspondences.	[Kim, Seungryong; Ham, Bumsub; Sohn, Kwanghoon] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea; [Min, Dongbo] Chungnam Natl Univ, Dept Comp Sci & Engn, Daejeon 305764, South Korea; [Do, Minh N.] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA; [Do, Minh N.] Univ Illinois, Coordinated Sci Lab, Urbana, IL 61801 USA	Yonsei University; Chungnam National University; University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign	Kim, S (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.	srkim89@yousei.ac.kr; dbmin@cnu.ac.kr; mimo@yousei.ac.kr; minhdo@illinois.edu; khsohn@yousei.ac.kr	N., Minh/AAX-8498-2020	N., Minh/0000-0001-5132-4986; Kim, Seungryong/0000-0003-2927-6273	National Research Foundation of Korea (NRF) - Korea government (MSIP) [NRF-2013R1A2A2A01068338]	National Research Foundation of Korea (NRF) - Korea government (MSIP)(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea)	This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (NRF-2013R1A2A2A01068338).	Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Donahue J, 2014, PR MACH LEARN RES, V32; Dong JM, 2015, PROC CVPR IEEE, P5097, DOI 10.1109/CVPR.2015.7299145; Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981; Fischer P, 2014, ARXIV14055769; Gastal E., 2011, P ACM SIGGRAGH; HaCohen Y, 2013, IEEE I CONF COMP VIS, P2384, DOI 10.1109/ICCV.2013.296; Hassner T, 2012, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2012.6247842; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; He KM, 2010, LECT NOTES COMPUT SC, V6311, P1; He Kaiming, 2015, ARXIV150500996; Heinrich MP, 2012, MED IMAGE ANAL, V16, P1423, DOI 10.1016/j.media.2012.05.008; Heo YS, 2013, IEEE T PATTERN ANAL, V35, P1094, DOI 10.1109/TPAMI.2012.167; Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136; Hur J, 2015, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2015.7298745; Irani M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P959, DOI 10.1109/ICCV.1998.710832; Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299; Kim S., 2014, P AS C COMP VIS, P368; Kim S, 2015, PROC CVPR IEEE, P2103, DOI 10.1109/CVPR.2015.7298822; Kokkinos I, 2008, PROC CVPR IEEE, P3544; Krishnan D., 2009, P SIGGRAPH; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lang M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185530; Lee CY, 2014, PROC CVPR IEEE, P4050, DOI 10.1109/CVPR.2014.516; Lee HS, 2013, PROC CVPR IEEE, P273, DOI 10.1109/CVPR.2013.42; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Li Y, 2015, IEEE I CONF COMP VIS, P4006, DOI 10.1109/ICCV.2015.456; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; Pinggera P, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.26; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Portz T, 2012, PROC CVPR IEEE, P1752, DOI 10.1109/CVPR.2012.6247871; Qiu WC, 2014, IEEE WINT CONF APPL, P1112, DOI 10.1109/WACV.2014.6835734; Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Saleem S, 2014, IEEE SIGNAL PROC LET, V21, P400, DOI 10.1109/LSP.2014.2304073; Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977; Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222; Shechtman E, 2007, PROC CVPR IEEE, P1744; Shen XY, 2014, LECT NOTES COMPUT SC, V8692, P309, DOI 10.1007/978-3-319-10593-2_21; Silberman Nathan, 2012, EUR C COMP VIS, DOI 10.1007/978-3-642-33715-4_54; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Simo-Serra E, 2015, INT J COMPUT VISION, V115, P136, DOI 10.1007/s11263-015-0805-1; Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Tombari F, 2015, LECT NOTES COMPUT SC, V9004, P586, DOI 10.1007/978-3-319-16808-1_39; Torabi A, 2013, PATTERN RECOGN, V46, P578, DOI 10.1016/j.patcog.2012.07.026; Trulls E, 2013, PROC CVPR IEEE, P2890, DOI 10.1109/CVPR.2013.372; Trzcinski T, 2015, IEEE T PATTERN ANAL, V37, P597, DOI 10.1109/TPAMI.2014.2343961; Xu JT, 2016, INT J COMPUT VISION, V119, P179, DOI 10.1007/s11263-016-0886-5; Yan Q, 2013, IEEE I CONF COMP VIS, P1537, DOI 10.1109/ICCV.2013.194; Yang HS, 2014, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2014.435; Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542; Ye YX, 2014, ISPRS J PHOTOGRAMM, V90, P83, DOI 10.1016/j.isprsjprs.2014.01.009; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345	72	26	28	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1712	1729		10.1109/TPAMI.2016.2615619	http://dx.doi.org/10.1109/TPAMI.2016.2615619			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	27723577	Green Submitted			2022-12-18	WOS:000406840800002
J	Ye, M; Shen, Y; Du, C; Pan, ZG; Yang, RG				Ye, Mao; Shen, Yang; Du, Chao; Pan, Zhigeng; Yang, Ruigang			Real-Time Simultaneous Pose and Shape Estimation for Articulated Objects Using a Single Depth Camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generative pose tracking; shape registration; real-time tracking; motion; depth cues; range data; surface fitting	MOTION CAPTURE; TRACKING	In this paper we present a novel real-time algorithm for simultaneous pose and shape estimation for articulated objects, such as human beings and animals. The key of our pose estimation component is to embed the articulated deformation model with exponential-maps-based parametrization into a Gaussian Mixture Model. Benefiting from this probabilistic measurement model, our algorithm requires no explicit point correspondences as opposed to most existing methods. Consequently, our approach is less sensitive to local minimum and handles fast and complex motions well. Moreover, our novel shape adaptation algorithm based on the same probabilistic model automatically captures the shape of the subjects during the dynamic pose estimation process. The personalized shape model in turn improves the tracking accuracy. Furthermore, we propose novel approaches to use either a mesh model or a sphere-set model as the template for both pose and shape estimation under this unified framework. Extensive evaluations on publicly available data sets demonstrate that our method outperforms most state-of-the-art pose estimation algorithms with large margin, especially in the case of challenging motions. Furthermore, our shape estimation method achieves comparable accuracy with state of the arts, yet requires neither statistical shape model nor extra calibration procedure. Our algorithm is not only accurate but also fast, we have implemented the entire processing pipeline on GPU. It can achieve up to 60 frames per second on a middle-range graphics card.	[Ye, Mao; Du, Chao; Yang, Ruigang] Univ Kentucky, Lexington, KY 40507 USA; [Shen, Yang] Lishui Univ, Lishui, Zhejiang, Peoples R China; [Pan, Zhigeng] Hangzhou Normal Univ, Digital Media, Hangzhou, Zhejiang, Peoples R China; [Pan, Zhigeng] Hangzhou Normal Univ, HCI Res Ctr, Hangzhou, Zhejiang, Peoples R China	University of Kentucky; Lishui University; Hangzhou Normal University; Hangzhou Normal University	Ye, M (corresponding author), Univ Kentucky, Lexington, KY 40507 USA.	mao.ye@uky.edu; tlsheny@163.com; chao.du@uky.edu; zgpan@hznu.edu.cn; ryang@uky.edu		Yang, Ruigang/0000-0001-5296-6307; Pan, Zhi-geng/0000-0003-0717-5850				Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Baak A, 2011, IEEE I CONF COMP VIS, P1092, DOI 10.1109/ICCV.2011.6126356; Ballan L., 2008, 3D DAT PROC VIS TRAN; Bogo F, 2015, IEEE I CONF COMP VIS, P2300, DOI 10.1109/ICCV.2015.265; Bradshaw G., 2002, THESIS; Bregler C, 2004, INT J COMPUT VISION, V56, P179, DOI 10.1023/B:VISI.0000011203.00237.9b; Brown B. Alex, 2007, Proceedings from the Institute for Nuclear Theory - vol. 16. Fourth Argonne/INT/MSU/JINA FRIB Theory Workshop. Rare Isotopes and Fundamental Symmetries, P21; Chang W, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966405; Cui Y, 2013, IEEE T PATTERN ANAL, V35, P1039, DOI 10.1109/TPAMI.2012.190; Cui Yan, 2012, P AS C COMP VIS, P133; de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697; Delaunoy A, 2014, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2014.193; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Gall J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1969, DOI 10.1109/CVPR.2011.5995582; Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755; Ganapathi V, 2012, LECT NOTES COMPUT SC, V7577, P738, DOI 10.1007/978-3-642-33783-3_53; Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141; Hasler N, 2009, COMPUT GRAPH FORUM, V28, P337, DOI 10.1111/j.1467-8659.2009.01373.x; Helten T, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P279, DOI 10.1109/3DV.2013.44; Li H., 2013, P ANN C COMP GRAPH I; Li H., 2012, ACM T GRAPHIC, V31, P2; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Murray R. M., 1994, MATH INTRO ROBOTIC M; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631; Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433; Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559; Plankers R, 2003, IEEE T PATTERN ANAL, V25, P1182, DOI 10.1109/TPAMI.2003.1227995; Pons-Moll G., 2011, VISUAL ANAL HUMANS, P139, DOI [10.1007/978-0-85729-997-0_9, DOI 10.1007/978-0-85729-997-0_9]; Pons-Moll G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.4; Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Sridhar S, 2015, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2015.7298941; Stoll C, 2011, IEEE I CONF COMP VIS, P951, DOI 10.1109/ICCV.2011.6126338; Straka M, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P41, DOI 10.1109/3DIMPVT.2012.18; Straka M, 2012, LECT NOTES COMPUT SC, V7572, P724, DOI 10.1007/978-3-642-33718-5_52; TAYLOR J, 2012, PROC CVPR IEEE, P103; Vlasic D., 2008, P 11 ANN C COMP GRAP; Wei X., 2012, P 11 ANN C COMP GRAP; Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Ye GZ, 2012, LECT NOTES COMPUT SC, V7573, P828, DOI 10.1007/978-3-642-33709-3_59; Ye M, 2014, PROC CVPR IEEE, P2353, DOI 10.1109/CVPR.2014.301; Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310; Zeng M, 2013, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2013.26	47	26	27	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1517	1532		10.1109/TPAMI.2016.2557783	http://dx.doi.org/10.1109/TPAMI.2016.2557783			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	27116732				2022-12-18	WOS:000379926200004
J	Chen, HY; Lin, YY; Chen, BY				Chen, Hsin-Yi; Lin, Yen-Yu; Chen, Bing-Yu			Co-Segmentation Guided Hough Transform for Robust Feature Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image feature matching; correspondence problems; Hough transform; co-segmentation; energy minimization	IMAGE; CLASSIFICATION; SELECTION; SCALE	We present an algorithm that integrates image co-segmentation into feature matching, and can robustly yield accurate and dense feature correspondences. Inspired by the fact that correct feature correspondences on the same object typically have coherent transformations, we cast the task of feature matching as a density estimation problem in the homography space. Specifically, we project the homographies of correspondence candidates into the parametric Hough space, in which geometric verification of correspondences can be activated by voting. The precision of matching is then boosted. On the other hand, we leverage image co-segmentation, which discovers object boundaries, to determine relevant voters and speed up Hough voting. In addition, correspondence enrichment can be achieved by inferring the concerted homographies that are propagated between the features within the same segments. The recall is hence increased. In our approach, feature matching and image co-segmentation are tightly coupled. Through an iterative optimization process, more and more correct correspondences are detected owing to object boundaries revealed by co-segmentation. The proposed approach is comprehensively evaluated. Promising experimental results on four datasets manifest its effectiveness.	[Chen, Hsin-Yi; Chen, Bing-Yu] Natl Taiwan Univ, Taipei 10764, Taiwan; [Lin, Yen-Yu] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 115, Taiwan	National Taiwan University; Academia Sinica - Taiwan	Chen, HY (corresponding author), Natl Taiwan Univ, Taipei 10764, Taiwan.	fensi@cmlab.csie.ntu.edu.tw; yylin@citi.sinica.edu.tw; robin@ntu.edu.tw	Chen, Bing-Yu/E-7498-2016	Chen, Bing-Yu/0000-0003-0169-7682; Lin, Yen-Yu/0000-0002-7183-6070	Ministry of Science and Technology; National Taiwan University; Intel Corporation [103-2221-E-001-026-MY2, 103-2911-I-002-001, NTU-ICRP-104R7501]	Ministry of Science and Technology(Ministry of Science, ICT & Future Planning, Republic of Korea); National Taiwan University(National Taiwan University); Intel Corporation(Intel Corporation)	The authors would like to thank the anonymous reviewers for their comments. This work was supported in part by Ministry of Science and Technology, National Taiwan University and Intel Corporation under Grants 103-2221-E-001-026-MY2, 103-2911-I-002-001, and NTU-ICRP-104R7501.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Albarelli A, 2012, INT J COMPUT VISION, V97, P36, DOI 10.1007/s11263-011-0432-4; Avrithis Y, 2014, INT J COMPUT VISION, V107, P1, DOI 10.1007/s11263-013-0659-3; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2005, PROC CVPR IEEE, P26; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Cech J, 2010, IEEE T PATTERN ANAL, V32, P1568, DOI 10.1109/TPAMI.2009.176; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen HY, 2013, PROC CVPR IEEE, P2762, DOI 10.1109/CVPR.2013.356; Chin TJ, 2012, IEEE T PATTERN ANAL, V34, P625, DOI 10.1109/TPAMI.2011.169; Cho M., 2008, P EUR C COMPUT VIS, P2129; Cho M., 2012, P 11 EUR C COMP VIS, P492; Cho M., 2009, P INT C COMP VIS, P144; Cho M., 2010, P EUR C COMPUT VIS, P144; Cox T., 2000, MULTIDIMENSIONAL SCA; Faktor A, 2013, IEEE I CONF COMP VIS, P1297, DOI 10.1109/ICCV.2013.164; Ferrari V, 2004, LECT NOTES COMPUT SC, V3021, P40; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Hacohen Y., 2011, ACM T GRAPHIC, V70, P1, DOI DOI 10.1145/2010324.1964965; Hauagge DC, 2012, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2012.6247677; JOULIN A, 2010, PROC CVPR IEEE, P1943, DOI DOI 10.1109/CVPR.2010.5539868; Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719; Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415; Kim E, 2012, PROC CVPR IEEE, P686, DOI 10.1109/CVPR.2012.6247737; Kim J, 2011, PROC CVPR IEEE, P1553, DOI 10.1109/CVPR.2011.5995526; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; LIU HR, 2010, PROC CVPR IEEE, P1609, DOI DOI 10.1109/CVPR.2010.5539780; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Rubio JC, 2012, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2012.6247745; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Sun J, 2013, IEEE I CONF COMP VIS, P3400, DOI 10.1109/ICCV.2013.422; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Tolias G, 2011, IEEE I CONF COMP VIS, P1653, DOI 10.1109/ICCV.2011.6126427; Torresani L, 2013, IEEE T PATTERN ANAL, V35, P259, DOI 10.1109/TPAMI.2012.105; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; Wang F, 2013, IEEE I CONF COMP VIS, P849, DOI 10.1109/ICCV.2013.110; Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294; Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566; Yarlagadda P, 2010, LECT NOTES COMPUT SC, V6315, P197, DOI 10.1007/978-3-642-15555-0_15; Yuan Y, 2012, PATTERN RECOGN LETT, V33, P471, DOI 10.1016/j.patrec.2011.02.008; Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667	51	26	28	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2388	2401		10.1109/TPAMI.2015.2420556	http://dx.doi.org/10.1109/TPAMI.2015.2420556			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539845				2022-12-18	WOS:000364831700003
J	Broderick, T; Mackey, L; Paisley, J; Jordan, MI				Broderick, Tamara; Mackey, Lester; Paisley, John; Jordan, Michael I.			Combinatorial Clustering and the Beta Negative Binomial Process	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Beta process; admixture; mixed membership; Bayesian; nonparametric; integer latent feature model	DIRICHLET; MIXTURE; MODELS; DISTRIBUTIONS; ESTIMATORS	We develop a Bayesian nonparametric approach to a general family of latent class problems in which individuals can belong simultaneously to multiple classes and where each class can be exhibited multiple times by an individual. We introduce a combinatorial stochastic process known as the negative binomial process (NBP) as an infinite-dimensional prior appropriate for such problems. We show that the NBP is conjugate to the beta process, and we characterize the posterior distribution under the beta-negative binomial process (BNBP) and hierarchical models based on the BNBP (the HBNBP). We study the asymptotic properties of the BNBP and develop a three-parameter extension of the BNBP that exhibits power-law behavior. We derive MCMC algorithms for posterior inference under the HBNBP, and we present experiments using these algorithms in the domains of image segmentation, object recognition, and document analysis.	[Broderick, Tamara; Jordan, Michael I.] Univ Calif Berkeley, Dept Stat, Berkeley, CA 94705 USA; [Broderick, Tamara; Jordan, Michael I.] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94705 USA; [Mackey, Lester] Stanford Univ, Dept Stat, Stanford, CA 94305 USA; [Paisley, John] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA	University of California System; University of California Berkeley; University of California System; University of California Berkeley; Stanford University; Columbia University	Broderick, T (corresponding author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94705 USA.		Jordan, Michael I/C-5253-2013; Paisley, John/AAF-8586-2019	Jordan, Michael/0000-0001-8935-817X	IARPA under the "Knowledge Discovery and Dissemination" program [IARPA-BAA-09-10]; ONR under the Multidisciplinary University Research Initiative (MURI) program [N00014-11-1-0688]; National Science Foundation Graduate Research Fellowship; National Defense Science and Engineering Graduate Fellowship	IARPA under the "Knowledge Discovery and Dissemination" program; ONR under the Multidisciplinary University Research Initiative (MURI) program; National Science Foundation Graduate Research Fellowship(National Science Foundation (NSF)); National Defense Science and Engineering Graduate Fellowship	Support for this project was provided by IARPA under the "Knowledge Discovery and Dissemination" program (IARPA-BAA-09-10) and by ONR under the Multidisciplinary University Research Initiative (MURI) program (N00014-11-1-0688). Tamara Broderick was supported by a National Science Foundation Graduate Research Fellowship. Lester Mackey was supported by the National Defense Science and Engineering Graduate Fellowship.	Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Broderick T, 2012, BAYESIAN ANAL, V7, P439, DOI 10.1214/12-BA715; Chen H, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1001060; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Damien P, 1999, J ROY STAT SOC B, V61, P331; Erosheva EA, 2005, STUD CLASS DATA ANAL, P11, DOI 10.1007/3-540-28084-7_2; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gnedin A, 2007, PROBAB SURV, V4, P146, DOI 10.1214/07-PS092; Goldwater S., 2006, P ADV NEUR INF PROC, V18, P459; Griffiths T.L., 2006, ADV NEURAL INFORM PR, P475; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; HJORT NL, 1990, ANN STAT, V18, P1259, DOI 10.1214/aos/1176347749; Kalli M, 2011, STAT COMPUT, V21, P93, DOI 10.1007/s11222-009-9150-y; Kim YD, 1999, ANN STAT, V27, P562, DOI 10.1214/aos/1018031207; Kingman J. F. C., 1993, POISSON PROCESSES; KINGMAN JFC, 1967, PAC J MATH, V21, P59, DOI 10.2140/pjm.1967.21.59; KORWAR RM, 1973, ANN PROBAB, V1, P705, DOI 10.1214/aop/1176996898; Lijoi A, 2007, J R STAT SOC B, V69, P715, DOI 10.1111/j.1467-9868.2007.00609.x; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MacEachern SN, 1998, J COMPUT GRAPH STAT, V7, P223, DOI 10.2307/1390815; McCloskey JW., 1965, MODEL DISTRIBUTION I; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521; Mitzenmacher M., 2004, INTERNET MATH, V1, P226, DOI [10.1080/15427951.2004.10129088, DOI 10.1080/15427951.2004.10129088]; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Neal RM, 2003, ANN STAT, V31, P705, DOI 10.1214/aos/1056562461; Newman MEJ, 2005, CONTEMP PHYS, V46, P323, DOI 10.1080/00107510500052444; PAISLEY J., 2010, INT C MACH LEARN HAI; Papaspiliopoulos O., 2008, 8 U WARW CTR RES STA; Pitman J, 1997, ANN PROBAB, V25, P855; Pitman J., 2006, LECT NOTES MATH, V1875; Pritchard JK, 2000, GENETICS, V155, P945; Qi F., 2010, J INEQUAL APPL, V2010, P204; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; Sivic J., 2005, AIM2005005 MIT AI LA; Teh Y. W., 2007, P INT C ART INT STAT, V11; Teh Y. W., 2009, P ADV NEUR INF PROC, V22, P1838; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985; THIBAUX R., 2007, P INT C ART INT STAT, V11; Thibaux R, 2008, THESIS U CALIFORNIA; Titsias Michalis, 2008, ADV NEURAL INFORM PR; Tricomi F.G., 1951, PACIFIC J MATH, V1, P133, DOI [DOI 10.2140/PJM.1951.1.133, 10.2140/pjm.1951.1.133]; van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334; Verbeek J., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383098; Walker SG, 2007, COMMUN STAT-SIMUL C, V36, P45, DOI 10.1080/03610910601096262; Watterson G. A., 1974, Advances in Applied Probability, V6, P463, DOI 10.2307/1426228; West M., 1992, 92A03 DUK U I STAT; Willsky A. S., 2009, ADV NEURAL INFORM PR, P549; Wood F., 2009, P 26 ANN INT C MACH, P1129, DOI DOI 10.1145/1553374.1553518; Zhou Mingyuan, 2012, AISTATS, P1462	53	26	27	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					290	306		10.1109/TPAMI.2014.2318721	http://dx.doi.org/10.1109/TPAMI.2014.2318721			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353242	Green Submitted			2022-12-18	WOS:000349625500007
J	Sagawa, R; Furukawa, R; Kawasaki, H				Sagawa, Ryusuke; Furukawa, Ryo; Kawasaki, Hiroshi			Dense 3D Reconstruction from High Frame-Rate Video Using a Static Grid Pattern	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dense 3D reconstruction; projector-camera systems; grid patterns; spatio-temporal analysis	STRUCTURED-LIGHT; ACQUISITION; PROJECTION	Dense 3D reconstruction of fast moving objects could contribute to various applications such as body structure analysis, accident avoidance, and so on. In this paper, we propose a technique based on a one-shot scanning method, which reconstructs 3D shapes for each frame of a high frame-rate video capturing the scenes projected by a static pattern. To avoid instability of image processing, we restrict the number of colors used in the pattern to less than two. The proposed technique comprises (1) an efficient algorithm to eliminate ambiguity of projected parallel-line patterns by using intersection points, (2) a batch reconstruction algorithm of multiple frames by using spatio-temporal constraints, and (3) an efficient detection method of color-encoded grid pattern based on de Bruijn sequence. In the experiments, the line detection algorithm worked effectively and the dense reconstruction algorithm produces accurate and robust results. We also show the improved results by using temporal constraints. Finally, the dense reconstructions of fast moving objects in a high frame-rate video are presented.	[Sagawa, Ryusuke] Natl Inst Adv Ind Sci & Technol, Intelligent Syst Res Inst, Serv Robot Res Grp, Tsukuba, Ibaraki 3058568, Japan; [Sagawa, Ryusuke] Osaka Univ, Inst Sci & Ind Res, Suita, Osaka 565, Japan; [Furukawa, Ryo] Hiroshima City Univ, Grad Sch Informat Sci, Hiroshima, Japan; [Kawasaki, Hiroshi] Kagoshima Univ, Dept Informat & Biomed Engn, Kagoshima 890, Japan; [Kawasaki, Hiroshi] Saitama Univ, Saitama, Japan; [Kawasaki, Hiroshi] Microsoft Res Redmond, Washington, DC USA	National Institute of Advanced Industrial Science & Technology (AIST); Osaka University; Kagoshima University; Saitama University; Microsoft	Sagawa, R (corresponding author), Natl Inst Adv Ind Sci & Technol, Intelligent Syst Res Inst, Serv Robot Res Grp, Tsukuba Cent 2,1-1-1 Umezono, Tsukuba, Ibaraki 3058568, Japan.	ryusuke.sagawa@aist.go.jp; ryo-f@hiroshima-cu.ac.jp; kawasaki@ibe.kagoshima-u.ac.jp	Furukawa, Ryo/GWZ-2117-2022; Sagawa, Ryusuke/M-4271-2016	Furukawa, Ryo/0000-0002-2063-1008; Sagawa, Ryusuke/0000-0002-6778-8838	Strategic Information and Communications R&D Promotion Programme (SCOPE) [101710002]; Funding Program for Next Generation World-Leading Researchers [LR030]; Adaptable and Seamless Technology Transfer Program through Target-driven RD [AS2421093H]	Strategic Information and Communications R&D Promotion Programme (SCOPE); Funding Program for Next Generation World-Leading Researchers(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science); Adaptable and Seamless Technology Transfer Program through Target-driven RD	This work was supported in part by Strategic Information and Communications R&D Promotion Programme (SCOPE) No.101710002 (Ministry of Internal Affairs and Communications, Japan), Funding Program for Next Generation World-Leading Researchers No. LR030 (Cabinet Office, Government Of Japan), and Adaptable and Seamless Technology Transfer Program through Target-driven R&D No. AS2421093H (JST) in Japan.	[Anonymous], 2012, STANFORD 3D SCANNING; Batlle J, 1998, PATTERN RECOGN, V31, P963, DOI 10.1016/S0031-3203(97)00074-5; Bouguet J.-Y., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P514, DOI 10.1109/CVPR.1999.786986; BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Casey C.J., 2008, HUMAN COMPUTER INTER; Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177; Chang XW, 2007, GPS SOLUT, V11, P289, DOI 10.1007/s10291-007-0063-y; Davis J, 2005, IEEE T PATTERN ANAL, V27, P296, DOI 10.1109/TPAMI.2005.37; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Frueh C, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P318, DOI 10.1109/3DIM.2005.26; Furukawa Ryo, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P40, DOI 10.2197/ipsjtcva.4.40; Furukawa R., 2009, IPSJ T COMPUT VIS AP, V1, P139, DOI [10.2197/ipsjtcva.1.139, DOI 10.2197/IPSJTCVA.1.139]; Guan C, 2003, OPT EXPRESS, V11, P406, DOI 10.1364/OE.11.000406; Guhring J, 2001, PROC SPIE, V4309, P220; Hall-Holt O, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P359, DOI 10.1109/ICCV.2001.937648; Inokuchi S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P806; Je C, 2004, LECT NOTES COMPUT SC, V3021, P95; Kawasaki H., 2010, P 5 INT S 3D DAT PRO, pMay 2010; Kawasaki H., 2008, PROCEEDINGSOF IEEE C, P1; Kawasaki H., 2010, P 1 INT S 3D DAT PRO; Kawasaki H, 2007, LECT NOTES COMPUT SC, V4844, P847; Koninckx TP, 2006, IEEE T PATTERN ANAL, V28, P432, DOI 10.1109/TPAMI.2006.62; Microsoft, 2010, XBOX 360 KINECT; Narasimhan SG, 2008, LECT NOTES COMPUT SC, V5305, P830, DOI 10.1007/978-3-540-88693-8_61; Pan JH, 2005, OPT ENG, V44, DOI 10.1117/1.1840973; Sagawa R., 2009, P IEEE INT C COMP VI; Sagawa R, 2011, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2011.6126460; Salvi J, 1998, PATTERN RECOGN LETT, V19, P1055, DOI 10.1016/S0167-8655(98)00085-3; Tajima J., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P309, DOI 10.1109/ICPR.1990.118121; Teunissen PJG, 1995, J GEODESY, V70, P65, DOI 10.1007/BF00863419; Ulusoy A., 2009, P IEEE INT WORKSH 3; VUYLSTEKE P, 1990, IEEE T PATTERN ANAL, V12, P148, DOI 10.1109/34.44402; Weise T., 2007, IEEE C COMPUTER VISI, P1; Young M., 2007, P IEEE C COMP VIS PA; Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759; Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035; Zhang S, 2006, OPT ENG, V45, DOI 10.1117/1.2336196	38	26	28	0	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1733	1747		10.1109/TPAMI.2014.2300490	http://dx.doi.org/10.1109/TPAMI.2014.2300490			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352228				2022-12-18	WOS:000340210100003
J	Konukoglu, E; Glocker, B; Criminisi, A; Pohl, KM				Konukoglu, Ender; Glocker, Ben; Criminisi, Antonio; Pohl, Kilian M.			WESD-Weighted Spectral Distance for Measuring Shape Dissimilarity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape distance; spectral distance; Laplace operator; Laplace spectrum; segmentations; label maps; medical images	ONE HEAR; SURFACES	This paper presents a new distance for measuring shape dissimilarity between objects. Recent publications introduced the use of eigenvalues of the Laplace operator as compact shape descriptors. Here, we revisit the eigenvalues to define a proper distance, called Weighted Spectral Distance (WESD), for quantifying shape dissimilarity. The definition of WESD is derived through analyzing the heat trace. This analysis provides the proposed distance with an intuitive meaning and mathematically links it to the intrinsic geometry of objects. We analyze the resulting distance definition, present and prove its important theoretical properties. Some of these properties include: 1) WESD is defined over the entire sequence of eigenvalues yet it is guaranteed to converge, 2) it is a pseudometric, 3) it is accurately approximated with a finite number of eigenvalues, and 4) it can be mapped to the [0, 1) interval. Last, experiments conducted on synthetic and real objects are presented. These experiments highlight the practical benefits of WESD for applications in vision and medical image analysis.	[Konukoglu, Ender] Harvard Univ, Massachusetts Gen Hosp, Sch Med, Athinoula A Martinos Ctr Biomed Imaging, Cambridge, MA 02144 USA; [Glocker, Ben; Criminisi, Antonio] Microsoft Res Cambridge, Cambridge CB3 0FB, England; [Pohl, Kilian M.] Univ Penn, Philadelphia, PA 19104 USA	Harvard University; Massachusetts General Hospital; Microsoft; University of Pennsylvania	Konukoglu, E (corresponding author), Harvard Univ, Massachusetts Gen Hosp, Sch Med, Athinoula A Martinos Ctr Biomed Imaging, Cambridge, MA 02144 USA.	ender.konukoglu@gmail.com		Glocker, Ben/0000-0002-4897-9356	Institute for Translational Medicine and Therapeutics (ITMAT) Transdisciplinary Program;  [UL1RR024134]; NATIONAL CENTER FOR RESEARCH RESOURCES [P41RR013218, UL1RR024134] Funding Source: NIH RePORTER	Institute for Translational Medicine and Therapeutics (ITMAT) Transdisciplinary Program; ; NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR))	The authors would like to thank the support in part by Grant Number UL1RR024134 and by the Institute for Translational Medicine and Therapeutics (ITMAT) Transdisciplinary Program.	Ames W.F., 1977, NUMER METH PART D E; ARNOLDI WE, 1951, Q APPL MATH, V9, P17, DOI 10.1090/qam/42792; Bookstein FL, 2001, TERATOLOGY, V64, P4, DOI 10.1002/tera.1044.abs; Bronstein AM, 2008, INT J COMPUT VISION, V78, P67, DOI 10.1007/s11263-007-0078-4; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6; Bronstein M.M., 2010, P IEEE C COMP VIS PA; Bronstein Michael M, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1065, DOI 10.1109/TPAMI.2010.210; Chan T., 2010, P IEEE C COMP VIS PA; Courant R., 1966, METHOD MATH PHYS, V1; Desjardins B., 2012, P 15 INT C MED IM CO; EVANS LC, 1998, AM MATH SOC; Gnutzmann S, 2005, J PHYS A-MATH GEN, V38, P8921, DOI 10.1088/0305-4470/38/41/006; Gnutzmann S, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.090201; GORDON C, 1992, INVENT MATH, V110, P1, DOI 10.1007/BF01231320; Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002; Jain V., 2006, P INT C SHAP MOD APP; Jurman G., 2010, INTRO SPECTRAL DISTA; KAC M, 1966, AM MATH MON, V73, P1, DOI 10.2307/2313748; Levy B., 2006, P IEEE C SHAP MOD AP; Lian ZH, 2010, IEEE IMAGE PROC, P3181, DOI 10.1109/ICIP.2010.5654226; Mansi T, 2011, IEEE T MED IMAGING, V30, P1605, DOI 10.1109/TMI.2011.2135375; McKean H.P., 1967, J DIFFERENTIAL GEOME, V1, P43; Memoli F, 2011, APPL COMPUT HARMON A, V30, P363, DOI 10.1016/j.acha.2010.09.005; Ovsjanikov Maks, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P320, DOI 10.1109/ICCVW.2009.5457682; Pleijel A., 1954, ARK MAT, V2, P553, DOI [10.1007/BF02591229, DOI 10.1007/BF02591229]; PROTTER MH, 1987, SIAM REV, V29, P185, DOI 10.1137/1029041; Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011; Reuter M, 2009, COMPUT AIDED DESIGN, V41, P739, DOI 10.1016/j.cad.2009.02.007; Rustamov R.M., 2007, P EUR S GEOM PROC; Shattuck DW, 2008, NEUROIMAGE, V39, P1064, DOI 10.1016/j.neuroimage.2007.09.031; Shenton M.E., 2007, P 10 INT C MED IM CO; Smeets D, 2009, LECT NOTES COMPUT SC, V5702, P757, DOI 10.1007/978-3-642-03767-2_92; SMITH L, 1981, INVENT MATH, V63, P467, DOI 10.1007/BF01389065; Sun J., 2009, P EUR S GEOM PROC; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Toga A., 2009, P INT S BIOM IM; Vandermeulen D., 2011, P EUR ACM SIGGR S 3D; Vandermuelen D., 2010, P 4 IEEE INT C BIOM; Vassilevich DV, 2003, PHYS REP, V388, P279, DOI 10.1016/j.physrep.2003.09.002; Watson G. N., 1927, COURSE MODERN ANAL; Weyl H, 1912, MATH ANN, V71, P441, DOI 10.1007/BF01456804; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008	43	26	26	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2284	2297		10.1109/TPAMI.2012.275	http://dx.doi.org/10.1109/TPAMI.2012.275			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868785	Green Submitted, Green Accepted			2022-12-18	WOS:000322029000017
J	Kaaniche, MB; Bremond, F				Kaaniche, Mohamed-Becha; Bremond, Francois			Recognizing Gestures by Learning Local Motion Signatures of HOG Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gesture recognition; motion detection; HOG descriptors; feature tracking; probabilistic learning and classification		We introduce a new gesture recognition framework based on learning local motion signatures (LMSs) of HOG descriptors introduced by [1]. Our main contribution is to propose a new probabilistic learning-classification scheme based on a reliable tracking of local features. After the generation of these LMSs computed on one individual by tracking Histograms of Oriented Gradient (HOG) [2] descriptor, we learn a codebook of video-words (i.e., clusters of LMSs) using k-means algorithm on a learning gesture video database. Then, the video-words are compacted to a code-book of codewords by the Maximization of Mutual Information (MMI) algorithm. At the final step, we compare the LMSs generated for a new gesture w.r.t. the learned code-book via the k-nearest neighbors (k-NN) algorithm and a novel voting strategy. Our main contribution is the handling of the N to N mapping between codewords and gesture labels within the proposed voting strategy. Experiments have been carried out on two public gesture databases: KTH [3] and IXMAS [4]. Results show that the proposed method outperforms recent state-of-the-art methods.	[Kaaniche, Mohamed-Becha] Univ Carthage, Digital Secur Res Unit, Higher Sch Commun Tunis SupCom, Ariana, Tunisia; [Bremond, Francois] INRIA, F-06902 Sophia Antipolis, France	Universite de Carthage; Inria	Kaaniche, MB (corresponding author), Univ Carthage, Digital Secur Res Unit, Higher Sch Commun Tunis SupCom, Route Raoued Km 3,5,2083 El Ghazala, Ariana, Tunisia.	medbecha.kaaniche@supcom.rnu.tn; Francois.Bremond@inria.fr		Kaaniche, Mohamed-Becha/0000-0003-4443-5658	ST Microelectronics Rousset [PS26/27]; Conseil Regional Provence-Alpes-Cote d'Azur	ST Microelectronics Rousset; Conseil Regional Provence-Alpes-Cote d'Azur(Region Auvergne-Rhone-AlpesRegion Provence-Alpes-Cote d'Azur)	The authors would like to thank ST Microelectronics Rousset which supported this work under PS26/27 Smart Environment project financed by Conseil Regional Provence-Alpes-Cote d'Azur.	Brox T, 2009, PROC CVPR IEEE, P41, DOI 10.1109/CVPRW.2009.5206697; Calderara Simone, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P121, DOI 10.1109/AVSS.2008.32; Chu C.-W., 2005, COMP VIS PATT REC WO, P69; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Kaaniche M.B., 2010, P IEEE C COMP VIS PA; Kaaniche MB, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P140, DOI 10.1109/AVSS.2009.26; Kim D, 2007, PATTERN RECOGN, V40, P3012, DOI 10.1016/j.patcog.2007.02.010; Liu Jun-Li, 2008, Endocrine Metabolic & Immune Disorders-Drug Targets, V8, P1, DOI 10.2174/187153008783928361; Lu W.-L., 2006, 3 CAN C COMP ROB VIS, P6, DOI DOI 10.1109/CRV; Lu W. L., 2006, P ECCV WORKSH COMP V; Luo Q., 2008, MACHINE VISION APPL, V21, P377; LV F, 2007, P IEEE INT C COMP VI; MATIKAINEN P, 2009, P IEEE INT C COMP VI; McNeill D., 1992, HAND MIND WHAT GESTU; Messing R., 2009, P IEEE INT C COMP VI; Munoz-Salinas R, 2008, PATTERN RECOGN LETT, V29, P319, DOI 10.1016/j.patrec.2007.10.011; Nghiem A.-T., 2009, P 3 INT C IM CRIM DE; Niebles J.C., 2006, BMVC, V3, P1249; Park IC, 2007, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD.2007.4601872; Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42; REDDY KK, 2009, P IEEE INT C COMP VI; Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2008, P ACM INT C MULT, P357; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721; Weinland D, 2007, IEEE I CONF COMP VIS, P170; Yao A., 2010, P IEEE INT C COMP VI; Yilmaz A, 2008, COMPUT VIS IMAGE UND, V109, P335, DOI 10.1016/j.cviu.2007.09.006	31	26	28	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2012	34	11					2247	2258		10.1109/TPAMI.2012.19	http://dx.doi.org/10.1109/TPAMI.2012.19			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	005MR	22997128	Green Submitted			2022-12-18	WOS:000308755000015
J	Ben-Yosef, G; Ben-Shahar, O				Ben-Yosef, Guy; Ben-Shahar, Ohad			A Tangent Bundle Theory for Visual Curve Completion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual completion; curve completion; tangent bundle; inpainting	PERCEPTUAL ORGANIZATION; HORIZONTAL CONNECTIONS; CONTOUR INTERPOLATION; SUBJECTIVE CONTOURS; ILLUSORY CONTOURS; MODEL; SHAPE; STATISTICS	Visual curve completion is a fundamental perceptual mechanism that completes the missing parts (e. g., due to occlusion) between observed contour fragments. Previous research into the shape of completed curves has generally followed an "axiomatic" approach, where desired perceptual/geometrical properties are first defined as axioms, followed by mathematical investigation into curves that satisfy them. However, determining psychophysically such desired properties is difficult and researchers still debate what they should be in the first place. Instead, here we exploit the observation that curve completion is an early visual process to formalize the problem in the unit tangent bundle R-2 x S-1, which abstracts the primary visual cortex (V1) and facilitates exploration of basic principles from which perceptual properties are later derived rather than imposed. Exploring here the elementary principle of least action in V1, we show how the problem becomes one of finding minimum-length admissible curves in R-2 x S-1. We formalize the problem in variational terms, we analyze it theoretically, and we formulate practical algorithms for the reconstruction of these completed curves. We then explore their induced visual properties vis-a-vis popular perceptual axioms and show how our theory predicts many perceptual properties reported in the corresponding perceptual literature. Finally, we demonstrate a variety of curve completions and report comparisons to psychophysical data and other completion models.	[Ben-Yosef, Guy; Ben-Shahar, Ohad] Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel	Ben Gurion University	Ben-Yosef, G (corresponding author), Ben Gurion Univ Negev, Dept Comp Sci, POB 653, IL-84105 Beer Sheva, Israel.	guybeny@cs.bgu.ac.il; ben-shahar@cs.bgu.ac.il	Ben-Shahar, Ohad/F-8918-2015	Ben-Shahar, Ohad/0000-0001-5346-152X	European Commission (CROPS GA) [246252]; Israel Science Foundation (ISF) [1245/08]; Frankel fund; Paul Ivanier center for Robotics Research; Zlotowski Center for Neuroscience at Ben-Gurion University	European Commission (CROPS GA); Israel Science Foundation (ISF)(Israel Science Foundation); Frankel fund; Paul Ivanier center for Robotics Research; Zlotowski Center for Neuroscience at Ben-Gurion University	This work was funded in part by the European Commission in the 7th Framework Programme (CROPS GA no. 246252) and the Israel Science Foundation (ISF) grant No. 1245/08. The authors also thank the generous support of the Frankel fund, the Paul Ivanier center for Robotics Research, and the Zlotowski Center for Neuroscience at Ben-Gurion University.	Ben-Shahar O, 2004, NEURAL COMPUT, V16, P445, DOI 10.1162/089976604772744866; Ben-Shahar O, 2003, IEEE T PATTERN ANAL, V25, P401, DOI 10.1109/TPAMI.2003.1190568; Ben-Shahar O., 2003, THESIS YALE U; Ben-Yosef G., 2010, P IEEE C COMP VIS PA; Bosking WH, 1997, J NEUROSCI, V17, P2112; Brady M, 1980, AAAI, P15; Citti G, 2006, J MATH IMAGING VIS, V24, P307, DOI 10.1007/s10851-005-3630-2; COREN S, 1972, PSYCHOL REV, V79, P359, DOI 10.1037/h0032940; Fantoni C, 2003, J VISION, V3, P281, DOI 10.1167/3.4.4; Fulvio JM, 2008, VISION RES, V48, P831, DOI 10.1016/j.visres.2007.12.018; Fulvio JM, 2009, J VISION, V9, DOI 10.1167/9.4.5; Geisler WS, 2009, VISUAL NEUROSCI, V26, P109, DOI 10.1017/S0952523808080875; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; Gerbino W, 2006, VISION RES, V46, P3142, DOI 10.1016/j.visres.2006.03.030; GILBERT CD, 1992, NEURON, V9, P1, DOI 10.1016/0896-6273(92)90215-Y; GROSOF DH, 1993, NATURE, V365, P550, DOI 10.1038/365550a0; Guttman SE, 2004, VISION RES, V44, P1799, DOI 10.1016/j.visres.2004.02.008; Hladky RK, 2010, J MATH IMAGING VIS, V36, P1, DOI 10.1007/s10851-009-0167-9; HOFFMAN WC, 1989, APPL MATH COMPUT, V32, P137, DOI 10.1016/0096-3003(89)90091-X; HORN BKP, 1983, ACM T MATH SOFTWARE, V9, P441, DOI 10.1145/356056.356061; HOSCHEK J, 1989, FUNDAMENTALS COMPUTE; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; Jung YM, 2008, J VIS COMMUN IMAGE R, V19, P42, DOI 10.1016/j.jvcir.2007.07.001; Kanizsa Gaetano, 1979, ORG VISION ESSAYS GE; KELLMAN PJ, 1991, COGNITIVE PSYCHOL, V23, P141, DOI 10.1016/0010-0285(91)90009-D; Kimia BB, 2003, INT J COMPUT VISION, V54, P157, DOI 10.1023/A:1023713602895; KNUTH DE, 1979, B AM MATH SOC, V1, P337, DOI 10.1090/S0273-0979-1979-14598-1; Kohler W., 1920, SOURCE BOOK GESTALT, P17; Landau L.D., 1986, THEORY ELASTICITY, DOI 10.1016/C2009-0-25521-8; Lee TS, 2001, P NATL ACAD SCI USA, V98, P1907, DOI 10.1073/pnas.031579998; Levien R., 2008, UCBEECS2008111; Levien R., 2008, UCBEECS2008103; Love A.E.H, 2013, TREATISE MATH THEORY; MUMFORD D, 1994, ALGEBRIC GEOMETRY IT; O'Neill B., 1983, SEMIRIEMANNIAN GEOME; Palmer S.E., 1999, VISION SCI PHOTONS P; Petitot J., 2003, AXIOMATHES, V13, P347; Ren XF, 2008, INT J COMPUT VISION, V77, P47, DOI 10.1007/s11263-007-0092-6; Ringach DL, 1996, VISION RES, V36, P3037, DOI 10.1016/0042-6989(96)00062-4; ROCKLAND KS, 1982, SCIENCE, V215, P1532, DOI 10.1126/science.7063863; RUTKOWSKI WS, 1979, COMPUT VISION GRAPH, V9, P89, DOI 10.1016/0146-664X(79)90086-8; Sarti A, 2002, INT J COMPUT VISION, V46, P201, DOI 10.1023/A:1014028906229; SCHOENBERG IJ, 1946, Q APPL MATH, V4, P45, DOI 10.1090/qam/15914; Schumann F., 1904, Z PSYCHOL, V33, P161; Sharon E, 2000, IEEE T PATTERN ANAL, V22, P1117, DOI 10.1109/34.879792; Singh M, 2005, P NATL ACAD SCI USA, V102, P939, DOI 10.1073/pnas.0408444102; Singh M, 2004, PSYCHOL SCI, V15, P454, DOI 10.1111/j.0956-7976.2004.00701.x; Singh M, 1999, PERCEPT PSYCHOPHYS, V61, P943, DOI 10.3758/BF03206908; TAKEICHI H, 1995, PERCEPTION, V24, P1011, DOI 10.1068/p241011; ULLMAN S, 1976, BIOL CYBERN, V25, P1; VONDERHEYDT R, 1984, SCIENCE, V224, P1260, DOI 10.1126/science.6539501; WEISS I, 1988, COMPUT VISION GRAPH, V41, P80, DOI 10.1016/0734-189X(88)90118-1; Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640; Willard S., 2012, GEN TOPOLOGY; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837	56	26	27	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1263	1280		10.1109/TPAMI.2011.262	http://dx.doi.org/10.1109/TPAMI.2011.262			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22201060	Green Submitted			2022-12-18	WOS:000304138300002
J	Hwang, Y; Kim, JS; Kweon, IS				Hwang, Youngbae; Kim, Jun-Sik; Kweon, In So			Difference-Based Image Noise Modeling Using Skellam Distribution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Difference-based noise modeling; Skellam distribution; edge detection; background subtraction	EDGE	By the laws of quantum physics, pixel intensity does not have a true value, but should be a random variable. Contrary to the conventional assumptions, the distribution of intensity may not be an additive Gaussian. We propose to directly model the intensity difference and show its validity by an experimental comparison to the conventional additive model. As a model of the intensity difference, we present a Skellam distribution derived from the Poisson photon noise model. This modeling induces a linear relationship between intensity and Skellam parameters, while conventional variance computation methods do not yield any significant relationship between these parameters under natural illumination. The intensity-Skellam line is invariant to scene, illumination, and even most of camera parameters. We also propose practical methods to obtain the line using a color pattern and an arbitrary image under natural illumination. Because the Skellam parameters that can be obtained from this linearity determine a noise distribution for each intensity value, we can statistically determine whether any intensity difference is caused by an underlying signal difference or by noise. We demonstrate the effectiveness of this new noise model by applying it to practical applications of background subtraction and edge detection.	[Hwang, Youngbae] KETI, Multimedia IP Ctr, Songnam 463816, Gyeonggi Do, South Korea; [Kim, Jun-Sik] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Kweon, In So] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea	Korea Electronics Technology Institute (KETI); Carnegie Mellon University; Korea Advanced Institute of Science & Technology (KAIST)	Hwang, Y (corresponding author), KETI, Multimedia IP Ctr, 68 Yatap Dong, Songnam 463816, Gyeonggi Do, South Korea.	ybhwang@keti.re.kr; kimjs@cs.cmu.edu; iskweon@ee.kaist.ac.kr	Kweon, In So/C-2023-2011		National Research Laboratory (NRL) of the Ministry of Science and Technology (MOST) [M1-0302-00-0064]; National Research Foundation of Korea (NRF); Korea government (MEST) [2011-0018250]	National Research Laboratory (NRL) of the Ministry of Science and Technology (MOST); National Research Foundation of Korea (NRF)(National Research Foundation of Korea); Korea government (MEST)(Ministry of Education, Science & Technology (MEST), Republic of KoreaKorean Government)	This research is supported by the National Research Laboratory (NRL) program (No. M1-0302-00-0064) of the Ministry of Science and Technology (MOST) and the National Research Foundation of Korea (NRF) grant funded by the Korea government (MEST) (No. 2011-0018250).	Abramowitz M., 1972, HDB MATH FUNCTIONS F; Alter F, 2006, LECT NOTES COMPUT SC, V3954, P267; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Dougherty E. D., 1990, PROBABILITY STAT ENG; Foi A, 2008, IEEE T IMAGE PROCESS, V17, P1737, DOI 10.1109/TIP.2008.2001399; Harwood D., 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; Hwang Y., 2007, P IEEE C COMP VIS PA; Liu C., 2006, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2006.207; Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI [10.1109/TPAMI.2007.1176, 10.1109/TPAMI.20071176]; Ruzon MA, 2001, IEEE T PATTERN ANAL, V23, P1281, DOI 10.1109/34.969118; SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339; SKELLAM JG, 1946, J ROY STAT SOC A STA, V109, P296, DOI 10.2307/2981372; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Van de Weijer J, 2006, IEEE T IMAGE PROCESS, V15, P118, DOI 10.1109/TIP.2005.860343; van de Weijer J, 2005, IEEE T PATTERN ANAL, V27, P625, DOI 10.1109/TPAMI.2005.75; Yavuz M., 2000, P IEEE NSS MIC, p15/229; Young I., 1997, DIGIT SIGNAL PROCESS, pXI	19	26	27	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1329	1341		10.1109/TPAMI.2011.224	http://dx.doi.org/10.1109/TPAMI.2011.224			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22144520				2022-12-18	WOS:000304138300006
J	Tan, P; Quan, L; Zickler, T				Tan, Ping; Quan, Long; Zickler, Todd			The Geometry of Reflectance Symmetries	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Reflectance symmetry; projective geometry; autocalibration; photometric stereo	PHOTOMETRIC STEREO; SURFACES; COLOR; SHAPE	Different materials reflect light in different ways, and this reflectance interacts with shape, lighting, and viewpoint to determine an object's image. Common materials exhibit diverse reflectance effects, and this is a significant source of difficulty for image analysis. One strategy for dealing with this diversity is to build computational tools that exploit reflectance symmetries, such as reciprocity and isotropy, that are exhibited by broad classes of materials. By building tools that exploit these symmetries, one can create vision systems that are more likely to succeed in real-world, non-Lambertian environments. In this paper, we develop a framework for representing and exploiting reflectance symmetries. We analyze the conditions for distinct surface points to have local view and lighting conditions that are equivalent under these symmetries, and we represent these conditions in terms of the geometric structure they induce on the Gaussian sphere and its abstraction, the projective plane. We also study the behavior of these structures under perturbations of surface shape and explore applications to both calibrated and uncalibrated photometric stereo.	[Tan, Ping] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore; [Quan, Long] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China; [Zickler, Todd] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA	National University of Singapore; Hong Kong University of Science & Technology; Harvard University	Tan, P (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.	eletp@nus.edu.sg; quan@cse.ust.hk; zickler@eecs.harvard.edu		Tan, Ping/0000-0002-4506-6973	Singapore MOE [R-263-000-555-112]; HOME 2015 project [R-263-000-592-305]; Hong Kong RGC GRF [619409, 618510, 618908]; National Natural Science Foundation of China [60933006]; US National Science Foundation [IIS-0546408]; US Office of Naval Research [N000140911022]; US Army Research Laboratory; US Army Research Office [54262-CI]; Alfred P. Sloan Foundation	Singapore MOE(Ministry of Education, Singapore); HOME 2015 project; Hong Kong RGC GRF(Hong Kong Research Grants Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); US National Science Foundation(National Science Foundation (NSF)); US Office of Naval Research(Office of Naval Research); US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); US Army Research Office; Alfred P. Sloan Foundation(Alfred P. Sloan Foundation)	The authors thank the anonymous reviewers for their valuable feedback and Neil Alldrin for sharing his code and data. This work was supported by the Singapore MOE grant R-263-000-555-112 and HOME 2015 project R-263-000-592-305. Long Quan was supported by the Hong Kong RGC GRF 619409, 618510, and 618908, and the National Natural Science Foundation of China (60933006). Todd Zickler was supported by the US National Science Foundation under Career Award IIS-0546408, the US Office of Naval Research through award N000140911022, the US Army Research Laboratory and the US Army Research Office under contract/grant 54262-CI, and a fellowship from the Alfred P. Sloan Foundation.	Alldrin N., 2008, P IEEE C COMP VIS PA; Alldrin N. G., 2007, P IEEE C COMP VIS PA; [Anonymous], 2005, P IEEE INT C COMP VI; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Cook R., 1982, ACM T GRAPHIC, V1, P7, DOI DOI 10.1145/357290.357293; Coxeter H.S.M., 1993, REAL PROJECTIVE PLAN, V3rd; Drbohlav O, 2005, IEEE I CONF COMP VIS, P1850; Drbohlav O, 2002, LECT NOTES COMPUT SC, V2351, P46; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; Joshi N., 2007, P IEEE INT C COMP VI; Koenderink JJ, 2001, PERCEPTION, V30, P431, DOI 10.1068/p3030; Lafortune E. P. F., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P117, DOI 10.1145/258734.258801; LU J, 1999, INT J COMPUT VISION, V32, P1; Lu JP, 1999, INT J COMPUT VISION, V32, P213, DOI 10.1023/A:1008157029424; Marschner S. R, 1998, THESIS CORNELL U; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Ngan A, 2005, EUR S REND, V2, P117, DOI DOI 10.2312/EGWR/EGSR05/117-126; Nicodemus F., 1977, NBS US MONOGRAPH, V161; PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839; Romeiro F., 2008, P 10 EUR C COMP VIS; Rusinkiewicz S. M., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P11; SATO Y, 1994, J OPT SOC AM A, V11, P2990, DOI 10.1364/JOSAA.11.002990; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Stark MM, 2005, IEEE T VIS COMPUT GR, V11, P126, DOI 10.1109/TVCG.2005.26; TAGARE HD, 1991, IEEE T PATTERN ANAL, V13, P133, DOI 10.1109/34.67643; Tan P., 2006, P EUR C COMP VIS; Tan P., 2009, P IEEE C COMP VIS PA; Tan P., 2007, P IEEE C COMP VIS PA; VONHELMHOLTZ H, 1925, TREATISE PHYSL OPTIC, V1; WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078; Woodham R. J., 1978, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.155. Image Understanding Systems and Industrial Applications, P136; Yuille A., 1997, P IEEE C COMP VIS PA; ZICKLER T, 2002, P EUR C COMP VIS; Zickler TE, 2003, PROC CVPR IEEE, P548; Zickler TE, 2002, INT J COMPUT VISION, V49, P215, DOI 10.1023/A:1020149707513	37	26	26	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2506	2520		10.1109/TPAMI.2011.35	http://dx.doi.org/10.1109/TPAMI.2011.35			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21339528				2022-12-18	WOS:000295980000015
J	Harmeling, S; Williams, CKI				Harmeling, Stefan; Williams, Christopher K. I.			Greedy Learning of Binary Latent Trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised learning; latent variable model; hierarchical latent class model; greedy methods	MODELS	Inferring latent structures from observations helps to model and possibly also understand underlying data generating processes. A rich class of latent structures is the latent trees, i.e., tree-structured distributions involving latent variables where the visible variables are leaves. These are also called hierarchical latent class (HLC) models. Zhang and Kocka [21] proposed a search algorithm for learning such models in the spirit of Bayesian network structure learning. While such an approach can find good solutions, it can be computationally expensive. As an alternative, we investigate two greedy procedures: The BIN-G algorithm determines both the structure of the tree and the cardinality of the latent variables in a bottom-up fashion. The BIN-A algorithm first determines the tree structure using agglomerative hierarchical clustering, and then determines the cardinality of the latent variables as for BIN-G. We show that even with restricting ourselves to binary trees, we obtain HLC models of comparable quality to Zhang's solutions (in terms of cross-validated log-likelihood), while being generally faster to compute. This claim is validated by a comprehensive comparison on several data sets. Furthermore, we demonstrate that our methods are able to estimate interpretable latent structures on real-world data with a large number of variables. By applying our method to a restricted version of the 20 newsgroups data, these models turn out to be related to topic models, and on data from the PASCAL Visual Object Classes (VOC) 2007 challenge, we show how such tree-structured models help us understand how objects co-occur in images. For reproducibility of all experiments in this paper, all code and data sets (or links to data) are available at http://people.kyb.tuebingen.mpg.de/harmeling/code/ltt-1.4.tar.	[Harmeling, Stefan] Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany; [Williams, Christopher K. I.] Univ Edinburgh, Inst Adapt & Neural Computat, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland	Max Planck Society; University of Edinburgh	Harmeling, S (corresponding author), Max Planck Inst Biol Cybernet, Spemannstr 38, D-72076 Tubingen, Germany.	stefan.harmeling@tuebingen.mpg.de; ckiw@inf.ed.ac.uk			European Community, under the PASCAL Network of Excellence [IST-2002-506778]	European Community, under the PASCAL Network of Excellence(European Commission)	The authors thank Nevin L. Zhang for making compiled code of the algorithm in Zhang and Kocka [22] available, and Christoph Lampert for generating the vision data sets. They thank the anonymous reviewers for their comments that helped improve the paper; in particular, they thank the reviewer who pushed them to formalize the BIN-A algorithm and compare it with BIN-G. Furthermore, Stefan Harmeling thanks Dominik Janzing and Hannes Nickisch for general discussion. This work is supported in part by the IST Programme of the European Community, under the PASCAL Network of Excellence, IST-2002-506778. This publication reflects only the authors' views.	Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bollen K. A, 1989, STRUCTURAL EQUATIONS; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CONNOLLY D, 1993, P 10 INT C MACH LEAR, P65; Duda R.O., 2000, PATTERN CLASSIFICATI; Felsenstein J., 2004, INFERRING PHYLOGENIE; Feng XJ, 2002, IEEE T PATTERN ANAL, V24, P467, DOI 10.1109/34.993555; Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1007/BF00114265; FRIEDMAN N, 2003, 80 HEBR U; Ghahramani Z., 2005, P 22 INT C MACH LEAR, P297, DOI DOI 10.1145/1102351.1102389; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kemp C, 2008, P NATL ACAD SCI USA, V105, P10687, DOI 10.1073/pnas.0802631105; KOHLMANN T, 1997, APPL LATENT TRAIT LA; Kojadinovic I, 2004, COMPUT STAT DATA AN, V46, P269, DOI 10.1016/S0167-9473(03)00153-1; Lazarsfeld P.F., 1968, LATENT STRUCTURE ANA; Neal RM, 2003, BAYESIAN STATISTICS 7, P619; Teh Y. W., 2008, ADV NEURAL INFORM PR, P1481; Wang Y, 2008, J ARTIF INTELL RES, V32, P879, DOI 10.1613/jair.2530; WILLIAMS CKI, 2000, ADV NEURAL INFORM PR, V12; Zhang NL, 2004, J MACH LEARN RES, V5, P697; Zhang NL, 2004, P 16 IEEE INT C TOOL	22	26	26	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1087	1097		10.1109/TPAMI.2010.145	http://dx.doi.org/10.1109/TPAMI.2010.145			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	20714018	Green Submitted, Green Accepted			2022-12-18	WOS:000289524000002
J	Christou, IT				Christou, Ioannis T.			Coordination of Cluster Ensembles via Exact Methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering; machine learning; constrained optimization; combinatorial algorithms	MINIMUM SUM; CONSENSUS	We present a novel optimization-based method for the combination of cluster ensembles for the class of problems with intracluster criteria, such as Minimum-Sum-of-Squares-Clustering (MSSC). We propose a simple and efficient algorithm-called EXAMCE-for this class of problems that is inspired from a Set-Partitioning formulation of the original clustering problem. We prove some theoretical properties of the solutions produced by our algorithm, and in particular that, under general assumptions, though the algorithm recombines solution fragments so as to find the solution of a Set-Covering relaxation of the original formulation, it is guaranteed to find better solutions than the ones in the ensemble. For the MSSC problem in particular, a prototype implementation of our algorithm found a new better solution than the previously best known for 21 of the test instances of the 40-instance TSPLIB benchmark data sets used in [1], [2], and [3], and found a worse-quality solution than the best known only five times. For other published benchmark data sets where the optimal MSSC solution is known, we match them. The algorithm is particularly effective when the number of clusters is large, in which case it is able to escape the local minima found by K-means type algorithms by recombining the solutions in a Set-Covering context. We also establish the stability of the algorithm with extensive computational experiments, by showing that multiple runs of EXAMCE for the same clustering problem instance produce high-quality solutions whose Adjusted Rand Index is consistently above 0.95. Finally, in experiments utilizing external criteria to compute the validity of clustering, EXAMCE is capable of producing high-quality results that are comparable in quality to those of the best known clustering algorithms.	[Christou, Ioannis T.] Athens Informat Technol, Paiania 19002, Greece; [Christou, Ioannis T.] Carnegie Mellon Univ, Informat Networking Inst, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Christou, IT (corresponding author), Athens Informat Technol, 19Km Markopoulou Ave,Box 68, Paiania 19002, Greece.	ichr@ait.edu.gr						Achterberg T, 2007, THESIS TU BERLIN; AKTEKEOZTURK B, 2007, P 20 MINIEURO C CONT; Asuncion A, 2007, UCI MACHINE LEARNING; Ayad HG, 2008, IEEE T PATTERN ANAL, V30, P160, DOI 10.1109/TPAMI.2007.1138; Baum E., 1986, NEURAL NETWORKS COMP; Bradley PS., 2000, MICROSOFT RES REDMON, V20, P0; Breiman L., 1994, 421 U CAL BERK DEP S; CHRISTOU IT, 2000, NONLINEAR ASSIGNMENT; DANTZIG GB, 1960, OPER RES, V8, P101, DOI 10.1287/opre.8.1.101; Dimitriadou E, 2002, INT J PATTERN RECOGN, V16, P901, DOI 10.1142/S0218001402002052; Du Merle O, 2000, SIAM J SCI COMPUT, V21, P1485, DOI 10.1137/S1064827597328327; Fischer B, 2003, IEEE T PATTERN ANAL, V25, P1411, DOI 10.1109/TPAMI.2003.1240115; Hansen P., 1997, Location Science, V5, P207, DOI 10.1016/S0966-8349(98)00030-8; Hansen P, 2001, PATTERN RECOGN, V34, P405, DOI 10.1016/S0031-3203(99)00216-2; Hansen P, 1997, MATH PROGRAM, V79, P191, DOI 10.1007/BF02614317; JAIN AK, 2002, STRUCTURAL SYNTACTIC, P442; Karypis G, 2000, VLSI DES, V11, P285, DOI 10.1155/2000/19436; Kuncheva L I, 2004, COMBINING PATTERN CL; Kuncheva LI, 2006, IEEE T PATTERN ANAL, V28, P1798, DOI 10.1109/TPAMI.2006.226; LANGE T, 2005, P INT C KNOWL DISC D; Laszlo M, 2006, IEEE T PATTERN ANAL, V28, P533, DOI 10.1109/TPAMI.2006.66; Li HF, 2004, 2004 IEEE COMPUTATIONAL SYSTEMS BIOINFORMATICS CONFERENCE, PROCEEDINGS, P142; Meila M., 2005, P 22 INT C MACH LEAR, P577; Nemhauser G.L., 1988, INTEGER COMBINATORIA; Pacheco JA, 2005, COMPUT OPER RES, V32, P1325, DOI 10.1016/j.cor.2003.11.006; Pelleg D., 2000, P 17 INT C MACH LEAR, DOI DOI 10.1038/S41598-021-86770-6; PENG JM, 2005, FDN RECENT ADV DATA, P79; Resende MGC, 2004, J HEURISTICS, V10, P59, DOI 10.1023/B:HEUR.0000019986.96257.50; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Singh V., 2008, ADV NEURAL INFORM PR, P1353; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1; Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237	33	26	26	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					279	293		10.1109/TPAMI.2010.85	http://dx.doi.org/10.1109/TPAMI.2010.85			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	20421664				2022-12-18	WOS:000285313200006
J	Ben-Ari, R; Sochen, N				Ben-Ari, Rami; Sochen, Nir			Stereo Matching with Mumford-Shah Regularization and Occlusion Handling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; Mumford-Shah functional; variational stereo vision; occlusion handling; Total Variation		This paper addresses the problem of correspondence establishment in binocular stereo vision. We suggest a novel spatially continuous approach for stereo matching based on the variational framework. The proposed method suggests a unique regularization term based on Mumford-Shah functional for discontinuity preserving, combined with a new energy functional for occlusion handling. The evaluation process is based on concurrent minimization of two coupled energy functionals, one for domain segmentation (occluded versus visible) and the other for disparity evaluation. In addition to a dense disparity map, our method also provides an estimation for the half-occlusion domain and a discontinuity function allocating the disparity/depth boundaries. Two new constraints are introduced improving the revealed discontinuity map. The experimental tests include a wide range of real data sets from the Middlebury stereo database. The results demonstrate the capability of our method in calculating an accurate disparity function with sharp discontinuities and occlusion map recovery. Significant improvements are shown compared to a recently published variational stereo approach. A comparison on the Middlebury stereo benchmark with subpixel accuracies shows that our method is currently among the top-ranked stereo matching algorithms.	[Ben-Ari, Rami] Orbotech Ltd, IL-81101 Yavne, Israel; [Sochen, Nir] Tel Aviv Univ, Sch Math Sci, Dept Appl Math, IL-69978 Tel Aviv, Israel	Tel Aviv University	Ben-Ari, R (corresponding author), Orbotech Ltd, IL-81101 Yavne, Israel.	rami-ba@Orbotech.com; sochen@post.ac.il						Alicandro R., 1999, INTERFACE FREE BOUND, V1, P17, DOI DOI 10.4171/IFB/2; Alvarez L, 2002, J VIS COMMUN IMAGE R, V13, P3, DOI 10.1006/jvci.2001.0482; AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805; AMIAZ T, 2005, P ICIP 2005 GEN IT S, V3, P1264; Bar L, 2007, IEEE T IMAGE PROCESS, V16, P1101, DOI 10.1109/TIP.2007.891805; BENARI R, 2007, IEEE 11 INT C COMP V, P1, DOI DOI 10.1109/ICCV.2007.4408996; Bleyer M, 2004, IEEE IMAGE PROC, P2997; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; BROX T, 2004, P 8 EUR C COMP VIS, V4, P25; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; DALMASO G, 1993, PROGR NONLINEAR DIFF; DHOND UR, 1995, IEEE T PATTERN ANAL, V17, P719, DOI 10.1109/34.391415; Di Stefano L., 2007, P IEEE PAC RIM S IM; Evans LC., 1992, MEASURE THEORY FINE; Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428; GEHRIG S, 2007, P IEEE INT C COMP VI; GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; Kim H, 2003, IEEE IMAGE PROC, P373; Klaus A, 2006, INT C PATT RECOG, P15; KLODT M, 2008, P EUR C COMP VIS; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Kumar A, 1997, IEEE DECIS CONTR P, P1125, DOI 10.1109/CDC.1997.657598; Lei C., 2006, P IEEE COMP SOC C CO, V2, P2378, DOI DOI 10.1109/CVPR.2006.251; MANSOURI AR, 1998, P IEEE INT C IM PROC, V3, P114; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; Mattoccia S., 2009, P AS C COMP VIS; MILED W, P 3 CAN C COMP ROB V; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Nir T, 2008, INT J COMPUT VISION, V76, P205, DOI 10.1007/s11263-007-0051-2; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; POCK T, 2008, P EUR C COMP VIS; ROBERT L, 1996, P EUR C COMP VIS, P439; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Shah J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P202, DOI 10.1109/CVPR.1991.139688; Shah J., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P34, DOI 10.1109/CVPR.1993.341004; Slesareva N, 2005, LECT NOTES COMPUT SC, V3663, P33; Sun J, 2005, PROC CVPR IEEE, P399; Tikhonov A.N., 1977, SOLUTION ILL POSED P; VENKATESWAR V, 1995, INT J COMPUT VISION, V15, P245, DOI 10.1007/BF01451743; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; Yang Q., 2006, P IEEE C COMP VIS PA, P2347; YANG Q, 2007, P IEEE C COMP VIS PA; Yoon KJ, 2005, PROC CVPR IEEE, P924; 2010, MIDDLEBURY OPTICAL F; 2010, STEREO MATCHING BASE; [No title captured]; 2010, MIDDLEBURY STEREO BE	50	26	29	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2010	32	11					2071	2084		10.1109/TPAMI.2010.32	http://dx.doi.org/10.1109/TPAMI.2010.32			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	652GI	20847394				2022-12-18	WOS:000281990900010
J	Alahari, K; Kohli, P; Torr, PHS				Alahari, Karteek; Kohli, Pushmeet; Torr, Philip H. S.			Dynamic Hybrid Algorithms for MAP Inference in Discrete MRFs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; multilabel problems; energy minimization; approximate algorithms	ENERGY MINIMIZATION	In this paper, we present novel techniques that improve the computational and memory efficiency of algorithms for solving multilabel energy functions arising from discrete MRFs or CRFs. These methods are motivated by the observations that the performance of minimization algorithms depends on: 1) the initialization used for the primal and dual variables and 2) the number of primal variables involved in the energy function. Our first method (dynamic alpha-expansion) works by "recycling" results from previous problem instances. The second method simplifies the energy function by "reducing" the number of unknown variables present in the problem. Further, we show that it can also be used to generate a good initialization for the dynamic alpha-expansion algorithm by "reusing" dual variables. We test the performance of our methods on energy functions encountered in the problems of stereo matching and color and object-based segmentation. Experimental results show that our methods achieve a substantial improvement in the performance of alpha-expansion, as well as other popular algorithms such as sequential tree-reweighted message passing and max-product belief propagation. We also demonstrate the applicability of our schemes for certain higher order energy functions, such as the one described in [1], for interactive texture-based image and video segmentation. In most cases, we achieve a 10-15 times speed-up in the computation time. Our modified alpha-expansion algorithm provides similar performance to Fast-PD [2], but is conceptually much simpler. Both alpha-expansion and Fast-PD can be made orders of magnitude faster when used in conjunction with the "reduce" scheme proposed in this paper.	[Alahari, Karteek; Torr, Philip H. S.] Oxford Brookes Univ, Dept Comp, Sch Technol, Oxford OX33 1HX, England; [Kohli, Pushmeet] Microsoft Res Cambridge, Cambridge CB3 0FB, England	Oxford Brookes University; Microsoft	Alahari, K (corresponding author), Oxford Brookes Univ, Dept Comp, Sch Technol, Oxford OX33 1HX, England.	karteek.alahari@brookes.ac.uk; pkohli@microsoft.com; philiptorr@brookes.ac.uk	Alahari, Karteek/AAL-1766-2020	Alahari, Karteek/0000-0002-1838-5936	EPSRC [EP/C006631/1(P), GR/T21790/01(P)]; European Community under the PASCAL2 Network of Excellence [IST-2007-216886]; Royal Society	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); European Community under the PASCAL2 Network of Excellence(European Commission); Royal Society(Royal Society of London)	This work was supported by the EPSRC research grants EP/C006631/1(P) and GR/T21790/01(P), the IST Programme of the European Community, under the PASCAL2 Network of Excellence, IST-2007-216886. P.H.S. Torr is in receipt of Royal Society Wolfson Research Merit Award.	Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Felzenszwalb PR, 2004, PROC CVPR IEEE, P261; Freedman D, 2005, PROC CVPR IEEE, P939; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; IWATA S, 1999, P 7 MPS C INT PROGR, P259; Juan O., 2006, P IEEE COMP SOC C CO, V1, P1023, DOI [DOI 10.1109/CVPR.2006.47, 10.1109/CVPR.2006.47]; Kohli P, 2005, IEEE I CONF COMP VIS, P922; Kohli P., 2008, P 25 INT C MACH LEAR, P480, DOI DOI 10.1145/1390156.1390217; KOHLI P, 2008, P IEEE INT C COMP VI; Kohli P, 2009, IEEE T PATTERN ANAL, V31, P1645, DOI 10.1109/TPAMI.2008.217; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Komodakis N, 2005, IEEE I CONF COMP VIS, P1018; KOMODAKIS N, 2007, P IEEE INT C COMP VI; Kovtun I, 2003, LECT NOTES COMPUT SC, V2781, P402; KOVTUN I, 2004, THESIS IRTC ITS NAT; Lan XY, 2006, LECT NOTES COMPUT SC, V3952, P269; Paget R, 1998, IEEE T IMAGE PROCESS, V7, P925, DOI 10.1109/83.679446; PEARL J, 1998, PROBABILISTIC REASON; Roth S, 2005, PROC CVPR IEEE, P860; Rother C, 2005, PROC CVPR IEEE, P589; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; SCHLENKER B, 2006, EUR UROL, V6, P1; SCHLESINGER M, 2002, 10 LECT STAT STRUCTU; SCHROFF F, 2006, P IND C COMP VIS GRA; SHOTTON J, 2006, P EUR C COMP VIS, V1, P1, DOI DOI 10.1007/11744023_; Szeliski R, 2006, LECT NOTES COMPUT SC, V3952, P16; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036; Yedidia JS, 2000, ADV NEURAL INFORM PR, V13, P689; ZALESKY B, 2003, EFFICIENT DETERMINAT	37	26	28	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1846	1857		10.1109/TPAMI.2009.194	http://dx.doi.org/10.1109/TPAMI.2009.194			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20724761	Green Submitted			2022-12-18	WOS:000281000700010
J	Lee, S; Liu, YX				Lee, Seungkyu; Liu, Yanxi			Skewed Rotation Symmetry Group Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Skewed rotation symmetry; symmetry group; frieze group; discrete Fourier transform; saliency map; cyclic group; dihedral group	MODEL; PERCEPTION; ATTENTION; OBJECT; SHAPE	We present a novel and effective algorithm for affinely skewed rotation symmetry group detection from real-world images. We define a complete skewed rotation symmetry detection problem as discovering five independent properties of a skewed rotation symmetry group: 1) the center of rotation, 2) the affine deformation, 3) the type of the symmetry group, 4) the cardinality of the symmetry group, and 5) the supporting region of the symmetry group in the image. We propose a frieze-expansion (FE) method that transforms rotation symmetry group detection into a simple, 1D translation symmetry detection problem. We define and construct a pair of rotational symmetry saliency maps, complemented by a local feature method. Frequency analysis, using Discrete Fourier Transform (DFT), is applied to the frieze-expansion patterns (FEPs) to uncover the types (cyclic, dihedral, and O(2)), the cardinalities, and the corresponding supporting regions, concentric or otherwise, of multiple rotation symmetry groups in an image. The phase information of the FEP is used to rectify affinely skewed rotation symmetry groups. Our result advances the state of the art in symmetry detection by offering a unique combination of region-based, feature-based, and frequency-based approaches. Experimental results on 170 synthetic and natural images demonstrate superior performance of our rotation symmetry detection algorithm over existing methods.	[Lee, Seungkyu] Penn State Univ, Dept Comp Sci & Engn, State Coll, PA 16803 USA; [Liu, Yanxi] Penn State Univ, Dept Comp Sci & Engn & Elect Engn, University Pk, PA 16802 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Lee, S (corresponding author), Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA.	seungkyu74@gmail.com; yanxi@cse.psu.edu			Northrup Grumman Corporation; Pennsylvania State University	Northrup Grumman Corporation; Pennsylvania State University	The authors thank Loy and Eklundh [25] for their source code for rotation symmetry detection, and Robert Collins and David Capel for helpful discussions. They also thank their associate editor and three reviewers for their constructive comments. This work is supported in part by a gift grant from Northrup Grumman Corporation, a Google research award, and Pennsylvania State University research grants to Yanxi Liu.	[Anonymous], 2007, PASCAL VISUAL OBJECT; Carlsson S., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P249, DOI 10.1007/BFb0055671; Cornelius H., 2006, P C COMP VIS PATT RE, P191; Cornelius H, 2007, LECT NOTES COMPUT SC, V4522, P152; Cornelius H, 2006, INT C PATT RECOG, P292; Derrode S, 2004, SIGNAL PROCESS, V84, P25, DOI 10.1016/j.sigpro.2003.07.006; ENQUIST M, 1994, NATURE, V372, P169, DOI 10.1038/372169a0; FLYNN PJ, 1994, IEEE T PATTERN ANAL, V16, P814, DOI 10.1109/34.308477; Giurfa M, 1996, NATURE, V382, P458, DOI 10.1038/382458a0; Gonzalez C., 2002, DIGITAL IMAGE PROCES; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Heidemann G, 2004, IEEE T PATTERN ANAL, V26, P817, DOI 10.1109/TPAMI.2004.29; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; Keller Y, 2006, IEEE T IMAGE PROCESS, V15, P2198, DOI 10.1109/TIP.2006.875227; Kootstra G., 2008, P 19 BRIT MACH VIS C, P1115; Korah T, 2008, LECT NOTES COMPUT SC, V5302, P359, DOI 10.1007/978-3-540-88682-2_28; Kurki I, 2004, NEUROSCI LETT, V360, P100, DOI 10.1016/j.neulet.2004.01.053; Lee HM, 2008, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2008/01/008; LEE S, 2007, P COMP VIS PATT REC; Lei YW, 1999, PATTERN RECOGN, V32, P167, DOI 10.1016/S0031-3203(98)00135-6; Lin HC, 1997, PATTERN RECOGN LETT, V18, P433, DOI 10.1016/S0167-8655(97)00030-5; Lin WC, 2007, IEEE T PATTERN ANAL, V29, P777, DOI 10.1109/TPAMI.2007.1053; Liu Y., 2005, P SIGGRAPH TECHN SKE; Liu Yanxi, 2008, P IEEE C COMP VIS PA; Liu YX, 2004, ACM T GRAPHIC, V23, P368, DOI 10.1145/1015706.1015731; Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332; LOCHER P, 1987, EYE MOVEMENTS PHYSL; Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508; Park M., P 2008 IEEE 19 INT S, P1, DOI [10.1109/PIMRC.2008.4699890, DOI 10.1109/PIMRC.2008.4699890]; Pauly PJ, 2008, RARITAN, V27, P1; Prasad VSN, 2005, IEEE I CONF COMP VIS, P954; Proakis J. G., 1996, DIGIT SIGNAL PROCESS; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; RIKLINRAVIV T, 2006, P IEEE C COMP VIS PA, P1015; Shen DG, 2000, INT C PATT RECOG, P1010, DOI 10.1109/ICPR.2000.903716; VanGool L, 1996, PROC CVPR IEEE, P285, DOI 10.1109/CVPR.1996.517087; Weyl H., 1952, SYMMETRY; YIP R, 1991, P INT C IND EL CONTR, V2, P1259; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508	40	26	30	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1659	1672		10.1109/TPAMI.2009.173	http://dx.doi.org/10.1109/TPAMI.2009.173			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	626MB	20634559				2022-12-18	WOS:000279969000009
J	Sobol-Shikler, T; Robinson, P				Sobol-Shikler, Tal; Robinson, Peter			Classification of Complex Information: Inference of Co-Occurring Affective States from Their Expressions in Speech	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Affective computing; human perception; cognition; affective states; emotions; speech; machine learning; intelligent systems; multiclass; multilabel		We present a classification algorithm for inferring affective states (emotions, mental states, attitudes, and the like) from their nonverbal expressions in speech. It is based on the observations that affective states can occur simultaneously and different sets of vocal features, such as intonation and speech rate, distinguish between nonverbal expressions of different affective states. The input to the inference system was a large set of vocal features and metrics that were extracted from each utterance. The classification algorithm conducted independent pairwise comparisons between nine affective-state groups. The classifier used various subsets of metrics of the vocal features and various classification algorithms for different pairs of affective-state groups. Average classification accuracy of the 36 pairwise machines was 75 percent, using 10-fold cross validation. The comparison results were consolidated into a single ranked list of the nine affective-state groups. This list was the output of the system and represented the inferred combination of co-occurring affective states for the analyzed utterance. The inference accuracy of the combined machine was 83 percent. The system automatically characterized over 500 affective state concepts from the Mind Reading database. The inference of co-occurring affective states was validated by comparing the inferred combinations to the lexical definitions of the labels of the analyzed sentences. The distinguishing capabilities of the system were comparable to human performance.	[Sobol-Shikler, Tal] Ben Gurion Univ Negev, Dept Ind Engn & Management, IL-84105 Beer Sheva, Israel; [Robinson, Peter] Univ Cambridge, Comp Lab, Cambridge CB3 0FD, England	Ben Gurion University; University of Cambridge	Sobol-Shikler, T (corresponding author), Ben Gurion Univ Negev, Dept Ind Engn & Management, POB 653, IL-84105 Beer Sheva, Israel.	stal@bgu.ac.il; pr@cl.cam.ac.uk			AAUW Educational Foundation; Cambridge Overseas Trust; Girton College; Computer Laboratory; Deutsche Telekom Laboratories at BenGurion University	AAUW Educational Foundation; Cambridge Overseas Trust; Girton College; Computer Laboratory; Deutsche Telekom Laboratories at BenGurion University	The authors thank Edna Schechtman, Yael Edan, Yehuda Werner, and Boaz Lerner for their help in revising this paper. They also thank the AAUW Educational Foundation, Cambridge Overseas Trust, Girton College, the Computer Laboratory, and Deutsche Telekom Laboratories at BenGurion University for their partial support of this research.	ALLWEIN E, 2000, P 17 INT C MACH LEAR; Baron-Cohen S., 2002, CAMBRIDGE MED, V17, P28; Baron-Cohen S., 2004, MIND READING INTERAC; Baron-Cohen S., 1999, DESCENT MIND PSYCHOL; BARONCOHEN S, 1985, COGNITION, V21, P37, DOI 10.1016/0010-0277(85)90022-8; Batliner A., 2007, P 16 INT C PHONETICS, P2201; Bechara A, 1997, SCIENCE, V275, P1293, DOI 10.1126/science.275.5304.1293; Boersma P., 1993, IFA PROC, V17, P97; Burkhardt F., 2008, EMOTION MARKUP LANGU; Cornelius R.R., 2000, P ISCA TUT RES WORKS; Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197; DECONDORCET CMJ, 1986, ESSAY APPL ANAL PROB; Dellaert F., 1996, P INT C SPOK LANG PR; den Noort M. V., 2005, P INT C COGN SYST DE; Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007; Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P33, DOI 10.1016/S0167-6393(02)00070-5; Ekman P., 1999, HDB COGN EMOT, V98, P16; el Kaliouby R, 2005, REAL-TIME VISION FOR HUMAN-COMPUTER INTERACTION, P181; Fernandez R, 2003, SPEECH COMMUN, V40, P145, DOI 10.1016/S0167-6393(02)00080-8; FERNANDEZ R, 2005, P INT 05 EUR 9 EUR C; Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944; Galileo Henry, 1914, DIALOGUES 2 NEW SCI; GOLAN O, 2006, J AUTISM DEV DISORD, V23, P7160; Gomez J., 1991, NATURAL THEORIES MIN, P195; Gorman P., 1979, PYTHAGORAS LIFE; Grimm M, 2007, ROBUST SPEECH RECOGN; Grundland M., 2005, P EUROGRAPHICS WORKS, P101; GRUNDLAND M, 2007, THESIS U CAMBRIDGE; Hall M. A., 1998, CORRELATION BASED FE; Haynes JD, 2006, NAT REV NEUROSCI, V7, P523, DOI 10.1038/nrn1931; Hollander M, 1973, NONPARAMETRIC STAT M; Hook K, 2004, HUM-COMPUT INT-SPRIN, V7, P127; Hoque M. Y. M., 2006, P 6 INT C INT VIRT A; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; James William, 1884, MIND, V34, P188, DOI [10.1093/mind/os-IX.34.188, DOI 10.1093/MIND/OS-IX.34.188]; KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185; Kim J, 2007, ROBUST SPEECH RECOGN, V265, P280; LAMBLICHUS, 1989, PYTHAGOREAN LIFE; Malkevitch J, 2008, PROCESS ELECTING PRE; MOORE CA, 1994, COMPUT SPEECH LANG, V8, P385, DOI 10.1006/csla.1994.1020; Nass C., 2005, WIRED SPEECH VOICE A; *NEM LTD, 2006, VOIC AN TECHN; OUDEYER PY, 2003, INT J HUMAN COMPUTER, V59, P157, DOI [DOI 10.1016/S1071-5819(02)00141-6, DOI 10.1016/S1071-581(02)00141-6]; PETRUSHIN V, 1999, P INT C ART NEUR NET; PHELPS RI, 1985, PROTOTYPICAL APPROAC; Picard Rosalind W., 1997, AFFECTIVE COMPUTING; Platt J C, 1999, ADV KERNEL METHODS S; PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Reeves B., 1996, MEDIA EQUATION PEOPL; ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X; Scherer K.R., 1984, APPROACHES EMOTION, P293; SCHERER KR, 1993, COGNITION EMOTION, V7, P325, DOI 10.1080/02699939308409192; SCHERER KR, 1995, P 13 INT C PHON SCI, P90; Schroder M. J. D. t., 2004, SPEECH EMOTION RES O; Schwartz DA, 2003, J NEUROSCI, V23, P7160, DOI 10.1523/JNEUROSCI.23-18-07160.2003; Slors M, 2001, J PHILOS, V98, P186, DOI 10.2307/2678477; Sobol-Shikler T., 2004, P INT C SPOK LANG PR; Sobol-Shikler T, 2008, P IEEE INT C SYST MA; SOBOLSHIKLER T, 2004, DESIGNING MORE INCLU; SOBOLSHIKLER T, 2004, P 2 CAMBR WORKSH UN; SOBOLSHIKLER T, 2009, UCAMCLTR740; TRAMO MJ, 2003, COGNITIVE NEUROSCIEN; Vapnik V., 1982, ESTIMATION DEPENDENC; Vidrascu L., 2007, P INT WORKSH PAR SPE; Visa S., 2005, P 16 MIDW ART INT CO, P67; WHISSELL C, 1989, EMOTION THEORY RES E, V4, P113; *WIK FREE ENC, 2008, COND METH; Witten IH, 1999, DATA MINING PRACTICA; XIAO Z, 2006, P INT C DIG TEL; Xiao ZZ, 2007, IEEE INT SYM MULTIM, P291, DOI 10.1109/ISM.Workshops.2007.56; ZAJONC RB, 1980, AM PSYCHOL, V35, P151, DOI 10.1037/0003-066X.35.2.151; ZWICKER E, 1957, J ACOUST SOC AM, V29, P548, DOI 10.1121/1.1908963; ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630; 2008, CAMBRIDGE DICT ONLIN; 2006, HUMAINE DELIVERABLE	76	26	27	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1284	1297		10.1109/TPAMI.2009.107	http://dx.doi.org/10.1109/TPAMI.2009.107			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	595YC	20489230				2022-12-18	WOS:000277649100010
J	Liu, GC; Lin, ZC; Yu, Y; Tang, XO				Liu, Guangcan; Lin, Zhouchen; Yu, Yong; Tang, Xiaoou			Unsupervised Object Segmentation with a Hybrid Graph Model (HGM)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Segmentation; graph-theoretic methods; spectral clustering		In this work, we address the problem of performing class-specific unsupervised object segmentation, i.e., automatic segmentation without annotated training images. Object segmentation can be regarded as a special data clustering problem where both class-specific information and local texture/color similarities have to be considered. To this end, we propose a hybrid graph model (HGM) that can make effective use of both symmetric and asymmetric relationship among samples. The vertices of a hybrid graph represent the samples and are connected by directed edges and/or undirected ones, which represent the asymmetric and/or symmetric relationship between them, respectively. When applied to object segmentation, vertices are superpixels, the asymmetric relationship is the conditional dependence of occurrence, and the symmetric relationship is the color/texture similarity. By combining the Markov chain formed by the directed subgraph and the minimal cut of the undirected subgraph, the object boundaries can be determined for each image. Using the HGM, we can conveniently achieve simultaneous segmentation and recognition by integrating both top-down and bottom-up information into a unified process. Experiments on 42 object classes (9,415 images in total) show promising results.	[Liu, Guangcan; Yu, Yong] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China; [Lin, Zhouchen; Tang, Xiaoou] Microsoft Res Asia, Visual Comp Grp, Beijing 100080, Peoples R China; [Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China	Shanghai Jiao Tong University; Microsoft; Microsoft Research Asia; Chinese University of Hong Kong	Liu, GC (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.	roth@sjtu.edu.cn; zhoulin@microsoft.com; yyu@apex.sjtu.edu.cn; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012					Abd El Munim HE, 2005, IEEE I CONF COMP VIS, P930; AGARWAL S, 2002, P ECCV, P113; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Borenstein E, 2004, LECT NOTES COMPUT SC, V3023, P315; BORENSTEIN E., 2004, P IEEE C COMP VIS PA; BORENSTEIN E, 2002, P EUR C COMP VIS, P109; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; *COR CORP, 2006, COR PHOT LIB; Cour T., 2007, P IEEE C COMP VIS PA, P1; COUR T, 2005, P 10 INT WORKSH ART; Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046; Fei-Fei L., 2004, P IEEE C COMP VIS PA; Fergus R, 2005, PROC CVPR IEEE, P380; Golub G. H., 1996, MATRIX COMPUTATIONS; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Leibe B., 2004, EUROPEAN C COMPUTER, P17; Levin A, 2006, LECT NOTES COMPUT SC, V3954, P581; Liu Johan, 2007, Journal of Shanghai University, V11, P1, DOI 10.1007/s11741-007-0101-6; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Meila M, 2001, ADV NEUR IN, V13, P873; Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521; Mori G, 2005, IEEE I CONF COMP VIS, P1417; Ng AY, 2002, ADV NEUR IN, V14, P849; Puzicha J, 1997, PROC CVPR IEEE, P267, DOI 10.1109/CVPR.1997.609331; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; Sharon E, 2001, PROC CVPR IEEE, P469; Sharon E, 2006, NATURE, V442, P810, DOI 10.1038/nature04977; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; SZUMMER M, 2001, NIPS, P945; Tishby N., 2000, ADV NEURAL INFORM PR, P640; TU Z, 2006, P CAT LEV OBJ REC, P545; Winn J, 2005, IEEE I CONF COMP VIS, P756; YU S, 2002, P NIPS, P1383; Yu SX, 2003, PROC CVPR IEEE, P39; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; Zhao BL, 2005, FRONT BIOSCI-LANDMRK, V10, P454, DOI 10.2741/1541; ZHOU D, 2005, P 22 INT C MACH LEAR, P1036	42	26	29	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					910	924		10.1109/TPAMI.2009.40	http://dx.doi.org/10.1109/TPAMI.2009.40			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299714				2022-12-18	WOS:000275569300011
J	Srivastava, A; Jermyn, IH				Srivastava, Anuj; Jermyn, Ian H.			Looking for Shapes in Two-Dimensional Cluttered Point Clouds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape classification; clutter model; Fisher-Rao metric; planar shape model; diffeomorphism		We study the problem of identifying shape classes in point clouds. These clouds contain sampled points along contours and are corrupted by clutter and observation noise. Taking an analysis-by-synthesis approach, we simulate high-probability configurations of sampled contours using models learned from training data to evaluate the given test data. To facilitate simulations, we develop statistical models for sources of (nuisance) variability: 1) shape variations within classes, 2) variability in sampling continuous curves, 3) pose and scale variability, 4) observation noise, and 5) points introduced by clutter. The variability in sampling closed curves into finite points is represented by positive diffeomorphisms of a unit circle. We derive probability models on these functions using their square-root forms and the Fisher-Rao metric. Using a Monte Carlo approach, we simulate configurations from a joint prior on the shape-sample space and compare them to the data using a likelihood function. Average likelihoods of simulated configurations lead to estimates of posterior probabilities of different classes and, hence, Bayesian classification.	[Srivastava, Anuj] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA; [Jermyn, Ian H.] INRIA Ariana, F-06902 Sophia Antipolis, France	State University System of Florida; Florida State University	Srivastava, A (corresponding author), Florida State Univ, Dept Stat, Room 106D,Bldg OSB, Tallahassee, FL 32306 USA.	anuj@stat.fsu.edu; Ian.Jermyn@sophia.inria.fr	Srivastava, Anuj/L-4705-2019; Srivastava, Anuj/F-7417-2011	Srivastava, Anuj/0000-0001-7406-0338	US Army Research Office [W911NF-04-01-0268]; US Air Force Office of Scientific Research [FA9550-06-1-0324]; North-rop-Grumman Innovation Alliance; INRIA/Florida State University Associated Team "SHAPES"	US Army Research Office; US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); North-rop-Grumman Innovation Alliance; INRIA/Florida State University Associated Team "SHAPES"	The authors thank the producers of the Kimia database for making it public. This work was partially supported by US Army Research Office W911NF-04-01-0268, US Air Force Office of Scientific Research FA9550-06-1-0324, and North-rop-Grumman Innovation Alliance grants and by the INRIA/Florida State University Associated Team "SHAPES."	Amari S., 1985, LECT NOTES STAT, P28; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; CENCOV NN, 1982, STAT DECISION RULES, V53; Charpiat G, 2005, FOUND COMPUT MATH, V5, P1, DOI 10.1007/s10208-003-0094-x; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Felzenszwalb P., 2007, P IEEE C COMP VIS PA; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Glaunes J, 2004, PROC CVPR IEEE, P712; Joshi SH, 2007, P IEEE C COMP VIS PA; Joshi SH, 2007, LECT NOTES COMPUT SC, V4679, P387; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Lang S., 1999, FUNDAMENTALS DIFFERE; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; Maybank SJ, 2004, IEEE T PATTERN ANAL, V26, P1579, DOI 10.1109/TPAMI.2004.122; Memoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y; Michor PW, 2006, J EUR MATH SOC, V8, P1, DOI 10.4171/JEMS/37; Mio W, 2007, INT J COMPUT VISION, V73, P307, DOI [10.1007/s11263-006-9968-0, 10.1007/s11263-006-996S-0]; PETER A, 2006, P 9 INT C MED IM COM; ROCHERY M, 2005, P 10 IEEE INT C COMP; Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; SRIVASTAVA A, 2000, APS COMM NETW MULTIM, P869	24	26	26	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1616	1629		10.1109/TPAMI.2008.223	http://dx.doi.org/10.1109/TPAMI.2008.223			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD	19574622	Green Accepted			2022-12-18	WOS:000267369800006
J	Beveridge, JR; Draper, BA; Chang, JM; Kirby, M; Kley, H; Peterson, C				Beveridge, J. Ross; Draper, Bruce A.; Chang, Jen-Mei; Kirby, Michael; Kley, Holger; Peterson, Chris			Principal Angles Separate Subject Illumination Spaces in YDB and CMU-PIE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; illumination subspaces; principal angle; set-to-set classification	FACE RECOGNITION; SET	The theory of illumination subspaces is well developed and has been tested extensively on the Yale Face Database B (YDB) and CMU-PIE (PIE) data sets. This paper shows that if face recognition under varying illumination is cast as a problem of matching sets of images to sets of images, then the minimal principal angle between subspaces is sufficient to perfectly separate matching pairs of image sets from nonmatching pairs of image sets sampled from YDB and PIE. This is true even for subspaces estimated from as few as six images and when one of the subspaces is estimated from as few as three images if the second subspace is estimated from a larger set (10 or more). This suggests that variation under illumination may be thought of as useful discriminating information rather than unwanted noise.	[Beveridge, J. Ross; Draper, Bruce A.] Colorado State Univ, Comp Sci Dept 1873, Ft Collins, CO 80523 USA; [Chang, Jen-Mei] Calif State Univ Long Beach, Dept Math & Stat, Long Beach, CA 90840 USA; [Kirby, Michael; Kley, Holger; Peterson, Chris] Colorado State Univ, Dept Math, Ft Collins, CO 80523 USA	Colorado State University; California State University System; California State University Long Beach; Colorado State University	Beveridge, JR (corresponding author), Colorado State Univ, Comp Sci Dept 1873, Ft Collins, CO 80523 USA.	ross@cs.colostate.edu; draper@cs.colostate.edu; jchang@csulb.edu; kirby@math.colostate.edu; kley@math.colostate.edu; peterson@math.colostate.edu		Beveridge, Ross/0000-0001-6489-6676	US National Science Foundation [DMS-0434351]; US DoD-USAF-Office of Scientific Research [FA9550-04-1-0094]	US National Science Foundation(National Science Foundation (NSF)); US DoD-USAF-Office of Scientific Research	This study was partially supported by the US National Science Foundation under Award DMS-0434351 and the US DoD-USAF-Office of Scientific Research under Contract FA9550-04-1-0094. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the US National Science Foundation or the US DoD-USAF-Office of Scientific Research.	Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; BJORCK A, 1973, MATH COMPUT, V27, P579, DOI 10.2307/2005662; Chang J, 2008, THESIS COLORADO STAT; CHANG JM, 2006, P INT C IM PROC COMP, V2, P396; Chin TJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P461; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Finlayson GD, 2004, LECT NOTES COMPUT SC, V3023, P582; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fukui K., 2003, P INT S ROB RES, P192; Georghiades AS, 1998, PROC CVPR IEEE, P52, DOI 10.1109/CVPR.1998.698587; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gross R, 2004, IEEE T PATTERN ANAL, V26, P449, DOI 10.1109/TPAMI.2004.1265861; Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332; Kim TK, 2007, PATTERN RECOGN, V40, P2475, DOI 10.1016/j.patcog.2006.12.030; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; LUI X, 2004, IEEE T PATTERN ANAL, V26, P662; Nishiyama M, 2005, LECT NOTES COMPUT SC, V3546, P71; Nishiyama M., 2007, P IEEE C COMP VIS PA, P1; Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Stewart G., 1990, MATRIX PERTURBATION; Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009; SUN QS, 2005, P INT C INT COMP, P958; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; WOLF L, 2003, J MACHINE LEARNING R, V4, P913; Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968	30	26	26	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					351	356		10.1109/TPAMI.2008.200	http://dx.doi.org/10.1109/TPAMI.2008.200			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110498				2022-12-18	WOS:000261846800011
J	Vasconcelos, M; Vasconcelos, N				Vasconcelos, Manuela; Vasconcelos, Nuno			Natural Image Statistics and Low-Complexity Feature Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction and construction; low complexity; natural image statistics; information theory; feature discrimination versus dependence; image databases; object recognition; texture; perceptual reasoning	MUTUAL INFORMATION	Low-complexity feature selection is analyzed in the context of visual recognition. It is hypothesized that high-order dependences of bandpass features contain little information for discrimination of natural images. This hypothesis is characterized formally by the introduction of the concepts of conjunctive interference and decomposability order of a feature set. Necessary and sufficient conditions for the feasibility of low-complexity feature selection are then derived in terms of these concepts. It is shown that the intrinsic complexity of feature selection is determined by the decomposability order of the feature set and not its dimension. Feature selection algorithms are then derived for all levels of complexity and are shown to be approximated by existing information-theoretic methods, which they consistently outperform. The new algorithms are also used to objectively test the hypothesis of low decomposability order through comparison of classification performance. It is shown that, for image classification, the gain of modeling feature dependencies has strongly diminishing returns: best results are obtained under the assumption of decomposability order 1. This suggests a generic law for bandpass features extracted from natural images: that the effect, on the dependence of any two features, of observing any other feature is constant across image classes.	[Vasconcelos, Manuela; Vasconcelos, Nuno] Univ Calif San Diego, Stat Visual Comp Lab, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Vasconcelos, M (corresponding author), Univ Calif San Diego, Stat Visual Comp Lab, 9500 Gilman Dr,MC 0407, La Jolla, CA 92093 USA.	maspcv@gmail.com; nuno@ece.ucsd.edu		Vasconcelos, Nuno/0000-0002-9024-4302	US National Science Foundation (NSF) [IIS-0448609, -0534985]	US National Science Foundation (NSF)(National Science Foundation (NSF))	The authors would like to thank the three anonymous reviewers for their comments, which substantially improved clarity of the presentation. This work was funded by the US National Science Foundation (NSF) under Awards IIS-0448609 and -0534985.	ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301; Barlow H. B., 1961, P331; BARROWS G, 1996, P IEEE INT S TIM FRE; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616; CAVE KR, 1990, COGNITIVE PSYCHOL, V22, P225, DOI 10.1016/0010-0285(90)90017-X; Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633; Chow TWS, 2005, IEEE T NEURAL NETWOR, V16, P213, DOI 10.1109/TNN.2004.841414; Clarke R. J., 1985, TRANSFORM CODING IMA; Cover T. M., 1977, IEEE T SYSTEMS MAN C, V7; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Deneve S, 1999, NAT NEUROSCI, V2, P740, DOI 10.1038/11205; Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396; Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Dumais S, 1998, IEEE INTELL SYST APP, V13, P21; Dumais S., 2000, P 23 ANN INT ACM SIG, P256, DOI 10.1145/345508.345593.; FARVARDIN N, 1984, IEEE T INFORM TH MAY; Field D., 1989, NEURAL COMPUT, V6, P559; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gao D., 2005, ADV NEURAL INFORM PR, P481; Grall-Maes E, 2002, IEEE T SIGNAL PROCES, V50, P779, DOI 10.1109/78.992120; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Heiler M, 2005, INT J COMPUT VISION, V63, P5, DOI 10.1007/s11263-005-4944-7; Huang J., 1999, P IEEE C COMP VIS PA; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JURIE F, 2005, P 11 IEEE INT C COMP, V1; Koller D., 1996, P 13 INT C MACH LEAR; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P305; LEVIN A, 2004, P IEEE C COMP VIS PA, V1; LEWIS D, 1997, P WORKSH SPEECH NAT, P212; LI SZ, 2002, P 7 EUR C COMP VIS E; LOCHOVSKY GWF, 2004, P 13 ACM C INF KNOWL, P342; Long F, 2003, P NATL ACAD SCI USA, V100, P15190, DOI 10.1073/pnas.2036361100; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Moulin P, 1999, IEEE T INFORM THEORY, V45, P909, DOI 10.1109/18.761332; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Pouget A, 2000, NAT REV NEUROSCI, V1, P125, DOI 10.1038/35039062; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Ratanamahatana C, 2003, APPL ARTIF INTELL, V17, P475, DOI 10.1080/08839510390219327; Roth S, 2005, PROC CVPR IEEE, P860; RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006; SCANLON P, 2004, P INT C SPOK LANG PR, P857; Schatten G, 1998, J LAW MED ETHICS, V26, P29, DOI 10.1111/j.1748-720X.1998.tb01903.x; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; Schwartz O, 2001, NAT NEUROSCI, V4, P819, DOI 10.1038/90526; SEO Y, 1971, TECHNICAL REPORT CMU, P45; SEO YW, 2004, CMURITR0418; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214; Tourassi GD, 2001, MED PHYS, V28, P2394, DOI 10.1118/1.1418724; TREISMAN A, 1988, PSYCHOL REV, V95, P15, DOI 10.1037/0033-295X.95.1.15; TREISMAN A, 1990, J EXP PSYCHOL HUMAN, V16, P459, DOI 10.1037/0096-1523.16.3.459; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P2315, DOI 10.1098/rspb.1998.0577; Vasconcelos M, 2005, PROC SPIE, V5807, P284, DOI 10.1117/12.604289; VASCONCELOS N, 2002, NEURAL INFORM PROCES; VASCONCELOS N, 2003, P IEEE C COMP VIS PA; VASCONCELOS N, 2002, P 7 EUR C COMP VIS E; VASCONCELOS N, 2004, P IEEE C COMP VIS PA; Vidal-Naquet M., 2003, P IEEE C COMP VIS PA; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774; Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411; Xing E.P., 2001, ICML CITESEER, V1, P601; YANG H, 2000, P NEUR INF PROC SYST; ZARJAM P, 2003, P IEEE INT S CIRC SY, V5; COMP INFOMAX MAXIMUM	81	26	28	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					228	244		10.1109/TPAMI.2008.77	http://dx.doi.org/10.1109/TPAMI.2008.77			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	385XL	19110490	Green Submitted			2022-12-18	WOS:000261846800003
J	Taron, M; Paragios, N; Jolly, MP				Taron, Maxime; Paragios, Nikos; Jolly, Marie-Pierre			Registration with Uncertainties and Statistical Modeling of Shapes with Variable Metric Kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape registration; shape modeling; uncertainty estimates; nonparametric statistics; variable metric kernels	APPROXIMATIONS; POINTS; SPACE	Registration and modeling of shapes are two important problems in computer vision and pattern recognition. Despite enormous progress made over the past decade, these problems are still open. In this paper, we advance the state of the art in both directions. First, we consider an efficient registration method that aims to recover a one-to-one correspondence between shapes and introduce measures of uncertainties driven from the data which explain the local support of the recovered transformations. To this end, a free-form deformation is used to describe the deformation model. The transformation is combined with an objective function defined in the space of implicit functions used to represent shapes. Once the registration parameters have been recovered, we introduce a novel technique for model building and statistical interpretation of the training examples based on a variable bandwidth kernel approach. The support on the kernels varies spatially and is determined according to the uncertainties of the registration process. Such a technique introduces the ability to account for potential registration errors in the model. Handwritten character recognition and knowledge-based object extraction in medical images are examples of applications that demonstrate the potentials of the proposed framework.	[Taron, Maxime; Paragios, Nikos] Ecole Cent Paris, Dept Appl Math, F-77455 Marne La Vallee 2, France; [Taron, Maxime] Ecole Natl Ponts & Chaussees, CERTIS, F-77455 Marne La Vallee 2, France; [Paragios, Nikos] Parc Orsay Univ, Equipe Projet GALEN, INRIA Saclay Ile France, F-91893 Orsay, France; [Jolly, Marie-Pierre] Siemens Corp Res, Imaging & Visualizat Dept, Princeton, NJ 08540 USA	UDICE-French Research Universities; Universite Paris Saclay; Ecole des Ponts ParisTech; Siemens AG	Taron, M (corresponding author), Ecole Cent Paris, Dept Appl Math, 6 Av Blaise Pascal Cite Descartes, F-77455 Marne La Vallee 2, France.	maxime.taron@certis.enpc.fr; nikos.paragios@ecp.fr; marie-pierre.jolly@siemens.com						ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bishop C.M., 1996, NEURAL NETWORKS PATT, P1; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Charpiat G, 2005, FOUND COMPUT MATH, V5, P1, DOI 10.1007/s10208-003-0094-x; Chen HF, 2002, LECT NOTES COMPUT SC, V2350, P236; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cootes TF, 1999, IMAGE VISION COMPUT, V17, P567, DOI 10.1016/S0262-8856(98)00175-9; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; DEMENTHON D, 2001, P IEEE 8 INT C COMP, P438; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x; HUANG X, 2003, P 6 INT C MED IM COM; Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Kanatani K, 2004, IEEE T PATTERN ANAL, V26, P1307, DOI 10.1109/TPAMI.2004.93; LECUN Y, 2008, MNIST DATABASE HANDW; Lefebure M, 2001, J MATH IMAGING VIS, V14, P131, DOI 10.1023/A:1011259231755; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; LIPSON P, 1990, P 1 EUR C COMP VIS, P413; LUNDERVOLD A, 1999, P IEEE C COMP VIS PA, P1231; MA J, 2008, OSU SVM CLASSIFIER M; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Mittal A, 2004, PROC CVPR IEEE, P302; MONTAGNAT J, 1997, P IEEE C COMP VIS PA; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Paragios N, 2003, COMPUT VIS IMAGE UND, V89, P142, DOI 10.1016/S1077-3142(03)00010-9; Pauwels E. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P997, DOI 10.1109/ICCV.1999.790377; Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720; Pennec X, 1997, INT J COMPUT VISION, V25, P203, DOI 10.1023/A:1007976002485; Rohr K, 1999, LECT NOTES COMPUT SC, V1613, P252; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Sain SR, 2002, COMPUT STAT DATA AN, V39, P165, DOI 10.1016/S0167-9473(01)00053-6; Scholkopf B., 2001, LEARNING KERNELS SUP; Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903; Simoncelli EP, 1999, HDB COMPUTER VISION, P397; SOFKA M, 2007, P IEEE C COMP VIS PA, P18; STEWART C, 2005, MATH MODELS COMPUTER; Stewart CV, 2003, IEEE T MED IMAGING, V22, P1379, DOI 10.1109/TMI.2003.819276; Taron M, 2005, IEEE I CONF COMP VIS, P1659; TARON M, 2005, P IEEE WORKSH VAR LE, P198; TENMOTO H, 1998, ADV PATTERN RECOGNIT, V1451, P831; Trouve A, 1998, INT J COMPUT VISION, V28, P213, DOI 10.1023/A:1008001603737; TSAI A, 2004, P 7 INT C MED IM COM, P1; Uzumcu M, 2003, PROC SPIE, V5032, P375, DOI 10.1117/12.481310; WAND M, 1968, KERNEL SMOOTHING; Wang Y, 2004, COMPUT GRAPH FORUM, V23, P677, DOI 10.1111/j.1467-8659.2004.00800.x; Xie ZY, 2001, INNOV APPL MATH, P545; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; [No title captured]	57	26	27	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					99	113		10.1109/TPAMI.2008.36	http://dx.doi.org/10.1109/TPAMI.2008.36			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029549				2022-12-18	WOS:000260889700009
J	Yan, F; Christmas, W; Kittler, J				Yan, Fei; Christmas, William; Kittler, Josef			Layered data association using graph-theoretic formulation with applications to tennis ball tracking in monocular sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		data association; trajectory reconstruction; graph theory; shortest path	MLESAC; PATHS	In this paper, we propose a multilayered data association scheme with graph-theoretic formulation for tracking multiple objects that undergo switching dynamics in clutter. The proposed scheme takes as input object candidates detected in each frame. At the object candidate level, "tracklets" are "grown" from sets of candidates that have high probabilities of containing only true positives. At the tracklet level, a directed and weighted graph is constructed, where each node is a tracklet and the edge weight between two nodes is defined according to the "compatibility" of the two tracklets. The association problem is then formulated as an all-pairs shortest path (APSP) problem in this graph. Finally, at the path level, by analyzing the APSPs, all object trajectories are identified, and track initiation and track termination are automatically dealt with. By exploiting a special topological property of the graph, we have also developed a more efficient APSP algorithm than the general-purpose ones. The proposed data association scheme is applied to tennis sequences to track tennis balls. Experiments show that it works well on sequences where other data association methods perform poorly or fail completely.	[Yan, Fei; Christmas, William; Kittler, Josef] Univ Surrey, Fac Engn & Phys Sci, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	University of Surrey	Yan, F (corresponding author), Univ Surrey, Fac Engn & Phys Sci, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	f.yan@surrey.ac.uk; w.christmas@surrey.ac.uk; j.kittler@surrey.ac.uk		Christmas, William/0000-0002-6796-3536				Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Chum O., 2004, P ACCV, V2, P812; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; JOHNSON DB, 1977, J ACM, V24, P1, DOI 10.1145/321992.321993; Mazor E, 1998, IEEE T AERO ELEC SYS, V34, P103, DOI 10.1109/7.640267; Miyamori H., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P320, DOI 10.1109/AFGR.2000.840653; Pingali GS, 1998, PROC CVPR IEEE, P260, DOI 10.1109/CVPR.1998.698618; QUACH T, 1994, IEEE DECIS CONTR P, P271, DOI 10.1109/CDC.1994.410918; REID DB, 1979, IEEE T AUTOMATIC CON, V24, P6; SMITH P, 1975, IEEE T AUTOMAT CONTR, VAC20, P101, DOI 10.1109/TAC.1975.1100851; Tordoff BJ, 2005, IEEE T PATTERN ANAL, V27, P1523, DOI 10.1109/TPAMI.2005.199; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Willett P, 1998, P SOC PHOTO-OPT INS, V3373, P416, DOI 10.1117/12.324645; WOLF JK, 1989, IEEE T AERO ELEC SYS, V25, P287, DOI 10.1109/7.18692; [No title captured]; [No title captured]; [No title captured]; [No title captured]	20	26	27	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1814	1830		10.1109/TPAMI.2007.70834	http://dx.doi.org/10.1109/TPAMI.2007.70834			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703833				2022-12-18	WOS:000258344900011
J	Feldman, D; Weinshall, D				Feldman, Doron; Weinshall, Daphna			Motion segmentation and depth ordering using an occlusion detector	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; video analysis; motion; depth cues; segmentation	INFORMATION; FRAMEWORK	We present a novel method for motion segmentation and depth ordering from a video sequence in general motion. We first compute motion segmentation based on differential properties of the spatio-temporal domain and scale-space integration. Given a motion boundary, we describe two algorithms to determine depth ordering from two-and three-frame sequences. A remarkable characteristic of our method is its ability compute depth ordering from only two frames. The segmentation and depth ordering algorithms are shown to give good results on six real sequences taken in general motion. We use synthetic data to show robustness to high levels of noise and illumination changes; we also include cases where no intensity edge exists at the location of the motion boundary or when no parametric motion model can describe the data. Finally, we describe psychophysical experiments showing that people, like our algorithm, can compute depth ordering from only two frames even when the boundary between the layers is not visible in a single frame.	[Feldman, Doron; Weinshall, Daphna] Hebrew Univ Jerusalem, Sch Comp Sci & Engn, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Feldman, D (corresponding author), Hebrew Univ Jerusalem, Sch Comp Sci & Engn, IL-91904 Jerusalem, Israel.	doronf@cs.huji.ac.il; daphna@cs.huji.ac.il						Apostoloff N, 2005, PROC CVPR IEEE, P553; Bergen L, 2000, PROC CVPR IEEE, P536, DOI 10.1109/CVPR.2000.854907; Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933; CHOU GT, P INT C COMP VIS, P1050; Cunningham DW, 1998, PERCEPT PSYCHOPHYS, V60, P839, DOI 10.3758/BF03206067; Darrell T., 1995, 314 MIT MED LAB; FELDMAN D, 2006, P WORKSH DYN VIS EUR; GAMBLE E, 1987, 970 MIT AL LAB; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KAPLAN GA, 1969, PERCEPT PSYCHOPHYS, V6, P193, DOI 10.3758/BF03207015; Ke QF, 2001, PROC CVPR IEEE, P255; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Laptev I, 2004, INT C PATT RECOG, P52, DOI 10.1109/ICPR.2004.1334003; Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Middendorf M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P178, DOI 10.1109/ICCV.2001.937515; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; MUTCH KM, 1985, IEEE T PATTERN ANAL, V7, P133, DOI 10.1109/TPAMI.1985.4767638; Nicolescu M, 2005, IEEE T PATTERN ANAL, V27, P739, DOI 10.1109/TPAMI.2005.91; NIYOGI SA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1044, DOI 10.1109/ICCV.1995.466819; Odobez J.-M., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P628, DOI 10.1109/ICIP.1995.537713; Ogale AS, 2005, IEEE T PATTERN ANAL, V27, P988, DOI 10.1109/TPAMI.2005.123; Pao H.-K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P948, DOI 10.1109/ICCV.1999.790350; REN X, 2006, P EUR C COMP VIS, V2, P614; Saund E, 1999, COMPUT VIS IMAGE UND, V76, P70, DOI 10.1006/cviu.1999.0789; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; Shi JB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1154, DOI 10.1109/ICCV.1998.710861; Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; TWEED D, 2000, P BRIT MACH VIS C; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; Xiao JJ, 2005, PROC CVPR IEEE, P698; YONAS A, 1987, PERCEPT PSYCHOPHYS, V41, P53, DOI 10.3758/BF03208213	36	26	28	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1171	1185		10.1109/TPAMI.2007.70766	http://dx.doi.org/10.1109/TPAMI.2007.70766			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550901	Green Submitted			2022-12-18	WOS:000256294100005
J	Mezghani, N; Mitiche, A; Cheriet, M				Mezghani, Neila; Mitiche, Amar; Cheriet, Mohamed			Bayes classification of online Arabic characters by Gibbs modeling of class conditional densities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes classification; Gibbs density parameter estimation; histograms; online handwritten Arabic character recognition	HANDWRITING RECOGNITION; MINIMAX ENTROPY; ALGORITHMS	This study investigates Bayes classification of online Arabic characters using histograms of tangent differences and Gibbs modeling of the class-conditional probability density functions. The parameters of these Gibbs density functions are estimated following the Zhu et al. constrained maximum entropy formalism, originally introduced for image and shape synthesis. We investigate two partition function estimation methods: one uses the training sample, and the other draws from a reference distribution. The efficiency of the corresponding Bayes decision methods, and of a combination of these, is shown in experiments using a database of 9,504 freely written samples by 22 writers. Comparisons to the nearest neighbor rule method and a Kohonen neural network method are provided.	[Mezghani, Neila] Hop Notre Dame de Bon Secours, CHUM, Ctr Rech, Lab Rech Imagerie & Orthopedie LIO, Montreal, PQ H2L 4M1, Canada; [Mitiche, Amar] INR EMT, Montreal, PQ H5A 1K6, Canada; [Cheriet, Mohamed] ETS, Montreal, PQ H3C 1K3, Canada	Universite de Montreal; University of Quebec; Ecole de Technologie Superieure - Canada	Mezghani, N (corresponding author), Hop Notre Dame de Bon Secours, CHUM, Ctr Rech, Lab Rech Imagerie & Orthopedie LIO, 1560,Rue Sherbrooke Est,Local Y-1615, Montreal, PQ H2L 4M1, Canada.	neila.mezghani@etsmtl.ca; mitiche@emt.inrs.ca; mohamed.cheriet@etsmtl.ca						ALBADR B, 1995, SIGNAL PROCESS, V41, P49, DOI 10.1016/0165-1684(94)00090-M; ALEMAMI S, 1990, IEEE T PATTERN ANAL, V12, P704, DOI 10.1109/34.56214; Alimi AM, 1997, PROC INT CONF DOC, P382, DOI 10.1109/ICDAR.1997.619875; ALIMI AM, 1997, P IEEE INT C NEUR NE, V3, P1397; Amin A, 1998, PATTERN RECOGN, V31, P517, DOI 10.1016/S0031-3203(97)00084-8; Amin A, 1997, PROC INT CONF DOC, P596, DOI 10.1109/ICDAR.1997.620572; BALL GR, 2006, P INT WORKSH FRONT H; Ben Amara N.E., 2003, IJDAR, V5, P195; Biadsy F., 2006, P INT WORKSH FRONT H; Bouslama F, 1998, 1998 SECOND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED INTELLIGENT ELECTRONIC SYSTEMS, KES '98, PROCEEDINGS, VOL, 3, P76, DOI 10.1109/KES.1998.725956; DESCOMBES X, 1997, P INT WORKSH EN MIN; Doermann D, 1998, COMPUT VIS IMAGE UND, V70, P287, DOI 10.1006/cviu.1998.0692; Duda P.E.H.R.O., 2001, PATTERN CLASSIFICATI; ELSHEIKH TS, 1990, PATTERN RECOGN, V23, P1323, DOI 10.1016/0031-3203(90)90078-Y; ELWAKIL MS, 1989, PATTERN RECOGN, V22, P97, DOI 10.1016/0031-3203(89)90058-7; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GOVINDAN VK, 1990, PATTERN RECOGN, V23, P671, DOI 10.1016/0031-3203(90)90091-X; Hassin AH, 2004, J COMPUT SCI TECH-CH, V19, P538, DOI 10.1007/BF02944755; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; JEBARA T, 2000, UNCERTAINITY ARTIFIC; JEHANBESSON S, 2005, MATH MODELS COMPUTER; JIANCHANG M, 1999, P INT JOINT C NEUR N, V4, P2934; Khorsheed MS, 2002, PATTERN ANAL APPL, V5, P31, DOI 10.1007/s100440200004; KOHONEN T, 1995, SELFORGANIZING MAPS; Liu CL, 2004, IEEE T PATTERN ANAL, V26, P198, DOI 10.1109/TPAMI.2004.1262182; Lorette G., 1999, International Journal on Document Analysis and Recognition, V2, P2, DOI 10.1007/s100320050030; Lorigo LM, 2006, IEEE T PATTERN ANAL, V28, P712, DOI 10.1109/TPAMI.2006.102; MAHJOUB MA, 1997, P 17 JOURN TUN EL AU, P341; MAHMOUD SA, 1994, PATTERN RECOGN, V27, P815, DOI 10.1016/0031-3203(94)90166-X; Marukatat S, 2003, PROC INT CONF DOC, P1048; Mezghani N., 2005, International Journal on Document Analysis and Recognition, V7, P201, DOI 10.1007/s10032-005-0145-8; Mezghani N, 2003, PROC INT CONF DOC, P900; Mezghani N, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P490, DOI 10.1109/IWFHR.2002.1030958; MEZGHANI N, 2002, P VIS INT 2002, P186; Mitiche A, 1996, INT J PATTERN RECOGN, V10, P393, DOI 10.1142/S0218001496000268; Mitiche A, 2001, NEURAL NETWORKS, V14, P575, DOI 10.1016/S0893-6080(01)00035-1; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424, DOI 10.1109/TPAMI.2004.105; Olivier C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P264, DOI 10.1109/ICPR.1996.546952; Onnia V, 2001, IEEE IMAGE PROC, P513, DOI 10.1109/ICIP.2001.959066; PAKKER KR, 1995, MACH VISION APPL, V8, P232; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; PLAMONDON R, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P303, DOI 10.1109/ICPR.1992.201778; PLAMONDON R, 1994, P 4 INT WORKSH FRONT, P1; Potamianos G, 1997, IEEE T INFORM THEORY, V43, P1948, DOI 10.1109/18.641558; Sabourin M., 1993, Proceedings. Second Annual Symposium on Document Analysis and Information Retrieval, P397; SCHENKEL M, 1994, INT CONF ACOUST SPEE, P637; Shah J, 1998, PROC CVPR IEEE, P92, DOI 10.1109/CVPR.1998.698593; Shima K, 2004, PATTERN RECOGN LETT, V25, P1051, DOI 10.1016/j.patrec.2004.03.002; Spall JC, 2003, IEEE CONTR SYST MAG, V23, P34, DOI 10.1109/MCS.2003.1188770; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; TAPPERT CC, 1988, P INT C PATT REC NOV, V2, P1123; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2; Zeki A. M., 2005, P INT C INF COMM TEC, V2005, P11; Zheng LY, 2004, PATTERN RECOGN LETT, V25, P1723, DOI 10.1016/j.patrec.2004.06.015; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170, DOI 10.1109/34.809110; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627	57	26	29	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1121	1131		10.1109/TPAMI.2007.70753	http://dx.doi.org/10.1109/TPAMI.2007.70753			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550897				2022-12-18	WOS:000256294100001
J	Hara, K; Nishino, K; Ikeuchi, K				Hara, Kenji; Nishino, Ko; Ikeuchi, Katsushi			Mixture of spherical distributions for single-view relighting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						inverse rendering; von Mises-Fisher distribution; finite mixture distribution; EM algorithm	ILLUMINANT DIRECTION; REFLECTION; COLOR; SHAPE	We present a method for simultaneously estimating the illumination of a scene and the reflectance property of an object from single view images - a single image or a small number of images taken from the same viewpoint. We assume that the illumination consists of multiple point light sources, and the shape of the object is known. First, we represent the illumination on the surface of a unit sphere as a finite mixture of von Mises-Fisher distributions based on a novel spherical specular reflection model that well approximates the Torrance-Sparrow reflection model. Next, we estimate the parameters of this mixture model including the number of its component distributions and the standard deviation of them, which correspond to the number of light sources and the surface roughness, respectively. Finally, using these results as the initial estimates, we iteratively refine the estimates based on the original Torrance-Sparrow reflection model. The final estimates can be used to relight single-view images such as altering the intensities and directions of the individual light sources. The proposed method provides a unified framework based on directional statistics for simultaneously estimating the intensities and directions of an unknown number of light sources, as well as the specular reflection parameter of the object in the scene.	Kyushu Univ, Fac Design, Dept Visual Commun Design, Minami Ku, Fukuoka 8158540, Japan; Drexel Univ, Coll Engn, Dept Comp Sci, Philadelphia, PA 19104 USA; Univ Tokyo, Inst Ind Sci, Tokyo 1538505, Japan	Kyushu University; Drexel University; University of Tokyo	Hara, K (corresponding author), Kyushu Univ, Fac Design, Dept Visual Commun Design, Minami Ku, 4-9-1 Shiobaru, Fukuoka 8158540, Japan.	hara@design.kyushu-u.ac.jp; kon@drexel.edu; ki@cvl.iis.u-tokyo.ac.jp						BOIVIN S, 2001, P SIGGRAPH C, P197; CANG S, 2003, P 8 INT C NEUR INF P, P14; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Drettakis G., 1997, Rendering Techniques '97. Proceedings of the Eurographics Workshop. Eurographics, P45; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; FISHER R, 1953, PROC R SOC LON SER-A, V217, P295, DOI 10.1098/rspa.1953.0064; Fournier A., 1993, Proceedings Graphics Interface '93, P254; Hara K, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P560; Hougen D. R., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P148, DOI 10.1109/ICCV.1993.378225; IKEUCHI K, 1991, IEEE T PATTERN ANAL, V13, P1139, DOI 10.1109/34.103274; Kim CY, 1998, J OPT SOC AM A, V15, P2341, DOI 10.1364/JOSAA.15.002341; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; Li YZ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1366, DOI 10.1109/ICCV.2003.1238649; Mardia K.V., 2000, DIRECTIONAL STAT; Marschner SR, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P262; Miyazaki D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P982; Mukawa N., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P507, DOI 10.1109/ICCV.1990.139583; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; Nishino K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P599, DOI 10.1109/ICCV.2001.937573; NISHINO K, 2005, DUCS0512; Okabe T, 2004, PROC CVPR IEEE, P50; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Sato I, 2003, IEEE T PATTERN ANAL, V25, P290, DOI 10.1109/TPAMI.2003.1182093; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; SHEN L, 2006, P C COMP VIS PATT RE, P1833; Solomon F., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P466, DOI 10.1109/CVPR.1992.223149; Sra S, 2003, KDD 03, P19, DOI DOI 10.1145/956750.956757; Tan RT, 2005, IEEE T PATTERN ANAL, V27, P178, DOI 10.1109/TPAMI.2005.36; Tominaga S, 2000, IEEE COMPUT GRAPH, V20, P58, DOI 10.1109/38.865881; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; Verbeek JJ, 2003, NEURAL COMPUT, V15, P469, DOI 10.1162/089976603762553004; Wang Y, 2003, GRAPH MODELS, V65, P185, DOI 10.1016/S1524-0703(03)00043-2; WANG Y, 2002, P EUR C COMP VIS, P272; WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078; WATSON GS, 1956, BIOMETRIKA, V43, P344, DOI 10.1093/biomet/43.3-4.344; Yang Y., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P534, DOI 10.1109/CVPR.1991.139749; YU Y, 1998, P SIGGRAPH 98, P207; Yu YZ, 1999, COMP GRAPH, P215; Zhang LX, 2001, CANCER GENE THER, V8, P915; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658; Zhou WD, 2002, P ANN INT IEEE EMBS, P206, DOI 10.1109/IEMBS.2002.1134458	42	26	27	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					25	35		10.1109/TPAMI.2007.1164	http://dx.doi.org/10.1109/TPAMI.2007.1164			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000322				2022-12-18	WOS:000250843500003
J	Wang, P; Ji, Q; Wayman, JL				Wang, Peng; Ji, Qiang; Wayman, James L.			Modeling and predicting face recognition system performance based on analysis of similarity scores	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; similarity scores; performance modeling; performance prediction; image quality	METHODOLOGY	This paper presents methods of modeling and predicting face recognition (FR) system performance based on analysis of similarity scores. We define the performance of an FR system as its recognition accuracy, and consider the intrinsic and extrinsic factors affecting its performance. The intrinsic factors of an FR system include the gallery images, the FR algorithm, and the tuning parameters. The extrinsic factors include mainly query image conditions. For performance modeling, we propose the concept of "perfect recognition," based on which a performance metric is extracted from perfect recognition similarity scores (PRSS) to relate the performance of an FR system to its intrinsic factors. The PRSS performance metric allows tuning FR algorithm parameters offline for near optimal performance. In addition, the performance metric extracted from query images is used to adjust face alignment parameters online for improved performance. For online prediction of the performance of an FR system on query images, features are extracted from the actual recognition similarity scores and their corresponding PRSS. Using such features, we can predict online if an individual query image can be correctly matched by the FR system, based on which we can reduce the incorrect match rates. Experimental results demonstrate that the performance of an FR system can be significantly improved using the presented methods.	Univ Penn, Dept Radiol, Sect Biomed Image Anal, Philadelphia, PA 19104 USA; Rensselaer Polytech Inst, Dept Elect & Comp Syst Engn, Troy, NY 12180 USA; San Jose State Univ, Off Grad Studies & Res, San Jose, CA 95192 USA	University of Pennsylvania; Rensselaer Polytechnic Institute; California State University System; San Jose State University	Wang, P (corresponding author), Univ Penn, Dept Radiol, Sect Biomed Image Anal, 3600 Market St,Suite 380, Philadelphia, PA 19104 USA.	wpeng@ieee.org; qji@ecse.rpi.edu; JLWayman@aol.com						[Anonymous], 2006, FACE RECOGNITION VEN; Beveridge R., 2003, CSU FACE IDENTIFICAT; GIVENS G, 2004, P IEEE INT C COMP VI, V2; James L., 2005, BIOMETRIC SYSTEMS TE; Johnson AY, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P100; Li WL, 2005, 2005 IEEE International Conference on Computational Intelligence for Homeland Security and Personal Safety, P57; McCullagh P., 1989, GEN LINEAR MODELS, V2nd; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Schmid NA, 2004, IEEE T SIGNAL PROCES, V52, P3036, DOI 10.1109/TSP.2004.833863; Schmid NA, 2005, INT CONF ACOUST SPEE, P93; TABASSI E, 2004, 7151 NISTIR; WANG P, 2005, P IEEE WORKSH FAC RE; WANG R, 2005, P IEEE INT C COMP VI; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	15	26	27	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					665	670		10.1109/TPAMI.2007.1015	http://dx.doi.org/10.1109/TPAMI.2007.1015			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299223	Green Submitted			2022-12-18	WOS:000244855600014
J	Qiao, Y; Nishiara, M; Yasuhara, M				Qiao, Yu; Nishiara, Mikihiko; Yasuhara, Makoto			A framework toward restoration of writing order from single-stroked handwriting image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwriting recognition; writing order restoration; edge continuity relation; temporal information; graph matching; Euler path	TEMPORAL INFORMATION; DYNAMIC INFORMATION; RECOVERY; ONLINE; RECOGNITION	Restoration of writing order from a single-stroked handwriting image can be seen as the problem of finding the smoothest path in its graph representation. In this paper, a 3-phase approach to restore a writing order is proposed within the framework of the Edge Continuity Relation (ECR). In the initial, local phase, in order to obtain possible ECRs at an even-degree node, a neural network is used for the node of degree 4 and a theoretical approach is presented for the node of degree higher than 4 by introducing certain reasonable assumptions. In the second phase, we identify double-traced lines by employing maximum weighted matching. This makes it possible to transform the problem of obtaining possible ECRs at odd-degree node to that at even-degree node. In the final, global phase, we find all the candidates of single-stroked paths by depth first search and select the best one by evaluating SLALOM smoothness. Experiments on static images converted from online data in the Unipen database show that our method achieves a restoration rate of 96.0 percent.	Univ Electrocommun, Dept Informat Management Sci, Grad Sch Informat Syst, Chofu, Tokyo 1828585, Japan	University of Electro-Communications - Japan	Qiao, Y (corresponding author), Univ Electrocommun, Dept Informat Management Sci, Grad Sch Informat Syst, 1-5-1 Chofugaoka, Chofu, Tokyo 1828585, Japan.	qiaoyu@math-sys.is.uec.ac.jp; mikihiko@is.uec.ac.jp; yas@is.uec.ac.jp	Qiao, Yu/C-6604-2009					BABCOCK MK, 1988, AM J PSYCHOL, V101, P111, DOI 10.2307/1422797; BOCCIGNONE G, 1993, PATTERN RECOGN, V26, P409, DOI 10.1016/0031-3203(93)90168-V; Bunke H, 1997, PROC INT CONF DOC, P931, DOI 10.1109/ICDAR.1997.620647; CHANG HD, 1993, PATTERN RECOGN, V26, P711, DOI 10.1016/0031-3203(93)90123-E; Doermann D. S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P162, DOI 10.1109/CVPR.1992.223211; DOERMANN DS, 1995, INT J COMPUT VISION, V15, P143, DOI 10.1007/BF01450853; Duda R.O., 2000, PATTERN CLASSIFICATI; Edmonds J., 1973, Mathematical Programming, V5, P88, DOI 10.1007/BF01580113; EDMONDS J, 1965, J RES NATL BUR STAND, VB 69, P125, DOI 10.6028/jres.069B.013; GABOW HN, 1990, PROCEEDINGS OF THE FIRST ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P434; GOVINDARAJU V, 1992, PIXELS FEATURES, V2, P17; GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870; HUANG T, 1995, P IEEE SYST MAN CYB, P2789; ISOMICHI Y, 1981, IEICE T A, V64, P285; JAEGER S, 1998, THESIS; Jager S., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P150, DOI 10.1109/ICPR.1996.546812; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; KADOTA S, 1976, P INT C PATT REC, P113; Kato Y., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P261, DOI 10.1109/ICDAR.1999.791774; Kato Y, 2000, IEEE T PATTERN ANAL, V22, P938, DOI 10.1109/34.877517; LALLICAN PM, 2000, P 7 INT WORKSH FRONT, P303; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; LEE S, 1992, IEEE T SYST MAN CYB, V22, P755, DOI 10.1109/21.156588; Liu K, 1997, PROC INT CONF DOC, P211, DOI 10.1109/ICDAR.1997.619843; Liu K, 1999, IEEE T PATTERN ANAL, V21, P1095, DOI 10.1109/34.799914; MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417; Plamondon R, 1999, IEEE T IMAGE PROCESS, V8, P80, DOI 10.1109/83.736691; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Qiao Y, 2005, PROC INT CONF DOC, P227, DOI 10.1109/ICDAR.2005.25; Qiao Y, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P118; QIAO Y, 2006, P 31 INT C AC SPEECH; RABINER L, 1993, FUNDAMENTALS SPEECH, pCH4; Steinherz T, 2005, IEEE T PATTERN ANAL, V27, P669, DOI 10.1109/TPAMI.2005.94; Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010	34	26	30	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1724	1737		10.1109/TPAMI.2006.216	http://dx.doi.org/10.1109/TPAMI.2006.216			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063679				2022-12-18	WOS:000240443400002
J	Xue, HH; Govindaraju, V				Xue, HH; Govindaraju, V			Hidden Markov models combining discrete symbols and continuous attributes in handwriting recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov processes; handwriting analysis	WORD RECOGNITION; SEGMENTATION	Prior arts in handwritten word recognition model either discrete features or continuous features, but not both. This paper combines discrete symbols and continuous attributes into structural handwriting features and model, them by transition-emitting and state-emitting hidden Markov models. The models are rigorously defined and experiments have proven their effectiveness.	IBM Corp, Adv Clustering Technol Team, Poughkeepsie, NY 12601 USA; Ctr Document Anal & Recognit, Amherst, NY 14228 USA	International Business Machines (IBM)	Xue, HH (corresponding author), IBM Corp, Adv Clustering Technol Team, 2455 S Rd, Poughkeepsie, NY 12601 USA.	hanhong@us.ibm.com; venu@cubs.buffalo.edu						Baum LE, 1972, INEQUALITIES, V3, P1; BOURLARD H, 2002, HDB BRAIN THEORY NEU; BUNKE H, 1995, PATTERN RECOGN, V28, P1399, DOI 10.1016/0031-3203(95)00013-P; CHEN M, 1993, THESIS STATE U NEW Y; CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074; Dzuba G, 1998, P 6 INT WORKSH FRONT, P99; El-Yacoubi A, 1999, IEEE T PATTERN ANAL, V21, P752, DOI 10.1109/34.784288; FORNEY GD, 1973, P IEEE, V61, P263; HOLLERBACH JM, 1981, BIOL CYBERN, V39, P139, DOI 10.1007/BF00336740; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; HUMPHREYS GW, 1990, COGNITIVE PSYCHOL, V22, P517, DOI 10.1016/0010-0285(90)90012-S; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887; Tulyakov S., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P164, DOI 10.1109/ICDAR.2001.953776; WHEELER DD, 1970, COGNITIVE PSYCHOL, V1, P59, DOI 10.1016/0010-0285(70)90005-8; XUE H, 2001, P 6 ICDAR, P96; YOUNG A, 1995, WASTE MANAGE RES, V13, P3, DOI 10.1177/0734242X9501300102	18	26	27	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					458	462		10.1109/TPAMI.2006.55	http://dx.doi.org/10.1109/TPAMI.2006.55			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526430	Green Submitted			2022-12-18	WOS:000234517900010
J	Adan, A; Adan, M				Adan, A; Adan, M			A flexible similarity measure for 3D shapes recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; feature measurement; object recognition; similarity measures; pattern recognition	OBJECT RECOGNITION; REPRESENTATION SCHEME; SIGNATURES	This paper is devoted to presenting a new strategy for 3D objects recognition using a flexible similarity measure based on the recent Modeling Wave (MW) topology in spherical models. MW topology allows us to establish an n-connectivity relationship in 3D objects modeling meshes. Using the complete object model, a study on considering different partial information of the model has been carried out to recognize an object. For this, we have introduced a new feature called Cone-Curvature (CC), which originates from the MW concept. CC gives an extended geometrical surroundings knowledge for every node of the mesh model and allows us to define a robust and adaptable similarity measure between objects for a specific model database. The defined similarity metric has been successfully tested in our lab using range data of a wide variety of 3D shapes. Finally, we show the applicability of our method presenting experimentation for recognition on noise and occlusion conditions in complex scenes.	Univ Castilla La Mancha, Dept IEE & Automat, E-13071 Ciudad Real, Spain; Univ Castilla La Mancha, Dept Matemat Aplicada, E-13071 Ciudad Real, Spain	Universidad de Castilla-La Mancha; Universidad de Castilla-La Mancha	Adan, A (corresponding author), Univ Castilla La Mancha, Dept IEE & Automat, E-13071 Ciudad Real, Spain.	Antonio.Adan@uclm.es; Miguel.Adan@uclm.es	Adán, Antonio/A-1153-2012	Adán, Antonio/0000-0002-0370-9651; Adan, Alfredo/0000-0002-0849-8814				Adan A, 2000, COMPUT VIS IMAGE UND, V79, P281, DOI 10.1006/cviu.2000.0855; Adan A, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P532, DOI 10.1109/TDPVT.2002.1024112; Adan A, 2001, PATTERN RECOGN, V34, P1331, DOI 10.1016/S0031-3203(00)00101-1; ADAN A, 1998, LECT NOTES COMPUTER, V1351, P482; ALBOUL L, 1996, MATH SURFACES, V6, P171; Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3; Bezdek J. C., 1978, Fuzzy Sets and Systems, V1, P111, DOI 10.1016/0165-0114(78)90012-X; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; Cyr CM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P254, DOI 10.1109/ICCV.2001.937526; DELINGUETTE H, 1994, 2214 INRIA; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; DYN N, 2000, MATH METHODS CURVES, P135; HEBERT M, 1995, IEEE T PATT ANAL MAC, V17; Jain R., 1995, MACHINE VISION; JOHNSON AE, 1997, IEEE C COMP VIS PATT, P684; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; LIU X, 2003, P C VIS PATT REC, V1, P813; Merchan P, 2002, LECT NOTES ARTIF INT, V2527, P923; Miettinen K., 1999, NONLINEAR MULTIOBJEC; OSADA R, 2001, SHAPE MODELING I MAY; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; Sehgal A, 2003, PATTERN RECOGN, V36, P765, DOI 10.1016/S0031-3203(02)00102-4; Serratosa F, 2003, PATTERN RECOGN, V36, P781, DOI 10.1016/S0031-3203(02)00107-3; SHUM HY, 1966, P IEEE C COMP VIS PA, P526; Super BJ, 2003, PATTERN RECOGN, V36, P69, DOI 10.1016/S0031-3203(02)00023-7; Vandeborre JP, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P644, DOI 10.1109/TDPVT.2002.1024132; Veltkamp R., 2001, UUCS200103; Yamany S. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1098, DOI 10.1109/ICCV.1999.790402; Yamany SM, 2002, IEEE T PATTERN ANAL, V24, P1105, DOI 10.1109/TPAMI.2002.1023806; YU PL, 1973, MANAGE SCI B-APPL, V19, P936, DOI 10.1287/mnsc.19.8.936; ZADEH LA, 1963, IEEE T AUTOMAT CONTR, VAC 8, P59, DOI 10.1109/TAC.1963.1105511; Zeleny M., 1973, MULTIPLE CRITERIA DE, P262	33	26	29	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2004	26	11					1507	1520		10.1109/TPAMI.2004.94	http://dx.doi.org/10.1109/TPAMI.2004.94			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	852EC	15521497				2022-12-18	WOS:000223737000009
J	Bala, E; Cetin, AE				Bala, E; Cetin, AE			Computationally efficient wavelet affine invariant functions for shape recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						affine transformation; decimated wavelet transform; shape recognition; computational efficiency	OBJECT RECOGNITION; REPRESENTATION; MAXIMA	An affine invariant function for object recognition is constructed from wavelet coefficients of the object boundary. In previous works, undecimated dyadic wavelet transform was used to construct affine invariant functions. In this paper, an algorithm based on decimated wavelet transform is developed to compute an affine invariant function. As a result computational complexity is reduced without decreasing recognition performance. Experimental results are presented.	Univ Delaware, Dept Elect & Comp Engn, Newark, DE 19716 USA; Bilkent Univ, Dept Elect & Elect Engn, TR-06800 Ankara, Turkey	University of Delaware; Ihsan Dogramaci Bilkent University	Bala, E (corresponding author), Univ Delaware, Dept Elect & Comp Engn, 140 Evans Hall, Newark, DE 19716 USA.	erdem@udel.edu; cetin@ee.bilkent.edu.tr						ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; CETIN AE, 1994, IEEE T SIGNAL PROCES, V42, P194, DOI 10.1109/78.258135; FREEMAN H, 1978, PATTERN RECOGN, V10, P159, DOI 10.1016/0031-3203(78)90024-9; Guggenheimer H.W., 1963, DIFFERENTIAL GEOMETR; KHALIL M, 2003, COMMUNICATION; Khalil MI, 2001, IEEE T PATTERN ANAL, V23, P1152, DOI 10.1109/34.954605; Khalil MI, 2000, PATTERN RECOGN LETT, V21, P863, DOI 10.1016/S0167-8655(00)00046-5; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Mundy J., 1992, GEOMETRIC INVARIANCE; REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675; Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P846, DOI 10.1109/34.608288; Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P910, DOI 10.1109/34.608294; WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536	13	26	32	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					1095	U1		10.1109/TPAMI.2004.39	http://dx.doi.org/10.1109/TPAMI.2004.39			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641739	Green Submitted			2022-12-18	WOS:000221872400013
J	Wei, J				Wei, J			Markov edit distance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edit distance; Markov Random Field; dynamic programming; statistical dependency; text processing; pattern recognition	STRING CORRECTION PROBLEM; RECOGNITION; SUBSEQUENCES; COMPUTATION; RETRIEVAL; IMAGES	Edit distance was originally developed by Levenstein several decades ago to measure the distance between two strings. It was found that this distance can be computed by an elegant dynamic programming procedure. The edit distance has played important roles in a wide array of applications due to its representational efficacy and computational efficiency. To effect a more reasonable distance measure, the normalized edit distance was proposed. Many algorithms and studies have been dedicated along this line with impressive performances in recent years. There is, however, a fundamental problem with the original definition of edit distance that has remained elusive: its context-free nature. In determining the possible actions, i.e., insertion, deletion, and substitution, no systematic consideration was given to the local behaviors of the string/pattern in question that indeed encompass great amount of useful information regarding its content. In this paper, inspired by the success of the Markov Random Field theory, a new edit distance called Markov edit distance (MED) within the dynamic programming framework is proposed to take full advantage of the local statistical dependencies in the pattern in order to arrive at enhanced matching performance. Within this framework, two specialized distance measures are developed: The reshuffling MED to handle cases where a subpattern in the target pattern is the reshuffles of that in the source pattern, and the coherence MED which is able to incur local content based substitution, insertion, and deletion. The applications based on these two MEDs in string matching are then explored, whereof encouraging empirical results have been observed.	CUNY City Coll, Dept Comp Sci, New York, NY 10031 USA	City University of New York (CUNY) System; City College of New York (CUNY)	Wei, J (corresponding author), CUNY City Coll, Dept Comp Sci, Convent Ave & 138th St, New York, NY 10031 USA.	wei@cs.ccny.cuny.edu						Alferez R, 1999, IEEE T PATTERN ANAL, V21, P505, DOI 10.1109/34.771318; Arslan AN, 2000, J DISCRETE ALGORITHM, V1, P3; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; Drew MS, 1999, PATTERN RECOGN, V32, P1369, DOI 10.1016/S0031-3203(98)00168-X; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P195, DOI 10.1109/34.481543; KOCH MW, 1989, PATTERN RECOGN LETT, V10, P297, DOI 10.1016/0167-8655(89)90032-9; LOWRANCE R, 1975, J ACM, V22, P177, DOI 10.1145/321879.321880; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; OKUDA T, 1976, IEEE T COMPUT, V25, P172, DOI 10.1109/TC.1976.5009232; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; OOMMEN BJ, 1986, INFORM SCIENCES, V40, P267, DOI 10.1016/0020-0255(86)90061-7; OOMMEN BJ, 1987, IEEE T PATTERN ANAL, V9, P676, DOI 10.1109/TPAMI.1987.4767962; Oommen BJ, 1996, IEEE T PATTERN ANAL, V18, P669, DOI 10.1109/34.506420; Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800; Seni G, 1996, PATTERN RECOGN, V29, P405, DOI 10.1016/0031-3203(95)00102-6; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; TSAY YT, 1993, IEEE T PATTERN ANAL, V15, P180, DOI 10.1109/34.192491; VIDAL E, 1995, IEEE T PATTERN ANAL, V17, P899, DOI 10.1109/34.406656; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WANG YP, 1990, IEEE T PATTERN ANAL, V12, P1080, DOI 10.1109/34.61707; Wei H, 2002, IEEE T IMAGE PROCESS, V11, P912, DOI 10.1109/TIP.2002.801125; ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714	24	26	28	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					311	321		10.1109/TPAMI.2004.1262315	http://dx.doi.org/10.1109/TPAMI.2004.1262315			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376879				2022-12-18	WOS:000188949400003
J	Tordoff, B; Murray, D				Tordoff, B; Murray, D			Reactive control of zoom while fixating using perspective and affine cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active vision; zoom control; fixation; tracking; self -calibration; perspective projection; affine projection	MOTION	This paper describes reactive visual methods of controlling the zoom setting of the lens of an active camera while fixating upon an object. The first method assumes a perspective projection and adjusts zoom to preserve the ratio of focal length to scene depth. The active camera is constrained to rotate, permitting self-calibration from the image motion of points on the static background. A planar structure from motion algorithm is used to recover the depth of the foreground. The foreground-background segmentation exploits the properties of the two different interimage homographies which are observed. The fixation point is updated by transfer via the observed planar structure. The planar method is shown to work on real imagery, but results from simulated data suggest that its extension to general 3D structure is problematical under realistic viewing and noise regimes. The second method assumes an affine projection. It requires no self-calibration and the zooming camera may move generally. Fixation is again updated using transfer, but now via the affine structure recovered by factorization. Analysis of the projection matrices allows the relative scale of the affine bases in different views to be found in a number of ways and, hence, controlled to unity. The various ways are compared and the best used on real imagery captured from an active camera fitted with a controllable zoom lens in both look-move and continuous operation.	Univ Oxford, Dept Engn Sci, Act Vis Lab, Oxford OX1 3PJ, England	University of Oxford	Tordoff, B (corresponding author), Univ Oxford, Dept Engn Sci, Act Vis Lab, Parks Rd, Oxford OX1 3PJ, England.	bjt@robots.ox.ac.uk; dwm@robots.ox.ac.uk						BOBICK A, 1995, P ICCV 95 WORKSH CON, P13; de Agapito L., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P15, DOI 10.1109/CVPR.1999.786911; DEAGAPITO L, 1998, P BRIT MACH VIS C, P105; Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285; Fayman JA, 1998, IEEE INT CONF ROBOT, P2783, DOI 10.1109/ROBOT.1998.680464; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gleicher M. L., 2002, P 2 INT S SMART GRAP; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HARTLEY R, 1994, P 3 EUR C COMP VIS, P471; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hayman E, 2003, IEEE T PATTERN ANAL, V25, P1015, DOI 10.1109/TPAMI.2003.1217605; HAYMAN E, 1996, P 7 BRIT MACH VIS C; KAHL F, 1998, P 14 INT C PATT REC; KAHL F, 1998, P EUR C COMP VIS, P327; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; LUONG QT, 1994, P 3 EUR C COMP VIS S, P589; MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171; Mundy J., 1992, GEOMETRIC INVARIANCE; Murray DW, 1996, COMPUT VIS IMAGE UND, V63, P169, DOI 10.1006/cviu.1996.0012; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; Quan L, 1997, IEEE T PATTERN ANAL, V19, P834, DOI 10.1109/34.608285; Reid I. D., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P76, DOI 10.1109/ICCV.1993.378233; Reid ID, 1996, INT J COMPUT VISION, V18, P41, DOI 10.1007/BF00126139; SEO Y, 1998, P IAPR WORKSH MACH V, P274; SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553; Thorballsson T., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P450, DOI 10.1109/CVPR.1999.786977; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tordoff B, 2000, INT C PATT RECOG, P423, DOI 10.1109/ICPR.2000.905367; TORDOFF B, 2002, P 7 EUR C COMP VIS J; Tordoff B., 2002, THESIS U OXFORD; Tordoff BJ, 2003, PROC CVPR IEEE, P273; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; VIEVILLE T, 1995, ROBOT AUTON SYST, V14, P1, DOI 10.1016/0921-8890(94)00019-X	34	26	28	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2004	26	1					98	112		10.1109/TPAMI.2004.1261082	http://dx.doi.org/10.1109/TPAMI.2004.1261082			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	752LF	15382689				2022-12-18	WOS:000187161400008
J	Beiden, SV; Maloof, MA; Wagner, RF				Beiden, SV; Maloof, MA; Wagner, RF			A general model for finite-sample effects in training and testing of competing classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; classifier design and evaluation; discriminant analysis; ROC analysis; components-of-variance models; bootstrap methods	STATISTICAL PATTERN-RECOGNITION; OF-VARIANCE MODELS; ROC ANALYSIS; CROSS-VALIDATION; COMPONENTS; PERFORMANCE; BOOTSTRAP; DESIGN; SIZE; INDEX	The conventional wisdom in the field of statistical pattern recognition (SPR) is that the size of the finite test sample dominates the variance in the assessment of the performance of a classical or neural classifier. The present work shows that this result has only narrow applicability. In particular, when competing algorithms are compared, the finite training sample more commonly dominates this uncertainty. This general problem in SPR is analyzed using a formal structure recently developed for multivariate random-effects receiver operating characteristic (ROC) analysis. Monte Carlo trials within the general model are used to explore the detailed statistical structure of several representative problems in the subfield of computer-aided diagnosis in medicine. The scaling laws between variance of accuracy measures and number of training samples and number of test samples are investigated and found to be comparable to those discussed in the classic text of Fukunaga, but important interaction terms have been neglected by previous authors. Finally, the importance of the contribution of finite trainers to the uncertainties argues for some form of bootstrap analysis to sample that uncertainty. The leading contemporary candidate is an extension of the 0.632 bootstrap and associated error analysis, as opposed to the more commonly used cross-validation.	US FDA, Ctr Devices & Radiol Hlth, Rockville, MD 20857 USA; Georgetown Univ, Dept Comp Sci, Washington, DC 20057 USA	US Food & Drug Administration (FDA); Georgetown University	Beiden, SV (corresponding author), US FDA, Ctr Devices & Radiol Hlth, Rockville, MD 20857 USA.							Beiden SV, 2000, ACAD RADIOL, V7, P341, DOI 10.1016/S1076-6332(00)80008-2; Beiden SV, 2001, ACAD RADIOL, V8, P605, DOI 10.1016/S1076-6332(03)80685-2; Beiden SV, 2001, ACAD RADIOL, V8, P616, DOI 10.1016/S1076-6332(03)80686-4; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805; Clarke LP, 2001, ACAD RADIOL, V8, P447, DOI 10.1016/S1076-6332(03)80555-X; DODD LE, 2003, UNPUB ACAD RADIOLOGY; DORFMAN DD, 1992, INVEST RADIOL, V27, P723, DOI 10.1097/00004424-199209000-00015; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B., 1994, MONOGR STAT APPL PRO, DOI DOI 10.1007/978-1-4899-4541-9; Efron Bradley., 1982, JACKKNIFE BOOSTRAP O; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P1087, DOI 10.1109/34.42839; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P873, DOI 10.1109/34.31448; FUKUNAGA K, 1990, INTRO STAT PATTER RE; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jiang YL, 1996, RADIOLOGY, V201, P745, DOI 10.1148/radiology.201.3.8939225; MALOOF MA, CS0201 GEORG U DEP C; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; Metz C. E., 1986, MULTIPLE REGRESSION, P365; METZ CE, 1989, INVEST RADIOL, V24, P234, DOI 10.1097/00004424-198903000-00012; METZ CE, 1986, INVEST RADIOL, V21, P720, DOI 10.1097/00004424-198609000-00009; METZ CE, 2003, ROCSOFTWARE; Raudys S., 2001, STAT NEURAL CLASSIFI, P209, DOI [10.1007/978-1-4471-0359-2_6, DOI 10.1007/978-1-4471-0359-2_6]; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Ripley BD., 1996; Roe CA, 1997, ACAD RADIOL, V4, P587, DOI 10.1016/S1076-6332(97)80210-3; Wagner RF, 1999, P SOC PHOTO-OPT INS, V3661, P523, DOI 10.1117/12.348608	29	26	26	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1561	1569		10.1109/TPAMI.2003.1251149	http://dx.doi.org/10.1109/TPAMI.2003.1251149			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA					2022-12-18	WOS:000186765000006
J	Ye, M; Haralick, RM; Shapiro, LG				Ye, M; Haralick, RM; Shapiro, LG			Estimating piecewise-smooth optical flow with global matching and graduated optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical flow; motion discontinuity; occlusion; energy minimization	ROBUST; SEGMENTATION; COMPUTATION	This paper presents a new method for estimating piecewise-smooth optical flow. We propose a global optimization formulation with three-frame matching and local variation and develop an efficient technique to minimize the resultant global energy. This technique takes advantage of local gradient, global gradient, and global matching methods and alleviates their limitations. Experiments on various synthetic and real data show that this method achieves highly competitive accuracy.	Microsoft Corp, Redmond, WA 98052 USA; CUNY, Grad Ctr, Dept Comp Sci, New York, NY 10016 USA; Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Microsoft; City University of New York (CUNY) System; University of Washington; University of Washington Seattle	Ye, M (corresponding author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.	mingye@microsoft.com; haralick@gc.cuny.edu; shapiro@cs.washington.edu	Haralick, Robert/AAW-5151-2020	manickam, vijayabhama.M/0000-0001-9437-9477				Bab-Hadiashar A, 1998, INT J COMPUT VISION, V29, P59, DOI 10.1023/A:1008090730467; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BATTITI R, 1991, INT J COMPUT VISION, V6, P133, DOI 10.1007/BF00128153; BERGEN JR, 1992, P EUR C COMP VIS, P237; Black M, 1992, THESIS YALE U; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; DEPOMMIER R, 1992, P INT C AC SPEECH SI, V3, P269; Farneback G, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P171, DOI 10.1109/ICCV.2001.937514; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; Galvin B., 1998, P BRIT MACH VIS C; Haralick RM., 1992, COMPUTER ROBOT VISIO; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; KANG SB, 2001, PROC CVPR IEEE, P103, DOI DOI 10.HTTP://WWW.10.1109/CVPR.2001.990462; KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350; Lim KP, 2002, IEEE T PATTERN ANAL, V24, P712, DOI 10.1109/34.1000246; Memin E, 1998, IEEE T IMAGE PROCESS, V7, P703, DOI 10.1109/83.668027; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029; Ong EP, 1999, INT J COMPUT VISION, V31, P51, DOI 10.1023/A:1008046826441; Press W.H., 1997, NUMER RECIPES C; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; SCHUNCK BG, 1989, IEEE T PATTERN ANAL, V11, P1010, DOI 10.1109/34.42834; Shulman D., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P81, DOI 10.1109/WVM.1989.47097; Sim DG, 1998, IEEE T PATTERN ANAL, V20, P353, DOI 10.1109/34.677261; Simoncelli E, 1993, THESIS MIT; Sun SJ, 2000, IEEE IMAGE PROC, P852; SZELISKI R, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P194, DOI 10.1109/CVPR.1994.323829; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; TORR PHS, 1998, P ICCV, P983; Weiss Y, 2001, NEURAL COMPUT, V13, P2173, DOI 10.1162/089976601750541769; Ye M, 2000, INT C PATT RECOG, P1052, DOI 10.1109/ICPR.2000.903726; YE M, 2002, THESIS U WASHINGTON; YE M, 2000, VISION INTERFACE REA, P209; YE M, 2001, P CVPR, V2, P712; YE M, 2002, P INT C IM PROC	41	26	27	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1625	1630		10.1109/tpami.2003.1251156	http://dx.doi.org/10.1109/tpami.2003.1251156			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA		Green Submitted			2022-12-18	WOS:000186765000013
J	Bottino, A; Laurentini, A				Bottino, A; Laurentini, A			Introducing a new problem: Shape-from-silhouette when the relative positions of the viewpoints is unknown	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape-from-silhouette; volume intersection; visual hull; computer vision; object reconstruction	RECONSTRUCTION; DEFORMATION; SEQUENCES	3D shapes can be reconstructed from 2D silhouettes by back-projecting them from the corresponding viewpoints and intersecting the resulting solid cones. However, in many practical cases as observing an aircraft or an asteroid, the positions of the viewpoints with respect to the object are not known. In these cases, the relative position of the solid cones is not known and the intersection cannot be performed. The purpose of this paper is introducing and stating in a theoretical framework the problem of understanding 3D shapes from silhouettes when the relative positions of the viewpoints are unknown. The results presented provide a first insight into the problem. In particular, the case of orthographic viewing directions parallel to the same plane is thoroughly discussed, and sets of inequalities are presented which allow determining objects compatible with the silhouettes.	Politecn Torino, Dipartimento Automat & Informat, I-10129 Turin, Italy	Polytechnic University of Turin	Bottino, A (corresponding author), Politecn Torino, Dipartimento Automat & Informat, Corso Duca Abruzzi 24, I-10129 Turin, Italy.	andrea.bottino@polito.it; aldo.laurentini@polito.it	Bottino, Andrea/F-4509-2012	Bottino, Andrea/0000-0002-8894-5089				AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; Astrom K, 1999, IEEE T PATTERN ANAL, V21, P114, DOI 10.1109/34.748821; BOTTINO A, 2001, P 9 INT C CTR EUR CO, V2, P230; Boyer E, 1997, INT J COMPUT VISION, V22, P219, DOI 10.1023/A:1007978616082; CHIEN CH, 1989, IEEE T PATTERN ANAL, V11, P372, DOI 10.1109/34.19034; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; Dobkin D., 1986, P 18 ANN ACM S THEOR, P424; JAULIN L, 1996, BOUNDING APPROACHES, P363; Jones M, 2000, IEE P-VIS IMAGE SIGN, V147, P1, DOI 10.1049/ip-vis:20000101; Laurentini A, 1997, COMPUT VIS IMAGE UND, V67, P81, DOI 10.1006/cviu.1996.0508; LAURENTINI A, 1995, IEEE T PATTERN ANAL, V17, P188, DOI 10.1109/34.368170; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LINDENBAUM M, 1990, PATTERN RECOGN, V23, P1343, DOI 10.1016/0031-3203(90)90080-5; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; Mendonca PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461; NOBORIO H, 1988, IEEE T PATTERN ANAL, V10, P769, DOI 10.1109/34.9101; POTMESIL M, 1987, COMPUT VISION GRAPH, V40, P1, DOI 10.1016/0734-189X(87)90053-3; SKIENA SS, 1992, P IEEE, V80, P1364, DOI 10.1109/5.163406; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; ZHENG JY, 1994, IEEE T PATTERN ANAL, V16, P163, DOI 10.1109/34.273734; [No title captured]	21	26	28	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1484	1493		10.1109/TPAMI.2003.1240121	http://dx.doi.org/10.1109/TPAMI.2003.1240121			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	733NG		Green Submitted			2022-12-18	WOS:000186006800012
J	Iannarilli, FJ; Rubin, PA				Iannarilli, FJ; Rubin, PA			Feature selection for multiclass discrimination via mixed-integer linear programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature selection; discrimination; classification; mixed-integer; linear programming; branch-and-bound		We reformulate branch-and-bound feature selection employing L-infinity or particular L-p metrics, as mixed-Integer linear programming (MILP) problems, affording convenience of widely available MILP solvers. These formulations offer direct influence over individual pairwise interclass margins, which is useful for feature selection in multiclass settings.	Aerodyne Res Inc, Billerica, MA 01821 USA; Michigan State Univ, Eli Broad Grad Sch Management, Dept Management, E Lansing, MI 48824 USA	Aerodyne Research; Michigan State University	Iannarilli, FJ (corresponding author), Aerodyne Res Inc, 45 Manning Rd, Billerica, MA 01821 USA.	franki@aerodyne.com; rubin@msu.edu	Rubin, Paul/AAF-9116-2020	Rubin, Paul/0000-0002-6313-4968				Bishop, 1995, NEURAL NETWORKS PATT; Bruzzone L, 2000, INT J REMOTE SENS, V21, P549, DOI 10.1080/014311600210740; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Dash M., 1997, Intelligent Data Analysis, V1; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; DUIN R, 2000, PRTOOLS, V3; Glen JJ, 2001, J OPER RES SOC, V52, P328, DOI 10.1057/palgrave.jors.2601085; HAND DJ, 1981, DISCRIMINATION CLASS, pCH6; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Mitchell JE., 2001, ENCY OPTIMIZATION; MITCHELL TOM M., 1997, MACH LEARN, P2; NARENDRA P, 1977, IEEE T COMPUT, V26, P917, DOI 10.1109/TC.1977.1674939; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Tou JT, 1974, PATTERN RECOGN; VANEDERBEI RJ, 2001, LINEAR PROGRAMMING; Wolsey LA, 1998, INTEGER PROGRAMMING	18	26	26	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2003	25	6					779	783		10.1109/TPAMI.2003.1201827	http://dx.doi.org/10.1109/TPAMI.2003.1201827			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	680DP					2022-12-18	WOS:000182961300012
J	Shen, H; Stewart, CV; Roysam, B; Lin, G; Tanenbaum, HL				Shen, H; Stewart, CV; Roysam, B; Lin, G; Tanenbaum, HL			Frame-rate spatial referencing based on invariant indexing and alignment with application to online retinal image registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						retinal laser surgery; registration; invariant indexing; robust estimation; retinal imaging; ophthalmic image processing; biomedical image processing	3D OBJECT RECOGNITION; NEOVASCULARIZATION; TRANSFORMATIONS; TRACKING	This paper describes an algorithm to continually and accurately estimate the absolute location of a diagnostic or surgical tool (such as a laser) pointed at the human retina, from a series of image frames. We treat the problem as a registration problem using diagnostic images to build a spatial map of the retina and then registering each online image against this map. Since the image location where the laser strikes the retina is easily found, this registration determines the position of the laser in the global coordinate system defined by the spatial map. For each online image, the algorithm computes similarity invariants, locally valid despite the curved nature of the retina, from constellations of vascular landmarks. These are detected using a high-speed algorithm that iteratively traces the blood vessel structure. Invariant indexing establishes initial correspondences between landmarks from the online image and landmarks stored in the spatial map. Robust alignment and verification steps extend the similarity transformation computed from these initial correspondences to a global, high-order transformation. In initial experimentation, the method has achieved 100 percent success on 1024 x 1024 retina images. With a version of the tracing algorithm optimized for speed on 512 x 512 images, the computation time is only 51 milliseconds per image on a 900MHz PentiumIII processor and a 97 percent success rate is achieved. The median registration error in either case is about 1 pixel.	Siemens Corp Res, Imaging & Visualizat Dept, Princeton, NJ USA; Rensselaer Polytech Inst, Troy, NY 12180 USA; Ctr Sight, Albany, NY 12204 USA	Siemens AG; Rensselaer Polytechnic Institute	Shen, H (corresponding author), Siemens Corp Res, Imaging & Visualizat Dept, 755 Coll Rd E, Princeton, NJ USA.							BARRETT SF, 1994, OPT ENG, V33, P150, DOI 10.1117/12.149134; Becker DE, 1998, IEEE T BIO-MED ENG, V45, P105, DOI 10.1109/10.650362; Beis JS, 1999, IEEE T PATTERN ANAL, V21, P1000, DOI 10.1109/34.799907; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BINFORD TO, 1993, P DARPA IM UND WORKS, P819; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Can A, 2002, IEEE T PATTERN ANAL, V24, P347, DOI 10.1109/34.990136; Can A, 2002, IEEE T PATTERN ANAL, V24, P412, DOI 10.1109/34.990145; Can A, 1999, IEEE Trans Inf Technol Biomed, V3, P125, DOI 10.1109/4233.767088; Can A, 2000, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2000.854924; CAN A, 1999, P IEEE C COMP VIS PA, P286; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; FINE SL, 1988, ARCH OPHTHALMOL-CHIC, V106, P1524, DOI 10.1001/archopht.1988.01060140692035; Hampel FR., 2011, WILEY SERIES PROBABI; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Jacobs DW, 1997, INT J COMPUT VISION, V21, P123, DOI 10.1023/A:1007927623619; KRAUSS JM, 1995, LASER SURG MED, V17, P102, DOI 10.1002/lsm.1900170203; Kyriacos S, 1997, FRACTALS, V5, P615, DOI 10.1142/S0218348X97000498; MARKOW MS, 1993, IEEE T BIO-MED ENG, V40, P1269, DOI 10.1109/10.250583; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; MONAHAN PM, 1993, RETINA-J RET VIT DIS, V13, P187, DOI 10.1097/00006982-199313030-00001; MONAHAN PM, 1993, RETINA-J RET VIT DIS, V13, P196, DOI 10.1097/00006982-199313030-00002; MURPHY R, 1986, OPHTHALMOLOGY, V9, P696; ROIDER J, 1995, KLIN MONATSBL AUGENH, V206, P428, DOI 10.1055/s-2008-1035482; ROTHWELL CA, 1995, INT J COMPUT VISION, V16, P57, DOI 10.1007/BF01428193; SEL I, 1965, DETECTION THEORY; Shen H, 2001, IEEE T INF TECHNOL B, V5, P77, DOI 10.1109/4233.908405; SHEN H, 2000, THESIS RENSSELAER PO; STEWART CV, 1999, SIAM REV, V41; TSAI CL, 2001, UNPUB IEEE T INFORMA; ZIMMERGALLER IE, 1995, INT OPHTHALMOL CLIN, V35, P37, DOI 10.1097/00004397-199503540-00005; ZISSERMAN A, 1995, ARTIF INTELL, V78, P239, DOI 10.1016/0004-3702(95)00023-2	32	26	27	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2003	25	3					379	384		10.1109/TPAMI.2003.1182101	http://dx.doi.org/10.1109/TPAMI.2003.1182101			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	647BL					2022-12-18	WOS:000181071300010
J	Jain, A; Moulin, P; Miller, MI; Ramchandran, K				Jain, A; Moulin, P; Miller, MI; Ramchandran, K			Information-theoretic bounds on target recognition performance based on degraded image data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Information Theory Workshop (DECI)	FEB, 1999	SANTA FE, NEW MEXICO	IEEE		object recognition; automatic target recognition; imaging sensors; multisensor data fusion; data compression; performance metrics	SYSTEMS	This paper derives bounds on the performance of statistical object recognition systems, wherein an image of a target is observed by a remote sensor. Detection and recognition problems are modeled as composite hypothesis testing problems involving nuisance parameters. We develop information-theoretic performance bounds on target recognition based on statistical models for sensors and data, and examine conditions under which these bounds are tight. In particular, we examine the validity of asymptotic approximations to probability of error in such imaging problems. Problems involving Gaussian, Poisson, and multiplicative noise, and random pixel deletions are considered, as well as least-favorable Gaussian clutter. A sixth application involving compressed sensor image data is considered in some detail. This study provides a systematic and computationally attractive framework for analytically characterizing target recognition performance under complicated, non-Gaussian models and optimizing system parameters.	QUALCOMM Inc, San Diego, CA 92126 USA; Univ Illinois, Beckman Inst, Coordinated Sci Lab, Urbana, IL 61801 USA; Univ Illinois, ECE Dept, Urbana, IL 61801 USA; Johns Hopkins Univ, Baltimore, MD 21218 USA; Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Qualcomm; University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign; Johns Hopkins University; University of California System; University of California Berkeley	Jain, A (corresponding author), QUALCOMM Inc, 5775 Morehouse Dr,L-529H, San Diego, CA 92126 USA.		Miller, Michael I./A-3213-2010					ALI SM, 1966, J ROYAL STAT SOC B, V28, P132; BERGER JO, 1984, BAYESIAN DECISION TH; Bucklew J.A., 1990, LARGE DEVIATION TECH; CLARKE BS, 1990, IEEE T INFORM THEORY, V36, P453, DOI 10.1109/18.54897; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Feller W, 2008, INTRO PROBABILITY TH, V2; FUKUNAGA K, 2000, STAT PATTERN RECOGNI; Gersho A., 1992, VECTOR QUANTIZATION; Grenander U, 1998, IEEE T PATTERN ANAL, V20, P790, DOI 10.1109/34.709572; JAIN A, 1999, THESIS U ILLINOIS UR; JANA S, 1999, P C INF SYST SCI MAR; KASSAM SA, 1977, IEEE T COMMUN, V25, P479, DOI 10.1109/TCOM.1977.1093858; Lanterman AD, 1999, OPT ENG, V38, P2134, DOI 10.1117/1.602323; Lehmann E RJ, 2005, TESTING STAT HYPOTHE, V3; LINDENBAUM M, 1995, IEEE T PATTERN ANAL, V17, P666, DOI 10.1109/34.391409; LOPRESTO S, 1997, P IEEE DAT COMPR C; Mihcak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428; Miller JP, 1997, J SPORT REHABIL, V6, P1; Poor, 2013, INTRO SIGNAL DETECTI; POOR HV, 1977, IEEE T COMMUN, V25, P893, DOI 10.1109/TCOM.1977.1093935; Proakis J. G., 1995, DIGITAL COMMUNICATIO; Ratches JA, 1997, IEEE T PATTERN ANAL, V19, P1004, DOI 10.1109/34.615449; Rockefellar R.T., 1972, CONVEX ANAL; SIMS SRF, 1997, OPTICAL ENG, V36, P2671; Van Trees H. L, 2004, DETECTION ESTIMATION; [No title captured]; 1997, IEEE T IMAGE PROCESS, V6	28	26	29	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2002	24	9					1153	1166		10.1109/TPAMI.2002.1033209	http://dx.doi.org/10.1109/TPAMI.2002.1033209			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	587KW					2022-12-18	WOS:000177640500001
J	Cai, JH; Liu, ZQ				Cai, JH; Liu, ZQ			Hidden Markov models with spectral features for 2D shape recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hidden Markov models; spectral features; 2D shape recognition; outer contours; handwritten numeral recognition	MOMENT INVARIANTS; CLASSIFICATION; DESCRIPTORS	In this paper, we present a technique using Markov models with spectral features for recognizing 2D shapes. We will analyze the properties of Fourier spectral features derived from closed contours of 2D shapes and use these features for 2D pattern recognition. We develop algorithms for reestimating parameters of hidden Markov models. To demonstrate the effectiveness of our models, we have tested our methods on two image databases: hand-tools and unconstrained handwritten numerals. We are able to achieve high recognition rates of 99.4 percent and 96.7 percent without rejection on these two sets of image data, respectively.	Queensland Univ Technol, Sch Comp Sci & Software Engn, Brisbane, Qld 4001, Australia; City Univ Hong Kong, Sch Creat Media, Hong Kong, Hong Kong, Peoples R China	Queensland University of Technology (QUT); City University of Hong Kong	Cai, JH (corresponding author), Queensland Univ Technol, Sch Comp Sci & Software Engn, Brisbane, Qld 4001, Australia.		Cai, Jinhai/D-9024-2011					BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z; Brand M, 1996, 405 MIT MED LAB PERC; BRAND M, 1996, 407 MIT MED LAB PERC; Cai JH, 1999, IEEE T PATTERN ANAL, V21, P263, DOI 10.1109/34.754622; DAS M, 1990, IEEE T PATTERN ANAL, V12, P97, DOI 10.1109/34.41389; ELMS AJ, 1996, THESIS U SURREY; HE Y, 1991, IEEE T PATTERN ANAL, V13, P1172, DOI 10.1109/34.103276; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Huang X., 1990, HIDDEN MARKOV MODELS; KAUPPINEN H, 1995, IEEE T PATTERN ANAL, V17, P201, DOI 10.1109/34.368168; LANITIS A, 1993, P BRIT MACH VIS C, V1, P329; LIU HC, 1990, IEEE T PATTERN ANAL, V12, P1072, DOI 10.1109/34.61706; PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799; PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675; Sclaroff S, 1997, PATTERN RECOGN, V30, P627, DOI 10.1016/S0031-3203(96)00108-2; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P329; SEKITA I, 1992, IEEE T PATTERN ANAL, V14, P489, DOI 10.1109/34.126809; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; WILLIAMS C, 1994, THESIS U TORONTO	22	26	28	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2001	23	12					1454	1458		10.1109/34.977569	http://dx.doi.org/10.1109/34.977569			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	500NY		Green Submitted			2022-12-18	WOS:000172634700011
J	Jones, E; Runkle, P; Dasgupta, N; Couchman, L; Carin, L				Jones, E; Runkle, P; Dasgupta, N; Couchman, L; Carin, L			Genetic algorithm wavelet design for signal classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						genetic algorithms; wavelets; classification		Biorthogonal wavelets are applied to parse multiaspect transient scattering data in the context of signal classification. A language-based genetic algorithm is used to design wavelet filters that enhance classification performance. The biorthogonal wavelets are implemented via the lifting procedure and the optimization is carried out using a classification-based cost function. Example results are presented for target classification using measured scattering data.	Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA; Naval Res Lab, Phys Acoust, Washington, DC 20375 USA	Duke University; United States Department of Defense; United States Navy; Naval Research Laboratory	Jones, E (corresponding author), Duke Univ, Dept Elect & Comp Engn, Box 90291, Durham, NC 27708 USA.	couchman@nrl.navy.mil; lcarin@ee.duke.edu		Carin, Lawrence/0000-0001-6277-7948				Angeline P. J., 1996, P 1 ANN C GEN PROGR, P21; ANGELINE PJ, 1997, P 2 ANN C GEN PROGR, P9; Back T., 1991, P INT C GEN ALG ICGA, V2; CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730; CLAYPOOLE RL, 1998, P IEEE INT C AC SIGN; COHEN A, 1992, COMMUN PUR APPL MATH, V45, P485, DOI 10.1002/cpa.3160450502; Goldberg D.E., 2013, GENETIC ALGORITHMS; JONES EA, 1999, THESIS DUKE U; KIL DH, 1996, PATTERN RECOGNITION; Koza J. R, 1997, GENETIC PROGRAMMING; Koza JR, 1994, GENETIC PROGRAMMING; Levinson S. E., 1986, Computer Speech and Language, V1, P29, DOI 10.1016/S0885-2308(86)80009-2; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Mallat S., 1999, WAVELET TOUR SIGNAL; NAUR P, 1963, COMMUN ACM, V6, P77, DOI 10.1145/366274.366286; O'Neill M, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1143; Oslick M, 1998, INT CONF ACOUST SPEE, P1537; Poli R, 1998, EVOL COMPUT, V6, P231, DOI 10.1162/evco.1998.6.3.231; RUNKLE P, 1999, J ACOUSTICAL SOC AUG, P605; Runkle PR, 1999, IEEE T SIGNAL PROCES, V47, P2035, DOI 10.1109/78.771050; Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015; TEWFIK AH, 1992, IEEE T INFORM THEORY, V38, P747, DOI 10.1109/18.119734	22	26	28	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					890	895		10.1109/34.946991	http://dx.doi.org/10.1109/34.946991			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH					2022-12-18	WOS:000170283300008
J	Stein, GP; Shashua, A				Stein, GP; Shashua, A			Model-based brightness constraints: On direct estimation of structure and motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape representation and recovery; 3D recovery from 2D; shape from motion; image sequence analysis; algebraic and projective geometry	IMAGE; GEOMETRY	We describe a new direct method for estimating structure and motion from image intensities of multiple views. We extend the direct methods of Horn and Weldon [18] to three views. Adding the third view enables us to solve for motion and compute a dense depth map of the scene, directly from image spatio-temporal derivatives in a linear manner without first having to find point correspondences or compute optical flow. We describe the advantages and limitations of this method which are then verified with experiments using real images.	Mobileye Vis Technol Ltd, IL-97278 Jerusalem, Israel; Hebrew Univ Jerusalem, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Stein, GP (corresponding author), Mobileye Vis Technol Ltd, Ramot Arazim,24 Mishof Hadkalim St, IL-97278 Jerusalem, Israel.	gideon@moibleye.com; shashua@cs.huji.ac						AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; BERGEN JR, 1992, P EUR C COMP VIS JUN; BERGEN JR, 1990, HIERARCHICAL MOTION; Deriche R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P66, DOI 10.1109/ICCV.1990.139495; Dutta R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P106, DOI 10.1109/ICCV.1990.139504; FAUGERAS O, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P951, DOI 10.1109/ICCV.1995.466832; FAUGERAS O, 1998, P INT C COMP VIS 98; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Fermuller C, 1997, INT J COMPUT VISION, V21, P223, DOI 10.1023/A:1007951901001; FERMULLER C, 1995, P INT C COMP VIS JUN; FERMULLER C, 1997, P C COMP VIS PATT RE; HARTLEY R, 1995, P INT C COMP VIS JUN; Heeger D. J., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P96, DOI 10.1109/ICCV.1990.139502; HEEL J, 1990, 1190 AI MIT ART INT; HEYDEN A, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1058, DOI 10.1109/ICCV.1995.466817; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; IRANI M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P454, DOI 10.1109/CVPR.1994.323866; KUMAR R, 1994, P INT C PATT REC OCT; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; MCQUIRK IS, 1996, 1577 MIT; MICHAELS D, 1992, THESIS MIT; More J., 1980, ANL8074; NAGEL HH, 1992, ARTIFICIAL BIOL VISI, P193; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; REIGER J, 1985, J OPT SOC AM A, V2, P354; SAWHNEY HS, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P929, DOI 10.1109/CVPR.1994.323927; Shashua A, 1996, IEEE T PATTERN ANAL, V18, P873, DOI 10.1109/34.537342; SHASHUA A, 1995, IEEE T PATTERN ANAL, V17, P779, DOI 10.1109/34.400567; Shashua A., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P920, DOI 10.1109/ICCV.1995.466837; SHASHUA A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P483, DOI 10.1109/CVPR.1994.323870; SHASHUA A, 1996, P ARPA IM UND WORKSH; SHASHUA A, 1995, TENSOR BRIGHTNESS CO; SHASHUA A, 1996, P EUR C COMP VIS APR; Soatto S, 1996, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.1996.517166; SPETSAKIS M, 1990, P ARPA IM UND WORKSH; Stein G. P., 1993, THESIS MIT CAMBRIDGE; STEIN GP, 1998, P EUR C COMP VIS JUN; STEIN GP, 1997, P C COMP VIS PATT RE; STEIN GP, 1998, THESIS MIT; SZELISKI R, 1995, P IEEE WORKSH REPR V; Tian TY, 1996, PROC CVPR IEEE, P315, DOI 10.1109/CVPR.1996.517091; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TRIGGS B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P338, DOI 10.1109/ICCV.1995.466920; WENG J, 1989, P ICCV TAMPA, P64; Wolberg G, 1990, DIGITAL IMAGE WARPIN	49	26	30	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2000	22	9					992	1015		10.1109/34.877522	http://dx.doi.org/10.1109/34.877522			24	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	361TY					2022-12-18	WOS:000089741300007
J	Wolovich, WA; Unel, M				Wolovich, WA; Unel, M			The determination of implicit polynomial canonical curves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						implicit polynomials; affine transformations; object recognition; pose estimation; canonical curves		A new method is presented for identifying and comparing closed, bounded, free-form curves that are defined by even implicit polynomial (IP) equations in the Cartesian coordinates rand y. The method provides a new expression for an IP involving a product of conic factors with unique conic factor centers. The critical points for an IP curve also are defined. The conic factor centers and the critical points are shown to be useful related points that directly map to one another under affine transformations. In particular. the explicit determination of such points implies both a canonical form for the curves and the transformation matrix which relates affine equivalent curves.	Brown Univ, Div Engn, Providence, RI 02912 USA	Brown University	Wolovich, WA (corresponding author), Brown Univ, Div Engn, Providence, RI 02912 USA.	waw@lems.brown.edu; mu@lems.brown.edu	Unel, Mustafa/AAY-3881-2020	Unel, Mustafa/0000-0002-2907-3233				Ballard D.H., 1982, COMPUTER VISION; Bloomenthal J., 1997, INTRO IMPLICIT SURFA; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; LEI Z, 1995, P INT C IM PROC WASH; LEI Z, 1997, THESIS BROWN U PROVI; LEI Z, 1996, P 3 IEEE WORKSH APPL; *MATH WORKS INC, MATL US GUID; Mundy L., 1992, GEOMETRIC INVARIANTS; SELBY SM, 1996, CRC STANDARD MATH TA; TAUBIN G, 1994, IEEE T PATTERN ANAL, V16, P287, DOI 10.1109/34.276128; TAUBIN G, 1992, SYMBOLIC NUMERICAL C, pCH6; UNEL M, 1997, LEMS166; VIJAYAKUMAR B, 1995, INT C COMP VIS BOST; WOLOVICH W, 1998, LECT NOTES CONTROL I	16	26	28	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1998	20	10					1080	1090		10.1109/34.722620	http://dx.doi.org/10.1109/34.722620			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	128QB					2022-12-18	WOS:000076416400005
J	Baram, Y				Baram, Y			Partial classification: The benefit of deferred decision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; pattern recognition; hypothesis testing; decision making; machine learning; stock trading; medical diagnosis		It is shown that partial classification, which allows for indecision in certain regions of the data space, can increase a benefit function, defined as the difference between the probabilities of correct and incorrect decisions, joint with the event that a decision is made. This is particularly true for small data samples, which may cause a large deviation of the estimated separation surface from the intersection surface between the corresponding probability density functions. Employing a particular density estimation method, an indecision domain is naturally defined by a single parameter, whose optimal size, maximizing the benefit function, is derived from the data. The benefit function is shown to translate into profit in stock trading. Employing medical and economic data, it is shown that partial classification produces, on average, higher benefit values than full classification, assigning each new object to a class, and that the marginal benefit of partial classification reduces as the data size increases.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Baram, Y (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	baram@cs.technion.ac.il						AIZERMAN MA, 1965, AUTOMAT REM CONTR+, V25, P1175; Anderson T. W, 1984, INTRO MULTIVARIATE S; ANDREWS HC, 1972, MATH TECHNIQUES PATT; ARCHER NP, 1991, IEEE T SYST MAN CYB, V21, P735, DOI 10.1109/21.108291; BARAM Y, 1984, IEEE T ACOUST SPEECH, V32, P163, DOI 10.1109/TASSP.1984.1164290; Baum E. B., 1988, Journal of Complexity, V4, P193, DOI 10.1016/0885-064X(88)90020-9; Bishop, 1995, NEURAL NETWORKS PATT; Chow CK., 1957, IRE T ELECT COMPUTER, VEC-6, P247, DOI DOI 10.1109/TEC.1957.5222035; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274; Duda R.O., 2000, PATTERN CLASSIFICATI; FUKUNAGA K, 1972, IEEE T INFORM THEORY, V18, P814, DOI 10.1109/TIT.1972.1054919; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; Gordon AD, 1999, CLASSIFICATION; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; Hoel PG., 1984, INTRO MATH STAT; HORN AR, 1985, MATRIX ANAL; ISHIBUCHI H, 1993, FUZZY LOGIC, P225; MEINGUET J, 1979, Z ANGEW MATH PHYS, V30, P292, DOI 10.1007/BF01601941; Minsky M., 1988, PERCEPTRONS; Nilsson N., 1965, LEARNING MACHINES; Papoulis A., 2002, PROBABILITY RANDOM V; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Roth Z, 1996, IEEE T NEURAL NETWOR, V7, P1291, DOI 10.1109/72.536322; *U CA IRV, MACH LEARN DAT BAS	27	26	26	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1998	20	8					769	776		10.1109/34.709564	http://dx.doi.org/10.1109/34.709564			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	110GT					2022-12-18	WOS:000075372700001
J	Fischl, B; Schwartz, EL				Fischl, B; Schwartz, EL			Learning an integral equation approximation to nonlinear anisotropic diffusion in image processing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						anisotropic diffusion; image enhancement; nonlinear filtering; noise reduction	EDGE-DETECTION; SHOCK FILTERS; ENHANCEMENT; RESTORATION; RESPONSES; GEOMETRY	Multiscale image enhancement and representation is an important part of biological and machine early vision systems. The process of constructing this representation must be both rapid and insensitive to noise, while retaining image structure at all scales. This is a complex task as small scale structure is difficult to distinguish from noise, while larger scale structure requires more computational effort. In both cases, good localization can be problematic. Errors can also arise when conflicting results at different scales require cross-scale arbitration. Broadly speaking, multiscale image analysis has historically been accomplished using two types of techniques: those which are sensitive to image structure and those which are not. Algorithms in the latter category typically use a set of Variously sized blurring kernels to produce images, each of which retains structure at a different scale [1], [2], [3], [4]. The kernels used for the blurring are predefined and independent of the content of the image. Koenderink showed that if the kernels are Gaussian, then this process is equivalent to the evolution of the linear heat (or diffusion) equation. He thus transformed the integral equation representing the convolution process into the solution of a partial differential equation (PDE). Structure sensitive multiscale techniques attempt to analyze an image at a variety of scales within a single image [5], [6], [7]. Klinger [5] proposed the quad tree, one of the earliest structure-sensitive multiscale image representations. In this approach, a tree structure is built by recursively subdividing an image based on pixel variance in subregions. The final tree contains leaves representing image regions whose variance is small according to some measure. Recently [6], [8], the PDE formalism introduced by Koenderink has been extended to allow structure-sensitive multiscale analysis. Instead of the uniform blurring of the linear heat equation which destroys small scale structure as time evolves, Perona and Malik use a space-variant conductance coefficient based on the magnitude of the intensity gradient in the image, giving rise to a nonlinear PDE. Like the quadtree, the end result is a single image representation which contains information at all scales of interest. The Perona and Malik approach produces impressive results, but the numerical integration of a nonlinear PDE is a costly and inherently serial process. In this paper, we present a technique which obtains an approximate solution to the PDE for a specific time, via the solution of an integral equation which is the nonlinear analog of convolution. The kernel function of the integral equation plays the same role that a Green's function does for a linear PDE, allowing the direct solution of the nonlinear PDE for a specific time without requiring integration through intermediate times. We then use a learning technique to approximate the kernel function for arbitrary input images. The result is an improvement in speed and noise-sensitivity, as well as providing a means to parallelize an otherwise serial algorithm.			Fischl, B (corresponding author), BOSTON UNIV,DEPT COGNIT & NEURAL SYST,BOSTON,MA 02146, USA.							ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052; ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032; ANDERSON TW, 1971, INTRO MULTIVARIATE S; Barton G., 1989, ELEMENTS GREENS FUNC; BLAKEMORE C, 1970, NATURE, V228, P477, DOI 10.1038/228477a0; BREIMAN L, 1991, TECHNOMETRICS, V33, P125, DOI 10.2307/1269038; Broomhead D. S., 1988, Complex Systems, V2, P321; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012; COHEN MA, 1984, FIGURAL SYNTHESIS; COTTET GH, 1993, MATH COMPUT, V61, P659, DOI 10.1090/S0025-5718-1993-1195422-2; Dang T., 1994, Proceedings of the IEEE Southwest Symposium on Image Analysis and Interpretation, P65, DOI 10.1109/IAI.1994.336683; Duda R.O., 1973, J ROYAL STAT SOC SER; ELFALLAH AI, 1994, P SOC PHOTO-OPT INS, V2182, P49, DOI 10.1117/12.171091; ENGQUIST B, 1989, MATH COMPUT, V52, P509, DOI 10.1090/S0025-5718-1989-0955750-9; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gonzalez R. C., 1987, DIGITAL IMAGE PROCES; GROSSBERG S, 1985, PSYCHOL REV, V92, P173, DOI 10.1037/0033-295X.92.2.173; HABERMAN R, 1987, ELEMENTARY APPL PART; HUMMEL RA, 1986, READINGS COMPUTER VI; ILLNER R, 1993, MATH METHODS APPL SC, V17, P545; KACUR J, 1995, APPL NUMERICAL MATH, V50, P47; KLINGER A, 1971, OPTIMIZING METHODS S; Lecun Y., 1985, PROC COGNITIVA, P599; LI XP, 1994, PATTERN RECOGN, V27, P1029, DOI 10.1016/0031-3203(94)90142-2; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NIESSEN W, 1994, GEOMETRY DRIVEN DIFF, P393; NITZBERG M, 1992, IEEE T PATTERN ANAL, V14, P826, DOI 10.1109/34.149593; NORDSTROM KN, 1990, IMAGE VISION COMPUT, V8, P318, DOI 10.1016/0262-8856(90)80008-H; ORAM MW, 1992, J NEUROPHYSIOL, V68, P70, DOI 10.1152/jn.1992.68.1.70; OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053; Parker DB, 1985, LEARNING LOGIC; PAUWELS EJ, 1993, P SOC PHOTO-OPT INS, V2094, P836, DOI 10.1117/12.158000; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Perona P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P16; Perona P., 1994, GEOMETRY DRIVEN DIFF, P73, DOI [10.1007/978-94-017-1699-4-3, DOI 10.1007/978-94-017-1699-4]; PRICE CB, 1990, IEE PROC-I, V137, P136, DOI 10.1049/ip-i-2.1990.0020; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; THORPE SJ, 1989, CONNECTIONISM IN PERSPECTIVE, P63; VOGELS R, 1991, EXP BRAIN RES, V84, P1; Werbos P., 1974, REGRESSION NEW TOOLS; WHITAKER RT, 1993, CVGIP-IMAG UNDERSTAN, V57, P99, DOI 10.1006/ciun.1993.1006; WHITAKER RT, 1993, CVGIP-IMAG UNDERSTAN, V57, P111, DOI 10.1006/ciun.1993.1007; Witkin A.P., 1983, INT JOINT C ART INT, P1019	47	26	26	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1997	19	4					342	352		10.1109/34.588012	http://dx.doi.org/10.1109/34.588012			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WW122					2022-12-18	WOS:A1997WW12200005
J	Shimshoni, I; Ponce, J				Shimshoni, I; Ponce, J			Finite-resolution aspect graphs of polyhedral objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; 3D object modeling; aspect graphs; image resolution	ALGEBRAIC-SURFACES; CURVED OBJECTS; SPACE	We address the problem of computing the aspect graph of a polyhedral object observed by an orthographic camera with limited spatial resolution, such that two image points separated by a distance smaller than a preset threshold cannot be resolved. Under this model, views that would differ under normal orthographic projection may become equivalent, while ''accidental'' views may occur over finite areas of the view space. We present a catalogue of visual events for polyhedral objects and give an algorithm for computing the aspect graph and enumerating all qualitatively different aspects. The algorithm has been fully implemented and results are presented.	UNIV ILLINOIS,DEPT COMP SCI,URBANA,IL 61801; UNIV ILLINOIS,BECKMAN INST,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign	Shimshoni, I (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,IL-32000 HAIFA,ISRAEL.							Bowyer K. W., 1990, International Journal of Imaging Systems and Technology, V2, P315, DOI 10.1002/ima.1850020407; CASTORE G, 1984, SOLID MODELING COMPU, P277; CHEN S, 1991, P IEEE WORKSHOP DIRE, P34; EGGERT D, 1989, NOV P IEEE WORKSH IN, P102; EGGERT D, 1991, IEEE WORKSH DIR AUT, P44; EGGERT DW, 1993, IEEE T PATTERN ANAL, V15, P1114, DOI 10.1109/34.244674; EGGERT DW, 1991, ASPECT GRAPHS SOLIDS; GIGUS Z, 1990, IEEE T PATTERN ANAL, V12, P113, DOI 10.1109/34.44399; GIGUS Z, 1991, IEEE T PATTERN ANAL, V13, P542, DOI 10.1109/34.87341; Kahaner D., 1989, NUMERICAL METHODS SO; KENDER J, 1987, P 10 INT JOINT C ART, P801; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KRIEGMAN DJ, 1990, INT J COMPUT VISION, V5, P119, DOI 10.1007/BF00054918; Morgan A. P., 1987, SOLVING POLYNOMIAL S; PETITJEAN S, 1992, INT J COMPUT VISION, V9, P231, DOI 10.1007/BF00133703; PETITJEAN S, 1995, THESIS I NATL POLYTE; PLANTINGA H, 1990, INT J COMPUT VISION, V5, P137, DOI 10.1007/BF00054919; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; RIEGER J, 1993, FBIHHM22893 U HAMB; RIEGER JH, 1992, INT J COMPUT VISION, V7, P171, DOI 10.1007/BF00126392; RIEGER JH, 1990, ARTIF INTELL, V44, P1, DOI 10.1016/0004-3702(90)90097-J; SEALES WB, 1991, IEEE WORKSH DIR AUT, P54; SHIMSHONI I, 1994, P IEEE C COMP VIS PA, P514; STEWMAN J, 1988, P INT C COMP VIS TAM, P495; STEWMAN JH, 1987, IEEE WORKSHOP COMPUT, P123; WANG R, 1990, 10TH P INT C PATT RE, P8; WATTS N, 1987, 234 CS ROCH U	27	26	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1997	19	4					315	327		10.1109/34.588001	http://dx.doi.org/10.1109/34.588001			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WW122					2022-12-18	WOS:A1997WW12200003
J	Park, KR; Lee, CN				Park, KR; Lee, CN			Scale-space using mathematical morphology	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mathematical morphology; scale-space; causal property; generalized zero-crossing; fingerprints; alternating sequential filter	ZERO-CROSSINGS	In this paper, we prove that the scale-space of a one-dimensional gray-scale signal based on morphological filterings satisfies causality (no new feature points are created as scale gets larger). For this we refine the standard definition of zero-crossing so as to allow signals with certain singularity, and use them to define feature points. This new definition of zero-crossing agrees with the standard one in the case of functions with second order derivative. In particular, the scale-space based on the Gaussian kernel G does not need this concept because a filtered signal G * f is always infinitely differentiable. Using this generalized concept of zero-crossing, we show that a morphological filtering based on opening (and, hence, also closing by duality) satisfies causality. We note that some previous works have mistakes which are corrected in this paper. Our causality results do not apply to more general two-dimensional gray scale images. Causality results on alternating sequential filter, obtained as byproduct, are also included.			Park, KR (corresponding author), POHANG UNIV SCI & TECHNOL, DEPT MATH, SAN 31 HYOJA DONG, POHANG 790784, SOUTH KOREA.							BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BANGHAM JA, 1994, P SOC PHOTO-OPT INS, V2180, P90, DOI 10.1117/12.172560; BANGHAM JA, 1993, P IEEE WORKSH NONL S; CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; HARALICK RM, 1989, IEEE T ACOUST SPEECH, V37, P2067, DOI 10.1109/29.45553; JACKWAY PT, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P252, DOI 10.1109/ICPR.1992.201973; JACKWAY PT, 1995, THESIS QUEENSLAND U; JANG BK, 1991, P 25 ANN C INF SCI S, P1; NACKEN PFM, 1994, IEEE T PATTERN ANAL, V16, P656, DOI 10.1109/34.295918; PARK KR, 1994, INT C PATT RECOG, P159, DOI 10.1109/ICPR.1994.577146; ROCKAFFELAR TR, 1972, COVEX ANAL; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; VANDERBOOMGAARD R, 1993, P 1 INT WORKSH MATH; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	16	26	28	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1996	18	11					1121	1126		10.1109/34.544083	http://dx.doi.org/10.1109/34.544083			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VU159					2022-12-18	WOS:A1996VU15900009
J	Li, YH; Lopresti, D; Nagy, G; Tomkins, A				Li, YH; Lopresti, D; Nagy, G; Tomkins, A			Validation of image defect models for optical character recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical character recognition; document image defect models; OCR error classification; defect model validation		In this paper, we consider the problem of evaluating character image generators that model distortions encountered in optical character recognition (OCR). While a number of such defect models have been proposed, the contention that they produce the desired result is typically argued in an ad hoc and informal way. We introduce a rigorous and more pragmatic definition of when a model is accurate: we say a defect model is validated if the OCR errors induced by the model are indistinguishable from the errors encountered when using real scanned documents. We describe four measures to quantify this similarity, and compare and contrast them using over ten million scanned and synthesized characters in three fonts. The measures differentiate effectively between different fonts and different scans of the same font regardless of the underlying text.	MATSUSHITA INFORMAT TECHNOL LAB, PRINCETON, NJ 08540 USA; RENSSELAER POLYTECH INST, TROY, NY 12180 USA; CARNEGIE MELLON UNIV, DEPT COMP SCI, PITTSBURGH, PA 15213 USA	Rensselaer Polytechnic Institute; Carnegie Mellon University	Li, YH (corresponding author), GARI SOFTWARE, 293 EISENHOWER PKWY, SUITE 250, LIVINGSTON, NJ 07039 USA.			Nagy, George/0000-0002-0521-1443				Baird H. S., 1993, Proceedings. Second Annual Symposium on Document Analysis and Information Retrieval, P1; Baird H. S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P62, DOI 10.1109/ICDAR.1993.395781; Baird H. S., 1991, P 1 INT C DOC AN REC, P332; Baird HS., 1992, STRUCTURED DOCUMENT, P546, DOI [10.1007/978-3-642-77281-8_26, DOI 10.1007/978-3-642-77281-8_26]; BRADFORD R, 1991, P DOE INF C OAK RIDG; BUCHMAN M, 1993, P DIMUND WORK PAG DE; Devijver PA, 1982, PATTERN RECOGNITION; ESAKOV J, 1994, P 3 ANN S DOC AN INF, P401; HARALICK RM, 1993, P S DOC AN INF RET L, P65; Harman D., 1992, INFORMATION RETRIEVA, P363; HULL JJ, 1993, P S DOC AN INF RET L; Ishii K., 1990, Systems and Computers in Japan, V21, P35, DOI 10.1002/scj.4690210904; JENKINS F, 1993, USING IDEAL IMAGES E; Kanungo T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P730, DOI 10.1109/ICDAR.1993.395633; Kanungo T., 1994, Proceedings of IAPR Workshop on Machine Vision Applications, P552; Khoubyari S., 1993, Proceedings. Second Annual Symposium on Document Analysis and Information Retrieval, P217; LI Y, 1994, 6993R MATS INF TECHN; LI Y, 1994, P 3 ANN S DOC AN INF, P137; LOPRESTI D, 1995, IN PRESS P INT C DOC; NAGY G, 1994, P 3 ANN S DOC AN INF, P127; NAGY G, 1968, IEEE REG 3 CONV REC; PARIZEAU M, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P308, DOI 10.1109/ICPR.1992.201779; Pavlidis T., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P303; Rice S. V., 1993, 1993 ANN RES REPORT, P9; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WANG QR, 1983, IEEE T PATTERN ANAL, V5, P83; WILKINSON R, 1992, 1 CENS OPT CHAR REC	27	26	60	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1996	18	2					99	108		10.1109/34.481536	http://dx.doi.org/10.1109/34.481536			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TV669					2022-12-18	WOS:A1996TV66900002
J	McLauchlan, PF; Murray, DW				McLauchlan, PF; Murray, DW			Active camera calibration for a head-eye platform using the variable state-dimension filter	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						camera calibration; active vision; real-time vision; recursive filter	MOTION; STEREO	This correspondence presents a new technique for calibrating a camera mounted on a controllable head/eye platform. It uses the trajectories of an arbitrary number of tracked corner features to improve the calibration parameter estimates over time, utilizing a novel variable state dimension form of recursive filter. No special visual stimuli are required and no assumptions are made about the structure of the scene, other than that it is stationary relative to the head. The algorithm runs at 4 frames per second on a single Inmos T805 transputer, and is fully integrated into a real-time active vision system. Updated calibration parameters are regularly passed to the Vision modules that require them. Although the algorithm requires an initial estimate of camera focal length, results are presented from real experiments demonstrating that convergence is achieved for initial errors up to 50%.			McLauchlan, PF (corresponding author), UNIV OXFORD, DEPT ENGN SCI, PARKS RD, OXFORD OX1 3PJ, ENGLAND.							ARMSTRONG M, 1994, 5TH P BRIT MACH VIS, P509; Bar-Shalom Y., 1988, TRACKING DATA ASS; BEARDSLEY PA, 1992, THESIS U OXFORD; BROOKS RA, 1987, 4TH P INT S ROB RES; CIPOLLA R, 1992, INT J COMPUT VISION, V8, P53, DOI 10.1007/BF00126400; DU F, 1993, P IEEE C COMPUTER VI; Faugeras O. D., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P15; FAUGERAS OD, 1992, 2 EUR C COMP VIS ECC, P563; HARRIS CG, 1987, 3RD P ALV VIS C, P233; Hartley R. I., 1994, 3 EUR C COMP VIS ECC, V1, P471; HIPPISLEYCOX SD, 1994, 5TH P BRIT MACH VIS, P771; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781; MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171; Maybeck P. S., 1982, STOCHASTIC MODELS ES; MCLAUCHLAN PF, 1994, 3RD P EUR C COMP VIS, V1, P217; Murray D. W., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P403, DOI 10.1109/ICCV.1993.378187; MURRAY DW, 1995, INT J COMPUT VISION, V16, P205, DOI 10.1007/BF01539627; POLLARD SB, 1989, INT J ROBOT RES, V8, P3, DOI 10.1177/027836498900800401; REID ID, 1996, IN PRESS INT J COMPU; ROTHWELL CA, 1991, 2ND P BRIT MACH VIS; SHARKEY PM, 1993, MECHATRONICS, V3, P517, DOI 10.1016/0957-4158(93)90021-S; THACKER NA, 1992, 3RD P BRIT MACH VIS; TRIVEDI HP, 1987, IMAGE VISION COMPUT, V5, P181, DOI 10.1016/0262-8856(87)90047-3; WANG H, 1991, P BARNAIMAGE 91 BARC	25	26	26	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					15	22		10.1109/34.476007	http://dx.doi.org/10.1109/34.476007			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500002
J	KUMAR, A; BARSHALOM, Y; ORON, E				KUMAR, A; BARSHALOM, Y; ORON, E			PRECISION TRACKING BASED ON SEGMENTATION WITH OPTIMAL LAYERING FOR IMAGING SENSORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						IMAGE TRACKING; SEGMENTATION; CLUSTERING; IMAGING SENSORS; PROBABILISTIC DATA ASSOCIATION; OPTIMAL LAYERING; CENTROID ESTIMATION		In our previous work [5], we presented a method for precision tracking of a low observable target based on data obtained from imaging sensors. The image was divided into several layers of gray level intensities and thresholded. A binary image was obtained and grouped into clusters using image segmentation techniques. Using the centroid measurements of the clusters, the Probabilistic Data Association Filter (PDAF) was employed for tracking the target centroid. In this correspondence, the division of the image into several layers of gray level intensities is optimized by minimizing the Bayes risk. This optimal layering of the image has the following properties: 1) following the segmentation, a closed-form analytical expression is obtained for the noise variance of the centroid measurement based on a single frame; 2) in comparison to [5], the measurement noise variance is smaller by at least a factor of 2, thus improving the performance of the tracker. The usefulness of the method for practical applications is demonstrated by considering a sequence of real target images (a moving car) of about 20 pixels in size in a noisy urban environment where the measurement noise was calculated as having 0.32 pixel RMS value. Filtering with the PDAF further reduces this by a factor of 1.6.	IAI,ASHDOD,ISRAEL		KUMAR, A (corresponding author), UNIV CONNECTICUT,STORRS,CT 06269, USA.							Bar-Shalom Y., 1995, MULTITARGET MULTISEN; BARSHALOM Y, 1989, IEEE T AERO ELEC SYS, V25, P863, DOI 10.1109/7.40726; BARSHALOM Y, 1993, IMDAT IMAGE DATA ASS; KUMAR A, 1994, DIMACS WORKSHOP P; ORON E, 1993, IEEE T AERO ELEC SYS, V29, P977, DOI 10.1109/7.220944; VANRHEEDEN DR, 1988, IEEE T AEROSPACE ELE, V24; ZUPAN J, 1973, CLUSTERING LARGE DAT	7	26	26	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					182	188		10.1109/34.368171	http://dx.doi.org/10.1109/34.368171			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825					2022-12-18	WOS:A1995QE82500007
J	BOZMA, HI; DUNCAN, JS				BOZMA, HI; DUNCAN, JS			A GAME-THEORETIC APPROACH TO INTEGRATION OF MODULES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						INTEGRATION; FUSION; GAME-THEORY; IMAGE ANALYSIS; MULTIOBJECTIVE DECISION MAKING		This paper offers a new approach to integration of modules in an intelligent sensor system. Such a system requires that a set of modules-each doing a smaller portion of the overall task-be integrated within a unifying framework. From the perspective of computational systems, this problem holds a considerable interest because it is characterized by a set of coexisting mathematical objectives that need to be optimized simultaneously. In this sense, the design considerations necessitate the introduction of problem solving with multiple objectives. This paper explores these issues in the instance when each module is associated with a mathematical objective that is a function of the outputs of other modules. The integration problem is formulated and what is required of a good solution is presented. This examination interprets the decentralized mediation of conflicting subgoals as promoting a N-player game amongst the modules to be integrated and proposes a game-theoretic integration framework. We model the interaction among the modules as a noncooperative game and argue that this strategy leads to a framework in which the solutions correspond to a compromise decision. The rich mathematical literature greatly enhances our ability to examine issues of convergence, and based on this theory we present some analytical results on computation of equilibria. The application of this framework in image analysis motivates the hope that a framework such as game-theoretic integration will facilitate the development of general design principles for ''modular'' systems.	YALE UNIV,DEPT DIAGNOST RADIOL,NEW HAVEN,CT 06520; YALE UNIV,DEPT ELECT ENGN,NEW HAVEN,CT 06520	Yale University; Yale University	BOZMA, HI (corresponding author), BOGAZICI UNIV,DEPT ELECT & ELECTR ENGN,BEBEK 80815,TURKEY.		Bozma, Huriye Isil/A-2348-2017					ABOTT AL, 1990, P INT C COMPUTER VIS, P489; ALLEN PK, 1987, ROBOTIC OBJECT RECOG; ALOIMONOS JY, 1989, P IMAGE UNDERSTANDIN; Ballard D.H., 1982, COMPUTER VISION; Basar T., 1999, DYNAMIC NONCOOPERATI, V2; BELKNAP R, 1986, P IEEE COMP SOC C CV; Berger J.O., 1985, STAT DECISION THEORY, P74; Bertsekas D. P., 1991, AUTOMATICA; BINFORD T, 1982, INT J ROBOTICS RES, V1; BOZMA HI, 1991, THESIS YALE U; BOZMA HL, 1991, P C COMPUTER VISION; BOZMA HL, 1991, P IEEE WORKSHOP ROBO; BROOKS R, 1990, IEEE INT WORKSH INT, P389; DUNCAN JS, 1992, IEEE T PATTERN ANAL, V14, P502, DOI 10.1109/34.134056; ERMAN L, 1980, COMPUTING SURVEYS, V12; GARVEY TD, 1983, IJCAI, P319; Gennert M. A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P87, DOI 10.1109/CCV.1988.589974; Gennert M. A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P139, DOI 10.1109/CCV.1988.589984; GRIMSON WEL, 1987, INT J ROBOTICS RES; HACKETT JK, 1990, SPIE SENSOR FUSION 3, V1383, P611; Hanson A., 1978, COMPUTER VISION SYST; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; HORN BKP, 1989, P IMAGE UNDERSTANDIN, P584; LAUGIER TFG, 1991, IEEE T ROBOTIC AUTOM, P432; LI S, 1987, AUTOMATICA, V23, P523, DOI 10.1016/0005-1098(87)90081-1; Luenberger D.G, 2016, LINEAR NONLINEAR PRO, DOI 10.1007/978-3-319-18842-3; LUO RC, 1989, IEEE T SYST MAN CYB, V19, P901, DOI 10.1109/21.44007; LUO RC, 1987, IEEE P INT C ROBOTIC, P1941; MAHMOUD MS, 1977, IEEE T SYST MAN CYB, V7, P125, DOI 10.1109/TSMC.1977.4309677; NARENDRA KS, 1985, 4TH P YEAR WORKSH AP, P105; NASH J, 1951, ANN MATH, V54; PARENT P, 1989, IEEE T PATTERN ANAL, V11; PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12; Pratt W. K., 1978, DIGITAL IMAGE PROCES; ROBERTS KS, 1990, 1990 P IEEE INT C RO, P1252; SMITH RG, 1981, IEEE T SYST MAN CYB, V11, P61, DOI 10.1109/TSMC.1981.4308579; STARR MK, 1977, MULTIPLE CRITERIA DE; ZADEH LA, 1963, IEEE T AUTO CONT JAN, P59; Zucker S. W., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P568, DOI 10.1109/CCV.1988.590037; ZUCKER SW, 1987, COMPUTER VISION SYST	41	26	28	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1994	16	11					1074	1086		10.1109/34.334387	http://dx.doi.org/10.1109/34.334387			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PW081					2022-12-18	WOS:A1994PW08100002
J	OLIENSIS, J				OLIENSIS, J			LOCAL REPRODUCIBLE SMOOTHING WITHOUT SHRINKAGE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						CONTOURS; CURVE SHRINKAGE; EDGES; FOURIER REPRESENTATION; LINES; MATCHING; SCALE SPACE; SHAPE DESCRIPTION; SMOOTHING	CURVES	A simple local smoothing filter is defined for curves or surfaces, combining the advantages of Gaussian smoothing and Fourier curve description. Unlike Gaussian filters, the filter described here has no shrinkage problem. Repeated application of the filter does not yield a curve or surface smaller than the original but simply reproduces the approximate result that would have been obtained by a single application at the largest scale. Unlike Fourier description, the filter is local in space. The wavelet transform of Meyer [7] is also shown to have these properties.			OLIENSIS, J (corresponding author), UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,AMHERST,MA 01003, USA.		Rohlf, F J/A-8710-2008					BATTLE G, 1987, COMMUN MATH PHYS, V110, P601, DOI 10.1007/BF01205550; CHELLAPPA R, 1982, P C PATT RECOGN IMAG; HORN BKP, 1986, IEEE T PATTERN ANAL, V8, P665, DOI 10.1109/TPAMI.1986.4767839; LEMMAIRIE PG, 1988, J MATH PURE APPL, V67, P227; LOWE DG, 1989, INT J COMPUT VISION, V3, P119, DOI 10.1007/BF00126428; MALLAT SG, 1989, T AM MATH SOC, V315, P69, DOI 10.2307/2001373; MARIMONT DH, 1984, 4TH P NAT C ART INT, P237; Meyer Y., 1989, LONDON MATH SOC LECT, V137; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; SZELISKI R, 1989, BAYESIAN MODELING UN; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	14	26	33	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					307	312		10.1109/34.204914	http://dx.doi.org/10.1109/34.204914			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800013
J	ULUPINAR, F; NEVATIA, R				ULUPINAR, F; NEVATIA, R			PERCEPTION OF 3-D SURFACES FROM 2-D CONTOURS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SHAPE FROM CONTOUR; SYMMETRY ANALYSIS; ZERO GAUSSIAN CURVATURE SURFACES	SHAPE; REPRESENTATION	Inference of 3-D shape from 2-D contours in a single image is an important problem in machine vision, We survey classes of techniques proposed in the past and provide a critical analysis. We propose that two kinds of symmetries in figures, which are known as parallel and skew symmetries, give significant information about surface shape for a variety of objects. We derive the constraints imposed by these symmetries and show how to use them to infer 3-D shape. We discuss the zero Gaussian curvature (ZGC) surfaces in depth and show results on the recovery of surface orientation for various ZGC surfaces.	UNIV SO CALIF,SCH ENGN,INST ROBOT & INTELLIGENT SYST,LOS ANGELES,CA 90089	University of Southern California	ULUPINAR, F (corresponding author), BILKENT UNIV,FAC COMP ENGN,DEPT COMP ENGN,ANKARA,TURKEY.							BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BEIDERMAN I, 1987, PSYCHOL REV, V94, P115; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; HORAUD R, 1988, ARTIF INTELL, V37, P333, DOI 10.1016/0004-3702(88)90059-8; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; Kanade T., 1983, HUMAN MACHINE VISION, P237; KASHIPATI R, 1988, THESIS U SO CALIFORN; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; Lipschutz M., 1969, DIFFERENTIAL GEOMETR; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; MEDIONI G, 1987, COMPUT VISION GRAPH, V39, P267, DOI 10.1016/S0734-189X(87)80181-0; MOHAN R, 1989, 1989 P COMP VIS PATT, P333; NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; PONCE J, 1988, P IMAGE UNDERSTANDIN, P1074; SHAFER SA, 1983, COMPUT VISION GRAPH, V24, P182, DOI 10.1016/0734-189X(83)90042-7; STEVENS KA, 1981, ARTIF INTELL, V17, P47, DOI 10.1016/0004-3702(81)90020-5; Ulupinar F., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P414, DOI 10.1109/CCV.1988.590018; ULUPINAR F, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P582; ULUPINAR F, 1991, COMPUT VISION GRAPH, V52, P674; ULUPINAR F, 1991, IRIS278 U SO CAL REP; ULUPINAR F, 1990, 10TH P INT C PATT RE, P147; WEISS I, 1988, COMPUT VISION GRAPH, V41, P80, DOI 10.1016/0734-189X(88)90118-1; XU G, 1987, 1ST P ICCV LOND, P716	27	26	27	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1993	15	1					3	18		10.1109/34.184771	http://dx.doi.org/10.1109/34.184771			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	KH085		Green Submitted			2022-12-18	WOS:A1993KH08500001
J	JENQ, JF; SAHNI, S				JENQ, JF; SAHNI, S			SERIAL AND PARALLEL ALGORITHMS FOR THE MEDIAL AXIS TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						HYPERCUBE ALGORITHMS; IMAGE PROCESSING; MEDIAL AXIS TRANSFORM; SERIAL AND PARALLEL ALGORITHMS	GEOMETRIC-PROPERTIES; COMPUTATION	We develop an O(n2) time serial algorithm to obtain the medial axis transform (MAT) of an n x n image. An O(log n) time CREW PRAM algorithm and an O(log2 n) time SIMD hypercube parallel algorithm for the MAT are also developed. Both of these use O(n2) processors. Two problems associated with the MAT are also studied. These are the area and perimeter reporting problem. We develop an O(log n) time hypercube algorithm for both of these problems. Here, n is the number of squares in the MAT, and the algorithms use O(n2) processors.	UNIV FLORIDA,DEPT COMP & INFORMAT SCI,GAINESVILLE,FL 32611	State University System of Florida; University of Florida	JENQ, JF (corresponding author), TENNESSEE STATE UNIV,DEPT PHYS MATH & COMP SCI,NASHVILLE,TN 37209, USA.		Sahni, Sartaj K/A-7691-2009					Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; CHANDRAN S, 1987 P IEEE WORKSH C, P44; CHANDRAN S, IN PRESS ALGORITHMIC; Garey M.R., 1979, COMPUTERS INTRACTABI; GUTING RH, 1984, J ALGORITHM, V5, P303; JAVIS P, THESIS U MINNESOTA S; KRUSKAL CP, 1985, 1985 P INT C PAR PRO, P180; LEE DT, 1982, IEEE T PATTERN ANAL, V4, P363, DOI 10.1109/TPAMI.1982.4767267; LU M, 1988, J PARALLEL DISTR COM, V5, P154, DOI 10.1016/0743-7315(88)90026-3; NASSIMI D, 1981, IEEE T COMPUT, V30, P101, DOI 10.1109/TC.1981.6312172; NASSIMI D, 1982, IEEE T COMPUT, V31, P338, DOI 10.1109/TC.1982.1676004; Rosenfeld A., 1982, DIGITAL PICTURE PROC; VO K, 1982, J ALGORITHMS, V4, P366; WOOD D, 1984, INFORM PROCESSING LE, V17, P229; WU AY, 1986, COMPUT VISION GRAPH, V34, P76, DOI 10.1016/0734-189X(86)90049-6; WU AY, 1988, COMPUT VISION GRAPH, V41, P323, DOI 10.1016/0734-189X(88)90106-5; [No title captured]	17	26	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1992	14	12					1218	1224		10.1109/34.177389	http://dx.doi.org/10.1109/34.177389			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KC573					2022-12-18	WOS:A1992KC57300010
J	MAITRE, H; LUO, W				MAITRE, H; LUO, W			USING MODELS TO IMPROVE STEREO RECONSTRUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						COOPERATION BETWEEN PHOTOMETRY AND STEREO; STEREOVISION; 3-D MODELS	VISUAL SURFACE RECONSTRUCTION; DISPARITY GRADIENT LIMIT; ALGORITHM	We propose the collaboration of photometric and stereometric information to solve the stereo vision problem in the case of man-made environment. The proposed method improves a) the accuracy of the stereo information and b) its density by introducing a hypothesis on the object surfaces. Two kinds of hypotheses have been developed here: planar and quadratic objects. Reconstructions of complex scenes are given.			MAITRE, H (corresponding author), TELECOM PARIS,DEPT IMAGES,PARIS,FRANCE.							BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BURT P, 1980, SCIENCE, V208, P615, DOI 10.1126/science.7367885; Castan S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P444; EASTMAN RD, 1987, COMPUT VISION GRAPH, V39, P73, DOI 10.1016/S0734-189X(87)80203-7; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FOERSTNER W, 1986, PATT RECOGN PRACTICE, P57; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; GRIMSON WEL, 1981, IMAGES SURFACES; GRUEN AW, 1986, AUG P ISPRS COMM, V3, P284; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; HSIEH YC, 1990, 10TH P ICPR ATL CIT, P136; KIM NH, 1988, PATTERN RECOGN, V21, P505, DOI 10.1016/0031-3203(88)90009-X; LUO W, 1990, P SOC PHOTO-OPT INS, V1395, P518; LUO W, 1990, 10TH P ICPR ATL CIT, P60; MARR D, 1976, SCIENCE, V194, P238; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P113, DOI 10.1109/34.16708; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; SUK M, 1983, PATTERN RECOGN, V16, P469, DOI 10.1016/0031-3203(83)90051-1; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; WROBEL BP, 1988, P ISPRS COMMISSION, V3, P806; WU YF, 1989, 12TH P GRETSI JUAN L	24	26	30	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					269	277		10.1109/34.121794	http://dx.doi.org/10.1109/34.121794			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900013
J	MEER, P; SHER, CA; ROSENFELD, A				MEER, P; SHER, CA; ROSENFELD, A			THE CHAIN PYRAMID - HIERARCHICAL CONTOUR PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MEER, P (corresponding author), UNIV MARYLAND,AUTOMAT RES CTR,COLLEGE PK,MD 20742, USA.							AGI I, 1988, APR P IEEE INT C AC, P1969; [Anonymous], [No title captured]; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; CHEN BD, 1987, IEEE T PATTERN ANAL, V9, P438, DOI 10.1109/TPAMI.1987.4767925; CHIN RT, 1987, COMPUT VISION GRAPH, V40, P30, DOI 10.1016/0734-189X(87)90054-5; DARWISH AM, 1988, IEEE T PATTERN ANAL, V10, P56, DOI 10.1109/34.3867; DINSTEIN I, 1985, IEEE T PATTERN ANAL, V7, P116, DOI 10.1109/TPAMI.1985.4767627; EDELMAN S, 1987, COMPUT VISION GRAPH, V24, P169; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; FUA P, 1987, FEB P IM UND WORKSH, P227; HARTMANN G, 1987, BIOL CYBERN, V57, P73, DOI 10.1007/BF00318717; HONG TH, 1983, IEEE T SYST MAN CYB, V13, P631, DOI 10.1109/TSMC.1983.6313152; KOPLOWITZ J, 1987, IEEE T PATTERN ANAL, V9, P451, DOI 10.1109/TPAMI.1987.4767927; KROPATSCH WG, 1988, PATTERN RECOGN LETT, V6, P179; MAHONEY JV, 1987, MIT AITR980 ART INT; MEER P, 1988, PATTERN RECOGN LETT, V8, P229, DOI 10.1016/0167-8655(88)90030-X; MEER P, 1989, COMPUT VISION GRAPH, V45, P269, DOI 10.1016/0734-189X(89)90084-4; MILLER R, 1987, SIAM J COMPUT, V16, P38, DOI 10.1137/0216004; MINAMI T, 1986, IEEE T PATTERN ANAL, V8, P269, DOI 10.1109/TPAMI.1986.4767780; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; OGORMAN L, 1988, APR P IEEE INT C AC, P792; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; RICHARDS W, 1986, J OPT SOC AM A, V3, P1483, DOI 10.1364/JOSAA.3.001483; Rosenfeld A., 1987, INT J PATTERN RECOGN, V1, P71; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; TEH CH, 1988, JUN P INT C COMP VIS, P229; TREISMAN A, 1985, COMPUT VISION GRAPH, V31, P156, DOI 10.1016/S0734-189X(85)80004-9; TUOMENOKSA DL, 1983, 1983 IEEE COMP SOC S, P336; ULLMAN S, 1984, COGNITION, V18, P97, DOI 10.1016/0010-0277(84)90023-4; [No title captured]	33	26	28	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1990	12	4					363	376		10.1109/34.50622	http://dx.doi.org/10.1109/34.50622			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CV929					2022-12-18	WOS:A1990CV92900003
J	FISHER, AL; HIGHNAM, PT				FISHER, AL; HIGHNAM, PT			COMPUTING THE HOUGH TRANSFORM ON A SCAN LINE ARRAY PROCESSOR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											FISHER, AL (corresponding author), CARNEGIE MELLON UNIV,DEPT COMP SCI,PITTSBURGH,PA 15213, USA.							BARINGER WB, 1987, OCT P IEEE COMP SOC, P88; BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025; CHUANG HYH, 1985, P IEEE COMPUT SOC WO, P300; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Fisher A. L., 1986, 13th Annual International Symposium on Computer Architecture (Cat. No.86CH2291-3), P338; FISHER AL, 1985, NOV P IEEE WORKSH CO, P484; FISHER AL, 1988, P INT C PARALLEL P; FOUNTAIN TJ, 1988, IEEE T PATTERN ANAL, V10, P310, DOI 10.1109/34.3896; Guerra C., 1987, Proceedings of the 1987 Workshop on Computer Architecture for Pattern Analysis and Machine Intelligence: CAPAMI '87 (Cat. No.TH0203-0), P99; HANAHARA K, 1986, APR IEEE INT C ROB A, P1954; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; KUNG HT, 1985, OCT P INT C  COMP DE, P165; LITTLE JJ, 1987, FEB P DARPA IM UND W, P628; PETKOVIC D, 1985, NOV P IEEE COMP SOC, P320; SANZ JLC, 1987, IEEE T PATTERN ANAL, V9, P160, DOI 10.1109/TPAMI.1987.4767883; SILBERBERG TM, 1985, NOV IEEE C COMP ARCH, P387; WALLACE RS, 1985, JUN P IEEE COMP SOC, P665; WALLACE RS, 1987, OCT P IEEE COMP SOC, P209	18	26	56	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					262	265		10.1109/34.21795	http://dx.doi.org/10.1109/34.21795			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840					2022-12-18	WOS:A1989T384000006
J	SAUND, E				SAUND, E			DIMENSIONALITY-REDUCTION USING CONNECTIONIST NETWORKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)	SAUND, E (corresponding author), MIT,DEPT BRAIN & COGNIT SCI,CAMBRIDGE,MA 02139, USA.							ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; BALLARD DH, 1986, BEHAV BRAIN SCI, V9, P67, DOI 10.1017/S0140525X00021555; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; Hanson S.J., 1987, KNOWLEDGE REPRESENTA; HINTON GE, 1984, CMUCS84119 CARN MELL; HOPFIELD JJ, 1985, BIOL CYBERN; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KITTLER J, 1973, PATTERN RECOGN, V5, P335, DOI 10.1016/0031-3203(73)90025-3; KOCH C, 1985, MIT AI751 MEM; Kohonen Teuvo, 1984, SELF ORG ASS MEMORY; KRISHNAIAH, 1982, HDB STATISTICS, V2; Minsky M., 1969, PERCEPTRONS; ROSENBERG CR, 1987, 9TH P ANN C COGN SCI, P537; Rosenblatt F., 1961, PRINCIPLES NEURODYNA, DOI 10.21236/AD0256582; RUMELHART D, 1985, ICS8506 UCSD I COGN; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SAUND E, 1986, 5TH P NAT C ART INT, P638; TOU J, 1967, COMPUTER INFORMATION, V2; WALTERS D, 1987, 9TH ANN C COGN SCI S, P265; WATANABE S, 1965, 4TH T PRAG C INF THE	21	26	26	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					304	314		10.1109/34.21799	http://dx.doi.org/10.1109/34.21799			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840		Green Submitted			2022-12-18	WOS:A1989T384000010
J	LEE, D; PAVLIDIS, T				LEE, D; PAVLIDIS, T			ONE-DIMENSIONAL REGULARIZATION WITH DISCONTINUITIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SUNY STONY BROOK,DEPT COMP SCI,STONY BROOK,NY 11794	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	LEE, D (corresponding author), AT&T BELL LABS,TECH STAFF,MURRAY HILL,NJ 07974, USA.							Ahlberg J.H., 1967, THEORY SPLINES THEIR; BLAKE A, 1986, JUN P IEEE COMP VIS, P62; BLAKE A, 1986, JUN P IEEE COMP VIS, P656; CRAVEN P, 1977, TR445 U WISC DEP STA; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; FORSYTHE GE, 1967, COMPUTER SOLUTIONS L; Gelfand I. M., 1963, CALCULUS VARIATION; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; GRIMSON WEL, 1981, IMAGES SURFACES COMP; HILDRETH E, 1983, MEASUREMENT VISUAL M; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Lee D., 1985, Journal of Complexity, V1, P138, DOI 10.1016/0885-064X(85)90025-1; LEE D, 1986, J COMPLEXITY, V1, P295; MUMFORD D, 1985, JUN P IEEE COMP VIS, P22; POGGIO T, 1985, COMPUT VISION GRAPH, V31, P139, DOI 10.1016/S0734-189X(85)80003-7; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; REINSCH CH, 1967, NUMER MATH, V10, P177, DOI 10.1007/BF02162161; SCHOENBERG IJ, 1964, P NATL ACAD SCI USA, V52, P947, DOI 10.1073/pnas.52.4.947; Schumaker LL, 1976, APPROXIMATION THEORY, VII, P203; SHAHRARAY B, 1986, JUN P IEEE COMP SOC, P210; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1984, THESIS MIT CAMBRIDGE; Tikhonov A.N., 1977, SOLUTION ILL POSED P, V54, P266, DOI 10.1137/1021044; UTRERAS D, 1979, SMOOTHING TECHNIQUES, P196; WAHBA G, 1984, ROCKY MT J MATH, V14, P281, DOI 10.1216/RMJ-1984-14-1-281; Wahba G, 1979, SMOOTHING TECHNIQUES, P233; Whittaker E.T., 1922, P EDINBURGH MATH SOC, V41, P63, DOI [10.1017/S0013091500077853, DOI 10.1017/S0013091500077853]	28	26	27	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					822	829		10.1109/34.9105	http://dx.doi.org/10.1109/34.9105			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100005
J	SLOAN, KR; PAINTER, J				SLOAN, KR; PAINTER, J			PESSIMAL GUESSES MAY BE OPTIMAL - A COUNTERINTUITIVE SEARCH RESULT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SLOAN, KR (corresponding author), UNIV WASHINGTON,DEPT COMP SCI,SEATTLE,WA 98195, USA.							BOISSONNAT JD, P IJCAI 81, P658; CHRISTIANSEN HN, 1978, COMPUT GRAPHICS, V13; COOK LT, 1983, IEEE COMPUT GRAPH, V3, P13, DOI 10.1109/MCG.1983.263180; COOK LT, 1980, IEEE T BIOMED ENG, V27; CURCIO CA, 1981, J NEUROSCIENCE METHO, V4; FUCHS H, 1977, COMMUN ACM, V20, P693, DOI 10.1145/359842.359846; GANAPATHY S, 1982, COMPUT GRAPHICS, V16; KEPPEL E, 1975, IBM J RES DEV, V19; OROURKE J, 1981, AUG P IJCAI 81, P664; SHANI U, 1980, THESIS U ROCHESTER; SLOAN KR, 1987, APR P CHI PLUS GI 87, P115; SLOAN KR, 1981, AUG P PATT REC IM PR; WANG YF, 1985, JUN P COMP VIS PATT	13	26	29	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					949	955		10.1109/34.9117	http://dx.doi.org/10.1109/34.9117			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100017
J	BERGADANO, F; GIORDANA, A; SAITTA, L				BERGADANO, F; GIORDANA, A; SAITTA, L			AUTOMATED CONCEPT-ACQUISITION IN NOISY ENVIRONMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BERGADANO, F (corresponding author), UNIV TORINO,DIPARTIMENTO INFORMAT,CORSO SVIZZERA 185,I-10149 TORINO,ITALY.		bergadano, francesco/Q-2879-2019	BERGADANO, Francesco/0000-0003-2567-336X				[Anonymous], 1983, P MACHINE LEARNING; Arbab B, 1985, P IJCAI 85 LOS ANGEL, P631; BENBASSAT M, 1984, IEEE T PATTERN ANAL, V6, P201, DOI 10.1109/TPAMI.1984.4767503; BERGADANO F, 1986, FUZZY LOGIC KNOWLEDG, P127; BERGADANO F, 1987, INT J PATTERN RECOGN, V1, P189; Binford T. O., 1982, INT J ROBOT RES, V1, P18; BIRMAN KP, 1982, IEEE T PATTERN ANAL, V4, P369, DOI 10.1109/TPAMI.1982.4767268; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; BUCHANAN BG, 1978, PATTERN DIRECTED INF, P297; DEMORI R, INFORM SCI, V33, P115; ERMAN LD, 1980, COMPUT SURV, V12, P213, DOI 10.1145/356810.356816; FEIGENBAUM EA, 1978, PATTERN DIRECTED INF, P483; FU KS, 1982, SYNTACTIC PATTERN RE; HAYESROTH F, 1978, COMMUN ACM, V21, P401, DOI 10.1145/359488.359503; Kim J. H., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P170; KOPEE GE, 1982, TRENDS PERSPECTIVES; Lee H. S., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P624; LEMERLELOISEL R, 1981, P IJCAI 7 VANCOUVER, P141; LESMO L, 1985, INT J MAN MACH STUD, V22, P307, DOI 10.1016/S0020-7373(85)80006-7; LOVE PL, 1984, IEEE WORKSHOP APPLIC; MCKEOWN DM, 1985, IEEE T PATTERN ANAL, V7, P570, DOI 10.1109/TPAMI.1985.4767704; MICHALSKI R, 1986, P INT M ADV LEARNING; Michalski R. S., 1980, International Journal of Policy Analysis and Information Systems, V4, P125; Michalski R.S., 1983, MACHINE LEARNING ART, DOI [10.1007/978-3-662-12405-5, DOI 10.1007/978-3-662-12405-5]; Michalski R. S, 1983, MACHINE LEARNING; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349, DOI 10.1109/TPAMI.1980.4767034; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; MOSTOW DJ, 1978, PATTERN DIRECTED INF, P471; NANDHAKUMAR N, 1985, PATTERN RECOGN, V18, P383, DOI 10.1016/0031-3203(85)90009-3; NAZIF AM, 1984, IEEE T PATTERN ANAL, V6, P555, DOI 10.1109/TPAMI.1984.4767570; OKEEFE RA, 1983, P IJCAI 8 KARLSRUHE, P479; PHELPS RI, 1985, P IJCAI 9 LOS ANGELE, P698; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; RADA R, 1985, IEEE T PATTERN ANAL, V7, P523, DOI 10.1109/TPAMI.1985.4767700; Rendell L., 1986, Machine Learning, V1, P177, DOI 10.1007/BF00114117; RENDELL LA, 1983, AI J, V4, P369; Riseman E. M., 1984, Proceedings of the IEEE Workshop on Principles of Knowledge-Based Systems (Cat. No. 84CH2104-8), P159; SAMUEL AL, 1963, COMPUT THOUGHT, P71; Schaffer JD., 1985, P 9 INT JOINT C ART, V85, P593; SEGEN J, 1985, P IJCAI 9 LOS ANGELE, P634; SHEPHERD BA, 1983, P IJCAI 8 KARLSRUHE, P474; SIMON HA, 1983, MACHINE LEARNING ART, P25; Sturt E., 1981, Applied Statistics, V30, P213, DOI 10.2307/2346344; TSOTSOS JK, 1982, 6TH P INT JOINT C PA, P654; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Valiant LG, 1985, P 9 INT JOINT C ART, P560; VERE S, 1975, 4TH P INT JOINT C AR, P351; VERE SA, 1980, ARTIF INTELL, V14, P139, DOI 10.1016/0004-3702(80)90038-7; Watanabe S., 1969, KNOWING GUESSING; WINSTON PH, 1975, PSYCHOL COMPUTER VIS, pCH5; YAGER RR, 1983, INT J MAN MACH STUD, V19, P195, DOI 10.1016/S0020-7373(83)80056-X; ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8; [No title captured]	55	26	26	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1988	10	4					555	578		10.1109/34.3917	http://dx.doi.org/10.1109/34.3917			24	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	P1493					2022-12-18	WOS:A1988P149300010
J	MAITRE, H				MAITRE, H			CONTRIBUTION TO THE PREDICTION OF PERFORMANCES OF THE HOUGH TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MAITRE, H (corresponding author), ECOLE NATL SUPER TELECOMMUN,46 RUE BARRAULT,F-75634 PARIS 13,FRANCE.							ALAGAR VS, 1981, IEEE T PATTERN ANAL, V3, P245, DOI 10.1109/TPAMI.1981.4767097; BROWN CM, 1983, IEEE T PATTERN ANAL, V5, P493, DOI 10.1109/TPAMI.1983.4767428; COHEN M, 1979, PATTERN RECOGNITION, V9, P95; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; IANNINO A, 1979, THESIS STEVENS I TEC; LOPEZKRAHE J, THESIS U PARIS 6; Maitre H., 1985, Traitement du Signal, V2, P305; MAITRE H, 1984, 4EME P C REC FORM IN, P255; MORAVEC HP, 1977, AUG P INT JOINT C AR, P584; ROSENFELD A, 1984, COMPUT VISION GRAPH, V26, P347, DOI 10.1016/0734-189X(84)90218-4; Shapiro S. D., 1975, Computer Graphics and Image Processing, V4, P328, DOI 10.1016/0146-664X(75)90002-7; SHAPIRO SD, 1979, IEEE T PATTERN ANAL, V3, P310; SKLANSKY J, 1978, IEEE T COMPUT, V27, P923, DOI 10.1109/TC.1978.1674971; TIMOUMI R, 1985, THESIS U PARIS 11	14	26	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1986	8	5					669	674		10.1109/TPAMI.1986.4767840	http://dx.doi.org/10.1109/TPAMI.1986.4767840			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	D7584	21869364				2022-12-18	WOS:A1986D758400008
J	HONG, TH; SHNEIER, MO				HONG, TH; SHNEIER, MO			DESCRIBING A ROBOTS WORKSPACE USING A SEQUENCE OF VIEWS FROM A MOVING CAMERA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											HONG, TH (corresponding author), NBS,DIV ROBOT SYST,GAITHERSBURG,MD 20899, USA.							COMBA PG, 1968, J ACM, V15, P354, DOI 10.1145/321466.321468; CONNOLLY CI, 1984, MAR P INT C ROB ATL, P25; FIELD DA, 1982, IEEE COMPUT GRAPH, V2, P65; FIELD DA, 1981, GMR3656 GEN MOT RES; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; MEAGHER D, 1980, TRIPL111 RENSS POL I; PAVLIDIS T, 1982, ALGORITHMS GRAPHICS, pCH15; SRIHARI SN, 1981, COMPUT SURV, V13, P399, DOI 10.1145/356859.356862; UNDERWOOD SA, 1972, TR123 U TEX INF SYST	10	26	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					721	726		10.1109/TPAMI.1985.4767730	http://dx.doi.org/10.1109/TPAMI.1985.4767730			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869312				2022-12-18	WOS:A1985ATG0500012
J	LUNSCHER, WHHJ				LUNSCHER, WHHJ			THE ASYMPTOTIC OPTIMAL FREQUENCY-DOMAIN FILTER FOR EDGE-DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											LUNSCHER, WHHJ (corresponding author), UNIV BRITISH COLUMBIA,DEPT ELECT ENGN,VANCOUVER V6T 1Z2,BC,CANADA.							Flammer C., 1957, SPHEROIDAL WAVE FUNC; JERNIGAN ME, 1981, IEEE T SYST MAN CYB, V11, P441; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; SHANMUGAM KS, 1979, IEEE T PATTERN ANAL, V1, P37, DOI 10.1109/TPAMI.1979.4766874; SLEPIAN D, 1964, BELL SYST TECH J, V43, P3009, DOI 10.1002/j.1538-7305.1964.tb01037.x; SLEPIAN D, 1961, BELL SYST TECH J, V40, P43, DOI 10.1002/j.1538-7305.1961.tb03976.x; SLEPIAN D, 1965, J MATH PHYS CAMB, V44, P99, DOI 10.1002/sapm196544199; STREIFER W, 1968, J MATH PHYS CAMB, V47, P407, DOI 10.1002/sapm1968471407; STREIFER W, 1965, J OPT SOC AM, V55, P868, DOI 10.1364/JOSA.55.000868; STREIFER W, 1965, J OPT SOC AM, V55, P602	10	26	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					678	680		10.1109/TPAMI.1983.4767462	http://dx.doi.org/10.1109/TPAMI.1983.4767462			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869159				2022-12-18	WOS:A1983RV48800019
J	DYER, CR; ROSENFELD, A				DYER, CR; ROSENFELD, A			PARALLEL IMAGE-PROCESSING BY MEMORY-AUGMENTED CELLULAR AUTOMATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,CTR COMP SCI,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								BEYER WT, 1969, TR66 MAC MASS I TECH; Duff M.J.B., 1976, P 3 INT C PATT REC, P728; FUNG L, 1978, 17TH P ACM ANN TECHN, P11; Hopcroft J.E., 1969, FORMAL LANGUAGES THE; HOPCROFT JE, 1967, J COMPUT SYST SCI, V1, P166; KOSARAJU SR, 1979, 11TH P ANN ACM S THE, P231; LEVIALDI S, 1972, COMMUN ACM, V15, P7, DOI 10.1145/361237.361240; PRESTON K, 1979, P IEEE, V67, P826, DOI 10.1109/PROC.1979.11331; Rosenfeld A., 1979, PICTURE LANGUAGES; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SKLANSKY J, 1976, IEEE T COMPUT, V25, P187, DOI 10.1109/TC.1976.5009234; SMITH AR, 1971, 12 ANN S SWITCH AUT, P144; [No title captured]	14	26	26	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					29	41		10.1109/TPAMI.1981.4767048	http://dx.doi.org/10.1109/TPAMI.1981.4767048			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LK116	21868917				2022-12-18	WOS:A1981LK11600004
J	Fan, DP; Ji, GP; Cheng, MM; Shao, L				Fan, Deng-Ping; Ji, Ge-Peng; Cheng, Ming-Ming; Shao, Ling			Concealed Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; Annotations; Task analysis; Image segmentation; Benchmark testing; Animals; Art; Concealed object detection; camouflaged object detection; COD; dataset; benchmark	MODEL; CAMOUFLAGE	We present the first systematic study on concealed object detection (COD), which aims to identify objects that are visually embedded in their background. The high intrinsic similarities between the concealed objects and their background make COD far more challenging than traditional object detection/segmentation. To better understand this task, we collect a large-scale dataset, called COD10K, which consists of 10,000 images covering concealed objects in diverse real-world scenarios from 78 object categories. Further, we provide rich annotations including object categories, object boundaries, challenging attributes, object-level labels, and instance-level annotations. Our COD10K is the largest COD dataset to date, with the richest annotations, which enables comprehensive concealed object understanding and can even be used to help progress several other vision tasks, such as detection, segmentation, classification etc. Motivated by how animals hunt in the wild, we also design a simple but strong baseline for COD, termed the Search Identification Network (SINet). Without any bells and whistles, SINet outperforms twelve cutting-edge baselines on all datasets tested, making them robust, general architectures that could serve as catalysts for future research in COD. Finally, we provide some interesting findings, and highlight several potential applications and future directions. To spark research in this new field, our code, dataset, and online demo are available at our project page: http://mmcheng.net/cod.	[Fan, Deng-Ping; Cheng, Ming-Ming] Nankai Univ, Coll Comp Sci, Tianjin 300071, Peoples R China; [Fan, Deng-Ping; Ji, Ge-Peng; Shao, Ling] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates	Nankai University	Cheng, MM (corresponding author), Nankai Univ, Coll Comp Sci, Tianjin 300071, Peoples R China.	dengpfan@gmail.com; gepengai.ji@gmail.com; cmm@nankai.edu.cn; ling.shao@inceptioniai.org	Fan, Deng-Ping/ABD-4052-2020	Fan, Deng-Ping/0000-0002-5245-7518	National Key Research and Development Program of China [2018AAA0100400]; NSFC [61922046]; S&T Innovation Project from the Chinese Ministry of Education	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); S&T Innovation Project from the Chinese Ministry of Education	The author would like to thank Guolei Sun and Jianbing Shen for insightful feedback. This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0100400, in part by NSFC under Grant 61922046, and in part by S&T Innovation Project from the Chinese Ministry of Education. A preliminary version of this work has appeared in CVPR 2020 [1].	Ali Borji, 2018, Arxiv, DOI arXiv:1803.06091; Andrew Owens, 2020, Arxiv, DOI arXiv:2008.04237; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511; Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15; Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI 10.1007/s11263-021-01490-8; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cheng-Feng Sun, 2020, Learning and Collaboration Technologies. Human and Technology Ecosystems. 7th International Conference, LCT 2020. Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12206), P520, DOI 10.1007/978-3-030-50506-6_35; Chu HK, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778788; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Cott Hugh Bamford, 1940, ADAPTIVE COLORATCOTT; Cuthill IC, 2005, NATURE, V434, P72, DOI 10.1038/nature03312; Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44; Deng J., 2009, P 2009 IEEE C COMP V, P248, DOI DOI 10.1109/CVPR.2009.5206848; Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26; Denton E, 2014, ADV NEUR IN, V27; Dong HW, 2020, IEEE T IND INFORM, V16, P7448, DOI 10.1109/TII.2019.2958826; Enze Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P696, DOI 10.1007/978-3-030-58601-0_41; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan D.-P., 2021, SCI SINICA INFORM, V6, DOI [10.1360/SSI-2020-0370, DOI 10.1360/SSI-2020-0370]; Fan DP, 2021, IEEE T PATTERN ANAL, V44, P4339, DOI 10.1109/TPAMI.2021.3060412; Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285; Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645; Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406; Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875; Fan Q., 2021, IEEE C COMPUT VIS PA; Fu KR, 2022, IEEE T PATTERN ANAL, V44, P5541, DOI 10.1109/TPAMI.2021.3073689; Gao SH, 2021, PROC CVPR IEEE, P8665, DOI 10.1109/CVPR46437.2021.00856; Gao SH, 2021, PROC CVPR IEEE, P16800, DOI 10.1109/CVPR46437.2021.01653; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Hall JR, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.0064; He T, 2019, IEEE ACCESS, V7, P123453, DOI 10.1109/ACCESS.2019.2937461; He Y, 2020, IEEE T INSTRUM MEAS, V69, P1493, DOI 10.1109/TIM.2019.2915404; Fan H, 2020, Arxiv, DOI arXiv:2011.10875; Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688; Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4; Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jaderberg M., 2014, ARXIV14053866; Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975; Kalash M, 2021, IEEE T PATTERN ANAL, V43, P204, DOI 10.1109/TPAMI.2019.2927203; Kalra A., 2020, P IEEE CVF C COMP VI, P8602; Kingma D. P., 2015, 3 INT C LEARN REPR I, P1; Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Lamdouar H., 2020, ASIAN C COMPUT VIS; Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404; Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4; Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326; Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24; Lyu Y., 2021, PROC IEEE C COMPUT V; Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39; Medioni Gerard, 2009, OBJECT CATEGORIZATIO, V87; Mei HY, 2021, PROC CVPR IEEE, P8768, DOI 10.1109/CVPR46437.2021.00866; Mengshuo Wang, 2019, Arxiv, DOI arXiv:1810.13306; Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100; Mondal A, 2020, INT J IMAGE GRAPH, V20, DOI 10.1142/S021946782050028X; Mori G, 2005, IEEE I CONF COMP VIS, P1417; Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534; Owens A, 2014, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2014.350; Paszke A, 2019, ADV NEUR IN, V32; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Qin X.B., 2021, ARXIV; Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Shang-Hua Gao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P702, DOI 10.1007/978-3-030-58539-6_42; Shi F, 2021, IEEE REV BIOMED ENG, V14, P4, DOI 10.1109/RBME.2020.2987975; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Skurowski P, 2018, ANIMAL CAMOUFLAGE AN; Stevens M, 2009, PHILOS T R SOC B, V364, P423, DOI 10.1098/rstb.2008.0217; Szegedy C., 2016, P IEEE C COMP VIS PA, P2818, DOI DOI 10.1109/CVPR.2016.308; Tabernik D, 2020, J INTELL MANUF, V31, P759, DOI 10.1007/s10845-019-01476-x; Thayer GH., 1909, CONCEALING COLORATIO; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; TREISMAN A, 1988, Q J EXP PSYCHOL-A, V40, P201, DOI 10.1080/02724988843000104; Troscianko T, 2009, PHILOS T R SOC B, V364, P449, DOI 10.1098/rstb.2008.0218; Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006; Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099; Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514; Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321; WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774; Wu Zhe, 2019, CVPR, P3907; Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41; Xu YC, 2015, IEEE I CONF COMP VIS, P3442, DOI 10.1109/ICCV.2015.393; Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391; Zeng Y, 2019, IEEE I CONF COMP VIS, P7233, DOI 10.1109/ICCV.2019.00733; Zhai Q, 2021, PROC CVPR IEEE, P12992, DOI 10.1109/CVPR46437.2021.01280; Zhang J, 2022, IEEE T PATTERN ANAL, V44, P5761, DOI 10.1109/TPAMI.2021.3073564; Zhang Q, 2020, IEEE T IMAGE PROCESS, V29, P3321, DOI 10.1109/TIP.2019.2959253; Zhang YK, 2019, PROC CVPR IEEE, P7461, DOI 10.1109/CVPR.2019.00765; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887; Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320; Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009; Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1	109	25	25	45	49	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6024	6042		10.1109/TPAMI.2021.3085766	http://dx.doi.org/10.1109/TPAMI.2021.3085766			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34061739	Green Submitted			2022-12-18	WOS:000853875300016
J	Zhao, K; Han, Q; Zhang, CB; Xu, J; Cheng, MM				Zhao, Kai; Han, Qi; Zhang, Chang-Bin; Xu, Jun; Cheng, Ming-Ming			Deep Hough Transform for Semantic Line Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Transforms; Semantics; Image edge detection; Measurement; Feature extraction; Detectors; Task analysis; Semantic line detection; hough transform; CNN; deep learning	SALIENT OBJECT DETECTION; SEGMENT DETECTOR; DISTANCE	We focus on a fundamental task of detecting meaningful line structures, a.k.a., semantic line, in natural scenes. Many previous methods regard this problem as a special case of object detection and adjust existing object detectors for semantic line detection. However, these methods neglect the inherent characteristics of lines, leading to sub-optimal performance. Lines enjoy much simpler geometric property than complex objects and thus can be compactly parameterized by a few arguments. To better exploit the property of lines, in this paper, we incorporate the classical Hough transform technique into deeply learned representations and propose a one-shot end-to-end learning framework for line detection. By parameterizing lines with slopes and biases, we perform Hough transform to translate deep representations into the parametric domain, in which we perform line detection. Specifically, we aggregate features along candidate lines on the feature map plane and then assign the aggregated features to corresponding locations in the parametric domain. Consequently, the problem of detecting semantic lines in the spatial domain is transformed into spotting individual points in the parametric domain, making the post-processing steps, i.e., non-maximal suppression, more efficient. Furthermore, our method makes it easy to extract contextual line features that are critical for accurate line detection. In addition to the proposed method, we design an evaluation metric to assess the quality of line detection and construct a large scale dataset for the line detection task. Experimental results on our proposed dataset and another public dataset demonstrate the advantages of our method over previous state-of-the-art alternatives. The dataset and source code is available at https://mmcheng.net/dhtline/.	[Zhao, Kai; Han, Qi; Zhang, Chang-Bin; Cheng, Ming-Ming] Nankai Univ, Coll Comp Sci, TKLNDST, Tianjin 300350, Peoples R China; [Xu, Jun] Nankai Univ, Sch Stat & Data Sci, Tianjin 300071, Peoples R China	Nankai University; Nankai University	Cheng, MM (corresponding author), Nankai Univ, Coll Comp Sci, TKLNDST, Tianjin 300350, Peoples R China.	kz@kaizhao.net; hqer@foxmail.com; zhangchbin@mail.nankai.edu.cn; nankaimathxujun@gmail.com; cmm@nankai@edu.cn			National Key Research and Development Program of China [2018AAA0100400]; NSFC [61922046, 61620106008, 62002176]; S&T Innovation Project from Chinese Ministry of Education; Tianjin Natural Science Foundation [17JCJQJC43700]	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); S&T Innovation Project from Chinese Ministry of Education; Tianjin Natural Science Foundation(Natural Science Foundation of Tianjin)	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0100400, in part by the NSFC under Grants 61922046, 61620106008, and 62002176, in part by the S&T Innovation Project from Chinese Ministry of Education, and in part by the Tianjin Natural Science Foundation under Grant 17JCJQJC43700. Kai Zhao and Qi Han contributed equally to this work. A preliminary version of this work has been presented in [1].	Aggarwal N, 2006, IEEE T IMAGE PROCESS, V15, P582, DOI 10.1109/TIP.2005.863021; Ahmad T, 2017, IEEE IJCNN, P4436, DOI 10.1109/IJCNN.2017.7966418; Akinlar C, 2013, PATTERN RECOGN, V46, P725, DOI 10.1016/j.patcog.2012.09.020; Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001; Ba J., 2017, P 3 INT C LEARN REPR; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BENYACOUB S, 1995, IEE P-VIS IMAGE SIGN, V142, P7, DOI 10.1049/ip-vis:19951434; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Caplin S., 2008, ART DESIGN PHOTOSHOP; Chan T. S., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P126, DOI 10.1109/ICPR.1996.546737; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen ZQ, 2020, PROC CVPR IEEE, P42, DOI 10.1109/CVPR42600.2020.00012; Cheng MM, 2020, IEEE T IMAGE PROCESS, V29, P909, DOI 10.1109/TIP.2019.2936746; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cheng ZQ, 2019, IEEE I CONF COMP VIS, P6151, DOI 10.1109/ICCV.2019.00625; Deng BY, 2020, PROC CVPR IEEE, P31, DOI 10.1109/CVPR42600.2020.00011; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; ETEMADI A, 1992, IEE CONF PUBL, V354, P311; Fan RC, 2020, COMPUT VIS MEDIA, V6, P191, DOI 10.1007/s41095-020-0173-9; Fan RC, 2019, COMPUT VIS MEDIA, V5, P417, DOI 10.1007/s41095-019-0160-1; Feng H, 2014, IEEE T INSTRUM MEAS, V63, P877, DOI 10.1109/TIM.2013.2283741; Fernandes LAF, 2008, PATTERN RECOGN, V41, P299, DOI 10.1016/j.patcog.2007.04.003; Freeman M., 2007, PHOTOGRAPHERS EYE CO; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4; Hu SM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508381; Hu SM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508371; Huang K, 2018, PROC CVPR IEEE, P626, DOI 10.1109/CVPR.2018.00072; Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069; ILLINGWORTH J, 1987, IEEE T PATTERN ANAL, V9, P690, DOI 10.1109/TPAMI.1987.4767964; KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E; Ko K, 2018, IEEE IMAGE PROC, P2491, DOI 10.1109/ICIP.2018.8451621; Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40; Krages B., 2012, PHOTOGRAPHY ART COMP; Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053; Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1; Lee JT, 2019, IEEE ACCESS, V7, P114349, DOI 10.1109/ACCESS.2019.2936289; Lee JT, 2017, IEEE I CONF COMP VIS, P3249, DOI 10.1109/ICCV.2017.350; Limberger FA, 2015, PATTERN RECOGN, V48, P2043, DOI 10.1016/j.patcog.2014.12.020; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x; Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524; Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849; Mai L, 2016, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2016.60; Min J, 2019, IEEE I CONF COMP VIS, P3394, DOI 10.1109/ICCV.2019.00349; OGORMAN F, 1976, IEEE T COMPUT, V25, P449, DOI 10.1109/TC.1976.1674627; Paszke A, 2019, ADV NEUR IN, V32; PRINCEN J, 1990, COMPUT VISION GRAPH, V52, P57, DOI 10.1016/0734-189X(90)90123-D; Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937; Radon J., 1917, SITZBER SACHS AKAD W, V69, P262, DOI DOI 10.1109/TMI.1986.4307775; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Shang-Hua Gao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P702, DOI 10.1007/978-3-030-58539-6_42; Simonyan K., 2015, INT C LEARN REPR; Sobel I., 1968, STANFORD ARTIFICIAL, P271; von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300; Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xue N, 2020, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR42600.2020.00286; Yong-Qiang Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8907, DOI 10.1109/CVPR42600.2020.00893; Yu F., 2016, P ICLR 2016; Zhang SH, 2020, COMPUT VIS MEDIA, V6, P79, DOI 10.1007/s41095-020-0158-8; Zhang ZH, 2019, PROC CVPR IEEE, P7089, DOI 10.1109/CVPR.2019.00727; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao K, 2022, IEEE T PATTERN ANAL, V44, P4793, DOI 10.1109/TPAMI.2021.3077129; Zhao K, 2019, IEEE I CONF COMP VIS, P8848, DOI 10.1109/ICCV.2019.00894; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009; Zhou YC, 2019, IEEE I CONF COMP VIS, P962, DOI 10.1109/ICCV.2019.00105; Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360	78	25	25	20	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4793	4806		10.1109/TPAMI.2021.3077129	http://dx.doi.org/10.1109/TPAMI.2021.3077129			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33939606	Green Submitted			2022-12-18	WOS:000836666600025
J	Wan, J; Wang, QZ; Chan, AB				Wan, Jia; Wang, Qingzhong; Chan, Antoni B.			Kernel-Based Density Map Generation for Dense Object Counting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Crowd counting; vehicle counting; object counting; density map generation; density map estimation; deep learning	PEOPLE	Crowd counting is an essential topic in computer vision due to its practical usage in surveillance systems. The typical design of crowd counting algorithms is divided into two steps. First, the ground-truth density maps of crowd images are generated from the ground-truth dot maps (density map generation), e.g., by convolving with a Gaussian kernel. Second, deep learning models are designed to predict a density map from an input image (density map estimation). The density map based counting methods that incorporate density map as the intermediate representation have improved counting performance dramatically. However, in the sense of end-to-end training, the hand-crafted methods used for generating the density maps may not be optimal for the particular network or dataset used. To address this issue, we propose an adaptive density map generator, which takes the annotation dot map as input, and learns a density map representation for a counter. The counter and generator are trained jointly within an end-to-end framework. We also show that the proposed framework can be applied to general dense object counting tasks. Extensive experiments are conducted on 10 datasets for 3 applications: crowd counting, vehicle counting, and general object counting. The experiment results on these datasets confirm the effectiveness of the proposed learnable density map representations.	[Wan, Jia; Wang, Qingzhong; Chan, Antoni B.] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China	City University of Hong Kong	Chan, AB (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.	jiawan1998@gmail.com; qingzwang2-c@my.cityu.edu.hk; abchan@cityu.edu.hk	; CHAN, Antoni B./D-7858-2013	Wang, Qingzhong/0000-0003-1562-8098; Wan, Jia/0000-0001-8198-1629; CHAN, Antoni B./0000-0002-2886-2513	Research Grants Council of the Hong Kong Special Administrative Region, China [T32-101/15-R, CityU 11212518]; City University of Hong Kong [7004887]	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council); City University of Hong Kong(City University of Hong Kong)	The authors would like to thank the reviewers for their helpful comments. This work was supported by Grants from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. [T32-101/15-R] and CityU 11212518), and by a Strategic Research Grant from City University of Hong Kong (No. 7004887).	Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16; Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45; Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569; Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191; Gao J., 2019, ARXIV190702724; Gao JY, 2020, IEEE T CIRC SYST VID, V30, P3486, DOI 10.1109/TCSVT.2019.2919139; Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621; Goldman E, 2019, PROC CVPR IEEE, P5222, DOI 10.1109/CVPR.2019.00537; Guerrero-Gomez-Olmedo R, 2015, LECT NOTES COMPUT SC, V9117, P423, DOI 10.1007/978-3-319-19390-8_48; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hsieh MR, 2017, IEEE I CONF COMP VIS, P4165, DOI 10.1109/ICCV.2017.446; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33; Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629; Kang D., 2018, P BRIT MACH VIS C; Kang D, 2019, IEEE T CIRC SYST VID, V29, P1408, DOI 10.1109/TCSVT.2018.2837153; King DB, 2015, ACS SYM SER, V1214, P1; Laradji IH, 2018, LECT NOTES COMPUT SC, V11206, P560, DOI 10.1007/978-3-030-01216-8_34; Lempitsky V., 2010, NIPS, V23, P1324; Li M, 2008, INT C PATT RECOG, P1998; Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120; Lian DZ, 2019, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2019.00192; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Liu CC, 2019, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2019.00131; Liu LB, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P849; Liu LB, 2019, IEEE I CONF COMP VIS, P1774, DOI 10.1109/ICCV.2019.00186; Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334; Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524; Liu XL, 2018, PROC CVPR IEEE, P7661, DOI 10.1109/CVPR.2018.00799; Liu YT, 2019, PROC CVPR IEEE, P6462, DOI 10.1109/CVPR.2019.00663; Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624; Marsden M, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P27, DOI 10.5220/0006097300270033; Mundhenk TN, 2016, LECT NOTES COMPUT SC, V9907, P785, DOI 10.1007/978-3-319-46487-9_48; Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Sam D. B., 2020, IEEE T PATTERN ANAL; Sam DB, 2018, AAAI CONF ARTIF INTE, P7323; Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381; Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550; Shi MJ, 2019, PROC CVPR IEEE, P7271, DOI 10.1109/CVPR.2019.00745; Shi ZL, 2018, PROC CVPR IEEE, P5382, DOI 10.1109/CVPR.2018.00564; Sindagi V. A., 2020, IEEE T PATTERN ANAL; Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Sindagi VA, 2019, IEEE I CONF COMP VIS, P1002, DOI 10.1109/ICCV.2019.00109; Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206; Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007; Stahl T, 2019, IEEE T IMAGE PROCESS, V28, P1035, DOI 10.1109/TIP.2018.2875353; Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41; Wan J, 2019, IEEE I CONF COMP VIS, P1130, DOI 10.1109/ICCV.2019.00122; Wan J, 2019, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2019.00416; Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839; Wang QY, 2021, J MANUF PROCESS, V63, P2, DOI 10.1016/j.jmapro.2020.04.044; Wang Z., 2018, P BRIT MACH VIS C; Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418; Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684; Zhang Q, 2019, PROC CVPR IEEE, P8289, DOI 10.1109/CVPR.2019.00849; Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70; Zhao MM, 2019, PROC CVPR IEEE, P12728, DOI 10.1109/CVPR.2019.01302	64	25	25	11	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1357	1370		10.1109/TPAMI.2020.3022878	http://dx.doi.org/10.1109/TPAMI.2020.3022878			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32903177				2022-12-18	WOS:000752018000021
J	Balntas, V; Lenc, K; Vedaldi, A; Tuytelaars, T; Matas, J; Mikolajczyk, K				Balntas, Vassileios; Lenc, Karel; Vedaldi, Andrea; Tuytelaars, Tinne; Matas, Jiri; Mikolajczyk, Krystian			H-Patches: A Benchmark and Evaluation of Handcrafted and Learned Local Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Local features; feature descriptors; image matching; patch classification	IMAGE DESCRIPTORS; REPRESENTATION; PERFORMANCE	In this paper, a novel benchmark is introduced for evaluating local image descriptors. We demonstrate limitations of the commonly used datasets and evaluation protocols, that lead to ambiguities and contradictory results in the literature. Furthermore, these benchmarks are nearly saturated due to the recent improvements in local descriptors obtained by learning from large annotated datasets. To address these issues, we introduce a new large dataset suitable for training and testing modern descriptors, together with strictly defined evaluation protocols in several tasks such as matching, retrieval and verification. This allows for more realistic, thus more reliable comparisons in different application scenarios. We evaluate the performance of several state-of-the-art descriptors and analyse their properties. We show that a simple normalisation of traditional hand-crafted descriptors is able to boost their performance to the level of deep learning based descriptors once realistic benchmarks are considered. Additionally we specify a protocol for learning and evaluating using cross validation. We show that when training state-of-the-art descriptors on this dataset, the traditional verification task is almost entirely saturated.	[Balntas, Vassileios; Lenc, Karel; Vedaldi, Andrea] Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England; [Mikolajczyk, Krystian] Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England; [Tuytelaars, Tinne] Katholieke Univ Leuven, B-3000 Leuven, Belgium; [Matas, Jiri] Czech Tech Univ, Ctr Machine Percept, Prague 16000, Czech Republic	University of Oxford; Imperial College London; KU Leuven; Czech Technical University Prague	Lenc, K (corresponding author), Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England.	balntas@robots.ox.ac.uk; karel@robots.ox.ac.uk; vedaldi@robots.ox.ac.uk; tinne.tuytelaars@esat.kuleuven.be; matas@cmp.felk.cvut.cz; k.mikolajczyk@imperial.ac.uk	, Matas/AAW-3282-2020; Tuytelaars, Tinne/B-4319-2015; Vedaldi, Andrea/B-9071-2015	Tuytelaars, Tinne/0000-0003-3307-9723; Vedaldi, Andrea/0000-0003-1374-2858	ERC [638009-IDIU]; EPSRC [EP/M013774/1, EP/N007743/1]; EPSRC [EP/K01904X/2, EP/S032398/1] Funding Source: UKRI	ERC(European Research Council (ERC)European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	V. Balntas and K. Lenc contributed equally to this work. This research was supported by ERC 638009-IDIU, EPSRC SeeBiByte Programme Grant (EP/M013774/1) and by EPSRC EP/N007743/1. We would like to thank Dmytro Mishkin for providing networks trained on the splits of our dataset, and for the helpful discussions. We would like to thank Giorgos Tolias for help with descriptor normalisation. We would also like to thank Akis Tsiotsios for providing the camera used for collecting the data.	Aanaes H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8; Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16; Altwaijry H, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.15; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Balntas V., 2016, THESIS; Balntas V, 2017, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2017.410; Balntas V, 2015, PROC CVPR IEEE, P2367, DOI 10.1109/CVPR.2015.7298850; Balntas Vassileios, 2016, BMVC, V2, DOI DOI 10.5244/C.30.119; Bay H., 2006, EUR C COMP VIS ECCV, P404, DOI [10.1007/11744023_32, DOI 10.1007/11744023_32]; Bishop, 1995, NEURAL NETWORKS PATT; Brown M, 2005, PROC CVPR IEEE, P510; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Bursuc A, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P595, DOI 10.1145/2671188.2749379; Cai HP, 2011, IEEE T PATTERN ANAL, V33, P338, DOI 10.1109/TPAMI.2010.89; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Chandrasekhar Vijay, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2504, DOI 10.1109/CVPRW.2009.5206733; Chandrasekhar V, 2014, IEEE DATA COMPR CONF, P3, DOI 10.1109/DCC.2014.50; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Cordes K, 2011, IEEE SYMP DIFF EVOL, P104; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Davis J., 2006, P 23 INT C MACH LEAR, V148, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]; DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060; Donahue J, 2014, PR MACH LEARN RES, V32; Dong JM, 2015, PROC CVPR IEEE, P5097, DOI 10.1109/CVPR.2015.7299145; Dosovitskiy A., 2014, ADV NEURAL INFORM PR, V27, P766, DOI [DOI 10.1109/TPAMI.2015.2496141, 10.48550/arXiv.1406.6909]; Fan B, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995385; Fawcett T, 2004, MACH LEARN, V31, P1, DOI [10.1.1.10.9777, DOI 10.1016/J.PATREC.2005.10.010]; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartmann W, 2014, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2014.9; Hua G, 2007, IEEE I CONF COMP VIS, P229; Jacobs N, 2007, IEEE I CONF COMP VIS, P1305; Jahrer M., 2008, P COMP VIS WINT WORK, P39; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Ke Y, 2004, PROC CVPR IEEE, P506; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; Lenc K., 2011, VLBENCHMKARS; Lenc K, 2016, LECT NOTES COMPUT SC, V9915, P100, DOI 10.1007/978-3-319-49409-8_11; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Levi G, 2016, IEEE WINT CONF APPL; Lewis JP, 1994, PROC CANAD IMAG PROC, P120; Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Mainali P, 2014, IEEE T IMAGE PROCESS, V23, P2380, DOI 10.1109/TIP.2014.2315959; Mainali P, 2013, INT J COMPUT VISION, V104, P172, DOI 10.1007/s11263-013-0622-3; Mair E, 2010, LECT NOTES COMPUT SC, V6312, P183, DOI 10.1007/978-3-642-15552-9_14; Markus N, 2016, INT C PATT RECOG, P2380, DOI 10.1109/ICPR.2016.7899992; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9; Mikolajczyk K, 2007, IEEE I CONF COMP VIS, P337; Miksik O, 2012, INT C PATT RECOG, P2681; Mishchuk Anastasiya, 2017, ADV NEURAL INFORM PR; Mishkin D, 2018, LECT NOTES COMPUT SC, V11213, P287, DOI 10.1007/978-3-030-01240-3_18; Mukundan A., 2017, P BRIT MACH VIS C; OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366; Osendorfer Christian, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P624, DOI 10.1007/978-3-642-42051-1_77; Paulin M, 2017, INT J COMPUT VISION, V121, P149, DOI 10.1007/s11263-016-0924-3; Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19; Philipp JB, 2008, 2008 9TH ANNUAL NON-VOLATILE MEMORY TECHNOLOGY SYMPOSIUM, PROCEEDINGS, P12; Richardson A, 2013, IEEE INT CONF ROBOT, P631, DOI 10.1109/ICRA.2013.6630639; Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Salti S, 2013, PROC CVPR IEEE, P2898, DOI 10.1109/CVPR.2013.373; Simmons A, 2007, WASTE WASTE MANAG, P1, DOI 10.1007/978-0-387-34253-5; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163; Sochman J, 2009, INT J COMPUT VISION, V83, P149, DOI 10.1007/s11263-009-0229-x; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Strecha C, 2009, LECT NOTES COMPUT SC, V5748, P151, DOI 10.1007/978-3-642-03798-6_16; Taylor S, 2011, INT J COMPUT VISION, V94, P241, DOI 10.1007/s11263-011-0430-6; Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649; Trujillo L, 2006, INT C PATT RECOG, P211; Trzcinski T, 2015, IEEE T PATTERN ANAL, V37, P597, DOI 10.1109/TPAMI.2014.2343961; Trzcinski T, 2012, LECT NOTES COMPUT SC, V7572, P228, DOI 10.1007/978-3-642-33718-5_17; Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017; Van Gool L., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P642, DOI 10.1007/BFb0015574; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165; Vonikakis V., 2012, Proceedings of the 2012 IEEE International Conference on Imaging Systems and Techniques (IST), P158, DOI 10.1109/IST.2012.6295482; Wang JG, 2017, CHIN CONTR CONF, P1681, DOI 10.23919/ChiCC.2017.8027593; Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294; Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839; Xu XW, 2014, IEEE T IMAGE PROCESS, V23, P2983, DOI 10.1109/TIP.2014.2324824; Yang TY, 2016, PROC CVPR IEEE, P327, DOI 10.1109/CVPR.2016.42; Yi KM, 2016, PROC CVPR IEEE, P107, DOI 10.1109/CVPR.2016.19; Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28; Yu GS, 2011, IMAGE PROCESS ON LIN, V1, P11, DOI 10.5201/ipol.2011; ZAGORUYKO S, 2015, 2015 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2015.7299064; Zhang SL, 2014, IEEE T IMAGE PROCESS, V23, P3671, DOI 10.1109/TIP.2014.2330794; Ziegler A, 2012, ADV NEURAL INFORM PR, P1; Zitnick CL, 2011, IEEE I CONF COMP VIS, P359, DOI 10.1109/ICCV.2011.6126263	97	25	27	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2825	2841		10.1109/TPAMI.2019.2915233	http://dx.doi.org/10.1109/TPAMI.2019.2915233			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NX0AD	31094682	Green Submitted, Green Published			2022-12-18	WOS:000575381000007
J	Hesse, N; Pujades, S; Black, MJ; Arens, M; Hofmann, UG; Schroeder, AS				Hesse, Nikolas; Pujades, Sergi; Black, Michael J.; Arens, Michael; Hofmann, Ulrich G.; Schroeder, A. Sebastian			Learning and Tracking the 3D Body Shape of Freely Moving Infants from RGB-D sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape; Biological system modeling; Three-dimensional displays; Data models; Animals; Face; Avatars; Body models; data-driven; RGB-D; infants; motion analysis	MODEL; MOVEMENTS; POSE	Statistical models of the human body surface are generally learned from thousands of high-quality 3D scans in predefined poses to cover the wide variety of human body shapes and articulations. Acquisition of such data requires expensive equipment, calibration procedures, and is limited to cooperative subjects who can understand and follow instructions, such as adults. We present a method for learning a statistical 3D Skinned Multi-Infant Linear body model (SMIL) from incomplete, low-quality RGB-D sequences of freely moving infants. Quantitative experiments show that SMIL faithfully represents the RGB-D data and properly factorizes the shape and pose of the infants. To demonstrate the applicability of SMIL, we fit the model to RGB-D sequences of freely moving infants and show, with a case study, that our method captures enough motion detail for General Movements Assessment (GMA), a method used in clinical practice for early detection of neurodevelopmental disorders in infants. SMIL provides a new tool for analyzing infant shape and movement and is a step towards an automated system for GMA.	[Hesse, Nikolas; Arens, Michael] Fraunhofer IOSB, Inst Optron Syst Technol & Image Exploitat, D-76275 Ettlingen, Germany; [Pujades, Sergi] Univ Grenoble Alpes, Inria, CNRS, GrenobleINP,LJK, F-38334 Grenoble, France; [Black, Michael J.] Max Planck Inst Intelligent Syst, D-72076 Tubingen, Germany; [Hofmann, Ulrich G.] Univ Freiburg, Univ Med Ctr Freiburg, Fac Med, D-79085 Freiburg, Germany; [Schroeder, A. Sebastian] Ludwig Maximilians Univ Munchen, Hauner Childrens Hosp, D-80337 Munich, Germany	Fraunhofer Gesellschaft; Fraunhofer Optronics, System Technologies & Image Exploitation Ettlingen; Centre National de la Recherche Scientifique (CNRS); Communaute Universite Grenoble Alpes; UDICE-French Research Universities; Universite Grenoble Alpes (UGA); Inria; Max Planck Society; University of Freiburg; University of Munich	Hesse, N (corresponding author), Fraunhofer IOSB, Inst Optron Syst Technol & Image Exploitat, D-76275 Ettlingen, Germany.	nikolas.hesse@iosb.fraunhofer.de; sergi.pujades-rocamora@inria.fr; black@tuebingen.mpg.de; michael.arens@iosb.fraunhofer.de; ulrich.hofmann@coregen.uni-freiburg.de; sebastian.schroeder@med.uni-muenchen.de	Schroeder, Sebastian/GSN-8083-2022; Hofmann, Ulrich/D-7107-2013	Black, Michael/0000-0001-6077-4540; Pujades, Sergi/0000-0002-9604-7721; Hofmann, Ulrich/0000-0002-6264-3701; Schroeder, A. Sebastian/0000-0001-6664-2012; Hesse, Nikolas/0000-0003-1141-0614; Arens, Michael/0000-0002-7857-0332	Intel; Nvidia; Adobe; Facebook; Amazon; MPI	Intel(Intel Corporation); Nvidia; Adobe; Facebook(Facebook Inc); Amazon; MPI	MJB has received research gift funds from Intel, Nvidia, Adobe, Facebook, and Amazon. While MJB is a part-time employee of Amazon, his contribution was performed solely at, and funded solely by, MPI.	Achilles Felix, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P491, DOI 10.1007/978-3-319-46720-7_57; Alldieck T, 2018, INT CONF 3D VISION, P98, DOI 10.1109/3DV.2018.00022; Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bogo F, 2017, PROC CVPR IEEE, P5573, DOI 10.1109/CVPR.2017.591; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Bogo F, 2015, IEEE I CONF COMP VIS, P2300, DOI 10.1109/ICCV.2015.265; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Cashman TJ, 2013, IEEE T PATTERN ANAL, V35, P232, DOI 10.1109/TPAMI.2012.68; Chen Y, 2016, IEEE T VIS COMPUT GR, V22, P2000, DOI 10.1109/TVCG.2015.2478779; Chen YP, 2013, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2013.21; Clark RA, 2012, GAIT POSTURE, V36, P372, DOI 10.1016/j.gaitpost.2012.03.033; DeCarlo D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P67, DOI 10.1145/280814.280823; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Ganapathi V, 2012, LECT NOTES COMPUT SC, V7577, P738, DOI 10.1007/978-3-642-33783-3_53; Geman S, 1987, B INT STAT I, V4, P5; Hadders-Algra M, 2004, J PEDIATR-US, V145, pS12, DOI 10.1016/j.jpeds.2004.05.017; Hasler N, 2009, COMPUT GRAPH FORUM, V28, P337, DOI 10.1111/j.1467-8659.2009.01373.x; Helten T, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P279, DOI 10.1109/3DV.2013.44; Hesse N, 2019, LECT NOTES COMPUT SC, V11134, P32, DOI 10.1007/978-3-030-11024-6_3; Hesse N, 2018, LECT NOTES COMPUT SC, V11070, P792, DOI 10.1007/978-3-030-00928-1_89; Hirshberg DA, 2012, LECT NOTES COMPUT SC, V7577, P242, DOI 10.1007/978-3-642-33783-3_18; Kanazawa A, 2016, COMPUT GRAPH FORUM, V35, P365, DOI 10.1111/cgf.12838; Kim M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073685; Kontschieder P, 2014, LECT NOTES COMPUT SC, V8674, P429, DOI 10.1007/978-3-319-10470-6_54; Loper M., CHUMPY; Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013; Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11; Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969; Marcroft C, 2015, FRONT NEUROL, V5, DOI 10.3389/fneur.2014.00284; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062; Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055; Pishchulin L, 2017, PATTERN RECOGN, V67, P276, DOI 10.1016/j.patcog.2017.02.018; Pons-Moll G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073711; PRECHTL HFR, 1990, EARLY HUM DEV, V23, P151, DOI 10.1016/0378-3782(90)90011-7; Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883; Seo Hyewon, 2003, P 2003 S INT 3D GRAP, P19, DOI [DOI 10.1145/641480.641487, 10.1145/641480.641487]; Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494; Tung HYF, 2017, ADV NEUR IN, V30; Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465; Ye GZ, 2012, LECT NOTES COMPUT SC, V7573, P828, DOI 10.1007/978-3-642-33709-3_59; Ye M, 2014, PROC CVPR IEEE, P2353, DOI 10.1109/CVPR.2014.301; Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761; Zhang C, 2017, PROC CVPR IEEE, P5484, DOI 10.1109/CVPR.2017.582; Zhang Q, 2014, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2014.92; Zuffi S, 2017, PROC CVPR IEEE, P5524, DOI 10.1109/CVPR.2017.586	51	25	25	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2540	2551		10.1109/TPAMI.2019.2917908	http://dx.doi.org/10.1109/TPAMI.2019.2917908			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31180836	Green Submitted, Bronze			2022-12-18	WOS:000567471300016
J	Wang, KZ; Lin, L; Jiang, CH; Qian, C; Wei, PX				Wang, Keze; Lin, Liang; Jiang, Chenhan; Qian, Chen; Wei, Pengxu			3D Human Pose Machines with Self-Supervised Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Two dimensional displays; Pose estimation; Solid modeling; Task analysis; Deep learning; Feature extraction; Human pose estimation; convolutional neural networks; spatio-temporal modeling; self-supervised learning; geometric deep learning		Driven by recent computer vision and robotic applications, recovering 3D human poses has become increasingly important and attracted growing interests. In fact, completing this task is quite challenging due to the diverse appearances, viewpoints, occlusions and inherently geometric ambiguities inside monocular images. Most of the existing methods focus on designing some elaborate priors /constraints to directly regress 3D human poses based on the corresponding 2D human pose-aware features or 2D pose predictions. However, due to the insufficient 3D pose data for training and the domain gap between 2D space and 3D space, these methods have limited scalabilities for all practical scenarios (e.g., outdoor scene). Attempt to address this issue, this paper proposes a simple yet effective self-supervised correction mechanism to learn all intrinsic structures of human poses from abundant images. Specifically, the proposed mechanism involves two dual learning tasks, i.e., the 2D-to-3D pose transformation and 3D-to-2D pose projection, to serve as a bridge between 3D and 2D human poses in a type of "free" self-supervision for accurate 3D human pose estimation. The 2D-to-3D pose implies to sequentially regress intermediate 3D poses by transforming the pose representation from the 2D domain to the 3D domain under the sequence-dependent temporal context, while the 3D-to-2D pose projection contributes to refining the intermediate 3D poses by maintaining geometric consistency between the 2D projections of 3D poses and the estimated 2D poses. Therefore, these two dual learning tasks enable our model to adaptively learn from 3D human pose data and external large-scale 2D human pose data. We further apply our self-supervised correction mechanism to develop a 3D human pose machine, which jointly integrates the 2D spatial relationship, temporal smoothness of predictions and 3D geometric knowledge. Extensive evaluations on the Human3.6M and HumanEva-I benchmarks demonstrate the superior performance and efficiency of our framework over all the compared competing methods.	[Wang, Keze; Lin, Liang; Jiang, Chenhan; Wei, Pengxu] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China; [Wang, Keze] Minist Educ, Engn Res Ctr Adv Comp Engn Software, Beijing, Peoples R China; [Qian, Chen] SenseTime Grp, Hong Kong, Peoples R China	Sun Yat Sen University	Lin, L (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China.	kezewang@gmail.com; linlang@ieee.org; jiangchh6@mail2.sysu.edu.cn; qianchen@sensetime.com; pengxu.07@163.com	, qc/ABE-8196-2020	Wang, Keze/0000-0002-7817-8306	National Key Research and Development Program of China [2018YFC0830103]; National High Level Talents Special Support Plan (Ten Thousand Talents Program); National Natural Science Foundation of China (NSFC) [61622214, 61836012]; Ministry of Public Security Science and Technology Police Foundation [2016GABJC48]; Guandong "Climbing Program" special funds [pdjh2018b0013]	National Key Research and Development Program of China; National High Level Talents Special Support Plan (Ten Thousand Talents Program); National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Ministry of Public Security Science and Technology Police Foundation; Guandong "Climbing Program" special funds	This work was supported in part by the National Key Research and Development Program of China under Grant No. 2018YFC0830103, in part by National High Level Talents Special Support Plan (Ten Thousand Talents Program), in part by National Natural Science Foundation of China (NSFC) under Grant No. 61622214, and 61836012, in part by the Ministry of Public Security Science and Technology Police Foundation Project No. 2016GABJC48, and in part by Guandong "Climbing Program" special funds under Grant pdjh2018b0013.	Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156; [Anonymous], P BRIT MACH VIS C; [Anonymous], INTRO CYBERPSYCHOLOG; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Burgos-Artizzu XP, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.58; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chen CH, 2017, PROC CVPR IEEE, P5759, DOI 10.1109/CVPR.2017.610; Doersch C, 2017, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2017.226; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Du Y, 2016, LECT NOTES COMPUT SC, V9908, P20, DOI 10.1007/978-3-319-46493-0_2; Ghosh A., 1993, IEEE Transactions on Fuzzy Systems, V1, P54, DOI 10.1109/TFUZZ.1993.390285; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Graves A, 2014, PR MACH LEARN RES, V32, P1764; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Held C, 2012, COMPUTER, V45, P83, DOI 10.1109/MC.2012.97; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Kazemi V, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.48; Kingma D.P., 2015, INT C LEARN REPR ICL; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; LeCun Y., 1990, ADV NEURAL INFORM PR, P396, DOI DOI 10.1111/DSU.12130; Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326; Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23; Lin MD, 2017, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2017.588; Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013; Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Nie BX, 2017, IEEE I CONF COMP VIS, P3467, DOI 10.1109/ICCV.2017.373; Nie BX, 2015, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2015.7298734; Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062; Pal S. K., 1978, J ANAT SOC INDIA, VVI, P117; Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139; Radwan I, 2013, IEEE I CONF COMP VIS, P1888, DOI 10.1109/ICCV.2013.237; Rheingold H., 1991, VIRTUAL REALITY EXPL; Sanzari M, 2016, LECT NOTES COMPUT SC, V9912, P566, DOI 10.1007/978-3-319-46484-8_34; Sigal L, 2012, INT J COMPUT VISION, V98, P15, DOI 10.1007/s11263-011-0493-4; Simo-Serra E, 2013, PROC CVPR IEEE, P3634, DOI 10.1109/CVPR.2013.466; Simo-Serra E, 2012, PROC CVPR IEEE, P2673, DOI 10.1109/CVPR.2012.6247988; Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Tekin B, 2017, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2017.425; Tekin B, 2016, PROC CVPR IEEE, pCP8, DOI 10.1109/CVPR.2016.113; Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303; Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Yang W, 2016, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2016.335; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535; Zhou F, 2014, LECT NOTES COMPUT SC, V8694, P62, DOI 10.1007/978-3-319-10599-4_5; Zhou XW, 2017, IEEE T PATTERN ANAL, V39, P1648, DOI 10.1109/TPAMI.2016.2605097; Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537; Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51; Zhou XY, 2016, LECT NOTES COMPUT SC, V9915, P186, DOI 10.1007/978-3-319-49409-8_17	60	25	28	9	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1069	1082		10.1109/TPAMI.2019.2892452	http://dx.doi.org/10.1109/TPAMI.2019.2892452			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30640601	Green Submitted			2022-12-18	WOS:000523685800005
J	Yang, ZG; Li, Q; Liu, WY; Lv, JM				Yang, Zhenguo; Li, Qing; Liu, Wenyin; Lv, Jianming			Shared Multi-View Data Representation for Multi-Domain Event Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Data models; Dictionaries; Event detection; Social network services; Computational modeling; Task analysis; Media; Multi-domain event discovery; multimodal fusion; data representation learning	LOW-RANK; MATRIX FACTORIZATION; IMAGE; COMPLETION; ALGORITHM; MODEL; GRAPH	Internet platforms provide new ways for people to share experiences, generating massive amounts of data related to various real-world concepts. In this paper, we present an event detection framework to discover real-world events from multiple data domains, including online news media and social media. As multi-domain data possess multiple data views that are heterogeneous, initial dictionaries consisting of labeled data samples are exploited to align the multi-view data. Furthermore, a shared multi-view data representation (SMDR) model is devised, which learns underlying and intrinsic structures shared among the data views by considering the structures underlying the data, data variations, and informativeness of dictionaries. SMDR incorpvarious constraints in the objective function, including shared representation, low-rank, local invariance, reconstruction error, and dictionary independence constraints. Given the data representations achieved by SMDR, class-wise residual models are designed to discover the events underlying the data based on the reconstruction residuals. Extensive experiments conducted on two real-world event detection datasets, i.e., Multi-domain and Multi-modality Event Detection dataset, and MediaEval Social Event Detection 2014 dataset, indicating the effectiveness of the proposed approaches.	[Yang, Zhenguo; Liu, Wenyin] Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou 510006, Peoples R China; [Yang, Zhenguo] City Univ Hong Kong, Dept Comp Sci, Hong Kong 999077, Peoples R China; [Li, Qing] Hong Kong Polytech Univ, Dept Comp, Hong Kong 999077, Peoples R China; [Lv, Jianming] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China	Guangdong University of Technology; City University of Hong Kong; Hong Kong Polytechnic University; South China University of Technology	Liu, WY (corresponding author), Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou 510006, Peoples R China.; Li, Q (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong 999077, Peoples R China.	zhengyang5-c@my.cityu.edu.hk; csqli@comp.polyu.edu.hk; liuwy@gdut.edu.cn; jmlv@scut.edu.cn			National Natural Science Foundation of China [61703109, 91748107, 61876065]; China Postdoctoral Science Foundation [2018M643024]; Guangdong Innovative Research Team Program [2014ZT05G157]; Research Grants Council of HKSAR [PolyU 11211417]; Natural Science Foundation of Guangdong Province, China [2018A0303130022]; Science and Technology Planning Project of Guangdong Province, China [2016A010101012]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Guangdong Innovative Research Team Program; Research Grants Council of HKSAR(Hong Kong Research Grants Council); Natural Science Foundation of Guangdong Province, China(National Natural Science Foundation of Guangdong Province); Science and Technology Planning Project of Guangdong Province, China	This work is supported by the National Natural Science Foundation of China (No.61703109, No.91748107, No.61876065), China Postdoctoral Science Foundation (No.2018M643024), the Guangdong Innovative Research Team Program (No.2014ZT05G157), a general research fund from the Research Grants Council of HKSAR (project no. PolyU 11211417 (formerly, CityU 11211417)), Natural Science Foundation of Guangdong Province, China (No.2018A0303130022), and Science and Technology Planning Project of Guangdong Province, China (No.2016A010101012).	Ah-Pine J, 2015, ACM T INFORM SYST, V33, DOI 10.1145/2699668; Allan J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P37, DOI 10.1145/290941.290954; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2010, IMPLEMENTATION BENCH; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; Bao CL, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487966; Cabral R, 2015, IEEE T PATTERN ANAL, V37, P121, DOI 10.1109/TPAMI.2014.2343234; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Cao XC, 2015, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2015.7298657; Chen L, 2010, PROC CVPR IEEE, P3440, DOI 10.1109/CVPR.2010.5539988; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hays James, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587784; He R, 2014, IEEE T PATTERN ANAL, V36, P770, DOI 10.1109/TPAMI.2013.188; Jiang XD, 2015, IEEE T PATTERN ANAL, V37, P1067, DOI 10.1109/TPAMI.2014.2359453; Kim HJ, 2017, PROC CVPR IEEE, P3251, DOI 10.1109/CVPR.2017.346; Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152; Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461; Lin ZC, 2011, PROG MOL BIOL TRANSL, V98, P1, DOI 10.1016/B978-0-12-385506-0.00001-6; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2016, IEEE T PATTERN ANAL, V38, P417, DOI 10.1109/TPAMI.2015.2453969; Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217; Lu CW, 2013, PROC CVPR IEEE, P415, DOI 10.1109/CVPR.2013.60; Mairal J, 2010, J MACH LEARN RES, V11, P19; Mensch A, 2016, PR MACH LEARN RES, V48; Niu DL, 2014, IEEE T PATTERN ANAL, V36, P1340, DOI 10.1109/TPAMI.2013.180; Qian SS, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2659521; Qiu Q, 2014, IEEE T PATTERN ANAL, V36, P2173, DOI 10.1109/TPAMI.2014.2316824; Sakaki T, 2013, IEEE T KNOWL DATA EN, V25, P919, DOI 10.1109/TKDE.2012.29; Schinas M, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P189, DOI 10.1145/2733373.2809933; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109; Song L., 2007, ICML, P815; Sundaram YW, 2012, P 20 ACM INT C MULTI, P865, DOI [10.1145/2393347.2396332, DOI 10.1145/2393347.2396332]; Takahashi T, 2015, IEEE T PATTERN ANAL, V37, P1469, DOI 10.1109/TPAMI.2014.2382092; Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882; Vu TH, 2017, IEEE T IMAGE PROCESS, V26, P5160, DOI 10.1109/TIP.2017.2729885; Wang DY, 2014, IEEE T PATTERN ANAL, V36, P550, DOI 10.1109/TPAMI.2013.145; Wu F, 2014, IEEE T MULTIMEDIA, V16, P427, DOI 10.1109/TMM.2013.2291214; Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124; Wu X, 2008, IEEE T MULTIMEDIA, V10, P188, DOI 10.1109/TMM.2007.911778; Xiao M, 2015, IEEE T PATTERN ANAL, V37, P54, DOI 10.1109/TPAMI.2014.2343216; Yang XS, 2015, IEEE T MULTIMEDIA, V17, P346, DOI 10.1109/TMM.2015.2393635; Yang ZG, 2017, LECT NOTES COMPUT SC, V10569, P516, DOI 10.1007/978-3-319-68783-4_35; Yang ZG, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3015463; Yang ZG, 2017, WORLD WIDE WEB, V20, P995, DOI 10.1007/s11280-016-0405-1; Yang ZG, 2015, INT J MULTIMED DATA, V6, P1, DOI 10.4018/IJMDEM.2015100101; Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360; Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377; Yu Z, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/2600428.2609563; Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799; Zemene E, 2019, IEEE T PATTERN ANAL, V41, P148, DOI 10.1109/TPAMI.2017.2787132; Zhang L, 2016, IEEE T IMAGE PROCESS, V25, P1177, DOI 10.1109/TIP.2016.2516952; Zhang TZ, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2602633; Zhang ZY, 2013, IEEE T PATTERN ANAL, V35, P1717, DOI 10.1109/TPAMI.2012.274; Zhen XT, 2018, IEEE T PATTERN ANAL, V40, P497, DOI 10.1109/TPAMI.2017.2688363; Zhou MM, 2014, INTERNATIONAL CONFERENCE ON EDUCATION AND SOCIAL SCIENCES (INTCESS14), VOLS I AND II, P487; Zhuang LS, 2015, IEEE T IMAGE PROCESS, V24, P3717, DOI 10.1109/TIP.2015.2441632	66	25	25	6	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1243	1256		10.1109/TPAMI.2019.2893953	http://dx.doi.org/10.1109/TPAMI.2019.2893953			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30668464				2022-12-18	WOS:000523685800017
J	Xie, JW; Lu, Y; Gao, RQ; Zhu, SC; Wu, YN				Xie, Jianwen; Lu, Yang; Gao, Ruiqi; Zhu, Song-Chun; Wu, Ying Nian			Cooperative Training of Descriptor and Generator Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generators; Training; Computational modeling; Inference algorithms; Heuristic algorithms; Analytical models; Deep generative models; Energy-based models; Latent variable models; Bottom-up and top-down convolutional neural networks; Modified contrastive divergence; MCMC teaching	MODELS; EXPERTS	This paper studies the cooperative training of two generative models for image modeling and synthesis. Both models are parametrized by convolutional neural networks (ConvNets). The first model is a deep energy-based model, whose energy function is defined by a bottom-up ConvNet, which maps the observed image to the energy. We call it the descriptor network. The second model is a generator network, which is a non-linear version of factor analysis. It is defined by a top-down ConvNet, which maps the latent factors to the observed image. The maximum likelihood learning algorithms of both models involve MCMC sampling such as Langevin dynamics. We observe that the two learning algorithms can be seamlessly interwoven into a cooperative learning algorithm that can train both models simultaneously. Specifically, within each iteration of the cooperative learning algorithm, the generator model generates initial synthesized examples to initialize a finite-step MCMC that samples and trains the energy-based descriptor model. After that, the generator model learns from how the MCMC changes its synthesized examples. That is, the descriptor model teaches the generator model by MCMC, so that the generator model accumulates the MCMC transitions and reproduces them by direct ancestral sampling. We call this scheme MCMC teaching. We show that the cooperative algorithm can learn highly realistic generative models.	[Xie, Jianwen] Hikvis Res Inst, Santa Clara, CA 95054 USA; [Lu, Yang] Facebook, Menlo Pk, CA 94025 USA; [Gao, Ruiqi; Zhu, Song-Chun; Wu, Ying Nian] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Facebook Inc; University of California System; University of California Los Angeles	Xie, JW (corresponding author), Hikvis Res Inst, Santa Clara, CA 95054 USA.	jianwen@ucla.edu; yanglv@ucla.edu; ruiqigao@ucla.edu; sczhu@stat.ucla.edu; ywu@stat.ucla.edu			NVIDIA Corporation; Hikvision gift fund; NSF [DMS 1310391]; DARPA SIMPLEX [N66001-15-C-4035]; ONR MURI [N00014-16-1-2007]; DARPA ARO [W911NF-16-1-0579]	NVIDIA Corporation; Hikvision gift fund; NSF(National Science Foundation (NSF)); DARPA SIMPLEX; ONR MURI(MURIOffice of Naval Research); DARPA ARO(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	We thank Hansheng Jiang, Zilong Zheng, Erik Nijkamp, Tengyu Liu, Yaxuan Zhu, Zhaozhuo Xu and Xiaolin Fang for their assistance with coding and experiments. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research. The work is supported by Hikvision gift fund, NSF DMS 1310391, DARPA SIMPLEX N66001-15-C-4035, ONR MURI N00014-16-1-2007, and DARPAAROW911NF-16-1-0579.	Abraham B., 2005, PROC INT WORKSHOP TE, V1, P53; [Anonymous], ARXIV170407820; [Anonymous], ARXIV171108875; [Anonymous], INTERPOLATION INPAIN; [Anonymous], P ADV NEUR INF PROC; [Anonymous], 2006, IEEE T AUTOM SCI ENG; [Anonymous], P INT C LEARN REPR; [Anonymous], P INT C LEARN REPR; [Anonymous], TECH REP; Bengio Y, 2014, PR MACH LEARN RES, V32, P226; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Brooks B, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02018-w; Chen X, 2016, ADV NEUR IN, V29; Costantini R, 2008, IEEE T IMAGE PROCESS, V17, P42, DOI 10.1109/TIP.2007.910956; Cover T.M., 2012, ELEMENTS INFORM THEO, DOI DOI 10.1002/047174882X; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Ghanem B, 2010, LECT NOTES COMPUT SC, V6312, P223; Girolami M, 2011, J R STAT SOC B, V73, P123, DOI 10.1111/j.1467-9868.2010.00765.x; Goncalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021; Grenander U., 2007, PATTERN THEORY REPRE; Han T, 2017, AAAI CONF ARTIF INTE, P1976; Hensel M, 2017, ADV NEUR IN, V30; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton Geoffrey, 2015, ARXIV150302531, P1, DOI DOI 10.1063/1.4931082; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jin L., 2017, ADV NEURAL INFORM PR, P823; Kim T., 2016, ARXIV160603439; King DB, 2015, ACS SYM SER, V1214, P1; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lazarow J, 2017, IEEE I CONF COMP VIS, P2793, DOI 10.1109/ICCV.2017.302; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Lu Y, 2016, AAAI CONF ARTIF INTE, P1902; Luxburg U. V., 2016, ADV NEURAL INFORM PR, V29, P4790; Mnih A, 2014, PR MACH LEARN RES, V32, P1791; Neal RM, 2011, CH CRC HANDB MOD STA, P113; Ng A., 2004, P 21 INT C MACH LEAR; Ngiam J., 2011, P 28 INT C MACHINE L, P1105; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Roth S, 2005, PROC CVPR IEEE, P860; RUBIN DB, 1982, PSYCHOMETRIKA, V47, P69, DOI 10.1007/BF02293851; Salakhutdinov R., 2009, P 12 INT C ART INT S, P448; Salimans T, 2016, ADV NEUR IN, V29; Seung HS, 1998, ADV NEUR IN, V10, P654; Sutton R. S., 1998, INTRO REINFORCEMENT, V135; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Teh YW, 2004, J MACH LEARN RES, V4, P1235; Tieleman T., 2008, P 25 INT C MACHINE L, P1064, DOI DOI 10.1145/1390156.1390290; Tu Z, 2007, PROC CVPR IEEE, P500; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wasserstein G.A.N., 2017, ARXIV170107875; Welling M, 2014, AUTOENCODING VARIATI; Wu YN, 2008, Q APPL MATH, V66, P81; Xie JW, 2018, AAAI CONF ARTIF INTE, P4292; Xie JW, 2018, PROC CVPR IEEE, P8629, DOI 10.1109/CVPR.2018.00900; Xie JW, 2016, PR MACH LEARN RES, V48; Xie JW, 2017, PROC CVPR IEEE, P1061, DOI 10.1109/CVPR.2017.119; Younes L., 1999, STOCHASTICS STOCHAST, V65, P177, DOI DOI 10.1080/17442509908834179; Yu F., 2015, ARXIVABS150603365 CO; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhou MM, 2014, INTERNATIONAL CONFERENCE ON EDUCATION AND SOCIAL SCIENCES (INTCESS14), VOLS I AND II, P487; Zhu SC, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P847, DOI 10.1109/ICCV.1998.710816; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627; Zhu ZQ, 2016, SIGNAL PROCESS, V124, P63, DOI 10.1016/j.sigpro.2015.10.025; Ziebart B. D., 2008, AAAI, V8, P1433	74	25	26	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					27	45		10.1109/TPAMI.2018.2879081	http://dx.doi.org/10.1109/TPAMI.2018.2879081			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30387724	Green Submitted, hybrid			2022-12-18	WOS:000502294300003
J	Tian, YC; Dehghan, A; Shah, M				Tian, Yicong; Dehghan, Afshin; Shah, Mubarak			On Detection, Data Association and Segmentation for Multi-Target Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiple target tracking; object segmentation; network flow; lagrangian relaxation; dual decomposition	MULTIOBJECT TRACKING; MULTIPLE; EXTRACTION; ALGORITHM	In this work, we propose a tracker that differs from most existing multi-target trackers in two major ways. First, our tracker does not rely on a pre-trained object detector to get the initial object hypotheses. Second, our tracker's final output is the fine contours of the targets rather than traditional bounding boxes. Therefore, our tracker simultaneously solves three main problems: detection, data association and segmentation. This is especially important because the output of each of those three problems are highly correlated and the solution of one can greatly help improve the others. The proposed algorithm consists of two main components: structured learning and Lagrange dual decomposition. Our structured learning based tracker learns a model for each target and infers the best locations of all targets simultaneously in a video clip. The inference of our structured learning is achieved through a new Target Identity-aware Network Flow (TINF), where each node in the network encodes the probability of each target identity belonging to that node. The probabilities are obtained by training target specific models using a global structured learning technique. This is followed by proposed Lagrangian relaxation optimization to find the high quality solution to the network. This forms the first component of our tracker. The second component is Lagrange dual decomposition, which combines the structured learning tracker with a segmentation algorithm. For segmentation, multi-label Conditional Random Field (CRF) is applied to a superpixel based spatio-temporal graph in a segment of video, in order to assign background or target labels to every superpixel. We show how the multi-label CRF is combined with the structured learning tracker through our dual decomposition formulation. This leads to more accurate segmentation results and also helps better resolve typical difficulties in multiple target tracking, such as occlusion handling, ID-switch and track drifting. The experiments on diverse and challenging sequences show that our method achieves superior results compared to competitive approaches for detection, multiple target tracking as well as segmentation.	[Tian, Yicong] Univ Cent Florida, Comp Sci, Orlando, FL 32816 USA; [Dehghan, Afshin] Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA; [Shah, Mubarak] Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida; State University System of Florida; University of Central Florida; State University System of Florida; University of Central Florida	Tian, YC (corresponding author), Univ Cent Florida, Comp Sci, Orlando, FL 32816 USA.	tyc.cong@gmail.com; adehghan@cs.ucf.edu; shah@crcv.ucf.edu		Shah, Mubarak/0000-0001-6172-5572				Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156; Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159; Bar-Shalom Y., 1980, P C INF SCI SYST, P404; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003; Bibby C, 2010, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2010.5539818; Bischof H., 2006, BMVC, P47; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232; Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Chen S, 2014, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2014.148; Crammer K, 2006, J MACH LEARN RES, V7, P551; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; DEHGHAN A, 2015, PROC CVPR IEEE, P4091, DOI DOI 10.1109/CVPR.2015; Domke J., 2006, BRIT MACH VIS C, P509; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50; Huayan Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2433, DOI 10.1109/CVPR.2011.5995722; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Karakostas G, 2002, SIAM PROC S, P166; Kumar KCA, 2013, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2013.250; Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148; Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170; Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273; Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735; Milan A, 2015, PROC CVPR IEEE, P5397, DOI 10.1109/CVPR.2015.7299178; Mitzel D, 2010, LECT NOTES COMPUT SC, V6311, P397, DOI 10.1007/978-3-642-15549-9_29; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Rematas K, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCV.2011.6126455; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41; Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7; Segal AV, 2013, IEEE I CONF COMP VIS, P2904, DOI 10.1109/ICCV.2013.361; Shafique K, 2005, IEEE T PATTERN ANAL, V27, P51, DOI 10.1109/TPAMI.2005.1; SHITRIT HB, 2014, IEEE T PATTERN ANAL, V36, P1614, DOI DOI 10.1109/TPAMI.2013.210; Shoou I.Yu, 2016, ARXIV160407468; Shu G, 2013, PROC CVPR IEEE, P3721, DOI 10.1109/CVPR.2013.477; Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879; Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394; Tang SY, 2013, IEEE I CONF COMP VIS, P1049, DOI 10.1109/ICCV.2013.134; TANG SY, 2015, PROC CVPR IEEE, P5033; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Wang XC, 2014, LECT NOTES COMPUT SC, V8689, P17, DOI 10.1007/978-3-319-10590-1_2; Wen LY, 2015, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2015.7298835; Wu B., 2006, 2006 IEEE COMP SOC C, V1, P951, DOI [10.1109/CVPR.2006.312, DOI 10.1109/CVPR.2006.312]; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Wu Z, 2012, PROC CVPR IEEE, P1948, DOI 10.1109/CVPR.2012.6247896; Yin ZZ, 2009, PROC CVPR IEEE, P731, DOI 10.1109/CVPRW.2009.5206674; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]; YU SI, 2016, PROC CVPR IEEE, P3871, DOI DOI 10.1109/CVPR.2016.420; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87; Zhang LJ, 2008, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006286.pub2; Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240	68	25	27	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2146	2160		10.1109/TPAMI.2018.2849374	http://dx.doi.org/10.1109/TPAMI.2018.2849374			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	29994110				2022-12-18	WOS:000480343900008
J	Ebadi, SE; Izquierdo, E				Ebadi, Salehe Erfanian; Izquierdo, Ebroul			Foreground Segmentation with Tree-Structured Sparse RPCA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Approximated RPCA; structured-sparse; moving camera; dynamic background; cohesive foreground segmentation	BACKGROUND SUBTRACTION; LOW-RANK	Background subtraction is a fundamental video analysis technique that consists of creation of a background model that allows distinguishing foreground pixels. We present a new method in which the image sequence is assumed to be made up of the sum of a low-rank background matrix and a dynamic tree-structured sparse matrix. The decomposition task is then solved using our approximated Robust Principal Component Analysis (ARPCA) method which is an extension to the RPCA that can handle camera motion and noise. Our model dynamically estimates the support of the foreground regions via a superpixel generation step, so that spatial coherence can be imposed on these regions. Unlike conventional smoothness constraints such as MRF, our method is able to obtain crisp and meaningful foreground regions, and in general, handles large dynamic background motion better. To reduce the dimensionality and the curse of scale that is persistent in the RPCA-based methods, we model the background via Column Subset Selection Problem, that reduces the order of complexity and hence decreases computation time. Comprehensive evaluation on four benchmark datasets demonstrate the effectiveness of our method in outperforming state-of-the-art alternatives.	[Ebadi, Salehe Erfanian; Izquierdo, Ebroul] Queen Mary Univ London, Dept Elect Engn & Comp Sci, Mile End Rd, London E1 4NS, England	University of London; Queen Mary University London	Ebadi, SE (corresponding author), Queen Mary Univ London, Dept Elect Engn & Comp Sci, Mile End Rd, London E1 4NS, England.	s.erfanianebadi@qmul.ac.uk; e.izquierdo@qmul.ac.uk			LASIE project; European Union	LASIE project; European Union(European Commission)	This work was supported in part by the LASIE project (http://www.lasie-project.eu/) with funding from the European Union's Seventh Framework Program for research and technological development.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; [Anonymous], 2012, CDET; Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613; Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741; Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Culibrk D, 2007, IEEE T NEURAL NETWOR, V18, P1614, DOI 10.1109/TNN.2007.896861; Ebadi SE, 2016, IEEE IMAGE PROC, P3972, DOI 10.1109/ICIP.2016.7533105; Ebadi SE, 2016, LECT NOTES COMPUT SC, V9905, P314, DOI 10.1007/978-3-319-46448-0_19; Evangelio R. H., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P71, DOI 10.1109/AVSS.2011.6027297; Evangelio RH, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P300, DOI 10.1109/AVSS.2012.69; Gao Z, 2014, IEEE T PATTERN ANAL, V36, P1975, DOI 10.1109/TPAMI.2014.2314663; Guyon C., 2012, P AS C COMP VIS, P315, DOI DOI 10.1007/978-3-642-37410-4_28; Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239; He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848; Huang JZ, 2009, IEEE I CONF COMP VIS, P64, DOI 10.1109/ICCV.2009.5459202; Jacob L., 2009, P 26 INT C MACH LEAR, P433, DOI DOI 10.1145/1553374.1553431; Javed S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P930, DOI 10.1109/ICCVW.2015.123; Jenatton R, 2011, J MACH LEARN RES, V12, P2777; Jia K, 2012, LECT NOTES COMPUT SC, V7575, P331, DOI 10.1007/978-3-642-33765-9_24; JOLLIFFE IT, 1972, APPL STAT, V21, P160, DOI DOI 10.2307/2346488; Lee J, 2010, PROCEEDINGS OF THE 17TH INTERNATIONAL CONGRESS ON SOUND AND VIBRATION; Li L., 2003, P 11 ACM INT C MULT, P2, DOI DOI 10.1145/957013.957017; Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169; Lin Z., 2010, 100920105055 ARXIV, P1, DOI DOI 10.1016/J.JSB.2012.10.010; Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084; Maddalena L., 2012, PROC IEEE COMPUT SOC, P21; Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285; Mairal J., 2010, ADV NEURAL INFORM PR, P1558, DOI [DOI 10.5555/2997046.2997070, 10.5555/2997046.2997070]; ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Papailiopoulos D, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P997, DOI 10.1145/2623330.2623698; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Qiu C., 2011, ARXIV11063286; Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882; Sajid H, 2015, IEEE IMAGE PROC, P4530, DOI 10.1109/ICIP.2015.7351664; Schick A., 2012, P IEEE COMP SOC C CO, P27, DOI DOI 10.1109/CVPRW.2012.6238923; Sobral A., 2015, PROC 12 IEEE INT C A, P1, DOI [10.1109/AVSS.2015.7301753, DOI 10.1109/AVSS.2015.7301753]; St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137; St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Tiefenbacher P, 2012, P IEEE COMP SOC C CO, P38, DOI DOI 10.1109/CVPRW.2012.6238925; Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228; Wang Yan, 2014, PETROLEUM KNOWLEDGE, P8; Xin B, 2015, PROC CVPR IEEE, P4676, DOI 10.1109/CVPR.2015.7299099; Zelnik-Manor L, 2012, IEEE T SIGNAL PROCES, V60, P2386, DOI 10.1109/TSP.2012.2187642; Zhou T., 2011, INT C MACH LEARN ICM; Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132; Zhou Z., 2010, COMPUT RES REPOSITOR; Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005	50	25	29	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2273	2280		10.1109/TPAMI.2017.2745573	http://dx.doi.org/10.1109/TPAMI.2017.2745573			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28858787	Green Published, Green Submitted			2022-12-18	WOS:000440868400018
J	Rodrigues, F; Borysov, SS; Ribeiro, B; Pereira, FC				Rodrigues, Filipe; Borysov, Stanislav S.; Ribeiro, Bernardete; Pereira, Francisco C.			A Bayesian Additive Model for Understanding Public Transport Usage in Special Events	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Additive models; transportation demand; Gaussian processes; expectation propagation		Public special events, like sports games, concerts and festivals are well known to create disruptions in transportation systems, often catching the operators by surprise. Although these are usually planned well in advance, their impact is difficult to predict, even when organisers and transportation operators coordinate. The problem highly increases when several events happen concurrently. To solve these problems, costly processes, heavily reliant on manual search and personal experience, are usual practice in large cities like Singapore, London or Tokyo. This paper presents a Bayesian additive model with Gaussian process components that combines smart card records from public transport with context information about events that is continuously mined from the Web. We develop an efficient approximate inference algorithm using expectation propagation, which allows us to predict the total number of public transportation trips to the special event areas, thereby contributing to a more adaptive transportation system. Furthermore, for multiple concurrent event scenarios, the proposed algorithm is able to disaggregate gross trip counts into their most likely components related to specific events and routine behavior. Using real data from Singapore, we show that the presented model outperforms the best baseline model by up to 26 percent in R-2 and also has explanatory power for its individual components.	[Rodrigues, Filipe; Pereira, Francisco C.] Tech Univ Denmark, Bygning 115, DK-2800 Lyngby, Denmark; [Borysov, Stanislav S.] Singapore MIT Alliance Res & Technol, 1 CREATE Way, Singapore 138602, Singapore; [Borysov, Stanislav S.] KTH Royal Inst Technol, Roslagstullsbacken 23, SE-10691 Stockholm, Sweden; [Borysov, Stanislav S.] Stockholm Univ, Roslagstullsbacken 23, SE-10691 Stockholm, Sweden; [Ribeiro, Bernardete] Univ Coimbra, Dept Informat Engn, CISUC, P-3030290 Coimbra, Portugal; [Pereira, Francisco C.] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Technical University of Denmark; Singapore-MIT Alliance for Research & Technology Centre (SMART); Royal Institute of Technology; Stockholm University; Universidade de Coimbra; Massachusetts Institute of Technology (MIT)	Rodrigues, F (corresponding author), Tech Univ Denmark, Bygning 115, DK-2800 Lyngby, Denmark.	rodr@dtu.dk; borysov@kth.se; bribeiro@dei.uc.pt; camara@mit.edu	Ribeiro, Bernardete/A-8010-2016; Rodrigues, Filipe/H-8695-2019; Borysov, Stanislav/O-7465-2017; Pereira, Francisco Camara/B-2111-2010	Ribeiro, Bernardete/0000-0002-9770-7672; Rodrigues, Filipe/0000-0001-6979-6498; Borysov, Stanislav/0000-0003-2810-9203; Pereira, Francisco Camara/0000-0001-5457-9909	Fundacao para a Ciencia e Tecnologia (FCT) [SFRH/BD/78396/2011, PTDC/ECM-TRA/1898/2012]	Fundacao para a Ciencia e Tecnologia (FCT)(Portuguese Foundation for Science and TechnologyEuropean Commission)	The Fundacao para a Ciencia e Tecnologia (FCT) is gratefully acknowledged for founding this work with the grants SFRH/BD/78396/2011 and PTDC/ECM-TRA/1898/2012 (InfoCROWDS).	Barber D., 2012, BAYESIAN REASONING M; Ben-Akiva M. E., 1987, DISCRETE CHOICE ANAL; Bishop CM, 2013, PHILOS T R SOC A, V371, DOI 10.1098/rsta.2012.0222; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bolte F., 2006, TRANSPORT POLICY OBJ; BORG I., 2005, MODERN MULTIDIMENSIO, P207; Calabrese F, 2010, LECT NOTES COMPUT SC, V6030, P22, DOI 10.1007/978-3-642-12654-3_2; CHANG MS, 2013, J E ASIA SOC TRANSPO, V10, P710; Chipman HA, 2010, ANN APPL STAT, V4, P266, DOI 10.1214/09-AOAS285; Coutroubas F., 2003, P EUR TRANSP C; Duvenaud D.K., 2011, ADV NEURAL INFORM PR, P226; FHWA, 2006, FHWAHOP06113; HASTIE T, 2003, ELEMENTS STAT LEARNI; Hastie T. J., 1990, GEN ADDITIVE MODELS, V43; Ide T., 2009, P 2009 SIAM INT C DA, P1185, DOI DOI 10.1137/1.9781611972795.101; Krygsman S., 2004, TRANSPORT POLICY, V11, P265, DOI DOI 10.1016/j.tranpol.2003.12.001; Kuppam A, 2011, TRANSPORT RES REC, P24, DOI 10.3141/2246-04; Kwon JY, 2006, TRANSPORT RES REC, P84, DOI 10.3141/1959-10; Middleham F., 2006, DYNAMIC TRAFFIC MANA; Minka T., 2012, INFER NET 2 5; Minka T.P., 2001, P 17 C UNC ART INT, P362; Neumann M, 2009, IEEE DATA MINING, P387, DOI 10.1109/ICDM.2009.56; Pereira F., 2013, J INTELL TRANSP SYST, V19, P273; Pereira FC, 2015, IEEE T INTELL TRANSP, V16, P1370, DOI 10.1109/TITS.2014.2368119; Potier F., 2003, EUR TRANSP C STRASB; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Ravikumar P, 2009, J R STAT SOC B, V71, P1009, DOI 10.1111/j.1467-9868.2009.00718.x; van Oort N., 2015, P 9 ANN M TRANSP RES, P105; Winkler W.E, 1990, P SECT SURV RES ISS; Xie YC, 2010, TRANSPORT RES REC, P69, DOI 10.3141/2165-08; Zheng Y., 2015, IEEE T BIG DATA, V1, P16, DOI 10.1109/TBDATA.2015.2465959; Zheng Y, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2629592; Zheng Y, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1436, DOI 10.1145/2487575.2488188; Zhong MJ, 2014, ADV NEUR IN, V27	35	25	26	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2113	2126		10.1109/TPAMI.2016.2635136	http://dx.doi.org/10.1109/TPAMI.2016.2635136			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	28113999	Green Submitted			2022-12-18	WOS:000412028600001
J	Xiong, CM; Johnson, DM; Corso, JJ				Xiong, Caiming; Johnson, David M.; Corso, Jason J.			Active Clustering with Model-Based Uncertainty Reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active clustering; semi-supervised clustering; image clustering; uncertainty reduction	CONSTRAINTS	Semi-supervised clustering seeks to augment traditional clustering methods by incorporating side information provided via human expertise in order to increase the semantic meaningfulness of the resulting clusters. However, most current methods are passive in the sense that the side information is provided beforehand and selected randomly. This may require a large number of constraints, some of which could be redundant, unnecessary, or even detrimental to the clustering results. Thus in order to scale such semi-supervised algorithms to larger problems it is desirable to pursue an active clustering method-i.e., an algorithm that maximizes the effectiveness of the available human labor by only requesting human input where it will have the greatest impact. Here, we propose a novel online framework for active semi-supervised spectral clustering that selects pairwise constraints as clustering proceeds, based on the principle of uncertainty reduction. Using a first-order Taylor expansion, we decompose the expected uncertainty reduction problem into a gradient and a step-scale, computed via an application of matrix perturbation theory and cluster-assignment entropy, respectively. The resulting model is used to estimate the uncertainty reduction potential of each sample in the dataset. We then present the human user with pairwise queries with respect to only the best candidate sample. We evaluate our method using three different image datasets (faces, leaves and dogs), a set of common UCI machine learning datasets and a gene dataset. The results validate our decomposition formulation and show that our method is consistently superior to existing state-of-the-art techniques, as well as being robust to noise and to unknown numbers of clusters.	[Xiong, Caiming] Metamind Inc, Palo Alto, CA 94301 USA; [Johnson, David M.] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA; [Corso, Jason J.] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo; University of Michigan System; University of Michigan	Xiong, CM (corresponding author), Metamind Inc, Palo Alto, CA 94301 USA.	cmxiong.lhi@gmail.com; davidjoh@buffalo.edu; jjcorso@eecs.umich.edu		Johnson, David M/0000-0002-0861-3528; Corso, Jason/0000-0001-6454-9594	NSF CAREER [IIS-0845282]; ARO YIP [W911NF-11-1-0090]; DARPA Minds Eye [W911NF-10-2-0062]; DARPA CSSG [D11AP00245]; NPS [N00244-11-1-0022]	NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); ARO YIP; DARPA Minds Eye; DARPA CSSG(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); NPS	The authors are grateful for the support in part provided through the following grants: NSF CAREER IIS-0845282, ARO YIP W911NF-11-1-0090, DARPA Minds Eye W911NF-10-2-0062, DARPA CSSG D11AP00245, and NPS N00244-11-1-0022. Findings are those of the authors and do not reflect the views of the funding agencies.	Agrawal H., 2013, CLOUDCV LARGE SCALE; [Anonymous], 2007, P INT C MACH LEARN, DOI DOI 10.1145/1273496.1273542; Basu S, 2004, SIAM PROC S, P333; Basu Sugato, 2004, KDD, P59, DOI DOI 10.1145/1014052.1014062; Beygelzimer A., 2010, P ADV NEUR INF PROC, P199; Biswas A., 2011, P INT C MACH LEARN W, V2; Biswas A, 2014, INT J COMPUT VISION, V108, P133, DOI 10.1007/s11263-013-0680-6; Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980; Caiming Xiong, 2012, Proceedings of the IADIS International Conference on Intelligent Systems and Agents 2012 and IADIS European Conference on Data Mining 2012. Part of the IADIS Multi Conference on Computer Science and Information Systems 2012, P133; Chen L., 2011, P SIAM INT C DAT MIN, P862; Chen X., 2011, ASS ADV ART INT SAN; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; Davidson I, 2006, LECT NOTES ARTIF INT, V4213, P115; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Hoi S. C. H., 2008, P INT C MACH LEARN, P400, DOI DOI 10.1145/1390156.1390207; Huang RZ, 2009, DATA KNOWL ENG, V68, P49, DOI 10.1016/j.datak.2008.08.008; Huang SJ, 2014, IEEE T PATTERN ANAL, V36, P1936, DOI 10.1109/TPAMI.2014.2307881; Jain P, 2009, PROC CVPR IEEE, P762, DOI 10.1109/CVPRW.2009.5206651; Jiang L., 2008, 11 IEEE WORKSH DES E, P1, DOI [10.1109/CVPR.2008.4587451, DOI 10.1109/DDECS.2008.4538763>]; Kamvar S. D., 2003, P 18 INT JOINT C ART, P561; Khosla A., 2011, P WORKSH FIN GRAIN V; Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li ZG, 2009, IEEE I CONF COMP VIS, P421, DOI 10.1109/ICCV.2009.5459157; Lichman M, 2013, UCI MACHINE LEARNING; Mallapragada PK, 2008, INT C PATT RECOG, P2376; Ng AY, 2002, ADV NEUR IN, V14, P849; Pang-Ning T., 2006, INTRO DATA MINING; Rosenberg A., 2007, P 2007 JOINT C EMP M, P410; SETTLES B, 2010, 1648 U WISC; Stewart G.W., 1990, MATRIX PERTURBATION, V175; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Wang F, 2009, IEEE DATA MINING, P562, DOI 10.1109/ICDM.2009.66; Wauthier F. L., 2012, P 8 ACM SIGKDD INT C, P1339; Xing E. P., 2003, ADV NEURAL INF PROCE, P521; Xiong C., 2013, P ASS ADV ART INT, P149; Xiong C., 2012, P EUR C ART INT, P12; Xiong SC, 2014, IEEE T KNOWL DATA EN, V26, P43, DOI 10.1109/TKDE.2013.22; Xu QJ, 2005, LECT NOTES COMPUT SC, V3735, P294; Yan DH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P907; Zhang, 2011, P 20 ACM C INF KNOWL, P2161; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460	44	25	27	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					5	17		10.1109/TPAMI.2016.2539965	http://dx.doi.org/10.1109/TPAMI.2016.2539965			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26978555	hybrid, Green Submitted			2022-12-18	WOS:000390421300003
J	Panagakis, Y; Nicolaou, MA; Zafeiriou, S; Pantic, M				Panagakis, Yannis; Nicolaou, Mihalis A.; Zafeiriou, Stefanos; Pantic, Maja			Robust Correlated and Individual Component Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-modal analysis; canonical correlation analysis; individual components; time warping; low-rank; sparsity	CANONICAL CORRELATION-ANALYSIS; FUSION; CONVERSATIONS; RECOGNITION; FORMULATION; ALGORITHM; SUBSPACE; SETS	Recovering correlated and individual components of two, possibly temporally misaligned, sets of data is a fundamental task in disciplines such as image, vision, and behavior computing, with application to problems such as multi-modal fusion (via correlated components), predictive analysis, and clustering (via the individual ones). Here, we study the extraction of correlated and individual components under real-world conditions, namely i) the presence of gross non-Gaussian noise and ii) temporally misaligned data. In this light, we propose a method for the Robust Correlated and Individual Component Analysis (RCICA) of two sets of data in the presence of gross, sparse errors. We furthermore extend RCICA in order to handle temporal incongruities arising in the data. To this end, two suitable optimization problems are solved. The generality of the proposed methods is demonstrated by applying them onto 4 applications, namely i) heterogeneous face recognition, ii) multi-modal feature fusion for human behavior analysis (i.e., audio-visual prediction of interest and conflict), iii) face clustering, and iv) the temporal alignment of facial expressions. Experimental results on 2 synthetic and 7 real world datasets indicate the robustness and effectiveness of the proposed methods on these application domains, outperforming other state-of-the-art methods in the field.	[Panagakis, Yannis] Imperial Coll London, Dept Comp, London, England; [Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, Pattern Recognit Stat Machine Learning Comp Vis, London, England; [Nicolaou, Mihalis A.] Goldsmiths Univ London, Dept Comp, London, England; [Pantic, Maja] Imperial Coll London, Dept Comp, Affect & Behav Comp, London, England; [Pantic, Maja] Univ Twente, EEMCS, POB 217, NL-7500 AE Enschede, Netherlands	Imperial College London; Imperial College London; University of London; Goldsmiths University London; Imperial College London; University of Twente	Panagakis, Y (corresponding author), Imperial Coll London, Dept Comp, London, England.	i.panagakis@imperial.ac.uk; m.nicolaou@gold.ac.uk; s.zafeiriou@imperial.ac.uk; m.pantic@imperial.ac.uk		Panagakis, Ioannis/0000-0003-0153-5210	Engineering and Physical Sciences Research Council [EP/N007743/1, EP/J017787/1, EP/H016988/1] Funding Source: researchfish; EPSRC [EP/J017787/1, EP/N007743/1, EP/H016988/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Akaho S., 2001, INT M PSYCH SOC, P263; Andrew Galen, 2013, ICML; Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0; Bach Francis R, 2005, TECHNICAL REPORT; Bao CL, 2013, IEEE I CONF COMP VIS, P3384, DOI 10.1109/ICCV.2013.420; Bertsekas DP., 1996, CONSTRAINED OPTIMIZA, V1st edn; Cai J. F., 2009, SIAM J OPTIMIZ, V2, P569; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chu DL, 2013, IEEE T PATTERN ANAL, V35, P3050, DOI 10.1109/TPAMI.2013.104; COOPER VW, 1986, J NONVERBAL BEHAV, V10, P134, DOI 10.1007/BF01000009; Correa NM, 2009, INT CONF ACOUST SPEE, P385, DOI 10.1109/ICASSP.2009.4959601; De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Fazel Maryam, 2002, THESIS, P3; Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Huang D, 2012, LECT NOTES COMPUT SC, V7575, P616, DOI 10.1007/978-3-642-33765-9_44; Huber P., 1981, ROBUST STAT; Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68; KETTENRING JR, 1971, BIOMETRIKA, V58, P433, DOI 10.1093/biomet/58.3.433; Kim S, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1166; Kim S, 2012, INT CONF ACOUST SPEE, P5089, DOI 10.1109/ICASSP.2012.6289065; Klami A, 2013, J MACH LEARN RES, V14, P965; LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li SZ, 2009, PROC CVPR IEEE, P267, DOI 10.1109/FSKD.2009.137; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2012, NEURAL COMPUT, V24, P3371, DOI 10.1162/NECO_a_00369; Lock EF, 2013, ANN APPL STAT, V7, P523, DOI 10.1214/12-AOAS597; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26; Martinez A., 1998, AR FACE DATABASE; McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9; Nicolaou MA, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853852; Nicolaou MA, 2014, IEEE T PATTERN ANAL, V36, P1299, DOI 10.1109/TPAMI.2014.16; Orozco J, 2013, IMAGE VISION COMPUT, V31, P322, DOI 10.1016/j.imavis.2013.02.001; Panagakis Y., 2012, P 13 INT C MUS INF R, P271; Panagakis Y, 2014, IEEE-ACM T AUDIO SPE, V22, P1905, DOI 10.1109/TASLP.2014.2355774; Panagakis Y, 2013, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.2013.76; Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424; Papamakarios G., 2014, P BRIT MACH VIS C BM, P11; Patras I, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P97, DOI 10.1109/AFGR.2004.1301515; Pentland A, 2005, P IEEE INT C COMP VI; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1963; Schuller B, 2009, IMAGE VISION COMPUT, V27, P1760, DOI 10.1016/j.imavis.2009.02.013; Schumann E., 2010, CREATING RANK CORREL; Shan C., 2007, BMVC, P1; Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163; Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160; Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tzimiropoulos G, 2012, IEEE T PATTERN ANAL, V34, P2454, DOI 10.1109/TPAMI.2012.40; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Xu W., 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhou F., 2009, ADV NEURAL INFORM PR, V22, P2286; Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812; Zhou GX, 2016, IEEE T NEUR NET LEAR, V27, P2426, DOI 10.1109/TNNLS.2015.2487364; Zou H., 2004, J COMPUT GRAPH STAT, V15, P2006	65	25	25	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1665	1678		10.1109/TPAMI.2015.2497700	http://dx.doi.org/10.1109/TPAMI.2015.2497700			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26552077	Green Submitted, Green Accepted			2022-12-18	WOS:000379926200014
